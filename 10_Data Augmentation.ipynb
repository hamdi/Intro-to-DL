{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627b97ec-6b94-427a-9c77-44e576fe2bee",
   "metadata": {},
   "source": [
    "### Notebook 10: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05048cc-4d1c-471a-bb1b-22274f6a3f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import pycocotools.mask as mask_util\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.modeling import DatasetMapperTTA\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb2721d-ec83-42a5-b68d-a28314460ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=Path('../')\n",
    "register_coco_instances('sartorius_train',{}, '../sartorius-annotations-coco-format/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_val',{},'../sartorius-annotations-coco-format/annotations_val.json', dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e223e8-1373-48e1-96ed-fc1dc645436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = [0.204, 0.386, 0.568]\n",
    "min_mask_area = [75, 150, 75]\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    false_positives = np.sum(matches, axis=0) == 0\n",
    "    if len(matches.shape)>1:\n",
    "        false_negatives = np.sum(matches, axis=1) == 0\n",
    "        true_positives = np.sum(matches, axis=1) == 1\n",
    "    else:\n",
    "        false_negatives = 0\n",
    "        true_positives = 0\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n",
    "    take = pred['instances'].scores >= score_threshold[pred_class]\n",
    "    pred_masks = pred['instances'].pred_masks[take].cpu().numpy()\n",
    "    if len(pred_masks)==0:\n",
    "        return 0.\n",
    "    else:\n",
    "        enc_preds = []\n",
    "        used = np.zeros(pred_masks[0].shape, dtype=int)\n",
    "        for mask in pred_masks:\n",
    "            mask = (mask * (1-used)).astype(bool)\n",
    "            if mask.sum() >= min_mask_area[pred_class]:\n",
    "                used += mask\n",
    "                enc_preds.append(mask_util.encode(np.asarray(mask, order='F')) )\n",
    "        enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "        ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "        prec = []\n",
    "        for t in np.arange(0.5, 1.0, 0.05):\n",
    "            tp, fp, fn = precision_at(t, ious)\n",
    "            p = tp / (tp + fp + fn)\n",
    "            prec.append(p)\n",
    "        return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"mAP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e617845-c7f3-4f73-8b4f-aac34977d8ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/08 18:47:55 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/08 18:47:56 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/08 18:48:00 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/08 18:48:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: []\n",
      "\u001b[32m[02/08 18:48:00 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/08 18:48:01 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/08 18:48:01 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/08 18:48:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/08 18:48:01 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 18:48:01 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/08 18:48:01 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/08 18:48:08 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 19  total_loss: 3.35  loss_cls: 1.362  loss_box_reg: 0.6466  loss_mask: 0.6934  loss_rpn_cls: 0.3992  loss_rpn_loc: 0.2887  time: 0.3142  data_time: 0.0243  lr: 9.9905e-06  max_mem: 2646M\n",
      "\u001b[32m[02/08 18:48:15 d2.utils.events]: \u001b[0m eta: 0:51:25  iter: 39  total_loss: 3.361  loss_cls: 1.287  loss_box_reg: 0.6772  loss_mask: 0.6877  loss_rpn_cls: 0.358  loss_rpn_loc: 0.3167  time: 0.3292  data_time: 0.0359  lr: 1.998e-05  max_mem: 3235M\n",
      "\u001b[32m[02/08 18:48:23 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 59  total_loss: 3.111  loss_cls: 1.113  loss_box_reg: 0.7385  loss_mask: 0.6725  loss_rpn_cls: 0.3235  loss_rpn_loc: 0.2469  time: 0.3462  data_time: 0.0640  lr: 2.997e-05  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:48:30 d2.utils.events]: \u001b[0m eta: 0:52:30  iter: 79  total_loss: 2.892  loss_cls: 0.8857  loss_box_reg: 0.8778  loss_mask: 0.6395  loss_rpn_cls: 0.2595  loss_rpn_loc: 0.2472  time: 0.3437  data_time: 0.0124  lr: 3.9961e-05  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:48:37 d2.utils.events]: \u001b[0m eta: 0:53:29  iter: 99  total_loss: 2.805  loss_cls: 0.7834  loss_box_reg: 0.8612  loss_mask: 0.6122  loss_rpn_cls: 0.2635  loss_rpn_loc: 0.2533  time: 0.3454  data_time: 0.0152  lr: 4.9951e-05  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:48:43 d2.utils.events]: \u001b[0m eta: 0:53:43  iter: 119  total_loss: 2.661  loss_cls: 0.7369  loss_box_reg: 0.8449  loss_mask: 0.595  loss_rpn_cls: 0.2308  loss_rpn_loc: 0.2276  time: 0.3442  data_time: 0.0102  lr: 5.9941e-05  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:48:51 d2.utils.events]: \u001b[0m eta: 0:54:05  iter: 139  total_loss: 2.61  loss_cls: 0.7254  loss_box_reg: 0.8485  loss_mask: 0.5728  loss_rpn_cls: 0.1998  loss_rpn_loc: 0.2499  time: 0.3484  data_time: 0.0460  lr: 6.993e-05  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:48:58 d2.utils.events]: \u001b[0m eta: 0:54:29  iter: 159  total_loss: 2.404  loss_cls: 0.6917  loss_box_reg: 0.8296  loss_mask: 0.5225  loss_rpn_cls: 0.2003  loss_rpn_loc: 0.2007  time: 0.3522  data_time: 0.0402  lr: 7.9921e-05  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:49:05 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 179  total_loss: 2.298  loss_cls: 0.6306  loss_box_reg: 0.8071  loss_mask: 0.4862  loss_rpn_cls: 0.1329  loss_rpn_loc: 0.1774  time: 0.3505  data_time: 0.0179  lr: 8.991e-05  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:49:12 d2.utils.events]: \u001b[0m eta: 0:54:01  iter: 199  total_loss: 2.241  loss_cls: 0.6296  loss_box_reg: 0.7983  loss_mask: 0.4697  loss_rpn_cls: 0.1684  loss_rpn_loc: 0.2041  time: 0.3512  data_time: 0.0361  lr: 9.9901e-05  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:49:19 d2.utils.events]: \u001b[0m eta: 0:53:54  iter: 219  total_loss: 2.123  loss_cls: 0.5678  loss_box_reg: 0.8147  loss_mask: 0.4411  loss_rpn_cls: 0.1362  loss_rpn_loc: 0.1739  time: 0.3492  data_time: 0.0083  lr: 0.00010989  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:49:26 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 239  total_loss: 1.962  loss_cls: 0.5098  loss_box_reg: 0.7824  loss_mask: 0.3986  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.1559  time: 0.3484  data_time: 0.0188  lr: 0.00011988  max_mem: 3244M\n",
      "\u001b[32m[02/08 18:49:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:49:27 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/08 18:49:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 18:49:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 18:49:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 18:49:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:49:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 18:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.2049 s/iter. Eval: 0.0494 s/iter. Total: 0.2550 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/08 18:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0008 s/iter. Inference: 0.2021 s/iter. Eval: 0.0822 s/iter. Total: 0.2852 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 18:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.2030 s/iter. Eval: 0.1034 s/iter. Total: 0.3073 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 18:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0008 s/iter. Inference: 0.2017 s/iter. Eval: 0.1104 s/iter. Total: 0.3129 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/08 18:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.2026 s/iter. Eval: 0.1095 s/iter. Total: 0.3129 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 18:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.2028 s/iter. Eval: 0.1324 s/iter. Total: 0.3361 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 18:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.2040 s/iter. Eval: 0.1417 s/iter. Total: 0.3466 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/08 18:50:07 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.2053 s/iter. Eval: 0.1299 s/iter. Total: 0.3361 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/08 18:50:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.031969 (0.336482 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:50:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:23 (0.205505 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:50:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 18:50:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.07089455476114787\n",
      "\u001b[32m[02/08 18:50:14 d2.utils.events]: \u001b[0m eta: 0:53:49  iter: 259  total_loss: 2.047  loss_cls: 0.5215  loss_box_reg: 0.7988  loss_mask: 0.3826  loss_rpn_cls: 0.1547  loss_rpn_loc: 0.1979  time: 0.3485  data_time: 0.0144  lr: 0.00012987  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:50:22 d2.utils.events]: \u001b[0m eta: 0:54:00  iter: 279  total_loss: 1.959  loss_cls: 0.4547  loss_box_reg: 0.7529  loss_mask: 0.399  loss_rpn_cls: 0.1511  loss_rpn_loc: 0.2016  time: 0.3537  data_time: 0.0736  lr: 0.00013986  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:50:29 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 299  total_loss: 1.902  loss_cls: 0.4712  loss_box_reg: 0.761  loss_mask: 0.3511  loss_rpn_cls: 0.1371  loss_rpn_loc: 0.1898  time: 0.3531  data_time: 0.0184  lr: 0.00014985  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:50:36 d2.utils.events]: \u001b[0m eta: 0:53:41  iter: 319  total_loss: 1.716  loss_cls: 0.3952  loss_box_reg: 0.74  loss_mask: 0.3253  loss_rpn_cls: 0.09719  loss_rpn_loc: 0.1403  time: 0.3522  data_time: 0.0210  lr: 0.00015984  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:50:43 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 339  total_loss: 1.57  loss_cls: 0.3775  loss_box_reg: 0.6884  loss_mask: 0.3281  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.1293  time: 0.3509  data_time: 0.0157  lr: 0.00016983  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:50:49 d2.utils.events]: \u001b[0m eta: 0:53:04  iter: 359  total_loss: 1.75  loss_cls: 0.3935  loss_box_reg: 0.7138  loss_mask: 0.3338  loss_rpn_cls: 0.1222  loss_rpn_loc: 0.1907  time: 0.3489  data_time: 0.0073  lr: 0.00017982  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:50:57 d2.utils.events]: \u001b[0m eta: 0:53:05  iter: 379  total_loss: 1.831  loss_cls: 0.4309  loss_box_reg: 0.7418  loss_mask: 0.3678  loss_rpn_cls: 0.1432  loss_rpn_loc: 0.187  time: 0.3516  data_time: 0.0600  lr: 0.00018981  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:51:04 d2.utils.events]: \u001b[0m eta: 0:53:12  iter: 399  total_loss: 1.754  loss_cls: 0.4133  loss_box_reg: 0.6841  loss_mask: 0.3396  loss_rpn_cls: 0.1264  loss_rpn_loc: 0.1954  time: 0.3519  data_time: 0.0186  lr: 0.0001998  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:51:12 d2.utils.events]: \u001b[0m eta: 0:53:10  iter: 419  total_loss: 1.749  loss_cls: 0.3932  loss_box_reg: 0.6713  loss_mask: 0.3426  loss_rpn_cls: 0.1321  loss_rpn_loc: 0.1906  time: 0.3529  data_time: 0.0359  lr: 0.00020979  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:51:19 d2.utils.events]: \u001b[0m eta: 0:53:08  iter: 439  total_loss: 1.786  loss_cls: 0.4126  loss_box_reg: 0.6918  loss_mask: 0.3305  loss_rpn_cls: 0.1253  loss_rpn_loc: 0.208  time: 0.3530  data_time: 0.0212  lr: 0.00021978  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:51:25 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 459  total_loss: 1.824  loss_cls: 0.4345  loss_box_reg: 0.7032  loss_mask: 0.3341  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.165  time: 0.3524  data_time: 0.0219  lr: 0.00022977  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:51:32 d2.utils.events]: \u001b[0m eta: 0:52:50  iter: 479  total_loss: 1.597  loss_cls: 0.3822  loss_box_reg: 0.6579  loss_mask: 0.3253  loss_rpn_cls: 0.09546  loss_rpn_loc: 0.1573  time: 0.3517  data_time: 0.0202  lr: 0.00023976  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:51:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:51:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 18:51:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 18:51:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 18:51:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:51:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 18:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1725 s/iter. Eval: 0.0965 s/iter. Total: 0.2698 s/iter. ETA=0:00:29\n",
      "\u001b[32m[02/08 18:51:43 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0008 s/iter. Inference: 0.1914 s/iter. Eval: 0.1879 s/iter. Total: 0.3802 s/iter. ETA=0:00:36\n",
      "\u001b[32m[02/08 18:51:48 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0008 s/iter. Inference: 0.1850 s/iter. Eval: 0.1793 s/iter. Total: 0.3651 s/iter. ETA=0:00:29\n",
      "\u001b[32m[02/08 18:51:53 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0008 s/iter. Inference: 0.1855 s/iter. Eval: 0.1856 s/iter. Total: 0.3721 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 18:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0008 s/iter. Inference: 0.1858 s/iter. Eval: 0.1846 s/iter. Total: 0.3713 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/08 18:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.1876 s/iter. Eval: 0.1994 s/iter. Total: 0.3879 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 18:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.1887 s/iter. Eval: 0.2231 s/iter. Total: 0.4126 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 18:52:14 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1906 s/iter. Eval: 0.2300 s/iter. Total: 0.4214 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 18:52:20 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.1894 s/iter. Eval: 0.2296 s/iter. Total: 0.4198 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 18:52:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.832438 (0.412349 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:52:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.188760 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:52:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 18:52:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.13066040772950602\n",
      "\u001b[32m[02/08 18:52:30 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 499  total_loss: 1.585  loss_cls: 0.3413  loss_box_reg: 0.6483  loss_mask: 0.3443  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.1437  time: 0.3520  data_time: 0.0457  lr: 0.00024975  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:52:37 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 519  total_loss: 1.69  loss_cls: 0.3794  loss_box_reg: 0.6732  loss_mask: 0.3205  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.185  time: 0.3519  data_time: 0.0296  lr: 0.00025974  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:52:44 d2.utils.events]: \u001b[0m eta: 0:52:30  iter: 539  total_loss: 1.686  loss_cls: 0.3973  loss_box_reg: 0.6595  loss_mask: 0.3301  loss_rpn_cls: 0.0979  loss_rpn_loc: 0.208  time: 0.3518  data_time: 0.0159  lr: 0.00026973  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:52:51 d2.utils.events]: \u001b[0m eta: 0:52:27  iter: 559  total_loss: 1.602  loss_cls: 0.352  loss_box_reg: 0.6156  loss_mask: 0.3249  loss_rpn_cls: 0.109  loss_rpn_loc: 0.1883  time: 0.3524  data_time: 0.0294  lr: 0.00027972  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:52:58 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 579  total_loss: 1.614  loss_cls: 0.3764  loss_box_reg: 0.6522  loss_mask: 0.3333  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.1663  time: 0.3523  data_time: 0.0157  lr: 0.00028971  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:53:05 d2.utils.events]: \u001b[0m eta: 0:52:24  iter: 599  total_loss: 1.643  loss_cls: 0.4372  loss_box_reg: 0.6577  loss_mask: 0.3184  loss_rpn_cls: 0.09778  loss_rpn_loc: 0.1688  time: 0.3519  data_time: 0.0094  lr: 0.0002997  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:53:12 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 619  total_loss: 1.652  loss_cls: 0.3961  loss_box_reg: 0.6291  loss_mask: 0.3123  loss_rpn_cls: 0.08869  loss_rpn_loc: 0.1648  time: 0.3522  data_time: 0.0289  lr: 0.00030969  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:53:19 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 639  total_loss: 1.736  loss_cls: 0.4157  loss_box_reg: 0.6482  loss_mask: 0.3063  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.1982  time: 0.3524  data_time: 0.0248  lr: 0.00031968  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:53:26 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 659  total_loss: 1.586  loss_cls: 0.3841  loss_box_reg: 0.6162  loss_mask: 0.3257  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.1547  time: 0.3521  data_time: 0.0228  lr: 0.00032967  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:53:34 d2.utils.events]: \u001b[0m eta: 0:52:00  iter: 679  total_loss: 1.695  loss_cls: 0.3772  loss_box_reg: 0.6543  loss_mask: 0.3253  loss_rpn_cls: 0.1181  loss_rpn_loc: 0.1954  time: 0.3525  data_time: 0.0310  lr: 0.00033966  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:53:41 d2.utils.events]: \u001b[0m eta: 0:51:52  iter: 699  total_loss: 1.606  loss_cls: 0.352  loss_box_reg: 0.6243  loss_mask: 0.3252  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.1561  time: 0.3524  data_time: 0.0199  lr: 0.00034965  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:53:48 d2.utils.events]: \u001b[0m eta: 0:51:47  iter: 719  total_loss: 1.673  loss_cls: 0.3907  loss_box_reg: 0.6359  loss_mask: 0.338  loss_rpn_cls: 0.118  loss_rpn_loc: 0.1737  time: 0.3530  data_time: 0.0375  lr: 0.00035964  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:53:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:53:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 18:53:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 18:53:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 18:53:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:53:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 18:53:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1537 s/iter. Eval: 0.0825 s/iter. Total: 0.2369 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 18:53:59 d2.evaluation.evaluator]: \u001b[0mInference done 24/121. Dataloading: 0.0008 s/iter. Inference: 0.1658 s/iter. Eval: 0.1923 s/iter. Total: 0.3589 s/iter. ETA=0:00:34\n",
      "\u001b[32m[02/08 18:54:04 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0008 s/iter. Inference: 0.1638 s/iter. Eval: 0.1866 s/iter. Total: 0.3512 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/08 18:54:09 d2.evaluation.evaluator]: \u001b[0mInference done 54/121. Dataloading: 0.0008 s/iter. Inference: 0.1623 s/iter. Eval: 0.1853 s/iter. Total: 0.3485 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 18:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.1604 s/iter. Eval: 0.1825 s/iter. Total: 0.3438 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 18:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1633 s/iter. Eval: 0.2103 s/iter. Total: 0.3744 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/08 18:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.1651 s/iter. Eval: 0.2148 s/iter. Total: 0.3807 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 18:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.1649 s/iter. Eval: 0.2160 s/iter. Total: 0.3818 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 18:54:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.412712 (0.374248 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:54:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.165264 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:54:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 18:54:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.16848498484295077\n",
      "\u001b[32m[02/08 18:54:41 d2.utils.events]: \u001b[0m eta: 0:51:41  iter: 739  total_loss: 1.482  loss_cls: 0.3314  loss_box_reg: 0.6078  loss_mask: 0.3205  loss_rpn_cls: 0.08175  loss_rpn_loc: 0.1662  time: 0.3530  data_time: 0.0196  lr: 0.00036963  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:54:49 d2.utils.events]: \u001b[0m eta: 0:51:39  iter: 759  total_loss: 1.727  loss_cls: 0.4023  loss_box_reg: 0.6712  loss_mask: 0.3433  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.199  time: 0.3542  data_time: 0.0570  lr: 0.00037962  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:54:56 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 779  total_loss: 1.705  loss_cls: 0.3993  loss_box_reg: 0.6515  loss_mask: 0.3265  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.1851  time: 0.3541  data_time: 0.0146  lr: 0.00038961  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:03 d2.utils.events]: \u001b[0m eta: 0:51:26  iter: 799  total_loss: 1.485  loss_cls: 0.3549  loss_box_reg: 0.6027  loss_mask: 0.3086  loss_rpn_cls: 0.08264  loss_rpn_loc: 0.1443  time: 0.3537  data_time: 0.0103  lr: 0.0003996  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:10 d2.utils.events]: \u001b[0m eta: 0:51:21  iter: 819  total_loss: 1.583  loss_cls: 0.3693  loss_box_reg: 0.6073  loss_mask: 0.2999  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1695  time: 0.3536  data_time: 0.0194  lr: 0.00040959  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:16 d2.utils.events]: \u001b[0m eta: 0:51:15  iter: 839  total_loss: 1.606  loss_cls: 0.3788  loss_box_reg: 0.6298  loss_mask: 0.3189  loss_rpn_cls: 0.09754  loss_rpn_loc: 0.1637  time: 0.3534  data_time: 0.0165  lr: 0.00041958  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:24 d2.utils.events]: \u001b[0m eta: 0:51:09  iter: 859  total_loss: 1.418  loss_cls: 0.3135  loss_box_reg: 0.5932  loss_mask: 0.317  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.1454  time: 0.3539  data_time: 0.0369  lr: 0.00042957  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:31 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 879  total_loss: 1.609  loss_cls: 0.3675  loss_box_reg: 0.637  loss_mask: 0.3172  loss_rpn_cls: 0.08981  loss_rpn_loc: 0.1536  time: 0.3542  data_time: 0.0360  lr: 0.00043956  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:38 d2.utils.events]: \u001b[0m eta: 0:50:55  iter: 899  total_loss: 1.466  loss_cls: 0.3211  loss_box_reg: 0.5898  loss_mask: 0.3041  loss_rpn_cls: 0.07971  loss_rpn_loc: 0.1635  time: 0.3538  data_time: 0.0163  lr: 0.00044955  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:45 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 919  total_loss: 1.575  loss_cls: 0.3599  loss_box_reg: 0.6174  loss_mask: 0.3166  loss_rpn_cls: 0.09499  loss_rpn_loc: 0.1667  time: 0.3540  data_time: 0.0349  lr: 0.00045954  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:53 d2.utils.events]: \u001b[0m eta: 0:50:42  iter: 939  total_loss: 1.587  loss_cls: 0.3657  loss_box_reg: 0.6174  loss_mask: 0.3256  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.1659  time: 0.3541  data_time: 0.0295  lr: 0.00046953  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:55:59 d2.utils.events]: \u001b[0m eta: 0:50:36  iter: 959  total_loss: 1.52  loss_cls: 0.3147  loss_box_reg: 0.6172  loss_mask: 0.2884  loss_rpn_cls: 0.08751  loss_rpn_loc: 0.1714  time: 0.3539  data_time: 0.0131  lr: 0.00047952  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:56:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:56:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 18:56:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 18:56:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 18:56:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:56:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 18:56:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1377 s/iter. Eval: 0.0849 s/iter. Total: 0.2232 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 18:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 25/121. Dataloading: 0.0008 s/iter. Inference: 0.1504 s/iter. Eval: 0.1684 s/iter. Total: 0.3196 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/08 18:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.1513 s/iter. Eval: 0.1679 s/iter. Total: 0.3200 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 18:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 58/121. Dataloading: 0.0008 s/iter. Inference: 0.1505 s/iter. Eval: 0.1646 s/iter. Total: 0.3159 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/08 18:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.1515 s/iter. Eval: 0.1705 s/iter. Total: 0.3229 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/08 18:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1566 s/iter. Eval: 0.1982 s/iter. Total: 0.3557 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 18:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1570 s/iter. Eval: 0.2017 s/iter. Total: 0.3595 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 18:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0008 s/iter. Inference: 0.1555 s/iter. Eval: 0.1968 s/iter. Total: 0.3532 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 18:56:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.544744 (0.349524 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:56:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.155800 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:56:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 18:56:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.18174004590773501\n",
      "\u001b[32m[02/08 18:56:49 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 979  total_loss: 1.494  loss_cls: 0.3467  loss_box_reg: 0.6201  loss_mask: 0.3074  loss_rpn_cls: 0.08957  loss_rpn_loc: 0.1396  time: 0.3537  data_time: 0.0133  lr: 0.00048951  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:56:56 d2.utils.events]: \u001b[0m eta: 0:50:23  iter: 999  total_loss: 1.536  loss_cls: 0.3649  loss_box_reg: 0.5768  loss_mask: 0.3176  loss_rpn_cls: 0.0805  loss_rpn_loc: 0.1533  time: 0.3535  data_time: 0.0168  lr: 0.0004995  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:57:03 d2.utils.events]: \u001b[0m eta: 0:50:19  iter: 1019  total_loss: 1.45  loss_cls: 0.3242  loss_box_reg: 0.6136  loss_mask: 0.2987  loss_rpn_cls: 0.06149  loss_rpn_loc: 0.1451  time: 0.3533  data_time: 0.0150  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:57:11 d2.utils.events]: \u001b[0m eta: 0:50:21  iter: 1039  total_loss: 1.664  loss_cls: 0.4083  loss_box_reg: 0.6528  loss_mask: 0.3235  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.187  time: 0.3546  data_time: 0.0721  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:57:18 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 1059  total_loss: 1.382  loss_cls: 0.3155  loss_box_reg: 0.5843  loss_mask: 0.2987  loss_rpn_cls: 0.07893  loss_rpn_loc: 0.1462  time: 0.3542  data_time: 0.0087  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:57:25 d2.utils.events]: \u001b[0m eta: 0:50:08  iter: 1079  total_loss: 1.404  loss_cls: 0.3124  loss_box_reg: 0.578  loss_mask: 0.3007  loss_rpn_cls: 0.09139  loss_rpn_loc: 0.1435  time: 0.3540  data_time: 0.0123  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:57:32 d2.utils.events]: \u001b[0m eta: 0:50:04  iter: 1099  total_loss: 1.543  loss_cls: 0.3408  loss_box_reg: 0.5796  loss_mask: 0.3234  loss_rpn_cls: 0.09758  loss_rpn_loc: 0.1682  time: 0.3541  data_time: 0.0243  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:57:39 d2.utils.events]: \u001b[0m eta: 0:49:58  iter: 1119  total_loss: 1.729  loss_cls: 0.4341  loss_box_reg: 0.6352  loss_mask: 0.3338  loss_rpn_cls: 0.125  loss_rpn_loc: 0.199  time: 0.3539  data_time: 0.0119  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:57:47 d2.utils.events]: \u001b[0m eta: 0:49:52  iter: 1139  total_loss: 1.5  loss_cls: 0.3693  loss_box_reg: 0.6044  loss_mask: 0.3268  loss_rpn_cls: 0.09661  loss_rpn_loc: 0.1606  time: 0.3546  data_time: 0.0496  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:57:54 d2.utils.events]: \u001b[0m eta: 0:49:45  iter: 1159  total_loss: 1.475  loss_cls: 0.3303  loss_box_reg: 0.5877  loss_mask: 0.3038  loss_rpn_cls: 0.08592  loss_rpn_loc: 0.1653  time: 0.3547  data_time: 0.0223  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:58:01 d2.utils.events]: \u001b[0m eta: 0:49:39  iter: 1179  total_loss: 1.556  loss_cls: 0.3276  loss_box_reg: 0.6005  loss_mask: 0.3305  loss_rpn_cls: 0.08416  loss_rpn_loc: 0.1328  time: 0.3551  data_time: 0.0472  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:58:09 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 1199  total_loss: 1.603  loss_cls: 0.3703  loss_box_reg: 0.6345  loss_mask: 0.3268  loss_rpn_cls: 0.09678  loss_rpn_loc: 0.1773  time: 0.3554  data_time: 0.0361  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:58:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 18:58:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 18:58:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 18:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 18:58:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 18:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1534 s/iter. Eval: 0.0781 s/iter. Total: 0.2322 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 18:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 25/121. Dataloading: 0.0007 s/iter. Inference: 0.1608 s/iter. Eval: 0.1680 s/iter. Total: 0.3295 s/iter. ETA=0:00:31\n",
      "\u001b[32m[02/08 18:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.1601 s/iter. Eval: 0.1650 s/iter. Total: 0.3259 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 18:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 58/121. Dataloading: 0.0008 s/iter. Inference: 0.1603 s/iter. Eval: 0.1617 s/iter. Total: 0.3228 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/08 18:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.1606 s/iter. Eval: 0.1681 s/iter. Total: 0.3296 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/08 18:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1639 s/iter. Eval: 0.1975 s/iter. Total: 0.3622 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 18:58:47 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0008 s/iter. Inference: 0.1654 s/iter. Eval: 0.2047 s/iter. Total: 0.3709 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 18:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.1649 s/iter. Eval: 0.2057 s/iter. Total: 0.3715 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 18:58:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.086540 (0.362815 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:58:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.164706 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 18:58:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 18:58:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.16913891296432265\n",
      "\u001b[32m[02/08 18:59:00 d2.utils.events]: \u001b[0m eta: 0:49:29  iter: 1219  total_loss: 1.439  loss_cls: 0.3136  loss_box_reg: 0.5822  loss_mask: 0.3085  loss_rpn_cls: 0.08721  loss_rpn_loc: 0.1561  time: 0.3551  data_time: 0.0175  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:59:07 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 1239  total_loss: 1.649  loss_cls: 0.3971  loss_box_reg: 0.6084  loss_mask: 0.3228  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.1815  time: 0.3550  data_time: 0.0133  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:59:14 d2.utils.events]: \u001b[0m eta: 0:49:15  iter: 1259  total_loss: 1.5  loss_cls: 0.3657  loss_box_reg: 0.5989  loss_mask: 0.3083  loss_rpn_cls: 0.07564  loss_rpn_loc: 0.14  time: 0.3550  data_time: 0.0272  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:59:21 d2.utils.events]: \u001b[0m eta: 0:49:04  iter: 1279  total_loss: 1.433  loss_cls: 0.3193  loss_box_reg: 0.5979  loss_mask: 0.3038  loss_rpn_cls: 0.07644  loss_rpn_loc: 0.1564  time: 0.3547  data_time: 0.0153  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:59:29 d2.utils.events]: \u001b[0m eta: 0:48:59  iter: 1299  total_loss: 1.648  loss_cls: 0.3619  loss_box_reg: 0.603  loss_mask: 0.3326  loss_rpn_cls: 0.09857  loss_rpn_loc: 0.1881  time: 0.3551  data_time: 0.0398  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:59:35 d2.utils.events]: \u001b[0m eta: 0:48:53  iter: 1319  total_loss: 1.416  loss_cls: 0.3231  loss_box_reg: 0.5917  loss_mask: 0.3057  loss_rpn_cls: 0.06948  loss_rpn_loc: 0.1362  time: 0.3548  data_time: 0.0093  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:59:43 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 1339  total_loss: 1.579  loss_cls: 0.3635  loss_box_reg: 0.6106  loss_mask: 0.3276  loss_rpn_cls: 0.09178  loss_rpn_loc: 0.1896  time: 0.3549  data_time: 0.0331  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:59:50 d2.utils.events]: \u001b[0m eta: 0:48:46  iter: 1359  total_loss: 1.541  loss_cls: 0.3562  loss_box_reg: 0.5922  loss_mask: 0.3106  loss_rpn_cls: 0.09987  loss_rpn_loc: 0.1686  time: 0.3548  data_time: 0.0152  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 18:59:57 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 1379  total_loss: 1.56  loss_cls: 0.3686  loss_box_reg: 0.6168  loss_mask: 0.3264  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1657  time: 0.3550  data_time: 0.0299  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:00:04 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 1399  total_loss: 1.583  loss_cls: 0.3779  loss_box_reg: 0.6081  loss_mask: 0.3371  loss_rpn_cls: 0.08463  loss_rpn_loc: 0.1699  time: 0.3553  data_time: 0.0318  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:00:12 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 1419  total_loss: 1.5  loss_cls: 0.3429  loss_box_reg: 0.5673  loss_mask: 0.3034  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1498  time: 0.3554  data_time: 0.0338  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:00:19 d2.utils.events]: \u001b[0m eta: 0:48:17  iter: 1439  total_loss: 1.498  loss_cls: 0.3462  loss_box_reg: 0.5837  loss_mask: 0.3098  loss_rpn_cls: 0.0809  loss_rpn_loc: 0.1561  time: 0.3554  data_time: 0.0302  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:00:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:00:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:00:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:00:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:00:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:00:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1430 s/iter. Eval: 0.0800 s/iter. Total: 0.2236 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 19:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 25/121. Dataloading: 0.0007 s/iter. Inference: 0.1505 s/iter. Eval: 0.1674 s/iter. Total: 0.3186 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/08 19:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0007 s/iter. Inference: 0.1523 s/iter. Eval: 0.1741 s/iter. Total: 0.3272 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 19:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 57/121. Dataloading: 0.0008 s/iter. Inference: 0.1495 s/iter. Eval: 0.1665 s/iter. Total: 0.3168 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/08 19:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1497 s/iter. Eval: 0.1777 s/iter. Total: 0.3283 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1533 s/iter. Eval: 0.2047 s/iter. Total: 0.3589 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0008 s/iter. Inference: 0.1544 s/iter. Eval: 0.2128 s/iter. Total: 0.3681 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 19:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.1533 s/iter. Eval: 0.2120 s/iter. Total: 0.3661 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 19:01:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.701086 (0.359492 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:01:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.153618 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:01:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:01:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.18895999833878196\n",
      "\u001b[32m[02/08 19:01:09 d2.utils.events]: \u001b[0m eta: 0:48:09  iter: 1459  total_loss: 1.279  loss_cls: 0.2627  loss_box_reg: 0.5432  loss_mask: 0.2936  loss_rpn_cls: 0.0592  loss_rpn_loc: 0.1386  time: 0.3551  data_time: 0.0077  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:01:17 d2.utils.events]: \u001b[0m eta: 0:48:06  iter: 1479  total_loss: 1.567  loss_cls: 0.3796  loss_box_reg: 0.5976  loss_mask: 0.3166  loss_rpn_cls: 0.0928  loss_rpn_loc: 0.1784  time: 0.3556  data_time: 0.0500  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:01:24 d2.utils.events]: \u001b[0m eta: 0:47:59  iter: 1499  total_loss: 1.255  loss_cls: 0.225  loss_box_reg: 0.5425  loss_mask: 0.2988  loss_rpn_cls: 0.05807  loss_rpn_loc: 0.1255  time: 0.3553  data_time: 0.0090  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:01:32 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 1519  total_loss: 1.531  loss_cls: 0.3568  loss_box_reg: 0.6222  loss_mask: 0.33  loss_rpn_cls: 0.08755  loss_rpn_loc: 0.1792  time: 0.3557  data_time: 0.0382  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:01:39 d2.utils.events]: \u001b[0m eta: 0:47:49  iter: 1539  total_loss: 1.603  loss_cls: 0.3539  loss_box_reg: 0.596  loss_mask: 0.3202  loss_rpn_cls: 0.08894  loss_rpn_loc: 0.1851  time: 0.3556  data_time: 0.0194  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:01:46 d2.utils.events]: \u001b[0m eta: 0:47:42  iter: 1559  total_loss: 1.565  loss_cls: 0.3591  loss_box_reg: 0.6247  loss_mask: 0.3148  loss_rpn_cls: 0.08202  loss_rpn_loc: 0.1797  time: 0.3554  data_time: 0.0138  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:01:52 d2.utils.events]: \u001b[0m eta: 0:47:32  iter: 1579  total_loss: 1.41  loss_cls: 0.3185  loss_box_reg: 0.5729  loss_mask: 0.3066  loss_rpn_cls: 0.07084  loss_rpn_loc: 0.1427  time: 0.3553  data_time: 0.0103  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:02:00 d2.utils.events]: \u001b[0m eta: 0:47:25  iter: 1599  total_loss: 1.426  loss_cls: 0.3328  loss_box_reg: 0.575  loss_mask: 0.2997  loss_rpn_cls: 0.0845  loss_rpn_loc: 0.163  time: 0.3556  data_time: 0.0454  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:02:07 d2.utils.events]: \u001b[0m eta: 0:47:22  iter: 1619  total_loss: 1.521  loss_cls: 0.3259  loss_box_reg: 0.5765  loss_mask: 0.3231  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.1712  time: 0.3554  data_time: 0.0169  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:02:15 d2.utils.events]: \u001b[0m eta: 0:47:10  iter: 1639  total_loss: 1.57  loss_cls: 0.3561  loss_box_reg: 0.5906  loss_mask: 0.3295  loss_rpn_cls: 0.08895  loss_rpn_loc: 0.1604  time: 0.3558  data_time: 0.0640  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:02:21 d2.utils.events]: \u001b[0m eta: 0:47:04  iter: 1659  total_loss: 1.339  loss_cls: 0.3025  loss_box_reg: 0.5866  loss_mask: 0.3079  loss_rpn_cls: 0.0626  loss_rpn_loc: 0.1439  time: 0.3554  data_time: 0.0139  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:02:28 d2.utils.events]: \u001b[0m eta: 0:46:55  iter: 1679  total_loss: 1.494  loss_cls: 0.3755  loss_box_reg: 0.5892  loss_mask: 0.295  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.1449  time: 0.3553  data_time: 0.0327  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:02:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:02:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:02:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:02:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:02:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:02:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1358 s/iter. Eval: 0.0770 s/iter. Total: 0.2135 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 26/121. Dataloading: 0.0008 s/iter. Inference: 0.1493 s/iter. Eval: 0.1543 s/iter. Total: 0.3045 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/08 19:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.1475 s/iter. Eval: 0.1523 s/iter. Total: 0.3007 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:02:52 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0008 s/iter. Inference: 0.1491 s/iter. Eval: 0.1640 s/iter. Total: 0.3140 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/08 19:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.1510 s/iter. Eval: 0.1675 s/iter. Total: 0.3193 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.1535 s/iter. Eval: 0.1842 s/iter. Total: 0.3385 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 19:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.1548 s/iter. Eval: 0.1906 s/iter. Total: 0.3462 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/08 19:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.1539 s/iter. Eval: 0.1784 s/iter. Total: 0.3331 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:03:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.868559 (0.335074 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:03:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.154193 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:03:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:03:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.18705619520222388\n",
      "\u001b[32m[02/08 19:03:16 d2.utils.events]: \u001b[0m eta: 0:46:48  iter: 1699  total_loss: 1.595  loss_cls: 0.3818  loss_box_reg: 0.6193  loss_mask: 0.3382  loss_rpn_cls: 0.09867  loss_rpn_loc: 0.1798  time: 0.3551  data_time: 0.0282  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:03:23 d2.utils.events]: \u001b[0m eta: 0:46:40  iter: 1719  total_loss: 1.653  loss_cls: 0.4064  loss_box_reg: 0.6291  loss_mask: 0.3188  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.1703  time: 0.3550  data_time: 0.0204  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:03:30 d2.utils.events]: \u001b[0m eta: 0:46:31  iter: 1739  total_loss: 1.426  loss_cls: 0.3173  loss_box_reg: 0.5619  loss_mask: 0.3183  loss_rpn_cls: 0.06694  loss_rpn_loc: 0.1503  time: 0.3551  data_time: 0.0420  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:03:37 d2.utils.events]: \u001b[0m eta: 0:46:22  iter: 1759  total_loss: 1.534  loss_cls: 0.3315  loss_box_reg: 0.5788  loss_mask: 0.3257  loss_rpn_cls: 0.08824  loss_rpn_loc: 0.1712  time: 0.3548  data_time: 0.0158  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:03:44 d2.utils.events]: \u001b[0m eta: 0:46:14  iter: 1779  total_loss: 1.584  loss_cls: 0.3524  loss_box_reg: 0.6026  loss_mask: 0.3193  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1936  time: 0.3550  data_time: 0.0516  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:03:51 d2.utils.events]: \u001b[0m eta: 0:46:04  iter: 1799  total_loss: 1.354  loss_cls: 0.2848  loss_box_reg: 0.5416  loss_mask: 0.3021  loss_rpn_cls: 0.06759  loss_rpn_loc: 0.1315  time: 0.3547  data_time: 0.0134  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:03:58 d2.utils.events]: \u001b[0m eta: 0:45:55  iter: 1819  total_loss: 1.428  loss_cls: 0.3432  loss_box_reg: 0.588  loss_mask: 0.3063  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.1577  time: 0.3547  data_time: 0.0372  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:04:05 d2.utils.events]: \u001b[0m eta: 0:45:46  iter: 1839  total_loss: 1.552  loss_cls: 0.3709  loss_box_reg: 0.6142  loss_mask: 0.3143  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.1624  time: 0.3547  data_time: 0.0328  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:04:12 d2.utils.events]: \u001b[0m eta: 0:45:33  iter: 1859  total_loss: 1.517  loss_cls: 0.3287  loss_box_reg: 0.6009  loss_mask: 0.3002  loss_rpn_cls: 0.08462  loss_rpn_loc: 0.1575  time: 0.3545  data_time: 0.0320  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:04:18 d2.utils.events]: \u001b[0m eta: 0:45:23  iter: 1879  total_loss: 1.462  loss_cls: 0.3149  loss_box_reg: 0.5881  loss_mask: 0.321  loss_rpn_cls: 0.07319  loss_rpn_loc: 0.1555  time: 0.3543  data_time: 0.0240  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:04:25 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 1899  total_loss: 1.381  loss_cls: 0.2928  loss_box_reg: 0.5525  loss_mask: 0.2873  loss_rpn_cls: 0.06051  loss_rpn_loc: 0.1295  time: 0.3540  data_time: 0.0186  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:04:31 d2.utils.events]: \u001b[0m eta: 0:45:05  iter: 1919  total_loss: 1.309  loss_cls: 0.3182  loss_box_reg: 0.5544  loss_mask: 0.2971  loss_rpn_cls: 0.09384  loss_rpn_loc: 0.1531  time: 0.3537  data_time: 0.0155  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:04:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:04:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:04:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:04:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:04:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:04:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:04:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1269 s/iter. Eval: 0.0730 s/iter. Total: 0.2005 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:04:46 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0007 s/iter. Inference: 0.1390 s/iter. Eval: 0.1325 s/iter. Total: 0.2723 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:04:51 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1408 s/iter. Eval: 0.1580 s/iter. Total: 0.2996 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:04:56 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1398 s/iter. Eval: 0.1498 s/iter. Total: 0.2905 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1428 s/iter. Eval: 0.1611 s/iter. Total: 0.3047 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1457 s/iter. Eval: 0.1754 s/iter. Total: 0.3220 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.1447 s/iter. Eval: 0.1720 s/iter. Total: 0.3176 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 19:05:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.897115 (0.309458 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:05:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.144221 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:05:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:05:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.19463516252682128\n",
      "\u001b[32m[02/08 19:05:17 d2.utils.events]: \u001b[0m eta: 0:44:57  iter: 1939  total_loss: 1.578  loss_cls: 0.3541  loss_box_reg: 0.5875  loss_mask: 0.3151  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.1819  time: 0.3538  data_time: 0.0400  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:05:24 d2.utils.events]: \u001b[0m eta: 0:44:49  iter: 1959  total_loss: 1.536  loss_cls: 0.3738  loss_box_reg: 0.6049  loss_mask: 0.3299  loss_rpn_cls: 0.09628  loss_rpn_loc: 0.1822  time: 0.3540  data_time: 0.0596  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:05:31 d2.utils.events]: \u001b[0m eta: 0:44:39  iter: 1979  total_loss: 1.458  loss_cls: 0.327  loss_box_reg: 0.5962  loss_mask: 0.3154  loss_rpn_cls: 0.06321  loss_rpn_loc: 0.1592  time: 0.3537  data_time: 0.0136  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:05:37 d2.utils.events]: \u001b[0m eta: 0:44:30  iter: 1999  total_loss: 1.424  loss_cls: 0.3156  loss_box_reg: 0.5842  loss_mask: 0.321  loss_rpn_cls: 0.06135  loss_rpn_loc: 0.151  time: 0.3535  data_time: 0.0186  lr: 0.0005  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:05:44 d2.utils.events]: \u001b[0m eta: 0:44:23  iter: 2019  total_loss: 1.506  loss_cls: 0.3417  loss_box_reg: 0.5887  loss_mask: 0.3152  loss_rpn_cls: 0.08197  loss_rpn_loc: 0.18  time: 0.3533  data_time: 0.0193  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:05:51 d2.utils.events]: \u001b[0m eta: 0:44:10  iter: 2039  total_loss: 1.501  loss_cls: 0.34  loss_box_reg: 0.5914  loss_mask: 0.3198  loss_rpn_cls: 0.07871  loss_rpn_loc: 0.1743  time: 0.3533  data_time: 0.0361  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:05:58 d2.utils.events]: \u001b[0m eta: 0:44:03  iter: 2059  total_loss: 1.377  loss_cls: 0.301  loss_box_reg: 0.5642  loss_mask: 0.2917  loss_rpn_cls: 0.06047  loss_rpn_loc: 0.1513  time: 0.3531  data_time: 0.0164  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:06:04 d2.utils.events]: \u001b[0m eta: 0:43:53  iter: 2079  total_loss: 1.322  loss_cls: 0.2782  loss_box_reg: 0.5683  loss_mask: 0.312  loss_rpn_cls: 0.05681  loss_rpn_loc: 0.127  time: 0.3529  data_time: 0.0301  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:06:11 d2.utils.events]: \u001b[0m eta: 0:43:43  iter: 2099  total_loss: 1.432  loss_cls: 0.317  loss_box_reg: 0.5429  loss_mask: 0.3025  loss_rpn_cls: 0.08923  loss_rpn_loc: 0.1622  time: 0.3528  data_time: 0.0313  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:06:18 d2.utils.events]: \u001b[0m eta: 0:43:31  iter: 2119  total_loss: 1.469  loss_cls: 0.3274  loss_box_reg: 0.5958  loss_mask: 0.3085  loss_rpn_cls: 0.07184  loss_rpn_loc: 0.1554  time: 0.3526  data_time: 0.0183  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:06:26 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 2139  total_loss: 1.497  loss_cls: 0.3529  loss_box_reg: 0.564  loss_mask: 0.3062  loss_rpn_cls: 0.08632  loss_rpn_loc: 0.1758  time: 0.3531  data_time: 0.0706  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:06:33 d2.utils.events]: \u001b[0m eta: 0:43:12  iter: 2159  total_loss: 1.363  loss_cls: 0.3148  loss_box_reg: 0.5692  loss_mask: 0.2994  loss_rpn_cls: 0.05638  loss_rpn_loc: 0.1285  time: 0.3529  data_time: 0.0176  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:06:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:06:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:06:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:06:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:06:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:06:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1331 s/iter. Eval: 0.0799 s/iter. Total: 0.2136 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0007 s/iter. Inference: 0.1399 s/iter. Eval: 0.1532 s/iter. Total: 0.2939 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/08 19:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1405 s/iter. Eval: 0.1652 s/iter. Total: 0.3065 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0008 s/iter. Inference: 0.1410 s/iter. Eval: 0.1626 s/iter. Total: 0.3044 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/08 19:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.1422 s/iter. Eval: 0.1726 s/iter. Total: 0.3156 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.1449 s/iter. Eval: 0.1940 s/iter. Total: 0.3398 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 19:07:14 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1465 s/iter. Eval: 0.2004 s/iter. Total: 0.3478 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/08 19:07:19 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.1470 s/iter. Eval: 0.1895 s/iter. Total: 0.3373 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/08 19:07:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.555806 (0.340998 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:07:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.147934 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:07:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:07:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.18782130003552602\n",
      "\u001b[32m[02/08 19:07:22 d2.utils.events]: \u001b[0m eta: 0:43:03  iter: 2179  total_loss: 1.548  loss_cls: 0.3377  loss_box_reg: 0.5934  loss_mask: 0.3297  loss_rpn_cls: 0.08773  loss_rpn_loc: 0.1497  time: 0.3532  data_time: 0.0711  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:07:29 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 2199  total_loss: 1.453  loss_cls: 0.3348  loss_box_reg: 0.574  loss_mask: 0.3185  loss_rpn_cls: 0.06866  loss_rpn_loc: 0.1534  time: 0.3531  data_time: 0.0174  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:07:36 d2.utils.events]: \u001b[0m eta: 0:42:47  iter: 2219  total_loss: 1.435  loss_cls: 0.3158  loss_box_reg: 0.5771  loss_mask: 0.3076  loss_rpn_cls: 0.07797  loss_rpn_loc: 0.145  time: 0.3532  data_time: 0.0233  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:07:44 d2.utils.events]: \u001b[0m eta: 0:42:40  iter: 2239  total_loss: 1.56  loss_cls: 0.3776  loss_box_reg: 0.5958  loss_mask: 0.3074  loss_rpn_cls: 0.09354  loss_rpn_loc: 0.1669  time: 0.3535  data_time: 0.0491  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:07:51 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 2259  total_loss: 1.387  loss_cls: 0.2988  loss_box_reg: 0.5361  loss_mask: 0.299  loss_rpn_cls: 0.07086  loss_rpn_loc: 0.1416  time: 0.3534  data_time: 0.0265  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:07:58 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 2279  total_loss: 1.472  loss_cls: 0.3242  loss_box_reg: 0.6007  loss_mask: 0.3149  loss_rpn_cls: 0.06774  loss_rpn_loc: 0.1693  time: 0.3534  data_time: 0.0193  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:08:05 d2.utils.events]: \u001b[0m eta: 0:42:19  iter: 2299  total_loss: 1.419  loss_cls: 0.313  loss_box_reg: 0.5637  loss_mask: 0.3001  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1371  time: 0.3533  data_time: 0.0281  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:08:12 d2.utils.events]: \u001b[0m eta: 0:42:12  iter: 2319  total_loss: 1.469  loss_cls: 0.3455  loss_box_reg: 0.5692  loss_mask: 0.3071  loss_rpn_cls: 0.07903  loss_rpn_loc: 0.1633  time: 0.3534  data_time: 0.0371  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:08:19 d2.utils.events]: \u001b[0m eta: 0:42:03  iter: 2339  total_loss: 1.404  loss_cls: 0.3216  loss_box_reg: 0.5766  loss_mask: 0.3199  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.1208  time: 0.3534  data_time: 0.0357  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:08:26 d2.utils.events]: \u001b[0m eta: 0:41:54  iter: 2359  total_loss: 1.599  loss_cls: 0.3703  loss_box_reg: 0.6196  loss_mask: 0.3108  loss_rpn_cls: 0.08619  loss_rpn_loc: 0.1606  time: 0.3532  data_time: 0.0143  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:08:33 d2.utils.events]: \u001b[0m eta: 0:41:48  iter: 2379  total_loss: 1.545  loss_cls: 0.3684  loss_box_reg: 0.6005  loss_mask: 0.318  loss_rpn_cls: 0.0906  loss_rpn_loc: 0.1748  time: 0.3535  data_time: 0.0490  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:08:40 d2.utils.events]: \u001b[0m eta: 0:41:34  iter: 2399  total_loss: 1.381  loss_cls: 0.3086  loss_box_reg: 0.5676  loss_mask: 0.3084  loss_rpn_cls: 0.05907  loss_rpn_loc: 0.1399  time: 0.3532  data_time: 0.0078  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:08:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:08:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:08:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:08:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:08:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:08:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1369 s/iter. Eval: 0.0842 s/iter. Total: 0.2217 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 19:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 25/121. Dataloading: 0.0007 s/iter. Inference: 0.1501 s/iter. Eval: 0.1707 s/iter. Total: 0.3216 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/08 19:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.1510 s/iter. Eval: 0.1698 s/iter. Total: 0.3216 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 58/121. Dataloading: 0.0008 s/iter. Inference: 0.1501 s/iter. Eval: 0.1661 s/iter. Total: 0.3170 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/08 19:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.1507 s/iter. Eval: 0.1692 s/iter. Total: 0.3207 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/08 19:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1551 s/iter. Eval: 0.1985 s/iter. Total: 0.3545 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1547 s/iter. Eval: 0.2009 s/iter. Total: 0.3565 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 19:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0008 s/iter. Inference: 0.1526 s/iter. Eval: 0.1940 s/iter. Total: 0.3475 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/08 19:09:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.124955 (0.345905 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:09:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.152663 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:09:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:09:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.1913778259539777\n",
      "\u001b[32m[02/08 19:09:29 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 2419  total_loss: 1.357  loss_cls: 0.3087  loss_box_reg: 0.5443  loss_mask: 0.2929  loss_rpn_cls: 0.06521  loss_rpn_loc: 0.1521  time: 0.3532  data_time: 0.0357  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:09:36 d2.utils.events]: \u001b[0m eta: 0:41:16  iter: 2439  total_loss: 1.464  loss_cls: 0.3232  loss_box_reg: 0.5604  loss_mask: 0.2922  loss_rpn_cls: 0.08946  loss_rpn_loc: 0.1539  time: 0.3531  data_time: 0.0262  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:09:43 d2.utils.events]: \u001b[0m eta: 0:41:05  iter: 2459  total_loss: 1.414  loss_cls: 0.318  loss_box_reg: 0.5691  loss_mask: 0.2966  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.1561  time: 0.3530  data_time: 0.0328  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:09:50 d2.utils.events]: \u001b[0m eta: 0:40:53  iter: 2479  total_loss: 1.512  loss_cls: 0.3447  loss_box_reg: 0.5943  loss_mask: 0.3112  loss_rpn_cls: 0.06937  loss_rpn_loc: 0.1592  time: 0.3529  data_time: 0.0264  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:09:56 d2.utils.events]: \u001b[0m eta: 0:40:46  iter: 2499  total_loss: 1.339  loss_cls: 0.3122  loss_box_reg: 0.5511  loss_mask: 0.3039  loss_rpn_cls: 0.06323  loss_rpn_loc: 0.1488  time: 0.3527  data_time: 0.0173  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:03 d2.utils.events]: \u001b[0m eta: 0:40:35  iter: 2519  total_loss: 1.27  loss_cls: 0.2775  loss_box_reg: 0.5315  loss_mask: 0.29  loss_rpn_cls: 0.04422  loss_rpn_loc: 0.1145  time: 0.3525  data_time: 0.0092  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:10 d2.utils.events]: \u001b[0m eta: 0:40:28  iter: 2539  total_loss: 1.368  loss_cls: 0.3323  loss_box_reg: 0.5576  loss_mask: 0.3126  loss_rpn_cls: 0.07335  loss_rpn_loc: 0.1254  time: 0.3525  data_time: 0.0411  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:17 d2.utils.events]: \u001b[0m eta: 0:40:22  iter: 2559  total_loss: 1.666  loss_cls: 0.3762  loss_box_reg: 0.6345  loss_mask: 0.3297  loss_rpn_cls: 0.09619  loss_rpn_loc: 0.1833  time: 0.3527  data_time: 0.0318  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:24 d2.utils.events]: \u001b[0m eta: 0:40:15  iter: 2579  total_loss: 1.318  loss_cls: 0.2964  loss_box_reg: 0.5412  loss_mask: 0.3091  loss_rpn_cls: 0.05291  loss_rpn_loc: 0.1331  time: 0.3526  data_time: 0.0139  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:31 d2.utils.events]: \u001b[0m eta: 0:40:07  iter: 2599  total_loss: 1.441  loss_cls: 0.3212  loss_box_reg: 0.5965  loss_mask: 0.315  loss_rpn_cls: 0.06247  loss_rpn_loc: 0.1421  time: 0.3525  data_time: 0.0173  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:38 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 2619  total_loss: 1.535  loss_cls: 0.3544  loss_box_reg: 0.5723  loss_mask: 0.302  loss_rpn_cls: 0.08932  loss_rpn_loc: 0.1704  time: 0.3526  data_time: 0.0315  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:45 d2.utils.events]: \u001b[0m eta: 0:39:55  iter: 2639  total_loss: 1.453  loss_cls: 0.3258  loss_box_reg: 0.5786  loss_mask: 0.3148  loss_rpn_cls: 0.0788  loss_rpn_loc: 0.1705  time: 0.3525  data_time: 0.0215  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:52 d2.utils.events]: \u001b[0m eta: 0:39:49  iter: 2659  total_loss: 1.319  loss_cls: 0.2906  loss_box_reg: 0.5331  loss_mask: 0.2905  loss_rpn_cls: 0.06331  loss_rpn_loc: 0.1421  time: 0.3525  data_time: 0.0288  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:10:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:10:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:10:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:10:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:10:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:10:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1421 s/iter. Eval: 0.0914 s/iter. Total: 0.2342 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:11:02 d2.evaluation.evaluator]: \u001b[0mInference done 25/121. Dataloading: 0.0008 s/iter. Inference: 0.1479 s/iter. Eval: 0.1723 s/iter. Total: 0.3210 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/08 19:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.1481 s/iter. Eval: 0.1775 s/iter. Total: 0.3265 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 19:11:12 d2.evaluation.evaluator]: \u001b[0mInference done 57/121. Dataloading: 0.0008 s/iter. Inference: 0.1460 s/iter. Eval: 0.1707 s/iter. Total: 0.3175 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/08 19:11:17 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1478 s/iter. Eval: 0.1805 s/iter. Total: 0.3291 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:11:22 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1519 s/iter. Eval: 0.2060 s/iter. Total: 0.3589 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1542 s/iter. Eval: 0.2160 s/iter. Total: 0.3710 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 19:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.1538 s/iter. Eval: 0.2127 s/iter. Total: 0.3674 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 19:11:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.729163 (0.359734 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:11:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.153652 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:11:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:11:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.1907391447908814\n",
      "\u001b[32m[02/08 19:11:44 d2.utils.events]: \u001b[0m eta: 0:39:46  iter: 2679  total_loss: 1.472  loss_cls: 0.3316  loss_box_reg: 0.5868  loss_mask: 0.312  loss_rpn_cls: 0.08166  loss_rpn_loc: 0.1586  time: 0.3528  data_time: 0.0492  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:11:51 d2.utils.events]: \u001b[0m eta: 0:39:41  iter: 2699  total_loss: 1.412  loss_cls: 0.3198  loss_box_reg: 0.5696  loss_mask: 0.323  loss_rpn_cls: 0.0767  loss_rpn_loc: 0.1612  time: 0.3530  data_time: 0.0340  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:11:59 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 2719  total_loss: 1.349  loss_cls: 0.32  loss_box_reg: 0.5605  loss_mask: 0.2965  loss_rpn_cls: 0.05205  loss_rpn_loc: 0.1425  time: 0.3530  data_time: 0.0177  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:12:05 d2.utils.events]: \u001b[0m eta: 0:39:32  iter: 2739  total_loss: 1.349  loss_cls: 0.2976  loss_box_reg: 0.5607  loss_mask: 0.2864  loss_rpn_cls: 0.0648  loss_rpn_loc: 0.1313  time: 0.3528  data_time: 0.0089  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:12:12 d2.utils.events]: \u001b[0m eta: 0:39:25  iter: 2759  total_loss: 1.402  loss_cls: 0.2946  loss_box_reg: 0.552  loss_mask: 0.2985  loss_rpn_cls: 0.07621  loss_rpn_loc: 0.1467  time: 0.3528  data_time: 0.0220  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:12:20 d2.utils.events]: \u001b[0m eta: 0:39:21  iter: 2779  total_loss: 1.384  loss_cls: 0.3216  loss_box_reg: 0.5525  loss_mask: 0.2956  loss_rpn_cls: 0.06195  loss_rpn_loc: 0.1631  time: 0.3529  data_time: 0.0349  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:12:27 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 2799  total_loss: 1.518  loss_cls: 0.3695  loss_box_reg: 0.5765  loss_mask: 0.3147  loss_rpn_cls: 0.07798  loss_rpn_loc: 0.1734  time: 0.3532  data_time: 0.0565  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:12:35 d2.utils.events]: \u001b[0m eta: 0:39:12  iter: 2819  total_loss: 1.346  loss_cls: 0.3104  loss_box_reg: 0.5382  loss_mask: 0.2885  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.1505  time: 0.3532  data_time: 0.0358  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:12:41 d2.utils.events]: \u001b[0m eta: 0:39:04  iter: 2839  total_loss: 1.442  loss_cls: 0.3381  loss_box_reg: 0.5708  loss_mask: 0.3087  loss_rpn_cls: 0.06288  loss_rpn_loc: 0.1478  time: 0.3530  data_time: 0.0094  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:12:48 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 2859  total_loss: 1.407  loss_cls: 0.328  loss_box_reg: 0.573  loss_mask: 0.3185  loss_rpn_cls: 0.07409  loss_rpn_loc: 0.1646  time: 0.3530  data_time: 0.0196  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:12:55 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 2879  total_loss: 1.385  loss_cls: 0.2995  loss_box_reg: 0.5602  loss_mask: 0.3028  loss_rpn_cls: 0.07729  loss_rpn_loc: 0.1445  time: 0.3530  data_time: 0.0292  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:13:02 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 2899  total_loss: 1.425  loss_cls: 0.3026  loss_box_reg: 0.5768  loss_mask: 0.301  loss_rpn_cls: 0.05896  loss_rpn_loc: 0.1391  time: 0.3531  data_time: 0.0262  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:13:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:13:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:13:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:13:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:13:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:13:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:13:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1269 s/iter. Eval: 0.0742 s/iter. Total: 0.2018 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:13:12 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0008 s/iter. Inference: 0.1386 s/iter. Eval: 0.1336 s/iter. Total: 0.2731 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:13:17 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1411 s/iter. Eval: 0.1501 s/iter. Total: 0.2921 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:13:22 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1404 s/iter. Eval: 0.1485 s/iter. Total: 0.2897 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1433 s/iter. Eval: 0.1594 s/iter. Total: 0.3036 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0008 s/iter. Inference: 0.1463 s/iter. Eval: 0.1693 s/iter. Total: 0.3164 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 19:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.1465 s/iter. Eval: 0.1775 s/iter. Total: 0.3249 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 19:13:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.694001 (0.316328 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:13:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.146085 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:13:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:13:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21048508024787177\n",
      "\u001b[32m[02/08 19:13:49 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 2919  total_loss: 1.457  loss_cls: 0.3367  loss_box_reg: 0.5771  loss_mask: 0.3078  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.1667  time: 0.3531  data_time: 0.0387  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:13:56 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 2939  total_loss: 1.396  loss_cls: 0.3316  loss_box_reg: 0.5586  loss_mask: 0.2988  loss_rpn_cls: 0.06185  loss_rpn_loc: 0.1495  time: 0.3531  data_time: 0.0199  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:14:03 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 2959  total_loss: 1.448  loss_cls: 0.3365  loss_box_reg: 0.5612  loss_mask: 0.313  loss_rpn_cls: 0.08058  loss_rpn_loc: 0.1575  time: 0.3531  data_time: 0.0182  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:14:10 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 2979  total_loss: 1.427  loss_cls: 0.3165  loss_box_reg: 0.5571  loss_mask: 0.2991  loss_rpn_cls: 0.07099  loss_rpn_loc: 0.1434  time: 0.3532  data_time: 0.0274  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:14:18 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 2999  total_loss: 1.363  loss_cls: 0.3378  loss_box_reg: 0.5595  loss_mask: 0.2888  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.1437  time: 0.3533  data_time: 0.0340  lr: 0.0004  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:14:24 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 3019  total_loss: 1.394  loss_cls: 0.3051  loss_box_reg: 0.5756  loss_mask: 0.3185  loss_rpn_cls: 0.07408  loss_rpn_loc: 0.1531  time: 0.3532  data_time: 0.0107  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:14:31 d2.utils.events]: \u001b[0m eta: 0:38:30  iter: 3039  total_loss: 1.364  loss_cls: 0.2891  loss_box_reg: 0.5562  loss_mask: 0.2962  loss_rpn_cls: 0.06169  loss_rpn_loc: 0.1285  time: 0.3531  data_time: 0.0235  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:14:38 d2.utils.events]: \u001b[0m eta: 0:38:23  iter: 3059  total_loss: 1.415  loss_cls: 0.2944  loss_box_reg: 0.5512  loss_mask: 0.3052  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.1316  time: 0.3531  data_time: 0.0344  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:14:45 d2.utils.events]: \u001b[0m eta: 0:38:23  iter: 3079  total_loss: 1.44  loss_cls: 0.3366  loss_box_reg: 0.5691  loss_mask: 0.3036  loss_rpn_cls: 0.08071  loss_rpn_loc: 0.1473  time: 0.3531  data_time: 0.0150  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:14:52 d2.utils.events]: \u001b[0m eta: 0:38:17  iter: 3099  total_loss: 1.426  loss_cls: 0.2977  loss_box_reg: 0.581  loss_mask: 0.3278  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.1432  time: 0.3532  data_time: 0.0218  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:15:00 d2.utils.events]: \u001b[0m eta: 0:38:12  iter: 3119  total_loss: 1.427  loss_cls: 0.3297  loss_box_reg: 0.56  loss_mask: 0.2962  loss_rpn_cls: 0.08137  loss_rpn_loc: 0.1477  time: 0.3532  data_time: 0.0341  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:15:07 d2.utils.events]: \u001b[0m eta: 0:38:05  iter: 3139  total_loss: 1.268  loss_cls: 0.2742  loss_box_reg: 0.5203  loss_mask: 0.3067  loss_rpn_cls: 0.0465  loss_rpn_loc: 0.1374  time: 0.3533  data_time: 0.0429  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:15:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:15:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:15:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:15:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:15:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:15:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1323 s/iter. Eval: 0.0811 s/iter. Total: 0.2141 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:15:18 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0008 s/iter. Inference: 0.1446 s/iter. Eval: 0.1497 s/iter. Total: 0.2951 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/08 19:15:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1464 s/iter. Eval: 0.1642 s/iter. Total: 0.3115 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:15:28 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1459 s/iter. Eval: 0.1575 s/iter. Total: 0.3042 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:15:34 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1488 s/iter. Eval: 0.1702 s/iter. Total: 0.3199 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:15:39 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0008 s/iter. Inference: 0.1512 s/iter. Eval: 0.1783 s/iter. Total: 0.3303 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 19:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.1509 s/iter. Eval: 0.1840 s/iter. Total: 0.3358 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/08 19:15:49 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.1500 s/iter. Eval: 0.1767 s/iter. Total: 0.3276 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:15:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.045981 (0.327983 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:15:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.150002 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:15:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:15:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20791958661490942\n",
      "\u001b[32m[02/08 19:15:54 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 3159  total_loss: 1.437  loss_cls: 0.3118  loss_box_reg: 0.561  loss_mask: 0.3017  loss_rpn_cls: 0.07755  loss_rpn_loc: 0.1611  time: 0.3533  data_time: 0.0232  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:02 d2.utils.events]: \u001b[0m eta: 0:37:56  iter: 3179  total_loss: 1.417  loss_cls: 0.3254  loss_box_reg: 0.5434  loss_mask: 0.2975  loss_rpn_cls: 0.0678  loss_rpn_loc: 0.1684  time: 0.3534  data_time: 0.0346  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:09 d2.utils.events]: \u001b[0m eta: 0:37:54  iter: 3199  total_loss: 1.446  loss_cls: 0.3218  loss_box_reg: 0.581  loss_mask: 0.3122  loss_rpn_cls: 0.06418  loss_rpn_loc: 0.159  time: 0.3535  data_time: 0.0263  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:16 d2.utils.events]: \u001b[0m eta: 0:37:43  iter: 3219  total_loss: 1.355  loss_cls: 0.2863  loss_box_reg: 0.554  loss_mask: 0.3093  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.1514  time: 0.3536  data_time: 0.0335  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:24 d2.utils.events]: \u001b[0m eta: 0:37:36  iter: 3239  total_loss: 1.381  loss_cls: 0.3183  loss_box_reg: 0.5704  loss_mask: 0.3063  loss_rpn_cls: 0.05883  loss_rpn_loc: 0.1354  time: 0.3536  data_time: 0.0341  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:31 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 3259  total_loss: 1.413  loss_cls: 0.3342  loss_box_reg: 0.5437  loss_mask: 0.2978  loss_rpn_cls: 0.07853  loss_rpn_loc: 0.1574  time: 0.3536  data_time: 0.0275  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:38 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 3279  total_loss: 1.426  loss_cls: 0.3247  loss_box_reg: 0.5805  loss_mask: 0.3008  loss_rpn_cls: 0.07294  loss_rpn_loc: 0.144  time: 0.3536  data_time: 0.0195  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:45 d2.utils.events]: \u001b[0m eta: 0:37:19  iter: 3299  total_loss: 1.313  loss_cls: 0.3038  loss_box_reg: 0.5481  loss_mask: 0.2971  loss_rpn_cls: 0.07139  loss_rpn_loc: 0.1441  time: 0.3536  data_time: 0.0280  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:52 d2.utils.events]: \u001b[0m eta: 0:37:14  iter: 3319  total_loss: 1.246  loss_cls: 0.2555  loss_box_reg: 0.5415  loss_mask: 0.3165  loss_rpn_cls: 0.06379  loss_rpn_loc: 0.1365  time: 0.3536  data_time: 0.0351  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:16:59 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 3339  total_loss: 1.394  loss_cls: 0.3176  loss_box_reg: 0.5717  loss_mask: 0.3033  loss_rpn_cls: 0.06324  loss_rpn_loc: 0.1299  time: 0.3536  data_time: 0.0144  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:17:06 d2.utils.events]: \u001b[0m eta: 0:37:03  iter: 3359  total_loss: 1.407  loss_cls: 0.3366  loss_box_reg: 0.561  loss_mask: 0.2998  loss_rpn_cls: 0.07108  loss_rpn_loc: 0.1658  time: 0.3535  data_time: 0.0267  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:17:13 d2.utils.events]: \u001b[0m eta: 0:36:54  iter: 3379  total_loss: 1.286  loss_cls: 0.2856  loss_box_reg: 0.5227  loss_mask: 0.3002  loss_rpn_cls: 0.05544  loss_rpn_loc: 0.1317  time: 0.3534  data_time: 0.0184  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:17:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:17:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:17:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:17:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:17:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:17:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1301 s/iter. Eval: 0.0826 s/iter. Total: 0.2133 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0008 s/iter. Inference: 0.1396 s/iter. Eval: 0.1504 s/iter. Total: 0.2908 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/08 19:17:30 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1433 s/iter. Eval: 0.1680 s/iter. Total: 0.3121 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 19:17:35 d2.evaluation.evaluator]: \u001b[0mInference done 60/121. Dataloading: 0.0008 s/iter. Inference: 0.1446 s/iter. Eval: 0.1679 s/iter. Total: 0.3134 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/08 19:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.1464 s/iter. Eval: 0.1746 s/iter. Total: 0.3219 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.1494 s/iter. Eval: 0.1912 s/iter. Total: 0.3415 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 19:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.1498 s/iter. Eval: 0.1979 s/iter. Total: 0.3486 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/08 19:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.1482 s/iter. Eval: 0.1853 s/iter. Total: 0.3344 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/08 19:17:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.985666 (0.336083 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:17:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.148440 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:17:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:17:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.19215364080653846\n",
      "\u001b[32m[02/08 19:18:00 d2.utils.events]: \u001b[0m eta: 0:36:48  iter: 3399  total_loss: 1.321  loss_cls: 0.2942  loss_box_reg: 0.5577  loss_mask: 0.3  loss_rpn_cls: 0.05122  loss_rpn_loc: 0.1254  time: 0.3533  data_time: 0.0149  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:18:07 d2.utils.events]: \u001b[0m eta: 0:36:43  iter: 3419  total_loss: 1.442  loss_cls: 0.3172  loss_box_reg: 0.5689  loss_mask: 0.299  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.162  time: 0.3533  data_time: 0.0219  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:18:14 d2.utils.events]: \u001b[0m eta: 0:36:36  iter: 3439  total_loss: 1.317  loss_cls: 0.2584  loss_box_reg: 0.5244  loss_mask: 0.292  loss_rpn_cls: 0.05037  loss_rpn_loc: 0.1099  time: 0.3531  data_time: 0.0094  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:18:21 d2.utils.events]: \u001b[0m eta: 0:36:34  iter: 3459  total_loss: 1.55  loss_cls: 0.3805  loss_box_reg: 0.5906  loss_mask: 0.3154  loss_rpn_cls: 0.0845  loss_rpn_loc: 0.1731  time: 0.3531  data_time: 0.0248  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:18:28 d2.utils.events]: \u001b[0m eta: 0:36:29  iter: 3479  total_loss: 1.459  loss_cls: 0.3214  loss_box_reg: 0.5629  loss_mask: 0.3149  loss_rpn_cls: 0.07202  loss_rpn_loc: 0.1644  time: 0.3532  data_time: 0.0387  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:18:35 d2.utils.events]: \u001b[0m eta: 0:36:22  iter: 3499  total_loss: 1.244  loss_cls: 0.2854  loss_box_reg: 0.536  loss_mask: 0.2963  loss_rpn_cls: 0.0572  loss_rpn_loc: 0.1012  time: 0.3531  data_time: 0.0193  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:18:42 d2.utils.events]: \u001b[0m eta: 0:36:19  iter: 3519  total_loss: 1.428  loss_cls: 0.3116  loss_box_reg: 0.5715  loss_mask: 0.3095  loss_rpn_cls: 0.07386  loss_rpn_loc: 0.1491  time: 0.3531  data_time: 0.0344  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:18:49 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 3539  total_loss: 1.343  loss_cls: 0.3113  loss_box_reg: 0.5386  loss_mask: 0.285  loss_rpn_cls: 0.05528  loss_rpn_loc: 0.155  time: 0.3532  data_time: 0.0186  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:18:56 d2.utils.events]: \u001b[0m eta: 0:36:08  iter: 3559  total_loss: 1.334  loss_cls: 0.2988  loss_box_reg: 0.5387  loss_mask: 0.2906  loss_rpn_cls: 0.05264  loss_rpn_loc: 0.1556  time: 0.3532  data_time: 0.0176  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:19:04 d2.utils.events]: \u001b[0m eta: 0:36:02  iter: 3579  total_loss: 1.402  loss_cls: 0.3276  loss_box_reg: 0.5681  loss_mask: 0.3035  loss_rpn_cls: 0.0642  loss_rpn_loc: 0.1696  time: 0.3532  data_time: 0.0252  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:19:11 d2.utils.events]: \u001b[0m eta: 0:35:58  iter: 3599  total_loss: 1.567  loss_cls: 0.3462  loss_box_reg: 0.5983  loss_mask: 0.32  loss_rpn_cls: 0.08644  loss_rpn_loc: 0.1565  time: 0.3533  data_time: 0.0229  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:19:18 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 3619  total_loss: 1.33  loss_cls: 0.3092  loss_box_reg: 0.5235  loss_mask: 0.2965  loss_rpn_cls: 0.05979  loss_rpn_loc: 0.1252  time: 0.3534  data_time: 0.0378  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:19:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:19:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:19:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:19:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:19:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:19:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:19:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1271 s/iter. Eval: 0.0712 s/iter. Total: 0.1989 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 19:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0007 s/iter. Inference: 0.1348 s/iter. Eval: 0.1462 s/iter. Total: 0.2817 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 19:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1400 s/iter. Eval: 0.1608 s/iter. Total: 0.3016 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0008 s/iter. Inference: 0.1410 s/iter. Eval: 0.1597 s/iter. Total: 0.3016 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/08 19:19:47 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.1427 s/iter. Eval: 0.1691 s/iter. Total: 0.3127 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:19:52 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.1452 s/iter. Eval: 0.1880 s/iter. Total: 0.3341 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 19:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.1456 s/iter. Eval: 0.1918 s/iter. Total: 0.3383 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/08 19:20:02 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.1444 s/iter. Eval: 0.1821 s/iter. Total: 0.3274 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:20:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.341085 (0.330527 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:20:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.144951 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:20:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:20:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.19599123113494302\n",
      "\u001b[32m[02/08 19:20:06 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 3639  total_loss: 1.246  loss_cls: 0.2569  loss_box_reg: 0.5442  loss_mask: 0.2999  loss_rpn_cls: 0.03594  loss_rpn_loc: 0.1111  time: 0.3535  data_time: 0.0423  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:20:13 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 3659  total_loss: 1.335  loss_cls: 0.2852  loss_box_reg: 0.5571  loss_mask: 0.299  loss_rpn_cls: 0.05818  loss_rpn_loc: 0.1497  time: 0.3535  data_time: 0.0258  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:20:21 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 3679  total_loss: 1.533  loss_cls: 0.3482  loss_box_reg: 0.5771  loss_mask: 0.319  loss_rpn_cls: 0.09398  loss_rpn_loc: 0.1934  time: 0.3537  data_time: 0.0460  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:20:29 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 3699  total_loss: 1.439  loss_cls: 0.3172  loss_box_reg: 0.5681  loss_mask: 0.307  loss_rpn_cls: 0.07954  loss_rpn_loc: 0.149  time: 0.3538  data_time: 0.0466  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:20:36 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 3719  total_loss: 1.216  loss_cls: 0.2407  loss_box_reg: 0.5365  loss_mask: 0.2944  loss_rpn_cls: 0.0481  loss_rpn_loc: 0.1159  time: 0.3537  data_time: 0.0164  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:20:43 d2.utils.events]: \u001b[0m eta: 0:35:08  iter: 3739  total_loss: 1.345  loss_cls: 0.2952  loss_box_reg: 0.5468  loss_mask: 0.3023  loss_rpn_cls: 0.0529  loss_rpn_loc: 0.1422  time: 0.3537  data_time: 0.0194  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:20:49 d2.utils.events]: \u001b[0m eta: 0:35:00  iter: 3759  total_loss: 1.249  loss_cls: 0.2815  loss_box_reg: 0.5268  loss_mask: 0.287  loss_rpn_cls: 0.05043  loss_rpn_loc: 0.1035  time: 0.3535  data_time: 0.0120  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:20:56 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 3779  total_loss: 1.312  loss_cls: 0.2678  loss_box_reg: 0.5434  loss_mask: 0.2971  loss_rpn_cls: 0.05501  loss_rpn_loc: 0.1519  time: 0.3536  data_time: 0.0424  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:21:03 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 3799  total_loss: 1.316  loss_cls: 0.3054  loss_box_reg: 0.5329  loss_mask: 0.3017  loss_rpn_cls: 0.06418  loss_rpn_loc: 0.1374  time: 0.3536  data_time: 0.0154  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:21:10 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 3819  total_loss: 1.269  loss_cls: 0.28  loss_box_reg: 0.5574  loss_mask: 0.2949  loss_rpn_cls: 0.03536  loss_rpn_loc: 0.1164  time: 0.3534  data_time: 0.0083  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:21:17 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 3839  total_loss: 1.529  loss_cls: 0.3376  loss_box_reg: 0.5949  loss_mask: 0.3295  loss_rpn_cls: 0.07445  loss_rpn_loc: 0.1685  time: 0.3535  data_time: 0.0434  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:21:25 d2.utils.events]: \u001b[0m eta: 0:34:26  iter: 3859  total_loss: 1.515  loss_cls: 0.3518  loss_box_reg: 0.5744  loss_mask: 0.3198  loss_rpn_cls: 0.07075  loss_rpn_loc: 0.1676  time: 0.3537  data_time: 0.0494  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:21:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:21:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:21:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:21:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:21:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:21:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1347 s/iter. Eval: 0.0786 s/iter. Total: 0.2139 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0008 s/iter. Inference: 0.1424 s/iter. Eval: 0.1491 s/iter. Total: 0.2923 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/08 19:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1428 s/iter. Eval: 0.1638 s/iter. Total: 0.3075 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0008 s/iter. Inference: 0.1428 s/iter. Eval: 0.1609 s/iter. Total: 0.3045 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/08 19:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1441 s/iter. Eval: 0.1713 s/iter. Total: 0.3162 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0008 s/iter. Inference: 0.1456 s/iter. Eval: 0.1810 s/iter. Total: 0.3275 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 19:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.1450 s/iter. Eval: 0.1863 s/iter. Total: 0.3322 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 19:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.1441 s/iter. Eval: 0.1797 s/iter. Total: 0.3246 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:22:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.689221 (0.324907 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:22:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.144105 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:22:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:22:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.19950554430965703\n",
      "\u001b[32m[02/08 19:22:12 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 3879  total_loss: 1.419  loss_cls: 0.3358  loss_box_reg: 0.5581  loss_mask: 0.289  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.1493  time: 0.3536  data_time: 0.0123  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:22:19 d2.utils.events]: \u001b[0m eta: 0:34:12  iter: 3899  total_loss: 1.301  loss_cls: 0.2963  loss_box_reg: 0.5254  loss_mask: 0.2878  loss_rpn_cls: 0.05843  loss_rpn_loc: 0.1345  time: 0.3536  data_time: 0.0323  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:22:25 d2.utils.events]: \u001b[0m eta: 0:34:02  iter: 3919  total_loss: 1.311  loss_cls: 0.2844  loss_box_reg: 0.5539  loss_mask: 0.2911  loss_rpn_cls: 0.05383  loss_rpn_loc: 0.1295  time: 0.3535  data_time: 0.0143  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:22:32 d2.utils.events]: \u001b[0m eta: 0:33:54  iter: 3939  total_loss: 1.461  loss_cls: 0.3211  loss_box_reg: 0.5726  loss_mask: 0.3305  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.1496  time: 0.3533  data_time: 0.0125  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:22:39 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 3959  total_loss: 1.579  loss_cls: 0.3441  loss_box_reg: 0.602  loss_mask: 0.3329  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.1755  time: 0.3534  data_time: 0.0436  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:22:46 d2.utils.events]: \u001b[0m eta: 0:33:37  iter: 3979  total_loss: 1.354  loss_cls: 0.2956  loss_box_reg: 0.5539  loss_mask: 0.2954  loss_rpn_cls: 0.05344  loss_rpn_loc: 0.1443  time: 0.3534  data_time: 0.0163  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:22:53 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 3999  total_loss: 1.292  loss_cls: 0.2906  loss_box_reg: 0.5395  loss_mask: 0.3012  loss_rpn_cls: 0.05106  loss_rpn_loc: 0.1179  time: 0.3533  data_time: 0.0156  lr: 0.00032  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:23:00 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 4019  total_loss: 1.431  loss_cls: 0.3208  loss_box_reg: 0.5598  loss_mask: 0.305  loss_rpn_cls: 0.06668  loss_rpn_loc: 0.1629  time: 0.3533  data_time: 0.0245  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:23:07 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 4039  total_loss: 1.482  loss_cls: 0.3232  loss_box_reg: 0.5748  loss_mask: 0.3054  loss_rpn_cls: 0.07987  loss_rpn_loc: 0.1594  time: 0.3533  data_time: 0.0252  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:23:15 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 4059  total_loss: 1.402  loss_cls: 0.3012  loss_box_reg: 0.5608  loss_mask: 0.2979  loss_rpn_cls: 0.07655  loss_rpn_loc: 0.1786  time: 0.3534  data_time: 0.0554  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:23:22 d2.utils.events]: \u001b[0m eta: 0:33:03  iter: 4079  total_loss: 1.251  loss_cls: 0.2837  loss_box_reg: 0.5207  loss_mask: 0.291  loss_rpn_cls: 0.05042  loss_rpn_loc: 0.0894  time: 0.3534  data_time: 0.0439  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:23:28 d2.utils.events]: \u001b[0m eta: 0:32:55  iter: 4099  total_loss: 1.442  loss_cls: 0.337  loss_box_reg: 0.5717  loss_mask: 0.3091  loss_rpn_cls: 0.0586  loss_rpn_loc: 0.1494  time: 0.3533  data_time: 0.0139  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:23:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:23:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:23:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:23:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:23:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:23:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:23:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1344 s/iter. Eval: 0.0818 s/iter. Total: 0.2169 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:23:42 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0008 s/iter. Inference: 0.1396 s/iter. Eval: 0.1523 s/iter. Total: 0.2927 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/08 19:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1428 s/iter. Eval: 0.1661 s/iter. Total: 0.3097 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0008 s/iter. Inference: 0.1438 s/iter. Eval: 0.1608 s/iter. Total: 0.3054 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/08 19:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1469 s/iter. Eval: 0.1720 s/iter. Total: 0.3197 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.1492 s/iter. Eval: 0.1840 s/iter. Total: 0.3341 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 19:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.1482 s/iter. Eval: 0.1887 s/iter. Total: 0.3377 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/08 19:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1472 s/iter. Eval: 0.1821 s/iter. Total: 0.3301 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:24:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.338434 (0.330504 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:24:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.147196 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:24:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:24:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20398086376076513\n",
      "\u001b[32m[02/08 19:24:16 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 4119  total_loss: 1.224  loss_cls: 0.2697  loss_box_reg: 0.5392  loss_mask: 0.2961  loss_rpn_cls: 0.04261  loss_rpn_loc: 0.1413  time: 0.3534  data_time: 0.0349  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:24:23 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 4139  total_loss: 1.423  loss_cls: 0.3308  loss_box_reg: 0.5537  loss_mask: 0.2914  loss_rpn_cls: 0.06718  loss_rpn_loc: 0.166  time: 0.3534  data_time: 0.0276  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:24:30 d2.utils.events]: \u001b[0m eta: 0:32:36  iter: 4159  total_loss: 1.293  loss_cls: 0.3107  loss_box_reg: 0.5437  loss_mask: 0.2995  loss_rpn_cls: 0.03511  loss_rpn_loc: 0.1094  time: 0.3534  data_time: 0.0261  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:24:38 d2.utils.events]: \u001b[0m eta: 0:32:29  iter: 4179  total_loss: 1.424  loss_cls: 0.322  loss_box_reg: 0.5683  loss_mask: 0.319  loss_rpn_cls: 0.07868  loss_rpn_loc: 0.1649  time: 0.3535  data_time: 0.0563  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:24:44 d2.utils.events]: \u001b[0m eta: 0:32:15  iter: 4199  total_loss: 1.208  loss_cls: 0.2561  loss_box_reg: 0.5126  loss_mask: 0.2925  loss_rpn_cls: 0.03923  loss_rpn_loc: 0.1218  time: 0.3533  data_time: 0.0162  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:24:51 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 4219  total_loss: 1.364  loss_cls: 0.306  loss_box_reg: 0.5602  loss_mask: 0.289  loss_rpn_cls: 0.05476  loss_rpn_loc: 0.1337  time: 0.3533  data_time: 0.0281  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:24:58 d2.utils.events]: \u001b[0m eta: 0:31:59  iter: 4239  total_loss: 1.337  loss_cls: 0.3091  loss_box_reg: 0.5318  loss_mask: 0.2953  loss_rpn_cls: 0.06638  loss_rpn_loc: 0.1232  time: 0.3532  data_time: 0.0331  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:25:06 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 4259  total_loss: 1.539  loss_cls: 0.3469  loss_box_reg: 0.5886  loss_mask: 0.3216  loss_rpn_cls: 0.09476  loss_rpn_loc: 0.1858  time: 0.3533  data_time: 0.0424  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:25:12 d2.utils.events]: \u001b[0m eta: 0:31:46  iter: 4279  total_loss: 1.296  loss_cls: 0.3011  loss_box_reg: 0.5359  loss_mask: 0.2922  loss_rpn_cls: 0.05844  loss_rpn_loc: 0.1327  time: 0.3532  data_time: 0.0101  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:25:20 d2.utils.events]: \u001b[0m eta: 0:31:42  iter: 4299  total_loss: 1.401  loss_cls: 0.3311  loss_box_reg: 0.5581  loss_mask: 0.3056  loss_rpn_cls: 0.06922  loss_rpn_loc: 0.1709  time: 0.3533  data_time: 0.0270  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:25:27 d2.utils.events]: \u001b[0m eta: 0:31:35  iter: 4319  total_loss: 1.383  loss_cls: 0.3036  loss_box_reg: 0.5434  loss_mask: 0.3079  loss_rpn_cls: 0.06896  loss_rpn_loc: 0.1392  time: 0.3534  data_time: 0.0300  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:25:34 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 4339  total_loss: 1.417  loss_cls: 0.315  loss_box_reg: 0.5538  loss_mask: 0.3045  loss_rpn_cls: 0.06297  loss_rpn_loc: 0.1588  time: 0.3534  data_time: 0.0441  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:25:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:25:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:25:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:25:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:25:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:25:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1317 s/iter. Eval: 0.0819 s/iter. Total: 0.2143 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:25:49 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0007 s/iter. Inference: 0.1367 s/iter. Eval: 0.1366 s/iter. Total: 0.2741 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1387 s/iter. Eval: 0.1575 s/iter. Total: 0.2970 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:25:59 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1386 s/iter. Eval: 0.1540 s/iter. Total: 0.2934 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:26:04 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.1410 s/iter. Eval: 0.1618 s/iter. Total: 0.3037 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:26:09 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0008 s/iter. Inference: 0.1439 s/iter. Eval: 0.1725 s/iter. Total: 0.3172 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.1426 s/iter. Eval: 0.1793 s/iter. Total: 0.3227 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 19:26:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.121874 (0.311395 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:26:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.141489 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:26:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:26:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20725484248606535\n",
      "\u001b[32m[02/08 19:26:20 d2.utils.events]: \u001b[0m eta: 0:31:20  iter: 4359  total_loss: 1.248  loss_cls: 0.2796  loss_box_reg: 0.528  loss_mask: 0.2835  loss_rpn_cls: 0.05103  loss_rpn_loc: 0.1336  time: 0.3535  data_time: 0.0345  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:26:27 d2.utils.events]: \u001b[0m eta: 0:31:13  iter: 4379  total_loss: 1.393  loss_cls: 0.328  loss_box_reg: 0.5682  loss_mask: 0.3208  loss_rpn_cls: 0.06793  loss_rpn_loc: 0.1466  time: 0.3534  data_time: 0.0164  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:26:33 d2.utils.events]: \u001b[0m eta: 0:31:07  iter: 4399  total_loss: 1.406  loss_cls: 0.3189  loss_box_reg: 0.5575  loss_mask: 0.3074  loss_rpn_cls: 0.07002  loss_rpn_loc: 0.1489  time: 0.3533  data_time: 0.0303  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:26:40 d2.utils.events]: \u001b[0m eta: 0:31:00  iter: 4419  total_loss: 1.328  loss_cls: 0.2944  loss_box_reg: 0.5313  loss_mask: 0.3104  loss_rpn_cls: 0.05086  loss_rpn_loc: 0.1393  time: 0.3533  data_time: 0.0348  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:26:47 d2.utils.events]: \u001b[0m eta: 0:30:53  iter: 4439  total_loss: 1.381  loss_cls: 0.3101  loss_box_reg: 0.5414  loss_mask: 0.3005  loss_rpn_cls: 0.06227  loss_rpn_loc: 0.1594  time: 0.3532  data_time: 0.0235  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:26:54 d2.utils.events]: \u001b[0m eta: 0:30:45  iter: 4459  total_loss: 1.324  loss_cls: 0.3005  loss_box_reg: 0.5379  loss_mask: 0.3016  loss_rpn_cls: 0.05413  loss_rpn_loc: 0.1349  time: 0.3531  data_time: 0.0139  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:27:01 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 4479  total_loss: 1.308  loss_cls: 0.308  loss_box_reg: 0.543  loss_mask: 0.2899  loss_rpn_cls: 0.04528  loss_rpn_loc: 0.157  time: 0.3532  data_time: 0.0437  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:27:08 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 4499  total_loss: 1.357  loss_cls: 0.3087  loss_box_reg: 0.5283  loss_mask: 0.2921  loss_rpn_cls: 0.05509  loss_rpn_loc: 0.1321  time: 0.3531  data_time: 0.0199  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:27:15 d2.utils.events]: \u001b[0m eta: 0:30:24  iter: 4519  total_loss: 1.386  loss_cls: 0.3118  loss_box_reg: 0.5324  loss_mask: 0.3011  loss_rpn_cls: 0.06126  loss_rpn_loc: 0.1638  time: 0.3531  data_time: 0.0221  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:27:22 d2.utils.events]: \u001b[0m eta: 0:30:15  iter: 4539  total_loss: 1.405  loss_cls: 0.3254  loss_box_reg: 0.555  loss_mask: 0.3033  loss_rpn_cls: 0.08272  loss_rpn_loc: 0.1404  time: 0.3532  data_time: 0.0463  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:27:30 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 4559  total_loss: 1.287  loss_cls: 0.2944  loss_box_reg: 0.5089  loss_mask: 0.2905  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.126  time: 0.3532  data_time: 0.0249  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:27:37 d2.utils.events]: \u001b[0m eta: 0:30:00  iter: 4579  total_loss: 1.394  loss_cls: 0.3241  loss_box_reg: 0.5549  loss_mask: 0.297  loss_rpn_cls: 0.07466  loss_rpn_loc: 0.1698  time: 0.3533  data_time: 0.0337  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:27:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:27:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:27:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:27:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:27:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:27:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1321 s/iter. Eval: 0.0804 s/iter. Total: 0.2132 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:27:52 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0007 s/iter. Inference: 0.1356 s/iter. Eval: 0.1491 s/iter. Total: 0.2855 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 19:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1357 s/iter. Eval: 0.1614 s/iter. Total: 0.2979 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1354 s/iter. Eval: 0.1582 s/iter. Total: 0.2944 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1391 s/iter. Eval: 0.1753 s/iter. Total: 0.3153 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.1420 s/iter. Eval: 0.1895 s/iter. Total: 0.3323 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 19:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.1427 s/iter. Eval: 0.1969 s/iter. Total: 0.3405 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/08 19:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.1423 s/iter. Eval: 0.1876 s/iter. Total: 0.3308 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:28:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.713339 (0.333736 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:28:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.142799 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:28:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:28:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21492189264637682\n",
      "\u001b[32m[02/08 19:28:26 d2.utils.events]: \u001b[0m eta: 0:29:52  iter: 4599  total_loss: 1.312  loss_cls: 0.3059  loss_box_reg: 0.5381  loss_mask: 0.2916  loss_rpn_cls: 0.05596  loss_rpn_loc: 0.1171  time: 0.3534  data_time: 0.0425  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:28:32 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 4619  total_loss: 1.218  loss_cls: 0.2553  loss_box_reg: 0.5341  loss_mask: 0.298  loss_rpn_cls: 0.03784  loss_rpn_loc: 0.1347  time: 0.3534  data_time: 0.0091  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:28:40 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 4639  total_loss: 1.453  loss_cls: 0.3282  loss_box_reg: 0.5707  loss_mask: 0.3032  loss_rpn_cls: 0.06423  loss_rpn_loc: 0.1614  time: 0.3534  data_time: 0.0361  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:28:47 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 4659  total_loss: 1.275  loss_cls: 0.2991  loss_box_reg: 0.5286  loss_mask: 0.2841  loss_rpn_cls: 0.04531  loss_rpn_loc: 0.1325  time: 0.3535  data_time: 0.0373  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:28:54 d2.utils.events]: \u001b[0m eta: 0:29:25  iter: 4679  total_loss: 1.392  loss_cls: 0.3089  loss_box_reg: 0.5562  loss_mask: 0.3007  loss_rpn_cls: 0.05543  loss_rpn_loc: 0.1489  time: 0.3535  data_time: 0.0226  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:29:01 d2.utils.events]: \u001b[0m eta: 0:29:18  iter: 4699  total_loss: 1.409  loss_cls: 0.3346  loss_box_reg: 0.5531  loss_mask: 0.2888  loss_rpn_cls: 0.07522  loss_rpn_loc: 0.1592  time: 0.3535  data_time: 0.0345  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:29:08 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 4719  total_loss: 1.333  loss_cls: 0.2591  loss_box_reg: 0.5579  loss_mask: 0.3106  loss_rpn_cls: 0.04975  loss_rpn_loc: 0.1257  time: 0.3534  data_time: 0.0154  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:29:16 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 4739  total_loss: 1.391  loss_cls: 0.3226  loss_box_reg: 0.5502  loss_mask: 0.3056  loss_rpn_cls: 0.07497  loss_rpn_loc: 0.1508  time: 0.3535  data_time: 0.0372  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:29:23 d2.utils.events]: \u001b[0m eta: 0:28:59  iter: 4759  total_loss: 1.394  loss_cls: 0.2991  loss_box_reg: 0.53  loss_mask: 0.2981  loss_rpn_cls: 0.06352  loss_rpn_loc: 0.1732  time: 0.3536  data_time: 0.0349  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:29:30 d2.utils.events]: \u001b[0m eta: 0:28:54  iter: 4779  total_loss: 1.376  loss_cls: 0.3199  loss_box_reg: 0.5471  loss_mask: 0.3031  loss_rpn_cls: 0.07326  loss_rpn_loc: 0.1432  time: 0.3537  data_time: 0.0244  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:29:37 d2.utils.events]: \u001b[0m eta: 0:28:48  iter: 4799  total_loss: 1.208  loss_cls: 0.2771  loss_box_reg: 0.52  loss_mask: 0.2809  loss_rpn_cls: 0.05088  loss_rpn_loc: 0.1302  time: 0.3536  data_time: 0.0213  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:29:44 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 4819  total_loss: 1.328  loss_cls: 0.2948  loss_box_reg: 0.5155  loss_mask: 0.2924  loss_rpn_cls: 0.05899  loss_rpn_loc: 0.1518  time: 0.3536  data_time: 0.0158  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:29:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:29:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:29:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:29:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:29:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:29:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1315 s/iter. Eval: 0.0842 s/iter. Total: 0.2164 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:30:00 d2.evaluation.evaluator]: \u001b[0mInference done 26/121. Dataloading: 0.0008 s/iter. Inference: 0.1402 s/iter. Eval: 0.1662 s/iter. Total: 0.3072 s/iter. ETA=0:00:29\n",
      "\u001b[32m[02/08 19:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.1405 s/iter. Eval: 0.1627 s/iter. Total: 0.3040 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0008 s/iter. Inference: 0.1421 s/iter. Eval: 0.1768 s/iter. Total: 0.3198 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/08 19:30:16 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.1430 s/iter. Eval: 0.1836 s/iter. Total: 0.3275 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/08 19:30:21 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.1460 s/iter. Eval: 0.2037 s/iter. Total: 0.3506 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 19:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1468 s/iter. Eval: 0.2109 s/iter. Total: 0.3585 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 19:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.1451 s/iter. Eval: 0.1972 s/iter. Total: 0.3432 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/08 19:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.205373 (0.346598 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.145837 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:30:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20102904882885836\n",
      "\u001b[32m[02/08 19:30:33 d2.utils.events]: \u001b[0m eta: 0:28:36  iter: 4839  total_loss: 1.117  loss_cls: 0.2485  loss_box_reg: 0.4718  loss_mask: 0.273  loss_rpn_cls: 0.04245  loss_rpn_loc: 0.09799  time: 0.3535  data_time: 0.0072  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:30:41 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 4859  total_loss: 1.341  loss_cls: 0.292  loss_box_reg: 0.5493  loss_mask: 0.3014  loss_rpn_cls: 0.04973  loss_rpn_loc: 0.1483  time: 0.3536  data_time: 0.0449  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:30:48 d2.utils.events]: \u001b[0m eta: 0:28:23  iter: 4879  total_loss: 1.477  loss_cls: 0.3454  loss_box_reg: 0.5561  loss_mask: 0.3185  loss_rpn_cls: 0.08494  loss_rpn_loc: 0.1528  time: 0.3536  data_time: 0.0168  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:30:55 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 4899  total_loss: 1.285  loss_cls: 0.2797  loss_box_reg: 0.5179  loss_mask: 0.2901  loss_rpn_cls: 0.04602  loss_rpn_loc: 0.1231  time: 0.3535  data_time: 0.0122  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:01 d2.utils.events]: \u001b[0m eta: 0:28:11  iter: 4919  total_loss: 1.407  loss_cls: 0.3292  loss_box_reg: 0.5529  loss_mask: 0.3029  loss_rpn_cls: 0.05589  loss_rpn_loc: 0.1366  time: 0.3535  data_time: 0.0166  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:08 d2.utils.events]: \u001b[0m eta: 0:28:04  iter: 4939  total_loss: 1.32  loss_cls: 0.2884  loss_box_reg: 0.5184  loss_mask: 0.286  loss_rpn_cls: 0.04675  loss_rpn_loc: 0.1342  time: 0.3534  data_time: 0.0189  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:15 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 4959  total_loss: 1.344  loss_cls: 0.3051  loss_box_reg: 0.5496  loss_mask: 0.3152  loss_rpn_cls: 0.07397  loss_rpn_loc: 0.145  time: 0.3534  data_time: 0.0124  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:22 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 4979  total_loss: 1.329  loss_cls: 0.2844  loss_box_reg: 0.5408  loss_mask: 0.2781  loss_rpn_cls: 0.05623  loss_rpn_loc: 0.1229  time: 0.3534  data_time: 0.0331  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:29 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 4999  total_loss: 1.232  loss_cls: 0.2843  loss_box_reg: 0.5183  loss_mask: 0.2856  loss_rpn_cls: 0.05832  loss_rpn_loc: 0.1212  time: 0.3534  data_time: 0.0273  lr: 0.000256  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:36 d2.utils.events]: \u001b[0m eta: 0:27:40  iter: 5019  total_loss: 1.443  loss_cls: 0.3123  loss_box_reg: 0.5731  loss_mask: 0.3024  loss_rpn_cls: 0.06806  loss_rpn_loc: 0.1437  time: 0.3534  data_time: 0.0217  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:43 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 5039  total_loss: 1.31  loss_cls: 0.2971  loss_box_reg: 0.5201  loss_mask: 0.2912  loss_rpn_cls: 0.04664  loss_rpn_loc: 0.1404  time: 0.3534  data_time: 0.0216  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:52 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 5059  total_loss: 1.544  loss_cls: 0.3601  loss_box_reg: 0.593  loss_mask: 0.3306  loss_rpn_cls: 0.06173  loss_rpn_loc: 0.165  time: 0.3536  data_time: 0.0625  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:31:59 d2.utils.events]: \u001b[0m eta: 0:27:21  iter: 5079  total_loss: 1.347  loss_cls: 0.2808  loss_box_reg: 0.5309  loss_mask: 0.2942  loss_rpn_cls: 0.06715  loss_rpn_loc: 0.1516  time: 0.3537  data_time: 0.0565  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:32:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:32:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:32:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:32:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:32:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:32:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1247 s/iter. Eval: 0.0782 s/iter. Total: 0.2035 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1335 s/iter. Eval: 0.1508 s/iter. Total: 0.2851 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 19:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.1372 s/iter. Eval: 0.1654 s/iter. Total: 0.3034 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.1379 s/iter. Eval: 0.1601 s/iter. Total: 0.2989 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1413 s/iter. Eval: 0.1720 s/iter. Total: 0.3142 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.1446 s/iter. Eval: 0.1808 s/iter. Total: 0.3262 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.1449 s/iter. Eval: 0.1851 s/iter. Total: 0.3308 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 19:32:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.163653 (0.320376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:32:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.144532 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:32:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:32:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2073620579209251\n",
      "\u001b[32m[02/08 19:32:45 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 5099  total_loss: 1.202  loss_cls: 0.2486  loss_box_reg: 0.5082  loss_mask: 0.2806  loss_rpn_cls: 0.03658  loss_rpn_loc: 0.1173  time: 0.3537  data_time: 0.0320  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:32:53 d2.utils.events]: \u001b[0m eta: 0:27:07  iter: 5119  total_loss: 1.457  loss_cls: 0.317  loss_box_reg: 0.5357  loss_mask: 0.3268  loss_rpn_cls: 0.09526  loss_rpn_loc: 0.1892  time: 0.3537  data_time: 0.0357  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:32:59 d2.utils.events]: \u001b[0m eta: 0:26:57  iter: 5139  total_loss: 1.333  loss_cls: 0.3089  loss_box_reg: 0.5346  loss_mask: 0.3021  loss_rpn_cls: 0.06163  loss_rpn_loc: 0.1398  time: 0.3536  data_time: 0.0186  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:33:06 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 5159  total_loss: 1.355  loss_cls: 0.2989  loss_box_reg: 0.5329  loss_mask: 0.3053  loss_rpn_cls: 0.06398  loss_rpn_loc: 0.1597  time: 0.3536  data_time: 0.0272  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:33:13 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 5179  total_loss: 1.322  loss_cls: 0.2856  loss_box_reg: 0.5385  loss_mask: 0.299  loss_rpn_cls: 0.05398  loss_rpn_loc: 0.1408  time: 0.3535  data_time: 0.0126  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:33:20 d2.utils.events]: \u001b[0m eta: 0:26:38  iter: 5199  total_loss: 1.43  loss_cls: 0.3277  loss_box_reg: 0.5634  loss_mask: 0.2889  loss_rpn_cls: 0.05935  loss_rpn_loc: 0.1434  time: 0.3535  data_time: 0.0298  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:33:28 d2.utils.events]: \u001b[0m eta: 0:26:32  iter: 5219  total_loss: 1.257  loss_cls: 0.2882  loss_box_reg: 0.5387  loss_mask: 0.3  loss_rpn_cls: 0.05542  loss_rpn_loc: 0.1157  time: 0.3537  data_time: 0.0592  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:33:35 d2.utils.events]: \u001b[0m eta: 0:26:27  iter: 5239  total_loss: 1.415  loss_cls: 0.3299  loss_box_reg: 0.5422  loss_mask: 0.3016  loss_rpn_cls: 0.07892  loss_rpn_loc: 0.1613  time: 0.3537  data_time: 0.0420  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:33:42 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 5259  total_loss: 1.269  loss_cls: 0.274  loss_box_reg: 0.5321  loss_mask: 0.2928  loss_rpn_cls: 0.05297  loss_rpn_loc: 0.13  time: 0.3537  data_time: 0.0135  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:33:49 d2.utils.events]: \u001b[0m eta: 0:26:13  iter: 5279  total_loss: 1.345  loss_cls: 0.3022  loss_box_reg: 0.5352  loss_mask: 0.3007  loss_rpn_cls: 0.05318  loss_rpn_loc: 0.1542  time: 0.3536  data_time: 0.0184  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:33:56 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 5299  total_loss: 1.351  loss_cls: 0.321  loss_box_reg: 0.5388  loss_mask: 0.2924  loss_rpn_cls: 0.06541  loss_rpn_loc: 0.145  time: 0.3537  data_time: 0.0299  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:34:04 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 5319  total_loss: 1.291  loss_cls: 0.3009  loss_box_reg: 0.5478  loss_mask: 0.2859  loss_rpn_cls: 0.06101  loss_rpn_loc: 0.1511  time: 0.3537  data_time: 0.0378  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:34:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:34:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:34:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:34:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:34:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:34:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1234 s/iter. Eval: 0.0696 s/iter. Total: 0.1937 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 19:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1328 s/iter. Eval: 0.1482 s/iter. Total: 0.2818 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1347 s/iter. Eval: 0.1613 s/iter. Total: 0.2969 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1340 s/iter. Eval: 0.1517 s/iter. Total: 0.2865 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1363 s/iter. Eval: 0.1649 s/iter. Total: 0.3020 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 19:34:35 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1394 s/iter. Eval: 0.1786 s/iter. Total: 0.3188 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:34:40 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.1385 s/iter. Eval: 0.1756 s/iter. Total: 0.3149 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 19:34:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.705946 (0.307810 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:34:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.137919 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:34:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:34:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21566880716451362\n",
      "\u001b[32m[02/08 19:34:49 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 5339  total_loss: 1.417  loss_cls: 0.3233  loss_box_reg: 0.5571  loss_mask: 0.2991  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.1497  time: 0.3537  data_time: 0.0366  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:34:56 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 5359  total_loss: 1.477  loss_cls: 0.3374  loss_box_reg: 0.5835  loss_mask: 0.3166  loss_rpn_cls: 0.07616  loss_rpn_loc: 0.1657  time: 0.3538  data_time: 0.0352  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:03 d2.utils.events]: \u001b[0m eta: 0:25:40  iter: 5379  total_loss: 1.427  loss_cls: 0.3168  loss_box_reg: 0.5693  loss_mask: 0.314  loss_rpn_cls: 0.05041  loss_rpn_loc: 0.1414  time: 0.3538  data_time: 0.0404  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:10 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 5399  total_loss: 1.228  loss_cls: 0.2397  loss_box_reg: 0.4953  loss_mask: 0.284  loss_rpn_cls: 0.03424  loss_rpn_loc: 0.1179  time: 0.3537  data_time: 0.0121  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:17 d2.utils.events]: \u001b[0m eta: 0:25:28  iter: 5419  total_loss: 1.393  loss_cls: 0.3211  loss_box_reg: 0.5338  loss_mask: 0.2951  loss_rpn_cls: 0.0763  loss_rpn_loc: 0.1637  time: 0.3537  data_time: 0.0182  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:25 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 5439  total_loss: 1.291  loss_cls: 0.2889  loss_box_reg: 0.5223  loss_mask: 0.2844  loss_rpn_cls: 0.05469  loss_rpn_loc: 0.1317  time: 0.3538  data_time: 0.0461  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:31 d2.utils.events]: \u001b[0m eta: 0:25:17  iter: 5459  total_loss: 1.199  loss_cls: 0.2707  loss_box_reg: 0.5117  loss_mask: 0.2803  loss_rpn_cls: 0.03277  loss_rpn_loc: 0.1191  time: 0.3538  data_time: 0.0199  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:38 d2.utils.events]: \u001b[0m eta: 0:25:10  iter: 5479  total_loss: 1.245  loss_cls: 0.2364  loss_box_reg: 0.5464  loss_mask: 0.3036  loss_rpn_cls: 0.04258  loss_rpn_loc: 0.1138  time: 0.3537  data_time: 0.0166  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:45 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 5499  total_loss: 1.327  loss_cls: 0.2882  loss_box_reg: 0.5397  loss_mask: 0.2945  loss_rpn_cls: 0.04897  loss_rpn_loc: 0.1412  time: 0.3537  data_time: 0.0233  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:52 d2.utils.events]: \u001b[0m eta: 0:24:55  iter: 5519  total_loss: 1.412  loss_cls: 0.2945  loss_box_reg: 0.5673  loss_mask: 0.3116  loss_rpn_cls: 0.05049  loss_rpn_loc: 0.1508  time: 0.3537  data_time: 0.0203  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:35:59 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 5539  total_loss: 1.28  loss_cls: 0.2818  loss_box_reg: 0.5007  loss_mask: 0.2741  loss_rpn_cls: 0.04813  loss_rpn_loc: 0.1424  time: 0.3536  data_time: 0.0250  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:36:06 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 5559  total_loss: 1.328  loss_cls: 0.3058  loss_box_reg: 0.5479  loss_mask: 0.2921  loss_rpn_cls: 0.0562  loss_rpn_loc: 0.1437  time: 0.3536  data_time: 0.0125  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:36:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:36:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:36:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:36:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:36:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:36:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1329 s/iter. Eval: 0.0857 s/iter. Total: 0.2192 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 19:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0007 s/iter. Inference: 0.1390 s/iter. Eval: 0.1542 s/iter. Total: 0.2939 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/08 19:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1412 s/iter. Eval: 0.1673 s/iter. Total: 0.3093 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 60/121. Dataloading: 0.0008 s/iter. Inference: 0.1412 s/iter. Eval: 0.1683 s/iter. Total: 0.3103 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/08 19:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.1427 s/iter. Eval: 0.1761 s/iter. Total: 0.3196 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 19:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.1460 s/iter. Eval: 0.1901 s/iter. Total: 0.3369 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 19:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.1458 s/iter. Eval: 0.1954 s/iter. Total: 0.3421 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/08 19:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1452 s/iter. Eval: 0.1873 s/iter. Total: 0.3333 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:36:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.693394 (0.333564 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:36:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.145164 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:36:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:36:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.1954961783355707\n",
      "\u001b[32m[02/08 19:36:54 d2.utils.events]: \u001b[0m eta: 0:24:34  iter: 5579  total_loss: 1.476  loss_cls: 0.3246  loss_box_reg: 0.5749  loss_mask: 0.31  loss_rpn_cls: 0.06199  loss_rpn_loc: 0.1596  time: 0.3536  data_time: 0.0296  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:01 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 5599  total_loss: 1.245  loss_cls: 0.267  loss_box_reg: 0.5265  loss_mask: 0.2906  loss_rpn_cls: 0.04261  loss_rpn_loc: 0.1331  time: 0.3536  data_time: 0.0348  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:08 d2.utils.events]: \u001b[0m eta: 0:24:18  iter: 5619  total_loss: 1.435  loss_cls: 0.3441  loss_box_reg: 0.5647  loss_mask: 0.3046  loss_rpn_cls: 0.07699  loss_rpn_loc: 0.1697  time: 0.3537  data_time: 0.0345  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:15 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 5639  total_loss: 1.214  loss_cls: 0.2708  loss_box_reg: 0.5143  loss_mask: 0.2982  loss_rpn_cls: 0.04212  loss_rpn_loc: 0.1211  time: 0.3536  data_time: 0.0128  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:23 d2.utils.events]: \u001b[0m eta: 0:24:04  iter: 5659  total_loss: 1.428  loss_cls: 0.3252  loss_box_reg: 0.5838  loss_mask: 0.3143  loss_rpn_cls: 0.06093  loss_rpn_loc: 0.1448  time: 0.3537  data_time: 0.0428  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:29 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 5679  total_loss: 1.154  loss_cls: 0.2511  loss_box_reg: 0.5056  loss_mask: 0.2797  loss_rpn_cls: 0.03511  loss_rpn_loc: 0.1014  time: 0.3535  data_time: 0.0072  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:36 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 5699  total_loss: 1.397  loss_cls: 0.3233  loss_box_reg: 0.548  loss_mask: 0.3032  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.1588  time: 0.3536  data_time: 0.0281  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:44 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 5719  total_loss: 1.388  loss_cls: 0.3196  loss_box_reg: 0.5301  loss_mask: 0.2919  loss_rpn_cls: 0.07427  loss_rpn_loc: 0.1583  time: 0.3537  data_time: 0.0548  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:51 d2.utils.events]: \u001b[0m eta: 0:23:37  iter: 5739  total_loss: 1.34  loss_cls: 0.3075  loss_box_reg: 0.5318  loss_mask: 0.3106  loss_rpn_cls: 0.06864  loss_rpn_loc: 0.1564  time: 0.3537  data_time: 0.0374  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:37:58 d2.utils.events]: \u001b[0m eta: 0:23:29  iter: 5759  total_loss: 1.248  loss_cls: 0.2476  loss_box_reg: 0.5114  loss_mask: 0.2942  loss_rpn_cls: 0.05207  loss_rpn_loc: 0.1347  time: 0.3537  data_time: 0.0237  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:38:05 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 5779  total_loss: 1.3  loss_cls: 0.2903  loss_box_reg: 0.5185  loss_mask: 0.2922  loss_rpn_cls: 0.0588  loss_rpn_loc: 0.1505  time: 0.3537  data_time: 0.0199  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:38:12 d2.utils.events]: \u001b[0m eta: 0:23:15  iter: 5799  total_loss: 1.324  loss_cls: 0.2905  loss_box_reg: 0.5431  loss_mask: 0.3002  loss_rpn_cls: 0.06195  loss_rpn_loc: 0.1435  time: 0.3536  data_time: 0.0146  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:38:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:38:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:38:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:38:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:38:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:38:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1279 s/iter. Eval: 0.0730 s/iter. Total: 0.2015 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0008 s/iter. Inference: 0.1346 s/iter. Eval: 0.1405 s/iter. Total: 0.2759 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1373 s/iter. Eval: 0.1576 s/iter. Total: 0.2957 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1363 s/iter. Eval: 0.1548 s/iter. Total: 0.2920 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1388 s/iter. Eval: 0.1682 s/iter. Total: 0.3079 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0008 s/iter. Inference: 0.1413 s/iter. Eval: 0.1772 s/iter. Total: 0.3194 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.1411 s/iter. Eval: 0.1828 s/iter. Total: 0.3247 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 19:38:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.104188 (0.319864 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:38:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.140825 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:38:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:38:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21046267529317647\n",
      "\u001b[32m[02/08 19:38:58 d2.utils.events]: \u001b[0m eta: 0:23:08  iter: 5819  total_loss: 1.365  loss_cls: 0.2938  loss_box_reg: 0.5494  loss_mask: 0.2951  loss_rpn_cls: 0.05675  loss_rpn_loc: 0.1414  time: 0.3536  data_time: 0.0335  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:39:05 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 5839  total_loss: 1.224  loss_cls: 0.2601  loss_box_reg: 0.516  loss_mask: 0.2874  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.1384  time: 0.3536  data_time: 0.0085  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:39:12 d2.utils.events]: \u001b[0m eta: 0:22:53  iter: 5859  total_loss: 1.279  loss_cls: 0.2946  loss_box_reg: 0.4877  loss_mask: 0.2692  loss_rpn_cls: 0.05348  loss_rpn_loc: 0.1324  time: 0.3535  data_time: 0.0144  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:39:19 d2.utils.events]: \u001b[0m eta: 0:22:46  iter: 5879  total_loss: 1.393  loss_cls: 0.317  loss_box_reg: 0.5477  loss_mask: 0.3117  loss_rpn_cls: 0.08169  loss_rpn_loc: 0.1513  time: 0.3536  data_time: 0.0492  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:39:26 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 5899  total_loss: 1.171  loss_cls: 0.2633  loss_box_reg: 0.5101  loss_mask: 0.2773  loss_rpn_cls: 0.03114  loss_rpn_loc: 0.1152  time: 0.3535  data_time: 0.0088  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:39:33 d2.utils.events]: \u001b[0m eta: 0:22:33  iter: 5919  total_loss: 1.302  loss_cls: 0.3127  loss_box_reg: 0.5241  loss_mask: 0.3073  loss_rpn_cls: 0.07079  loss_rpn_loc: 0.1457  time: 0.3536  data_time: 0.0450  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:39:41 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 5939  total_loss: 1.291  loss_cls: 0.3092  loss_box_reg: 0.5319  loss_mask: 0.3021  loss_rpn_cls: 0.06311  loss_rpn_loc: 0.1213  time: 0.3536  data_time: 0.0479  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:39:48 d2.utils.events]: \u001b[0m eta: 0:22:19  iter: 5959  total_loss: 1.346  loss_cls: 0.3002  loss_box_reg: 0.5605  loss_mask: 0.3001  loss_rpn_cls: 0.05014  loss_rpn_loc: 0.142  time: 0.3536  data_time: 0.0113  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:39:55 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 5979  total_loss: 1.46  loss_cls: 0.3234  loss_box_reg: 0.5526  loss_mask: 0.3049  loss_rpn_cls: 0.07318  loss_rpn_loc: 0.1769  time: 0.3536  data_time: 0.0187  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:40:02 d2.utils.events]: \u001b[0m eta: 0:22:07  iter: 5999  total_loss: 1.431  loss_cls: 0.3375  loss_box_reg: 0.5828  loss_mask: 0.3103  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.1588  time: 0.3536  data_time: 0.0240  lr: 0.0002048  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:40:09 d2.utils.events]: \u001b[0m eta: 0:22:01  iter: 6019  total_loss: 1.318  loss_cls: 0.2953  loss_box_reg: 0.5192  loss_mask: 0.2883  loss_rpn_cls: 0.05543  loss_rpn_loc: 0.1447  time: 0.3536  data_time: 0.0281  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:40:16 d2.utils.events]: \u001b[0m eta: 0:21:54  iter: 6039  total_loss: 1.334  loss_cls: 0.3034  loss_box_reg: 0.5229  loss_mask: 0.2889  loss_rpn_cls: 0.06334  loss_rpn_loc: 0.1412  time: 0.3536  data_time: 0.0319  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:40:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:40:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:40:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:40:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:40:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:40:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1270 s/iter. Eval: 0.0720 s/iter. Total: 0.1996 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 19:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0007 s/iter. Inference: 0.1337 s/iter. Eval: 0.1390 s/iter. Total: 0.2735 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1365 s/iter. Eval: 0.1563 s/iter. Total: 0.2936 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1362 s/iter. Eval: 0.1526 s/iter. Total: 0.2896 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:40:43 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1383 s/iter. Eval: 0.1648 s/iter. Total: 0.3039 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:40:48 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0008 s/iter. Inference: 0.1407 s/iter. Eval: 0.1760 s/iter. Total: 0.3175 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 19:40:53 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.1412 s/iter. Eval: 0.1823 s/iter. Total: 0.3244 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 19:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.1409 s/iter. Eval: 0.1767 s/iter. Total: 0.3185 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:40:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.971769 (0.318722 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:40:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.140943 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:40:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:40:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21393064969895353\n",
      "\u001b[32m[02/08 19:41:02 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 6059  total_loss: 1.355  loss_cls: 0.2931  loss_box_reg: 0.5332  loss_mask: 0.3055  loss_rpn_cls: 0.05784  loss_rpn_loc: 0.1375  time: 0.3535  data_time: 0.0208  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:41:09 d2.utils.events]: \u001b[0m eta: 0:21:40  iter: 6079  total_loss: 1.306  loss_cls: 0.2946  loss_box_reg: 0.5112  loss_mask: 0.2928  loss_rpn_cls: 0.05719  loss_rpn_loc: 0.1395  time: 0.3536  data_time: 0.0399  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:41:16 d2.utils.events]: \u001b[0m eta: 0:21:34  iter: 6099  total_loss: 1.26  loss_cls: 0.2854  loss_box_reg: 0.5367  loss_mask: 0.2956  loss_rpn_cls: 0.04692  loss_rpn_loc: 0.1356  time: 0.3535  data_time: 0.0125  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:41:23 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 6119  total_loss: 1.38  loss_cls: 0.3015  loss_box_reg: 0.5335  loss_mask: 0.3181  loss_rpn_cls: 0.0711  loss_rpn_loc: 0.1476  time: 0.3536  data_time: 0.0342  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:41:31 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 6139  total_loss: 1.277  loss_cls: 0.297  loss_box_reg: 0.5112  loss_mask: 0.288  loss_rpn_cls: 0.05731  loss_rpn_loc: 0.1342  time: 0.3536  data_time: 0.0275  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:41:37 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 6159  total_loss: 1.297  loss_cls: 0.2959  loss_box_reg: 0.5297  loss_mask: 0.2942  loss_rpn_cls: 0.04171  loss_rpn_loc: 0.1454  time: 0.3535  data_time: 0.0099  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:41:44 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 6179  total_loss: 1.146  loss_cls: 0.244  loss_box_reg: 0.4985  loss_mask: 0.2637  loss_rpn_cls: 0.03555  loss_rpn_loc: 0.1014  time: 0.3535  data_time: 0.0172  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:41:51 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 6199  total_loss: 1.223  loss_cls: 0.2727  loss_box_reg: 0.5115  loss_mask: 0.2996  loss_rpn_cls: 0.04575  loss_rpn_loc: 0.1186  time: 0.3535  data_time: 0.0513  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:41:59 d2.utils.events]: \u001b[0m eta: 0:20:54  iter: 6219  total_loss: 1.433  loss_cls: 0.3197  loss_box_reg: 0.5267  loss_mask: 0.2967  loss_rpn_cls: 0.08051  loss_rpn_loc: 0.1575  time: 0.3535  data_time: 0.0314  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:42:06 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 6239  total_loss: 1.431  loss_cls: 0.3362  loss_box_reg: 0.5507  loss_mask: 0.3058  loss_rpn_cls: 0.07027  loss_rpn_loc: 0.1548  time: 0.3535  data_time: 0.0196  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:42:13 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 6259  total_loss: 1.287  loss_cls: 0.304  loss_box_reg: 0.5226  loss_mask: 0.2839  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.1464  time: 0.3536  data_time: 0.0383  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:42:20 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 6279  total_loss: 1.376  loss_cls: 0.3259  loss_box_reg: 0.5625  loss_mask: 0.2983  loss_rpn_cls: 0.06002  loss_rpn_loc: 0.1458  time: 0.3535  data_time: 0.0174  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:42:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:42:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:42:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:42:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:42:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:42:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1277 s/iter. Eval: 0.0750 s/iter. Total: 0.2034 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0007 s/iter. Inference: 0.1338 s/iter. Eval: 0.1382 s/iter. Total: 0.2728 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1364 s/iter. Eval: 0.1541 s/iter. Total: 0.2914 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1357 s/iter. Eval: 0.1517 s/iter. Total: 0.2883 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1379 s/iter. Eval: 0.1639 s/iter. Total: 0.3026 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0008 s/iter. Inference: 0.1404 s/iter. Eval: 0.1708 s/iter. Total: 0.3120 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.1400 s/iter. Eval: 0.1748 s/iter. Total: 0.3157 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 19:43:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.071719 (0.310963 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:43:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.140148 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:43:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:43:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20957657286921177\n",
      "\u001b[32m[02/08 19:43:05 d2.utils.events]: \u001b[0m eta: 0:20:26  iter: 6299  total_loss: 1.253  loss_cls: 0.2921  loss_box_reg: 0.5255  loss_mask: 0.2948  loss_rpn_cls: 0.0453  loss_rpn_loc: 0.1309  time: 0.3535  data_time: 0.0381  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:43:13 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 6319  total_loss: 1.456  loss_cls: 0.334  loss_box_reg: 0.5493  loss_mask: 0.3178  loss_rpn_cls: 0.07783  loss_rpn_loc: 0.1773  time: 0.3536  data_time: 0.0486  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:43:20 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 6339  total_loss: 1.402  loss_cls: 0.3208  loss_box_reg: 0.5481  loss_mask: 0.3048  loss_rpn_cls: 0.06875  loss_rpn_loc: 0.1512  time: 0.3536  data_time: 0.0141  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:43:27 d2.utils.events]: \u001b[0m eta: 0:20:06  iter: 6359  total_loss: 1.299  loss_cls: 0.2852  loss_box_reg: 0.5265  loss_mask: 0.2985  loss_rpn_cls: 0.05841  loss_rpn_loc: 0.1354  time: 0.3536  data_time: 0.0359  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:43:34 d2.utils.events]: \u001b[0m eta: 0:19:59  iter: 6379  total_loss: 1.115  loss_cls: 0.2336  loss_box_reg: 0.481  loss_mask: 0.2739  loss_rpn_cls: 0.03929  loss_rpn_loc: 0.1219  time: 0.3536  data_time: 0.0198  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:43:41 d2.utils.events]: \u001b[0m eta: 0:19:52  iter: 6399  total_loss: 1.34  loss_cls: 0.2999  loss_box_reg: 0.5551  loss_mask: 0.303  loss_rpn_cls: 0.04292  loss_rpn_loc: 0.1186  time: 0.3535  data_time: 0.0153  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:43:47 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 6419  total_loss: 1.229  loss_cls: 0.2769  loss_box_reg: 0.5162  loss_mask: 0.2903  loss_rpn_cls: 0.05232  loss_rpn_loc: 0.1236  time: 0.3535  data_time: 0.0197  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:43:55 d2.utils.events]: \u001b[0m eta: 0:19:37  iter: 6439  total_loss: 1.398  loss_cls: 0.3109  loss_box_reg: 0.559  loss_mask: 0.3172  loss_rpn_cls: 0.06054  loss_rpn_loc: 0.1491  time: 0.3535  data_time: 0.0361  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:44:02 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 6459  total_loss: 1.308  loss_cls: 0.2831  loss_box_reg: 0.5215  loss_mask: 0.3039  loss_rpn_cls: 0.0621  loss_rpn_loc: 0.138  time: 0.3535  data_time: 0.0265  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:44:09 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 6479  total_loss: 1.384  loss_cls: 0.3007  loss_box_reg: 0.5324  loss_mask: 0.284  loss_rpn_cls: 0.05333  loss_rpn_loc: 0.1448  time: 0.3536  data_time: 0.0406  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:44:16 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 6499  total_loss: 1.403  loss_cls: 0.3202  loss_box_reg: 0.5582  loss_mask: 0.3115  loss_rpn_cls: 0.06219  loss_rpn_loc: 0.1449  time: 0.3536  data_time: 0.0240  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:44:23 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 6519  total_loss: 1.402  loss_cls: 0.3049  loss_box_reg: 0.5452  loss_mask: 0.3014  loss_rpn_cls: 0.05921  loss_rpn_loc: 0.1646  time: 0.3536  data_time: 0.0317  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:44:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:44:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:44:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:44:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:44:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:44:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1265 s/iter. Eval: 0.0692 s/iter. Total: 0.1964 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 19:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1340 s/iter. Eval: 0.1485 s/iter. Total: 0.2834 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 19:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1362 s/iter. Eval: 0.1601 s/iter. Total: 0.2972 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1351 s/iter. Eval: 0.1526 s/iter. Total: 0.2886 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1375 s/iter. Eval: 0.1663 s/iter. Total: 0.3047 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1405 s/iter. Eval: 0.1804 s/iter. Total: 0.3218 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.1398 s/iter. Eval: 0.1778 s/iter. Total: 0.3184 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 19:45:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.061597 (0.310876 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:45:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.139214 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:45:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:45:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21644157499226796\n",
      "\u001b[32m[02/08 19:45:09 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 6539  total_loss: 1.319  loss_cls: 0.2872  loss_box_reg: 0.5261  loss_mask: 0.294  loss_rpn_cls: 0.06272  loss_rpn_loc: 0.1371  time: 0.3536  data_time: 0.0152  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:45:15 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 6559  total_loss: 1.259  loss_cls: 0.2875  loss_box_reg: 0.5206  loss_mask: 0.2787  loss_rpn_cls: 0.05177  loss_rpn_loc: 0.1342  time: 0.3535  data_time: 0.0084  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:45:22 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 6579  total_loss: 1.245  loss_cls: 0.2703  loss_box_reg: 0.5111  loss_mask: 0.2853  loss_rpn_cls: 0.04404  loss_rpn_loc: 0.1467  time: 0.3534  data_time: 0.0155  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:45:29 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 6599  total_loss: 1.437  loss_cls: 0.3155  loss_box_reg: 0.5651  loss_mask: 0.3182  loss_rpn_cls: 0.08616  loss_rpn_loc: 0.1485  time: 0.3535  data_time: 0.0277  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:45:36 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 6619  total_loss: 1.379  loss_cls: 0.3273  loss_box_reg: 0.5519  loss_mask: 0.2946  loss_rpn_cls: 0.08264  loss_rpn_loc: 0.1406  time: 0.3535  data_time: 0.0326  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:45:44 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 6639  total_loss: 1.52  loss_cls: 0.3747  loss_box_reg: 0.6009  loss_mask: 0.3204  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.1867  time: 0.3535  data_time: 0.0239  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:45:51 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 6659  total_loss: 1.327  loss_cls: 0.2976  loss_box_reg: 0.5353  loss_mask: 0.3028  loss_rpn_cls: 0.04655  loss_rpn_loc: 0.1413  time: 0.3535  data_time: 0.0380  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:45:57 d2.utils.events]: \u001b[0m eta: 0:18:22  iter: 6679  total_loss: 1.164  loss_cls: 0.2504  loss_box_reg: 0.5088  loss_mask: 0.2916  loss_rpn_cls: 0.0364  loss_rpn_loc: 0.1233  time: 0.3535  data_time: 0.0080  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:46:05 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 6699  total_loss: 1.447  loss_cls: 0.3201  loss_box_reg: 0.5638  loss_mask: 0.3189  loss_rpn_cls: 0.06396  loss_rpn_loc: 0.154  time: 0.3535  data_time: 0.0340  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:46:12 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 6719  total_loss: 1.19  loss_cls: 0.2715  loss_box_reg: 0.4949  loss_mask: 0.2841  loss_rpn_cls: 0.03731  loss_rpn_loc: 0.129  time: 0.3535  data_time: 0.0331  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:46:19 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 6739  total_loss: 1.235  loss_cls: 0.3012  loss_box_reg: 0.5145  loss_mask: 0.2888  loss_rpn_cls: 0.03942  loss_rpn_loc: 0.1181  time: 0.3535  data_time: 0.0339  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:46:26 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 6759  total_loss: 1.301  loss_cls: 0.2953  loss_box_reg: 0.5314  loss_mask: 0.3064  loss_rpn_cls: 0.05347  loss_rpn_loc: 0.1351  time: 0.3535  data_time: 0.0237  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:46:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:46:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:46:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:46:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:46:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:46:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1267 s/iter. Eval: 0.0755 s/iter. Total: 0.2029 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1349 s/iter. Eval: 0.1444 s/iter. Total: 0.2801 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1371 s/iter. Eval: 0.1600 s/iter. Total: 0.2980 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1360 s/iter. Eval: 0.1518 s/iter. Total: 0.2886 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1389 s/iter. Eval: 0.1687 s/iter. Total: 0.3084 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 19:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0008 s/iter. Inference: 0.1407 s/iter. Eval: 0.1724 s/iter. Total: 0.3139 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 19:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0008 s/iter. Inference: 0.1398 s/iter. Eval: 0.1687 s/iter. Total: 0.3093 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/08 19:47:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.407720 (0.305239 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:47:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.139729 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:47:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:47:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2043247140630698\n",
      "\u001b[32m[02/08 19:47:11 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 6779  total_loss: 1.266  loss_cls: 0.2836  loss_box_reg: 0.4828  loss_mask: 0.2813  loss_rpn_cls: 0.05923  loss_rpn_loc: 0.1414  time: 0.3535  data_time: 0.0239  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:47:18 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 6799  total_loss: 1.227  loss_cls: 0.2787  loss_box_reg: 0.4951  loss_mask: 0.2826  loss_rpn_cls: 0.0423  loss_rpn_loc: 0.1347  time: 0.3535  data_time: 0.0207  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:47:25 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 6819  total_loss: 1.167  loss_cls: 0.2668  loss_box_reg: 0.5013  loss_mask: 0.2894  loss_rpn_cls: 0.03692  loss_rpn_loc: 0.1066  time: 0.3535  data_time: 0.0193  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:47:32 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 6839  total_loss: 1.298  loss_cls: 0.3051  loss_box_reg: 0.5066  loss_mask: 0.2876  loss_rpn_cls: 0.05002  loss_rpn_loc: 0.1361  time: 0.3535  data_time: 0.0288  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:47:39 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 6859  total_loss: 1.336  loss_cls: 0.2961  loss_box_reg: 0.5146  loss_mask: 0.2885  loss_rpn_cls: 0.05447  loss_rpn_loc: 0.1622  time: 0.3535  data_time: 0.0224  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:47:46 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 6879  total_loss: 1.3  loss_cls: 0.2987  loss_box_reg: 0.5153  loss_mask: 0.2935  loss_rpn_cls: 0.06494  loss_rpn_loc: 0.1458  time: 0.3534  data_time: 0.0320  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:47:53 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 6899  total_loss: 1.395  loss_cls: 0.3167  loss_box_reg: 0.5453  loss_mask: 0.2993  loss_rpn_cls: 0.06288  loss_rpn_loc: 0.1458  time: 0.3535  data_time: 0.0428  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:47:59 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 6919  total_loss: 1.236  loss_cls: 0.277  loss_box_reg: 0.5056  loss_mask: 0.2914  loss_rpn_cls: 0.04317  loss_rpn_loc: 0.1187  time: 0.3534  data_time: 0.0084  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:48:07 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 6939  total_loss: 1.418  loss_cls: 0.3099  loss_box_reg: 0.537  loss_mask: 0.2943  loss_rpn_cls: 0.06787  loss_rpn_loc: 0.1693  time: 0.3535  data_time: 0.0663  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:48:14 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 6959  total_loss: 1.376  loss_cls: 0.3089  loss_box_reg: 0.5283  loss_mask: 0.2997  loss_rpn_cls: 0.06335  loss_rpn_loc: 0.1472  time: 0.3534  data_time: 0.0190  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:48:21 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 6979  total_loss: 1.262  loss_cls: 0.2953  loss_box_reg: 0.5237  loss_mask: 0.2919  loss_rpn_cls: 0.03927  loss_rpn_loc: 0.1434  time: 0.3535  data_time: 0.0458  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:48:28 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 6999  total_loss: 1.286  loss_cls: 0.2793  loss_box_reg: 0.5252  loss_mask: 0.2944  loss_rpn_cls: 0.04278  loss_rpn_loc: 0.1141  time: 0.3534  data_time: 0.0134  lr: 0.00016384  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:48:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:48:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:48:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:48:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:48:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:48:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1247 s/iter. Eval: 0.0712 s/iter. Total: 0.1965 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 19:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0008 s/iter. Inference: 0.1317 s/iter. Eval: 0.1379 s/iter. Total: 0.2704 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1338 s/iter. Eval: 0.1617 s/iter. Total: 0.2964 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1327 s/iter. Eval: 0.1525 s/iter. Total: 0.2860 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1347 s/iter. Eval: 0.1647 s/iter. Total: 0.3003 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 19:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1377 s/iter. Eval: 0.1764 s/iter. Total: 0.3149 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0008 s/iter. Inference: 0.1365 s/iter. Eval: 0.1720 s/iter. Total: 0.3093 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 19:49:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.214317 (0.303572 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:49:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.136019 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:49:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:49:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2080403585746315\n",
      "\u001b[32m[02/08 19:49:12 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 7019  total_loss: 1.401  loss_cls: 0.2843  loss_box_reg: 0.5494  loss_mask: 0.3032  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.1713  time: 0.3534  data_time: 0.0219  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:49:19 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 7039  total_loss: 1.327  loss_cls: 0.309  loss_box_reg: 0.5225  loss_mask: 0.2923  loss_rpn_cls: 0.05055  loss_rpn_loc: 0.1419  time: 0.3534  data_time: 0.0277  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:49:26 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 7059  total_loss: 1.299  loss_cls: 0.2851  loss_box_reg: 0.5312  loss_mask: 0.2856  loss_rpn_cls: 0.03352  loss_rpn_loc: 0.1148  time: 0.3533  data_time: 0.0170  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:49:35 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 7079  total_loss: 1.418  loss_cls: 0.3185  loss_box_reg: 0.5486  loss_mask: 0.2926  loss_rpn_cls: 0.06969  loss_rpn_loc: 0.1744  time: 0.3535  data_time: 0.0774  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:49:42 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 7099  total_loss: 1.301  loss_cls: 0.3013  loss_box_reg: 0.5422  loss_mask: 0.2847  loss_rpn_cls: 0.06145  loss_rpn_loc: 0.1384  time: 0.3536  data_time: 0.0411  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:49:50 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 7119  total_loss: 1.291  loss_cls: 0.2999  loss_box_reg: 0.5255  loss_mask: 0.3033  loss_rpn_cls: 0.062  loss_rpn_loc: 0.1529  time: 0.3537  data_time: 0.0596  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:49:57 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 7139  total_loss: 1.363  loss_cls: 0.3081  loss_box_reg: 0.5618  loss_mask: 0.3098  loss_rpn_cls: 0.05618  loss_rpn_loc: 0.1418  time: 0.3537  data_time: 0.0163  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:50:04 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 7159  total_loss: 1.138  loss_cls: 0.2201  loss_box_reg: 0.4915  loss_mask: 0.2727  loss_rpn_cls: 0.02167  loss_rpn_loc: 0.08143  time: 0.3536  data_time: 0.0143  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:50:11 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 7179  total_loss: 1.265  loss_cls: 0.2936  loss_box_reg: 0.4928  loss_mask: 0.2754  loss_rpn_cls: 0.05677  loss_rpn_loc: 0.1233  time: 0.3536  data_time: 0.0185  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:50:17 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 7199  total_loss: 1.216  loss_cls: 0.2778  loss_box_reg: 0.4963  loss_mask: 0.2769  loss_rpn_cls: 0.04758  loss_rpn_loc: 0.1213  time: 0.3536  data_time: 0.0127  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:50:25 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 7219  total_loss: 1.371  loss_cls: 0.3066  loss_box_reg: 0.5508  loss_mask: 0.3105  loss_rpn_cls: 0.05617  loss_rpn_loc: 0.1558  time: 0.3536  data_time: 0.0322  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:50:32 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 7239  total_loss: 1.401  loss_cls: 0.3385  loss_box_reg: 0.5421  loss_mask: 0.2871  loss_rpn_cls: 0.06042  loss_rpn_loc: 0.154  time: 0.3537  data_time: 0.0333  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:50:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:50:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:50:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:50:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:50:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:50:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:50:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1295 s/iter. Eval: 0.0795 s/iter. Total: 0.2097 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 19:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0008 s/iter. Inference: 0.1360 s/iter. Eval: 0.1415 s/iter. Total: 0.2783 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1391 s/iter. Eval: 0.1585 s/iter. Total: 0.2985 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:50:58 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0008 s/iter. Inference: 0.1388 s/iter. Eval: 0.1575 s/iter. Total: 0.2971 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.1410 s/iter. Eval: 0.1686 s/iter. Total: 0.3105 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:51:08 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0008 s/iter. Inference: 0.1434 s/iter. Eval: 0.1779 s/iter. Total: 0.3222 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 19:51:13 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.1435 s/iter. Eval: 0.1843 s/iter. Total: 0.3287 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 19:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.1430 s/iter. Eval: 0.1777 s/iter. Total: 0.3216 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 19:51:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.349172 (0.321976 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:51:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.142992 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:51:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:51:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20469715609630657\n",
      "\u001b[32m[02/08 19:51:19 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 7259  total_loss: 1.316  loss_cls: 0.2944  loss_box_reg: 0.5336  loss_mask: 0.2951  loss_rpn_cls: 0.05959  loss_rpn_loc: 0.161  time: 0.3536  data_time: 0.0163  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:51:26 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 7279  total_loss: 1.206  loss_cls: 0.2668  loss_box_reg: 0.496  loss_mask: 0.2951  loss_rpn_cls: 0.03351  loss_rpn_loc: 0.1254  time: 0.3536  data_time: 0.0217  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:51:33 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 7299  total_loss: 1.256  loss_cls: 0.2628  loss_box_reg: 0.5401  loss_mask: 0.303  loss_rpn_cls: 0.04393  loss_rpn_loc: 0.1281  time: 0.3536  data_time: 0.0216  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:51:40 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 7319  total_loss: 1.159  loss_cls: 0.2649  loss_box_reg: 0.5074  loss_mask: 0.2683  loss_rpn_cls: 0.04137  loss_rpn_loc: 0.1165  time: 0.3536  data_time: 0.0186  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:51:47 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 7339  total_loss: 1.335  loss_cls: 0.3056  loss_box_reg: 0.5325  loss_mask: 0.2901  loss_rpn_cls: 0.04905  loss_rpn_loc: 0.1376  time: 0.3537  data_time: 0.0496  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:51:54 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 7359  total_loss: 1.241  loss_cls: 0.2646  loss_box_reg: 0.5052  loss_mask: 0.2951  loss_rpn_cls: 0.04204  loss_rpn_loc: 0.1356  time: 0.3536  data_time: 0.0118  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:52:01 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 7379  total_loss: 1.281  loss_cls: 0.2966  loss_box_reg: 0.5228  loss_mask: 0.2916  loss_rpn_cls: 0.03597  loss_rpn_loc: 0.1212  time: 0.3536  data_time: 0.0169  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:52:07 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 7399  total_loss: 1.294  loss_cls: 0.2751  loss_box_reg: 0.5229  loss_mask: 0.2989  loss_rpn_cls: 0.05127  loss_rpn_loc: 0.1288  time: 0.3535  data_time: 0.0146  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:52:14 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 7419  total_loss: 1.227  loss_cls: 0.2799  loss_box_reg: 0.5022  loss_mask: 0.2774  loss_rpn_cls: 0.03396  loss_rpn_loc: 0.1287  time: 0.3535  data_time: 0.0112  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:52:22 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 7439  total_loss: 1.371  loss_cls: 0.3045  loss_box_reg: 0.5499  loss_mask: 0.3082  loss_rpn_cls: 0.06287  loss_rpn_loc: 0.1289  time: 0.3536  data_time: 0.0432  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:52:29 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 7459  total_loss: 1.341  loss_cls: 0.3024  loss_box_reg: 0.5016  loss_mask: 0.2915  loss_rpn_cls: 0.05581  loss_rpn_loc: 0.1587  time: 0.3536  data_time: 0.0242  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:52:36 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 7479  total_loss: 1.041  loss_cls: 0.2215  loss_box_reg: 0.46  loss_mask: 0.2725  loss_rpn_cls: 0.03149  loss_rpn_loc: 0.08651  time: 0.3535  data_time: 0.0259  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:52:44 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 7499  total_loss: 1.433  loss_cls: 0.3207  loss_box_reg: 0.5477  loss_mask: 0.3088  loss_rpn_cls: 0.07803  loss_rpn_loc: 0.1635  time: 0.3536  data_time: 0.0493  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:52:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:52:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:52:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:52:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:52:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:52:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1269 s/iter. Eval: 0.0754 s/iter. Total: 0.2030 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0008 s/iter. Inference: 0.1340 s/iter. Eval: 0.1379 s/iter. Total: 0.2727 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1366 s/iter. Eval: 0.1541 s/iter. Total: 0.2916 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1362 s/iter. Eval: 0.1518 s/iter. Total: 0.2889 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 19:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.1383 s/iter. Eval: 0.1591 s/iter. Total: 0.2982 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.1415 s/iter. Eval: 0.1724 s/iter. Total: 0.3148 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.1411 s/iter. Eval: 0.1762 s/iter. Total: 0.3182 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 19:53:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.931769 (0.309757 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:53:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.140717 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:53:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:53:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2019271822350255\n",
      "\u001b[32m[02/08 19:53:30 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 7519  total_loss: 1.432  loss_cls: 0.3127  loss_box_reg: 0.5421  loss_mask: 0.3126  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.1711  time: 0.3537  data_time: 0.0495  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:53:37 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 7539  total_loss: 1.355  loss_cls: 0.2978  loss_box_reg: 0.5314  loss_mask: 0.2998  loss_rpn_cls: 0.05263  loss_rpn_loc: 0.1401  time: 0.3538  data_time: 0.0426  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:53:44 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 7559  total_loss: 1.347  loss_cls: 0.3128  loss_box_reg: 0.5291  loss_mask: 0.2868  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.155  time: 0.3538  data_time: 0.0293  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:53:52 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 7579  total_loss: 1.223  loss_cls: 0.283  loss_box_reg: 0.4872  loss_mask: 0.2858  loss_rpn_cls: 0.04756  loss_rpn_loc: 0.1351  time: 0.3539  data_time: 0.0482  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:53:59 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 7599  total_loss: 1.326  loss_cls: 0.3031  loss_box_reg: 0.5302  loss_mask: 0.3088  loss_rpn_cls: 0.07939  loss_rpn_loc: 0.1444  time: 0.3539  data_time: 0.0414  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:54:06 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 7619  total_loss: 1.26  loss_cls: 0.2783  loss_box_reg: 0.5029  loss_mask: 0.294  loss_rpn_cls: 0.04714  loss_rpn_loc: 0.1247  time: 0.3539  data_time: 0.0132  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:54:13 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 7639  total_loss: 1.412  loss_cls: 0.3251  loss_box_reg: 0.5473  loss_mask: 0.298  loss_rpn_cls: 0.06493  loss_rpn_loc: 0.1511  time: 0.3539  data_time: 0.0247  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:54:20 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 7659  total_loss: 1.311  loss_cls: 0.2972  loss_box_reg: 0.5177  loss_mask: 0.2972  loss_rpn_cls: 0.03794  loss_rpn_loc: 0.1229  time: 0.3539  data_time: 0.0321  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:54:27 d2.utils.events]: \u001b[0m eta: 0:12:54  iter: 7679  total_loss: 1.187  loss_cls: 0.2739  loss_box_reg: 0.4998  loss_mask: 0.2925  loss_rpn_cls: 0.03901  loss_rpn_loc: 0.1199  time: 0.3538  data_time: 0.0153  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:54:34 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 7699  total_loss: 1.369  loss_cls: 0.2915  loss_box_reg: 0.5229  loss_mask: 0.2916  loss_rpn_cls: 0.06033  loss_rpn_loc: 0.1512  time: 0.3538  data_time: 0.0227  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:54:41 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 7719  total_loss: 1.391  loss_cls: 0.2975  loss_box_reg: 0.5215  loss_mask: 0.3014  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.1463  time: 0.3538  data_time: 0.0225  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:54:48 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 7739  total_loss: 1.288  loss_cls: 0.2982  loss_box_reg: 0.5301  loss_mask: 0.2844  loss_rpn_cls: 0.05798  loss_rpn_loc: 0.1335  time: 0.3538  data_time: 0.0286  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:54:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:54:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:54:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:54:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:54:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:54:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1275 s/iter. Eval: 0.0801 s/iter. Total: 0.2083 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0007 s/iter. Inference: 0.1324 s/iter. Eval: 0.1411 s/iter. Total: 0.2744 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1333 s/iter. Eval: 0.1564 s/iter. Total: 0.2906 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.1334 s/iter. Eval: 0.1577 s/iter. Total: 0.2920 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1353 s/iter. Eval: 0.1670 s/iter. Total: 0.3032 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 19:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.1392 s/iter. Eval: 0.1761 s/iter. Total: 0.3161 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.1389 s/iter. Eval: 0.1794 s/iter. Total: 0.3191 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 19:55:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.860471 (0.309142 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:55:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.138554 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:55:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:55:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20741209247619435\n",
      "\u001b[32m[02/08 19:55:33 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 7759  total_loss: 1.153  loss_cls: 0.2167  loss_box_reg: 0.5062  loss_mask: 0.2931  loss_rpn_cls: 0.03534  loss_rpn_loc: 0.1189  time: 0.3538  data_time: 0.0094  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:55:40 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 7779  total_loss: 1.308  loss_cls: 0.2885  loss_box_reg: 0.5206  loss_mask: 0.2798  loss_rpn_cls: 0.06372  loss_rpn_loc: 0.1505  time: 0.3538  data_time: 0.0287  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:55:47 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 7799  total_loss: 1.146  loss_cls: 0.2678  loss_box_reg: 0.4803  loss_mask: 0.2815  loss_rpn_cls: 0.03656  loss_rpn_loc: 0.1088  time: 0.3537  data_time: 0.0174  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:55:54 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 7819  total_loss: 1.359  loss_cls: 0.3076  loss_box_reg: 0.5338  loss_mask: 0.3063  loss_rpn_cls: 0.07067  loss_rpn_loc: 0.1531  time: 0.3538  data_time: 0.0317  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:02 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 7839  total_loss: 1.377  loss_cls: 0.3177  loss_box_reg: 0.5324  loss_mask: 0.2989  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.1497  time: 0.3538  data_time: 0.0318  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:09 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 7859  total_loss: 1.316  loss_cls: 0.2997  loss_box_reg: 0.5011  loss_mask: 0.2916  loss_rpn_cls: 0.0489  loss_rpn_loc: 0.1416  time: 0.3539  data_time: 0.0572  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:17 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 7879  total_loss: 1.322  loss_cls: 0.2816  loss_box_reg: 0.549  loss_mask: 0.3192  loss_rpn_cls: 0.05566  loss_rpn_loc: 0.1336  time: 0.3539  data_time: 0.0370  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:24 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 7899  total_loss: 1.22  loss_cls: 0.2779  loss_box_reg: 0.5278  loss_mask: 0.2891  loss_rpn_cls: 0.04861  loss_rpn_loc: 0.1312  time: 0.3539  data_time: 0.0218  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:31 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 7919  total_loss: 1.332  loss_cls: 0.3046  loss_box_reg: 0.5273  loss_mask: 0.2929  loss_rpn_cls: 0.04477  loss_rpn_loc: 0.1308  time: 0.3539  data_time: 0.0208  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:37 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 7939  total_loss: 1.207  loss_cls: 0.2603  loss_box_reg: 0.5187  loss_mask: 0.2933  loss_rpn_cls: 0.03348  loss_rpn_loc: 0.1261  time: 0.3538  data_time: 0.0177  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:45 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 7959  total_loss: 1.373  loss_cls: 0.3174  loss_box_reg: 0.5295  loss_mask: 0.3098  loss_rpn_cls: 0.05653  loss_rpn_loc: 0.1547  time: 0.3538  data_time: 0.0299  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:51 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 7979  total_loss: 1.26  loss_cls: 0.2863  loss_box_reg: 0.5266  loss_mask: 0.2901  loss_rpn_cls: 0.03593  loss_rpn_loc: 0.1171  time: 0.3538  data_time: 0.0180  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:56:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:56:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:56:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:56:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:56:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:56:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1257 s/iter. Eval: 0.0725 s/iter. Total: 0.1988 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 19:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1336 s/iter. Eval: 0.1499 s/iter. Total: 0.2843 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 19:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1358 s/iter. Eval: 0.1608 s/iter. Total: 0.2975 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1347 s/iter. Eval: 0.1526 s/iter. Total: 0.2881 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1376 s/iter. Eval: 0.1698 s/iter. Total: 0.3082 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 19:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0008 s/iter. Inference: 0.1394 s/iter. Eval: 0.1724 s/iter. Total: 0.3127 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 19:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0008 s/iter. Inference: 0.1383 s/iter. Eval: 0.1683 s/iter. Total: 0.3075 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/08 19:57:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.203385 (0.303477 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:57:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.138402 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:57:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:57:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20760251503713745\n",
      "\u001b[32m[02/08 19:57:36 d2.utils.events]: \u001b[0m eta: 0:11:09  iter: 7999  total_loss: 1.267  loss_cls: 0.2815  loss_box_reg: 0.527  loss_mask: 0.286  loss_rpn_cls: 0.03123  loss_rpn_loc: 0.1214  time: 0.3538  data_time: 0.0157  lr: 0.00013107  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:57:43 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 8019  total_loss: 1.273  loss_cls: 0.2759  loss_box_reg: 0.5338  loss_mask: 0.3049  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.1403  time: 0.3538  data_time: 0.0210  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:57:51 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 8039  total_loss: 1.245  loss_cls: 0.2711  loss_box_reg: 0.5058  loss_mask: 0.2922  loss_rpn_cls: 0.0578  loss_rpn_loc: 0.123  time: 0.3539  data_time: 0.0807  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:57:58 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 8059  total_loss: 1.299  loss_cls: 0.3134  loss_box_reg: 0.5354  loss_mask: 0.2978  loss_rpn_cls: 0.0487  loss_rpn_loc: 0.1283  time: 0.3539  data_time: 0.0429  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:05 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 8079  total_loss: 1.131  loss_cls: 0.2402  loss_box_reg: 0.4803  loss_mask: 0.2997  loss_rpn_cls: 0.03079  loss_rpn_loc: 0.102  time: 0.3539  data_time: 0.0331  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:12 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 8099  total_loss: 1.349  loss_cls: 0.3104  loss_box_reg: 0.5266  loss_mask: 0.3027  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.1571  time: 0.3539  data_time: 0.0183  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:20 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 8119  total_loss: 1.403  loss_cls: 0.3164  loss_box_reg: 0.5663  loss_mask: 0.3259  loss_rpn_cls: 0.07216  loss_rpn_loc: 0.1659  time: 0.3540  data_time: 0.0358  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:27 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 8139  total_loss: 1.226  loss_cls: 0.2632  loss_box_reg: 0.4977  loss_mask: 0.2826  loss_rpn_cls: 0.04309  loss_rpn_loc: 0.1243  time: 0.3539  data_time: 0.0095  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:33 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 8159  total_loss: 1.142  loss_cls: 0.275  loss_box_reg: 0.4631  loss_mask: 0.2799  loss_rpn_cls: 0.03402  loss_rpn_loc: 0.1079  time: 0.3539  data_time: 0.0141  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:40 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 8179  total_loss: 1.256  loss_cls: 0.2903  loss_box_reg: 0.4935  loss_mask: 0.2784  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.1437  time: 0.3539  data_time: 0.0153  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:47 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 8199  total_loss: 1.286  loss_cls: 0.2763  loss_box_reg: 0.523  loss_mask: 0.2943  loss_rpn_cls: 0.05618  loss_rpn_loc: 0.142  time: 0.3538  data_time: 0.0151  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:54 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 8219  total_loss: 1.206  loss_cls: 0.2637  loss_box_reg: 0.5051  loss_mask: 0.2807  loss_rpn_cls: 0.04057  loss_rpn_loc: 0.1106  time: 0.3538  data_time: 0.0251  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:58:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:58:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 19:58:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 19:58:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 19:58:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 19:58:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 19:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1271 s/iter. Eval: 0.0776 s/iter. Total: 0.2053 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1336 s/iter. Eval: 0.1450 s/iter. Total: 0.2795 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 19:59:11 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1368 s/iter. Eval: 0.1599 s/iter. Total: 0.2976 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 19:59:16 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1351 s/iter. Eval: 0.1511 s/iter. Total: 0.2870 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 19:59:21 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1381 s/iter. Eval: 0.1624 s/iter. Total: 0.3013 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 19:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1412 s/iter. Eval: 0.1763 s/iter. Total: 0.3184 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 19:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0008 s/iter. Inference: 0.1396 s/iter. Eval: 0.1717 s/iter. Total: 0.3122 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 19:59:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.407064 (0.305233 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:59:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.138946 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 19:59:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 19:59:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20882345054255158\n",
      "\u001b[32m[02/08 19:59:39 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 8239  total_loss: 1.34  loss_cls: 0.2996  loss_box_reg: 0.5384  loss_mask: 0.2972  loss_rpn_cls: 0.06133  loss_rpn_loc: 0.1683  time: 0.3538  data_time: 0.0190  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:59:45 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 8259  total_loss: 1.238  loss_cls: 0.2571  loss_box_reg: 0.5019  loss_mask: 0.2771  loss_rpn_cls: 0.03474  loss_rpn_loc: 0.1219  time: 0.3538  data_time: 0.0105  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:59:52 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 8279  total_loss: 1.227  loss_cls: 0.2847  loss_box_reg: 0.5104  loss_mask: 0.2825  loss_rpn_cls: 0.04341  loss_rpn_loc: 0.1224  time: 0.3537  data_time: 0.0185  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 19:59:59 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 8299  total_loss: 1.253  loss_cls: 0.2736  loss_box_reg: 0.5101  loss_mask: 0.307  loss_rpn_cls: 0.04357  loss_rpn_loc: 0.1279  time: 0.3537  data_time: 0.0199  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:00:06 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 8319  total_loss: 1.181  loss_cls: 0.2558  loss_box_reg: 0.4951  loss_mask: 0.276  loss_rpn_cls: 0.03068  loss_rpn_loc: 0.1146  time: 0.3537  data_time: 0.0237  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:00:14 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 8339  total_loss: 1.227  loss_cls: 0.2858  loss_box_reg: 0.5059  loss_mask: 0.2902  loss_rpn_cls: 0.04035  loss_rpn_loc: 0.117  time: 0.3537  data_time: 0.0322  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:00:21 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 8359  total_loss: 1.259  loss_cls: 0.2908  loss_box_reg: 0.5102  loss_mask: 0.2798  loss_rpn_cls: 0.0524  loss_rpn_loc: 0.1318  time: 0.3538  data_time: 0.0175  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:00:28 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 8379  total_loss: 1.198  loss_cls: 0.2787  loss_box_reg: 0.485  loss_mask: 0.2884  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.1214  time: 0.3538  data_time: 0.0377  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:00:35 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 8399  total_loss: 1.274  loss_cls: 0.2643  loss_box_reg: 0.5181  loss_mask: 0.2865  loss_rpn_cls: 0.03903  loss_rpn_loc: 0.1319  time: 0.3538  data_time: 0.0260  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:00:42 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 8419  total_loss: 1.393  loss_cls: 0.3134  loss_box_reg: 0.5456  loss_mask: 0.3004  loss_rpn_cls: 0.05478  loss_rpn_loc: 0.1381  time: 0.3538  data_time: 0.0247  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:00:49 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 8439  total_loss: 1.274  loss_cls: 0.2787  loss_box_reg: 0.5086  loss_mask: 0.3048  loss_rpn_cls: 0.05014  loss_rpn_loc: 0.1356  time: 0.3538  data_time: 0.0104  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:00:57 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 8459  total_loss: 1.346  loss_cls: 0.2899  loss_box_reg: 0.5256  loss_mask: 0.2991  loss_rpn_cls: 0.07574  loss_rpn_loc: 0.1491  time: 0.3539  data_time: 0.0736  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:01:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:01:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 20:01:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 20:01:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 20:01:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:01:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 20:01:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1201 s/iter. Eval: 0.0650 s/iter. Total: 0.1857 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/08 20:01:10 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1338 s/iter. Eval: 0.1413 s/iter. Total: 0.2760 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 20:01:15 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.1356 s/iter. Eval: 0.1515 s/iter. Total: 0.2880 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 20:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0008 s/iter. Inference: 0.1326 s/iter. Eval: 0.1395 s/iter. Total: 0.2730 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 20:01:25 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1363 s/iter. Eval: 0.1602 s/iter. Total: 0.2973 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 20:01:30 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0008 s/iter. Inference: 0.1375 s/iter. Eval: 0.1627 s/iter. Total: 0.3010 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/08 20:01:35 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0008 s/iter. Inference: 0.1366 s/iter. Eval: 0.1604 s/iter. Total: 0.2979 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/08 20:01:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.130866 (0.294232 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:01:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.136465 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:01:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 20:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21883867997961726\n",
      "\u001b[32m[02/08 20:01:41 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 8479  total_loss: 1.339  loss_cls: 0.2771  loss_box_reg: 0.5022  loss_mask: 0.291  loss_rpn_cls: 0.05751  loss_rpn_loc: 0.1517  time: 0.3539  data_time: 0.0231  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:01:47 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 8499  total_loss: 1.215  loss_cls: 0.2473  loss_box_reg: 0.5072  loss_mask: 0.287  loss_rpn_cls: 0.03302  loss_rpn_loc: 0.1113  time: 0.3538  data_time: 0.0097  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:01:55 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 8519  total_loss: 1.333  loss_cls: 0.3316  loss_box_reg: 0.5265  loss_mask: 0.2975  loss_rpn_cls: 0.07106  loss_rpn_loc: 0.1518  time: 0.3539  data_time: 0.0486  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:02 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 8539  total_loss: 1.164  loss_cls: 0.2577  loss_box_reg: 0.4762  loss_mask: 0.2806  loss_rpn_cls: 0.04495  loss_rpn_loc: 0.1164  time: 0.3539  data_time: 0.0141  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:09 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 8559  total_loss: 1.296  loss_cls: 0.2948  loss_box_reg: 0.5285  loss_mask: 0.2814  loss_rpn_cls: 0.05403  loss_rpn_loc: 0.1476  time: 0.3539  data_time: 0.0267  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:16 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 8579  total_loss: 1.246  loss_cls: 0.2645  loss_box_reg: 0.5036  loss_mask: 0.2869  loss_rpn_cls: 0.04953  loss_rpn_loc: 0.1312  time: 0.3539  data_time: 0.0445  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:23 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 8599  total_loss: 1.147  loss_cls: 0.2558  loss_box_reg: 0.4816  loss_mask: 0.2787  loss_rpn_cls: 0.03996  loss_rpn_loc: 0.1094  time: 0.3539  data_time: 0.0300  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:30 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 8619  total_loss: 1.129  loss_cls: 0.248  loss_box_reg: 0.4799  loss_mask: 0.275  loss_rpn_cls: 0.04105  loss_rpn_loc: 0.1114  time: 0.3539  data_time: 0.0210  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:38 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 8639  total_loss: 1.342  loss_cls: 0.3086  loss_box_reg: 0.5372  loss_mask: 0.3065  loss_rpn_cls: 0.05116  loss_rpn_loc: 0.1443  time: 0.3539  data_time: 0.0398  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:45 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 8659  total_loss: 1.324  loss_cls: 0.303  loss_box_reg: 0.5337  loss_mask: 0.289  loss_rpn_cls: 0.05291  loss_rpn_loc: 0.1444  time: 0.3539  data_time: 0.0310  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:52 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 8679  total_loss: 1.428  loss_cls: 0.3287  loss_box_reg: 0.5638  loss_mask: 0.306  loss_rpn_cls: 0.06588  loss_rpn_loc: 0.1516  time: 0.3540  data_time: 0.0308  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:02:59 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 8699  total_loss: 1.284  loss_cls: 0.2829  loss_box_reg: 0.5159  loss_mask: 0.2956  loss_rpn_cls: 0.05663  loss_rpn_loc: 0.1334  time: 0.3540  data_time: 0.0156  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:03:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:03:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 20:03:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 20:03:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 20:03:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:03:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 20:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1284 s/iter. Eval: 0.0781 s/iter. Total: 0.2071 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:03:12 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0007 s/iter. Inference: 0.1373 s/iter. Eval: 0.1473 s/iter. Total: 0.2854 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 20:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1367 s/iter. Eval: 0.1562 s/iter. Total: 0.2939 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1352 s/iter. Eval: 0.1532 s/iter. Total: 0.2893 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 20:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1376 s/iter. Eval: 0.1662 s/iter. Total: 0.3046 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 20:03:34 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1404 s/iter. Eval: 0.1788 s/iter. Total: 0.3201 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 20:03:39 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.1393 s/iter. Eval: 0.1763 s/iter. Total: 0.3165 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 20:03:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.813290 (0.308735 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:03:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.138675 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:03:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 20:03:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20992302702436563\n",
      "\u001b[32m[02/08 20:03:44 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 8719  total_loss: 1.25  loss_cls: 0.2813  loss_box_reg: 0.5082  loss_mask: 0.2813  loss_rpn_cls: 0.03331  loss_rpn_loc: 0.1314  time: 0.3539  data_time: 0.0129  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:03:52 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 8739  total_loss: 1.399  loss_cls: 0.3041  loss_box_reg: 0.5296  loss_mask: 0.3041  loss_rpn_cls: 0.0505  loss_rpn_loc: 0.1481  time: 0.3540  data_time: 0.0439  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:03:59 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 8759  total_loss: 1.168  loss_cls: 0.2399  loss_box_reg: 0.5007  loss_mask: 0.2931  loss_rpn_cls: 0.03377  loss_rpn_loc: 0.1307  time: 0.3540  data_time: 0.0118  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:04:08 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 8779  total_loss: 1.336  loss_cls: 0.2897  loss_box_reg: 0.5203  loss_mask: 0.2961  loss_rpn_cls: 0.0569  loss_rpn_loc: 0.1401  time: 0.3542  data_time: 0.0812  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:04:15 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 8799  total_loss: 1.082  loss_cls: 0.2299  loss_box_reg: 0.4607  loss_mask: 0.2711  loss_rpn_cls: 0.03  loss_rpn_loc: 0.1019  time: 0.3541  data_time: 0.0183  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:04:22 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 8819  total_loss: 1.29  loss_cls: 0.2903  loss_box_reg: 0.5157  loss_mask: 0.2944  loss_rpn_cls: 0.06181  loss_rpn_loc: 0.1385  time: 0.3541  data_time: 0.0199  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:04:29 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 8839  total_loss: 1.351  loss_cls: 0.3283  loss_box_reg: 0.4985  loss_mask: 0.2736  loss_rpn_cls: 0.06113  loss_rpn_loc: 0.1534  time: 0.3542  data_time: 0.0400  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:04:37 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 8859  total_loss: 1.34  loss_cls: 0.2974  loss_box_reg: 0.5168  loss_mask: 0.2998  loss_rpn_cls: 0.05932  loss_rpn_loc: 0.1531  time: 0.3543  data_time: 0.0418  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:04:44 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 8879  total_loss: 1.336  loss_cls: 0.2978  loss_box_reg: 0.537  loss_mask: 0.296  loss_rpn_cls: 0.04388  loss_rpn_loc: 0.1378  time: 0.3543  data_time: 0.0227  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:04:51 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 8899  total_loss: 1.224  loss_cls: 0.2792  loss_box_reg: 0.4935  loss_mask: 0.2755  loss_rpn_cls: 0.04795  loss_rpn_loc: 0.1275  time: 0.3543  data_time: 0.0145  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:04:58 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 8919  total_loss: 1.315  loss_cls: 0.2853  loss_box_reg: 0.5174  loss_mask: 0.3005  loss_rpn_cls: 0.0516  loss_rpn_loc: 0.1283  time: 0.3543  data_time: 0.0308  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:05:06 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 8939  total_loss: 1.4  loss_cls: 0.2975  loss_box_reg: 0.5087  loss_mask: 0.298  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.1562  time: 0.3544  data_time: 0.0498  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:05:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:05:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 20:05:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 20:05:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 20:05:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:05:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 20:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1271 s/iter. Eval: 0.0812 s/iter. Total: 0.2089 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1374 s/iter. Eval: 0.1486 s/iter. Total: 0.2867 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 20:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1383 s/iter. Eval: 0.1614 s/iter. Total: 0.3005 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.1373 s/iter. Eval: 0.1556 s/iter. Total: 0.2938 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 20:05:36 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1402 s/iter. Eval: 0.1654 s/iter. Total: 0.3064 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 20:05:41 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1433 s/iter. Eval: 0.1797 s/iter. Total: 0.3239 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 20:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0008 s/iter. Inference: 0.1417 s/iter. Eval: 0.1747 s/iter. Total: 0.3172 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 20:05:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.997315 (0.310322 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:05:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.140971 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:05:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 20:05:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20660114051457576\n",
      "\u001b[32m[02/08 20:05:51 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 8959  total_loss: 1.285  loss_cls: 0.2737  loss_box_reg: 0.5189  loss_mask: 0.3004  loss_rpn_cls: 0.03587  loss_rpn_loc: 0.131  time: 0.3543  data_time: 0.0178  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:05:59 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 8979  total_loss: 1.387  loss_cls: 0.2966  loss_box_reg: 0.5364  loss_mask: 0.3031  loss_rpn_cls: 0.05074  loss_rpn_loc: 0.1553  time: 0.3544  data_time: 0.0258  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:06:06 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 8999  total_loss: 1.389  loss_cls: 0.3102  loss_box_reg: 0.5462  loss_mask: 0.3169  loss_rpn_cls: 0.06308  loss_rpn_loc: 0.1571  time: 0.3544  data_time: 0.0327  lr: 0.00010486  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:06:13 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 9019  total_loss: 1.292  loss_cls: 0.2878  loss_box_reg: 0.5121  loss_mask: 0.3021  loss_rpn_cls: 0.03836  loss_rpn_loc: 0.1404  time: 0.3544  data_time: 0.0188  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:06:20 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 9039  total_loss: 1.245  loss_cls: 0.2763  loss_box_reg: 0.5009  loss_mask: 0.2813  loss_rpn_cls: 0.03033  loss_rpn_loc: 0.1246  time: 0.3544  data_time: 0.0199  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:06:27 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 9059  total_loss: 1.218  loss_cls: 0.2831  loss_box_reg: 0.494  loss_mask: 0.2791  loss_rpn_cls: 0.04588  loss_rpn_loc: 0.12  time: 0.3543  data_time: 0.0083  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:06:33 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 9079  total_loss: 1.238  loss_cls: 0.2755  loss_box_reg: 0.5015  loss_mask: 0.2826  loss_rpn_cls: 0.04511  loss_rpn_loc: 0.1359  time: 0.3543  data_time: 0.0155  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:06:41 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 9099  total_loss: 1.395  loss_cls: 0.3231  loss_box_reg: 0.5649  loss_mask: 0.3172  loss_rpn_cls: 0.06954  loss_rpn_loc: 0.1593  time: 0.3543  data_time: 0.0363  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:06:48 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 9119  total_loss: 1.266  loss_cls: 0.2824  loss_box_reg: 0.4958  loss_mask: 0.2898  loss_rpn_cls: 0.03615  loss_rpn_loc: 0.1279  time: 0.3543  data_time: 0.0175  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:06:55 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 9139  total_loss: 1.283  loss_cls: 0.3018  loss_box_reg: 0.4975  loss_mask: 0.2823  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.1311  time: 0.3543  data_time: 0.0158  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:07:03 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 9159  total_loss: 1.215  loss_cls: 0.2918  loss_box_reg: 0.5102  loss_mask: 0.2979  loss_rpn_cls: 0.05618  loss_rpn_loc: 0.1376  time: 0.3544  data_time: 0.0651  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:07:11 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 9179  total_loss: 1.215  loss_cls: 0.2839  loss_box_reg: 0.5164  loss_mask: 0.2948  loss_rpn_cls: 0.05234  loss_rpn_loc: 0.1332  time: 0.3545  data_time: 0.0605  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:07:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:07:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 20:07:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 20:07:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 20:07:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:07:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 20:07:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1252 s/iter. Eval: 0.0738 s/iter. Total: 0.1996 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 20:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1349 s/iter. Eval: 0.1421 s/iter. Total: 0.2779 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 20:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1366 s/iter. Eval: 0.1567 s/iter. Total: 0.2941 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1354 s/iter. Eval: 0.1487 s/iter. Total: 0.2849 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 20:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1384 s/iter. Eval: 0.1656 s/iter. Total: 0.3048 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 20:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0008 s/iter. Inference: 0.1401 s/iter. Eval: 0.1696 s/iter. Total: 0.3106 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 20:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0008 s/iter. Inference: 0.1392 s/iter. Eval: 0.1668 s/iter. Total: 0.3068 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/08 20:07:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.165551 (0.303151 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:07:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.139177 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:07:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 20:07:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2082117731895739\n",
      "\u001b[32m[02/08 20:07:55 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 9199  total_loss: 1.205  loss_cls: 0.2295  loss_box_reg: 0.4939  loss_mask: 0.2903  loss_rpn_cls: 0.04231  loss_rpn_loc: 0.1281  time: 0.3545  data_time: 0.0158  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:02 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 9219  total_loss: 1.217  loss_cls: 0.2813  loss_box_reg: 0.4988  loss_mask: 0.2889  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.1377  time: 0.3545  data_time: 0.0382  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:09 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9239  total_loss: 1.1  loss_cls: 0.237  loss_box_reg: 0.471  loss_mask: 0.2684  loss_rpn_cls: 0.02782  loss_rpn_loc: 0.1238  time: 0.3544  data_time: 0.0131  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:16 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 9259  total_loss: 1.305  loss_cls: 0.2751  loss_box_reg: 0.5385  loss_mask: 0.2891  loss_rpn_cls: 0.05509  loss_rpn_loc: 0.1305  time: 0.3544  data_time: 0.0119  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:23 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 9279  total_loss: 1.234  loss_cls: 0.2953  loss_box_reg: 0.498  loss_mask: 0.3016  loss_rpn_cls: 0.0489  loss_rpn_loc: 0.1324  time: 0.3544  data_time: 0.0348  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:30 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 9299  total_loss: 1.255  loss_cls: 0.3023  loss_box_reg: 0.5151  loss_mask: 0.2819  loss_rpn_cls: 0.04778  loss_rpn_loc: 0.1221  time: 0.3544  data_time: 0.0180  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:37 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 9319  total_loss: 1.104  loss_cls: 0.2481  loss_box_reg: 0.4746  loss_mask: 0.2847  loss_rpn_cls: 0.03899  loss_rpn_loc: 0.1037  time: 0.3544  data_time: 0.0137  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:45 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 9339  total_loss: 1.29  loss_cls: 0.3  loss_box_reg: 0.5067  loss_mask: 0.3033  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.1437  time: 0.3545  data_time: 0.0628  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:52 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 9359  total_loss: 1.275  loss_cls: 0.3001  loss_box_reg: 0.511  loss_mask: 0.2893  loss_rpn_cls: 0.03963  loss_rpn_loc: 0.1437  time: 0.3544  data_time: 0.0093  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:08:59 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 9379  total_loss: 1.384  loss_cls: 0.3109  loss_box_reg: 0.5148  loss_mask: 0.3086  loss_rpn_cls: 0.07261  loss_rpn_loc: 0.1463  time: 0.3545  data_time: 0.0421  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:09:06 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9399  total_loss: 1.144  loss_cls: 0.225  loss_box_reg: 0.489  loss_mask: 0.2768  loss_rpn_cls: 0.03823  loss_rpn_loc: 0.1018  time: 0.3544  data_time: 0.0141  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:09:13 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 9419  total_loss: 1.375  loss_cls: 0.3214  loss_box_reg: 0.5435  loss_mask: 0.2964  loss_rpn_cls: 0.06669  loss_rpn_loc: 0.1554  time: 0.3544  data_time: 0.0209  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:09:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:09:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 20:09:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 20:09:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 20:09:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:09:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 20:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1215 s/iter. Eval: 0.0743 s/iter. Total: 0.1965 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 20:09:28 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0008 s/iter. Inference: 0.1311 s/iter. Eval: 0.1398 s/iter. Total: 0.2718 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 20:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.1345 s/iter. Eval: 0.1545 s/iter. Total: 0.2899 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:09:38 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.1346 s/iter. Eval: 0.1527 s/iter. Total: 0.2882 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 20:09:43 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.1358 s/iter. Eval: 0.1617 s/iter. Total: 0.2983 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 20:09:48 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0008 s/iter. Inference: 0.1391 s/iter. Eval: 0.1720 s/iter. Total: 0.3120 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 20:09:53 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.1392 s/iter. Eval: 0.1762 s/iter. Total: 0.3162 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 20:09:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.102028 (0.311224 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:09:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.139283 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:09:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 20:09:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2095829080556244\n",
      "\u001b[32m[02/08 20:09:58 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 9439  total_loss: 1.393  loss_cls: 0.2947  loss_box_reg: 0.5239  loss_mask: 0.3019  loss_rpn_cls: 0.05355  loss_rpn_loc: 0.1626  time: 0.3544  data_time: 0.0209  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:10:06 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 9459  total_loss: 1.288  loss_cls: 0.2728  loss_box_reg: 0.5277  loss_mask: 0.293  loss_rpn_cls: 0.05054  loss_rpn_loc: 0.1407  time: 0.3545  data_time: 0.0429  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:10:13 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 9479  total_loss: 1.256  loss_cls: 0.2749  loss_box_reg: 0.5328  loss_mask: 0.2884  loss_rpn_cls: 0.04165  loss_rpn_loc: 0.1391  time: 0.3545  data_time: 0.0329  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:10:21 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 9499  total_loss: 1.331  loss_cls: 0.307  loss_box_reg: 0.5522  loss_mask: 0.2963  loss_rpn_cls: 0.05697  loss_rpn_loc: 0.1629  time: 0.3545  data_time: 0.0273  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:10:27 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 9519  total_loss: 1.157  loss_cls: 0.2483  loss_box_reg: 0.4704  loss_mask: 0.2751  loss_rpn_cls: 0.044  loss_rpn_loc: 0.1164  time: 0.3545  data_time: 0.0152  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:10:35 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9539  total_loss: 1.225  loss_cls: 0.272  loss_box_reg: 0.4906  loss_mask: 0.2966  loss_rpn_cls: 0.05067  loss_rpn_loc: 0.1265  time: 0.3545  data_time: 0.0283  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:10:42 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 9559  total_loss: 1.305  loss_cls: 0.2839  loss_box_reg: 0.5134  loss_mask: 0.2964  loss_rpn_cls: 0.06258  loss_rpn_loc: 0.1456  time: 0.3545  data_time: 0.0219  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:10:48 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 9579  total_loss: 1.106  loss_cls: 0.2302  loss_box_reg: 0.4616  loss_mask: 0.2775  loss_rpn_cls: 0.04418  loss_rpn_loc: 0.1098  time: 0.3544  data_time: 0.0077  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:10:55 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 9599  total_loss: 1.337  loss_cls: 0.2985  loss_box_reg: 0.5281  loss_mask: 0.2981  loss_rpn_cls: 0.05639  loss_rpn_loc: 0.1489  time: 0.3545  data_time: 0.0293  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:11:02 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 9619  total_loss: 1.153  loss_cls: 0.2524  loss_box_reg: 0.4818  loss_mask: 0.284  loss_rpn_cls: 0.02766  loss_rpn_loc: 0.1273  time: 0.3544  data_time: 0.0212  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:11:10 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 9639  total_loss: 1.296  loss_cls: 0.2833  loss_box_reg: 0.5105  loss_mask: 0.2978  loss_rpn_cls: 0.04573  loss_rpn_loc: 0.147  time: 0.3545  data_time: 0.0350  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:11:16 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 9659  total_loss: 1.234  loss_cls: 0.2644  loss_box_reg: 0.5034  loss_mask: 0.2811  loss_rpn_cls: 0.03126  loss_rpn_loc: 0.1194  time: 0.3544  data_time: 0.0177  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:11:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:11:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 20:11:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 20:11:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 20:11:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:11:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 20:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1216 s/iter. Eval: 0.0731 s/iter. Total: 0.1955 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 20:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1321 s/iter. Eval: 0.1355 s/iter. Total: 0.2684 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 20:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1341 s/iter. Eval: 0.1465 s/iter. Total: 0.2815 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 20:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0009 s/iter. Inference: 0.1323 s/iter. Eval: 0.1380 s/iter. Total: 0.2713 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 20:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1362 s/iter. Eval: 0.1574 s/iter. Total: 0.2946 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 20:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0008 s/iter. Inference: 0.1368 s/iter. Eval: 0.1602 s/iter. Total: 0.2979 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/08 20:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.1352 s/iter. Eval: 0.1568 s/iter. Total: 0.2929 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/08 20:12:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.725656 (0.290738 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:12:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.135129 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:12:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 20:12:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2118871028592093\n",
      "\u001b[32m[02/08 20:12:00 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 9679  total_loss: 1.348  loss_cls: 0.3085  loss_box_reg: 0.5275  loss_mask: 0.2973  loss_rpn_cls: 0.04208  loss_rpn_loc: 0.1365  time: 0.3545  data_time: 0.0517  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:12:07 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 9699  total_loss: 1.319  loss_cls: 0.2933  loss_box_reg: 0.5231  loss_mask: 0.2929  loss_rpn_cls: 0.07645  loss_rpn_loc: 0.1491  time: 0.3545  data_time: 0.0268  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:12:14 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 9719  total_loss: 1.045  loss_cls: 0.2026  loss_box_reg: 0.4661  loss_mask: 0.2666  loss_rpn_cls: 0.02624  loss_rpn_loc: 0.09198  time: 0.3545  data_time: 0.0207  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:12:22 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 9739  total_loss: 1.359  loss_cls: 0.3033  loss_box_reg: 0.5116  loss_mask: 0.3018  loss_rpn_cls: 0.04855  loss_rpn_loc: 0.1375  time: 0.3545  data_time: 0.0615  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:12:28 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 9759  total_loss: 1.264  loss_cls: 0.2693  loss_box_reg: 0.5156  loss_mask: 0.2999  loss_rpn_cls: 0.04446  loss_rpn_loc: 0.1259  time: 0.3545  data_time: 0.0172  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:12:35 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 9779  total_loss: 1.19  loss_cls: 0.2566  loss_box_reg: 0.518  loss_mask: 0.2923  loss_rpn_cls: 0.03202  loss_rpn_loc: 0.1146  time: 0.3544  data_time: 0.0089  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:12:42 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 9799  total_loss: 1.376  loss_cls: 0.3054  loss_box_reg: 0.5221  loss_mask: 0.3043  loss_rpn_cls: 0.06469  loss_rpn_loc: 0.1499  time: 0.3544  data_time: 0.0533  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:12:49 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 9819  total_loss: 1.268  loss_cls: 0.2433  loss_box_reg: 0.4934  loss_mask: 0.2952  loss_rpn_cls: 0.05622  loss_rpn_loc: 0.1329  time: 0.3544  data_time: 0.0291  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:12:56 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 9839  total_loss: 1.366  loss_cls: 0.2845  loss_box_reg: 0.5462  loss_mask: 0.2912  loss_rpn_cls: 0.04537  loss_rpn_loc: 0.1543  time: 0.3544  data_time: 0.0230  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:13:03 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 9859  total_loss: 1.233  loss_cls: 0.2867  loss_box_reg: 0.4951  loss_mask: 0.2824  loss_rpn_cls: 0.05394  loss_rpn_loc: 0.1248  time: 0.3544  data_time: 0.0299  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:13:10 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 9879  total_loss: 1.434  loss_cls: 0.2956  loss_box_reg: 0.5421  loss_mask: 0.2926  loss_rpn_cls: 0.05916  loss_rpn_loc: 0.1512  time: 0.3544  data_time: 0.0535  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:13:17 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 9899  total_loss: 1.302  loss_cls: 0.2878  loss_box_reg: 0.5315  loss_mask: 0.3076  loss_rpn_cls: 0.05458  loss_rpn_loc: 0.1364  time: 0.3544  data_time: 0.0236  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:13:25 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 9919  total_loss: 1.222  loss_cls: 0.2784  loss_box_reg: 0.4774  loss_mask: 0.2799  loss_rpn_cls: 0.04926  loss_rpn_loc: 0.1393  time: 0.3544  data_time: 0.0276  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:13:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:13:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 20:13:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 20:13:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 20:13:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:13:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 20:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1256 s/iter. Eval: 0.0767 s/iter. Total: 0.2029 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1337 s/iter. Eval: 0.1411 s/iter. Total: 0.2756 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 20:13:39 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1353 s/iter. Eval: 0.1552 s/iter. Total: 0.2913 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:13:44 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1344 s/iter. Eval: 0.1479 s/iter. Total: 0.2831 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 20:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1378 s/iter. Eval: 0.1648 s/iter. Total: 0.3035 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 20:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0008 s/iter. Inference: 0.1396 s/iter. Eval: 0.1684 s/iter. Total: 0.3088 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 20:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0008 s/iter. Inference: 0.1383 s/iter. Eval: 0.1648 s/iter. Total: 0.3040 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/08 20:14:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.829841 (0.300257 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:14:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.138184 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:14:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 20:14:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21185063620919525\n",
      "\u001b[32m[02/08 20:14:09 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 9939  total_loss: 1.345  loss_cls: 0.3053  loss_box_reg: 0.5268  loss_mask: 0.2792  loss_rpn_cls: 0.06361  loss_rpn_loc: 0.1573  time: 0.3545  data_time: 0.0339  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:14:16 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 9959  total_loss: 1.248  loss_cls: 0.2761  loss_box_reg: 0.5037  loss_mask: 0.2996  loss_rpn_cls: 0.03677  loss_rpn_loc: 0.1329  time: 0.3545  data_time: 0.0214  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:14:23 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 9979  total_loss: 1.342  loss_cls: 0.2931  loss_box_reg: 0.5364  loss_mask: 0.304  loss_rpn_cls: 0.05576  loss_rpn_loc: 0.1566  time: 0.3545  data_time: 0.0172  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:14:30 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.136  loss_cls: 0.24  loss_box_reg: 0.4617  loss_mask: 0.2764  loss_rpn_cls: 0.02773  loss_rpn_loc: 0.0961  time: 0.3544  data_time: 0.0136  lr: 8.3886e-05  max_mem: 4036M\n",
      "\u001b[32m[02/08 20:14:30 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 0:59:03 (0.3544 s / it)\n",
      "\u001b[32m[02/08 20:14:30 d2.engine.hooks]: \u001b[0mTotal training time: 1:26:27 (0:27:23 on hooks)\n",
      "\u001b[32m[02/08 20:14:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:14:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/08 20:14:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 20:14:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 20:14:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 20:14:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 20:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1293 s/iter. Eval: 0.0856 s/iter. Total: 0.2156 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 20:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1341 s/iter. Eval: 0.1444 s/iter. Total: 0.2793 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 20:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1356 s/iter. Eval: 0.1565 s/iter. Total: 0.2929 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 20:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.1339 s/iter. Eval: 0.1457 s/iter. Total: 0.2805 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/08 20:14:55 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1371 s/iter. Eval: 0.1632 s/iter. Total: 0.3012 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 20:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0008 s/iter. Inference: 0.1388 s/iter. Eval: 0.1670 s/iter. Total: 0.3067 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 20:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0008 s/iter. Inference: 0.1380 s/iter. Eval: 0.1637 s/iter. Total: 0.3025 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/08 20:15:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.615525 (0.298410 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:15:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.137699 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 20:15:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 20:15:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2105550384906003\n"
     ]
    }
   ],
   "source": [
    "# No augmentation\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 4000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24], [40], [80], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 3.0]]\n",
    "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.7]\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.75\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.03\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 700\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_10.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f03977-0dcc-414f-863c-8c21062e31ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/08 22:49:48 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/08 22:49:49 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/08 22:49:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/08 22:49:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomContrast(intensity_min=0.95, intensity_max=1.05), RandomBrightness(intensity_min=0.95, intensity_max=1.05), RandomFlip(prob=0.5), RandomFlip(prob=0.5, horizontal=False, vertical=True), ResizeShortestEdge(short_edge_length=(832, 864, 896, 928, 960, 992, 1024), max_size=9999, sample_style='choice')]\n",
      "\u001b[32m[02/08 22:49:53 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/08 22:49:53 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/08 22:49:53 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/08 22:49:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/08 22:49:53 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 22:49:53 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/08 22:49:53 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/08 22:50:11 d2.utils.events]: \u001b[0m eta: 2:09:43  iter: 19  total_loss: 3.498  loss_cls: 1.525  loss_box_reg: 0.5863  loss_mask: 0.6938  loss_rpn_cls: 0.3226  loss_rpn_loc: 0.3108  time: 0.8616  data_time: 0.1723  lr: 9.9905e-06  max_mem: 7132M\n",
      "\u001b[32m[02/08 22:50:29 d2.utils.events]: \u001b[0m eta: 1:55:51  iter: 39  total_loss: 3.123  loss_cls: 1.39  loss_box_reg: 0.4175  loss_mask: 0.6885  loss_rpn_cls: 0.3299  loss_rpn_loc: 0.2339  time: 0.8867  data_time: 0.2375  lr: 1.998e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:50:46 d2.utils.events]: \u001b[0m eta: 1:53:59  iter: 59  total_loss: 2.944  loss_cls: 1.166  loss_box_reg: 0.521  loss_mask: 0.6711  loss_rpn_cls: 0.3053  loss_rpn_loc: 0.2501  time: 0.8589  data_time: 0.1495  lr: 2.997e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:51:03 d2.utils.events]: \u001b[0m eta: 1:55:23  iter: 79  total_loss: 2.723  loss_cls: 0.9494  loss_box_reg: 0.6657  loss_mask: 0.6623  loss_rpn_cls: 0.2553  loss_rpn_loc: 0.2281  time: 0.8608  data_time: 0.1652  lr: 3.9961e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:51:20 d2.utils.events]: \u001b[0m eta: 1:57:48  iter: 99  total_loss: 2.687  loss_cls: 0.8329  loss_box_reg: 0.7985  loss_mask: 0.6303  loss_rpn_cls: 0.2037  loss_rpn_loc: 0.2155  time: 0.8574  data_time: 0.1243  lr: 4.9951e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:51:35 d2.utils.events]: \u001b[0m eta: 1:57:22  iter: 119  total_loss: 2.556  loss_cls: 0.7652  loss_box_reg: 0.8619  loss_mask: 0.5932  loss_rpn_cls: 0.1573  loss_rpn_loc: 0.184  time: 0.8408  data_time: 0.0715  lr: 5.9941e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:51:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 22:51:55 d2.utils.events]: \u001b[0m eta: 1:57:47  iter: 139  total_loss: 2.486  loss_cls: 0.7468  loss_box_reg: 0.8715  loss_mask: 0.5666  loss_rpn_cls: 0.1377  loss_rpn_loc: 0.1713  time: 0.8670  data_time: 0.1967  lr: 6.993e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:52:16 d2.utils.events]: \u001b[0m eta: 1:59:21  iter: 159  total_loss: 2.42  loss_cls: 0.7344  loss_box_reg: 0.8537  loss_mask: 0.5395  loss_rpn_cls: 0.1212  loss_rpn_loc: 0.1698  time: 0.8846  data_time: 0.2445  lr: 7.9921e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:52:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 22:52:37 d2.utils.events]: \u001b[0m eta: 2:00:56  iter: 179  total_loss: 2.375  loss_cls: 0.7108  loss_box_reg: 0.8203  loss_mask: 0.5182  loss_rpn_cls: 0.1499  loss_rpn_loc: 0.1721  time: 0.9077  data_time: 0.2289  lr: 8.991e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:52:53 d2.utils.events]: \u001b[0m eta: 2:00:47  iter: 199  total_loss: 2.232  loss_cls: 0.6836  loss_box_reg: 0.8409  loss_mask: 0.4859  loss_rpn_cls: 0.09633  loss_rpn_loc: 0.1288  time: 0.8967  data_time: 0.0893  lr: 9.9901e-05  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:53:11 d2.utils.events]: \u001b[0m eta: 2:00:20  iter: 219  total_loss: 2.176  loss_cls: 0.6597  loss_box_reg: 0.8068  loss_mask: 0.4526  loss_rpn_cls: 0.09387  loss_rpn_loc: 0.1635  time: 0.8953  data_time: 0.1873  lr: 0.00010989  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:53:27 d2.utils.events]: \u001b[0m eta: 1:58:13  iter: 239  total_loss: 2.004  loss_cls: 0.566  loss_box_reg: 0.8243  loss_mask: 0.4281  loss_rpn_cls: 0.08669  loss_rpn_loc: 0.1343  time: 0.8872  data_time: 0.1218  lr: 0.00011988  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:53:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 22:53:29 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/08 22:53:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 22:53:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 22:53:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 22:53:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 22:53:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 22:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.2292 s/iter. Eval: 0.0054 s/iter. Total: 0.2354 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 22:53:37 d2.evaluation.evaluator]: \u001b[0mInference done 31/121. Dataloading: 0.0009 s/iter. Inference: 0.2366 s/iter. Eval: 0.0103 s/iter. Total: 0.2479 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 22:53:42 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0009 s/iter. Inference: 0.2345 s/iter. Eval: 0.0111 s/iter. Total: 0.2465 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 22:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0009 s/iter. Inference: 0.2337 s/iter. Eval: 0.0110 s/iter. Total: 0.2457 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 22:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0009 s/iter. Inference: 0.2329 s/iter. Eval: 0.0129 s/iter. Total: 0.2467 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/08 22:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0009 s/iter. Inference: 0.2311 s/iter. Eval: 0.0123 s/iter. Total: 0.2444 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/08 22:53:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.381722 (0.244670 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 22:53:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:26 (0.231568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 22:53:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 22:53:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.04845112222671372\n",
      "\u001b[32m[02/08 22:54:12 d2.utils.events]: \u001b[0m eta: 1:58:02  iter: 259  total_loss: 1.975  loss_cls: 0.5466  loss_box_reg: 0.833  loss_mask: 0.3836  loss_rpn_cls: 0.07888  loss_rpn_loc: 0.1415  time: 0.8749  data_time: 0.0391  lr: 0.00012987  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:54:28 d2.utils.events]: \u001b[0m eta: 1:58:09  iter: 279  total_loss: 1.687  loss_cls: 0.3783  loss_box_reg: 0.8007  loss_mask: 0.3431  loss_rpn_cls: 0.08443  loss_rpn_loc: 0.09547  time: 0.8689  data_time: 0.0714  lr: 0.00013986  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:54:45 d2.utils.events]: \u001b[0m eta: 1:58:05  iter: 299  total_loss: 1.894  loss_cls: 0.4695  loss_box_reg: 0.7599  loss_mask: 0.3527  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1557  time: 0.8687  data_time: 0.1488  lr: 0.00014985  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:55:03 d2.utils.events]: \u001b[0m eta: 1:58:27  iter: 319  total_loss: 1.803  loss_cls: 0.5145  loss_box_reg: 0.7302  loss_mask: 0.331  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.1454  time: 0.8698  data_time: 0.1741  lr: 0.00015984  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:55:23 d2.utils.events]: \u001b[0m eta: 1:58:33  iter: 339  total_loss: 1.748  loss_cls: 0.4517  loss_box_reg: 0.7344  loss_mask: 0.3409  loss_rpn_cls: 0.07104  loss_rpn_loc: 0.1264  time: 0.8772  data_time: 0.2611  lr: 0.00016983  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:55:38 d2.utils.events]: \u001b[0m eta: 1:57:12  iter: 359  total_loss: 1.63  loss_cls: 0.4296  loss_box_reg: 0.6808  loss_mask: 0.32  loss_rpn_cls: 0.06776  loss_rpn_loc: 0.1263  time: 0.8709  data_time: 0.0981  lr: 0.00017982  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:55:57 d2.utils.events]: \u001b[0m eta: 1:57:06  iter: 379  total_loss: 1.623  loss_cls: 0.42  loss_box_reg: 0.6798  loss_mask: 0.3282  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.1146  time: 0.8757  data_time: 0.2323  lr: 0.00018981  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:56:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 22:56:20 d2.utils.events]: \u001b[0m eta: 1:57:49  iter: 399  total_loss: 1.841  loss_cls: 0.5172  loss_box_reg: 0.7054  loss_mask: 0.3273  loss_rpn_cls: 0.09664  loss_rpn_loc: 0.152  time: 0.8899  data_time: 0.2894  lr: 0.0001998  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:56:39 d2.utils.events]: \u001b[0m eta: 1:57:53  iter: 419  total_loss: 1.831  loss_cls: 0.5036  loss_box_reg: 0.737  loss_mask: 0.3259  loss_rpn_cls: 0.09309  loss_rpn_loc: 0.1491  time: 0.8927  data_time: 0.2230  lr: 0.00020979  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:56:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 22:57:00 d2.utils.events]: \u001b[0m eta: 1:57:38  iter: 439  total_loss: 1.677  loss_cls: 0.4203  loss_box_reg: 0.6586  loss_mask: 0.3348  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.1379  time: 0.8982  data_time: 0.1668  lr: 0.00021978  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:57:16 d2.utils.events]: \u001b[0m eta: 1:56:31  iter: 459  total_loss: 1.548  loss_cls: 0.4072  loss_box_reg: 0.6478  loss_mask: 0.3134  loss_rpn_cls: 0.05857  loss_rpn_loc: 0.1159  time: 0.8957  data_time: 0.1470  lr: 0.00022977  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:57:35 d2.utils.events]: \u001b[0m eta: 1:56:10  iter: 479  total_loss: 1.664  loss_cls: 0.4048  loss_box_reg: 0.7173  loss_mask: 0.3241  loss_rpn_cls: 0.07553  loss_rpn_loc: 0.1368  time: 0.8968  data_time: 0.2095  lr: 0.00023976  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:57:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 22:57:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 22:57:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 22:57:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 22:57:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 22:57:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 22:57:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1762 s/iter. Eval: 0.0422 s/iter. Total: 0.2192 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 22:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 25/121. Dataloading: 0.0009 s/iter. Inference: 0.1935 s/iter. Eval: 0.1308 s/iter. Total: 0.3252 s/iter. ETA=0:00:31\n",
      "\u001b[32m[02/08 22:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.1950 s/iter. Eval: 0.1286 s/iter. Total: 0.3246 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 22:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 57/121. Dataloading: 0.0009 s/iter. Inference: 0.1921 s/iter. Eval: 0.1295 s/iter. Total: 0.3226 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/08 22:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0009 s/iter. Inference: 0.1923 s/iter. Eval: 0.1392 s/iter. Total: 0.3325 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 22:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0009 s/iter. Inference: 0.1965 s/iter. Eval: 0.1623 s/iter. Total: 0.3597 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 22:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1982 s/iter. Eval: 0.1750 s/iter. Total: 0.3742 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 22:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0009 s/iter. Inference: 0.1966 s/iter. Eval: 0.1720 s/iter. Total: 0.3696 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 22:58:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.156251 (0.363416 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 22:58:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.197054 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 22:58:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 22:58:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2337956472664777\n",
      "\u001b[32m[02/08 22:58:35 d2.utils.events]: \u001b[0m eta: 1:55:32  iter: 499  total_loss: 1.358  loss_cls: 0.3575  loss_box_reg: 0.5811  loss_mask: 0.289  loss_rpn_cls: 0.05069  loss_rpn_loc: 0.1029  time: 0.8919  data_time: 0.0746  lr: 0.00024975  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:58:53 d2.utils.events]: \u001b[0m eta: 1:55:59  iter: 519  total_loss: 1.636  loss_cls: 0.4012  loss_box_reg: 0.6591  loss_mask: 0.33  loss_rpn_cls: 0.06045  loss_rpn_loc: 0.1487  time: 0.8913  data_time: 0.1360  lr: 0.00025974  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:59:11 d2.utils.events]: \u001b[0m eta: 1:56:24  iter: 539  total_loss: 1.532  loss_cls: 0.3864  loss_box_reg: 0.6328  loss_mask: 0.3159  loss_rpn_cls: 0.07585  loss_rpn_loc: 0.1319  time: 0.8927  data_time: 0.1814  lr: 0.00026973  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:59:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 22:59:35 d2.utils.events]: \u001b[0m eta: 1:56:10  iter: 559  total_loss: 1.448  loss_cls: 0.3698  loss_box_reg: 0.6198  loss_mask: 0.3173  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.1129  time: 0.9036  data_time: 0.3122  lr: 0.00027972  max_mem: 9270M\n",
      "\u001b[32m[02/08 22:59:54 d2.utils.events]: \u001b[0m eta: 1:55:58  iter: 579  total_loss: 1.635  loss_cls: 0.4252  loss_box_reg: 0.6313  loss_mask: 0.3304  loss_rpn_cls: 0.06632  loss_rpn_loc: 0.1261  time: 0.9056  data_time: 0.2306  lr: 0.00028971  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:00:12 d2.utils.events]: \u001b[0m eta: 1:55:45  iter: 599  total_loss: 1.59  loss_cls: 0.4035  loss_box_reg: 0.6391  loss_mask: 0.2977  loss_rpn_cls: 0.07622  loss_rpn_loc: 0.129  time: 0.9043  data_time: 0.1294  lr: 0.0002997  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:00:30 d2.utils.events]: \u001b[0m eta: 1:55:33  iter: 619  total_loss: 1.534  loss_cls: 0.4042  loss_box_reg: 0.6054  loss_mask: 0.3126  loss_rpn_cls: 0.0775  loss_rpn_loc: 0.1438  time: 0.9051  data_time: 0.1983  lr: 0.00030969  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:00:46 d2.utils.events]: \u001b[0m eta: 1:55:18  iter: 639  total_loss: 1.524  loss_cls: 0.391  loss_box_reg: 0.6071  loss_mask: 0.3082  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.126  time: 0.9014  data_time: 0.0575  lr: 0.00031968  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:01:06 d2.utils.events]: \u001b[0m eta: 1:55:03  iter: 659  total_loss: 1.501  loss_cls: 0.3802  loss_box_reg: 0.625  loss_mask: 0.3122  loss_rpn_cls: 0.06763  loss_rpn_loc: 0.1176  time: 0.9051  data_time: 0.2913  lr: 0.00032967  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:01:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:01:27 d2.utils.events]: \u001b[0m eta: 1:54:48  iter: 679  total_loss: 1.6  loss_cls: 0.4288  loss_box_reg: 0.6289  loss_mask: 0.3288  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1304  time: 0.9086  data_time: 0.1933  lr: 0.00033966  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:01:42 d2.utils.events]: \u001b[0m eta: 1:54:27  iter: 699  total_loss: 1.416  loss_cls: 0.3571  loss_box_reg: 0.5958  loss_mask: 0.2933  loss_rpn_cls: 0.07421  loss_rpn_loc: 0.08978  time: 0.9041  data_time: 0.0538  lr: 0.00034965  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:01:59 d2.utils.events]: \u001b[0m eta: 1:54:18  iter: 719  total_loss: 1.535  loss_cls: 0.3988  loss_box_reg: 0.6094  loss_mask: 0.3113  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.1439  time: 0.9020  data_time: 0.0835  lr: 0.00035964  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:02:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:02:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:02:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:02:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:02:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:02:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:02:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1553 s/iter. Eval: 0.0477 s/iter. Total: 0.2037 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:02:12 d2.evaluation.evaluator]: \u001b[0mInference done 26/121. Dataloading: 0.0009 s/iter. Inference: 0.1666 s/iter. Eval: 0.1359 s/iter. Total: 0.3034 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/08 23:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0009 s/iter. Inference: 0.1669 s/iter. Eval: 0.1339 s/iter. Total: 0.3017 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 23:02:23 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0009 s/iter. Inference: 0.1678 s/iter. Eval: 0.1464 s/iter. Total: 0.3152 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/08 23:02:28 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0009 s/iter. Inference: 0.1674 s/iter. Eval: 0.1526 s/iter. Total: 0.3211 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 23:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0009 s/iter. Inference: 0.1714 s/iter. Eval: 0.1743 s/iter. Total: 0.3466 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 23:02:39 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0010 s/iter. Inference: 0.1727 s/iter. Eval: 0.1839 s/iter. Total: 0.3577 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 23:02:44 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0010 s/iter. Inference: 0.1707 s/iter. Eval: 0.1700 s/iter. Total: 0.3418 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/08 23:02:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.062877 (0.345370 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:02:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.171911 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:02:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:02:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26611216980818\n",
      "\u001b[32m[02/08 23:02:57 d2.utils.events]: \u001b[0m eta: 1:54:04  iter: 739  total_loss: 1.468  loss_cls: 0.3836  loss_box_reg: 0.605  loss_mask: 0.3009  loss_rpn_cls: 0.06024  loss_rpn_loc: 0.1268  time: 0.8996  data_time: 0.0888  lr: 0.00036963  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:03:16 d2.utils.events]: \u001b[0m eta: 1:53:52  iter: 759  total_loss: 1.539  loss_cls: 0.4014  loss_box_reg: 0.6131  loss_mask: 0.322  loss_rpn_cls: 0.07301  loss_rpn_loc: 0.15  time: 0.9005  data_time: 0.1982  lr: 0.00037962  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:03:33 d2.utils.events]: \u001b[0m eta: 1:53:35  iter: 779  total_loss: 1.384  loss_cls: 0.3637  loss_box_reg: 0.5777  loss_mask: 0.313  loss_rpn_cls: 0.04819  loss_rpn_loc: 0.1131  time: 0.8995  data_time: 0.1464  lr: 0.00038961  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:03:50 d2.utils.events]: \u001b[0m eta: 1:53:17  iter: 799  total_loss: 1.485  loss_cls: 0.3927  loss_box_reg: 0.6043  loss_mask: 0.3084  loss_rpn_cls: 0.04802  loss_rpn_loc: 0.1201  time: 0.8982  data_time: 0.1461  lr: 0.0003996  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:04:05 d2.utils.events]: \u001b[0m eta: 1:53:01  iter: 819  total_loss: 1.553  loss_cls: 0.3836  loss_box_reg: 0.6188  loss_mask: 0.3134  loss_rpn_cls: 0.06931  loss_rpn_loc: 0.1279  time: 0.8952  data_time: 0.1058  lr: 0.00040959  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:04:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:04:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:04:29 d2.utils.events]: \u001b[0m eta: 1:52:49  iter: 839  total_loss: 1.573  loss_cls: 0.4224  loss_box_reg: 0.6066  loss_mask: 0.3236  loss_rpn_cls: 0.06755  loss_rpn_loc: 0.1306  time: 0.9023  data_time: 0.2019  lr: 0.00041958  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:04:46 d2.utils.events]: \u001b[0m eta: 1:52:35  iter: 859  total_loss: 1.472  loss_cls: 0.4006  loss_box_reg: 0.6011  loss_mask: 0.3138  loss_rpn_cls: 0.05  loss_rpn_loc: 0.1266  time: 0.9006  data_time: 0.1129  lr: 0.00042957  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:05:04 d2.utils.events]: \u001b[0m eta: 1:52:17  iter: 879  total_loss: 1.442  loss_cls: 0.3851  loss_box_reg: 0.579  loss_mask: 0.2977  loss_rpn_cls: 0.05082  loss_rpn_loc: 0.1106  time: 0.9010  data_time: 0.2277  lr: 0.00043956  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:05:25 d2.utils.events]: \u001b[0m eta: 1:51:59  iter: 899  total_loss: 1.471  loss_cls: 0.3844  loss_box_reg: 0.5629  loss_mask: 0.303  loss_rpn_cls: 0.06903  loss_rpn_loc: 0.1289  time: 0.9037  data_time: 0.2927  lr: 0.00044955  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:05:42 d2.utils.events]: \u001b[0m eta: 1:51:47  iter: 919  total_loss: 1.599  loss_cls: 0.4336  loss_box_reg: 0.6184  loss_mask: 0.3108  loss_rpn_cls: 0.06993  loss_rpn_loc: 0.1357  time: 0.9028  data_time: 0.1319  lr: 0.00045954  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:06:00 d2.utils.events]: \u001b[0m eta: 1:51:32  iter: 939  total_loss: 1.444  loss_cls: 0.3952  loss_box_reg: 0.574  loss_mask: 0.3012  loss_rpn_cls: 0.05406  loss_rpn_loc: 0.1246  time: 0.9032  data_time: 0.2076  lr: 0.00046953  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:06:18 d2.utils.events]: \u001b[0m eta: 1:51:11  iter: 959  total_loss: 1.415  loss_cls: 0.3767  loss_box_reg: 0.5925  loss_mask: 0.3019  loss_rpn_cls: 0.04148  loss_rpn_loc: 0.106  time: 0.9023  data_time: 0.1724  lr: 0.00047952  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:06:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:06:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:06:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:06:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:06:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:06:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1540 s/iter. Eval: 0.0563 s/iter. Total: 0.2111 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 23:06:37 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0009 s/iter. Inference: 0.1656 s/iter. Eval: 0.1241 s/iter. Total: 0.2907 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/08 23:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1689 s/iter. Eval: 0.1373 s/iter. Total: 0.3072 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 23:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1652 s/iter. Eval: 0.1375 s/iter. Total: 0.3036 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 23:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1668 s/iter. Eval: 0.1461 s/iter. Total: 0.3139 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 23:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1704 s/iter. Eval: 0.1581 s/iter. Total: 0.3295 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 23:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1697 s/iter. Eval: 0.1599 s/iter. Total: 0.3306 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 23:07:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.555500 (0.323754 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:07:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.169019 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:07:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:07:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2741582101229654\n",
      "\u001b[32m[02/08 23:07:18 d2.utils.events]: \u001b[0m eta: 1:50:56  iter: 979  total_loss: 1.544  loss_cls: 0.4024  loss_box_reg: 0.6029  loss_mask: 0.3145  loss_rpn_cls: 0.06665  loss_rpn_loc: 0.1211  time: 0.9044  data_time: 0.2639  lr: 0.00048951  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:07:36 d2.utils.events]: \u001b[0m eta: 1:50:41  iter: 999  total_loss: 1.454  loss_cls: 0.3906  loss_box_reg: 0.585  loss_mask: 0.3011  loss_rpn_cls: 0.05966  loss_rpn_loc: 0.1093  time: 0.9047  data_time: 0.1912  lr: 0.0004995  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:07:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:07:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:08:01 d2.utils.events]: \u001b[0m eta: 1:50:33  iter: 1019  total_loss: 1.595  loss_cls: 0.4234  loss_box_reg: 0.6094  loss_mask: 0.3148  loss_rpn_cls: 0.08327  loss_rpn_loc: 0.1333  time: 0.9117  data_time: 0.2678  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:08:18 d2.utils.events]: \u001b[0m eta: 1:50:19  iter: 1039  total_loss: 1.452  loss_cls: 0.3675  loss_box_reg: 0.5723  loss_mask: 0.3005  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.1218  time: 0.9104  data_time: 0.1711  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:08:36 d2.utils.events]: \u001b[0m eta: 1:50:10  iter: 1059  total_loss: 1.533  loss_cls: 0.4224  loss_box_reg: 0.5764  loss_mask: 0.3232  loss_rpn_cls: 0.08893  loss_rpn_loc: 0.1341  time: 0.9100  data_time: 0.1892  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:08:55 d2.utils.events]: \u001b[0m eta: 1:49:57  iter: 1079  total_loss: 1.476  loss_cls: 0.3947  loss_box_reg: 0.5714  loss_mask: 0.3032  loss_rpn_cls: 0.06436  loss_rpn_loc: 0.1313  time: 0.9106  data_time: 0.2202  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:09:11 d2.utils.events]: \u001b[0m eta: 1:49:39  iter: 1099  total_loss: 1.314  loss_cls: 0.3327  loss_box_reg: 0.5782  loss_mask: 0.2963  loss_rpn_cls: 0.04267  loss_rpn_loc: 0.1092  time: 0.9088  data_time: 0.1184  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:09:28 d2.utils.events]: \u001b[0m eta: 1:49:22  iter: 1119  total_loss: 1.396  loss_cls: 0.3794  loss_box_reg: 0.5841  loss_mask: 0.3067  loss_rpn_cls: 0.04608  loss_rpn_loc: 0.08448  time: 0.9073  data_time: 0.1289  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:09:43 d2.utils.events]: \u001b[0m eta: 1:48:59  iter: 1139  total_loss: 1.404  loss_cls: 0.3788  loss_box_reg: 0.5705  loss_mask: 0.3035  loss_rpn_cls: 0.0544  loss_rpn_loc: 0.1313  time: 0.9049  data_time: 0.1043  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:09:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:10:05 d2.utils.events]: \u001b[0m eta: 1:48:40  iter: 1159  total_loss: 1.518  loss_cls: 0.3982  loss_box_reg: 0.5896  loss_mask: 0.3031  loss_rpn_cls: 0.06381  loss_rpn_loc: 0.1246  time: 0.9081  data_time: 0.2104  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:10:23 d2.utils.events]: \u001b[0m eta: 1:48:20  iter: 1179  total_loss: 1.537  loss_cls: 0.4131  loss_box_reg: 0.6098  loss_mask: 0.3138  loss_rpn_cls: 0.05747  loss_rpn_loc: 0.1307  time: 0.9081  data_time: 0.1851  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:10:37 d2.utils.events]: \u001b[0m eta: 1:47:46  iter: 1199  total_loss: 1.255  loss_cls: 0.336  loss_box_reg: 0.5497  loss_mask: 0.2772  loss_rpn_cls: 0.03582  loss_rpn_loc: 0.07571  time: 0.9047  data_time: 0.0387  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:10:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:10:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:10:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:10:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:10:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:10:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1518 s/iter. Eval: 0.0560 s/iter. Total: 0.2085 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:10:53 d2.evaluation.evaluator]: \u001b[0mInference done 26/121. Dataloading: 0.0009 s/iter. Inference: 0.1671 s/iter. Eval: 0.1308 s/iter. Total: 0.2989 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/08 23:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1704 s/iter. Eval: 0.1363 s/iter. Total: 0.3077 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 23:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0010 s/iter. Inference: 0.1691 s/iter. Eval: 0.1361 s/iter. Total: 0.3062 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/08 23:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0010 s/iter. Inference: 0.1709 s/iter. Eval: 0.1433 s/iter. Total: 0.3153 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 23:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0010 s/iter. Inference: 0.1732 s/iter. Eval: 0.1510 s/iter. Total: 0.3252 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 23:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0010 s/iter. Inference: 0.1716 s/iter. Eval: 0.1542 s/iter. Total: 0.3269 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 23:11:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.248722 (0.321110 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:11:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.170714 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:11:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:11:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26781003139155607\n",
      "\u001b[32m[02/08 23:11:32 d2.utils.events]: \u001b[0m eta: 1:47:29  iter: 1219  total_loss: 1.418  loss_cls: 0.3404  loss_box_reg: 0.5514  loss_mask: 0.3046  loss_rpn_cls: 0.04437  loss_rpn_loc: 0.115  time: 0.9025  data_time: 0.1003  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:11:55 d2.utils.events]: \u001b[0m eta: 1:47:36  iter: 1239  total_loss: 1.525  loss_cls: 0.4149  loss_box_reg: 0.6046  loss_mask: 0.3113  loss_rpn_cls: 0.0681  loss_rpn_loc: 0.1361  time: 0.9066  data_time: 0.3973  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:12:16 d2.utils.events]: \u001b[0m eta: 1:47:17  iter: 1259  total_loss: 1.552  loss_cls: 0.4309  loss_box_reg: 0.5986  loss_mask: 0.3117  loss_rpn_cls: 0.07308  loss_rpn_loc: 0.1292  time: 0.9084  data_time: 0.3198  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:12:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:12:35 d2.utils.events]: \u001b[0m eta: 1:46:55  iter: 1279  total_loss: 1.535  loss_cls: 0.3939  loss_box_reg: 0.6065  loss_mask: 0.2951  loss_rpn_cls: 0.05732  loss_rpn_loc: 0.1294  time: 0.9090  data_time: 0.1621  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:12:49 d2.utils.events]: \u001b[0m eta: 1:46:19  iter: 1299  total_loss: 1.447  loss_cls: 0.3712  loss_box_reg: 0.5787  loss_mask: 0.3082  loss_rpn_cls: 0.05845  loss_rpn_loc: 0.1123  time: 0.9062  data_time: 0.0697  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:12:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:13:08 d2.utils.events]: \u001b[0m eta: 1:45:52  iter: 1319  total_loss: 1.395  loss_cls: 0.3708  loss_box_reg: 0.5839  loss_mask: 0.3243  loss_rpn_cls: 0.04644  loss_rpn_loc: 0.1023  time: 0.9067  data_time: 0.1724  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:13:24 d2.utils.events]: \u001b[0m eta: 1:45:31  iter: 1339  total_loss: 1.433  loss_cls: 0.3616  loss_box_reg: 0.6018  loss_mask: 0.2992  loss_rpn_cls: 0.04504  loss_rpn_loc: 0.1169  time: 0.9048  data_time: 0.0950  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:13:41 d2.utils.events]: \u001b[0m eta: 1:45:26  iter: 1359  total_loss: 1.418  loss_cls: 0.3864  loss_box_reg: 0.562  loss_mask: 0.2888  loss_rpn_cls: 0.05767  loss_rpn_loc: 0.1166  time: 0.9046  data_time: 0.1882  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:13:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:14:03 d2.utils.events]: \u001b[0m eta: 1:45:12  iter: 1379  total_loss: 1.398  loss_cls: 0.3728  loss_box_reg: 0.5734  loss_mask: 0.2973  loss_rpn_cls: 0.05481  loss_rpn_loc: 0.1142  time: 0.9073  data_time: 0.2467  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:14:19 d2.utils.events]: \u001b[0m eta: 1:44:54  iter: 1399  total_loss: 1.396  loss_cls: 0.365  loss_box_reg: 0.5769  loss_mask: 0.2853  loss_rpn_cls: 0.0378  loss_rpn_loc: 0.1191  time: 0.9058  data_time: 0.0693  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:14:37 d2.utils.events]: \u001b[0m eta: 1:44:36  iter: 1419  total_loss: 1.477  loss_cls: 0.3812  loss_box_reg: 0.5798  loss_mask: 0.2947  loss_rpn_cls: 0.04324  loss_rpn_loc: 0.1212  time: 0.9058  data_time: 0.1893  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:14:53 d2.utils.events]: \u001b[0m eta: 1:44:18  iter: 1439  total_loss: 1.428  loss_cls: 0.3541  loss_box_reg: 0.5785  loss_mask: 0.2966  loss_rpn_cls: 0.04535  loss_rpn_loc: 0.1082  time: 0.9043  data_time: 0.1245  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:15:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:15:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:15:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:15:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:15:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:15:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:15:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1623 s/iter. Eval: 0.0631 s/iter. Total: 0.2262 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 23:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 26/121. Dataloading: 0.0009 s/iter. Inference: 0.1683 s/iter. Eval: 0.1466 s/iter. Total: 0.3159 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/08 23:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0009 s/iter. Inference: 0.1686 s/iter. Eval: 0.1410 s/iter. Total: 0.3106 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/08 23:15:24 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0009 s/iter. Inference: 0.1692 s/iter. Eval: 0.1554 s/iter. Total: 0.3257 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/08 23:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0009 s/iter. Inference: 0.1689 s/iter. Eval: 0.1615 s/iter. Total: 0.3314 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/08 23:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0009 s/iter. Inference: 0.1720 s/iter. Eval: 0.1845 s/iter. Total: 0.3574 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 23:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0009 s/iter. Inference: 0.1747 s/iter. Eval: 0.1926 s/iter. Total: 0.3683 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 23:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0009 s/iter. Inference: 0.1733 s/iter. Eval: 0.1800 s/iter. Total: 0.3544 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/08 23:15:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.421649 (0.357083 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:15:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.173890 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:15:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:15:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2672918775772136\n",
      "\u001b[32m[02/08 23:15:55 d2.utils.events]: \u001b[0m eta: 1:44:06  iter: 1459  total_loss: 1.386  loss_cls: 0.351  loss_box_reg: 0.5642  loss_mask: 0.2968  loss_rpn_cls: 0.0588  loss_rpn_loc: 0.1104  time: 0.9041  data_time: 0.1844  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:16:11 d2.utils.events]: \u001b[0m eta: 1:43:58  iter: 1479  total_loss: 1.455  loss_cls: 0.3865  loss_box_reg: 0.5964  loss_mask: 0.3236  loss_rpn_cls: 0.04976  loss_rpn_loc: 0.1216  time: 0.9028  data_time: 0.0894  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:16:32 d2.utils.events]: \u001b[0m eta: 1:44:06  iter: 1499  total_loss: 1.432  loss_cls: 0.3924  loss_box_reg: 0.5888  loss_mask: 0.2978  loss_rpn_cls: 0.05152  loss_rpn_loc: 0.1301  time: 0.9050  data_time: 0.2995  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:16:48 d2.utils.events]: \u001b[0m eta: 1:43:26  iter: 1519  total_loss: 1.311  loss_cls: 0.3514  loss_box_reg: 0.5634  loss_mask: 0.292  loss_rpn_cls: 0.04621  loss_rpn_loc: 0.07817  time: 0.9035  data_time: 0.0974  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:17:06 d2.utils.events]: \u001b[0m eta: 1:43:07  iter: 1539  total_loss: 1.416  loss_cls: 0.3625  loss_box_reg: 0.5713  loss_mask: 0.2969  loss_rpn_cls: 0.04617  loss_rpn_loc: 0.1171  time: 0.9034  data_time: 0.1792  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:17:23 d2.utils.events]: \u001b[0m eta: 1:42:54  iter: 1559  total_loss: 1.355  loss_cls: 0.3629  loss_box_reg: 0.5744  loss_mask: 0.3104  loss_rpn_cls: 0.04476  loss_rpn_loc: 0.1138  time: 0.9029  data_time: 0.1364  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:17:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:17:47 d2.utils.events]: \u001b[0m eta: 1:42:38  iter: 1579  total_loss: 1.3  loss_cls: 0.3458  loss_box_reg: 0.5584  loss_mask: 0.2932  loss_rpn_cls: 0.03273  loss_rpn_loc: 0.09084  time: 0.9066  data_time: 0.3468  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:17:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:18:10 d2.utils.events]: \u001b[0m eta: 1:42:24  iter: 1599  total_loss: 1.461  loss_cls: 0.4034  loss_box_reg: 0.6017  loss_mask: 0.3193  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.1312  time: 0.9094  data_time: 0.3633  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:18:27 d2.utils.events]: \u001b[0m eta: 1:42:02  iter: 1619  total_loss: 1.407  loss_cls: 0.3658  loss_box_reg: 0.5595  loss_mask: 0.3097  loss_rpn_cls: 0.04158  loss_rpn_loc: 0.1182  time: 0.9085  data_time: 0.1484  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:18:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:18:47 d2.utils.events]: \u001b[0m eta: 1:41:40  iter: 1639  total_loss: 1.503  loss_cls: 0.3775  loss_box_reg: 0.5948  loss_mask: 0.2934  loss_rpn_cls: 0.0632  loss_rpn_loc: 0.1207  time: 0.9096  data_time: 0.2104  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:19:06 d2.utils.events]: \u001b[0m eta: 1:41:33  iter: 1659  total_loss: 1.527  loss_cls: 0.4342  loss_box_reg: 0.6006  loss_mask: 0.308  loss_rpn_cls: 0.06939  loss_rpn_loc: 0.1275  time: 0.9101  data_time: 0.2052  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:19:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:19:27 d2.utils.events]: \u001b[0m eta: 1:41:13  iter: 1679  total_loss: 1.513  loss_cls: 0.4076  loss_box_reg: 0.6093  loss_mask: 0.3144  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.1179  time: 0.9122  data_time: 0.2237  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:19:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:19:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:19:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:19:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:19:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:19:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1406 s/iter. Eval: 0.0516 s/iter. Total: 0.1930 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 23:19:47 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1582 s/iter. Eval: 0.1102 s/iter. Total: 0.2694 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 23:19:52 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1262 s/iter. Total: 0.2873 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1569 s/iter. Eval: 0.1283 s/iter. Total: 0.2862 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 23:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1583 s/iter. Eval: 0.1428 s/iter. Total: 0.3021 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 23:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0009 s/iter. Inference: 0.1605 s/iter. Eval: 0.1506 s/iter. Total: 0.3121 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/08 23:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0009 s/iter. Inference: 0.1588 s/iter. Eval: 0.1468 s/iter. Total: 0.3066 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 23:20:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.275113 (0.304096 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:20:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159471 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:20:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:20:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2894213750856096\n",
      "\u001b[32m[02/08 23:20:21 d2.utils.events]: \u001b[0m eta: 1:41:07  iter: 1699  total_loss: 1.369  loss_cls: 0.3587  loss_box_reg: 0.5159  loss_mask: 0.2876  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.1259  time: 0.9112  data_time: 0.0848  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:20:40 d2.utils.events]: \u001b[0m eta: 1:40:41  iter: 1719  total_loss: 1.44  loss_cls: 0.3724  loss_box_reg: 0.5834  loss_mask: 0.3197  loss_rpn_cls: 0.05534  loss_rpn_loc: 0.1264  time: 0.9114  data_time: 0.1916  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:20:56 d2.utils.events]: \u001b[0m eta: 1:40:18  iter: 1739  total_loss: 1.299  loss_cls: 0.3628  loss_box_reg: 0.5499  loss_mask: 0.2834  loss_rpn_cls: 0.04246  loss_rpn_loc: 0.08596  time: 0.9103  data_time: 0.1164  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:21:13 d2.utils.events]: \u001b[0m eta: 1:39:46  iter: 1759  total_loss: 1.416  loss_cls: 0.3636  loss_box_reg: 0.5856  loss_mask: 0.3116  loss_rpn_cls: 0.04796  loss_rpn_loc: 0.1083  time: 0.9096  data_time: 0.1576  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:21:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:21:35 d2.utils.events]: \u001b[0m eta: 1:39:26  iter: 1779  total_loss: 1.407  loss_cls: 0.3735  loss_box_reg: 0.5976  loss_mask: 0.302  loss_rpn_cls: 0.0565  loss_rpn_loc: 0.1206  time: 0.9118  data_time: 0.2601  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:21:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:21:58 d2.utils.events]: \u001b[0m eta: 1:39:34  iter: 1799  total_loss: 1.467  loss_cls: 0.3848  loss_box_reg: 0.5791  loss_mask: 0.3011  loss_rpn_cls: 0.05511  loss_rpn_loc: 0.1168  time: 0.9144  data_time: 0.2567  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:22:13 d2.utils.events]: \u001b[0m eta: 1:39:21  iter: 1819  total_loss: 1.425  loss_cls: 0.37  loss_box_reg: 0.5687  loss_mask: 0.2974  loss_rpn_cls: 0.04711  loss_rpn_loc: 0.09122  time: 0.9123  data_time: 0.0246  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:22:28 d2.utils.events]: \u001b[0m eta: 1:38:55  iter: 1839  total_loss: 1.415  loss_cls: 0.3782  loss_box_reg: 0.5783  loss_mask: 0.3123  loss_rpn_cls: 0.04789  loss_rpn_loc: 0.108  time: 0.9109  data_time: 0.0770  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:22:43 d2.utils.events]: \u001b[0m eta: 1:38:30  iter: 1859  total_loss: 1.343  loss_cls: 0.3539  loss_box_reg: 0.5548  loss_mask: 0.2956  loss_rpn_cls: 0.03557  loss_rpn_loc: 0.1042  time: 0.9090  data_time: 0.0238  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:23:07 d2.utils.events]: \u001b[0m eta: 1:38:40  iter: 1879  total_loss: 1.412  loss_cls: 0.3753  loss_box_reg: 0.5687  loss_mask: 0.2932  loss_rpn_cls: 0.05753  loss_rpn_loc: 0.1213  time: 0.9119  data_time: 0.3641  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:23:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:23:29 d2.utils.events]: \u001b[0m eta: 1:38:42  iter: 1899  total_loss: 1.39  loss_cls: 0.369  loss_box_reg: 0.5569  loss_mask: 0.2901  loss_rpn_cls: 0.04658  loss_rpn_loc: 0.1165  time: 0.9139  data_time: 0.2730  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:23:51 d2.utils.events]: \u001b[0m eta: 1:38:27  iter: 1919  total_loss: 1.4  loss_cls: 0.3609  loss_box_reg: 0.5494  loss_mask: 0.3008  loss_rpn_cls: 0.05618  loss_rpn_loc: 0.1164  time: 0.9159  data_time: 0.3600  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:24:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:24:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:24:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:24:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:24:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:24:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:24:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1482 s/iter. Eval: 0.0584 s/iter. Total: 0.2073 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:24:10 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0009 s/iter. Inference: 0.1589 s/iter. Eval: 0.1242 s/iter. Total: 0.2840 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/08 23:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1614 s/iter. Eval: 0.1355 s/iter. Total: 0.2979 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1328 s/iter. Total: 0.2934 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 23:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0009 s/iter. Inference: 0.1619 s/iter. Eval: 0.1446 s/iter. Total: 0.3076 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 23:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0009 s/iter. Inference: 0.1644 s/iter. Eval: 0.1565 s/iter. Total: 0.3219 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 23:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0009 s/iter. Inference: 0.1648 s/iter. Eval: 0.1613 s/iter. Total: 0.3271 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 23:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0009 s/iter. Inference: 0.1636 s/iter. Eval: 0.1563 s/iter. Total: 0.3209 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 23:24:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.266251 (0.321261 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:24:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.163563 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:24:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:24:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2862914191782325\n",
      "\u001b[32m[02/08 23:24:44 d2.utils.events]: \u001b[0m eta: 1:37:57  iter: 1939  total_loss: 1.283  loss_cls: 0.3205  loss_box_reg: 0.556  loss_mask: 0.2764  loss_rpn_cls: 0.0233  loss_rpn_loc: 0.06841  time: 0.9135  data_time: 0.0239  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:25:02 d2.utils.events]: \u001b[0m eta: 1:37:46  iter: 1959  total_loss: 1.355  loss_cls: 0.3567  loss_box_reg: 0.5584  loss_mask: 0.2987  loss_rpn_cls: 0.04893  loss_rpn_loc: 0.1079  time: 0.9134  data_time: 0.2144  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:25:19 d2.utils.events]: \u001b[0m eta: 1:37:31  iter: 1979  total_loss: 1.296  loss_cls: 0.3359  loss_box_reg: 0.5361  loss_mask: 0.292  loss_rpn_cls: 0.03685  loss_rpn_loc: 0.1008  time: 0.9129  data_time: 0.1544  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:25:36 d2.utils.events]: \u001b[0m eta: 1:37:16  iter: 1999  total_loss: 1.3  loss_cls: 0.3331  loss_box_reg: 0.544  loss_mask: 0.2777  loss_rpn_cls: 0.0388  loss_rpn_loc: 0.09453  time: 0.9121  data_time: 0.1383  lr: 0.0005  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:25:54 d2.utils.events]: \u001b[0m eta: 1:36:58  iter: 2019  total_loss: 1.357  loss_cls: 0.3676  loss_box_reg: 0.5662  loss_mask: 0.2979  loss_rpn_cls: 0.04524  loss_rpn_loc: 0.1045  time: 0.9121  data_time: 0.1709  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:26:12 d2.utils.events]: \u001b[0m eta: 1:36:47  iter: 2039  total_loss: 1.461  loss_cls: 0.4054  loss_box_reg: 0.5753  loss_mask: 0.2977  loss_rpn_cls: 0.05367  loss_rpn_loc: 0.1179  time: 0.9119  data_time: 0.1684  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:26:30 d2.utils.events]: \u001b[0m eta: 1:36:25  iter: 2059  total_loss: 1.291  loss_cls: 0.3396  loss_box_reg: 0.546  loss_mask: 0.3163  loss_rpn_cls: 0.0376  loss_rpn_loc: 0.09416  time: 0.9116  data_time: 0.1824  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:26:47 d2.utils.events]: \u001b[0m eta: 1:36:07  iter: 2079  total_loss: 1.387  loss_cls: 0.3663  loss_box_reg: 0.5803  loss_mask: 0.3029  loss_rpn_cls: 0.05166  loss_rpn_loc: 0.1184  time: 0.9112  data_time: 0.1736  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:27:08 d2.utils.events]: \u001b[0m eta: 1:35:56  iter: 2099  total_loss: 1.422  loss_cls: 0.374  loss_box_reg: 0.5551  loss_mask: 0.2946  loss_rpn_cls: 0.05372  loss_rpn_loc: 0.1157  time: 0.9126  data_time: 0.3392  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:27:26 d2.utils.events]: \u001b[0m eta: 1:35:50  iter: 2119  total_loss: 1.48  loss_cls: 0.3866  loss_box_reg: 0.5704  loss_mask: 0.3069  loss_rpn_cls: 0.0568  loss_rpn_loc: 0.1192  time: 0.9125  data_time: 0.1817  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:27:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:27:47 d2.utils.events]: \u001b[0m eta: 1:35:40  iter: 2139  total_loss: 1.272  loss_cls: 0.3338  loss_box_reg: 0.5513  loss_mask: 0.3019  loss_rpn_cls: 0.03453  loss_rpn_loc: 0.09888  time: 0.9136  data_time: 0.2410  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:27:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:28:08 d2.utils.events]: \u001b[0m eta: 1:35:26  iter: 2159  total_loss: 1.473  loss_cls: 0.3624  loss_box_reg: 0.5705  loss_mask: 0.3007  loss_rpn_cls: 0.04545  loss_rpn_loc: 0.1196  time: 0.9150  data_time: 0.2370  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:28:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:28:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:28:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:28:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:28:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:28:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1514 s/iter. Eval: 0.0424 s/iter. Total: 0.1946 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 23:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1557 s/iter. Eval: 0.1194 s/iter. Total: 0.2760 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 23:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1625 s/iter. Eval: 0.1375 s/iter. Total: 0.3009 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1596 s/iter. Eval: 0.1294 s/iter. Total: 0.2899 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 23:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1464 s/iter. Total: 0.3082 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 23:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1639 s/iter. Eval: 0.1556 s/iter. Total: 0.3205 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 23:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0009 s/iter. Inference: 0.1622 s/iter. Eval: 0.1514 s/iter. Total: 0.3146 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 23:29:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.050365 (0.310779 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:29:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.162443 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:29:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:29:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.28452155313510064\n",
      "\u001b[32m[02/08 23:29:05 d2.utils.events]: \u001b[0m eta: 1:35:08  iter: 2179  total_loss: 1.429  loss_cls: 0.3719  loss_box_reg: 0.5568  loss_mask: 0.3041  loss_rpn_cls: 0.05653  loss_rpn_loc: 0.1106  time: 0.9150  data_time: 0.1940  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:29:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:29:26 d2.utils.events]: \u001b[0m eta: 1:35:10  iter: 2199  total_loss: 1.422  loss_cls: 0.3841  loss_box_reg: 0.559  loss_mask: 0.2994  loss_rpn_cls: 0.06097  loss_rpn_loc: 0.134  time: 0.9162  data_time: 0.1993  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:29:40 d2.utils.events]: \u001b[0m eta: 1:34:52  iter: 2219  total_loss: 1.28  loss_cls: 0.3147  loss_box_reg: 0.5504  loss_mask: 0.2921  loss_rpn_cls: 0.03721  loss_rpn_loc: 0.07387  time: 0.9147  data_time: 0.0915  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:29:58 d2.utils.events]: \u001b[0m eta: 1:34:27  iter: 2239  total_loss: 1.326  loss_cls: 0.3433  loss_box_reg: 0.55  loss_mask: 0.3007  loss_rpn_cls: 0.05409  loss_rpn_loc: 0.1133  time: 0.9142  data_time: 0.1773  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:30:17 d2.utils.events]: \u001b[0m eta: 1:34:14  iter: 2259  total_loss: 1.424  loss_cls: 0.3658  loss_box_reg: 0.5682  loss_mask: 0.2986  loss_rpn_cls: 0.04683  loss_rpn_loc: 0.1348  time: 0.9145  data_time: 0.2433  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:30:32 d2.utils.events]: \u001b[0m eta: 1:34:03  iter: 2279  total_loss: 1.361  loss_cls: 0.3396  loss_box_reg: 0.5623  loss_mask: 0.2987  loss_rpn_cls: 0.03376  loss_rpn_loc: 0.1079  time: 0.9133  data_time: 0.0780  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:30:50 d2.utils.events]: \u001b[0m eta: 1:34:13  iter: 2299  total_loss: 1.36  loss_cls: 0.3657  loss_box_reg: 0.5518  loss_mask: 0.2965  loss_rpn_cls: 0.04518  loss_rpn_loc: 0.1179  time: 0.9132  data_time: 0.1526  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:31:10 d2.utils.events]: \u001b[0m eta: 1:34:13  iter: 2319  total_loss: 1.508  loss_cls: 0.3929  loss_box_reg: 0.5911  loss_mask: 0.3205  loss_rpn_cls: 0.04777  loss_rpn_loc: 0.1183  time: 0.9139  data_time: 0.2175  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:31:28 d2.utils.events]: \u001b[0m eta: 1:34:03  iter: 2339  total_loss: 1.367  loss_cls: 0.3626  loss_box_reg: 0.538  loss_mask: 0.286  loss_rpn_cls: 0.04168  loss_rpn_loc: 0.09954  time: 0.9136  data_time: 0.1864  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:31:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:31:48 d2.utils.events]: \u001b[0m eta: 1:33:45  iter: 2359  total_loss: 1.309  loss_cls: 0.3349  loss_box_reg: 0.5333  loss_mask: 0.2968  loss_rpn_cls: 0.05767  loss_rpn_loc: 0.09841  time: 0.9146  data_time: 0.1816  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:32:07 d2.utils.events]: \u001b[0m eta: 1:33:29  iter: 2379  total_loss: 1.31  loss_cls: 0.3458  loss_box_reg: 0.5339  loss_mask: 0.2931  loss_rpn_cls: 0.0336  loss_rpn_loc: 0.1056  time: 0.9148  data_time: 0.1822  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:32:23 d2.utils.events]: \u001b[0m eta: 1:33:15  iter: 2399  total_loss: 1.344  loss_cls: 0.3486  loss_box_reg: 0.5649  loss_mask: 0.3004  loss_rpn_cls: 0.03611  loss_rpn_loc: 0.08841  time: 0.9137  data_time: 0.0647  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:32:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:32:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:32:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:32:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:32:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:32:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1552 s/iter. Eval: 0.0572 s/iter. Total: 0.2132 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 23:32:50 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0009 s/iter. Inference: 0.1593 s/iter. Eval: 0.1271 s/iter. Total: 0.2874 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/08 23:32:55 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1636 s/iter. Eval: 0.1374 s/iter. Total: 0.3019 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/08 23:33:00 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0009 s/iter. Inference: 0.1629 s/iter. Eval: 0.1364 s/iter. Total: 0.3002 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/08 23:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0009 s/iter. Inference: 0.1650 s/iter. Eval: 0.1481 s/iter. Total: 0.3141 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/08 23:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0009 s/iter. Inference: 0.1703 s/iter. Eval: 0.1632 s/iter. Total: 0.3345 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/08 23:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0009 s/iter. Inference: 0.1707 s/iter. Eval: 0.1677 s/iter. Total: 0.3395 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/08 23:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0009 s/iter. Inference: 0.1703 s/iter. Eval: 0.1617 s/iter. Total: 0.3331 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 23:33:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.883997 (0.335207 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:33:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.170819 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:33:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:33:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2775465514965262\n",
      "\u001b[32m[02/08 23:33:22 d2.utils.events]: \u001b[0m eta: 1:33:01  iter: 2419  total_loss: 1.461  loss_cls: 0.3774  loss_box_reg: 0.5898  loss_mask: 0.3042  loss_rpn_cls: 0.06177  loss_rpn_loc: 0.1189  time: 0.9137  data_time: 0.1926  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:33:41 d2.utils.events]: \u001b[0m eta: 1:32:58  iter: 2439  total_loss: 1.452  loss_cls: 0.3707  loss_box_reg: 0.5805  loss_mask: 0.3172  loss_rpn_cls: 0.05566  loss_rpn_loc: 0.1112  time: 0.9137  data_time: 0.1660  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:33:56 d2.utils.events]: \u001b[0m eta: 1:32:37  iter: 2459  total_loss: 1.157  loss_cls: 0.284  loss_box_reg: 0.5211  loss_mask: 0.2792  loss_rpn_cls: 0.0227  loss_rpn_loc: 0.06049  time: 0.9127  data_time: 0.0908  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:34:13 d2.utils.events]: \u001b[0m eta: 1:32:24  iter: 2479  total_loss: 1.484  loss_cls: 0.3712  loss_box_reg: 0.5872  loss_mask: 0.319  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.1126  time: 0.9119  data_time: 0.0985  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:34:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:34:31 d2.utils.events]: \u001b[0m eta: 1:31:53  iter: 2499  total_loss: 1.402  loss_cls: 0.3676  loss_box_reg: 0.5847  loss_mask: 0.2998  loss_rpn_cls: 0.04434  loss_rpn_loc: 0.1097  time: 0.9121  data_time: 0.1415  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:34:46 d2.utils.events]: \u001b[0m eta: 1:31:47  iter: 2519  total_loss: 1.286  loss_cls: 0.3507  loss_box_reg: 0.5386  loss_mask: 0.2762  loss_rpn_cls: 0.02767  loss_rpn_loc: 0.09688  time: 0.9107  data_time: 0.0269  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:35:06 d2.utils.events]: \u001b[0m eta: 1:31:40  iter: 2539  total_loss: 1.468  loss_cls: 0.4029  loss_box_reg: 0.5774  loss_mask: 0.3055  loss_rpn_cls: 0.05476  loss_rpn_loc: 0.1223  time: 0.9112  data_time: 0.2147  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:35:26 d2.utils.events]: \u001b[0m eta: 1:31:31  iter: 2559  total_loss: 1.409  loss_cls: 0.3793  loss_box_reg: 0.5697  loss_mask: 0.3137  loss_rpn_cls: 0.05557  loss_rpn_loc: 0.1225  time: 0.9120  data_time: 0.2410  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:35:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:35:47 d2.utils.events]: \u001b[0m eta: 1:31:17  iter: 2579  total_loss: 1.372  loss_cls: 0.382  loss_box_reg: 0.5555  loss_mask: 0.2872  loss_rpn_cls: 0.04455  loss_rpn_loc: 0.1216  time: 0.9132  data_time: 0.2378  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:36:06 d2.utils.events]: \u001b[0m eta: 1:31:00  iter: 2599  total_loss: 1.371  loss_cls: 0.3569  loss_box_reg: 0.5634  loss_mask: 0.3054  loss_rpn_cls: 0.03639  loss_rpn_loc: 0.09398  time: 0.9133  data_time: 0.2065  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:36:24 d2.utils.events]: \u001b[0m eta: 1:30:49  iter: 2619  total_loss: 1.376  loss_cls: 0.3679  loss_box_reg: 0.5394  loss_mask: 0.2779  loss_rpn_cls: 0.04735  loss_rpn_loc: 0.1106  time: 0.9131  data_time: 0.1971  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:36:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:36:45 d2.utils.events]: \u001b[0m eta: 1:30:36  iter: 2639  total_loss: 1.51  loss_cls: 0.3974  loss_box_reg: 0.5878  loss_mask: 0.2991  loss_rpn_cls: 0.05462  loss_rpn_loc: 0.1223  time: 0.9145  data_time: 0.2776  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:37:02 d2.utils.events]: \u001b[0m eta: 1:30:18  iter: 2659  total_loss: 1.379  loss_cls: 0.36  loss_box_reg: 0.5621  loss_mask: 0.2975  loss_rpn_cls: 0.03794  loss_rpn_loc: 0.1114  time: 0.9140  data_time: 0.1498  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:37:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:37:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:37:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:37:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:37:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:37:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1403 s/iter. Eval: 0.0514 s/iter. Total: 0.1924 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 23:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1551 s/iter. Eval: 0.1154 s/iter. Total: 0.2715 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 23:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1579 s/iter. Eval: 0.1299 s/iter. Total: 0.2888 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1576 s/iter. Eval: 0.1330 s/iter. Total: 0.2915 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 23:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1605 s/iter. Eval: 0.1433 s/iter. Total: 0.3048 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 23:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1639 s/iter. Eval: 0.1555 s/iter. Total: 0.3204 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 23:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0009 s/iter. Inference: 0.1621 s/iter. Eval: 0.1565 s/iter. Total: 0.3196 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 23:37:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.431410 (0.314064 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:37:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.161791 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:37:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:37:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2887282332621265\n",
      "\u001b[32m[02/08 23:37:59 d2.utils.events]: \u001b[0m eta: 1:29:59  iter: 2679  total_loss: 1.403  loss_cls: 0.3779  loss_box_reg: 0.5545  loss_mask: 0.2938  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.1088  time: 0.9138  data_time: 0.1990  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:38:15 d2.utils.events]: \u001b[0m eta: 1:29:35  iter: 2699  total_loss: 1.414  loss_cls: 0.3667  loss_box_reg: 0.5827  loss_mask: 0.3015  loss_rpn_cls: 0.0343  loss_rpn_loc: 0.1173  time: 0.9131  data_time: 0.1485  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:38:31 d2.utils.events]: \u001b[0m eta: 1:29:23  iter: 2719  total_loss: 1.404  loss_cls: 0.3527  loss_box_reg: 0.5735  loss_mask: 0.3037  loss_rpn_cls: 0.0458  loss_rpn_loc: 0.1176  time: 0.9121  data_time: 0.0815  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:38:46 d2.utils.events]: \u001b[0m eta: 1:29:05  iter: 2739  total_loss: 1.291  loss_cls: 0.3437  loss_box_reg: 0.5355  loss_mask: 0.2775  loss_rpn_cls: 0.03707  loss_rpn_loc: 0.09634  time: 0.9111  data_time: 0.1078  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:39:04 d2.utils.events]: \u001b[0m eta: 1:29:00  iter: 2759  total_loss: 1.356  loss_cls: 0.3425  loss_box_reg: 0.5558  loss_mask: 0.2974  loss_rpn_cls: 0.03628  loss_rpn_loc: 0.1145  time: 0.9111  data_time: 0.1941  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:39:21 d2.utils.events]: \u001b[0m eta: 1:28:49  iter: 2779  total_loss: 1.335  loss_cls: 0.3563  loss_box_reg: 0.5447  loss_mask: 0.2948  loss_rpn_cls: 0.03408  loss_rpn_loc: 0.1111  time: 0.9107  data_time: 0.1358  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:39:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:39:43 d2.utils.events]: \u001b[0m eta: 1:28:24  iter: 2799  total_loss: 1.463  loss_cls: 0.366  loss_box_reg: 0.5979  loss_mask: 0.3094  loss_rpn_cls: 0.05356  loss_rpn_loc: 0.1153  time: 0.9118  data_time: 0.2651  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:40:00 d2.utils.events]: \u001b[0m eta: 1:28:05  iter: 2819  total_loss: 1.366  loss_cls: 0.3519  loss_box_reg: 0.5581  loss_mask: 0.2986  loss_rpn_cls: 0.03841  loss_rpn_loc: 0.107  time: 0.9114  data_time: 0.1442  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:40:18 d2.utils.events]: \u001b[0m eta: 1:27:50  iter: 2839  total_loss: 1.436  loss_cls: 0.3721  loss_box_reg: 0.5386  loss_mask: 0.3034  loss_rpn_cls: 0.05543  loss_rpn_loc: 0.1175  time: 0.9113  data_time: 0.1794  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:40:36 d2.utils.events]: \u001b[0m eta: 1:27:48  iter: 2859  total_loss: 1.338  loss_cls: 0.3534  loss_box_reg: 0.5409  loss_mask: 0.3031  loss_rpn_cls: 0.05468  loss_rpn_loc: 0.1019  time: 0.9112  data_time: 0.1390  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:40:55 d2.utils.events]: \u001b[0m eta: 1:27:19  iter: 2879  total_loss: 1.393  loss_cls: 0.3519  loss_box_reg: 0.568  loss_mask: 0.2926  loss_rpn_cls: 0.03907  loss_rpn_loc: 0.1114  time: 0.9116  data_time: 0.2587  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:41:17 d2.utils.events]: \u001b[0m eta: 1:27:07  iter: 2899  total_loss: 1.471  loss_cls: 0.3774  loss_box_reg: 0.5844  loss_mask: 0.3008  loss_rpn_cls: 0.06443  loss_rpn_loc: 0.1281  time: 0.9129  data_time: 0.3376  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:41:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:41:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:41:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:41:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:41:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:41:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1484 s/iter. Eval: 0.0568 s/iter. Total: 0.2058 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1539 s/iter. Eval: 0.1219 s/iter. Total: 0.2767 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 23:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1574 s/iter. Eval: 0.1369 s/iter. Total: 0.2953 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0009 s/iter. Inference: 0.1595 s/iter. Eval: 0.1368 s/iter. Total: 0.2973 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 23:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0009 s/iter. Inference: 0.1600 s/iter. Eval: 0.1472 s/iter. Total: 0.3082 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 23:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0010 s/iter. Inference: 0.1625 s/iter. Eval: 0.1618 s/iter. Total: 0.3252 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/08 23:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0010 s/iter. Inference: 0.1628 s/iter. Eval: 0.1656 s/iter. Total: 0.3294 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/08 23:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0010 s/iter. Inference: 0.1617 s/iter. Eval: 0.1604 s/iter. Total: 0.3231 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/08 23:42:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.528037 (0.323518 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:42:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.161711 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:42:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:42:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2941729662278104\n",
      "\u001b[32m[02/08 23:42:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:42:19 d2.utils.events]: \u001b[0m eta: 1:26:51  iter: 2919  total_loss: 1.442  loss_cls: 0.3702  loss_box_reg: 0.5809  loss_mask: 0.3041  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.1312  time: 0.9143  data_time: 0.2660  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:42:37 d2.utils.events]: \u001b[0m eta: 1:26:49  iter: 2939  total_loss: 1.345  loss_cls: 0.3356  loss_box_reg: 0.5446  loss_mask: 0.2897  loss_rpn_cls: 0.04081  loss_rpn_loc: 0.1079  time: 0.9140  data_time: 0.1550  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:42:51 d2.utils.events]: \u001b[0m eta: 1:26:28  iter: 2959  total_loss: 1.272  loss_cls: 0.3138  loss_box_reg: 0.5322  loss_mask: 0.2909  loss_rpn_cls: 0.02497  loss_rpn_loc: 0.1039  time: 0.9127  data_time: 0.0459  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:43:07 d2.utils.events]: \u001b[0m eta: 1:26:08  iter: 2979  total_loss: 1.349  loss_cls: 0.362  loss_box_reg: 0.5525  loss_mask: 0.2938  loss_rpn_cls: 0.0475  loss_rpn_loc: 0.08694  time: 0.9121  data_time: 0.1307  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:43:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:43:27 d2.utils.events]: \u001b[0m eta: 1:25:56  iter: 2999  total_loss: 1.372  loss_cls: 0.3397  loss_box_reg: 0.5702  loss_mask: 0.3092  loss_rpn_cls: 0.04527  loss_rpn_loc: 0.1029  time: 0.9127  data_time: 0.2032  lr: 0.0004  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:43:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:43:48 d2.utils.events]: \u001b[0m eta: 1:25:32  iter: 3019  total_loss: 1.328  loss_cls: 0.3432  loss_box_reg: 0.5535  loss_mask: 0.2969  loss_rpn_cls: 0.03711  loss_rpn_loc: 0.0947  time: 0.9133  data_time: 0.2210  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:44:05 d2.utils.events]: \u001b[0m eta: 1:25:16  iter: 3039  total_loss: 1.416  loss_cls: 0.3735  loss_box_reg: 0.5492  loss_mask: 0.2821  loss_rpn_cls: 0.05813  loss_rpn_loc: 0.1195  time: 0.9130  data_time: 0.1778  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:44:25 d2.utils.events]: \u001b[0m eta: 1:25:09  iter: 3059  total_loss: 1.378  loss_cls: 0.3558  loss_box_reg: 0.5458  loss_mask: 0.2948  loss_rpn_cls: 0.05444  loss_rpn_loc: 0.1238  time: 0.9136  data_time: 0.2852  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:44:42 d2.utils.events]: \u001b[0m eta: 1:24:53  iter: 3079  total_loss: 1.394  loss_cls: 0.3644  loss_box_reg: 0.5737  loss_mask: 0.3032  loss_rpn_cls: 0.05701  loss_rpn_loc: 0.1122  time: 0.9130  data_time: 0.1604  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:44:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:44:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:45:03 d2.utils.events]: \u001b[0m eta: 1:24:30  iter: 3099  total_loss: 1.34  loss_cls: 0.336  loss_box_reg: 0.5756  loss_mask: 0.2973  loss_rpn_cls: 0.04006  loss_rpn_loc: 0.1043  time: 0.9140  data_time: 0.2002  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:45:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:45:24 d2.utils.events]: \u001b[0m eta: 1:24:11  iter: 3119  total_loss: 1.469  loss_cls: 0.3923  loss_box_reg: 0.5785  loss_mask: 0.2955  loss_rpn_cls: 0.05745  loss_rpn_loc: 0.1204  time: 0.9149  data_time: 0.2839  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:45:41 d2.utils.events]: \u001b[0m eta: 1:24:01  iter: 3139  total_loss: 1.337  loss_cls: 0.3627  loss_box_reg: 0.5628  loss_mask: 0.2892  loss_rpn_cls: 0.04111  loss_rpn_loc: 0.1046  time: 0.9144  data_time: 0.1350  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:45:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:45:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:45:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:45:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:45:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:45:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1402 s/iter. Eval: 0.0585 s/iter. Total: 0.1994 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 23:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1485 s/iter. Eval: 0.1319 s/iter. Total: 0.2813 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 23:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1517 s/iter. Eval: 0.1428 s/iter. Total: 0.2955 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1514 s/iter. Eval: 0.1346 s/iter. Total: 0.2869 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 23:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1531 s/iter. Eval: 0.1484 s/iter. Total: 0.3025 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 23:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1563 s/iter. Eval: 0.1617 s/iter. Total: 0.3190 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 23:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0009 s/iter. Inference: 0.1555 s/iter. Eval: 0.1623 s/iter. Total: 0.3187 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 23:46:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.516216 (0.314795 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:46:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.155244 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:46:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:46:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29524292325360346\n",
      "\u001b[32m[02/08 23:46:36 d2.utils.events]: \u001b[0m eta: 1:23:44  iter: 3159  total_loss: 1.297  loss_cls: 0.3382  loss_box_reg: 0.5404  loss_mask: 0.2914  loss_rpn_cls: 0.03265  loss_rpn_loc: 0.1038  time: 0.9138  data_time: 0.1279  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:46:51 d2.utils.events]: \u001b[0m eta: 1:23:29  iter: 3179  total_loss: 1.344  loss_cls: 0.3526  loss_box_reg: 0.5575  loss_mask: 0.2951  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.09975  time: 0.9128  data_time: 0.0679  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:47:07 d2.utils.events]: \u001b[0m eta: 1:23:05  iter: 3199  total_loss: 1.38  loss_cls: 0.3337  loss_box_reg: 0.5821  loss_mask: 0.2967  loss_rpn_cls: 0.04447  loss_rpn_loc: 0.09561  time: 0.9121  data_time: 0.1261  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:47:26 d2.utils.events]: \u001b[0m eta: 1:23:03  iter: 3219  total_loss: 1.376  loss_cls: 0.3662  loss_box_reg: 0.5568  loss_mask: 0.2943  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.1223  time: 0.9124  data_time: 0.2315  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:47:45 d2.utils.events]: \u001b[0m eta: 1:22:49  iter: 3239  total_loss: 1.35  loss_cls: 0.3453  loss_box_reg: 0.5389  loss_mask: 0.2805  loss_rpn_cls: 0.04773  loss_rpn_loc: 0.1012  time: 0.9125  data_time: 0.2257  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:48:02 d2.utils.events]: \u001b[0m eta: 1:22:34  iter: 3259  total_loss: 1.327  loss_cls: 0.3268  loss_box_reg: 0.5184  loss_mask: 0.2963  loss_rpn_cls: 0.03462  loss_rpn_loc: 0.09015  time: 0.9121  data_time: 0.1726  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:48:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:48:22 d2.utils.events]: \u001b[0m eta: 1:22:16  iter: 3279  total_loss: 1.477  loss_cls: 0.389  loss_box_reg: 0.5924  loss_mask: 0.2932  loss_rpn_cls: 0.0505  loss_rpn_loc: 0.1062  time: 0.9127  data_time: 0.1848  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:48:38 d2.utils.events]: \u001b[0m eta: 1:21:47  iter: 3299  total_loss: 1.354  loss_cls: 0.3512  loss_box_reg: 0.5781  loss_mask: 0.2921  loss_rpn_cls: 0.03628  loss_rpn_loc: 0.1165  time: 0.9120  data_time: 0.1036  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:48:55 d2.utils.events]: \u001b[0m eta: 1:21:28  iter: 3319  total_loss: 1.311  loss_cls: 0.3575  loss_box_reg: 0.5444  loss_mask: 0.2809  loss_rpn_cls: 0.03532  loss_rpn_loc: 0.1121  time: 0.9117  data_time: 0.1787  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:49:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:49:16 d2.utils.events]: \u001b[0m eta: 1:21:22  iter: 3339  total_loss: 1.363  loss_cls: 0.3544  loss_box_reg: 0.5537  loss_mask: 0.306  loss_rpn_cls: 0.05154  loss_rpn_loc: 0.1177  time: 0.9126  data_time: 0.2397  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:49:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:49:36 d2.utils.events]: \u001b[0m eta: 1:21:00  iter: 3359  total_loss: 1.273  loss_cls: 0.33  loss_box_reg: 0.5178  loss_mask: 0.2785  loss_rpn_cls: 0.05189  loss_rpn_loc: 0.1086  time: 0.9129  data_time: 0.2141  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:49:54 d2.utils.events]: \u001b[0m eta: 1:20:47  iter: 3379  total_loss: 1.448  loss_cls: 0.3791  loss_box_reg: 0.5764  loss_mask: 0.3011  loss_rpn_cls: 0.05595  loss_rpn_loc: 0.1177  time: 0.9129  data_time: 0.1972  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:50:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:50:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:50:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:50:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:50:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:50:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1439 s/iter. Eval: 0.0512 s/iter. Total: 0.1958 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 23:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1525 s/iter. Eval: 0.1264 s/iter. Total: 0.2799 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 23:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1524 s/iter. Eval: 0.1351 s/iter. Total: 0.2885 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 23:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0009 s/iter. Inference: 0.1516 s/iter. Eval: 0.1254 s/iter. Total: 0.2780 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/08 23:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1547 s/iter. Eval: 0.1472 s/iter. Total: 0.3029 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 23:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1575 s/iter. Eval: 0.1569 s/iter. Total: 0.3154 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 23:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0009 s/iter. Inference: 0.1567 s/iter. Eval: 0.1553 s/iter. Total: 0.3130 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 23:50:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.731010 (0.308026 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:50:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.156513 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:50:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:50:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.28962423640571694\n",
      "\u001b[32m[02/08 23:50:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:50:53 d2.utils.events]: \u001b[0m eta: 1:20:32  iter: 3399  total_loss: 1.335  loss_cls: 0.3585  loss_box_reg: 0.546  loss_mask: 0.2931  loss_rpn_cls: 0.04666  loss_rpn_loc: 0.1144  time: 0.9138  data_time: 0.2225  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:51:09 d2.utils.events]: \u001b[0m eta: 1:20:14  iter: 3419  total_loss: 1.334  loss_cls: 0.3637  loss_box_reg: 0.5631  loss_mask: 0.3046  loss_rpn_cls: 0.0288  loss_rpn_loc: 0.1045  time: 0.9131  data_time: 0.0878  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:51:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:51:32 d2.utils.events]: \u001b[0m eta: 1:20:05  iter: 3439  total_loss: 1.413  loss_cls: 0.3731  loss_box_reg: 0.5768  loss_mask: 0.304  loss_rpn_cls: 0.05335  loss_rpn_loc: 0.1257  time: 0.9145  data_time: 0.2640  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:51:48 d2.utils.events]: \u001b[0m eta: 1:19:56  iter: 3459  total_loss: 1.298  loss_cls: 0.343  loss_box_reg: 0.5366  loss_mask: 0.2888  loss_rpn_cls: 0.03752  loss_rpn_loc: 0.1025  time: 0.9139  data_time: 0.1004  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:52:03 d2.utils.events]: \u001b[0m eta: 1:19:32  iter: 3479  total_loss: 1.297  loss_cls: 0.3212  loss_box_reg: 0.553  loss_mask: 0.288  loss_rpn_cls: 0.03967  loss_rpn_loc: 0.08982  time: 0.9130  data_time: 0.0994  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:52:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:52:23 d2.utils.events]: \u001b[0m eta: 1:19:11  iter: 3499  total_loss: 1.236  loss_cls: 0.286  loss_box_reg: 0.5323  loss_mask: 0.2827  loss_rpn_cls: 0.03058  loss_rpn_loc: 0.06595  time: 0.9135  data_time: 0.2199  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:52:44 d2.utils.events]: \u001b[0m eta: 1:19:01  iter: 3519  total_loss: 1.413  loss_cls: 0.3688  loss_box_reg: 0.558  loss_mask: 0.3067  loss_rpn_cls: 0.04799  loss_rpn_loc: 0.1279  time: 0.9142  data_time: 0.3099  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:53:02 d2.utils.events]: \u001b[0m eta: 1:18:42  iter: 3539  total_loss: 1.378  loss_cls: 0.3536  loss_box_reg: 0.5676  loss_mask: 0.3099  loss_rpn_cls: 0.04386  loss_rpn_loc: 0.1256  time: 0.9142  data_time: 0.1796  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:53:20 d2.utils.events]: \u001b[0m eta: 1:18:15  iter: 3559  total_loss: 1.377  loss_cls: 0.3615  loss_box_reg: 0.5578  loss_mask: 0.3147  loss_rpn_cls: 0.04246  loss_rpn_loc: 0.1068  time: 0.9142  data_time: 0.2177  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:53:37 d2.utils.events]: \u001b[0m eta: 1:17:54  iter: 3579  total_loss: 1.317  loss_cls: 0.3393  loss_box_reg: 0.5691  loss_mask: 0.3094  loss_rpn_cls: 0.03229  loss_rpn_loc: 0.1102  time: 0.9137  data_time: 0.1693  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:53:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:54:00 d2.utils.events]: \u001b[0m eta: 1:17:49  iter: 3599  total_loss: 1.404  loss_cls: 0.3764  loss_box_reg: 0.5549  loss_mask: 0.293  loss_rpn_cls: 0.03869  loss_rpn_loc: 0.122  time: 0.9149  data_time: 0.2860  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:54:19 d2.utils.events]: \u001b[0m eta: 1:17:35  iter: 3619  total_loss: 1.379  loss_cls: 0.3584  loss_box_reg: 0.5613  loss_mask: 0.2942  loss_rpn_cls: 0.05369  loss_rpn_loc: 0.1137  time: 0.9152  data_time: 0.2325  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:54:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:54:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:54:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:54:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:54:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:54:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:54:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1414 s/iter. Eval: 0.0502 s/iter. Total: 0.1924 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/08 23:54:35 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1557 s/iter. Eval: 0.1169 s/iter. Total: 0.2736 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 23:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1590 s/iter. Eval: 0.1329 s/iter. Total: 0.2929 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1583 s/iter. Eval: 0.1344 s/iter. Total: 0.2937 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/08 23:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1452 s/iter. Total: 0.3063 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/08 23:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1627 s/iter. Eval: 0.1564 s/iter. Total: 0.3201 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 23:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0009 s/iter. Inference: 0.1615 s/iter. Eval: 0.1578 s/iter. Total: 0.3203 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/08 23:55:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.570521 (0.315263 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:55:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.161164 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:55:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:55:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2943712206730946\n",
      "\u001b[32m[02/08 23:55:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:55:18 d2.utils.events]: \u001b[0m eta: 1:17:17  iter: 3639  total_loss: 1.404  loss_cls: 0.3576  loss_box_reg: 0.5717  loss_mask: 0.2995  loss_rpn_cls: 0.04861  loss_rpn_loc: 0.1162  time: 0.9157  data_time: 0.2166  lr: 0.00032  max_mem: 9270M\n",
      "\u001b[32m[02/08 23:55:37 d2.utils.events]: \u001b[0m eta: 1:17:00  iter: 3659  total_loss: 1.367  loss_cls: 0.3496  loss_box_reg: 0.5412  loss_mask: 0.2913  loss_rpn_cls: 0.04008  loss_rpn_loc: 0.1081  time: 0.9159  data_time: 0.2147  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:55:56 d2.utils.events]: \u001b[0m eta: 1:16:50  iter: 3679  total_loss: 1.398  loss_cls: 0.3601  loss_box_reg: 0.5633  loss_mask: 0.2985  loss_rpn_cls: 0.04266  loss_rpn_loc: 0.1115  time: 0.9161  data_time: 0.2574  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:56:13 d2.utils.events]: \u001b[0m eta: 1:16:38  iter: 3699  total_loss: 1.306  loss_cls: 0.3393  loss_box_reg: 0.5622  loss_mask: 0.2912  loss_rpn_cls: 0.04586  loss_rpn_loc: 0.1096  time: 0.9157  data_time: 0.1219  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:56:30 d2.utils.events]: \u001b[0m eta: 1:16:21  iter: 3719  total_loss: 1.33  loss_cls: 0.3389  loss_box_reg: 0.5632  loss_mask: 0.2893  loss_rpn_cls: 0.02721  loss_rpn_loc: 0.09097  time: 0.9154  data_time: 0.1524  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:56:47 d2.utils.events]: \u001b[0m eta: 1:16:19  iter: 3739  total_loss: 1.295  loss_cls: 0.3294  loss_box_reg: 0.5204  loss_mask: 0.2796  loss_rpn_cls: 0.03067  loss_rpn_loc: 0.1065  time: 0.9150  data_time: 0.1386  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:56:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:57:07 d2.utils.events]: \u001b[0m eta: 1:16:01  iter: 3759  total_loss: 1.377  loss_cls: 0.3814  loss_box_reg: 0.5495  loss_mask: 0.2914  loss_rpn_cls: 0.03711  loss_rpn_loc: 0.119  time: 0.9155  data_time: 0.1980  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:57:27 d2.utils.events]: \u001b[0m eta: 1:15:49  iter: 3779  total_loss: 1.369  loss_cls: 0.3382  loss_box_reg: 0.5494  loss_mask: 0.2989  loss_rpn_cls: 0.05252  loss_rpn_loc: 0.1131  time: 0.9160  data_time: 0.2703  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:57:47 d2.utils.events]: \u001b[0m eta: 1:15:44  iter: 3799  total_loss: 1.485  loss_cls: 0.3918  loss_box_reg: 0.5908  loss_mask: 0.3153  loss_rpn_cls: 0.05537  loss_rpn_loc: 0.129  time: 0.9164  data_time: 0.2530  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:58:03 d2.utils.events]: \u001b[0m eta: 1:15:35  iter: 3819  total_loss: 1.392  loss_cls: 0.3895  loss_box_reg: 0.558  loss_mask: 0.2962  loss_rpn_cls: 0.04779  loss_rpn_loc: 0.1152  time: 0.9158  data_time: 0.0991  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:58:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:58:23 d2.utils.events]: \u001b[0m eta: 1:15:29  iter: 3839  total_loss: 1.371  loss_cls: 0.3547  loss_box_reg: 0.5318  loss_mask: 0.2885  loss_rpn_cls: 0.05484  loss_rpn_loc: 0.1114  time: 0.9162  data_time: 0.1734  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:58:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/08 23:58:43 d2.utils.events]: \u001b[0m eta: 1:15:00  iter: 3859  total_loss: 1.432  loss_cls: 0.3744  loss_box_reg: 0.5509  loss_mask: 0.3057  loss_rpn_cls: 0.05314  loss_rpn_loc: 0.1017  time: 0.9167  data_time: 0.1920  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:58:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:58:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/08 23:58:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/08 23:58:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/08 23:58:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/08 23:58:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/08 23:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1480 s/iter. Eval: 0.0513 s/iter. Total: 0.2000 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1552 s/iter. Eval: 0.1240 s/iter. Total: 0.2802 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/08 23:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1577 s/iter. Eval: 0.1354 s/iter. Total: 0.2942 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/08 23:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1571 s/iter. Eval: 0.1271 s/iter. Total: 0.2852 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/08 23:59:18 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1585 s/iter. Eval: 0.1449 s/iter. Total: 0.3044 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/08 23:59:23 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1614 s/iter. Eval: 0.1542 s/iter. Total: 0.3166 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/08 23:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0009 s/iter. Inference: 0.1604 s/iter. Eval: 0.1520 s/iter. Total: 0.3135 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/08 23:59:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.924662 (0.309695 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:59:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.160459 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/08 23:59:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/08 23:59:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2954978252067783\n",
      "\u001b[32m[02/08 23:59:37 d2.utils.events]: \u001b[0m eta: 1:14:42  iter: 3879  total_loss: 1.328  loss_cls: 0.3498  loss_box_reg: 0.5429  loss_mask: 0.2856  loss_rpn_cls: 0.04449  loss_rpn_loc: 0.09762  time: 0.9161  data_time: 0.0836  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/08 23:59:57 d2.utils.events]: \u001b[0m eta: 1:14:22  iter: 3899  total_loss: 1.361  loss_cls: 0.3471  loss_box_reg: 0.5397  loss_mask: 0.315  loss_rpn_cls: 0.04865  loss_rpn_loc: 0.1045  time: 0.9165  data_time: 0.2586  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:00:14 d2.utils.events]: \u001b[0m eta: 1:14:02  iter: 3919  total_loss: 1.425  loss_cls: 0.3654  loss_box_reg: 0.5652  loss_mask: 0.2948  loss_rpn_cls: 0.05073  loss_rpn_loc: 0.1247  time: 0.9161  data_time: 0.1421  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:00:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:00:34 d2.utils.events]: \u001b[0m eta: 1:13:48  iter: 3939  total_loss: 1.34  loss_cls: 0.3477  loss_box_reg: 0.5316  loss_mask: 0.2814  loss_rpn_cls: 0.04628  loss_rpn_loc: 0.1139  time: 0.9166  data_time: 0.2096  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:00:52 d2.utils.events]: \u001b[0m eta: 1:13:47  iter: 3959  total_loss: 1.383  loss_cls: 0.3568  loss_box_reg: 0.5517  loss_mask: 0.3026  loss_rpn_cls: 0.04202  loss_rpn_loc: 0.1201  time: 0.9164  data_time: 0.1568  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:01:09 d2.utils.events]: \u001b[0m eta: 1:13:34  iter: 3979  total_loss: 1.355  loss_cls: 0.3669  loss_box_reg: 0.5377  loss_mask: 0.2997  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.1158  time: 0.9160  data_time: 0.1233  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:01:29 d2.utils.events]: \u001b[0m eta: 1:13:33  iter: 3999  total_loss: 1.42  loss_cls: 0.3642  loss_box_reg: 0.5494  loss_mask: 0.3145  loss_rpn_cls: 0.04492  loss_rpn_loc: 0.1128  time: 0.9164  data_time: 0.2725  lr: 0.00032  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:01:46 d2.utils.events]: \u001b[0m eta: 1:13:28  iter: 4019  total_loss: 1.405  loss_cls: 0.3415  loss_box_reg: 0.6047  loss_mask: 0.3108  loss_rpn_cls: 0.03719  loss_rpn_loc: 0.1051  time: 0.9162  data_time: 0.1239  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:02:04 d2.utils.events]: \u001b[0m eta: 1:13:13  iter: 4039  total_loss: 1.307  loss_cls: 0.349  loss_box_reg: 0.5343  loss_mask: 0.2901  loss_rpn_cls: 0.0414  loss_rpn_loc: 0.1002  time: 0.9161  data_time: 0.1696  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:02:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:02:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:02:27 d2.utils.events]: \u001b[0m eta: 1:12:58  iter: 4059  total_loss: 1.353  loss_cls: 0.3585  loss_box_reg: 0.571  loss_mask: 0.3054  loss_rpn_cls: 0.05244  loss_rpn_loc: 0.1168  time: 0.9172  data_time: 0.2373  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:02:45 d2.utils.events]: \u001b[0m eta: 1:12:46  iter: 4079  total_loss: 1.361  loss_cls: 0.3722  loss_box_reg: 0.5504  loss_mask: 0.2832  loss_rpn_cls: 0.04623  loss_rpn_loc: 0.1014  time: 0.9173  data_time: 0.2165  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:03:01 d2.utils.events]: \u001b[0m eta: 1:12:35  iter: 4099  total_loss: 1.293  loss_cls: 0.3358  loss_box_reg: 0.5459  loss_mask: 0.2844  loss_rpn_cls: 0.03831  loss_rpn_loc: 0.1037  time: 0.9167  data_time: 0.1206  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:03:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:03:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:03:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:03:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:03:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:03:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1432 s/iter. Eval: 0.0515 s/iter. Total: 0.1954 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 00:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0009 s/iter. Inference: 0.1578 s/iter. Eval: 0.1223 s/iter. Total: 0.2810 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/09 00:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1574 s/iter. Eval: 0.1320 s/iter. Total: 0.2904 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1551 s/iter. Eval: 0.1336 s/iter. Total: 0.2898 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 00:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1565 s/iter. Eval: 0.1453 s/iter. Total: 0.3028 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/09 00:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1573 s/iter. Total: 0.3187 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1592 s/iter. Eval: 0.1592 s/iter. Total: 0.3194 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:03:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.491684 (0.314583 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:03:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158569 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:03:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:03:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.296951558976948\n",
      "\u001b[32m[02/09 00:03:56 d2.utils.events]: \u001b[0m eta: 1:12:15  iter: 4119  total_loss: 1.263  loss_cls: 0.326  loss_box_reg: 0.5386  loss_mask: 0.2754  loss_rpn_cls: 0.03434  loss_rpn_loc: 0.1012  time: 0.9161  data_time: 0.1072  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:04:12 d2.utils.events]: \u001b[0m eta: 1:11:58  iter: 4139  total_loss: 1.255  loss_cls: 0.3251  loss_box_reg: 0.5291  loss_mask: 0.2736  loss_rpn_cls: 0.03243  loss_rpn_loc: 0.09303  time: 0.9156  data_time: 0.1334  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:04:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:04:33 d2.utils.events]: \u001b[0m eta: 1:11:46  iter: 4159  total_loss: 1.36  loss_cls: 0.3531  loss_box_reg: 0.5335  loss_mask: 0.2868  loss_rpn_cls: 0.04046  loss_rpn_loc: 0.1068  time: 0.9163  data_time: 0.2205  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:04:50 d2.utils.events]: \u001b[0m eta: 1:11:30  iter: 4179  total_loss: 1.382  loss_cls: 0.353  loss_box_reg: 0.5637  loss_mask: 0.3148  loss_rpn_cls: 0.04361  loss_rpn_loc: 0.1116  time: 0.9160  data_time: 0.1629  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:05:08 d2.utils.events]: \u001b[0m eta: 1:11:15  iter: 4199  total_loss: 1.395  loss_cls: 0.3559  loss_box_reg: 0.5718  loss_mask: 0.3091  loss_rpn_cls: 0.04474  loss_rpn_loc: 0.1221  time: 0.9159  data_time: 0.1864  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:05:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:05:31 d2.utils.events]: \u001b[0m eta: 1:11:00  iter: 4219  total_loss: 1.458  loss_cls: 0.3623  loss_box_reg: 0.5804  loss_mask: 0.3143  loss_rpn_cls: 0.06009  loss_rpn_loc: 0.121  time: 0.9169  data_time: 0.2523  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:05:51 d2.utils.events]: \u001b[0m eta: 1:10:48  iter: 4239  total_loss: 1.367  loss_cls: 0.3585  loss_box_reg: 0.5546  loss_mask: 0.3088  loss_rpn_cls: 0.05038  loss_rpn_loc: 0.1101  time: 0.9173  data_time: 0.2679  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:06:08 d2.utils.events]: \u001b[0m eta: 1:10:36  iter: 4259  total_loss: 1.293  loss_cls: 0.322  loss_box_reg: 0.5359  loss_mask: 0.2781  loss_rpn_cls: 0.03238  loss_rpn_loc: 0.0876  time: 0.9169  data_time: 0.1108  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:06:25 d2.utils.events]: \u001b[0m eta: 1:10:25  iter: 4279  total_loss: 1.342  loss_cls: 0.3474  loss_box_reg: 0.5529  loss_mask: 0.2912  loss_rpn_cls: 0.04895  loss_rpn_loc: 0.1129  time: 0.9167  data_time: 0.1571  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:06:43 d2.utils.events]: \u001b[0m eta: 1:10:12  iter: 4299  total_loss: 1.445  loss_cls: 0.3613  loss_box_reg: 0.5765  loss_mask: 0.3075  loss_rpn_cls: 0.04756  loss_rpn_loc: 0.121  time: 0.9166  data_time: 0.1787  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:07:01 d2.utils.events]: \u001b[0m eta: 1:10:00  iter: 4319  total_loss: 1.434  loss_cls: 0.384  loss_box_reg: 0.5758  loss_mask: 0.3144  loss_rpn_cls: 0.05294  loss_rpn_loc: 0.1239  time: 0.9166  data_time: 0.1512  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:07:18 d2.utils.events]: \u001b[0m eta: 1:09:38  iter: 4339  total_loss: 1.398  loss_cls: 0.3403  loss_box_reg: 0.5636  loss_mask: 0.3017  loss_rpn_cls: 0.02623  loss_rpn_loc: 0.09974  time: 0.9162  data_time: 0.1549  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:07:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:07:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:07:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:07:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:07:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:07:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1468 s/iter. Eval: 0.0556 s/iter. Total: 0.2031 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:07:40 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1519 s/iter. Eval: 0.1270 s/iter. Total: 0.2799 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1557 s/iter. Eval: 0.1413 s/iter. Total: 0.2980 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0009 s/iter. Inference: 0.1506 s/iter. Eval: 0.1283 s/iter. Total: 0.2799 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/09 00:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1541 s/iter. Eval: 0.1490 s/iter. Total: 0.3041 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 00:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0009 s/iter. Inference: 0.1560 s/iter. Eval: 0.1571 s/iter. Total: 0.3141 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/09 00:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1559 s/iter. Eval: 0.1572 s/iter. Total: 0.3141 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/09 00:08:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.786120 (0.308501 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:08:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.155427 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:08:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:08:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2958593370619153\n",
      "\u001b[32m[02/09 00:08:13 d2.utils.events]: \u001b[0m eta: 1:09:28  iter: 4359  total_loss: 1.237  loss_cls: 0.3053  loss_box_reg: 0.5406  loss_mask: 0.2805  loss_rpn_cls: 0.03586  loss_rpn_loc: 0.09275  time: 0.9158  data_time: 0.1167  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:08:28 d2.utils.events]: \u001b[0m eta: 1:09:09  iter: 4379  total_loss: 1.286  loss_cls: 0.3327  loss_box_reg: 0.5295  loss_mask: 0.2935  loss_rpn_cls: 0.03641  loss_rpn_loc: 0.1173  time: 0.9151  data_time: 0.0830  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:08:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:08:47 d2.utils.events]: \u001b[0m eta: 1:08:51  iter: 4399  total_loss: 1.31  loss_cls: 0.3382  loss_box_reg: 0.5609  loss_mask: 0.3047  loss_rpn_cls: 0.05852  loss_rpn_loc: 0.115  time: 0.9154  data_time: 0.2048  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:09:04 d2.utils.events]: \u001b[0m eta: 1:08:37  iter: 4419  total_loss: 1.347  loss_cls: 0.3451  loss_box_reg: 0.5438  loss_mask: 0.276  loss_rpn_cls: 0.04401  loss_rpn_loc: 0.1123  time: 0.9150  data_time: 0.1342  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:09:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:09:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:09:28 d2.utils.events]: \u001b[0m eta: 1:08:17  iter: 4439  total_loss: 1.495  loss_cls: 0.388  loss_box_reg: 0.576  loss_mask: 0.3184  loss_rpn_cls: 0.04804  loss_rpn_loc: 0.1212  time: 0.9164  data_time: 0.2914  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:09:44 d2.utils.events]: \u001b[0m eta: 1:08:00  iter: 4459  total_loss: 1.295  loss_cls: 0.3257  loss_box_reg: 0.5309  loss_mask: 0.2858  loss_rpn_cls: 0.03055  loss_rpn_loc: 0.08766  time: 0.9158  data_time: 0.0908  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:09:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:10:05 d2.utils.events]: \u001b[0m eta: 1:07:49  iter: 4479  total_loss: 1.438  loss_cls: 0.3918  loss_box_reg: 0.5552  loss_mask: 0.3019  loss_rpn_cls: 0.05  loss_rpn_loc: 0.1191  time: 0.9163  data_time: 0.1887  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:10:21 d2.utils.events]: \u001b[0m eta: 1:07:39  iter: 4499  total_loss: 1.369  loss_cls: 0.3669  loss_box_reg: 0.5481  loss_mask: 0.2928  loss_rpn_cls: 0.04853  loss_rpn_loc: 0.1221  time: 0.9159  data_time: 0.1124  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:10:39 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 4519  total_loss: 1.308  loss_cls: 0.3284  loss_box_reg: 0.5275  loss_mask: 0.2886  loss_rpn_cls: 0.03078  loss_rpn_loc: 0.1064  time: 0.9157  data_time: 0.1585  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:10:57 d2.utils.events]: \u001b[0m eta: 1:07:05  iter: 4539  total_loss: 1.291  loss_cls: 0.3421  loss_box_reg: 0.5322  loss_mask: 0.2954  loss_rpn_cls: 0.03668  loss_rpn_loc: 0.1081  time: 0.9156  data_time: 0.1725  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:10:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:11:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:11:18 d2.utils.events]: \u001b[0m eta: 1:06:57  iter: 4559  total_loss: 1.433  loss_cls: 0.3642  loss_box_reg: 0.5392  loss_mask: 0.2935  loss_rpn_cls: 0.04862  loss_rpn_loc: 0.1129  time: 0.9163  data_time: 0.1250  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:11:36 d2.utils.events]: \u001b[0m eta: 1:06:41  iter: 4579  total_loss: 1.33  loss_cls: 0.3484  loss_box_reg: 0.5454  loss_mask: 0.2837  loss_rpn_cls: 0.03245  loss_rpn_loc: 0.09525  time: 0.9162  data_time: 0.1871  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:11:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:11:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:11:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:11:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1488 s/iter. Eval: 0.0539 s/iter. Total: 0.2035 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1577 s/iter. Eval: 0.1170 s/iter. Total: 0.2757 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1638 s/iter. Eval: 0.1342 s/iter. Total: 0.2990 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/09 00:12:10 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1361 s/iter. Total: 0.2976 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/09 00:12:15 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1469 s/iter. Total: 0.3087 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/09 00:12:20 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1627 s/iter. Eval: 0.1584 s/iter. Total: 0.3222 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:12:26 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1608 s/iter. Eval: 0.1599 s/iter. Total: 0.3218 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:12:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.807355 (0.317305 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:12:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.160485 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:12:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:12:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29506524676099527\n",
      "\u001b[32m[02/09 00:12:31 d2.utils.events]: \u001b[0m eta: 1:06:25  iter: 4599  total_loss: 1.409  loss_cls: 0.3622  loss_box_reg: 0.5741  loss_mask: 0.3055  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.115  time: 0.9157  data_time: 0.0658  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:12:51 d2.utils.events]: \u001b[0m eta: 1:06:08  iter: 4619  total_loss: 1.464  loss_cls: 0.389  loss_box_reg: 0.5783  loss_mask: 0.2971  loss_rpn_cls: 0.0593  loss_rpn_loc: 0.1133  time: 0.9161  data_time: 0.2759  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:13:11 d2.utils.events]: \u001b[0m eta: 1:05:56  iter: 4639  total_loss: 1.311  loss_cls: 0.3581  loss_box_reg: 0.5527  loss_mask: 0.3  loss_rpn_cls: 0.05157  loss_rpn_loc: 0.1123  time: 0.9164  data_time: 0.2464  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:13:28 d2.utils.events]: \u001b[0m eta: 1:05:41  iter: 4659  total_loss: 1.26  loss_cls: 0.297  loss_box_reg: 0.4977  loss_mask: 0.2754  loss_rpn_cls: 0.04807  loss_rpn_loc: 0.0872  time: 0.9162  data_time: 0.1779  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:13:46 d2.utils.events]: \u001b[0m eta: 1:05:28  iter: 4679  total_loss: 1.414  loss_cls: 0.3792  loss_box_reg: 0.5675  loss_mask: 0.302  loss_rpn_cls: 0.04292  loss_rpn_loc: 0.123  time: 0.9160  data_time: 0.1252  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:13:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:14:03 d2.utils.events]: \u001b[0m eta: 1:05:09  iter: 4699  total_loss: 1.187  loss_cls: 0.2976  loss_box_reg: 0.5184  loss_mask: 0.2787  loss_rpn_cls: 0.03083  loss_rpn_loc: 0.08798  time: 0.9159  data_time: 0.1338  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:14:20 d2.utils.events]: \u001b[0m eta: 1:04:54  iter: 4719  total_loss: 1.27  loss_cls: 0.3246  loss_box_reg: 0.5267  loss_mask: 0.2826  loss_rpn_cls: 0.02571  loss_rpn_loc: 0.09417  time: 0.9154  data_time: 0.1073  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:14:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:14:42 d2.utils.events]: \u001b[0m eta: 1:04:40  iter: 4739  total_loss: 1.428  loss_cls: 0.3589  loss_box_reg: 0.5666  loss_mask: 0.3031  loss_rpn_cls: 0.05872  loss_rpn_loc: 0.1145  time: 0.9162  data_time: 0.1963  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:14:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:15:03 d2.utils.events]: \u001b[0m eta: 1:04:27  iter: 4759  total_loss: 1.441  loss_cls: 0.35  loss_box_reg: 0.5791  loss_mask: 0.3146  loss_rpn_cls: 0.04513  loss_rpn_loc: 0.1048  time: 0.9168  data_time: 0.1398  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:15:23 d2.utils.events]: \u001b[0m eta: 1:04:13  iter: 4779  total_loss: 1.358  loss_cls: 0.3622  loss_box_reg: 0.5648  loss_mask: 0.3007  loss_rpn_cls: 0.04926  loss_rpn_loc: 0.1189  time: 0.9171  data_time: 0.2664  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:15:38 d2.utils.events]: \u001b[0m eta: 1:03:54  iter: 4799  total_loss: 1.315  loss_cls: 0.3423  loss_box_reg: 0.5389  loss_mask: 0.2877  loss_rpn_cls: 0.03887  loss_rpn_loc: 0.1133  time: 0.9166  data_time: 0.0719  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:15:55 d2.utils.events]: \u001b[0m eta: 1:03:40  iter: 4819  total_loss: 1.398  loss_cls: 0.363  loss_box_reg: 0.5555  loss_mask: 0.2952  loss_rpn_cls: 0.03991  loss_rpn_loc: 0.1132  time: 0.9161  data_time: 0.1124  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:16:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:16:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:16:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:16:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:16:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:16:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1516 s/iter. Eval: 0.0531 s/iter. Total: 0.2055 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1574 s/iter. Eval: 0.1152 s/iter. Total: 0.2736 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1603 s/iter. Eval: 0.1293 s/iter. Total: 0.2905 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1577 s/iter. Eval: 0.1314 s/iter. Total: 0.2901 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 00:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1586 s/iter. Eval: 0.1413 s/iter. Total: 0.3008 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 00:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1609 s/iter. Eval: 0.1528 s/iter. Total: 0.3147 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0009 s/iter. Inference: 0.1602 s/iter. Eval: 0.1541 s/iter. Total: 0.3152 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:16:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.171345 (0.311822 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:16:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.160363 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:16:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:16:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2977033399850475\n",
      "\u001b[32m[02/09 00:16:51 d2.utils.events]: \u001b[0m eta: 1:03:25  iter: 4839  total_loss: 1.42  loss_cls: 0.3635  loss_box_reg: 0.5733  loss_mask: 0.2936  loss_rpn_cls: 0.05565  loss_rpn_loc: 0.1159  time: 0.9162  data_time: 0.1939  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:17:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:17:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:17:13 d2.utils.events]: \u001b[0m eta: 1:03:14  iter: 4859  total_loss: 1.322  loss_cls: 0.3572  loss_box_reg: 0.5483  loss_mask: 0.2896  loss_rpn_cls: 0.04838  loss_rpn_loc: 0.1094  time: 0.9169  data_time: 0.1102  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:17:31 d2.utils.events]: \u001b[0m eta: 1:03:06  iter: 4879  total_loss: 1.362  loss_cls: 0.3391  loss_box_reg: 0.5555  loss_mask: 0.3082  loss_rpn_cls: 0.03425  loss_rpn_loc: 0.111  time: 0.9167  data_time: 0.1638  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:17:49 d2.utils.events]: \u001b[0m eta: 1:02:44  iter: 4899  total_loss: 1.359  loss_cls: 0.345  loss_box_reg: 0.5571  loss_mask: 0.2819  loss_rpn_cls: 0.04236  loss_rpn_loc: 0.1138  time: 0.9168  data_time: 0.2289  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:18:06 d2.utils.events]: \u001b[0m eta: 1:02:34  iter: 4919  total_loss: 1.303  loss_cls: 0.3393  loss_box_reg: 0.54  loss_mask: 0.2994  loss_rpn_cls: 0.04571  loss_rpn_loc: 0.1105  time: 0.9164  data_time: 0.1087  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:18:25 d2.utils.events]: \u001b[0m eta: 1:02:28  iter: 4939  total_loss: 1.369  loss_cls: 0.3567  loss_box_reg: 0.5249  loss_mask: 0.3044  loss_rpn_cls: 0.05282  loss_rpn_loc: 0.1173  time: 0.9166  data_time: 0.2095  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:18:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:18:45 d2.utils.events]: \u001b[0m eta: 1:02:14  iter: 4959  total_loss: 1.284  loss_cls: 0.338  loss_box_reg: 0.5266  loss_mask: 0.2878  loss_rpn_cls: 0.04182  loss_rpn_loc: 0.09756  time: 0.9169  data_time: 0.1484  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:19:01 d2.utils.events]: \u001b[0m eta: 1:02:00  iter: 4979  total_loss: 1.375  loss_cls: 0.3203  loss_box_reg: 0.5656  loss_mask: 0.309  loss_rpn_cls: 0.02897  loss_rpn_loc: 0.08991  time: 0.9165  data_time: 0.0919  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:19:19 d2.utils.events]: \u001b[0m eta: 1:01:39  iter: 4999  total_loss: 1.315  loss_cls: 0.3281  loss_box_reg: 0.5486  loss_mask: 0.2996  loss_rpn_cls: 0.03938  loss_rpn_loc: 0.07896  time: 0.9164  data_time: 0.1945  lr: 0.000256  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:19:36 d2.utils.events]: \u001b[0m eta: 1:01:21  iter: 5019  total_loss: 1.355  loss_cls: 0.3476  loss_box_reg: 0.5683  loss_mask: 0.2976  loss_rpn_cls: 0.03069  loss_rpn_loc: 0.1006  time: 0.9162  data_time: 0.1555  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:19:54 d2.utils.events]: \u001b[0m eta: 1:01:10  iter: 5039  total_loss: 1.274  loss_cls: 0.3313  loss_box_reg: 0.5386  loss_mask: 0.288  loss_rpn_cls: 0.04832  loss_rpn_loc: 0.09603  time: 0.9160  data_time: 0.1478  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:20:12 d2.utils.events]: \u001b[0m eta: 1:00:55  iter: 5059  total_loss: 1.355  loss_cls: 0.3655  loss_box_reg: 0.5336  loss_mask: 0.2875  loss_rpn_cls: 0.04524  loss_rpn_loc: 0.1101  time: 0.9159  data_time: 0.1666  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:20:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:20:32 d2.utils.events]: \u001b[0m eta: 1:00:42  iter: 5079  total_loss: 1.404  loss_cls: 0.3718  loss_box_reg: 0.5451  loss_mask: 0.3123  loss_rpn_cls: 0.0399  loss_rpn_loc: 0.1154  time: 0.9163  data_time: 0.1631  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:20:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:20:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:20:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:20:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:20:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:20:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1463 s/iter. Eval: 0.0541 s/iter. Total: 0.2012 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1532 s/iter. Eval: 0.1178 s/iter. Total: 0.2719 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1554 s/iter. Eval: 0.1427 s/iter. Total: 0.2991 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1528 s/iter. Eval: 0.1349 s/iter. Total: 0.2887 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 00:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1552 s/iter. Eval: 0.1473 s/iter. Total: 0.3035 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/09 00:21:03 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1589 s/iter. Total: 0.3204 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:21:08 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1592 s/iter. Eval: 0.1603 s/iter. Total: 0.3206 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:21:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.533226 (0.314942 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:21:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158108 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:21:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:21:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2942431243215731\n",
      "\u001b[32m[02/09 00:21:26 d2.utils.events]: \u001b[0m eta: 1:00:25  iter: 5099  total_loss: 1.371  loss_cls: 0.3464  loss_box_reg: 0.5371  loss_mask: 0.2778  loss_rpn_cls: 0.04393  loss_rpn_loc: 0.1193  time: 0.9158  data_time: 0.1197  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:21:41 d2.utils.events]: \u001b[0m eta: 1:00:07  iter: 5119  total_loss: 1.277  loss_cls: 0.3076  loss_box_reg: 0.5343  loss_mask: 0.3012  loss_rpn_cls: 0.03359  loss_rpn_loc: 0.08788  time: 0.9150  data_time: 0.0432  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:22:00 d2.utils.events]: \u001b[0m eta: 0:59:59  iter: 5139  total_loss: 1.344  loss_cls: 0.3256  loss_box_reg: 0.537  loss_mask: 0.2949  loss_rpn_cls: 0.04432  loss_rpn_loc: 0.1121  time: 0.9152  data_time: 0.2294  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:22:17 d2.utils.events]: \u001b[0m eta: 0:59:40  iter: 5159  total_loss: 1.265  loss_cls: 0.33  loss_box_reg: 0.5228  loss_mask: 0.273  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.1091  time: 0.9149  data_time: 0.1367  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:22:33 d2.utils.events]: \u001b[0m eta: 0:59:26  iter: 5179  total_loss: 1.291  loss_cls: 0.3437  loss_box_reg: 0.5489  loss_mask: 0.2836  loss_rpn_cls: 0.03566  loss_rpn_loc: 0.08774  time: 0.9146  data_time: 0.1159  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:22:50 d2.utils.events]: \u001b[0m eta: 0:59:13  iter: 5199  total_loss: 1.3  loss_cls: 0.3239  loss_box_reg: 0.5391  loss_mask: 0.284  loss_rpn_cls: 0.02499  loss_rpn_loc: 0.1109  time: 0.9142  data_time: 0.1035  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:23:08 d2.utils.events]: \u001b[0m eta: 0:58:55  iter: 5219  total_loss: 1.382  loss_cls: 0.3382  loss_box_reg: 0.5624  loss_mask: 0.303  loss_rpn_cls: 0.04389  loss_rpn_loc: 0.08883  time: 0.9143  data_time: 0.2291  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:23:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:23:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:23:34 d2.utils.events]: \u001b[0m eta: 0:58:40  iter: 5239  total_loss: 1.466  loss_cls: 0.3909  loss_box_reg: 0.5871  loss_mask: 0.3148  loss_rpn_cls: 0.04942  loss_rpn_loc: 0.1255  time: 0.9156  data_time: 0.3077  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:23:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:23:53 d2.utils.events]: \u001b[0m eta: 0:58:26  iter: 5259  total_loss: 1.368  loss_cls: 0.3549  loss_box_reg: 0.5513  loss_mask: 0.3001  loss_rpn_cls: 0.05472  loss_rpn_loc: 0.119  time: 0.9159  data_time: 0.1564  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:24:10 d2.utils.events]: \u001b[0m eta: 0:58:08  iter: 5279  total_loss: 1.378  loss_cls: 0.3503  loss_box_reg: 0.5528  loss_mask: 0.3008  loss_rpn_cls: 0.05058  loss_rpn_loc: 0.116  time: 0.9155  data_time: 0.1150  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:24:27 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 5299  total_loss: 1.219  loss_cls: 0.3126  loss_box_reg: 0.4921  loss_mask: 0.273  loss_rpn_cls: 0.03951  loss_rpn_loc: 0.1093  time: 0.9153  data_time: 0.1409  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:24:48 d2.utils.events]: \u001b[0m eta: 0:57:39  iter: 5319  total_loss: 1.433  loss_cls: 0.3699  loss_box_reg: 0.5772  loss_mask: 0.3057  loss_rpn_cls: 0.05943  loss_rpn_loc: 0.1312  time: 0.9158  data_time: 0.2914  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:24:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:24:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:24:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:24:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:24:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:24:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:24:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1477 s/iter. Eval: 0.0550 s/iter. Total: 0.2035 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:25:03 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1517 s/iter. Eval: 0.1268 s/iter. Total: 0.2795 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:25:08 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1558 s/iter. Eval: 0.1390 s/iter. Total: 0.2958 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:25:13 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1543 s/iter. Eval: 0.1313 s/iter. Total: 0.2866 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 00:25:18 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1575 s/iter. Eval: 0.1437 s/iter. Total: 0.3023 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 00:25:23 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1604 s/iter. Eval: 0.1549 s/iter. Total: 0.3164 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1565 s/iter. Total: 0.3173 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:25:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.321339 (0.313115 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:25:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159623 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:25:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:25:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29631284569146754\n",
      "\u001b[32m[02/09 00:25:46 d2.utils.events]: \u001b[0m eta: 0:57:28  iter: 5339  total_loss: 1.342  loss_cls: 0.3611  loss_box_reg: 0.5428  loss_mask: 0.2944  loss_rpn_cls: 0.05004  loss_rpn_loc: 0.1031  time: 0.9159  data_time: 0.1202  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:26:03 d2.utils.events]: \u001b[0m eta: 0:57:16  iter: 5359  total_loss: 1.338  loss_cls: 0.3643  loss_box_reg: 0.5411  loss_mask: 0.3032  loss_rpn_cls: 0.04427  loss_rpn_loc: 0.1086  time: 0.9158  data_time: 0.1809  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:26:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:26:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:26:27 d2.utils.events]: \u001b[0m eta: 0:57:04  iter: 5379  total_loss: 1.244  loss_cls: 0.3215  loss_box_reg: 0.5302  loss_mask: 0.2848  loss_rpn_cls: 0.03641  loss_rpn_loc: 0.09648  time: 0.9168  data_time: 0.2152  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:26:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:26:48 d2.utils.events]: \u001b[0m eta: 0:56:49  iter: 5399  total_loss: 1.329  loss_cls: 0.336  loss_box_reg: 0.5393  loss_mask: 0.2833  loss_rpn_cls: 0.03835  loss_rpn_loc: 0.1029  time: 0.9174  data_time: 0.2272  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:27:07 d2.utils.events]: \u001b[0m eta: 0:56:37  iter: 5419  total_loss: 1.254  loss_cls: 0.33  loss_box_reg: 0.5167  loss_mask: 0.2759  loss_rpn_cls: 0.03817  loss_rpn_loc: 0.1127  time: 0.9174  data_time: 0.2104  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:27:26 d2.utils.events]: \u001b[0m eta: 0:56:20  iter: 5439  total_loss: 1.298  loss_cls: 0.3448  loss_box_reg: 0.5164  loss_mask: 0.2991  loss_rpn_cls: 0.04566  loss_rpn_loc: 0.1039  time: 0.9176  data_time: 0.2464  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:27:41 d2.utils.events]: \u001b[0m eta: 0:56:04  iter: 5459  total_loss: 1.222  loss_cls: 0.323  loss_box_reg: 0.5136  loss_mask: 0.2735  loss_rpn_cls: 0.03014  loss_rpn_loc: 0.09309  time: 0.9169  data_time: 0.0183  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:27:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:28:06 d2.utils.events]: \u001b[0m eta: 0:55:58  iter: 5479  total_loss: 1.519  loss_cls: 0.4012  loss_box_reg: 0.5868  loss_mask: 0.3145  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.1315  time: 0.9182  data_time: 0.3689  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:28:24 d2.utils.events]: \u001b[0m eta: 0:55:46  iter: 5499  total_loss: 1.391  loss_cls: 0.3429  loss_box_reg: 0.565  loss_mask: 0.3016  loss_rpn_cls: 0.02889  loss_rpn_loc: 0.1026  time: 0.9181  data_time: 0.1648  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:28:40 d2.utils.events]: \u001b[0m eta: 0:55:33  iter: 5519  total_loss: 1.421  loss_cls: 0.3621  loss_box_reg: 0.5678  loss_mask: 0.3021  loss_rpn_cls: 0.05364  loss_rpn_loc: 0.1219  time: 0.9176  data_time: 0.0433  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:28:55 d2.utils.events]: \u001b[0m eta: 0:55:20  iter: 5539  total_loss: 1.364  loss_cls: 0.337  loss_box_reg: 0.5186  loss_mask: 0.2936  loss_rpn_cls: 0.04713  loss_rpn_loc: 0.1033  time: 0.9170  data_time: 0.0366  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:29:17 d2.utils.events]: \u001b[0m eta: 0:55:04  iter: 5559  total_loss: 1.508  loss_cls: 0.4059  loss_box_reg: 0.5891  loss_mask: 0.3127  loss_rpn_cls: 0.05797  loss_rpn_loc: 0.1369  time: 0.9176  data_time: 0.3525  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:29:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:29:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:29:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:29:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:29:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:29:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1454 s/iter. Eval: 0.0519 s/iter. Total: 0.1981 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 00:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1548 s/iter. Eval: 0.1149 s/iter. Total: 0.2706 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1575 s/iter. Eval: 0.1296 s/iter. Total: 0.2880 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1578 s/iter. Eval: 0.1315 s/iter. Total: 0.2902 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 00:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1584 s/iter. Eval: 0.1418 s/iter. Total: 0.3011 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 00:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1611 s/iter. Eval: 0.1529 s/iter. Total: 0.3150 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:29:55 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0009 s/iter. Inference: 0.1599 s/iter. Eval: 0.1544 s/iter. Total: 0.3152 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:29:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.001413 (0.310357 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:29:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159341 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:29:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:29:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29711185345705415\n",
      "\u001b[32m[02/09 00:30:11 d2.utils.events]: \u001b[0m eta: 0:54:52  iter: 5579  total_loss: 1.268  loss_cls: 0.3264  loss_box_reg: 0.5352  loss_mask: 0.286  loss_rpn_cls: 0.03978  loss_rpn_loc: 0.1034  time: 0.9172  data_time: 0.0838  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:30:29 d2.utils.events]: \u001b[0m eta: 0:54:34  iter: 5599  total_loss: 1.351  loss_cls: 0.3475  loss_box_reg: 0.5446  loss_mask: 0.3009  loss_rpn_cls: 0.03536  loss_rpn_loc: 0.1188  time: 0.9172  data_time: 0.2367  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:30:48 d2.utils.events]: \u001b[0m eta: 0:54:19  iter: 5619  total_loss: 1.376  loss_cls: 0.3311  loss_box_reg: 0.5675  loss_mask: 0.2921  loss_rpn_cls: 0.04791  loss_rpn_loc: 0.1138  time: 0.9173  data_time: 0.2131  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:31:05 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 5639  total_loss: 1.3  loss_cls: 0.3357  loss_box_reg: 0.5342  loss_mask: 0.2838  loss_rpn_cls: 0.03384  loss_rpn_loc: 0.09482  time: 0.9170  data_time: 0.1165  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:31:23 d2.utils.events]: \u001b[0m eta: 0:53:51  iter: 5659  total_loss: 1.383  loss_cls: 0.3692  loss_box_reg: 0.5525  loss_mask: 0.2954  loss_rpn_cls: 0.04484  loss_rpn_loc: 0.125  time: 0.9170  data_time: 0.1990  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:31:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:31:43 d2.utils.events]: \u001b[0m eta: 0:53:34  iter: 5679  total_loss: 1.385  loss_cls: 0.3464  loss_box_reg: 0.5232  loss_mask: 0.2954  loss_rpn_cls: 0.04365  loss_rpn_loc: 0.1143  time: 0.9173  data_time: 0.1623  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:32:04 d2.utils.events]: \u001b[0m eta: 0:53:31  iter: 5699  total_loss: 1.453  loss_cls: 0.379  loss_box_reg: 0.5678  loss_mask: 0.3116  loss_rpn_cls: 0.05451  loss_rpn_loc: 0.1151  time: 0.9177  data_time: 0.3007  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:32:22 d2.utils.events]: \u001b[0m eta: 0:53:16  iter: 5719  total_loss: 1.369  loss_cls: 0.3523  loss_box_reg: 0.5528  loss_mask: 0.2908  loss_rpn_cls: 0.04217  loss_rpn_loc: 0.1134  time: 0.9176  data_time: 0.1879  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:32:39 d2.utils.events]: \u001b[0m eta: 0:53:01  iter: 5739  total_loss: 1.328  loss_cls: 0.3315  loss_box_reg: 0.5277  loss_mask: 0.2837  loss_rpn_cls: 0.03807  loss_rpn_loc: 0.09092  time: 0.9174  data_time: 0.1611  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:32:56 d2.utils.events]: \u001b[0m eta: 0:52:46  iter: 5759  total_loss: 1.33  loss_cls: 0.3473  loss_box_reg: 0.5519  loss_mask: 0.283  loss_rpn_cls: 0.03616  loss_rpn_loc: 0.1161  time: 0.9172  data_time: 0.1350  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:33:13 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 5779  total_loss: 1.369  loss_cls: 0.3456  loss_box_reg: 0.5539  loss_mask: 0.3027  loss_rpn_cls: 0.03873  loss_rpn_loc: 0.1198  time: 0.9170  data_time: 0.1608  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:33:32 d2.utils.events]: \u001b[0m eta: 0:52:12  iter: 5799  total_loss: 1.317  loss_cls: 0.3505  loss_box_reg: 0.5394  loss_mask: 0.301  loss_rpn_cls: 0.03447  loss_rpn_loc: 0.1113  time: 0.9171  data_time: 0.2258  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:33:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:33:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:33:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:33:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:33:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:33:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:33:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1430 s/iter. Eval: 0.0551 s/iter. Total: 0.1988 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 00:33:48 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1553 s/iter. Eval: 0.1177 s/iter. Total: 0.2739 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1562 s/iter. Eval: 0.1406 s/iter. Total: 0.2978 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1531 s/iter. Eval: 0.1326 s/iter. Total: 0.2867 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 00:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1558 s/iter. Eval: 0.1455 s/iter. Total: 0.3023 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/09 00:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1610 s/iter. Eval: 0.1577 s/iter. Total: 0.3198 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1592 s/iter. Total: 0.3200 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:34:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.532667 (0.314937 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:34:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159108 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:34:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:34:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29776780878232423\n",
      "\u001b[32m[02/09 00:34:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:34:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:34:34 d2.utils.events]: \u001b[0m eta: 0:52:01  iter: 5819  total_loss: 1.429  loss_cls: 0.3672  loss_box_reg: 0.5657  loss_mask: 0.315  loss_rpn_cls: 0.05132  loss_rpn_loc: 0.1213  time: 0.9180  data_time: 0.2106  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:34:50 d2.utils.events]: \u001b[0m eta: 0:51:43  iter: 5839  total_loss: 1.337  loss_cls: 0.3416  loss_box_reg: 0.5368  loss_mask: 0.277  loss_rpn_cls: 0.04117  loss_rpn_loc: 0.1081  time: 0.9176  data_time: 0.0907  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:35:06 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 5859  total_loss: 1.338  loss_cls: 0.3449  loss_box_reg: 0.5363  loss_mask: 0.2821  loss_rpn_cls: 0.05331  loss_rpn_loc: 0.1148  time: 0.9172  data_time: 0.0923  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:35:24 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 5879  total_loss: 1.298  loss_cls: 0.3353  loss_box_reg: 0.5199  loss_mask: 0.2854  loss_rpn_cls: 0.0349  loss_rpn_loc: 0.09344  time: 0.9171  data_time: 0.1673  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:35:39 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 5899  total_loss: 1.361  loss_cls: 0.3473  loss_box_reg: 0.5646  loss_mask: 0.294  loss_rpn_cls: 0.03897  loss_rpn_loc: 0.1133  time: 0.9166  data_time: 0.0654  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:35:57 d2.utils.events]: \u001b[0m eta: 0:50:37  iter: 5919  total_loss: 1.386  loss_cls: 0.3562  loss_box_reg: 0.584  loss_mask: 0.3079  loss_rpn_cls: 0.04898  loss_rpn_loc: 0.128  time: 0.9164  data_time: 0.1343  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:36:13 d2.utils.events]: \u001b[0m eta: 0:50:17  iter: 5939  total_loss: 1.322  loss_cls: 0.3479  loss_box_reg: 0.5388  loss_mask: 0.2993  loss_rpn_cls: 0.03752  loss_rpn_loc: 0.09179  time: 0.9160  data_time: 0.1264  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:36:33 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 5959  total_loss: 1.311  loss_cls: 0.3443  loss_box_reg: 0.5532  loss_mask: 0.2891  loss_rpn_cls: 0.03768  loss_rpn_loc: 0.1104  time: 0.9163  data_time: 0.2427  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:36:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:36:58 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 5979  total_loss: 1.345  loss_cls: 0.3633  loss_box_reg: 0.5477  loss_mask: 0.3014  loss_rpn_cls: 0.04267  loss_rpn_loc: 0.118  time: 0.9174  data_time: 0.4179  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:37:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:37:18 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 5999  total_loss: 1.403  loss_cls: 0.3611  loss_box_reg: 0.5669  loss_mask: 0.294  loss_rpn_cls: 0.04341  loss_rpn_loc: 0.124  time: 0.9176  data_time: 0.1814  lr: 0.0002048  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:37:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:37:34 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 6019  total_loss: 1.182  loss_cls: 0.297  loss_box_reg: 0.5125  loss_mask: 0.2884  loss_rpn_cls: 0.02239  loss_rpn_loc: 0.08518  time: 0.9174  data_time: 0.0872  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:37:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:37:57 d2.utils.events]: \u001b[0m eta: 0:49:04  iter: 6039  total_loss: 1.321  loss_cls: 0.3631  loss_box_reg: 0.531  loss_mask: 0.2854  loss_rpn_cls: 0.05428  loss_rpn_loc: 0.09957  time: 0.9180  data_time: 0.2669  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:38:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:38:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:38:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:38:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:38:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:38:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:38:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1453 s/iter. Eval: 0.0571 s/iter. Total: 0.2032 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0009 s/iter. Inference: 0.1533 s/iter. Eval: 0.1295 s/iter. Total: 0.2837 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/09 00:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1532 s/iter. Eval: 0.1392 s/iter. Total: 0.2933 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0009 s/iter. Inference: 0.1530 s/iter. Eval: 0.1347 s/iter. Total: 0.2886 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/09 00:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1539 s/iter. Eval: 0.1485 s/iter. Total: 0.3034 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/09 00:38:38 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1567 s/iter. Eval: 0.1593 s/iter. Total: 0.3170 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0009 s/iter. Inference: 0.1558 s/iter. Eval: 0.1613 s/iter. Total: 0.3181 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:38:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.166837 (0.311783 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:38:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.155584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:38:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:38:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2932912627902928\n",
      "\u001b[32m[02/09 00:38:55 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 6059  total_loss: 1.321  loss_cls: 0.332  loss_box_reg: 0.5333  loss_mask: 0.2875  loss_rpn_cls: 0.04409  loss_rpn_loc: 0.1108  time: 0.9183  data_time: 0.2034  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:39:09 d2.utils.events]: \u001b[0m eta: 0:48:18  iter: 6079  total_loss: 1.288  loss_cls: 0.3238  loss_box_reg: 0.5436  loss_mask: 0.2777  loss_rpn_cls: 0.02786  loss_rpn_loc: 0.09114  time: 0.9176  data_time: 0.0488  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:39:28 d2.utils.events]: \u001b[0m eta: 0:48:12  iter: 6099  total_loss: 1.363  loss_cls: 0.3705  loss_box_reg: 0.545  loss_mask: 0.2957  loss_rpn_cls: 0.04438  loss_rpn_loc: 0.1126  time: 0.9177  data_time: 0.2554  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:39:44 d2.utils.events]: \u001b[0m eta: 0:47:59  iter: 6119  total_loss: 1.305  loss_cls: 0.334  loss_box_reg: 0.5276  loss_mask: 0.287  loss_rpn_cls: 0.03187  loss_rpn_loc: 0.08584  time: 0.9174  data_time: 0.1146  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:40:01 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 6139  total_loss: 1.356  loss_cls: 0.3688  loss_box_reg: 0.5605  loss_mask: 0.3032  loss_rpn_cls: 0.04033  loss_rpn_loc: 0.1036  time: 0.9170  data_time: 0.1040  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:40:17 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 6159  total_loss: 1.236  loss_cls: 0.3104  loss_box_reg: 0.5298  loss_mask: 0.2837  loss_rpn_cls: 0.03377  loss_rpn_loc: 0.09842  time: 0.9167  data_time: 0.1004  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:40:32 d2.utils.events]: \u001b[0m eta: 0:47:09  iter: 6179  total_loss: 1.323  loss_cls: 0.3522  loss_box_reg: 0.529  loss_mask: 0.2892  loss_rpn_cls: 0.03472  loss_rpn_loc: 0.1095  time: 0.9162  data_time: 0.1006  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:40:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:40:54 d2.utils.events]: \u001b[0m eta: 0:46:59  iter: 6199  total_loss: 1.416  loss_cls: 0.3627  loss_box_reg: 0.5598  loss_mask: 0.3104  loss_rpn_cls: 0.04655  loss_rpn_loc: 0.114  time: 0.9167  data_time: 0.2516  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:41:10 d2.utils.events]: \u001b[0m eta: 0:46:49  iter: 6219  total_loss: 1.31  loss_cls: 0.3479  loss_box_reg: 0.5409  loss_mask: 0.2879  loss_rpn_cls: 0.05091  loss_rpn_loc: 0.115  time: 0.9164  data_time: 0.1406  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:41:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:41:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:41:34 d2.utils.events]: \u001b[0m eta: 0:46:32  iter: 6239  total_loss: 1.338  loss_cls: 0.3385  loss_box_reg: 0.5628  loss_mask: 0.2964  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.1083  time: 0.9173  data_time: 0.3135  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:41:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:41:54 d2.utils.events]: \u001b[0m eta: 0:46:19  iter: 6259  total_loss: 1.272  loss_cls: 0.3291  loss_box_reg: 0.5385  loss_mask: 0.2773  loss_rpn_cls: 0.04285  loss_rpn_loc: 0.1002  time: 0.9175  data_time: 0.1666  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:42:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:42:15 d2.utils.events]: \u001b[0m eta: 0:46:02  iter: 6279  total_loss: 1.338  loss_cls: 0.3376  loss_box_reg: 0.5563  loss_mask: 0.3104  loss_rpn_cls: 0.03252  loss_rpn_loc: 0.09966  time: 0.9180  data_time: 0.2241  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:42:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:42:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:42:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:42:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:42:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:42:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:42:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:42:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1497 s/iter. Eval: 0.0587 s/iter. Total: 0.2092 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/09 00:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1546 s/iter. Eval: 0.1211 s/iter. Total: 0.2767 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1547 s/iter. Eval: 0.1363 s/iter. Total: 0.2920 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1532 s/iter. Eval: 0.1380 s/iter. Total: 0.2921 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 00:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1538 s/iter. Eval: 0.1491 s/iter. Total: 0.3039 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/09 00:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1565 s/iter. Eval: 0.1608 s/iter. Total: 0.3183 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0009 s/iter. Inference: 0.1558 s/iter. Eval: 0.1622 s/iter. Total: 0.3189 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 00:43:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.543026 (0.315026 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:43:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.156051 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:43:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:43:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.296539755379015\n",
      "\u001b[32m[02/09 00:43:16 d2.utils.events]: \u001b[0m eta: 0:45:45  iter: 6299  total_loss: 1.434  loss_cls: 0.3621  loss_box_reg: 0.5657  loss_mask: 0.304  loss_rpn_cls: 0.04814  loss_rpn_loc: 0.1094  time: 0.9186  data_time: 0.2882  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:43:33 d2.utils.events]: \u001b[0m eta: 0:45:19  iter: 6319  total_loss: 1.242  loss_cls: 0.2892  loss_box_reg: 0.5488  loss_mask: 0.2834  loss_rpn_cls: 0.03306  loss_rpn_loc: 0.09635  time: 0.9184  data_time: 0.1653  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:43:52 d2.utils.events]: \u001b[0m eta: 0:45:01  iter: 6339  total_loss: 1.25  loss_cls: 0.3245  loss_box_reg: 0.5244  loss_mask: 0.2891  loss_rpn_cls: 0.03498  loss_rpn_loc: 0.105  time: 0.9185  data_time: 0.2574  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:44:08 d2.utils.events]: \u001b[0m eta: 0:44:43  iter: 6359  total_loss: 1.338  loss_cls: 0.3455  loss_box_reg: 0.5502  loss_mask: 0.2943  loss_rpn_cls: 0.03029  loss_rpn_loc: 0.105  time: 0.9182  data_time: 0.1238  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:44:26 d2.utils.events]: \u001b[0m eta: 0:44:28  iter: 6379  total_loss: 1.23  loss_cls: 0.3261  loss_box_reg: 0.5294  loss_mask: 0.2934  loss_rpn_cls: 0.04376  loss_rpn_loc: 0.1049  time: 0.9180  data_time: 0.1595  lr: 0.00016384  max_mem: 9339M\n",
      "\u001b[32m[02/09 00:44:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:44:49 d2.utils.events]: \u001b[0m eta: 0:44:13  iter: 6399  total_loss: 1.262  loss_cls: 0.3135  loss_box_reg: 0.5141  loss_mask: 0.2867  loss_rpn_cls: 0.05132  loss_rpn_loc: 0.089  time: 0.9188  data_time: 0.3208  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:45:04 d2.utils.events]: \u001b[0m eta: 0:43:57  iter: 6419  total_loss: 1.305  loss_cls: 0.332  loss_box_reg: 0.5335  loss_mask: 0.2866  loss_rpn_cls: 0.03151  loss_rpn_loc: 0.09183  time: 0.9183  data_time: 0.0904  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:45:22 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 6439  total_loss: 1.372  loss_cls: 0.3731  loss_box_reg: 0.5496  loss_mask: 0.3063  loss_rpn_cls: 0.04131  loss_rpn_loc: 0.1103  time: 0.9181  data_time: 0.1719  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:45:41 d2.utils.events]: \u001b[0m eta: 0:43:25  iter: 6459  total_loss: 1.319  loss_cls: 0.3418  loss_box_reg: 0.5507  loss_mask: 0.2913  loss_rpn_cls: 0.05172  loss_rpn_loc: 0.1044  time: 0.9182  data_time: 0.2615  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:45:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:46:03 d2.utils.events]: \u001b[0m eta: 0:43:05  iter: 6479  total_loss: 1.485  loss_cls: 0.4035  loss_box_reg: 0.592  loss_mask: 0.3133  loss_rpn_cls: 0.05785  loss_rpn_loc: 0.1432  time: 0.9188  data_time: 0.2794  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:46:19 d2.utils.events]: \u001b[0m eta: 0:42:50  iter: 6499  total_loss: 1.334  loss_cls: 0.3626  loss_box_reg: 0.5484  loss_mask: 0.2932  loss_rpn_cls: 0.05837  loss_rpn_loc: 0.1116  time: 0.9184  data_time: 0.1108  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:46:36 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 6519  total_loss: 1.255  loss_cls: 0.323  loss_box_reg: 0.5198  loss_mask: 0.2779  loss_rpn_cls: 0.03415  loss_rpn_loc: 0.1056  time: 0.9183  data_time: 0.1768  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:46:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:46:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:46:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:46:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:46:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:46:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1389 s/iter. Eval: 0.0530 s/iter. Total: 0.1927 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 00:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1481 s/iter. Eval: 0.1256 s/iter. Total: 0.2746 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1494 s/iter. Eval: 0.1355 s/iter. Total: 0.2859 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 00:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0009 s/iter. Inference: 0.1498 s/iter. Eval: 0.1280 s/iter. Total: 0.2788 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/09 00:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1533 s/iter. Eval: 0.1466 s/iter. Total: 0.3009 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 00:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0009 s/iter. Inference: 0.1551 s/iter. Eval: 0.1548 s/iter. Total: 0.3108 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/09 00:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0009 s/iter. Inference: 0.1537 s/iter. Eval: 0.1512 s/iter. Total: 0.3059 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/09 00:47:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.240985 (0.303802 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:47:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.153953 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:47:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:47:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2982089199921663\n",
      "\u001b[32m[02/09 00:47:32 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 6539  total_loss: 1.361  loss_cls: 0.3558  loss_box_reg: 0.5291  loss_mask: 0.2862  loss_rpn_cls: 0.04623  loss_rpn_loc: 0.1137  time: 0.9183  data_time: 0.2057  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:47:50 d2.utils.events]: \u001b[0m eta: 0:41:55  iter: 6559  total_loss: 1.422  loss_cls: 0.3702  loss_box_reg: 0.5576  loss_mask: 0.3108  loss_rpn_cls: 0.03862  loss_rpn_loc: 0.1198  time: 0.9182  data_time: 0.1703  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:48:05 d2.utils.events]: \u001b[0m eta: 0:41:38  iter: 6579  total_loss: 1.235  loss_cls: 0.3115  loss_box_reg: 0.5272  loss_mask: 0.2847  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.08666  time: 0.9177  data_time: 0.0880  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:48:19 d2.utils.events]: \u001b[0m eta: 0:41:23  iter: 6599  total_loss: 1.23  loss_cls: 0.3159  loss_box_reg: 0.5149  loss_mask: 0.2784  loss_rpn_cls: 0.03392  loss_rpn_loc: 0.1048  time: 0.9171  data_time: 0.0489  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:48:38 d2.utils.events]: \u001b[0m eta: 0:41:07  iter: 6619  total_loss: 1.355  loss_cls: 0.3567  loss_box_reg: 0.5501  loss_mask: 0.2899  loss_rpn_cls: 0.0404  loss_rpn_loc: 0.111  time: 0.9172  data_time: 0.2405  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:48:56 d2.utils.events]: \u001b[0m eta: 0:40:53  iter: 6639  total_loss: 1.402  loss_cls: 0.3606  loss_box_reg: 0.5676  loss_mask: 0.289  loss_rpn_cls: 0.03792  loss_rpn_loc: 0.1128  time: 0.9171  data_time: 0.1947  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:49:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:49:19 d2.utils.events]: \u001b[0m eta: 0:40:34  iter: 6659  total_loss: 1.273  loss_cls: 0.3044  loss_box_reg: 0.5213  loss_mask: 0.2775  loss_rpn_cls: 0.02743  loss_rpn_loc: 0.09683  time: 0.9178  data_time: 0.3486  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:49:36 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 6679  total_loss: 1.306  loss_cls: 0.3217  loss_box_reg: 0.5103  loss_mask: 0.2834  loss_rpn_cls: 0.04086  loss_rpn_loc: 0.121  time: 0.9175  data_time: 0.1448  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:49:53 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 6699  total_loss: 1.401  loss_cls: 0.3466  loss_box_reg: 0.5435  loss_mask: 0.3023  loss_rpn_cls: 0.04245  loss_rpn_loc: 0.1123  time: 0.9175  data_time: 0.2049  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:50:09 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 6719  total_loss: 1.405  loss_cls: 0.3684  loss_box_reg: 0.5491  loss_mask: 0.296  loss_rpn_cls: 0.05536  loss_rpn_loc: 0.1246  time: 0.9171  data_time: 0.0632  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:50:26 d2.utils.events]: \u001b[0m eta: 0:39:39  iter: 6739  total_loss: 1.31  loss_cls: 0.3285  loss_box_reg: 0.523  loss_mask: 0.2958  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.1012  time: 0.9169  data_time: 0.1364  lr: 0.00016384  max_mem: 9357M\n",
      "\u001b[32m[02/09 00:50:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 00:50:49 d2.utils.events]: \u001b[0m eta: 0:39:26  iter: 6759  total_loss: 1.426  loss_cls: 0.3933  loss_box_reg: 0.5714  loss_mask: 0.3012  loss_rpn_cls: 0.04142  loss_rpn_loc: 0.1186  time: 0.9176  data_time: 0.2687  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:51:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:51:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:51:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:51:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:51:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:51:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1378 s/iter. Eval: 0.0498 s/iter. Total: 0.1884 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/09 00:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1468 s/iter. Eval: 0.1242 s/iter. Total: 0.2719 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1516 s/iter. Eval: 0.1373 s/iter. Total: 0.2899 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1486 s/iter. Eval: 0.1272 s/iter. Total: 0.2768 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/09 00:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1520 s/iter. Eval: 0.1463 s/iter. Total: 0.2994 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 00:51:32 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1546 s/iter. Eval: 0.1565 s/iter. Total: 0.3122 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:51:37 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1536 s/iter. Eval: 0.1528 s/iter. Total: 0.3075 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/09 00:51:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.197277 (0.303425 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:51:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.153451 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:51:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:51:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2999020756672049\n",
      "\u001b[32m[02/09 00:51:44 d2.utils.events]: \u001b[0m eta: 0:39:12  iter: 6779  total_loss: 1.387  loss_cls: 0.3651  loss_box_reg: 0.5568  loss_mask: 0.2939  loss_rpn_cls: 0.06009  loss_rpn_loc: 0.12  time: 0.9175  data_time: 0.1811  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:52:04 d2.utils.events]: \u001b[0m eta: 0:38:58  iter: 6799  total_loss: 1.429  loss_cls: 0.3715  loss_box_reg: 0.5844  loss_mask: 0.2974  loss_rpn_cls: 0.05035  loss_rpn_loc: 0.1069  time: 0.9177  data_time: 0.2521  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:52:21 d2.utils.events]: \u001b[0m eta: 0:38:41  iter: 6819  total_loss: 1.302  loss_cls: 0.3436  loss_box_reg: 0.5594  loss_mask: 0.2891  loss_rpn_cls: 0.02804  loss_rpn_loc: 0.1034  time: 0.9174  data_time: 0.1394  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:52:39 d2.utils.events]: \u001b[0m eta: 0:38:27  iter: 6839  total_loss: 1.29  loss_cls: 0.3502  loss_box_reg: 0.4988  loss_mask: 0.2863  loss_rpn_cls: 0.0448  loss_rpn_loc: 0.09657  time: 0.9174  data_time: 0.1977  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:52:55 d2.utils.events]: \u001b[0m eta: 0:38:12  iter: 6859  total_loss: 1.405  loss_cls: 0.3756  loss_box_reg: 0.5461  loss_mask: 0.3055  loss_rpn_cls: 0.04311  loss_rpn_loc: 0.1143  time: 0.9170  data_time: 0.1044  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:53:10 d2.utils.events]: \u001b[0m eta: 0:37:57  iter: 6879  total_loss: 1.275  loss_cls: 0.3198  loss_box_reg: 0.5191  loss_mask: 0.2737  loss_rpn_cls: 0.04191  loss_rpn_loc: 0.1061  time: 0.9166  data_time: 0.0751  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:53:27 d2.utils.events]: \u001b[0m eta: 0:37:43  iter: 6899  total_loss: 1.197  loss_cls: 0.3059  loss_box_reg: 0.502  loss_mask: 0.2845  loss_rpn_cls: 0.03767  loss_rpn_loc: 0.07216  time: 0.9164  data_time: 0.1504  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:53:44 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 6919  total_loss: 1.361  loss_cls: 0.3456  loss_box_reg: 0.5564  loss_mask: 0.2857  loss_rpn_cls: 0.03988  loss_rpn_loc: 0.12  time: 0.9162  data_time: 0.1758  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:54:05 d2.utils.events]: \u001b[0m eta: 0:37:11  iter: 6939  total_loss: 1.312  loss_cls: 0.3257  loss_box_reg: 0.5475  loss_mask: 0.2988  loss_rpn_cls: 0.0482  loss_rpn_loc: 0.1142  time: 0.9166  data_time: 0.3378  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:54:21 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 6959  total_loss: 1.234  loss_cls: 0.3273  loss_box_reg: 0.5259  loss_mask: 0.2688  loss_rpn_cls: 0.0442  loss_rpn_loc: 0.09112  time: 0.9162  data_time: 0.1254  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:54:43 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 6979  total_loss: 1.393  loss_cls: 0.3751  loss_box_reg: 0.5391  loss_mask: 0.2936  loss_rpn_cls: 0.03755  loss_rpn_loc: 0.1092  time: 0.9167  data_time: 0.3807  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:55:01 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 6999  total_loss: 1.406  loss_cls: 0.3665  loss_box_reg: 0.5789  loss_mask: 0.3115  loss_rpn_cls: 0.05382  loss_rpn_loc: 0.1181  time: 0.9168  data_time: 0.2216  lr: 0.00016384  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:55:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:55:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:55:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:55:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:55:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:55:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1450 s/iter. Eval: 0.0553 s/iter. Total: 0.2010 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1488 s/iter. Eval: 0.1299 s/iter. Total: 0.2797 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1523 s/iter. Eval: 0.1411 s/iter. Total: 0.2944 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0009 s/iter. Inference: 0.1490 s/iter. Eval: 0.1309 s/iter. Total: 0.2809 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/09 00:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1526 s/iter. Eval: 0.1511 s/iter. Total: 0.3048 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 00:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1552 s/iter. Eval: 0.1607 s/iter. Total: 0.3169 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 00:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1543 s/iter. Eval: 0.1579 s/iter. Total: 0.3132 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/09 00:55:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.701034 (0.307768 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:55:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.153916 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 00:55:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 00:55:53 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3012485002187839\n",
      "\u001b[32m[02/09 00:55:54 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 7019  total_loss: 1.226  loss_cls: 0.2956  loss_box_reg: 0.5404  loss_mask: 0.2822  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.08295  time: 0.9163  data_time: 0.0468  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:56:16 d2.utils.events]: \u001b[0m eta: 0:35:55  iter: 7039  total_loss: 1.602  loss_cls: 0.4208  loss_box_reg: 0.6099  loss_mask: 0.3316  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.1395  time: 0.9168  data_time: 0.3625  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:56:35 d2.utils.events]: \u001b[0m eta: 0:35:38  iter: 7059  total_loss: 1.376  loss_cls: 0.3738  loss_box_reg: 0.5614  loss_mask: 0.3127  loss_rpn_cls: 0.04307  loss_rpn_loc: 0.1139  time: 0.9169  data_time: 0.2649  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:56:51 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 7079  total_loss: 1.333  loss_cls: 0.34  loss_box_reg: 0.5364  loss_mask: 0.2882  loss_rpn_cls: 0.03758  loss_rpn_loc: 0.1071  time: 0.9166  data_time: 0.1363  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:57:07 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 7099  total_loss: 1.325  loss_cls: 0.3567  loss_box_reg: 0.5355  loss_mask: 0.2787  loss_rpn_cls: 0.04597  loss_rpn_loc: 0.1111  time: 0.9163  data_time: 0.0966  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:57:24 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 7119  total_loss: 1.311  loss_cls: 0.3203  loss_box_reg: 0.5394  loss_mask: 0.3039  loss_rpn_cls: 0.02821  loss_rpn_loc: 0.09066  time: 0.9160  data_time: 0.1362  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:57:40 d2.utils.events]: \u001b[0m eta: 0:34:44  iter: 7139  total_loss: 1.367  loss_cls: 0.3374  loss_box_reg: 0.5618  loss_mask: 0.3092  loss_rpn_cls: 0.0436  loss_rpn_loc: 0.1098  time: 0.9157  data_time: 0.1017  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:57:58 d2.utils.events]: \u001b[0m eta: 0:34:30  iter: 7159  total_loss: 1.371  loss_cls: 0.362  loss_box_reg: 0.5437  loss_mask: 0.2919  loss_rpn_cls: 0.04561  loss_rpn_loc: 0.114  time: 0.9156  data_time: 0.1991  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:58:13 d2.utils.events]: \u001b[0m eta: 0:34:16  iter: 7179  total_loss: 1.317  loss_cls: 0.3382  loss_box_reg: 0.5234  loss_mask: 0.2903  loss_rpn_cls: 0.04226  loss_rpn_loc: 0.09892  time: 0.9151  data_time: 0.0696  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:58:30 d2.utils.events]: \u001b[0m eta: 0:33:59  iter: 7199  total_loss: 1.333  loss_cls: 0.3334  loss_box_reg: 0.5262  loss_mask: 0.3015  loss_rpn_cls: 0.03664  loss_rpn_loc: 0.1111  time: 0.9150  data_time: 0.1992  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:58:52 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 7219  total_loss: 1.42  loss_cls: 0.3925  loss_box_reg: 0.5757  loss_mask: 0.3093  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.1247  time: 0.9156  data_time: 0.3914  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:59:11 d2.utils.events]: \u001b[0m eta: 0:33:33  iter: 7239  total_loss: 1.288  loss_cls: 0.3257  loss_box_reg: 0.5277  loss_mask: 0.2853  loss_rpn_cls: 0.03686  loss_rpn_loc: 0.1066  time: 0.9156  data_time: 0.2247  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 00:59:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:59:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 00:59:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 00:59:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 00:59:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 00:59:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 00:59:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1446 s/iter. Eval: 0.0535 s/iter. Total: 0.1989 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 00:59:36 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1498 s/iter. Eval: 0.1295 s/iter. Total: 0.2803 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 00:59:41 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1518 s/iter. Eval: 0.1422 s/iter. Total: 0.2950 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 00:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0009 s/iter. Inference: 0.1490 s/iter. Eval: 0.1319 s/iter. Total: 0.2819 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/09 00:59:52 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1526 s/iter. Eval: 0.1550 s/iter. Total: 0.3086 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 00:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1560 s/iter. Eval: 0.1665 s/iter. Total: 0.3235 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 01:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0010 s/iter. Inference: 0.1561 s/iter. Eval: 0.1658 s/iter. Total: 0.3230 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 01:00:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.673922 (0.316154 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:00:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.155724 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:00:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:00:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2971562731857238\n",
      "\u001b[32m[02/09 01:00:06 d2.utils.events]: \u001b[0m eta: 0:33:16  iter: 7259  total_loss: 1.23  loss_cls: 0.3256  loss_box_reg: 0.5169  loss_mask: 0.3002  loss_rpn_cls: 0.03896  loss_rpn_loc: 0.105  time: 0.9153  data_time: 0.1376  lr: 0.00013107  max_mem: 9446M\n",
      "\u001b[32m[02/09 01:00:27 d2.utils.events]: \u001b[0m eta: 0:33:04  iter: 7279  total_loss: 1.323  loss_cls: 0.3311  loss_box_reg: 0.529  loss_mask: 0.2812  loss_rpn_cls: 0.03807  loss_rpn_loc: 0.1104  time: 0.9157  data_time: 0.3228  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:00:47 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 7299  total_loss: 1.377  loss_cls: 0.3511  loss_box_reg: 0.55  loss_mask: 0.3042  loss_rpn_cls: 0.04882  loss_rpn_loc: 0.1145  time: 0.9160  data_time: 0.2965  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:01:03 d2.utils.events]: \u001b[0m eta: 0:32:34  iter: 7319  total_loss: 1.236  loss_cls: 0.3269  loss_box_reg: 0.5292  loss_mask: 0.2935  loss_rpn_cls: 0.03764  loss_rpn_loc: 0.09811  time: 0.9156  data_time: 0.1366  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:01:20 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 7339  total_loss: 1.352  loss_cls: 0.3592  loss_box_reg: 0.5489  loss_mask: 0.2845  loss_rpn_cls: 0.0411  loss_rpn_loc: 0.1076  time: 0.9154  data_time: 0.1422  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:01:35 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 7359  total_loss: 1.329  loss_cls: 0.3546  loss_box_reg: 0.5547  loss_mask: 0.2937  loss_rpn_cls: 0.03423  loss_rpn_loc: 0.08593  time: 0.9149  data_time: 0.0684  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:01:53 d2.utils.events]: \u001b[0m eta: 0:31:45  iter: 7379  total_loss: 1.397  loss_cls: 0.3652  loss_box_reg: 0.5777  loss_mask: 0.3039  loss_rpn_cls: 0.0451  loss_rpn_loc: 0.1209  time: 0.9149  data_time: 0.1778  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:01:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:02:17 d2.utils.events]: \u001b[0m eta: 0:31:32  iter: 7399  total_loss: 1.349  loss_cls: 0.3515  loss_box_reg: 0.5398  loss_mask: 0.2906  loss_rpn_cls: 0.05005  loss_rpn_loc: 0.121  time: 0.9156  data_time: 0.3636  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:02:32 d2.utils.events]: \u001b[0m eta: 0:31:16  iter: 7419  total_loss: 1.23  loss_cls: 0.3067  loss_box_reg: 0.5295  loss_mask: 0.2937  loss_rpn_cls: 0.03084  loss_rpn_loc: 0.088  time: 0.9152  data_time: 0.1049  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:02:48 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 7439  total_loss: 1.33  loss_cls: 0.3312  loss_box_reg: 0.5671  loss_mask: 0.2877  loss_rpn_cls: 0.03228  loss_rpn_loc: 0.1155  time: 0.9150  data_time: 0.1243  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:03:07 d2.utils.events]: \u001b[0m eta: 0:30:53  iter: 7459  total_loss: 1.318  loss_cls: 0.3473  loss_box_reg: 0.525  loss_mask: 0.3066  loss_rpn_cls: 0.04982  loss_rpn_loc: 0.1085  time: 0.9150  data_time: 0.1927  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:03:22 d2.utils.events]: \u001b[0m eta: 0:30:35  iter: 7479  total_loss: 1.252  loss_cls: 0.3409  loss_box_reg: 0.52  loss_mask: 0.2798  loss_rpn_cls: 0.02887  loss_rpn_loc: 0.08938  time: 0.9146  data_time: 0.0796  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:03:40 d2.utils.events]: \u001b[0m eta: 0:30:21  iter: 7499  total_loss: 1.446  loss_cls: 0.3747  loss_box_reg: 0.5528  loss_mask: 0.3053  loss_rpn_cls: 0.05235  loss_rpn_loc: 0.1188  time: 0.9145  data_time: 0.1498  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:03:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:03:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:03:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:03:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:03:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:03:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:03:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1458 s/iter. Eval: 0.0587 s/iter. Total: 0.2054 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:03:50 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1516 s/iter. Eval: 0.1325 s/iter. Total: 0.2851 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/09 01:03:55 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1529 s/iter. Eval: 0.1456 s/iter. Total: 0.2995 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:04:00 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1509 s/iter. Eval: 0.1362 s/iter. Total: 0.2882 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 01:04:05 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1531 s/iter. Eval: 0.1479 s/iter. Total: 0.3021 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:04:10 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1557 s/iter. Eval: 0.1592 s/iter. Total: 0.3160 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 01:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1557 s/iter. Eval: 0.1621 s/iter. Total: 0.3188 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 01:04:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.298055 (0.312914 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:04:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.155314 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:04:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:04:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29800839426537346\n",
      "\u001b[32m[02/09 01:04:38 d2.utils.events]: \u001b[0m eta: 0:30:10  iter: 7519  total_loss: 1.336  loss_cls: 0.3661  loss_box_reg: 0.5575  loss_mask: 0.2989  loss_rpn_cls: 0.0534  loss_rpn_loc: 0.09573  time: 0.9147  data_time: 0.2826  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:04:54 d2.utils.events]: \u001b[0m eta: 0:29:53  iter: 7539  total_loss: 1.215  loss_cls: 0.3115  loss_box_reg: 0.5025  loss_mask: 0.2746  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.096  time: 0.9144  data_time: 0.1021  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:05:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:05:16 d2.utils.events]: \u001b[0m eta: 0:29:38  iter: 7559  total_loss: 1.27  loss_cls: 0.3388  loss_box_reg: 0.5146  loss_mask: 0.287  loss_rpn_cls: 0.03817  loss_rpn_loc: 0.1146  time: 0.9149  data_time: 0.2715  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:05:33 d2.utils.events]: \u001b[0m eta: 0:29:25  iter: 7579  total_loss: 1.119  loss_cls: 0.272  loss_box_reg: 0.489  loss_mask: 0.2734  loss_rpn_cls: 0.02593  loss_rpn_loc: 0.07719  time: 0.9147  data_time: 0.1337  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:05:49 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 7599  total_loss: 1.302  loss_cls: 0.3256  loss_box_reg: 0.5184  loss_mask: 0.2827  loss_rpn_cls: 0.04561  loss_rpn_loc: 0.1038  time: 0.9144  data_time: 0.1138  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:05:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:06:09 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 7619  total_loss: 1.403  loss_cls: 0.363  loss_box_reg: 0.5675  loss_mask: 0.2898  loss_rpn_cls: 0.04151  loss_rpn_loc: 0.102  time: 0.9147  data_time: 0.1990  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:06:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:06:32 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 7639  total_loss: 1.397  loss_cls: 0.3661  loss_box_reg: 0.5508  loss_mask: 0.3012  loss_rpn_cls: 0.04711  loss_rpn_loc: 0.1275  time: 0.9152  data_time: 0.2555  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:06:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:06:52 d2.utils.events]: \u001b[0m eta: 0:28:30  iter: 7659  total_loss: 1.356  loss_cls: 0.331  loss_box_reg: 0.5573  loss_mask: 0.2901  loss_rpn_cls: 0.03489  loss_rpn_loc: 0.1098  time: 0.9154  data_time: 0.2008  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:07:09 d2.utils.events]: \u001b[0m eta: 0:28:18  iter: 7679  total_loss: 1.401  loss_cls: 0.3677  loss_box_reg: 0.5635  loss_mask: 0.306  loss_rpn_cls: 0.04638  loss_rpn_loc: 0.1255  time: 0.9153  data_time: 0.1442  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:07:28 d2.utils.events]: \u001b[0m eta: 0:28:02  iter: 7699  total_loss: 1.346  loss_cls: 0.3479  loss_box_reg: 0.5648  loss_mask: 0.3108  loss_rpn_cls: 0.03861  loss_rpn_loc: 0.1202  time: 0.9154  data_time: 0.2524  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:07:45 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 7719  total_loss: 1.344  loss_cls: 0.3608  loss_box_reg: 0.5485  loss_mask: 0.2917  loss_rpn_cls: 0.04468  loss_rpn_loc: 0.112  time: 0.9153  data_time: 0.1482  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:08:01 d2.utils.events]: \u001b[0m eta: 0:27:30  iter: 7739  total_loss: 1.264  loss_cls: 0.3161  loss_box_reg: 0.527  loss_mask: 0.2868  loss_rpn_cls: 0.03964  loss_rpn_loc: 0.09076  time: 0.9150  data_time: 0.0967  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:08:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:08:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:08:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:08:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:08:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:08:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1447 s/iter. Eval: 0.0578 s/iter. Total: 0.2033 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:08:15 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1499 s/iter. Eval: 0.1256 s/iter. Total: 0.2765 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 01:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1500 s/iter. Eval: 0.1356 s/iter. Total: 0.2866 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0009 s/iter. Inference: 0.1492 s/iter. Eval: 0.1266 s/iter. Total: 0.2768 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/09 01:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1520 s/iter. Eval: 0.1459 s/iter. Total: 0.2989 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0010 s/iter. Inference: 0.1542 s/iter. Eval: 0.1539 s/iter. Total: 0.3091 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/09 01:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1536 s/iter. Eval: 0.1526 s/iter. Total: 0.3072 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/09 01:08:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.484487 (0.305901 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:08:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.154051 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:08:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:08:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29803916073830866\n",
      "\u001b[32m[02/09 01:08:57 d2.utils.events]: \u001b[0m eta: 0:27:15  iter: 7759  total_loss: 1.373  loss_cls: 0.3591  loss_box_reg: 0.5676  loss_mask: 0.2973  loss_rpn_cls: 0.04573  loss_rpn_loc: 0.1197  time: 0.9148  data_time: 0.1644  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:09:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:09:18 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 7779  total_loss: 1.4  loss_cls: 0.369  loss_box_reg: 0.5587  loss_mask: 0.3007  loss_rpn_cls: 0.05199  loss_rpn_loc: 0.113  time: 0.9152  data_time: 0.1874  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:09:41 d2.utils.events]: \u001b[0m eta: 0:26:45  iter: 7799  total_loss: 1.381  loss_cls: 0.3572  loss_box_reg: 0.5409  loss_mask: 0.3033  loss_rpn_cls: 0.05437  loss_rpn_loc: 0.1215  time: 0.9158  data_time: 0.4360  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:09:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:10:01 d2.utils.events]: \u001b[0m eta: 0:26:32  iter: 7819  total_loss: 1.306  loss_cls: 0.3632  loss_box_reg: 0.5253  loss_mask: 0.2883  loss_rpn_cls: 0.04359  loss_rpn_loc: 0.1057  time: 0.9160  data_time: 0.1924  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:10:19 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 7839  total_loss: 1.3  loss_cls: 0.3459  loss_box_reg: 0.5386  loss_mask: 0.2995  loss_rpn_cls: 0.0269  loss_rpn_loc: 0.08011  time: 0.9160  data_time: 0.1781  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:10:34 d2.utils.events]: \u001b[0m eta: 0:26:01  iter: 7859  total_loss: 1.265  loss_cls: 0.3158  loss_box_reg: 0.5315  loss_mask: 0.2823  loss_rpn_cls: 0.03298  loss_rpn_loc: 0.0903  time: 0.9157  data_time: 0.1124  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:10:59 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 7879  total_loss: 1.333  loss_cls: 0.3536  loss_box_reg: 0.5547  loss_mask: 0.2921  loss_rpn_cls: 0.0502  loss_rpn_loc: 0.1165  time: 0.9164  data_time: 0.4629  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:11:13 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 7899  total_loss: 1.282  loss_cls: 0.314  loss_box_reg: 0.5369  loss_mask: 0.2817  loss_rpn_cls: 0.0372  loss_rpn_loc: 0.1098  time: 0.9159  data_time: 0.0338  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:11:31 d2.utils.events]: \u001b[0m eta: 0:25:17  iter: 7919  total_loss: 1.292  loss_cls: 0.3286  loss_box_reg: 0.5367  loss_mask: 0.2848  loss_rpn_cls: 0.03165  loss_rpn_loc: 0.09282  time: 0.9158  data_time: 0.2020  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:11:49 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 7939  total_loss: 1.348  loss_cls: 0.3663  loss_box_reg: 0.5569  loss_mask: 0.3061  loss_rpn_cls: 0.0459  loss_rpn_loc: 0.1048  time: 0.9158  data_time: 0.2059  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:12:07 d2.utils.events]: \u001b[0m eta: 0:24:49  iter: 7959  total_loss: 1.231  loss_cls: 0.3298  loss_box_reg: 0.5088  loss_mask: 0.2687  loss_rpn_cls: 0.03309  loss_rpn_loc: 0.107  time: 0.9157  data_time: 0.1958  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:12:22 d2.utils.events]: \u001b[0m eta: 0:24:34  iter: 7979  total_loss: 1.355  loss_cls: 0.3479  loss_box_reg: 0.5461  loss_mask: 0.2941  loss_rpn_cls: 0.0466  loss_rpn_loc: 0.1266  time: 0.9153  data_time: 0.0638  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:12:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:12:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:12:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:12:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:12:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:12:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1426 s/iter. Eval: 0.0562 s/iter. Total: 0.1996 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:12:37 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0010 s/iter. Inference: 0.1504 s/iter. Eval: 0.1235 s/iter. Total: 0.2749 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 01:12:42 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0010 s/iter. Inference: 0.1519 s/iter. Eval: 0.1388 s/iter. Total: 0.2917 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:12:47 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0010 s/iter. Inference: 0.1512 s/iter. Eval: 0.1400 s/iter. Total: 0.2922 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 01:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1520 s/iter. Eval: 0.1506 s/iter. Total: 0.3037 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/09 01:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1551 s/iter. Eval: 0.1628 s/iter. Total: 0.3190 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 01:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1549 s/iter. Eval: 0.1657 s/iter. Total: 0.3217 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 01:13:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.620142 (0.315691 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:13:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.154473 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:13:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:13:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2969727230403689\n",
      "\u001b[32m[02/09 01:13:18 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 7999  total_loss: 1.32  loss_cls: 0.3535  loss_box_reg: 0.552  loss_mask: 0.3044  loss_rpn_cls: 0.04504  loss_rpn_loc: 0.1183  time: 0.9153  data_time: 0.1927  lr: 0.00013107  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:13:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:13:42 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 8019  total_loss: 1.426  loss_cls: 0.3811  loss_box_reg: 0.5607  loss_mask: 0.3145  loss_rpn_cls: 0.0521  loss_rpn_loc: 0.1197  time: 0.9159  data_time: 0.3342  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:13:58 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 8039  total_loss: 1.211  loss_cls: 0.2857  loss_box_reg: 0.5279  loss_mask: 0.2733  loss_rpn_cls: 0.03047  loss_rpn_loc: 0.09086  time: 0.9156  data_time: 0.1197  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:14:18 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 8059  total_loss: 1.401  loss_cls: 0.3683  loss_box_reg: 0.5485  loss_mask: 0.3045  loss_rpn_cls: 0.05601  loss_rpn_loc: 0.1162  time: 0.9158  data_time: 0.2793  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:14:38 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 8079  total_loss: 1.347  loss_cls: 0.355  loss_box_reg: 0.5425  loss_mask: 0.2904  loss_rpn_cls: 0.04961  loss_rpn_loc: 0.1125  time: 0.9160  data_time: 0.2770  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:14:53 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 8099  total_loss: 1.275  loss_cls: 0.3363  loss_box_reg: 0.5367  loss_mask: 0.2964  loss_rpn_cls: 0.02854  loss_rpn_loc: 0.1027  time: 0.9157  data_time: 0.1083  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:14:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:15:14 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 8119  total_loss: 1.364  loss_cls: 0.3451  loss_box_reg: 0.5534  loss_mask: 0.2832  loss_rpn_cls: 0.03419  loss_rpn_loc: 0.119  time: 0.9159  data_time: 0.1937  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:15:31 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 8139  total_loss: 1.248  loss_cls: 0.323  loss_box_reg: 0.5239  loss_mask: 0.2771  loss_rpn_cls: 0.02761  loss_rpn_loc: 0.08808  time: 0.9158  data_time: 0.1757  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:15:46 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 8159  total_loss: 1.273  loss_cls: 0.3314  loss_box_reg: 0.5183  loss_mask: 0.2879  loss_rpn_cls: 0.03492  loss_rpn_loc: 0.08599  time: 0.9154  data_time: 0.1015  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:16:03 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 8179  total_loss: 1.273  loss_cls: 0.3327  loss_box_reg: 0.5206  loss_mask: 0.282  loss_rpn_cls: 0.04207  loss_rpn_loc: 0.09858  time: 0.9153  data_time: 0.1676  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:16:20 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 8199  total_loss: 1.366  loss_cls: 0.3618  loss_box_reg: 0.5731  loss_mask: 0.3062  loss_rpn_cls: 0.04889  loss_rpn_loc: 0.108  time: 0.9151  data_time: 0.1379  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:16:37 d2.utils.events]: \u001b[0m eta: 0:21:37  iter: 8219  total_loss: 1.378  loss_cls: 0.3582  loss_box_reg: 0.5489  loss_mask: 0.2978  loss_rpn_cls: 0.02964  loss_rpn_loc: 0.1171  time: 0.9149  data_time: 0.1091  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:16:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:16:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:16:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:16:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:16:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:16:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1401 s/iter. Eval: 0.0541 s/iter. Total: 0.1951 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1489 s/iter. Eval: 0.1273 s/iter. Total: 0.2772 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 01:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0010 s/iter. Inference: 0.1497 s/iter. Eval: 0.1365 s/iter. Total: 0.2873 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0010 s/iter. Inference: 0.1479 s/iter. Eval: 0.1277 s/iter. Total: 0.2767 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/09 01:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1517 s/iter. Eval: 0.1511 s/iter. Total: 0.3039 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1547 s/iter. Eval: 0.1624 s/iter. Total: 0.3182 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 01:17:20 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1534 s/iter. Eval: 0.1582 s/iter. Total: 0.3127 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/09 01:17:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.812014 (0.308724 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:17:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.153500 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:17:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:17:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3009452241742924\n",
      "\u001b[32m[02/09 01:17:32 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 8239  total_loss: 1.305  loss_cls: 0.3439  loss_box_reg: 0.5414  loss_mask: 0.2879  loss_rpn_cls: 0.03607  loss_rpn_loc: 0.1224  time: 0.9148  data_time: 0.1498  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:17:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:17:51 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 8259  total_loss: 1.298  loss_cls: 0.3293  loss_box_reg: 0.5313  loss_mask: 0.2937  loss_rpn_cls: 0.03146  loss_rpn_loc: 0.1004  time: 0.9149  data_time: 0.1658  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:18:11 d2.utils.events]: \u001b[0m eta: 0:20:54  iter: 8279  total_loss: 1.327  loss_cls: 0.337  loss_box_reg: 0.5277  loss_mask: 0.2927  loss_rpn_cls: 0.03775  loss_rpn_loc: 0.1108  time: 0.9150  data_time: 0.2409  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:18:29 d2.utils.events]: \u001b[0m eta: 0:20:40  iter: 8299  total_loss: 1.399  loss_cls: 0.3642  loss_box_reg: 0.5651  loss_mask: 0.3106  loss_rpn_cls: 0.04243  loss_rpn_loc: 0.09704  time: 0.9150  data_time: 0.1932  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:18:46 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 8319  total_loss: 1.238  loss_cls: 0.3214  loss_box_reg: 0.5367  loss_mask: 0.3002  loss_rpn_cls: 0.0421  loss_rpn_loc: 0.1103  time: 0.9148  data_time: 0.1103  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:19:02 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 8339  total_loss: 1.367  loss_cls: 0.3586  loss_box_reg: 0.5644  loss_mask: 0.2895  loss_rpn_cls: 0.03431  loss_rpn_loc: 0.1197  time: 0.9146  data_time: 0.1153  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:19:23 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 8359  total_loss: 1.355  loss_cls: 0.3529  loss_box_reg: 0.5401  loss_mask: 0.3002  loss_rpn_cls: 0.05141  loss_rpn_loc: 0.1246  time: 0.9149  data_time: 0.3023  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:19:40 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 8379  total_loss: 1.278  loss_cls: 0.329  loss_box_reg: 0.5197  loss_mask: 0.2901  loss_rpn_cls: 0.03107  loss_rpn_loc: 0.1003  time: 0.9147  data_time: 0.1275  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:19:56 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 8399  total_loss: 1.237  loss_cls: 0.3125  loss_box_reg: 0.4943  loss_mask: 0.2837  loss_rpn_cls: 0.0435  loss_rpn_loc: 0.09181  time: 0.9144  data_time: 0.0930  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:20:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:20:19 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 8419  total_loss: 1.3  loss_cls: 0.3501  loss_box_reg: 0.5647  loss_mask: 0.3023  loss_rpn_cls: 0.03589  loss_rpn_loc: 0.08983  time: 0.9150  data_time: 0.3132  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:20:37 d2.utils.events]: \u001b[0m eta: 0:19:06  iter: 8439  total_loss: 1.292  loss_cls: 0.3108  loss_box_reg: 0.5327  loss_mask: 0.3023  loss_rpn_cls: 0.03069  loss_rpn_loc: 0.1062  time: 0.9150  data_time: 0.1685  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:20:53 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 8459  total_loss: 1.204  loss_cls: 0.3216  loss_box_reg: 0.5164  loss_mask: 0.2766  loss_rpn_cls: 0.02813  loss_rpn_loc: 0.07679  time: 0.9147  data_time: 0.0970  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:21:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:21:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:21:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:21:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:21:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:21:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1456 s/iter. Eval: 0.0527 s/iter. Total: 0.1991 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1542 s/iter. Eval: 0.1283 s/iter. Total: 0.2836 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/09 01:21:18 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1564 s/iter. Eval: 0.1402 s/iter. Total: 0.2977 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:21:23 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1566 s/iter. Eval: 0.1315 s/iter. Total: 0.2891 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 01:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1590 s/iter. Eval: 0.1493 s/iter. Total: 0.3093 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1616 s/iter. Eval: 0.1600 s/iter. Total: 0.3227 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 01:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1606 s/iter. Eval: 0.1577 s/iter. Total: 0.3193 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/09 01:21:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.420698 (0.313972 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:21:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.160096 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:21:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:21:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30032015958767494\n",
      "\u001b[32m[02/09 01:21:54 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 8479  total_loss: 1.272  loss_cls: 0.3219  loss_box_reg: 0.5171  loss_mask: 0.2817  loss_rpn_cls: 0.04062  loss_rpn_loc: 0.09828  time: 0.9151  data_time: 0.3186  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:22:15 d2.utils.events]: \u001b[0m eta: 0:18:22  iter: 8499  total_loss: 1.443  loss_cls: 0.3858  loss_box_reg: 0.5471  loss_mask: 0.2901  loss_rpn_cls: 0.06578  loss_rpn_loc: 0.1262  time: 0.9155  data_time: 0.3296  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:22:35 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 8519  total_loss: 1.293  loss_cls: 0.3378  loss_box_reg: 0.5269  loss_mask: 0.2999  loss_rpn_cls: 0.04001  loss_rpn_loc: 0.1081  time: 0.9157  data_time: 0.2068  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:22:53 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 8539  total_loss: 1.419  loss_cls: 0.372  loss_box_reg: 0.5863  loss_mask: 0.2926  loss_rpn_cls: 0.05945  loss_rpn_loc: 0.1184  time: 0.9157  data_time: 0.1883  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:23:10 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 8559  total_loss: 1.383  loss_cls: 0.3543  loss_box_reg: 0.5492  loss_mask: 0.2944  loss_rpn_cls: 0.04089  loss_rpn_loc: 0.1172  time: 0.9155  data_time: 0.1092  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:23:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:23:31 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 8579  total_loss: 1.298  loss_cls: 0.3151  loss_box_reg: 0.5486  loss_mask: 0.2984  loss_rpn_cls: 0.04198  loss_rpn_loc: 0.1066  time: 0.9158  data_time: 0.2154  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:23:49 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 8599  total_loss: 1.314  loss_cls: 0.3458  loss_box_reg: 0.5118  loss_mask: 0.2962  loss_rpn_cls: 0.02943  loss_rpn_loc: 0.1095  time: 0.9158  data_time: 0.1749  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:24:07 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 8619  total_loss: 1.276  loss_cls: 0.3534  loss_box_reg: 0.5501  loss_mask: 0.2961  loss_rpn_cls: 0.03948  loss_rpn_loc: 0.07824  time: 0.9157  data_time: 0.1751  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:24:22 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 8639  total_loss: 1.236  loss_cls: 0.3219  loss_box_reg: 0.525  loss_mask: 0.278  loss_rpn_cls: 0.02577  loss_rpn_loc: 0.08693  time: 0.9154  data_time: 0.0857  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:24:43 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 8659  total_loss: 1.305  loss_cls: 0.3482  loss_box_reg: 0.5205  loss_mask: 0.3023  loss_rpn_cls: 0.0422  loss_rpn_loc: 0.118  time: 0.9157  data_time: 0.2809  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:24:59 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 8679  total_loss: 1.288  loss_cls: 0.3406  loss_box_reg: 0.5296  loss_mask: 0.2881  loss_rpn_cls: 0.03208  loss_rpn_loc: 0.09333  time: 0.9154  data_time: 0.1367  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:25:15 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 8699  total_loss: 1.162  loss_cls: 0.2878  loss_box_reg: 0.501  loss_mask: 0.2744  loss_rpn_cls: 0.03003  loss_rpn_loc: 0.07234  time: 0.9152  data_time: 0.0941  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:25:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:25:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:25:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:25:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:25:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:25:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1466 s/iter. Eval: 0.0549 s/iter. Total: 0.2023 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0010 s/iter. Inference: 0.1526 s/iter. Eval: 0.1188 s/iter. Total: 0.2724 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 01:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0010 s/iter. Inference: 0.1555 s/iter. Eval: 0.1348 s/iter. Total: 0.2913 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0010 s/iter. Inference: 0.1529 s/iter. Eval: 0.1356 s/iter. Total: 0.2896 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 01:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1535 s/iter. Eval: 0.1461 s/iter. Total: 0.3006 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1557 s/iter. Eval: 0.1570 s/iter. Total: 0.3137 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 01:26:01 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1565 s/iter. Eval: 0.1592 s/iter. Total: 0.3167 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 01:26:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.982887 (0.310197 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:26:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.155559 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:26:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:26:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29941777647082646\n",
      "\u001b[32m[02/09 01:26:12 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 8719  total_loss: 1.331  loss_cls: 0.343  loss_box_reg: 0.5358  loss_mask: 0.2911  loss_rpn_cls: 0.03429  loss_rpn_loc: 0.1017  time: 0.9151  data_time: 0.2051  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:26:27 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 8739  total_loss: 1.293  loss_cls: 0.3244  loss_box_reg: 0.5476  loss_mask: 0.2803  loss_rpn_cls: 0.03154  loss_rpn_loc: 0.09318  time: 0.9149  data_time: 0.1148  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:26:43 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 8759  total_loss: 1.221  loss_cls: 0.3063  loss_box_reg: 0.5067  loss_mask: 0.2736  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.09373  time: 0.9145  data_time: 0.1010  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:26:59 d2.utils.events]: \u001b[0m eta: 0:14:56  iter: 8779  total_loss: 1.331  loss_cls: 0.3344  loss_box_reg: 0.5458  loss_mask: 0.3094  loss_rpn_cls: 0.04197  loss_rpn_loc: 0.1002  time: 0.9143  data_time: 0.1049  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:27:16 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 8799  total_loss: 1.357  loss_cls: 0.3661  loss_box_reg: 0.5287  loss_mask: 0.2822  loss_rpn_cls: 0.03636  loss_rpn_loc: 0.1091  time: 0.9141  data_time: 0.1374  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:27:37 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 8819  total_loss: 1.354  loss_cls: 0.3325  loss_box_reg: 0.5464  loss_mask: 0.2934  loss_rpn_cls: 0.04345  loss_rpn_loc: 0.1122  time: 0.9144  data_time: 0.3051  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:27:53 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 8839  total_loss: 1.268  loss_cls: 0.2958  loss_box_reg: 0.5247  loss_mask: 0.2854  loss_rpn_cls: 0.03404  loss_rpn_loc: 0.0737  time: 0.9141  data_time: 0.1324  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:28:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:28:16 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 8859  total_loss: 1.209  loss_cls: 0.3054  loss_box_reg: 0.5277  loss_mask: 0.2898  loss_rpn_cls: 0.0297  loss_rpn_loc: 0.09225  time: 0.9147  data_time: 0.3342  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:28:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:28:38 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 8879  total_loss: 1.376  loss_cls: 0.3463  loss_box_reg: 0.5562  loss_mask: 0.2961  loss_rpn_cls: 0.04392  loss_rpn_loc: 0.1166  time: 0.9152  data_time: 0.2743  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:28:57 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 8899  total_loss: 1.39  loss_cls: 0.3472  loss_box_reg: 0.5662  loss_mask: 0.2908  loss_rpn_cls: 0.05818  loss_rpn_loc: 0.1141  time: 0.9152  data_time: 0.2150  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:29:16 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 8919  total_loss: 1.362  loss_cls: 0.3462  loss_box_reg: 0.5658  loss_mask: 0.3033  loss_rpn_cls: 0.03955  loss_rpn_loc: 0.1064  time: 0.9152  data_time: 0.1781  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:29:34 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 8939  total_loss: 1.376  loss_cls: 0.3661  loss_box_reg: 0.562  loss_mask: 0.292  loss_rpn_cls: 0.03648  loss_rpn_loc: 0.1071  time: 0.9152  data_time: 0.2010  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:29:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:29:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:29:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:29:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:29:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:29:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1404 s/iter. Eval: 0.0545 s/iter. Total: 0.1958 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:29:55 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1496 s/iter. Eval: 0.1276 s/iter. Total: 0.2782 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 01:30:00 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1520 s/iter. Eval: 0.1395 s/iter. Total: 0.2925 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1507 s/iter. Eval: 0.1333 s/iter. Total: 0.2851 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/09 01:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1523 s/iter. Eval: 0.1461 s/iter. Total: 0.2994 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1551 s/iter. Eval: 0.1575 s/iter. Total: 0.3136 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/09 01:30:21 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1564 s/iter. Eval: 0.1608 s/iter. Total: 0.3183 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/09 01:30:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.352173 (0.313381 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:30:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.156424 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:30:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:30:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2993474139397032\n",
      "\u001b[32m[02/09 01:30:31 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 8959  total_loss: 1.405  loss_cls: 0.3652  loss_box_reg: 0.5736  loss_mask: 0.3198  loss_rpn_cls: 0.04742  loss_rpn_loc: 0.1136  time: 0.9153  data_time: 0.2389  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:30:48 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 8979  total_loss: 1.335  loss_cls: 0.3436  loss_box_reg: 0.5473  loss_mask: 0.2915  loss_rpn_cls: 0.03969  loss_rpn_loc: 0.09767  time: 0.9151  data_time: 0.1385  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:31:05 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 8999  total_loss: 1.333  loss_cls: 0.3543  loss_box_reg: 0.5328  loss_mask: 0.2944  loss_rpn_cls: 0.05451  loss_rpn_loc: 0.1073  time: 0.9150  data_time: 0.1464  lr: 0.00010486  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:31:22 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 9019  total_loss: 1.388  loss_cls: 0.3496  loss_box_reg: 0.5638  loss_mask: 0.3019  loss_rpn_cls: 0.0447  loss_rpn_loc: 0.1047  time: 0.9148  data_time: 0.1211  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:31:43 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 9039  total_loss: 1.399  loss_cls: 0.3579  loss_box_reg: 0.5632  loss_mask: 0.3033  loss_rpn_cls: 0.04477  loss_rpn_loc: 0.1124  time: 0.9151  data_time: 0.3274  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:31:58 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 9059  total_loss: 1.35  loss_cls: 0.3308  loss_box_reg: 0.5468  loss_mask: 0.2867  loss_rpn_cls: 0.04524  loss_rpn_loc: 0.0935  time: 0.9148  data_time: 0.0935  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:32:19 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 9079  total_loss: 1.343  loss_cls: 0.3608  loss_box_reg: 0.5336  loss_mask: 0.2871  loss_rpn_cls: 0.03257  loss_rpn_loc: 0.1152  time: 0.9151  data_time: 0.3613  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:32:37 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 9099  total_loss: 1.336  loss_cls: 0.3427  loss_box_reg: 0.5258  loss_mask: 0.2766  loss_rpn_cls: 0.03639  loss_rpn_loc: 0.0913  time: 0.9151  data_time: 0.2055  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:32:55 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 9119  total_loss: 1.271  loss_cls: 0.3292  loss_box_reg: 0.5556  loss_mask: 0.2922  loss_rpn_cls: 0.03437  loss_rpn_loc: 0.0947  time: 0.9150  data_time: 0.1984  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:33:12 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 9139  total_loss: 1.305  loss_cls: 0.3321  loss_box_reg: 0.5484  loss_mask: 0.295  loss_rpn_cls: 0.04242  loss_rpn_loc: 0.09606  time: 0.9149  data_time: 0.1844  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:33:30 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 9159  total_loss: 1.243  loss_cls: 0.3273  loss_box_reg: 0.4973  loss_mask: 0.2625  loss_rpn_cls: 0.03184  loss_rpn_loc: 0.09878  time: 0.9148  data_time: 0.2055  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:33:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:33:51 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 9179  total_loss: 1.215  loss_cls: 0.3053  loss_box_reg: 0.5216  loss_mask: 0.2782  loss_rpn_cls: 0.03337  loss_rpn_loc: 0.08182  time: 0.9151  data_time: 0.2053  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:34:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:34:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:34:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:34:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:34:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:34:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1410 s/iter. Eval: 0.0557 s/iter. Total: 0.1977 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1480 s/iter. Eval: 0.1252 s/iter. Total: 0.2742 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 01:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0010 s/iter. Inference: 0.1495 s/iter. Eval: 0.1358 s/iter. Total: 0.2863 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0010 s/iter. Inference: 0.1468 s/iter. Eval: 0.1241 s/iter. Total: 0.2719 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/09 01:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1503 s/iter. Eval: 0.1454 s/iter. Total: 0.2967 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0010 s/iter. Inference: 0.1525 s/iter. Eval: 0.1532 s/iter. Total: 0.3068 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/09 01:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0010 s/iter. Inference: 0.1514 s/iter. Eval: 0.1495 s/iter. Total: 0.3019 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/09 01:34:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.798110 (0.299984 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:34:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.151754 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:34:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:34:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3003690884074588\n",
      "\u001b[32m[02/09 01:34:45 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 9199  total_loss: 1.319  loss_cls: 0.3346  loss_box_reg: 0.5501  loss_mask: 0.2992  loss_rpn_cls: 0.03711  loss_rpn_loc: 0.09826  time: 0.9149  data_time: 0.1602  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:34:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:35:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:35:08 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 9219  total_loss: 1.339  loss_cls: 0.3375  loss_box_reg: 0.5266  loss_mask: 0.3025  loss_rpn_cls: 0.03041  loss_rpn_loc: 0.1108  time: 0.9155  data_time: 0.2683  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:35:25 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 9239  total_loss: 1.329  loss_cls: 0.3456  loss_box_reg: 0.5371  loss_mask: 0.2934  loss_rpn_cls: 0.0489  loss_rpn_loc: 0.1134  time: 0.9153  data_time: 0.1526  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:35:41 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 9259  total_loss: 1.349  loss_cls: 0.3502  loss_box_reg: 0.5344  loss_mask: 0.287  loss_rpn_cls: 0.0428  loss_rpn_loc: 0.1112  time: 0.9151  data_time: 0.1292  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:35:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:35:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:36:04 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 9279  total_loss: 1.391  loss_cls: 0.3324  loss_box_reg: 0.5513  loss_mask: 0.3116  loss_rpn_cls: 0.0292  loss_rpn_loc: 0.1044  time: 0.9156  data_time: 0.2706  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:36:22 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 9299  total_loss: 1.258  loss_cls: 0.2967  loss_box_reg: 0.5197  loss_mask: 0.2807  loss_rpn_cls: 0.03799  loss_rpn_loc: 0.09785  time: 0.9156  data_time: 0.2085  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:36:37 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 9319  total_loss: 1.332  loss_cls: 0.3471  loss_box_reg: 0.5155  loss_mask: 0.2845  loss_rpn_cls: 0.04011  loss_rpn_loc: 0.1015  time: 0.9152  data_time: 0.0916  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:36:56 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 9339  total_loss: 1.31  loss_cls: 0.3262  loss_box_reg: 0.5523  loss_mask: 0.2985  loss_rpn_cls: 0.04181  loss_rpn_loc: 0.09035  time: 0.9152  data_time: 0.2003  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:37:16 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 9359  total_loss: 1.316  loss_cls: 0.3409  loss_box_reg: 0.5251  loss_mask: 0.291  loss_rpn_cls: 0.04497  loss_rpn_loc: 0.1057  time: 0.9155  data_time: 0.3254  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:37:36 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 9379  total_loss: 1.412  loss_cls: 0.3646  loss_box_reg: 0.5693  loss_mask: 0.292  loss_rpn_cls: 0.04706  loss_rpn_loc: 0.1234  time: 0.9157  data_time: 0.3116  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:37:52 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 9399  total_loss: 1.298  loss_cls: 0.3411  loss_box_reg: 0.5122  loss_mask: 0.2816  loss_rpn_cls: 0.033  loss_rpn_loc: 0.09881  time: 0.9154  data_time: 0.1179  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:38:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:38:14 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 9419  total_loss: 1.354  loss_cls: 0.3551  loss_box_reg: 0.5245  loss_mask: 0.2859  loss_rpn_cls: 0.05193  loss_rpn_loc: 0.1187  time: 0.9157  data_time: 0.2444  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:38:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:38:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:38:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:38:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:38:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:38:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:38:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.1393 s/iter. Eval: 0.0567 s/iter. Total: 0.1969 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:38:38 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1472 s/iter. Eval: 0.1262 s/iter. Total: 0.2744 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 01:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0010 s/iter. Inference: 0.1483 s/iter. Eval: 0.1359 s/iter. Total: 0.2852 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0009 s/iter. Inference: 0.1457 s/iter. Eval: 0.1242 s/iter. Total: 0.2709 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/09 01:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1491 s/iter. Eval: 0.1461 s/iter. Total: 0.2963 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0010 s/iter. Inference: 0.1514 s/iter. Eval: 0.1547 s/iter. Total: 0.3071 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/09 01:39:04 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0010 s/iter. Inference: 0.1503 s/iter. Eval: 0.1499 s/iter. Total: 0.3012 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/09 01:39:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.831589 (0.300272 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:39:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.150602 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:39:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:39:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3012846362605643\n",
      "\u001b[32m[02/09 01:39:08 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 9439  total_loss: 1.246  loss_cls: 0.3464  loss_box_reg: 0.5034  loss_mask: 0.2776  loss_rpn_cls: 0.0339  loss_rpn_loc: 0.09639  time: 0.9156  data_time: 0.1841  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:39:24 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 9459  total_loss: 1.351  loss_cls: 0.3392  loss_box_reg: 0.5577  loss_mask: 0.2874  loss_rpn_cls: 0.04161  loss_rpn_loc: 0.1156  time: 0.9154  data_time: 0.1413  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:39:41 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 9479  total_loss: 1.319  loss_cls: 0.3534  loss_box_reg: 0.5448  loss_mask: 0.2793  loss_rpn_cls: 0.02994  loss_rpn_loc: 0.1005  time: 0.9152  data_time: 0.1454  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:39:59 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 9499  total_loss: 1.311  loss_cls: 0.3264  loss_box_reg: 0.5256  loss_mask: 0.2832  loss_rpn_cls: 0.04776  loss_rpn_loc: 0.09148  time: 0.9152  data_time: 0.1865  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:40:14 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 9519  total_loss: 1.325  loss_cls: 0.326  loss_box_reg: 0.5408  loss_mask: 0.2867  loss_rpn_cls: 0.03082  loss_rpn_loc: 0.1005  time: 0.9149  data_time: 0.1016  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:40:31 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 9539  total_loss: 1.351  loss_cls: 0.3602  loss_box_reg: 0.5571  loss_mask: 0.2944  loss_rpn_cls: 0.03614  loss_rpn_loc: 0.107  time: 0.9147  data_time: 0.1337  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:40:51 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 9559  total_loss: 1.443  loss_cls: 0.3852  loss_box_reg: 0.5766  loss_mask: 0.305  loss_rpn_cls: 0.04572  loss_rpn_loc: 0.1216  time: 0.9149  data_time: 0.3133  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:41:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:41:13 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 9579  total_loss: 1.253  loss_cls: 0.3241  loss_box_reg: 0.5405  loss_mask: 0.2797  loss_rpn_cls: 0.04034  loss_rpn_loc: 0.1052  time: 0.9153  data_time: 0.2700  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:41:32 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 9599  total_loss: 1.349  loss_cls: 0.3449  loss_box_reg: 0.5242  loss_mask: 0.2991  loss_rpn_cls: 0.03595  loss_rpn_loc: 0.1045  time: 0.9154  data_time: 0.2246  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:41:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:41:52 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 9619  total_loss: 1.423  loss_cls: 0.3769  loss_box_reg: 0.5652  loss_mask: 0.3069  loss_rpn_cls: 0.05086  loss_rpn_loc: 0.1474  time: 0.9156  data_time: 0.2236  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:42:07 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 9639  total_loss: 1.295  loss_cls: 0.3246  loss_box_reg: 0.5412  loss_mask: 0.291  loss_rpn_cls: 0.03542  loss_rpn_loc: 0.09213  time: 0.9152  data_time: 0.0654  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:42:25 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 9659  total_loss: 1.394  loss_cls: 0.3439  loss_box_reg: 0.541  loss_mask: 0.2934  loss_rpn_cls: 0.05233  loss_rpn_loc: 0.1127  time: 0.9152  data_time: 0.2390  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:42:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:42:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:42:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:42:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:42:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:42:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.1388 s/iter. Eval: 0.0569 s/iter. Total: 0.1967 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1461 s/iter. Eval: 0.1237 s/iter. Total: 0.2708 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/09 01:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1475 s/iter. Eval: 0.1331 s/iter. Total: 0.2816 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0009 s/iter. Inference: 0.1450 s/iter. Eval: 0.1218 s/iter. Total: 0.2678 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/09 01:43:06 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1487 s/iter. Eval: 0.1439 s/iter. Total: 0.2935 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0009 s/iter. Inference: 0.1510 s/iter. Eval: 0.1522 s/iter. Total: 0.3042 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/09 01:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0009 s/iter. Inference: 0.1498 s/iter. Eval: 0.1477 s/iter. Total: 0.2984 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/09 01:43:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.510664 (0.297506 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:43:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.150049 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:43:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:43:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30330681532902987\n",
      "\u001b[32m[02/09 01:43:19 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 9679  total_loss: 1.226  loss_cls: 0.3095  loss_box_reg: 0.5185  loss_mask: 0.2822  loss_rpn_cls: 0.02247  loss_rpn_loc: 0.09032  time: 0.9151  data_time: 0.1707  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:43:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:43:39 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 9699  total_loss: 1.242  loss_cls: 0.3105  loss_box_reg: 0.5332  loss_mask: 0.2966  loss_rpn_cls: 0.02767  loss_rpn_loc: 0.07237  time: 0.9153  data_time: 0.2421  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:43:57 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9719  total_loss: 1.404  loss_cls: 0.3595  loss_box_reg: 0.5615  loss_mask: 0.302  loss_rpn_cls: 0.04585  loss_rpn_loc: 0.1144  time: 0.9152  data_time: 0.1756  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:44:15 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 9739  total_loss: 1.255  loss_cls: 0.3387  loss_box_reg: 0.4917  loss_mask: 0.2795  loss_rpn_cls: 0.03462  loss_rpn_loc: 0.1011  time: 0.9151  data_time: 0.1908  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:44:29 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 9759  total_loss: 1.366  loss_cls: 0.3622  loss_box_reg: 0.5484  loss_mask: 0.2947  loss_rpn_cls: 0.04211  loss_rpn_loc: 0.1289  time: 0.9148  data_time: 0.0780  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:44:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:44:48 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 9779  total_loss: 1.256  loss_cls: 0.3425  loss_box_reg: 0.5079  loss_mask: 0.2684  loss_rpn_cls: 0.02819  loss_rpn_loc: 0.101  time: 0.9148  data_time: 0.1543  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:45:07 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 9799  total_loss: 1.35  loss_cls: 0.3324  loss_box_reg: 0.5251  loss_mask: 0.2972  loss_rpn_cls: 0.04704  loss_rpn_loc: 0.1184  time: 0.9148  data_time: 0.2275  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:45:21 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 9819  total_loss: 1.19  loss_cls: 0.3002  loss_box_reg: 0.5117  loss_mask: 0.2697  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.08993  time: 0.9145  data_time: 0.0756  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:45:38 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 9839  total_loss: 1.363  loss_cls: 0.3638  loss_box_reg: 0.5451  loss_mask: 0.2891  loss_rpn_cls: 0.04312  loss_rpn_loc: 0.109  time: 0.9143  data_time: 0.1364  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:45:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:45:57 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 9859  total_loss: 1.258  loss_cls: 0.3118  loss_box_reg: 0.5128  loss_mask: 0.2819  loss_rpn_cls: 0.02757  loss_rpn_loc: 0.08419  time: 0.9144  data_time: 0.1872  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:46:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:46:20 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 9879  total_loss: 1.416  loss_cls: 0.38  loss_box_reg: 0.5683  loss_mask: 0.2937  loss_rpn_cls: 0.05191  loss_rpn_loc: 0.1199  time: 0.9148  data_time: 0.3120  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:46:39 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 9899  total_loss: 1.292  loss_cls: 0.3396  loss_box_reg: 0.5402  loss_mask: 0.2781  loss_rpn_cls: 0.0396  loss_rpn_loc: 0.1097  time: 0.9149  data_time: 0.2948  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:46:55 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 9919  total_loss: 1.257  loss_cls: 0.3054  loss_box_reg: 0.5306  loss_mask: 0.2983  loss_rpn_cls: 0.05405  loss_rpn_loc: 0.1004  time: 0.9147  data_time: 0.1214  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:46:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:46:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:46:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:46:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:46:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:46:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1401 s/iter. Eval: 0.0561 s/iter. Total: 0.1970 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1462 s/iter. Eval: 0.1235 s/iter. Total: 0.2707 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/09 01:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1475 s/iter. Eval: 0.1327 s/iter. Total: 0.2811 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0009 s/iter. Inference: 0.1466 s/iter. Eval: 0.1233 s/iter. Total: 0.2709 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/09 01:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1496 s/iter. Eval: 0.1436 s/iter. Total: 0.2941 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0009 s/iter. Inference: 0.1517 s/iter. Eval: 0.1520 s/iter. Total: 0.3047 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/09 01:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0009 s/iter. Inference: 0.1504 s/iter. Eval: 0.1477 s/iter. Total: 0.2991 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/09 01:47:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.574987 (0.298060 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:47:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.150538 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:47:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:47:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3011102246537672\n",
      "\u001b[32m[02/09 01:47:50 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 9939  total_loss: 1.352  loss_cls: 0.3574  loss_box_reg: 0.554  loss_mask: 0.2975  loss_rpn_cls: 0.04274  loss_rpn_loc: 0.1119  time: 0.9147  data_time: 0.2263  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:48:06 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 9959  total_loss: 1.3  loss_cls: 0.3257  loss_box_reg: 0.5217  loss_mask: 0.2921  loss_rpn_cls: 0.02962  loss_rpn_loc: 0.1053  time: 0.9144  data_time: 0.1253  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:48:22 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 9979  total_loss: 1.243  loss_cls: 0.3019  loss_box_reg: 0.5108  loss_mask: 0.2836  loss_rpn_cls: 0.03527  loss_rpn_loc: 0.09615  time: 0.9142  data_time: 0.1636  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:48:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7fea8e25e310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/09 01:48:44 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.237  loss_cls: 0.3049  loss_box_reg: 0.5272  loss_mask: 0.29  loss_rpn_cls: 0.03395  loss_rpn_loc: 0.09599  time: 0.9145  data_time: 0.2892  lr: 8.3886e-05  max_mem: 9489M\n",
      "\u001b[32m[02/09 01:48:44 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 2:32:23 (0.9146 s / it)\n",
      "\u001b[32m[02/09 01:48:44 d2.engine.hooks]: \u001b[0mTotal training time: 2:58:48 (0:26:24 on hooks)\n",
      "\u001b[32m[02/09 01:48:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:48:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/09 01:48:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/09 01:48:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/09 01:48:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/09 01:48:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/09 01:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1405 s/iter. Eval: 0.0626 s/iter. Total: 0.2038 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/09 01:48:52 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1471 s/iter. Eval: 0.1294 s/iter. Total: 0.2774 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/09 01:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1482 s/iter. Eval: 0.1360 s/iter. Total: 0.2852 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/09 01:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0009 s/iter. Inference: 0.1455 s/iter. Eval: 0.1239 s/iter. Total: 0.2704 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/09 01:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1490 s/iter. Eval: 0.1448 s/iter. Total: 0.2948 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/09 01:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0009 s/iter. Inference: 0.1514 s/iter. Eval: 0.1526 s/iter. Total: 0.3050 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/09 01:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0009 s/iter. Inference: 0.1502 s/iter. Eval: 0.1478 s/iter. Total: 0.2990 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/09 01:49:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.570453 (0.298021 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:49:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.150516 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/09 01:49:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/09 01:49:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29955294027006957\n"
     ]
    }
   ],
   "source": [
    "# Default augmentations + we add more augmentations\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "        T.RandomContrast(0.95,1.05),\n",
    "        T.RandomBrightness(0.95,1.05),\n",
    "        T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.ResizeShortestEdge(short_edge_length=(832, 864, 896, 928, 960, 992, 1024), max_size=9999, sample_style='choice')\n",
    "        ]))\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.INPUT.MIN_SIZE_TEST = 1024\n",
    "cfg.INPUT.MAX_SIZE_TEST = 3000\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 4000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24], [40], [80], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 3.0]]\n",
    "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.7]\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.75\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.03\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 700\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_10.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4b5bd7-0cf8-4338-92cd-e18c04730018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  1\n",
      "mAP : 0.2103876271902451\n",
      "False negatives : 0.10366114738905222\n",
      "False positives : 0.17422062519708162\n",
      "Experiment  2\n",
      "mAP : 0.3002627002133756\n",
      "False negatives : 0.10839094834021118\n",
      "False positives : 0.1582021753237467\n",
      "Experiment  3\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(output):\n",
    "    with open(f\"output_{output}/metrics.json\",'r') as f:\n",
    "        metrics = [json.loads(line) for line in f]\n",
    "    print(\"mAP :\", np.mean([metrics[i][\"mAP IoU\"] for i in range(len(metrics)) if 'mAP IoU' in metrics[i]][-10:]))\n",
    "    print(\"False negatives :\", np.mean([metrics[i][\"mask_rcnn/false_negative\"] for i in range(len(metrics)) if 'mask_rcnn/false_negative' in metrics[i]][-100:]))\n",
    "    print(\"False positives :\", np.mean([metrics[i][\"mask_rcnn/false_positive\"] for i in range(len(metrics)) if 'mask_rcnn/false_positive' in metrics[i]][-100:]))\n",
    "i=1\n",
    "while True:\n",
    "    try:\n",
    "        print(\"Experiment \",i)\n",
    "        print_metrics(\"10.\"+str(i))\n",
    "        i+=1\n",
    "    except:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
