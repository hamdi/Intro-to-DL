{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c9dc13-e37c-48c1-961f-811c0c34c9f2",
   "metadata": {},
   "source": [
    "### Notebook 7: Training with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea9205b-8628-43a6-9557-a7c4c462a53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.solver.build import get_default_optimizer_params\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd4af33-59b1-4f0b-a411-f07a2072bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/11 19:02:15 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n"
     ]
    }
   ],
   "source": [
    "dataDir=Path('../')\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "register_coco_instances('sartorius_train',{}, '../sartorius-annotations-coco-format/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_val',{},'../sartorius-annotations-coco-format/annotations_val.json', dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33773979-c754-4d86-8558-45663796d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1\n",
    "    false_positives = np.sum(matches, axis=0) == 0\n",
    "    false_negatives = np.sum(matches, axis=1) == 0\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"MaP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_optimizer(cls, cfg, model):\n",
    "        params = get_default_optimizer_params(\n",
    "            model,\n",
    "            base_lr=cfg.SOLVER.BASE_LR,\n",
    "            weight_decay_norm=cfg.SOLVER.WEIGHT_DECAY_NORM,\n",
    "            bias_lr_factor=cfg.SOLVER.BIAS_LR_FACTOR,\n",
    "            weight_decay_bias=cfg.SOLVER.WEIGHT_DECAY_BIAS,\n",
    "        )\n",
    "        return torch.optim.Adam(\n",
    "        params,\n",
    "        lr=cfg.SOLVER.BASE_LR,\n",
    "        weight_decay=cfg.SOLVER.WEIGHT_DECAY,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95bcc501-0f59-4b81-9e8e-9873466a755d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/11 19:02:58 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/11 19:02:59 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/11 19:02:59 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/11 19:03:00 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/11 19:03:00 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[01/11 19:03:00 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/11 19:03:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/11 19:03:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/11 19:03:00 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:03:00 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/11 19:03:00 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/11 19:03:10 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 19  total_loss: 2.964  loss_cls: 1.319  loss_box_reg: 0.4621  loss_mask: 0.6924  loss_rpn_cls: 0.2287  loss_rpn_loc: 0.2344  time: 0.4408  data_time: 0.1201  lr: 9.9905e-06  max_mem: 4883M\n",
      "\u001b[32m[01/11 19:03:22 d2.utils.events]: \u001b[0m eta: 0:56:52  iter: 39  total_loss: 2.515  loss_cls: 0.7689  loss_box_reg: 0.5925  loss_mask: 0.6792  loss_rpn_cls: 0.1867  loss_rpn_loc: 0.2291  time: 0.5419  data_time: 0.2887  lr: 1.998e-05  max_mem: 4883M\n",
      "\u001b[32m[01/11 19:03:34 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 59  total_loss: 2.2  loss_cls: 0.5962  loss_box_reg: 0.6219  loss_mask: 0.6143  loss_rpn_cls: 0.1638  loss_rpn_loc: 0.2265  time: 0.5549  data_time: 0.2511  lr: 2.997e-05  max_mem: 5118M\n",
      "\u001b[32m[01/11 19:03:47 d2.utils.events]: \u001b[0m eta: 0:57:30  iter: 79  total_loss: 1.938  loss_cls: 0.5117  loss_box_reg: 0.6535  loss_mask: 0.445  loss_rpn_cls: 0.1266  loss_rpn_loc: 0.2527  time: 0.5817  data_time: 0.3052  lr: 3.9961e-05  max_mem: 5590M\n",
      "\u001b[32m[01/11 19:03:58 d2.utils.events]: \u001b[0m eta: 0:57:14  iter: 99  total_loss: 1.833  loss_cls: 0.4198  loss_box_reg: 0.6778  loss_mask: 0.394  loss_rpn_cls: 0.1151  loss_rpn_loc: 0.225  time: 0.5753  data_time: 0.2092  lr: 4.9951e-05  max_mem: 5610M\n",
      "\u001b[32m[01/11 19:04:12 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 119  total_loss: 1.717  loss_cls: 0.4007  loss_box_reg: 0.6396  loss_mask: 0.3634  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.2144  time: 0.5925  data_time: 0.3395  lr: 5.9941e-05  max_mem: 5610M\n",
      "\u001b[32m[01/11 19:04:27 d2.utils.events]: \u001b[0m eta: 0:58:39  iter: 139  total_loss: 1.7  loss_cls: 0.3861  loss_box_reg: 0.5622  loss_mask: 0.3426  loss_rpn_cls: 0.1529  loss_rpn_loc: 0.2426  time: 0.6206  data_time: 0.4351  lr: 6.993e-05  max_mem: 5610M\n",
      "\u001b[32m[01/11 19:04:44 d2.utils.events]: \u001b[0m eta: 0:59:30  iter: 159  total_loss: 1.758  loss_cls: 0.4469  loss_box_reg: 0.5779  loss_mask: 0.3548  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.2508  time: 0.6443  data_time: 0.4442  lr: 7.9921e-05  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:04:55 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 179  total_loss: 1.659  loss_cls: 0.3444  loss_box_reg: 0.5991  loss_mask: 0.3294  loss_rpn_cls: 0.105  loss_rpn_loc: 0.2111  time: 0.6385  data_time: 0.2523  lr: 8.991e-05  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:05:05 d2.utils.events]: \u001b[0m eta: 0:58:44  iter: 199  total_loss: 1.673  loss_cls: 0.4128  loss_box_reg: 0.6054  loss_mask: 0.3111  loss_rpn_cls: 0.1359  loss_rpn_loc: 0.2165  time: 0.6215  data_time: 0.1388  lr: 9.9901e-05  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:05:15 d2.utils.events]: \u001b[0m eta: 0:58:10  iter: 219  total_loss: 1.734  loss_cls: 0.5151  loss_box_reg: 0.5816  loss_mask: 0.3295  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.2144  time: 0.6113  data_time: 0.1777  lr: 0.00010989  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:05:27 d2.utils.events]: \u001b[0m eta: 0:58:03  iter: 239  total_loss: 1.661  loss_cls: 0.4576  loss_box_reg: 0.5599  loss_mask: 0.3264  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.2189  time: 0.6081  data_time: 0.2399  lr: 0.00011988  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:05:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:05:28 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/11 19:05:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:05:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:05:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:05:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:05:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0775 s/iter. Eval: 0.0116 s/iter. Total: 0.0898 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0777 s/iter. Eval: 0.0190 s/iter. Total: 0.0974 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 19:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0007 s/iter. Inference: 0.0779 s/iter. Eval: 0.0200 s/iter. Total: 0.0986 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 19:05:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.522979 (0.099336 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:05:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077989 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:05:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:05:41 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.18514573036946086\n",
      "\u001b[32m[01/11 19:05:52 d2.utils.events]: \u001b[0m eta: 0:58:05  iter: 259  total_loss: 1.739  loss_cls: 0.4516  loss_box_reg: 0.5546  loss_mask: 0.3263  loss_rpn_cls: 0.1261  loss_rpn_loc: 0.2335  time: 0.6091  data_time: 0.2870  lr: 0.00012987  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:06:02 d2.utils.events]: \u001b[0m eta: 0:57:27  iter: 279  total_loss: 1.626  loss_cls: 0.4134  loss_box_reg: 0.6073  loss_mask: 0.3314  loss_rpn_cls: 0.08946  loss_rpn_loc: 0.219  time: 0.6007  data_time: 0.1600  lr: 0.00013986  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:06:16 d2.utils.events]: \u001b[0m eta: 0:57:42  iter: 299  total_loss: 1.718  loss_cls: 0.4418  loss_box_reg: 0.5817  loss_mask: 0.3158  loss_rpn_cls: 0.1577  loss_rpn_loc: 0.2272  time: 0.6075  data_time: 0.3609  lr: 0.00014985  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:06:27 d2.utils.events]: \u001b[0m eta: 0:57:33  iter: 319  total_loss: 1.651  loss_cls: 0.3695  loss_box_reg: 0.5681  loss_mask: 0.3261  loss_rpn_cls: 0.142  loss_rpn_loc: 0.2152  time: 0.6055  data_time: 0.2377  lr: 0.00015984  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:06:40 d2.utils.events]: \u001b[0m eta: 0:57:30  iter: 339  total_loss: 1.6  loss_cls: 0.4165  loss_box_reg: 0.541  loss_mask: 0.3111  loss_rpn_cls: 0.1271  loss_rpn_loc: 0.2209  time: 0.6062  data_time: 0.2618  lr: 0.00016983  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:06:53 d2.utils.events]: \u001b[0m eta: 0:57:40  iter: 359  total_loss: 1.81  loss_cls: 0.5374  loss_box_reg: 0.5744  loss_mask: 0.3166  loss_rpn_cls: 0.1496  loss_rpn_loc: 0.232  time: 0.6101  data_time: 0.3368  lr: 0.00017982  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:07:06 d2.utils.events]: \u001b[0m eta: 0:57:39  iter: 379  total_loss: 1.849  loss_cls: 0.4407  loss_box_reg: 0.5625  loss_mask: 0.3459  loss_rpn_cls: 0.1677  loss_rpn_loc: 0.2491  time: 0.6118  data_time: 0.2940  lr: 0.00018981  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:07:17 d2.utils.events]: \u001b[0m eta: 0:57:28  iter: 399  total_loss: 1.781  loss_cls: 0.4345  loss_box_reg: 0.5894  loss_mask: 0.3236  loss_rpn_cls: 0.1337  loss_rpn_loc: 0.2252  time: 0.6097  data_time: 0.2284  lr: 0.0001998  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:07:29 d2.utils.events]: \u001b[0m eta: 0:57:21  iter: 419  total_loss: 1.874  loss_cls: 0.5003  loss_box_reg: 0.5707  loss_mask: 0.328  loss_rpn_cls: 0.1678  loss_rpn_loc: 0.2439  time: 0.6087  data_time: 0.2424  lr: 0.00020979  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:07:44 d2.utils.events]: \u001b[0m eta: 0:57:33  iter: 439  total_loss: 1.716  loss_cls: 0.4304  loss_box_reg: 0.5246  loss_mask: 0.3338  loss_rpn_cls: 0.1379  loss_rpn_loc: 0.2341  time: 0.6138  data_time: 0.3541  lr: 0.00021978  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:07:55 d2.utils.events]: \u001b[0m eta: 0:57:23  iter: 459  total_loss: 1.884  loss_cls: 0.4603  loss_box_reg: 0.5816  loss_mask: 0.3366  loss_rpn_cls: 0.187  loss_rpn_loc: 0.2454  time: 0.6116  data_time: 0.2266  lr: 0.00022977  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:08:03 d2.utils.events]: \u001b[0m eta: 0:57:00  iter: 479  total_loss: 1.823  loss_cls: 0.4569  loss_box_reg: 0.6289  loss_mask: 0.3339  loss_rpn_cls: 0.1505  loss_rpn_loc: 0.2419  time: 0.6031  data_time: 0.0885  lr: 0.00023976  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:08:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:08:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:08:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:08:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:08:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:08:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0729 s/iter. Eval: 0.0069 s/iter. Total: 0.0804 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 19:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0074 s/iter. Total: 0.0807 s/iter. ETA=0:00:03\n",
      "\u001b[32m[01/11 19:08:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.207808 (0.079378 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:08:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071875 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:08:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:08:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.1844177890027323\n",
      "\u001b[32m[01/11 19:08:25 d2.utils.events]: \u001b[0m eta: 0:56:56  iter: 499  total_loss: 1.809  loss_cls: 0.4881  loss_box_reg: 0.5788  loss_mask: 0.33  loss_rpn_cls: 0.1683  loss_rpn_loc: 0.2177  time: 0.6030  data_time: 0.2561  lr: 0.00024975  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:08:36 d2.utils.events]: \u001b[0m eta: 0:56:49  iter: 519  total_loss: 1.677  loss_cls: 0.3866  loss_box_reg: 0.5831  loss_mask: 0.3268  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.2281  time: 0.6005  data_time: 0.2000  lr: 0.00025974  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:08:53 d2.utils.events]: \u001b[0m eta: 0:56:47  iter: 539  total_loss: 1.838  loss_cls: 0.4638  loss_box_reg: 0.5849  loss_mask: 0.3192  loss_rpn_cls: 0.153  loss_rpn_loc: 0.2694  time: 0.6086  data_time: 0.4581  lr: 0.00026973  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:09:01 d2.utils.events]: \u001b[0m eta: 0:56:35  iter: 559  total_loss: 1.883  loss_cls: 0.5305  loss_box_reg: 0.5591  loss_mask: 0.3416  loss_rpn_cls: 0.2101  loss_rpn_loc: 0.2635  time: 0.6023  data_time: 0.1013  lr: 0.00027972  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:09:14 d2.utils.events]: \u001b[0m eta: 0:56:27  iter: 579  total_loss: 1.907  loss_cls: 0.514  loss_box_reg: 0.5818  loss_mask: 0.3425  loss_rpn_cls: 0.1899  loss_rpn_loc: 0.2592  time: 0.6030  data_time: 0.2860  lr: 0.00028971  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:09:27 d2.utils.events]: \u001b[0m eta: 0:56:25  iter: 599  total_loss: 1.871  loss_cls: 0.4925  loss_box_reg: 0.5792  loss_mask: 0.327  loss_rpn_cls: 0.1817  loss_rpn_loc: 0.2646  time: 0.6044  data_time: 0.2954  lr: 0.0002997  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:09:39 d2.utils.events]: \u001b[0m eta: 0:56:18  iter: 619  total_loss: 1.727  loss_cls: 0.4443  loss_box_reg: 0.5266  loss_mask: 0.3097  loss_rpn_cls: 0.1638  loss_rpn_loc: 0.2483  time: 0.6046  data_time: 0.2771  lr: 0.00030969  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:09:50 d2.utils.events]: \u001b[0m eta: 0:55:57  iter: 639  total_loss: 1.726  loss_cls: 0.4326  loss_box_reg: 0.5818  loss_mask: 0.3189  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.2433  time: 0.6032  data_time: 0.2283  lr: 0.00031968  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:10:00 d2.utils.events]: \u001b[0m eta: 0:55:36  iter: 659  total_loss: 1.638  loss_cls: 0.3939  loss_box_reg: 0.5782  loss_mask: 0.3048  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.2053  time: 0.5997  data_time: 0.1594  lr: 0.00032967  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:10:14 d2.utils.events]: \u001b[0m eta: 0:55:35  iter: 679  total_loss: 1.841  loss_cls: 0.4916  loss_box_reg: 0.6001  loss_mask: 0.33  loss_rpn_cls: 0.163  loss_rpn_loc: 0.2566  time: 0.6033  data_time: 0.3691  lr: 0.00033966  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:10:27 d2.utils.events]: \u001b[0m eta: 0:55:22  iter: 699  total_loss: 1.786  loss_cls: 0.494  loss_box_reg: 0.5977  loss_mask: 0.3309  loss_rpn_cls: 0.1347  loss_rpn_loc: 0.2506  time: 0.6037  data_time: 0.2770  lr: 0.00034965  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:10:42 d2.utils.events]: \u001b[0m eta: 0:55:20  iter: 719  total_loss: 1.75  loss_cls: 0.4582  loss_box_reg: 0.5555  loss_mask: 0.3232  loss_rpn_cls: 0.1483  loss_rpn_loc: 0.2395  time: 0.6086  data_time: 0.4226  lr: 0.00035964  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:10:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:10:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:10:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:10:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:10:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:10:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0708 s/iter. Eval: 0.0075 s/iter. Total: 0.0789 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 19:10:52 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0007 s/iter. Inference: 0.0732 s/iter. Eval: 0.0104 s/iter. Total: 0.0843 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:10:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.802074 (0.084501 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:10:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073209 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:10:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:10:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21001451326882645\n",
      "\u001b[32m[01/11 19:11:04 d2.utils.events]: \u001b[0m eta: 0:55:08  iter: 739  total_loss: 1.827  loss_cls: 0.4952  loss_box_reg: 0.6027  loss_mask: 0.3262  loss_rpn_cls: 0.1731  loss_rpn_loc: 0.2531  time: 0.6073  data_time: 0.2264  lr: 0.00036963  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:11:20 d2.utils.events]: \u001b[0m eta: 0:55:13  iter: 759  total_loss: 1.812  loss_cls: 0.4693  loss_box_reg: 0.5558  loss_mask: 0.3129  loss_rpn_cls: 0.174  loss_rpn_loc: 0.2453  time: 0.6111  data_time: 0.3971  lr: 0.00037962  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:11:30 d2.utils.events]: \u001b[0m eta: 0:54:59  iter: 779  total_loss: 1.714  loss_cls: 0.46  loss_box_reg: 0.5961  loss_mask: 0.3326  loss_rpn_cls: 0.1421  loss_rpn_loc: 0.244  time: 0.6093  data_time: 0.2041  lr: 0.00038961  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:11:43 d2.utils.events]: \u001b[0m eta: 0:54:52  iter: 799  total_loss: 1.792  loss_cls: 0.4451  loss_box_reg: 0.6331  loss_mask: 0.3151  loss_rpn_cls: 0.1566  loss_rpn_loc: 0.2341  time: 0.6097  data_time: 0.2876  lr: 0.0003996  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:11:53 d2.utils.events]: \u001b[0m eta: 0:54:39  iter: 819  total_loss: 1.936  loss_cls: 0.5005  loss_box_reg: 0.5626  loss_mask: 0.3507  loss_rpn_cls: 0.2139  loss_rpn_loc: 0.2751  time: 0.6071  data_time: 0.1807  lr: 0.00040959  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:12:07 d2.utils.events]: \u001b[0m eta: 0:54:32  iter: 839  total_loss: 2.359  loss_cls: 0.7233  loss_box_reg: 0.5881  loss_mask: 0.38  loss_rpn_cls: 0.2886  loss_rpn_loc: 0.2855  time: 0.6092  data_time: 0.3519  lr: 0.00041958  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:12:19 d2.utils.events]: \u001b[0m eta: 0:54:24  iter: 859  total_loss: 1.937  loss_cls: 0.5361  loss_box_reg: 0.6103  loss_mask: 0.335  loss_rpn_cls: 0.224  loss_rpn_loc: 0.279  time: 0.6093  data_time: 0.2843  lr: 0.00042957  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:12:33 d2.utils.events]: \u001b[0m eta: 0:54:17  iter: 879  total_loss: 2.047  loss_cls: 0.5928  loss_box_reg: 0.5897  loss_mask: 0.3424  loss_rpn_cls: 0.2208  loss_rpn_loc: 0.3004  time: 0.6108  data_time: 0.3296  lr: 0.00043956  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:12:43 d2.utils.events]: \u001b[0m eta: 0:54:10  iter: 899  total_loss: 1.921  loss_cls: 0.5475  loss_box_reg: 0.6121  loss_mask: 0.3399  loss_rpn_cls: 0.1442  loss_rpn_loc: 0.2659  time: 0.6084  data_time: 0.1585  lr: 0.00044955  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:12:55 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 919  total_loss: 1.996  loss_cls: 0.508  loss_box_reg: 0.6361  loss_mask: 0.3431  loss_rpn_cls: 0.2134  loss_rpn_loc: 0.2578  time: 0.6082  data_time: 0.2560  lr: 0.00045954  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:13:09 d2.utils.events]: \u001b[0m eta: 0:54:05  iter: 939  total_loss: 1.828  loss_cls: 0.4838  loss_box_reg: 0.5854  loss_mask: 0.3354  loss_rpn_cls: 0.153  loss_rpn_loc: 0.2541  time: 0.6106  data_time: 0.3754  lr: 0.00046953  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:13:20 d2.utils.events]: \u001b[0m eta: 0:54:01  iter: 959  total_loss: 1.772  loss_cls: 0.4862  loss_box_reg: 0.584  loss_mask: 0.322  loss_rpn_cls: 0.1483  loss_rpn_loc: 0.2502  time: 0.6095  data_time: 0.2201  lr: 0.00047952  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:13:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:13:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:13:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:13:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:13:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:13:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0722 s/iter. Eval: 0.0077 s/iter. Total: 0.0804 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 19:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0085 s/iter. Total: 0.0819 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:13:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.375902 (0.080827 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:13:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:13:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:13:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.17251366729389261\n",
      "\u001b[32m[01/11 19:13:40 d2.utils.events]: \u001b[0m eta: 0:53:54  iter: 979  total_loss: 2.017  loss_cls: 0.551  loss_box_reg: 0.5982  loss_mask: 0.34  loss_rpn_cls: 0.1844  loss_rpn_loc: 0.2542  time: 0.6068  data_time: 0.1399  lr: 0.00048951  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:13:57 d2.utils.events]: \u001b[0m eta: 0:53:48  iter: 999  total_loss: 1.893  loss_cls: 0.5549  loss_box_reg: 0.5646  loss_mask: 0.3462  loss_rpn_cls: 0.1863  loss_rpn_loc: 0.2486  time: 0.6108  data_time: 0.4313  lr: 0.0004995  max_mem: 6647M\n",
      "\u001b[32m[01/11 19:14:07 d2.utils.events]: \u001b[0m eta: 0:53:41  iter: 1019  total_loss: 1.955  loss_cls: 0.4952  loss_box_reg: 0.6696  loss_mask: 0.3441  loss_rpn_cls: 0.1393  loss_rpn_loc: 0.2517  time: 0.6088  data_time: 0.1682  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:14:17 d2.utils.events]: \u001b[0m eta: 0:53:32  iter: 1039  total_loss: 1.842  loss_cls: 0.4556  loss_box_reg: 0.6133  loss_mask: 0.3127  loss_rpn_cls: 0.1484  loss_rpn_loc: 0.2474  time: 0.6073  data_time: 0.1991  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:14:31 d2.utils.events]: \u001b[0m eta: 0:53:22  iter: 1059  total_loss: 1.753  loss_cls: 0.4302  loss_box_reg: 0.5857  loss_mask: 0.3207  loss_rpn_cls: 0.1487  loss_rpn_loc: 0.2603  time: 0.6086  data_time: 0.3391  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:14:45 d2.utils.events]: \u001b[0m eta: 0:53:25  iter: 1079  total_loss: 1.822  loss_cls: 0.5159  loss_box_reg: 0.5807  loss_mask: 0.3016  loss_rpn_cls: 0.1558  loss_rpn_loc: 0.2353  time: 0.6100  data_time: 0.3358  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:14:56 d2.utils.events]: \u001b[0m eta: 0:53:18  iter: 1099  total_loss: 1.781  loss_cls: 0.495  loss_box_reg: 0.6061  loss_mask: 0.3239  loss_rpn_cls: 0.1455  loss_rpn_loc: 0.248  time: 0.6097  data_time: 0.2614  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:15:07 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 1119  total_loss: 1.633  loss_cls: 0.391  loss_box_reg: 0.5782  loss_mask: 0.3203  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.2191  time: 0.6086  data_time: 0.2216  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:15:18 d2.utils.events]: \u001b[0m eta: 0:52:45  iter: 1139  total_loss: 1.782  loss_cls: 0.4649  loss_box_reg: 0.6033  loss_mask: 0.3238  loss_rpn_cls: 0.1283  loss_rpn_loc: 0.2396  time: 0.6071  data_time: 0.1893  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:15:28 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 1159  total_loss: 1.635  loss_cls: 0.4367  loss_box_reg: 0.5865  loss_mask: 0.32  loss_rpn_cls: 0.1262  loss_rpn_loc: 0.2471  time: 0.6056  data_time: 0.1911  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:15:39 d2.utils.events]: \u001b[0m eta: 0:52:26  iter: 1179  total_loss: 1.779  loss_cls: 0.3957  loss_box_reg: 0.5747  loss_mask: 0.3375  loss_rpn_cls: 0.1278  loss_rpn_loc: 0.2631  time: 0.6046  data_time: 0.2102  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:15:53 d2.utils.events]: \u001b[0m eta: 0:52:20  iter: 1199  total_loss: 1.748  loss_cls: 0.4189  loss_box_reg: 0.5588  loss_mask: 0.31  loss_rpn_cls: 0.158  loss_rpn_loc: 0.2477  time: 0.6057  data_time: 0.3418  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:16:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:16:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:16:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:16:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:16:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:16:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:16:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0714 s/iter. Eval: 0.0086 s/iter. Total: 0.0807 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 19:16:06 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0007 s/iter. Inference: 0.0725 s/iter. Eval: 0.0092 s/iter. Total: 0.0825 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:16:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.461934 (0.081568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:16:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072199 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:16:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:16:10 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.20563389897245993\n",
      "\u001b[32m[01/11 19:16:16 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 1219  total_loss: 1.73  loss_cls: 0.4291  loss_box_reg: 0.5338  loss_mask: 0.3216  loss_rpn_cls: 0.1561  loss_rpn_loc: 0.2461  time: 0.6066  data_time: 0.3018  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:16:32 d2.utils.events]: \u001b[0m eta: 0:52:19  iter: 1239  total_loss: 1.63  loss_cls: 0.4067  loss_box_reg: 0.546  loss_mask: 0.305  loss_rpn_cls: 0.131  loss_rpn_loc: 0.2232  time: 0.6092  data_time: 0.4205  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:16:45 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 1259  total_loss: 1.813  loss_cls: 0.4721  loss_box_reg: 0.5961  loss_mask: 0.337  loss_rpn_cls: 0.1257  loss_rpn_loc: 0.2492  time: 0.6097  data_time: 0.3107  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:16:56 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 1279  total_loss: 1.824  loss_cls: 0.5012  loss_box_reg: 0.5568  loss_mask: 0.3123  loss_rpn_cls: 0.17  loss_rpn_loc: 0.2628  time: 0.6091  data_time: 0.2301  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:17:08 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 1299  total_loss: 1.708  loss_cls: 0.4195  loss_box_reg: 0.5354  loss_mask: 0.3052  loss_rpn_cls: 0.1349  loss_rpn_loc: 0.2435  time: 0.6092  data_time: 0.2795  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:17:20 d2.utils.events]: \u001b[0m eta: 0:51:41  iter: 1319  total_loss: 1.948  loss_cls: 0.4898  loss_box_reg: 0.6221  loss_mask: 0.3533  loss_rpn_cls: 0.1604  loss_rpn_loc: 0.2714  time: 0.6085  data_time: 0.2298  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:17:30 d2.utils.events]: \u001b[0m eta: 0:51:29  iter: 1339  total_loss: 1.789  loss_cls: 0.462  loss_box_reg: 0.5912  loss_mask: 0.3321  loss_rpn_cls: 0.1521  loss_rpn_loc: 0.2534  time: 0.6069  data_time: 0.1828  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:17:41 d2.utils.events]: \u001b[0m eta: 0:51:19  iter: 1359  total_loss: 1.776  loss_cls: 0.4576  loss_box_reg: 0.5828  loss_mask: 0.3156  loss_rpn_cls: 0.143  loss_rpn_loc: 0.262  time: 0.6064  data_time: 0.2336  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:17:52 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 1379  total_loss: 1.819  loss_cls: 0.4401  loss_box_reg: 0.6147  loss_mask: 0.3276  loss_rpn_cls: 0.1557  loss_rpn_loc: 0.2529  time: 0.6054  data_time: 0.2040  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:18:03 d2.utils.events]: \u001b[0m eta: 0:51:05  iter: 1399  total_loss: 1.66  loss_cls: 0.4221  loss_box_reg: 0.547  loss_mask: 0.311  loss_rpn_cls: 0.1274  loss_rpn_loc: 0.2329  time: 0.6050  data_time: 0.2322  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:18:14 d2.utils.events]: \u001b[0m eta: 0:50:54  iter: 1419  total_loss: 1.535  loss_cls: 0.3641  loss_box_reg: 0.5575  loss_mask: 0.3103  loss_rpn_cls: 0.09035  loss_rpn_loc: 0.2446  time: 0.6038  data_time: 0.1936  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:18:26 d2.utils.events]: \u001b[0m eta: 0:50:39  iter: 1439  total_loss: 1.865  loss_cls: 0.5062  loss_box_reg: 0.5982  loss_mask: 0.3377  loss_rpn_cls: 0.1606  loss_rpn_loc: 0.2673  time: 0.6036  data_time: 0.2548  lr: 0.0005  max_mem: 6817M\n",
      "\u001b[32m[01/11 19:18:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:18:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:18:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:18:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:18:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:18:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0714 s/iter. Eval: 0.0085 s/iter. Total: 0.0804 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 19:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0746 s/iter. Eval: 0.0108 s/iter. Total: 0.0861 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:18:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.912978 (0.085457 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:18:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073933 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:18:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:18:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2075757113327967\n",
      "\u001b[32m[01/11 19:18:48 d2.utils.events]: \u001b[0m eta: 0:50:34  iter: 1459  total_loss: 1.652  loss_cls: 0.3818  loss_box_reg: 0.5259  loss_mask: 0.309  loss_rpn_cls: 0.09835  loss_rpn_loc: 0.244  time: 0.6029  data_time: 0.2104  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:19:00 d2.utils.events]: \u001b[0m eta: 0:50:34  iter: 1479  total_loss: 1.686  loss_cls: 0.3916  loss_box_reg: 0.586  loss_mask: 0.3216  loss_rpn_cls: 0.1353  loss_rpn_loc: 0.2281  time: 0.6032  data_time: 0.2783  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:19:14 d2.utils.events]: \u001b[0m eta: 0:50:26  iter: 1499  total_loss: 1.69  loss_cls: 0.4279  loss_box_reg: 0.582  loss_mask: 0.3167  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.2427  time: 0.6042  data_time: 0.3155  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:19:29 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 1519  total_loss: 1.645  loss_cls: 0.4308  loss_box_reg: 0.5081  loss_mask: 0.3388  loss_rpn_cls: 0.155  loss_rpn_loc: 0.2492  time: 0.6060  data_time: 0.3732  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:19:43 d2.utils.events]: \u001b[0m eta: 0:50:15  iter: 1539  total_loss: 1.723  loss_cls: 0.4109  loss_box_reg: 0.572  loss_mask: 0.3147  loss_rpn_cls: 0.1464  loss_rpn_loc: 0.2528  time: 0.6070  data_time: 0.3434  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:19:57 d2.utils.events]: \u001b[0m eta: 0:50:11  iter: 1559  total_loss: 1.819  loss_cls: 0.4424  loss_box_reg: 0.563  loss_mask: 0.3261  loss_rpn_cls: 0.1413  loss_rpn_loc: 0.2444  time: 0.6084  data_time: 0.3635  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:20:09 d2.utils.events]: \u001b[0m eta: 0:50:05  iter: 1579  total_loss: 1.714  loss_cls: 0.4216  loss_box_reg: 0.5613  loss_mask: 0.3279  loss_rpn_cls: 0.1683  loss_rpn_loc: 0.2719  time: 0.6087  data_time: 0.2832  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:20:21 d2.utils.events]: \u001b[0m eta: 0:49:55  iter: 1599  total_loss: 1.844  loss_cls: 0.4721  loss_box_reg: 0.5559  loss_mask: 0.3505  loss_rpn_cls: 0.1424  loss_rpn_loc: 0.2674  time: 0.6080  data_time: 0.2232  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:20:29 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 1619  total_loss: 1.774  loss_cls: 0.4495  loss_box_reg: 0.5897  loss_mask: 0.3295  loss_rpn_cls: 0.1166  loss_rpn_loc: 0.2439  time: 0.6059  data_time: 0.1123  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:20:39 d2.utils.events]: \u001b[0m eta: 0:49:39  iter: 1639  total_loss: 1.755  loss_cls: 0.4166  loss_box_reg: 0.6042  loss_mask: 0.3217  loss_rpn_cls: 0.1406  loss_rpn_loc: 0.259  time: 0.6047  data_time: 0.1778  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:20:52 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 1659  total_loss: 1.835  loss_cls: 0.5356  loss_box_reg: 0.5815  loss_mask: 0.3349  loss_rpn_cls: 0.1704  loss_rpn_loc: 0.2572  time: 0.6047  data_time: 0.2576  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:21:00 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 1679  total_loss: 1.968  loss_cls: 0.5058  loss_box_reg: 0.6102  loss_mask: 0.3298  loss_rpn_cls: 0.1317  loss_rpn_loc: 0.2481  time: 0.6023  data_time: 0.0851  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:21:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:21:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:21:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:21:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:21:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:21:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0715 s/iter. Eval: 0.0083 s/iter. Total: 0.0806 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 19:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0007 s/iter. Inference: 0.0724 s/iter. Eval: 0.0079 s/iter. Total: 0.0810 s/iter. ETA=0:00:03\n",
      "\u001b[32m[01/11 19:21:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.275532 (0.079961 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:21:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071840 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:21:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:21:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.19435035322373484\n",
      "\u001b[32m[01/11 19:21:21 d2.utils.events]: \u001b[0m eta: 0:49:17  iter: 1699  total_loss: 1.875  loss_cls: 0.5136  loss_box_reg: 0.5653  loss_mask: 0.3273  loss_rpn_cls: 0.1915  loss_rpn_loc: 0.2557  time: 0.6016  data_time: 0.1996  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:21:34 d2.utils.events]: \u001b[0m eta: 0:49:09  iter: 1719  total_loss: 1.883  loss_cls: 0.5346  loss_box_reg: 0.5539  loss_mask: 0.3383  loss_rpn_cls: 0.1656  loss_rpn_loc: 0.2633  time: 0.6023  data_time: 0.3130  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:21:44 d2.utils.events]: \u001b[0m eta: 0:48:57  iter: 1739  total_loss: 1.614  loss_cls: 0.3797  loss_box_reg: 0.5468  loss_mask: 0.3114  loss_rpn_cls: 0.07838  loss_rpn_loc: 0.2243  time: 0.6010  data_time: 0.1620  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:21:58 d2.utils.events]: \u001b[0m eta: 0:48:52  iter: 1759  total_loss: 1.781  loss_cls: 0.4681  loss_box_reg: 0.5387  loss_mask: 0.3178  loss_rpn_cls: 0.1648  loss_rpn_loc: 0.2653  time: 0.6019  data_time: 0.3434  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:22:08 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 1779  total_loss: 1.903  loss_cls: 0.519  loss_box_reg: 0.6199  loss_mask: 0.3034  loss_rpn_cls: 0.1596  loss_rpn_loc: 0.266  time: 0.6008  data_time: 0.1741  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:22:20 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 1799  total_loss: 1.618  loss_cls: 0.4215  loss_box_reg: 0.542  loss_mask: 0.2967  loss_rpn_cls: 0.1275  loss_rpn_loc: 0.2144  time: 0.6008  data_time: 0.2512  lr: 0.0005  max_mem: 6870M\n",
      "\u001b[32m[01/11 19:22:30 d2.utils.events]: \u001b[0m eta: 0:48:29  iter: 1819  total_loss: 1.734  loss_cls: 0.462  loss_box_reg: 0.5883  loss_mask: 0.317  loss_rpn_cls: 0.138  loss_rpn_loc: 0.2302  time: 0.5998  data_time: 0.1839  lr: 0.0005  max_mem: 6912M\n",
      "\u001b[32m[01/11 19:22:46 d2.utils.events]: \u001b[0m eta: 0:48:28  iter: 1839  total_loss: 1.598  loss_cls: 0.3907  loss_box_reg: 0.5504  loss_mask: 0.3197  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.2159  time: 0.6022  data_time: 0.4464  lr: 0.0005  max_mem: 6912M\n",
      "\u001b[32m[01/11 19:22:58 d2.utils.events]: \u001b[0m eta: 0:48:20  iter: 1859  total_loss: 1.654  loss_cls: 0.3735  loss_box_reg: 0.597  loss_mask: 0.3165  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.2432  time: 0.6018  data_time: 0.2377  lr: 0.0005  max_mem: 6912M\n",
      "\u001b[32m[01/11 19:23:12 d2.utils.events]: \u001b[0m eta: 0:48:14  iter: 1879  total_loss: 1.701  loss_cls: 0.4144  loss_box_reg: 0.5589  loss_mask: 0.342  loss_rpn_cls: 0.1849  loss_rpn_loc: 0.2873  time: 0.6030  data_time: 0.3665  lr: 0.0005  max_mem: 6912M\n",
      "\u001b[32m[01/11 19:23:24 d2.utils.events]: \u001b[0m eta: 0:48:06  iter: 1899  total_loss: 1.666  loss_cls: 0.3853  loss_box_reg: 0.5394  loss_mask: 0.3224  loss_rpn_cls: 0.1705  loss_rpn_loc: 0.2498  time: 0.6029  data_time: 0.2560  lr: 0.0005  max_mem: 6912M\n",
      "\u001b[32m[01/11 19:23:35 d2.utils.events]: \u001b[0m eta: 0:47:59  iter: 1919  total_loss: 1.702  loss_cls: 0.4068  loss_box_reg: 0.5966  loss_mask: 0.3306  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.2236  time: 0.6026  data_time: 0.2283  lr: 0.0005  max_mem: 6912M\n",
      "\u001b[32m[01/11 19:23:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:23:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:23:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:23:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:23:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:23:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0724 s/iter. Eval: 0.0070 s/iter. Total: 0.0799 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 19:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0745 s/iter. Eval: 0.0107 s/iter. Total: 0.0859 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:23:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.882170 (0.085191 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:23:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073654 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:23:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:23:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2132352343001227\n",
      "\u001b[32m[01/11 19:24:01 d2.utils.events]: \u001b[0m eta: 0:47:48  iter: 1939  total_loss: 1.759  loss_cls: 0.4407  loss_box_reg: 0.5715  loss_mask: 0.3246  loss_rpn_cls: 0.1294  loss_rpn_loc: 0.2493  time: 0.6037  data_time: 0.3403  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:24:14 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 1959  total_loss: 1.699  loss_cls: 0.4086  loss_box_reg: 0.5553  loss_mask: 0.3001  loss_rpn_cls: 0.126  loss_rpn_loc: 0.2541  time: 0.6045  data_time: 0.3330  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:24:25 d2.utils.events]: \u001b[0m eta: 0:47:31  iter: 1979  total_loss: 1.776  loss_cls: 0.4185  loss_box_reg: 0.6071  loss_mask: 0.3218  loss_rpn_cls: 0.1464  loss_rpn_loc: 0.2534  time: 0.6038  data_time: 0.2033  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:24:38 d2.utils.events]: \u001b[0m eta: 0:47:22  iter: 1999  total_loss: 1.876  loss_cls: 0.4738  loss_box_reg: 0.6094  loss_mask: 0.3304  loss_rpn_cls: 0.1521  loss_rpn_loc: 0.2574  time: 0.6041  data_time: 0.3076  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:24:52 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 2019  total_loss: 1.758  loss_cls: 0.4617  loss_box_reg: 0.5908  loss_mask: 0.348  loss_rpn_cls: 0.1379  loss_rpn_loc: 0.2765  time: 0.6049  data_time: 0.3547  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:25:04 d2.utils.events]: \u001b[0m eta: 0:47:13  iter: 2039  total_loss: 1.673  loss_cls: 0.4213  loss_box_reg: 0.5781  loss_mask: 0.3212  loss_rpn_cls: 0.116  loss_rpn_loc: 0.2462  time: 0.6049  data_time: 0.2650  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:25:13 d2.utils.events]: \u001b[0m eta: 0:47:06  iter: 2059  total_loss: 1.723  loss_cls: 0.3978  loss_box_reg: 0.5694  loss_mask: 0.3283  loss_rpn_cls: 0.126  loss_rpn_loc: 0.2424  time: 0.6038  data_time: 0.1591  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:25:23 d2.utils.events]: \u001b[0m eta: 0:46:49  iter: 2079  total_loss: 1.676  loss_cls: 0.3826  loss_box_reg: 0.6068  loss_mask: 0.3307  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.235  time: 0.6027  data_time: 0.1677  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:25:37 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 2099  total_loss: 1.661  loss_cls: 0.3747  loss_box_reg: 0.5843  loss_mask: 0.3258  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.266  time: 0.6036  data_time: 0.3548  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:25:50 d2.utils.events]: \u001b[0m eta: 0:46:49  iter: 2119  total_loss: 1.686  loss_cls: 0.4001  loss_box_reg: 0.553  loss_mask: 0.33  loss_rpn_cls: 0.17  loss_rpn_loc: 0.2548  time: 0.6042  data_time: 0.3100  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:26:02 d2.utils.events]: \u001b[0m eta: 0:46:42  iter: 2139  total_loss: 1.806  loss_cls: 0.4396  loss_box_reg: 0.6037  loss_mask: 0.317  loss_rpn_cls: 0.1529  loss_rpn_loc: 0.2474  time: 0.6040  data_time: 0.2529  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:26:12 d2.utils.events]: \u001b[0m eta: 0:46:35  iter: 2159  total_loss: 1.661  loss_cls: 0.4082  loss_box_reg: 0.6046  loss_mask: 0.3211  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.226  time: 0.6030  data_time: 0.1604  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:26:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:26:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:26:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:26:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:26:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:26:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0104 s/iter. Total: 0.0845 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0113 s/iter. Total: 0.0861 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:26:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.036294 (0.086520 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:26:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073900 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:26:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:26:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21116092774062484\n",
      "\u001b[32m[01/11 19:26:38 d2.utils.events]: \u001b[0m eta: 0:46:28  iter: 2179  total_loss: 1.618  loss_cls: 0.4044  loss_box_reg: 0.5402  loss_mask: 0.3013  loss_rpn_cls: 0.1423  loss_rpn_loc: 0.2275  time: 0.6044  data_time: 0.4060  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:26:50 d2.utils.events]: \u001b[0m eta: 0:46:20  iter: 2199  total_loss: 1.601  loss_cls: 0.3675  loss_box_reg: 0.5419  loss_mask: 0.2958  loss_rpn_cls: 0.1207  loss_rpn_loc: 0.2159  time: 0.6040  data_time: 0.2283  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:26:57 d2.utils.events]: \u001b[0m eta: 0:46:08  iter: 2219  total_loss: 1.627  loss_cls: 0.3936  loss_box_reg: 0.5843  loss_mask: 0.299  loss_rpn_cls: 0.09769  loss_rpn_loc: 0.2091  time: 0.6020  data_time: 0.0659  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:27:06 d2.utils.events]: \u001b[0m eta: 0:45:56  iter: 2239  total_loss: 1.725  loss_cls: 0.3947  loss_box_reg: 0.5896  loss_mask: 0.3287  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.2218  time: 0.6007  data_time: 0.1231  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:27:22 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 2259  total_loss: 1.743  loss_cls: 0.4309  loss_box_reg: 0.5774  loss_mask: 0.3288  loss_rpn_cls: 0.1601  loss_rpn_loc: 0.2784  time: 0.6023  data_time: 0.4237  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:27:35 d2.utils.events]: \u001b[0m eta: 0:45:47  iter: 2279  total_loss: 1.654  loss_cls: 0.4139  loss_box_reg: 0.5573  loss_mask: 0.3333  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.2463  time: 0.6027  data_time: 0.3157  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:27:47 d2.utils.events]: \u001b[0m eta: 0:45:39  iter: 2299  total_loss: 1.735  loss_cls: 0.3916  loss_box_reg: 0.5973  loss_mask: 0.3341  loss_rpn_cls: 0.1456  loss_rpn_loc: 0.2451  time: 0.6027  data_time: 0.2763  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:27:59 d2.utils.events]: \u001b[0m eta: 0:45:32  iter: 2319  total_loss: 1.806  loss_cls: 0.4282  loss_box_reg: 0.6128  loss_mask: 0.3222  loss_rpn_cls: 0.1497  loss_rpn_loc: 0.2479  time: 0.6025  data_time: 0.2458  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:28:12 d2.utils.events]: \u001b[0m eta: 0:45:28  iter: 2339  total_loss: 1.748  loss_cls: 0.4252  loss_box_reg: 0.5748  loss_mask: 0.3054  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.2677  time: 0.6030  data_time: 0.3144  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:28:27 d2.utils.events]: \u001b[0m eta: 0:45:29  iter: 2359  total_loss: 1.776  loss_cls: 0.4707  loss_box_reg: 0.5523  loss_mask: 0.3056  loss_rpn_cls: 0.1557  loss_rpn_loc: 0.2693  time: 0.6044  data_time: 0.3961  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:28:38 d2.utils.events]: \u001b[0m eta: 0:45:19  iter: 2379  total_loss: 1.635  loss_cls: 0.3611  loss_box_reg: 0.5768  loss_mask: 0.3255  loss_rpn_cls: 0.1123  loss_rpn_loc: 0.24  time: 0.6038  data_time: 0.1947  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:28:50 d2.utils.events]: \u001b[0m eta: 0:45:10  iter: 2399  total_loss: 1.703  loss_cls: 0.3943  loss_box_reg: 0.5673  loss_mask: 0.3174  loss_rpn_cls: 0.1452  loss_rpn_loc: 0.2401  time: 0.6038  data_time: 0.2735  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:29:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:29:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:29:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:29:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:29:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:29:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0731 s/iter. Eval: 0.0088 s/iter. Total: 0.0825 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0755 s/iter. Eval: 0.0112 s/iter. Total: 0.0875 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:29:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.055780 (0.086688 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:29:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074554 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:29:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:29:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21675921895936123\n",
      "\u001b[32m[01/11 19:29:15 d2.utils.events]: \u001b[0m eta: 0:45:21  iter: 2419  total_loss: 1.677  loss_cls: 0.4005  loss_box_reg: 0.5592  loss_mask: 0.3254  loss_rpn_cls: 0.139  loss_rpn_loc: 0.2352  time: 0.6043  data_time: 0.3026  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:29:27 d2.utils.events]: \u001b[0m eta: 0:45:15  iter: 2439  total_loss: 1.685  loss_cls: 0.4251  loss_box_reg: 0.5008  loss_mask: 0.3168  loss_rpn_cls: 0.1246  loss_rpn_loc: 0.228  time: 0.6045  data_time: 0.2909  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:29:39 d2.utils.events]: \u001b[0m eta: 0:45:08  iter: 2459  total_loss: 1.612  loss_cls: 0.3806  loss_box_reg: 0.555  loss_mask: 0.3125  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2226  time: 0.6045  data_time: 0.2587  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:29:54 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 2479  total_loss: 1.705  loss_cls: 0.4312  loss_box_reg: 0.5734  loss_mask: 0.3086  loss_rpn_cls: 0.144  loss_rpn_loc: 0.2679  time: 0.6056  data_time: 0.3733  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:30:06 d2.utils.events]: \u001b[0m eta: 0:44:58  iter: 2499  total_loss: 1.741  loss_cls: 0.4451  loss_box_reg: 0.5629  loss_mask: 0.321  loss_rpn_cls: 0.1498  loss_rpn_loc: 0.2469  time: 0.6057  data_time: 0.2723  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:30:18 d2.utils.events]: \u001b[0m eta: 0:44:50  iter: 2519  total_loss: 1.866  loss_cls: 0.4849  loss_box_reg: 0.5737  loss_mask: 0.3368  loss_rpn_cls: 0.1598  loss_rpn_loc: 0.2604  time: 0.6056  data_time: 0.2481  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:30:33 d2.utils.events]: \u001b[0m eta: 0:44:40  iter: 2539  total_loss: 1.756  loss_cls: 0.4438  loss_box_reg: 0.5703  loss_mask: 0.3337  loss_rpn_cls: 0.1409  loss_rpn_loc: 0.2499  time: 0.6067  data_time: 0.4118  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:30:46 d2.utils.events]: \u001b[0m eta: 0:44:33  iter: 2559  total_loss: 1.686  loss_cls: 0.4129  loss_box_reg: 0.5643  loss_mask: 0.3346  loss_rpn_cls: 0.1422  loss_rpn_loc: 0.2441  time: 0.6071  data_time: 0.3162  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:30:57 d2.utils.events]: \u001b[0m eta: 0:44:22  iter: 2579  total_loss: 1.787  loss_cls: 0.4284  loss_box_reg: 0.5697  loss_mask: 0.3316  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.2417  time: 0.6064  data_time: 0.1983  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:31:07 d2.utils.events]: \u001b[0m eta: 0:44:12  iter: 2599  total_loss: 1.701  loss_cls: 0.4079  loss_box_reg: 0.5928  loss_mask: 0.3133  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.2488  time: 0.6056  data_time: 0.1802  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:31:20 d2.utils.events]: \u001b[0m eta: 0:44:10  iter: 2619  total_loss: 1.728  loss_cls: 0.45  loss_box_reg: 0.5694  loss_mask: 0.3268  loss_rpn_cls: 0.1271  loss_rpn_loc: 0.252  time: 0.6059  data_time: 0.2995  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:31:31 d2.utils.events]: \u001b[0m eta: 0:44:05  iter: 2639  total_loss: 1.562  loss_cls: 0.4022  loss_box_reg: 0.5502  loss_mask: 0.2907  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.2072  time: 0.6055  data_time: 0.2262  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:31:41 d2.utils.events]: \u001b[0m eta: 0:43:50  iter: 2659  total_loss: 1.676  loss_cls: 0.3908  loss_box_reg: 0.5545  loss_mask: 0.3057  loss_rpn_cls: 0.1396  loss_rpn_loc: 0.2373  time: 0.6050  data_time: 0.1922  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:31:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:31:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:31:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:31:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:31:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:31:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0801 s/iter. Eval: 0.0128 s/iter. Total: 0.0936 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 19:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0771 s/iter. Eval: 0.0140 s/iter. Total: 0.0919 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 19:31:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.633016 (0.091664 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:31:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076621 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:31:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:31:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2285748924089632\n",
      "\u001b[32m[01/11 19:32:02 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 2679  total_loss: 1.573  loss_cls: 0.3631  loss_box_reg: 0.5531  loss_mask: 0.3075  loss_rpn_cls: 0.09766  loss_rpn_loc: 0.2223  time: 0.6038  data_time: 0.1201  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:32:18 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 2699  total_loss: 1.83  loss_cls: 0.4685  loss_box_reg: 0.573  loss_mask: 0.3355  loss_rpn_cls: 0.1407  loss_rpn_loc: 0.263  time: 0.6050  data_time: 0.3942  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:32:27 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 2719  total_loss: 1.517  loss_cls: 0.3562  loss_box_reg: 0.5675  loss_mask: 0.2939  loss_rpn_cls: 0.09786  loss_rpn_loc: 0.2361  time: 0.6041  data_time: 0.1459  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:32:39 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 2739  total_loss: 1.757  loss_cls: 0.4279  loss_box_reg: 0.5778  loss_mask: 0.3201  loss_rpn_cls: 0.1385  loss_rpn_loc: 0.2573  time: 0.6038  data_time: 0.2274  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:32:48 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 2759  total_loss: 1.624  loss_cls: 0.4155  loss_box_reg: 0.5408  loss_mask: 0.3112  loss_rpn_cls: 0.127  loss_rpn_loc: 0.2628  time: 0.6029  data_time: 0.1513  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:33:00 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 2779  total_loss: 1.782  loss_cls: 0.4612  loss_box_reg: 0.5953  loss_mask: 0.3152  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.2602  time: 0.6029  data_time: 0.2557  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:33:14 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 2799  total_loss: 1.817  loss_cls: 0.4402  loss_box_reg: 0.5809  loss_mask: 0.3317  loss_rpn_cls: 0.1292  loss_rpn_loc: 0.253  time: 0.6033  data_time: 0.3043  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:33:29 d2.utils.events]: \u001b[0m eta: 0:43:13  iter: 2819  total_loss: 1.656  loss_cls: 0.4056  loss_box_reg: 0.542  loss_mask: 0.3097  loss_rpn_cls: 0.1407  loss_rpn_loc: 0.2378  time: 0.6047  data_time: 0.4246  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:33:41 d2.utils.events]: \u001b[0m eta: 0:43:03  iter: 2839  total_loss: 1.69  loss_cls: 0.4196  loss_box_reg: 0.596  loss_mask: 0.3072  loss_rpn_cls: 0.123  loss_rpn_loc: 0.2302  time: 0.6046  data_time: 0.2470  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:33:52 d2.utils.events]: \u001b[0m eta: 0:42:57  iter: 2859  total_loss: 1.696  loss_cls: 0.4465  loss_box_reg: 0.554  loss_mask: 0.2983  loss_rpn_cls: 0.1382  loss_rpn_loc: 0.2106  time: 0.6041  data_time: 0.1993  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:34:01 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 2879  total_loss: 1.814  loss_cls: 0.4759  loss_box_reg: 0.6116  loss_mask: 0.3235  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.247  time: 0.6032  data_time: 0.1408  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:34:14 d2.utils.events]: \u001b[0m eta: 0:42:37  iter: 2899  total_loss: 1.617  loss_cls: 0.4226  loss_box_reg: 0.5441  loss_mask: 0.2986  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.2269  time: 0.6035  data_time: 0.3142  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:34:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:34:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:34:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:34:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:34:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:34:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0738 s/iter. Eval: 0.0106 s/iter. Total: 0.0850 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0741 s/iter. Eval: 0.0123 s/iter. Total: 0.0871 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:34:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.140349 (0.087417 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:34:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074196 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:34:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:34:27 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21206095239271153\n",
      "\u001b[32m[01/11 19:34:37 d2.utils.events]: \u001b[0m eta: 0:42:26  iter: 2919  total_loss: 1.575  loss_cls: 0.333  loss_box_reg: 0.5249  loss_mask: 0.319  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.2403  time: 0.6030  data_time: 0.2029  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:34:50 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 2939  total_loss: 1.705  loss_cls: 0.4158  loss_box_reg: 0.5496  loss_mask: 0.3131  loss_rpn_cls: 0.1695  loss_rpn_loc: 0.2389  time: 0.6034  data_time: 0.3164  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:35:00 d2.utils.events]: \u001b[0m eta: 0:42:03  iter: 2959  total_loss: 1.654  loss_cls: 0.4217  loss_box_reg: 0.5829  loss_mask: 0.3253  loss_rpn_cls: 0.1257  loss_rpn_loc: 0.2392  time: 0.6029  data_time: 0.1879  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:35:13 d2.utils.events]: \u001b[0m eta: 0:41:56  iter: 2979  total_loss: 1.757  loss_cls: 0.4117  loss_box_reg: 0.5675  loss_mask: 0.3414  loss_rpn_cls: 0.1232  loss_rpn_loc: 0.2474  time: 0.6031  data_time: 0.3060  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:35:25 d2.utils.events]: \u001b[0m eta: 0:41:44  iter: 2999  total_loss: 1.746  loss_cls: 0.4158  loss_box_reg: 0.591  loss_mask: 0.3117  loss_rpn_cls: 0.1306  loss_rpn_loc: 0.2516  time: 0.6029  data_time: 0.2384  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:35:34 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 3019  total_loss: 1.701  loss_cls: 0.4269  loss_box_reg: 0.5577  loss_mask: 0.3215  loss_rpn_cls: 0.09712  loss_rpn_loc: 0.2221  time: 0.6022  data_time: 0.1619  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:35:48 d2.utils.events]: \u001b[0m eta: 0:41:33  iter: 3039  total_loss: 1.777  loss_cls: 0.4436  loss_box_reg: 0.5898  loss_mask: 0.3161  loss_rpn_cls: 0.1505  loss_rpn_loc: 0.2487  time: 0.6027  data_time: 0.3362  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:36:00 d2.utils.events]: \u001b[0m eta: 0:41:27  iter: 3059  total_loss: 1.77  loss_cls: 0.4567  loss_box_reg: 0.5575  loss_mask: 0.3303  loss_rpn_cls: 0.1296  loss_rpn_loc: 0.2439  time: 0.6028  data_time: 0.2772  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:36:11 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 3079  total_loss: 1.585  loss_cls: 0.3741  loss_box_reg: 0.4927  loss_mask: 0.2892  loss_rpn_cls: 0.08435  loss_rpn_loc: 0.2245  time: 0.6023  data_time: 0.1893  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:36:25 d2.utils.events]: \u001b[0m eta: 0:41:19  iter: 3099  total_loss: 1.823  loss_cls: 0.5169  loss_box_reg: 0.5807  loss_mask: 0.3159  loss_rpn_cls: 0.1387  loss_rpn_loc: 0.2672  time: 0.6029  data_time: 0.3371  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:36:35 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 3119  total_loss: 1.635  loss_cls: 0.3947  loss_box_reg: 0.5821  loss_mask: 0.3209  loss_rpn_cls: 0.08505  loss_rpn_loc: 0.2363  time: 0.6024  data_time: 0.1773  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:36:48 d2.utils.events]: \u001b[0m eta: 0:40:55  iter: 3139  total_loss: 1.604  loss_cls: 0.3844  loss_box_reg: 0.5567  loss_mask: 0.3424  loss_rpn_cls: 0.08854  loss_rpn_loc: 0.2259  time: 0.6028  data_time: 0.3329  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:36:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:36:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:36:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:36:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:36:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:36:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0729 s/iter. Eval: 0.0083 s/iter. Total: 0.0819 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0142 s/iter. Total: 0.0902 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0752 s/iter. Eval: 0.0146 s/iter. Total: 0.0906 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 19:37:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.594714 (0.091334 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:37:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075248 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:37:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:37:03 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22347962508662764\n",
      "\u001b[32m[01/11 19:37:11 d2.utils.events]: \u001b[0m eta: 0:40:51  iter: 3159  total_loss: 1.711  loss_cls: 0.4301  loss_box_reg: 0.5795  loss_mask: 0.3234  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.2431  time: 0.6024  data_time: 0.2000  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:37:23 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 3179  total_loss: 1.661  loss_cls: 0.3786  loss_box_reg: 0.575  loss_mask: 0.3028  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.2257  time: 0.6022  data_time: 0.2396  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:37:32 d2.utils.events]: \u001b[0m eta: 0:40:32  iter: 3199  total_loss: 1.581  loss_cls: 0.3998  loss_box_reg: 0.5631  loss_mask: 0.307  loss_rpn_cls: 0.08772  loss_rpn_loc: 0.2288  time: 0.6014  data_time: 0.1393  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:37:43 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 3219  total_loss: 1.641  loss_cls: 0.4142  loss_box_reg: 0.5733  loss_mask: 0.3074  loss_rpn_cls: 0.1366  loss_rpn_loc: 0.2308  time: 0.6009  data_time: 0.2090  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:37:53 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 3239  total_loss: 1.677  loss_cls: 0.4198  loss_box_reg: 0.5656  loss_mask: 0.3162  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.2645  time: 0.6004  data_time: 0.1669  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:38:03 d2.utils.events]: \u001b[0m eta: 0:40:12  iter: 3259  total_loss: 1.692  loss_cls: 0.4297  loss_box_reg: 0.5534  loss_mask: 0.3352  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.2595  time: 0.5999  data_time: 0.1895  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:38:16 d2.utils.events]: \u001b[0m eta: 0:40:07  iter: 3279  total_loss: 1.658  loss_cls: 0.4181  loss_box_reg: 0.5543  loss_mask: 0.3248  loss_rpn_cls: 0.131  loss_rpn_loc: 0.2301  time: 0.6001  data_time: 0.2882  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:38:25 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 3299  total_loss: 1.64  loss_cls: 0.4083  loss_box_reg: 0.5799  loss_mask: 0.3044  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.2214  time: 0.5993  data_time: 0.1535  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:38:37 d2.utils.events]: \u001b[0m eta: 0:39:50  iter: 3319  total_loss: 1.717  loss_cls: 0.4098  loss_box_reg: 0.5663  loss_mask: 0.3154  loss_rpn_cls: 0.1241  loss_rpn_loc: 0.2387  time: 0.5991  data_time: 0.2252  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:38:49 d2.utils.events]: \u001b[0m eta: 0:39:42  iter: 3339  total_loss: 1.678  loss_cls: 0.4088  loss_box_reg: 0.5281  loss_mask: 0.3141  loss_rpn_cls: 0.1317  loss_rpn_loc: 0.2456  time: 0.5991  data_time: 0.2685  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:39:03 d2.utils.events]: \u001b[0m eta: 0:39:27  iter: 3359  total_loss: 1.699  loss_cls: 0.3729  loss_box_reg: 0.5485  loss_mask: 0.3179  loss_rpn_cls: 0.1441  loss_rpn_loc: 0.2467  time: 0.5997  data_time: 0.3686  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:39:16 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 3379  total_loss: 1.685  loss_cls: 0.3896  loss_box_reg: 0.5338  loss_mask: 0.3336  loss_rpn_cls: 0.1455  loss_rpn_loc: 0.2478  time: 0.6000  data_time: 0.3060  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:39:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:39:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:39:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:39:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:39:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:39:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0718 s/iter. Eval: 0.0085 s/iter. Total: 0.0808 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 19:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0127 s/iter. Total: 0.0873 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:39:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.255932 (0.088413 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:39:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074124 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:39:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:39:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22178862249824333\n",
      "\u001b[32m[01/11 19:39:39 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 3399  total_loss: 1.746  loss_cls: 0.4597  loss_box_reg: 0.5766  loss_mask: 0.3177  loss_rpn_cls: 0.124  loss_rpn_loc: 0.2683  time: 0.5998  data_time: 0.2408  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:39:48 d2.utils.events]: \u001b[0m eta: 0:38:58  iter: 3419  total_loss: 1.605  loss_cls: 0.3775  loss_box_reg: 0.5577  loss_mask: 0.3059  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.2237  time: 0.5990  data_time: 0.1312  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:40:00 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 3439  total_loss: 1.712  loss_cls: 0.4255  loss_box_reg: 0.564  loss_mask: 0.3231  loss_rpn_cls: 0.1611  loss_rpn_loc: 0.2605  time: 0.5992  data_time: 0.2891  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:40:10 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 3459  total_loss: 1.834  loss_cls: 0.4443  loss_box_reg: 0.562  loss_mask: 0.3452  loss_rpn_cls: 0.1672  loss_rpn_loc: 0.261  time: 0.5986  data_time: 0.1569  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:40:24 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 3479  total_loss: 1.757  loss_cls: 0.4021  loss_box_reg: 0.5703  loss_mask: 0.3172  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.2525  time: 0.5990  data_time: 0.3095  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:40:39 d2.utils.events]: \u001b[0m eta: 0:38:28  iter: 3499  total_loss: 1.553  loss_cls: 0.3521  loss_box_reg: 0.5258  loss_mask: 0.3126  loss_rpn_cls: 0.07915  loss_rpn_loc: 0.2405  time: 0.5998  data_time: 0.3979  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:40:50 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 3519  total_loss: 1.788  loss_cls: 0.4328  loss_box_reg: 0.5967  loss_mask: 0.3091  loss_rpn_cls: 0.1214  loss_rpn_loc: 0.2595  time: 0.5997  data_time: 0.2335  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:41:01 d2.utils.events]: \u001b[0m eta: 0:38:12  iter: 3539  total_loss: 1.653  loss_cls: 0.3739  loss_box_reg: 0.5524  loss_mask: 0.3104  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.2308  time: 0.5994  data_time: 0.2092  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:41:13 d2.utils.events]: \u001b[0m eta: 0:38:05  iter: 3559  total_loss: 1.752  loss_cls: 0.4358  loss_box_reg: 0.5915  loss_mask: 0.313  loss_rpn_cls: 0.1227  loss_rpn_loc: 0.2413  time: 0.5993  data_time: 0.2517  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:41:26 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 3579  total_loss: 1.738  loss_cls: 0.4621  loss_box_reg: 0.5637  loss_mask: 0.3347  loss_rpn_cls: 0.1364  loss_rpn_loc: 0.2578  time: 0.5996  data_time: 0.3036  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:41:36 d2.utils.events]: \u001b[0m eta: 0:37:51  iter: 3599  total_loss: 1.754  loss_cls: 0.4184  loss_box_reg: 0.6053  loss_mask: 0.3131  loss_rpn_cls: 0.1244  loss_rpn_loc: 0.2281  time: 0.5991  data_time: 0.1921  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:41:49 d2.utils.events]: \u001b[0m eta: 0:37:44  iter: 3619  total_loss: 1.568  loss_cls: 0.3841  loss_box_reg: 0.5342  loss_mask: 0.2906  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.2227  time: 0.5994  data_time: 0.3042  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:41:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:41:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:41:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:41:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:41:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:41:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0731 s/iter. Eval: 0.0103 s/iter. Total: 0.0841 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0113 s/iter. Total: 0.0858 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:42:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.873229 (0.085114 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:42:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073304 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:42:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:42:06 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.20906938369798764\n",
      "\u001b[32m[01/11 19:42:11 d2.utils.events]: \u001b[0m eta: 0:37:36  iter: 3639  total_loss: 1.653  loss_cls: 0.3945  loss_box_reg: 0.5516  loss_mask: 0.3001  loss_rpn_cls: 0.1244  loss_rpn_loc: 0.2276  time: 0.5992  data_time: 0.2162  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:42:23 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 3659  total_loss: 1.873  loss_cls: 0.4371  loss_box_reg: 0.574  loss_mask: 0.3259  loss_rpn_cls: 0.1459  loss_rpn_loc: 0.2644  time: 0.5992  data_time: 0.2590  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:42:37 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 3679  total_loss: 1.681  loss_cls: 0.3993  loss_box_reg: 0.5442  loss_mask: 0.3055  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.2643  time: 0.5996  data_time: 0.3196  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:42:46 d2.utils.events]: \u001b[0m eta: 0:37:17  iter: 3699  total_loss: 1.478  loss_cls: 0.3675  loss_box_reg: 0.5374  loss_mask: 0.2996  loss_rpn_cls: 0.08864  loss_rpn_loc: 0.1969  time: 0.5989  data_time: 0.1638  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:42:58 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 3719  total_loss: 1.496  loss_cls: 0.3396  loss_box_reg: 0.5423  loss_mask: 0.3154  loss_rpn_cls: 0.08469  loss_rpn_loc: 0.2267  time: 0.5989  data_time: 0.2563  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:43:10 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 3739  total_loss: 1.669  loss_cls: 0.4154  loss_box_reg: 0.5389  loss_mask: 0.3166  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.2353  time: 0.5990  data_time: 0.2800  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:43:21 d2.utils.events]: \u001b[0m eta: 0:36:56  iter: 3759  total_loss: 1.635  loss_cls: 0.4014  loss_box_reg: 0.563  loss_mask: 0.3084  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.2398  time: 0.5985  data_time: 0.1771  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:43:35 d2.utils.events]: \u001b[0m eta: 0:36:49  iter: 3779  total_loss: 1.681  loss_cls: 0.4252  loss_box_reg: 0.5752  loss_mask: 0.3284  loss_rpn_cls: 0.1399  loss_rpn_loc: 0.2569  time: 0.5991  data_time: 0.3713  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:43:49 d2.utils.events]: \u001b[0m eta: 0:36:37  iter: 3799  total_loss: 1.673  loss_cls: 0.4197  loss_box_reg: 0.5585  loss_mask: 0.3097  loss_rpn_cls: 0.1337  loss_rpn_loc: 0.2366  time: 0.5997  data_time: 0.3588  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:44:01 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 3819  total_loss: 1.689  loss_cls: 0.4157  loss_box_reg: 0.617  loss_mask: 0.3137  loss_rpn_cls: 0.1217  loss_rpn_loc: 0.242  time: 0.5997  data_time: 0.2701  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:44:17 d2.utils.events]: \u001b[0m eta: 0:36:19  iter: 3839  total_loss: 1.701  loss_cls: 0.4299  loss_box_reg: 0.5347  loss_mask: 0.3266  loss_rpn_cls: 0.1396  loss_rpn_loc: 0.2409  time: 0.6006  data_time: 0.4272  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:44:29 d2.utils.events]: \u001b[0m eta: 0:36:13  iter: 3859  total_loss: 1.705  loss_cls: 0.4423  loss_box_reg: 0.5763  loss_mask: 0.313  loss_rpn_cls: 0.1306  loss_rpn_loc: 0.2455  time: 0.6006  data_time: 0.2616  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:44:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:44:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:44:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:44:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:44:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:44:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0721 s/iter. Eval: 0.0091 s/iter. Total: 0.0818 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0131 s/iter. Total: 0.0881 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:44:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.343267 (0.089166 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:44:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074458 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:44:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:44:45 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23476201548751557\n",
      "\u001b[32m[01/11 19:44:47 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 3879  total_loss: 1.562  loss_cls: 0.3604  loss_box_reg: 0.5736  loss_mask: 0.2883  loss_rpn_cls: 0.09783  loss_rpn_loc: 0.2122  time: 0.5993  data_time: 0.0353  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:44:57 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 3899  total_loss: 1.571  loss_cls: 0.3525  loss_box_reg: 0.5495  loss_mask: 0.3035  loss_rpn_cls: 0.08351  loss_rpn_loc: 0.2024  time: 0.5988  data_time: 0.1779  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:45:11 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 3919  total_loss: 1.62  loss_cls: 0.3912  loss_box_reg: 0.5426  loss_mask: 0.3027  loss_rpn_cls: 0.117  loss_rpn_loc: 0.2535  time: 0.5992  data_time: 0.3436  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:45:20 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 3939  total_loss: 1.634  loss_cls: 0.4046  loss_box_reg: 0.5633  loss_mask: 0.3202  loss_rpn_cls: 0.08375  loss_rpn_loc: 0.2207  time: 0.5986  data_time: 0.1409  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:45:32 d2.utils.events]: \u001b[0m eta: 0:35:39  iter: 3959  total_loss: 1.724  loss_cls: 0.4337  loss_box_reg: 0.5641  loss_mask: 0.32  loss_rpn_cls: 0.1197  loss_rpn_loc: 0.2287  time: 0.5986  data_time: 0.2589  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:45:45 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 3979  total_loss: 1.697  loss_cls: 0.416  loss_box_reg: 0.5662  loss_mask: 0.3226  loss_rpn_cls: 0.1228  loss_rpn_loc: 0.2344  time: 0.5987  data_time: 0.2806  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:45:55 d2.utils.events]: \u001b[0m eta: 0:35:30  iter: 3999  total_loss: 1.685  loss_cls: 0.4127  loss_box_reg: 0.5504  loss_mask: 0.3173  loss_rpn_cls: 0.1317  loss_rpn_loc: 0.2409  time: 0.5982  data_time: 0.1681  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:46:07 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 4019  total_loss: 1.725  loss_cls: 0.4053  loss_box_reg: 0.5894  loss_mask: 0.319  loss_rpn_cls: 0.1414  loss_rpn_loc: 0.2611  time: 0.5983  data_time: 0.2679  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:46:22 d2.utils.events]: \u001b[0m eta: 0:35:17  iter: 4039  total_loss: 1.622  loss_cls: 0.3748  loss_box_reg: 0.5164  loss_mask: 0.3112  loss_rpn_cls: 0.1192  loss_rpn_loc: 0.2381  time: 0.5989  data_time: 0.3864  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:46:32 d2.utils.events]: \u001b[0m eta: 0:35:08  iter: 4059  total_loss: 1.666  loss_cls: 0.3868  loss_box_reg: 0.5579  loss_mask: 0.3095  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.2287  time: 0.5985  data_time: 0.1752  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:46:46 d2.utils.events]: \u001b[0m eta: 0:35:02  iter: 4079  total_loss: 1.688  loss_cls: 0.3952  loss_box_reg: 0.5484  loss_mask: 0.3222  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.2359  time: 0.5989  data_time: 0.3362  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:46:58 d2.utils.events]: \u001b[0m eta: 0:34:53  iter: 4099  total_loss: 1.667  loss_cls: 0.3923  loss_box_reg: 0.5817  loss_mask: 0.322  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.2214  time: 0.5990  data_time: 0.2847  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:47:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:47:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:47:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:47:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:47:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:47:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0775 s/iter. Eval: 0.0096 s/iter. Total: 0.0877 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0791 s/iter. Eval: 0.0154 s/iter. Total: 0.0952 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 19:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0796 s/iter. Eval: 0.0158 s/iter. Total: 0.0962 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 19:47:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.221288 (0.096735 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:47:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079660 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:47:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:47:20 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2251070917204853\n",
      "\u001b[32m[01/11 19:47:22 d2.utils.events]: \u001b[0m eta: 0:34:46  iter: 4119  total_loss: 1.567  loss_cls: 0.4016  loss_box_reg: 0.5705  loss_mask: 0.301  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.2256  time: 0.5989  data_time: 0.2285  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:47:34 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 4139  total_loss: 1.712  loss_cls: 0.4083  loss_box_reg: 0.5482  loss_mask: 0.3195  loss_rpn_cls: 0.1289  loss_rpn_loc: 0.2457  time: 0.5990  data_time: 0.2589  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:47:48 d2.utils.events]: \u001b[0m eta: 0:34:34  iter: 4159  total_loss: 1.899  loss_cls: 0.526  loss_box_reg: 0.5653  loss_mask: 0.3292  loss_rpn_cls: 0.1878  loss_rpn_loc: 0.2835  time: 0.5995  data_time: 0.3369  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:48:00 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 4179  total_loss: 1.767  loss_cls: 0.4674  loss_box_reg: 0.5567  loss_mask: 0.307  loss_rpn_cls: 0.128  loss_rpn_loc: 0.2519  time: 0.5995  data_time: 0.2508  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:48:12 d2.utils.events]: \u001b[0m eta: 0:34:31  iter: 4199  total_loss: 1.632  loss_cls: 0.4114  loss_box_reg: 0.5798  loss_mask: 0.3177  loss_rpn_cls: 0.1243  loss_rpn_loc: 0.2202  time: 0.5995  data_time: 0.2418  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:48:25 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 4219  total_loss: 1.675  loss_cls: 0.4364  loss_box_reg: 0.5682  loss_mask: 0.3131  loss_rpn_cls: 0.1424  loss_rpn_loc: 0.2415  time: 0.5996  data_time: 0.2677  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:48:37 d2.utils.events]: \u001b[0m eta: 0:34:18  iter: 4239  total_loss: 1.746  loss_cls: 0.4317  loss_box_reg: 0.5416  loss_mask: 0.308  loss_rpn_cls: 0.134  loss_rpn_loc: 0.2601  time: 0.5997  data_time: 0.2673  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:48:48 d2.utils.events]: \u001b[0m eta: 0:34:10  iter: 4259  total_loss: 1.681  loss_cls: 0.4053  loss_box_reg: 0.5448  loss_mask: 0.3088  loss_rpn_cls: 0.08192  loss_rpn_loc: 0.2225  time: 0.5993  data_time: 0.1889  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:49:02 d2.utils.events]: \u001b[0m eta: 0:34:07  iter: 4279  total_loss: 1.647  loss_cls: 0.4103  loss_box_reg: 0.5625  loss_mask: 0.3134  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.2514  time: 0.5998  data_time: 0.3552  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:49:14 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 4299  total_loss: 1.535  loss_cls: 0.3998  loss_box_reg: 0.517  loss_mask: 0.3116  loss_rpn_cls: 0.08515  loss_rpn_loc: 0.207  time: 0.5998  data_time: 0.2540  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:49:28 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 4319  total_loss: 1.569  loss_cls: 0.3681  loss_box_reg: 0.4959  loss_mask: 0.3053  loss_rpn_cls: 0.1272  loss_rpn_loc: 0.2369  time: 0.6003  data_time: 0.3812  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:49:37 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 4339  total_loss: 1.688  loss_cls: 0.4048  loss_box_reg: 0.5743  loss_mask: 0.315  loss_rpn_cls: 0.1187  loss_rpn_loc: 0.2505  time: 0.5997  data_time: 0.1373  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:49:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:49:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:49:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:49:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:49:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:49:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0732 s/iter. Eval: 0.0095 s/iter. Total: 0.0833 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0158 s/iter. Total: 0.0934 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 19:49:57 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0771 s/iter. Eval: 0.0159 s/iter. Total: 0.0938 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 19:49:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.958817 (0.094473 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:49:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077157 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:49:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:49:58 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21343010627399103\n",
      "\u001b[32m[01/11 19:49:59 d2.utils.events]: \u001b[0m eta: 0:33:38  iter: 4359  total_loss: 1.707  loss_cls: 0.4136  loss_box_reg: 0.5965  loss_mask: 0.3255  loss_rpn_cls: 0.07266  loss_rpn_loc: 0.2388  time: 0.5991  data_time: 0.1432  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:50:09 d2.utils.events]: \u001b[0m eta: 0:33:29  iter: 4379  total_loss: 1.555  loss_cls: 0.3785  loss_box_reg: 0.5777  loss_mask: 0.3182  loss_rpn_cls: 0.1297  loss_rpn_loc: 0.2352  time: 0.5987  data_time: 0.1766  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:50:21 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 4399  total_loss: 1.577  loss_cls: 0.3722  loss_box_reg: 0.5478  loss_mask: 0.3075  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.227  time: 0.5987  data_time: 0.2473  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:50:33 d2.utils.events]: \u001b[0m eta: 0:33:20  iter: 4419  total_loss: 1.698  loss_cls: 0.4322  loss_box_reg: 0.5661  loss_mask: 0.3259  loss_rpn_cls: 0.1449  loss_rpn_loc: 0.2209  time: 0.5987  data_time: 0.2519  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:50:43 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 4439  total_loss: 1.565  loss_cls: 0.3694  loss_box_reg: 0.5449  loss_mask: 0.3151  loss_rpn_cls: 0.09365  loss_rpn_loc: 0.2406  time: 0.5982  data_time: 0.1537  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:50:55 d2.utils.events]: \u001b[0m eta: 0:33:06  iter: 4459  total_loss: 1.706  loss_cls: 0.4155  loss_box_reg: 0.5238  loss_mask: 0.3199  loss_rpn_cls: 0.1252  loss_rpn_loc: 0.2484  time: 0.5982  data_time: 0.2467  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:51:06 d2.utils.events]: \u001b[0m eta: 0:32:57  iter: 4479  total_loss: 1.678  loss_cls: 0.405  loss_box_reg: 0.577  loss_mask: 0.3187  loss_rpn_cls: 0.09569  loss_rpn_loc: 0.2448  time: 0.5980  data_time: 0.2019  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:51:16 d2.utils.events]: \u001b[0m eta: 0:32:48  iter: 4499  total_loss: 1.713  loss_cls: 0.423  loss_box_reg: 0.5505  loss_mask: 0.3136  loss_rpn_cls: 0.08972  loss_rpn_loc: 0.226  time: 0.5976  data_time: 0.1779  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:51:29 d2.utils.events]: \u001b[0m eta: 0:32:40  iter: 4519  total_loss: 1.643  loss_cls: 0.4131  loss_box_reg: 0.5455  loss_mask: 0.31  loss_rpn_cls: 0.1197  loss_rpn_loc: 0.231  time: 0.5978  data_time: 0.2977  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:51:43 d2.utils.events]: \u001b[0m eta: 0:32:36  iter: 4539  total_loss: 1.526  loss_cls: 0.3841  loss_box_reg: 0.5185  loss_mask: 0.3091  loss_rpn_cls: 0.1353  loss_rpn_loc: 0.2466  time: 0.5982  data_time: 0.3436  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:51:57 d2.utils.events]: \u001b[0m eta: 0:32:26  iter: 4559  total_loss: 1.677  loss_cls: 0.3986  loss_box_reg: 0.5716  loss_mask: 0.3299  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.2607  time: 0.5988  data_time: 0.3812  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:52:09 d2.utils.events]: \u001b[0m eta: 0:32:21  iter: 4579  total_loss: 1.629  loss_cls: 0.3919  loss_box_reg: 0.5543  loss_mask: 0.3078  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.2375  time: 0.5986  data_time: 0.2236  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:52:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:52:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:52:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:52:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:52:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:52:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0780 s/iter. Eval: 0.0103 s/iter. Total: 0.0889 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:52:26 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0782 s/iter. Eval: 0.0159 s/iter. Total: 0.0949 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 19:52:31 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0156 s/iter. Total: 0.0933 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 19:52:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.894761 (0.093920 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:52:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076988 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:52:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:52:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2316304960895172\n",
      "\u001b[32m[01/11 19:52:32 d2.utils.events]: \u001b[0m eta: 0:32:16  iter: 4599  total_loss: 1.595  loss_cls: 0.4137  loss_box_reg: 0.5692  loss_mask: 0.3065  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.24  time: 0.5984  data_time: 0.1970  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:52:46 d2.utils.events]: \u001b[0m eta: 0:32:09  iter: 4619  total_loss: 1.729  loss_cls: 0.4165  loss_box_reg: 0.581  loss_mask: 0.3215  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.2722  time: 0.5989  data_time: 0.3523  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:53:01 d2.utils.events]: \u001b[0m eta: 0:32:08  iter: 4639  total_loss: 1.792  loss_cls: 0.4553  loss_box_reg: 0.576  loss_mask: 0.3308  loss_rpn_cls: 0.1631  loss_rpn_loc: 0.257  time: 0.5995  data_time: 0.3674  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:53:11 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 4659  total_loss: 1.57  loss_cls: 0.3762  loss_box_reg: 0.5622  loss_mask: 0.3012  loss_rpn_cls: 0.08582  loss_rpn_loc: 0.2161  time: 0.5992  data_time: 0.1856  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:53:22 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 4679  total_loss: 1.512  loss_cls: 0.3738  loss_box_reg: 0.5244  loss_mask: 0.2855  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2117  time: 0.5988  data_time: 0.1644  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:53:39 d2.utils.events]: \u001b[0m eta: 0:31:48  iter: 4699  total_loss: 1.594  loss_cls: 0.3985  loss_box_reg: 0.558  loss_mask: 0.3089  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.2344  time: 0.6001  data_time: 0.5354  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:53:51 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 4719  total_loss: 1.632  loss_cls: 0.4079  loss_box_reg: 0.5183  loss_mask: 0.3066  loss_rpn_cls: 0.15  loss_rpn_loc: 0.2463  time: 0.5999  data_time: 0.2277  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:54:04 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 4739  total_loss: 1.582  loss_cls: 0.3502  loss_box_reg: 0.5334  loss_mask: 0.3194  loss_rpn_cls: 0.111  loss_rpn_loc: 0.2258  time: 0.6002  data_time: 0.3138  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:54:17 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 4759  total_loss: 1.597  loss_cls: 0.3815  loss_box_reg: 0.5431  loss_mask: 0.2972  loss_rpn_cls: 0.09178  loss_rpn_loc: 0.2445  time: 0.6004  data_time: 0.3161  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:54:27 d2.utils.events]: \u001b[0m eta: 0:31:20  iter: 4779  total_loss: 1.632  loss_cls: 0.3989  loss_box_reg: 0.5587  loss_mask: 0.2928  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.239  time: 0.6000  data_time: 0.1721  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:54:36 d2.utils.events]: \u001b[0m eta: 0:31:09  iter: 4799  total_loss: 1.676  loss_cls: 0.3757  loss_box_reg: 0.5472  loss_mask: 0.3214  loss_rpn_cls: 0.09562  loss_rpn_loc: 0.2371  time: 0.5993  data_time: 0.0926  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:54:48 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 4819  total_loss: 1.677  loss_cls: 0.3946  loss_box_reg: 0.5537  loss_mask: 0.3098  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.2305  time: 0.5994  data_time: 0.2886  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:55:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:55:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:55:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:55:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:55:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:55:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0093 s/iter. Total: 0.0820 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0119 s/iter. Total: 0.0860 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:55:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.036415 (0.086521 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:55:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073340 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:55:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:55:13 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21635498200392334\n",
      "\u001b[32m[01/11 19:55:13 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 4839  total_loss: 1.725  loss_cls: 0.4326  loss_box_reg: 0.5586  loss_mask: 0.3233  loss_rpn_cls: 0.1736  loss_rpn_loc: 0.2765  time: 0.5996  data_time: 0.3082  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:55:20 d2.utils.events]: \u001b[0m eta: 0:30:44  iter: 4859  total_loss: 1.579  loss_cls: 0.3813  loss_box_reg: 0.5912  loss_mask: 0.3135  loss_rpn_cls: 0.09278  loss_rpn_loc: 0.2157  time: 0.5986  data_time: 0.0199  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:55:33 d2.utils.events]: \u001b[0m eta: 0:30:42  iter: 4879  total_loss: 1.643  loss_cls: 0.4092  loss_box_reg: 0.553  loss_mask: 0.3144  loss_rpn_cls: 0.126  loss_rpn_loc: 0.2311  time: 0.5988  data_time: 0.2900  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:55:47 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 4899  total_loss: 1.729  loss_cls: 0.4387  loss_box_reg: 0.5377  loss_mask: 0.3471  loss_rpn_cls: 0.134  loss_rpn_loc: 0.2759  time: 0.5993  data_time: 0.3770  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:56:02 d2.utils.events]: \u001b[0m eta: 0:30:29  iter: 4919  total_loss: 1.774  loss_cls: 0.4464  loss_box_reg: 0.5862  loss_mask: 0.3328  loss_rpn_cls: 0.1623  loss_rpn_loc: 0.2417  time: 0.5999  data_time: 0.3834  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:56:15 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 4939  total_loss: 1.59  loss_cls: 0.4015  loss_box_reg: 0.5452  loss_mask: 0.3161  loss_rpn_cls: 0.1402  loss_rpn_loc: 0.2428  time: 0.6002  data_time: 0.3286  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:56:25 d2.utils.events]: \u001b[0m eta: 0:30:15  iter: 4959  total_loss: 1.464  loss_cls: 0.3325  loss_box_reg: 0.5296  loss_mask: 0.3093  loss_rpn_cls: 0.07808  loss_rpn_loc: 0.2149  time: 0.5997  data_time: 0.1621  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:56:36 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 4979  total_loss: 1.649  loss_cls: 0.3702  loss_box_reg: 0.5627  loss_mask: 0.2969  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.2316  time: 0.5994  data_time: 0.1705  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:56:44 d2.utils.events]: \u001b[0m eta: 0:29:58  iter: 4999  total_loss: 1.515  loss_cls: 0.3295  loss_box_reg: 0.5774  loss_mask: 0.3198  loss_rpn_cls: 0.05791  loss_rpn_loc: 0.2224  time: 0.5987  data_time: 0.1190  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:56:56 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 5019  total_loss: 1.709  loss_cls: 0.4189  loss_box_reg: 0.6133  loss_mask: 0.3186  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.2446  time: 0.5987  data_time: 0.2627  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:57:08 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 5039  total_loss: 1.708  loss_cls: 0.4146  loss_box_reg: 0.5519  loss_mask: 0.3558  loss_rpn_cls: 0.109  loss_rpn_loc: 0.2353  time: 0.5987  data_time: 0.2501  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:57:20 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 5059  total_loss: 1.557  loss_cls: 0.3643  loss_box_reg: 0.5079  loss_mask: 0.3085  loss_rpn_cls: 0.09009  loss_rpn_loc: 0.2098  time: 0.5986  data_time: 0.2373  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:57:33 d2.utils.events]: \u001b[0m eta: 0:29:26  iter: 5079  total_loss: 1.636  loss_cls: 0.3928  loss_box_reg: 0.5454  loss_mask: 0.3157  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.2143  time: 0.5989  data_time: 0.3191  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:57:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:57:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 19:57:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 19:57:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 19:57:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 19:57:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 19:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0750 s/iter. Eval: 0.0112 s/iter. Total: 0.0869 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 19:57:42 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0746 s/iter. Eval: 0.0122 s/iter. Total: 0.0876 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 19:57:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.227619 (0.088169 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:57:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074863 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 19:57:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 19:57:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22509384886648356\n",
      "\u001b[32m[01/11 19:57:58 d2.utils.events]: \u001b[0m eta: 0:29:21  iter: 5099  total_loss: 1.719  loss_cls: 0.4788  loss_box_reg: 0.5629  loss_mask: 0.3113  loss_rpn_cls: 0.1626  loss_rpn_loc: 0.2522  time: 0.5991  data_time: 0.3159  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:58:12 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 5119  total_loss: 1.6  loss_cls: 0.3957  loss_box_reg: 0.5292  loss_mask: 0.2928  loss_rpn_cls: 0.114  loss_rpn_loc: 0.2257  time: 0.5995  data_time: 0.3507  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:58:22 d2.utils.events]: \u001b[0m eta: 0:29:07  iter: 5139  total_loss: 1.603  loss_cls: 0.3832  loss_box_reg: 0.5646  loss_mask: 0.2947  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2105  time: 0.5991  data_time: 0.1678  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:58:32 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 5159  total_loss: 1.707  loss_cls: 0.428  loss_box_reg: 0.5736  loss_mask: 0.3161  loss_rpn_cls: 0.1162  loss_rpn_loc: 0.2304  time: 0.5988  data_time: 0.2060  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:58:42 d2.utils.events]: \u001b[0m eta: 0:28:47  iter: 5179  total_loss: 1.543  loss_cls: 0.3798  loss_box_reg: 0.5806  loss_mask: 0.3176  loss_rpn_cls: 0.09398  loss_rpn_loc: 0.2281  time: 0.5984  data_time: 0.1587  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:58:57 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 5199  total_loss: 1.601  loss_cls: 0.3917  loss_box_reg: 0.5349  loss_mask: 0.3047  loss_rpn_cls: 0.1275  loss_rpn_loc: 0.237  time: 0.5990  data_time: 0.3816  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:59:09 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 5219  total_loss: 1.632  loss_cls: 0.368  loss_box_reg: 0.5812  loss_mask: 0.2967  loss_rpn_cls: 0.108  loss_rpn_loc: 0.2646  time: 0.5991  data_time: 0.2885  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:59:24 d2.utils.events]: \u001b[0m eta: 0:28:26  iter: 5239  total_loss: 1.583  loss_cls: 0.3814  loss_box_reg: 0.5222  loss_mask: 0.3125  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.221  time: 0.5996  data_time: 0.3920  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:59:36 d2.utils.events]: \u001b[0m eta: 0:28:18  iter: 5259  total_loss: 1.618  loss_cls: 0.3572  loss_box_reg: 0.5474  loss_mask: 0.3341  loss_rpn_cls: 0.1281  loss_rpn_loc: 0.2267  time: 0.5996  data_time: 0.2714  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:59:46 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 5279  total_loss: 1.785  loss_cls: 0.4291  loss_box_reg: 0.6003  loss_mask: 0.3357  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.2391  time: 0.5991  data_time: 0.1316  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 19:59:59 d2.utils.events]: \u001b[0m eta: 0:28:03  iter: 5299  total_loss: 1.689  loss_cls: 0.3762  loss_box_reg: 0.5542  loss_mask: 0.3288  loss_rpn_cls: 0.1251  loss_rpn_loc: 0.2524  time: 0.5993  data_time: 0.3051  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:00:08 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 5319  total_loss: 1.659  loss_cls: 0.3987  loss_box_reg: 0.5753  loss_mask: 0.3123  loss_rpn_cls: 0.101  loss_rpn_loc: 0.2344  time: 0.5988  data_time: 0.1170  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:00:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:00:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:00:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:00:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:00:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:00:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0747 s/iter. Eval: 0.0122 s/iter. Total: 0.0875 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0780 s/iter. Eval: 0.0183 s/iter. Total: 0.0971 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0007 s/iter. Inference: 0.0789 s/iter. Eval: 0.0188 s/iter. Total: 0.0985 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:00:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.511455 (0.099237 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:00:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078970 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:00:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:00:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21921485342700292\n",
      "\u001b[32m[01/11 20:00:33 d2.utils.events]: \u001b[0m eta: 0:27:50  iter: 5339  total_loss: 1.582  loss_cls: 0.3989  loss_box_reg: 0.5346  loss_mask: 0.3194  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.2334  time: 0.5989  data_time: 0.2927  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:00:47 d2.utils.events]: \u001b[0m eta: 0:27:44  iter: 5359  total_loss: 1.697  loss_cls: 0.3794  loss_box_reg: 0.5783  loss_mask: 0.304  loss_rpn_cls: 0.1373  loss_rpn_loc: 0.2464  time: 0.5992  data_time: 0.3249  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:01:00 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 5379  total_loss: 1.513  loss_cls: 0.3281  loss_box_reg: 0.5341  loss_mask: 0.3078  loss_rpn_cls: 0.117  loss_rpn_loc: 0.2342  time: 0.5994  data_time: 0.3250  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:01:15 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 5399  total_loss: 1.666  loss_cls: 0.3812  loss_box_reg: 0.5691  loss_mask: 0.3105  loss_rpn_cls: 0.1363  loss_rpn_loc: 0.2475  time: 0.5999  data_time: 0.3903  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:01:25 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 5419  total_loss: 1.606  loss_cls: 0.3987  loss_box_reg: 0.5694  loss_mask: 0.3202  loss_rpn_cls: 0.1236  loss_rpn_loc: 0.2273  time: 0.5996  data_time: 0.1819  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:01:36 d2.utils.events]: \u001b[0m eta: 0:27:15  iter: 5439  total_loss: 1.492  loss_cls: 0.3344  loss_box_reg: 0.547  loss_mask: 0.3114  loss_rpn_cls: 0.08372  loss_rpn_loc: 0.2295  time: 0.5995  data_time: 0.2240  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:01:49 d2.utils.events]: \u001b[0m eta: 0:27:12  iter: 5459  total_loss: 1.669  loss_cls: 0.4107  loss_box_reg: 0.5521  loss_mask: 0.3374  loss_rpn_cls: 0.117  loss_rpn_loc: 0.2362  time: 0.5996  data_time: 0.2748  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:02:01 d2.utils.events]: \u001b[0m eta: 0:27:03  iter: 5479  total_loss: 1.508  loss_cls: 0.3624  loss_box_reg: 0.5669  loss_mask: 0.3418  loss_rpn_cls: 0.09405  loss_rpn_loc: 0.2369  time: 0.5995  data_time: 0.2558  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:02:15 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 5499  total_loss: 1.603  loss_cls: 0.43  loss_box_reg: 0.5361  loss_mask: 0.3101  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.2251  time: 0.5999  data_time: 0.3498  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:02:26 d2.utils.events]: \u001b[0m eta: 0:26:55  iter: 5519  total_loss: 1.63  loss_cls: 0.4047  loss_box_reg: 0.5744  loss_mask: 0.3123  loss_rpn_cls: 0.09791  loss_rpn_loc: 0.2638  time: 0.5998  data_time: 0.2298  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:02:39 d2.utils.events]: \u001b[0m eta: 0:26:46  iter: 5539  total_loss: 1.794  loss_cls: 0.4476  loss_box_reg: 0.5812  loss_mask: 0.3292  loss_rpn_cls: 0.1421  loss_rpn_loc: 0.264  time: 0.6000  data_time: 0.3106  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:02:50 d2.utils.events]: \u001b[0m eta: 0:26:40  iter: 5559  total_loss: 1.582  loss_cls: 0.3968  loss_box_reg: 0.5203  loss_mask: 0.3015  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.235  time: 0.5999  data_time: 0.2113  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:02:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:02:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:02:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:02:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:02:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:02:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:02:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0101 s/iter. Total: 0.0852 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:03:00 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0761 s/iter. Eval: 0.0135 s/iter. Total: 0.0904 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 20:03:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.534380 (0.090814 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:03:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076105 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:03:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:03:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22696980664139987\n",
      "\u001b[32m[01/11 20:03:14 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 5579  total_loss: 1.546  loss_cls: 0.3695  loss_box_reg: 0.5225  loss_mask: 0.2992  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2149  time: 0.5998  data_time: 0.2309  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:03:24 d2.utils.events]: \u001b[0m eta: 0:26:23  iter: 5599  total_loss: 1.523  loss_cls: 0.3759  loss_box_reg: 0.5333  loss_mask: 0.311  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.2239  time: 0.5995  data_time: 0.1939  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:03:38 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 5619  total_loss: 1.609  loss_cls: 0.3606  loss_box_reg: 0.5596  loss_mask: 0.3129  loss_rpn_cls: 0.09943  loss_rpn_loc: 0.2305  time: 0.5998  data_time: 0.3338  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:03:48 d2.utils.events]: \u001b[0m eta: 0:26:03  iter: 5639  total_loss: 1.528  loss_cls: 0.3665  loss_box_reg: 0.5451  loss_mask: 0.3121  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.2133  time: 0.5995  data_time: 0.1617  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:04:01 d2.utils.events]: \u001b[0m eta: 0:25:56  iter: 5659  total_loss: 1.566  loss_cls: 0.3748  loss_box_reg: 0.5142  loss_mask: 0.324  loss_rpn_cls: 0.09828  loss_rpn_loc: 0.2328  time: 0.5997  data_time: 0.3143  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:04:15 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 5679  total_loss: 1.701  loss_cls: 0.4602  loss_box_reg: 0.5847  loss_mask: 0.3059  loss_rpn_cls: 0.132  loss_rpn_loc: 0.2385  time: 0.6000  data_time: 0.3135  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:04:23 d2.utils.events]: \u001b[0m eta: 0:25:42  iter: 5699  total_loss: 1.546  loss_cls: 0.4109  loss_box_reg: 0.5102  loss_mask: 0.286  loss_rpn_cls: 0.09041  loss_rpn_loc: 0.2384  time: 0.5994  data_time: 0.1065  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:04:34 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 5719  total_loss: 1.815  loss_cls: 0.4904  loss_box_reg: 0.5363  loss_mask: 0.3083  loss_rpn_cls: 0.1928  loss_rpn_loc: 0.2675  time: 0.5992  data_time: 0.2118  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:04:50 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 5739  total_loss: 1.737  loss_cls: 0.4229  loss_box_reg: 0.5662  loss_mask: 0.316  loss_rpn_cls: 0.1643  loss_rpn_loc: 0.2614  time: 0.5997  data_time: 0.4120  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:05:02 d2.utils.events]: \u001b[0m eta: 0:25:22  iter: 5759  total_loss: 1.699  loss_cls: 0.3924  loss_box_reg: 0.5455  loss_mask: 0.3221  loss_rpn_cls: 0.1468  loss_rpn_loc: 0.2494  time: 0.5998  data_time: 0.2576  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:05:16 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 5779  total_loss: 1.616  loss_cls: 0.3558  loss_box_reg: 0.5319  loss_mask: 0.3112  loss_rpn_cls: 0.114  loss_rpn_loc: 0.2383  time: 0.6001  data_time: 0.3558  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:05:29 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 5799  total_loss: 1.691  loss_cls: 0.4038  loss_box_reg: 0.5743  loss_mask: 0.3049  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.2544  time: 0.6003  data_time: 0.3036  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:05:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:05:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:05:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:05:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:05:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:05:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0742 s/iter. Eval: 0.0091 s/iter. Total: 0.0838 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0782 s/iter. Eval: 0.0147 s/iter. Total: 0.0937 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0777 s/iter. Eval: 0.0146 s/iter. Total: 0.0931 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:05:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.873027 (0.093733 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:05:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077611 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:05:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:05:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21271943780214583\n",
      "\u001b[32m[01/11 20:05:50 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 5819  total_loss: 1.681  loss_cls: 0.3772  loss_box_reg: 0.5761  loss_mask: 0.3301  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.2491  time: 0.5998  data_time: 0.1256  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:06:06 d2.utils.events]: \u001b[0m eta: 0:24:55  iter: 5839  total_loss: 1.7  loss_cls: 0.3794  loss_box_reg: 0.5463  loss_mask: 0.3196  loss_rpn_cls: 0.1479  loss_rpn_loc: 0.2683  time: 0.6004  data_time: 0.4184  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:06:19 d2.utils.events]: \u001b[0m eta: 0:24:55  iter: 5859  total_loss: 1.69  loss_cls: 0.4323  loss_box_reg: 0.5534  loss_mask: 0.3392  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.2332  time: 0.6006  data_time: 0.3090  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:06:30 d2.utils.events]: \u001b[0m eta: 0:24:47  iter: 5879  total_loss: 1.667  loss_cls: 0.4115  loss_box_reg: 0.561  loss_mask: 0.2985  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.2419  time: 0.6004  data_time: 0.1844  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:06:43 d2.utils.events]: \u001b[0m eta: 0:24:43  iter: 5899  total_loss: 1.621  loss_cls: 0.3944  loss_box_reg: 0.551  loss_mask: 0.3347  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.2515  time: 0.6006  data_time: 0.3051  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:06:55 d2.utils.events]: \u001b[0m eta: 0:24:32  iter: 5919  total_loss: 1.571  loss_cls: 0.3788  loss_box_reg: 0.5516  loss_mask: 0.3042  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.2225  time: 0.6006  data_time: 0.2495  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:07:06 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 5939  total_loss: 1.579  loss_cls: 0.4122  loss_box_reg: 0.5725  loss_mask: 0.311  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.2365  time: 0.6005  data_time: 0.2249  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:07:18 d2.utils.events]: \u001b[0m eta: 0:24:18  iter: 5959  total_loss: 1.602  loss_cls: 0.3854  loss_box_reg: 0.5441  loss_mask: 0.3189  loss_rpn_cls: 0.1301  loss_rpn_loc: 0.2415  time: 0.6004  data_time: 0.2293  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:07:29 d2.utils.events]: \u001b[0m eta: 0:24:12  iter: 5979  total_loss: 1.611  loss_cls: 0.3971  loss_box_reg: 0.5738  loss_mask: 0.3024  loss_rpn_cls: 0.1175  loss_rpn_loc: 0.2345  time: 0.6003  data_time: 0.1995  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:07:42 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 5999  total_loss: 1.697  loss_cls: 0.4066  loss_box_reg: 0.547  loss_mask: 0.3175  loss_rpn_cls: 0.1396  loss_rpn_loc: 0.2242  time: 0.6004  data_time: 0.2925  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:07:55 d2.utils.events]: \u001b[0m eta: 0:24:03  iter: 6019  total_loss: 1.53  loss_cls: 0.3376  loss_box_reg: 0.5501  loss_mask: 0.3134  loss_rpn_cls: 0.08915  loss_rpn_loc: 0.2206  time: 0.6005  data_time: 0.2990  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:08:06 d2.utils.events]: \u001b[0m eta: 0:23:55  iter: 6039  total_loss: 1.523  loss_cls: 0.35  loss_box_reg: 0.5531  loss_mask: 0.2932  loss_rpn_cls: 0.102  loss_rpn_loc: 0.203  time: 0.6005  data_time: 0.2438  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:08:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:08:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:08:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:08:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:08:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:08:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0742 s/iter. Eval: 0.0091 s/iter. Total: 0.0840 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:08:19 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0145 s/iter. Total: 0.0930 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:08:24 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0786 s/iter. Eval: 0.0148 s/iter. Total: 0.0942 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:08:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.001233 (0.094838 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:08:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078593 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:08:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:08:24 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22332766634164267\n",
      "\u001b[32m[01/11 20:08:30 d2.utils.events]: \u001b[0m eta: 0:23:50  iter: 6059  total_loss: 1.702  loss_cls: 0.4191  loss_box_reg: 0.5958  loss_mask: 0.342  loss_rpn_cls: 0.125  loss_rpn_loc: 0.259  time: 0.6005  data_time: 0.2349  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:08:41 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 6079  total_loss: 1.639  loss_cls: 0.4072  loss_box_reg: 0.5484  loss_mask: 0.3044  loss_rpn_cls: 0.1395  loss_rpn_loc: 0.2407  time: 0.6003  data_time: 0.2018  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:08:52 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 6099  total_loss: 1.579  loss_cls: 0.355  loss_box_reg: 0.5475  loss_mask: 0.3145  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.242  time: 0.6000  data_time: 0.1764  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:09:06 d2.utils.events]: \u001b[0m eta: 0:23:29  iter: 6119  total_loss: 1.698  loss_cls: 0.4065  loss_box_reg: 0.5481  loss_mask: 0.3019  loss_rpn_cls: 0.109  loss_rpn_loc: 0.2324  time: 0.6004  data_time: 0.3476  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:09:19 d2.utils.events]: \u001b[0m eta: 0:23:24  iter: 6139  total_loss: 1.644  loss_cls: 0.4136  loss_box_reg: 0.544  loss_mask: 0.3151  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.2439  time: 0.6006  data_time: 0.3341  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:09:30 d2.utils.events]: \u001b[0m eta: 0:23:15  iter: 6159  total_loss: 1.427  loss_cls: 0.3264  loss_box_reg: 0.527  loss_mask: 0.3025  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.1883  time: 0.6003  data_time: 0.1827  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:09:41 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 6179  total_loss: 1.565  loss_cls: 0.3564  loss_box_reg: 0.5295  loss_mask: 0.3231  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2316  time: 0.6003  data_time: 0.2384  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:09:55 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 6199  total_loss: 1.592  loss_cls: 0.4215  loss_box_reg: 0.5819  loss_mask: 0.3169  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.2348  time: 0.6005  data_time: 0.3345  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:10:08 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 6219  total_loss: 1.554  loss_cls: 0.3551  loss_box_reg: 0.5592  loss_mask: 0.3226  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.2366  time: 0.6007  data_time: 0.3095  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:10:18 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 6239  total_loss: 1.767  loss_cls: 0.4098  loss_box_reg: 0.5544  loss_mask: 0.2995  loss_rpn_cls: 0.1131  loss_rpn_loc: 0.2456  time: 0.6003  data_time: 0.1534  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:10:28 d2.utils.events]: \u001b[0m eta: 0:22:42  iter: 6259  total_loss: 1.561  loss_cls: 0.4101  loss_box_reg: 0.5589  loss_mask: 0.3187  loss_rpn_cls: 0.08648  loss_rpn_loc: 0.2424  time: 0.6000  data_time: 0.1576  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:10:38 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 6279  total_loss: 1.576  loss_cls: 0.3843  loss_box_reg: 0.5774  loss_mask: 0.3072  loss_rpn_cls: 0.09947  loss_rpn_loc: 0.2114  time: 0.5997  data_time: 0.1695  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:10:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:10:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:10:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:10:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:10:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:10:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0757 s/iter. Eval: 0.0106 s/iter. Total: 0.0869 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:10:53 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0775 s/iter. Eval: 0.0154 s/iter. Total: 0.0937 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:10:58 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0774 s/iter. Eval: 0.0152 s/iter. Total: 0.0933 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:10:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.906724 (0.094023 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:10:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077469 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:10:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:10:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2295306200109098\n",
      "\u001b[32m[01/11 20:11:07 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 6299  total_loss: 1.551  loss_cls: 0.3865  loss_box_reg: 0.4966  loss_mask: 0.3132  loss_rpn_cls: 0.1305  loss_rpn_loc: 0.2516  time: 0.6004  data_time: 0.4699  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:11:18 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 6319  total_loss: 1.588  loss_cls: 0.3706  loss_box_reg: 0.5572  loss_mask: 0.3018  loss_rpn_cls: 0.104  loss_rpn_loc: 0.238  time: 0.6003  data_time: 0.2179  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:11:28 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 6339  total_loss: 1.58  loss_cls: 0.3588  loss_box_reg: 0.5468  loss_mask: 0.3088  loss_rpn_cls: 0.0905  loss_rpn_loc: 0.2482  time: 0.6000  data_time: 0.1561  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:11:39 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 6359  total_loss: 1.566  loss_cls: 0.3819  loss_box_reg: 0.5782  loss_mask: 0.3127  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2157  time: 0.5999  data_time: 0.2322  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:11:50 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 6379  total_loss: 1.567  loss_cls: 0.3656  loss_box_reg: 0.5456  loss_mask: 0.3019  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.234  time: 0.5998  data_time: 0.2090  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:12:02 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 6399  total_loss: 1.608  loss_cls: 0.3764  loss_box_reg: 0.5274  loss_mask: 0.3081  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2306  time: 0.5997  data_time: 0.2519  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:12:14 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 6419  total_loss: 1.622  loss_cls: 0.3474  loss_box_reg: 0.5389  loss_mask: 0.3249  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.2185  time: 0.5997  data_time: 0.2292  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:12:28 d2.utils.events]: \u001b[0m eta: 0:21:30  iter: 6439  total_loss: 1.641  loss_cls: 0.4271  loss_box_reg: 0.5156  loss_mask: 0.3128  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2481  time: 0.6000  data_time: 0.3466  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:12:40 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 6459  total_loss: 1.738  loss_cls: 0.3933  loss_box_reg: 0.5533  loss_mask: 0.3169  loss_rpn_cls: 0.1306  loss_rpn_loc: 0.2542  time: 0.6001  data_time: 0.2677  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:12:49 d2.utils.events]: \u001b[0m eta: 0:21:14  iter: 6479  total_loss: 1.63  loss_cls: 0.3852  loss_box_reg: 0.5908  loss_mask: 0.3057  loss_rpn_cls: 0.07331  loss_rpn_loc: 0.2296  time: 0.5996  data_time: 0.1288  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:13:03 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 6499  total_loss: 1.517  loss_cls: 0.3252  loss_box_reg: 0.5068  loss_mask: 0.2933  loss_rpn_cls: 0.07099  loss_rpn_loc: 0.2119  time: 0.5998  data_time: 0.3143  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:13:15 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 6519  total_loss: 1.692  loss_cls: 0.3741  loss_box_reg: 0.5698  loss_mask: 0.3298  loss_rpn_cls: 0.1261  loss_rpn_loc: 0.2499  time: 0.5999  data_time: 0.2670  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:13:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:13:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:13:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:13:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:13:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:13:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0812 s/iter. Eval: 0.0132 s/iter. Total: 0.0951 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 20:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0007 s/iter. Inference: 0.0813 s/iter. Eval: 0.0175 s/iter. Total: 0.0995 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0007 s/iter. Inference: 0.0815 s/iter. Eval: 0.0185 s/iter. Total: 0.1008 s/iter. ETA=0:00:01\n",
      "\u001b[32m[01/11 20:13:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.701377 (0.100874 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:13:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.081319 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:13:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:13:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2416618496342489\n",
      "\u001b[32m[01/11 20:13:42 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 6539  total_loss: 1.586  loss_cls: 0.3739  loss_box_reg: 0.5155  loss_mask: 0.308  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.2266  time: 0.6001  data_time: 0.3175  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:13:55 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 6559  total_loss: 1.586  loss_cls: 0.369  loss_box_reg: 0.5533  loss_mask: 0.3202  loss_rpn_cls: 0.1333  loss_rpn_loc: 0.2365  time: 0.6003  data_time: 0.3249  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:14:08 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 6579  total_loss: 1.558  loss_cls: 0.3816  loss_box_reg: 0.5401  loss_mask: 0.3114  loss_rpn_cls: 0.1272  loss_rpn_loc: 0.2295  time: 0.6004  data_time: 0.2675  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:14:22 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 6599  total_loss: 1.503  loss_cls: 0.3514  loss_box_reg: 0.5405  loss_mask: 0.3059  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2212  time: 0.6007  data_time: 0.3402  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:14:33 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 6619  total_loss: 1.564  loss_cls: 0.3714  loss_box_reg: 0.5479  loss_mask: 0.3028  loss_rpn_cls: 0.09621  loss_rpn_loc: 0.2123  time: 0.6006  data_time: 0.2094  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:14:44 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 6639  total_loss: 1.631  loss_cls: 0.3819  loss_box_reg: 0.5592  loss_mask: 0.3283  loss_rpn_cls: 0.1217  loss_rpn_loc: 0.2603  time: 0.6005  data_time: 0.2384  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:14:55 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 6659  total_loss: 1.575  loss_cls: 0.3841  loss_box_reg: 0.5494  loss_mask: 0.3146  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.2086  time: 0.6004  data_time: 0.2049  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:15:08 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 6679  total_loss: 1.538  loss_cls: 0.3633  loss_box_reg: 0.5486  loss_mask: 0.3233  loss_rpn_cls: 0.09837  loss_rpn_loc: 0.2302  time: 0.6004  data_time: 0.2720  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:15:20 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 6699  total_loss: 1.62  loss_cls: 0.3627  loss_box_reg: 0.556  loss_mask: 0.3139  loss_rpn_cls: 0.1273  loss_rpn_loc: 0.2158  time: 0.6004  data_time: 0.2597  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:15:34 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 6719  total_loss: 1.493  loss_cls: 0.3482  loss_box_reg: 0.5458  loss_mask: 0.2928  loss_rpn_cls: 0.08678  loss_rpn_loc: 0.2208  time: 0.6008  data_time: 0.3800  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:15:45 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 6739  total_loss: 1.554  loss_cls: 0.3822  loss_box_reg: 0.5378  loss_mask: 0.3042  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.2293  time: 0.6005  data_time: 0.1739  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:15:59 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 6759  total_loss: 1.539  loss_cls: 0.3611  loss_box_reg: 0.5241  loss_mask: 0.2977  loss_rpn_cls: 0.101  loss_rpn_loc: 0.2142  time: 0.6008  data_time: 0.3502  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:16:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:16:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:16:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:16:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:16:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:16:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0753 s/iter. Eval: 0.0093 s/iter. Total: 0.0851 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0787 s/iter. Eval: 0.0152 s/iter. Total: 0.0947 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0788 s/iter. Eval: 0.0156 s/iter. Total: 0.0952 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:16:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.120366 (0.095865 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:16:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078872 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:16:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:16:20 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23103234440127213\n",
      "\u001b[32m[01/11 20:16:22 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 6779  total_loss: 1.674  loss_cls: 0.3812  loss_box_reg: 0.5758  loss_mask: 0.3093  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.2406  time: 0.6007  data_time: 0.1999  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:16:33 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 6799  total_loss: 1.746  loss_cls: 0.425  loss_box_reg: 0.5807  loss_mask: 0.3059  loss_rpn_cls: 0.1176  loss_rpn_loc: 0.2315  time: 0.6005  data_time: 0.1842  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:16:47 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 6819  total_loss: 1.664  loss_cls: 0.4304  loss_box_reg: 0.5267  loss_mask: 0.3153  loss_rpn_cls: 0.1409  loss_rpn_loc: 0.2525  time: 0.6008  data_time: 0.3341  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:16:58 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 6839  total_loss: 1.68  loss_cls: 0.3884  loss_box_reg: 0.5943  loss_mask: 0.3098  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.2356  time: 0.6006  data_time: 0.1966  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:17:14 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 6859  total_loss: 1.511  loss_cls: 0.3895  loss_box_reg: 0.4821  loss_mask: 0.3059  loss_rpn_cls: 0.1267  loss_rpn_loc: 0.2147  time: 0.6012  data_time: 0.4454  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:17:25 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 6879  total_loss: 1.605  loss_cls: 0.3732  loss_box_reg: 0.546  loss_mask: 0.3101  loss_rpn_cls: 0.08343  loss_rpn_loc: 0.2371  time: 0.6011  data_time: 0.2183  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:17:38 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 6899  total_loss: 1.569  loss_cls: 0.3701  loss_box_reg: 0.5297  loss_mask: 0.3079  loss_rpn_cls: 0.09625  loss_rpn_loc: 0.2103  time: 0.6012  data_time: 0.3131  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:17:48 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 6919  total_loss: 1.63  loss_cls: 0.3909  loss_box_reg: 0.5549  loss_mask: 0.3111  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.2282  time: 0.6009  data_time: 0.1477  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:17:58 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 6939  total_loss: 1.599  loss_cls: 0.3787  loss_box_reg: 0.5336  loss_mask: 0.2975  loss_rpn_cls: 0.124  loss_rpn_loc: 0.2286  time: 0.6007  data_time: 0.1807  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:18:09 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 6959  total_loss: 1.606  loss_cls: 0.3795  loss_box_reg: 0.5591  loss_mask: 0.3103  loss_rpn_cls: 0.09455  loss_rpn_loc: 0.2387  time: 0.6005  data_time: 0.2041  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:18:20 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 6979  total_loss: 1.482  loss_cls: 0.3534  loss_box_reg: 0.5365  loss_mask: 0.3014  loss_rpn_cls: 0.09368  loss_rpn_loc: 0.2313  time: 0.6003  data_time: 0.2074  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:18:30 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 6999  total_loss: 1.565  loss_cls: 0.3524  loss_box_reg: 0.5607  loss_mask: 0.3023  loss_rpn_cls: 0.09961  loss_rpn_loc: 0.2237  time: 0.6001  data_time: 0.1869  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:18:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:18:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:18:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:18:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:18:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:18:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0779 s/iter. Eval: 0.0133 s/iter. Total: 0.0920 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 20:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0780 s/iter. Eval: 0.0155 s/iter. Total: 0.0943 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0007 s/iter. Inference: 0.0780 s/iter. Eval: 0.0157 s/iter. Total: 0.0945 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:18:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.072083 (0.095449 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:18:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078101 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:18:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:18:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23172873360929674\n",
      "\u001b[32m[01/11 20:18:55 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 7019  total_loss: 1.671  loss_cls: 0.4169  loss_box_reg: 0.554  loss_mask: 0.3474  loss_rpn_cls: 0.1135  loss_rpn_loc: 0.2344  time: 0.6002  data_time: 0.2754  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:19:10 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 7039  total_loss: 1.65  loss_cls: 0.3815  loss_box_reg: 0.5521  loss_mask: 0.3272  loss_rpn_cls: 0.1534  loss_rpn_loc: 0.2376  time: 0.6006  data_time: 0.3721  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:19:21 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 7059  total_loss: 1.578  loss_cls: 0.3596  loss_box_reg: 0.5759  loss_mask: 0.3193  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.2098  time: 0.6004  data_time: 0.1963  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:19:33 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 7079  total_loss: 1.625  loss_cls: 0.387  loss_box_reg: 0.5652  loss_mask: 0.3261  loss_rpn_cls: 0.07762  loss_rpn_loc: 0.2335  time: 0.6004  data_time: 0.2553  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:19:42 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 7099  total_loss: 1.582  loss_cls: 0.3694  loss_box_reg: 0.5676  loss_mask: 0.3135  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.2085  time: 0.6000  data_time: 0.1526  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:19:53 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 7119  total_loss: 1.597  loss_cls: 0.3674  loss_box_reg: 0.579  loss_mask: 0.2981  loss_rpn_cls: 0.08688  loss_rpn_loc: 0.2193  time: 0.5998  data_time: 0.1824  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:20:07 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 7139  total_loss: 1.681  loss_cls: 0.3809  loss_box_reg: 0.5542  loss_mask: 0.3398  loss_rpn_cls: 0.16  loss_rpn_loc: 0.2442  time: 0.6001  data_time: 0.3511  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:20:17 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 7159  total_loss: 1.58  loss_cls: 0.388  loss_box_reg: 0.5668  loss_mask: 0.3141  loss_rpn_cls: 0.09922  loss_rpn_loc: 0.2213  time: 0.5999  data_time: 0.1828  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:20:29 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 7179  total_loss: 1.652  loss_cls: 0.4037  loss_box_reg: 0.5608  loss_mask: 0.3083  loss_rpn_cls: 0.107  loss_rpn_loc: 0.2559  time: 0.5999  data_time: 0.2616  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:20:43 d2.utils.events]: \u001b[0m eta: 0:16:51  iter: 7199  total_loss: 1.638  loss_cls: 0.3978  loss_box_reg: 0.5388  loss_mask: 0.3155  loss_rpn_cls: 0.112  loss_rpn_loc: 0.2338  time: 0.6002  data_time: 0.3486  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:20:57 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 7219  total_loss: 1.691  loss_cls: 0.3941  loss_box_reg: 0.5194  loss_mask: 0.3248  loss_rpn_cls: 0.1408  loss_rpn_loc: 0.242  time: 0.6005  data_time: 0.3457  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:21:14 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 7239  total_loss: 1.588  loss_cls: 0.3812  loss_box_reg: 0.5121  loss_mask: 0.3117  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.2422  time: 0.6011  data_time: 0.4499  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:21:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:21:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:21:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:21:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:21:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:21:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:21:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0746 s/iter. Eval: 0.0142 s/iter. Total: 0.0895 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0785 s/iter. Eval: 0.0169 s/iter. Total: 0.0962 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0007 s/iter. Inference: 0.0792 s/iter. Eval: 0.0175 s/iter. Total: 0.0975 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:21:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.391993 (0.098207 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:21:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079209 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:21:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:21:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22410204913918894\n",
      "\u001b[32m[01/11 20:21:37 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 7259  total_loss: 1.489  loss_cls: 0.3379  loss_box_reg: 0.5314  loss_mask: 0.3033  loss_rpn_cls: 0.08814  loss_rpn_loc: 0.2157  time: 0.6009  data_time: 0.2037  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:21:47 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 7279  total_loss: 1.595  loss_cls: 0.404  loss_box_reg: 0.5272  loss_mask: 0.3129  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.227  time: 0.6006  data_time: 0.1499  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:21:58 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 7299  total_loss: 1.584  loss_cls: 0.3604  loss_box_reg: 0.5202  loss_mask: 0.3051  loss_rpn_cls: 0.1328  loss_rpn_loc: 0.239  time: 0.6005  data_time: 0.2185  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:22:10 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 7319  total_loss: 1.648  loss_cls: 0.4464  loss_box_reg: 0.535  loss_mask: 0.2957  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.2416  time: 0.6005  data_time: 0.2385  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:22:20 d2.utils.events]: \u001b[0m eta: 0:16:06  iter: 7339  total_loss: 1.584  loss_cls: 0.3651  loss_box_reg: 0.5828  loss_mask: 0.3029  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.2414  time: 0.6002  data_time: 0.1692  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:22:34 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 7359  total_loss: 1.618  loss_cls: 0.388  loss_box_reg: 0.5716  loss_mask: 0.3288  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.2342  time: 0.6004  data_time: 0.3251  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:22:47 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 7379  total_loss: 1.939  loss_cls: 0.5233  loss_box_reg: 0.65  loss_mask: 0.3354  loss_rpn_cls: 0.1811  loss_rpn_loc: 0.2576  time: 0.6005  data_time: 0.2922  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:23:02 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 7399  total_loss: 2.837  loss_cls: 0.9412  loss_box_reg: 0.7502  loss_mask: 0.4023  loss_rpn_cls: 0.2146  loss_rpn_loc: 0.3088  time: 0.6010  data_time: 0.3991  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:23:11 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 7419  total_loss: 2.45  loss_cls: 0.8403  loss_box_reg: 0.843  loss_mask: 0.3299  loss_rpn_cls: 0.1553  loss_rpn_loc: 0.2858  time: 0.6006  data_time: 0.1253  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:23:24 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 7439  total_loss: 2.301  loss_cls: 0.7237  loss_box_reg: 0.8073  loss_mask: 0.3338  loss_rpn_cls: 0.1624  loss_rpn_loc: 0.3109  time: 0.6007  data_time: 0.3203  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:23:36 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 7459  total_loss: 2.281  loss_cls: 0.7024  loss_box_reg: 0.6675  loss_mask: 0.3868  loss_rpn_cls: 0.2026  loss_rpn_loc: 0.3062  time: 0.6007  data_time: 0.2511  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:23:47 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 7479  total_loss: 2.091  loss_cls: 0.6218  loss_box_reg: 0.6969  loss_mask: 0.3687  loss_rpn_cls: 0.1561  loss_rpn_loc: 0.2813  time: 0.6005  data_time: 0.1911  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:24:00 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 7499  total_loss: 1.892  loss_cls: 0.5638  loss_box_reg: 0.6086  loss_mask: 0.3174  loss_rpn_cls: 0.1852  loss_rpn_loc: 0.2674  time: 0.6007  data_time: 0.3355  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:24:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:24:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:24:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:24:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:24:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:24:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0117 s/iter. Total: 0.0863 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:24:08 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0776 s/iter. Eval: 0.0162 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:24:13 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0780 s/iter. Eval: 0.0168 s/iter. Total: 0.0955 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:24:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.183144 (0.096406 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:24:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078116 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:24:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:24:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2236797127345237\n",
      "\u001b[32m[01/11 20:24:24 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 7519  total_loss: 1.646  loss_cls: 0.4586  loss_box_reg: 0.5908  loss_mask: 0.3056  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.233  time: 0.6006  data_time: 0.2078  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:24:39 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 7539  total_loss: 1.848  loss_cls: 0.4708  loss_box_reg: 0.6045  loss_mask: 0.3313  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.2631  time: 0.6009  data_time: 0.3825  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:24:52 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 7559  total_loss: 1.63  loss_cls: 0.381  loss_box_reg: 0.5525  loss_mask: 0.314  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.2223  time: 0.6012  data_time: 0.3260  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:25:03 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 7579  total_loss: 1.717  loss_cls: 0.4292  loss_box_reg: 0.5508  loss_mask: 0.3221  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.2537  time: 0.6009  data_time: 0.1837  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:25:15 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 7599  total_loss: 1.696  loss_cls: 0.4316  loss_box_reg: 0.5922  loss_mask: 0.3207  loss_rpn_cls: 0.103  loss_rpn_loc: 0.2368  time: 0.6010  data_time: 0.2902  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:25:28 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 7619  total_loss: 1.634  loss_cls: 0.385  loss_box_reg: 0.6102  loss_mask: 0.2953  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.2317  time: 0.6011  data_time: 0.2798  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:25:40 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 7639  total_loss: 1.628  loss_cls: 0.3656  loss_box_reg: 0.5813  loss_mask: 0.3144  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.2342  time: 0.6011  data_time: 0.2821  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:25:53 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 7659  total_loss: 1.767  loss_cls: 0.4451  loss_box_reg: 0.5828  loss_mask: 0.3093  loss_rpn_cls: 0.1305  loss_rpn_loc: 0.2458  time: 0.6012  data_time: 0.2788  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:26:01 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 7679  total_loss: 1.715  loss_cls: 0.4303  loss_box_reg: 0.5923  loss_mask: 0.3115  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.2532  time: 0.6008  data_time: 0.0996  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:26:10 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 7699  total_loss: 1.444  loss_cls: 0.3247  loss_box_reg: 0.5111  loss_mask: 0.2951  loss_rpn_cls: 0.08389  loss_rpn_loc: 0.1951  time: 0.6004  data_time: 0.1159  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:26:24 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 7719  total_loss: 1.65  loss_cls: 0.4001  loss_box_reg: 0.5507  loss_mask: 0.3371  loss_rpn_cls: 0.1305  loss_rpn_loc: 0.2404  time: 0.6006  data_time: 0.3448  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:26:37 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 7739  total_loss: 1.587  loss_cls: 0.3839  loss_box_reg: 0.5691  loss_mask: 0.313  loss_rpn_cls: 0.09944  loss_rpn_loc: 0.2292  time: 0.6007  data_time: 0.3003  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:26:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:26:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:26:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:26:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:26:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:26:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0765 s/iter. Eval: 0.0119 s/iter. Total: 0.0891 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0009 s/iter. Inference: 0.0765 s/iter. Eval: 0.0132 s/iter. Total: 0.0907 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 20:26:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.349499 (0.089220 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:26:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075721 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:26:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:26:51 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22262380261881998\n",
      "\u001b[32m[01/11 20:27:02 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 7759  total_loss: 1.589  loss_cls: 0.3764  loss_box_reg: 0.5457  loss_mask: 0.2976  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.2168  time: 0.6009  data_time: 0.3033  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:27:14 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 7779  total_loss: 1.607  loss_cls: 0.3605  loss_box_reg: 0.5725  loss_mask: 0.3145  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.2362  time: 0.6009  data_time: 0.2570  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:27:25 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 7799  total_loss: 1.454  loss_cls: 0.3526  loss_box_reg: 0.5257  loss_mask: 0.3085  loss_rpn_cls: 0.08271  loss_rpn_loc: 0.223  time: 0.6007  data_time: 0.1855  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:27:37 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 7819  total_loss: 1.665  loss_cls: 0.4058  loss_box_reg: 0.5822  loss_mask: 0.3227  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.2428  time: 0.6007  data_time: 0.2579  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:27:50 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 7839  total_loss: 1.655  loss_cls: 0.3987  loss_box_reg: 0.5492  loss_mask: 0.314  loss_rpn_cls: 0.113  loss_rpn_loc: 0.2372  time: 0.6009  data_time: 0.3280  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:28:02 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 7859  total_loss: 1.67  loss_cls: 0.3932  loss_box_reg: 0.544  loss_mask: 0.3236  loss_rpn_cls: 0.09665  loss_rpn_loc: 0.2365  time: 0.6008  data_time: 0.2329  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:28:17 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 7879  total_loss: 1.636  loss_cls: 0.394  loss_box_reg: 0.5497  loss_mask: 0.3207  loss_rpn_cls: 0.142  loss_rpn_loc: 0.235  time: 0.6013  data_time: 0.4267  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:28:26 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 7899  total_loss: 1.669  loss_cls: 0.4002  loss_box_reg: 0.5983  loss_mask: 0.307  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.2362  time: 0.6009  data_time: 0.1254  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:28:39 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 7919  total_loss: 1.604  loss_cls: 0.4106  loss_box_reg: 0.5926  loss_mask: 0.3202  loss_rpn_cls: 0.108  loss_rpn_loc: 0.2357  time: 0.6010  data_time: 0.3026  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:28:52 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 7939  total_loss: 1.607  loss_cls: 0.3996  loss_box_reg: 0.5359  loss_mask: 0.3063  loss_rpn_cls: 0.09762  loss_rpn_loc: 0.23  time: 0.6010  data_time: 0.2650  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:29:03 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 7959  total_loss: 1.449  loss_cls: 0.3251  loss_box_reg: 0.5045  loss_mask: 0.2786  loss_rpn_cls: 0.07943  loss_rpn_loc: 0.1898  time: 0.6010  data_time: 0.2498  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:29:16 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 7979  total_loss: 1.598  loss_cls: 0.3766  loss_box_reg: 0.5347  loss_mask: 0.3065  loss_rpn_cls: 0.09247  loss_rpn_loc: 0.2387  time: 0.6011  data_time: 0.2783  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:29:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:29:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:29:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:29:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:29:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:29:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0741 s/iter. Eval: 0.0106 s/iter. Total: 0.0854 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0756 s/iter. Eval: 0.0122 s/iter. Total: 0.0886 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 20:29:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.304711 (0.088834 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:29:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075351 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:29:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:29:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2243981302925224\n",
      "\u001b[32m[01/11 20:29:42 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 7999  total_loss: 1.664  loss_cls: 0.4019  loss_box_reg: 0.5397  loss_mask: 0.3045  loss_rpn_cls: 0.1312  loss_rpn_loc: 0.2381  time: 0.6014  data_time: 0.3699  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:29:54 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 8019  total_loss: 1.585  loss_cls: 0.4035  loss_box_reg: 0.5159  loss_mask: 0.3138  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2426  time: 0.6013  data_time: 0.2311  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:30:04 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 8039  total_loss: 1.518  loss_cls: 0.3663  loss_box_reg: 0.5836  loss_mask: 0.3025  loss_rpn_cls: 0.0618  loss_rpn_loc: 0.2325  time: 0.6012  data_time: 0.1959  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:30:22 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 8059  total_loss: 1.588  loss_cls: 0.3724  loss_box_reg: 0.5397  loss_mask: 0.3242  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.2361  time: 0.6019  data_time: 0.5300  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:30:35 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 8079  total_loss: 1.481  loss_cls: 0.351  loss_box_reg: 0.5491  loss_mask: 0.2955  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.2329  time: 0.6020  data_time: 0.3127  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:30:48 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 8099  total_loss: 1.63  loss_cls: 0.3701  loss_box_reg: 0.5411  loss_mask: 0.29  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2349  time: 0.6021  data_time: 0.2854  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:30:58 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 8119  total_loss: 1.653  loss_cls: 0.4011  loss_box_reg: 0.5705  loss_mask: 0.3124  loss_rpn_cls: 0.09494  loss_rpn_loc: 0.2325  time: 0.6018  data_time: 0.1761  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:31:09 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 8139  total_loss: 1.721  loss_cls: 0.4256  loss_box_reg: 0.5869  loss_mask: 0.3248  loss_rpn_cls: 0.1257  loss_rpn_loc: 0.2449  time: 0.6017  data_time: 0.2264  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:31:19 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 8159  total_loss: 1.599  loss_cls: 0.3968  loss_box_reg: 0.5638  loss_mask: 0.2866  loss_rpn_cls: 0.08377  loss_rpn_loc: 0.2248  time: 0.6014  data_time: 0.1560  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:31:33 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 8179  total_loss: 1.708  loss_cls: 0.4204  loss_box_reg: 0.5604  loss_mask: 0.3156  loss_rpn_cls: 0.1297  loss_rpn_loc: 0.2431  time: 0.6017  data_time: 0.3699  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:31:44 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 8199  total_loss: 1.613  loss_cls: 0.366  loss_box_reg: 0.5464  loss_mask: 0.304  loss_rpn_cls: 0.08756  loss_rpn_loc: 0.2254  time: 0.6016  data_time: 0.2154  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:31:55 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 8219  total_loss: 1.636  loss_cls: 0.398  loss_box_reg: 0.5971  loss_mask: 0.2967  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.2148  time: 0.6014  data_time: 0.1681  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:32:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:32:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:32:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:32:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:32:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:32:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0752 s/iter. Eval: 0.0106 s/iter. Total: 0.0864 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0796 s/iter. Eval: 0.0163 s/iter. Total: 0.0967 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:32:13 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0008 s/iter. Inference: 0.0792 s/iter. Eval: 0.0167 s/iter. Total: 0.0967 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:32:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.261409 (0.097081 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:32:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079164 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:32:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:32:13 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24623910992537412\n",
      "\u001b[32m[01/11 20:32:23 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 8239  total_loss: 1.554  loss_cls: 0.377  loss_box_reg: 0.5207  loss_mask: 0.2928  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.2235  time: 0.6018  data_time: 0.4006  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:32:35 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 8259  total_loss: 1.61  loss_cls: 0.4205  loss_box_reg: 0.5591  loss_mask: 0.3017  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.233  time: 0.6019  data_time: 0.2656  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:32:47 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 8279  total_loss: 1.592  loss_cls: 0.3548  loss_box_reg: 0.5615  loss_mask: 0.3239  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.2518  time: 0.6019  data_time: 0.2543  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:33:03 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 8299  total_loss: 1.64  loss_cls: 0.3941  loss_box_reg: 0.4924  loss_mask: 0.3126  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.2408  time: 0.6023  data_time: 0.4129  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:33:15 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 8319  total_loss: 1.503  loss_cls: 0.3271  loss_box_reg: 0.517  loss_mask: 0.3181  loss_rpn_cls: 0.09267  loss_rpn_loc: 0.1995  time: 0.6023  data_time: 0.3006  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:33:27 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 8339  total_loss: 1.642  loss_cls: 0.434  loss_box_reg: 0.5609  loss_mask: 0.315  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2362  time: 0.6022  data_time: 0.2239  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:33:36 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 8359  total_loss: 1.658  loss_cls: 0.4126  loss_box_reg: 0.5802  loss_mask: 0.314  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.2344  time: 0.6020  data_time: 0.1480  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:33:49 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 8379  total_loss: 1.64  loss_cls: 0.3825  loss_box_reg: 0.5627  loss_mask: 0.3118  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.2504  time: 0.6021  data_time: 0.3096  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:34:00 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 8399  total_loss: 1.568  loss_cls: 0.3449  loss_box_reg: 0.5887  loss_mask: 0.308  loss_rpn_cls: 0.07634  loss_rpn_loc: 0.2287  time: 0.6020  data_time: 0.2040  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:34:09 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 8419  total_loss: 1.439  loss_cls: 0.3237  loss_box_reg: 0.5279  loss_mask: 0.3019  loss_rpn_cls: 0.06392  loss_rpn_loc: 0.2082  time: 0.6015  data_time: 0.1002  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:34:26 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 8439  total_loss: 1.531  loss_cls: 0.3579  loss_box_reg: 0.5184  loss_mask: 0.3075  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2321  time: 0.6021  data_time: 0.4723  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:34:38 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 8459  total_loss: 1.506  loss_cls: 0.3479  loss_box_reg: 0.534  loss_mask: 0.2917  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.2276  time: 0.6022  data_time: 0.2928  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:34:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:34:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:34:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:34:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:34:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:34:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0770 s/iter. Eval: 0.0099 s/iter. Total: 0.0877 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0008 s/iter. Inference: 0.0762 s/iter. Eval: 0.0136 s/iter. Total: 0.0907 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 20:34:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.507169 (0.090579 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:34:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075843 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:34:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:34:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2211805054103695\n",
      "\u001b[32m[01/11 20:35:01 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 8479  total_loss: 1.693  loss_cls: 0.4014  loss_box_reg: 0.6196  loss_mask: 0.3225  loss_rpn_cls: 0.1275  loss_rpn_loc: 0.2573  time: 0.6021  data_time: 0.2081  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:35:10 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 8499  total_loss: 1.607  loss_cls: 0.3666  loss_box_reg: 0.5406  loss_mask: 0.2888  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.2312  time: 0.6017  data_time: 0.1068  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:35:22 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 8519  total_loss: 1.566  loss_cls: 0.3608  loss_box_reg: 0.5431  loss_mask: 0.3082  loss_rpn_cls: 0.09654  loss_rpn_loc: 0.2264  time: 0.6017  data_time: 0.2390  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:35:37 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 8539  total_loss: 1.64  loss_cls: 0.4148  loss_box_reg: 0.5347  loss_mask: 0.3112  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.239  time: 0.6020  data_time: 0.3945  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:35:47 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 8559  total_loss: 1.527  loss_cls: 0.375  loss_box_reg: 0.5275  loss_mask: 0.3065  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.2393  time: 0.6018  data_time: 0.2050  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:35:57 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 8579  total_loss: 1.528  loss_cls: 0.3535  loss_box_reg: 0.5426  loss_mask: 0.302  loss_rpn_cls: 0.08999  loss_rpn_loc: 0.2239  time: 0.6016  data_time: 0.1461  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:36:10 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 8599  total_loss: 1.527  loss_cls: 0.3711  loss_box_reg: 0.5318  loss_mask: 0.3122  loss_rpn_cls: 0.1454  loss_rpn_loc: 0.2327  time: 0.6016  data_time: 0.2884  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:36:20 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 8619  total_loss: 1.579  loss_cls: 0.3835  loss_box_reg: 0.5592  loss_mask: 0.2929  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.252  time: 0.6014  data_time: 0.1704  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:36:34 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 8639  total_loss: 1.652  loss_cls: 0.3952  loss_box_reg: 0.5682  loss_mask: 0.3056  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.251  time: 0.6017  data_time: 0.3608  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:36:46 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 8659  total_loss: 1.584  loss_cls: 0.3982  loss_box_reg: 0.5675  loss_mask: 0.301  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.2196  time: 0.6016  data_time: 0.2311  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:36:59 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 8679  total_loss: 1.547  loss_cls: 0.3498  loss_box_reg: 0.5042  loss_mask: 0.2951  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2646  time: 0.6018  data_time: 0.3262  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:37:13 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 8699  total_loss: 1.641  loss_cls: 0.4109  loss_box_reg: 0.5193  loss_mask: 0.3201  loss_rpn_cls: 0.1299  loss_rpn_loc: 0.2292  time: 0.6020  data_time: 0.3303  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:37:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:37:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:37:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:37:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:37:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:37:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0761 s/iter. Eval: 0.0139 s/iter. Total: 0.0908 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0781 s/iter. Eval: 0.0163 s/iter. Total: 0.0953 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0778 s/iter. Eval: 0.0164 s/iter. Total: 0.0950 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:37:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.093740 (0.095636 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:37:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077815 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:37:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:37:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23530548599228784\n",
      "\u001b[32m[01/11 20:37:36 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 8719  total_loss: 1.551  loss_cls: 0.3581  loss_box_reg: 0.5376  loss_mask: 0.3123  loss_rpn_cls: 0.09305  loss_rpn_loc: 0.2266  time: 0.6018  data_time: 0.1586  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:37:47 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 8739  total_loss: 1.656  loss_cls: 0.4086  loss_box_reg: 0.5758  loss_mask: 0.301  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.2278  time: 0.6017  data_time: 0.2103  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:37:58 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 8759  total_loss: 1.486  loss_cls: 0.3254  loss_box_reg: 0.5219  loss_mask: 0.2946  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.2114  time: 0.6016  data_time: 0.2104  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:38:09 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 8779  total_loss: 1.496  loss_cls: 0.3549  loss_box_reg: 0.5317  loss_mask: 0.2837  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.2094  time: 0.6015  data_time: 0.2127  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:38:22 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 8799  total_loss: 1.625  loss_cls: 0.3593  loss_box_reg: 0.5468  loss_mask: 0.3423  loss_rpn_cls: 0.08937  loss_rpn_loc: 0.225  time: 0.6016  data_time: 0.2979  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:38:32 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 8819  total_loss: 1.515  loss_cls: 0.342  loss_box_reg: 0.5613  loss_mask: 0.2991  loss_rpn_cls: 0.0891  loss_rpn_loc: 0.2095  time: 0.6014  data_time: 0.1743  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:38:45 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 8839  total_loss: 1.489  loss_cls: 0.3463  loss_box_reg: 0.529  loss_mask: 0.3003  loss_rpn_cls: 0.08185  loss_rpn_loc: 0.216  time: 0.6014  data_time: 0.2727  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:39:01 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 8859  total_loss: 1.65  loss_cls: 0.3973  loss_box_reg: 0.5117  loss_mask: 0.3173  loss_rpn_cls: 0.1345  loss_rpn_loc: 0.2635  time: 0.6018  data_time: 0.4231  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:39:10 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 8879  total_loss: 1.563  loss_cls: 0.3825  loss_box_reg: 0.5422  loss_mask: 0.2974  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.2255  time: 0.6016  data_time: 0.1449  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:39:22 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 8899  total_loss: 1.537  loss_cls: 0.3301  loss_box_reg: 0.5716  loss_mask: 0.3078  loss_rpn_cls: 0.09062  loss_rpn_loc: 0.2279  time: 0.6015  data_time: 0.2560  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:39:35 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 8919  total_loss: 1.563  loss_cls: 0.3764  loss_box_reg: 0.5494  loss_mask: 0.2968  loss_rpn_cls: 0.1175  loss_rpn_loc: 0.2395  time: 0.6016  data_time: 0.2969  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:39:46 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 8939  total_loss: 1.616  loss_cls: 0.396  loss_box_reg: 0.5492  loss_mask: 0.3133  loss_rpn_cls: 0.1218  loss_rpn_loc: 0.2261  time: 0.6016  data_time: 0.2264  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:39:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:39:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:39:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:39:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:39:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:39:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0767 s/iter. Eval: 0.0120 s/iter. Total: 0.0895 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0783 s/iter. Eval: 0.0156 s/iter. Total: 0.0947 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0784 s/iter. Eval: 0.0151 s/iter. Total: 0.0943 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:40:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.047896 (0.095240 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:40:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078541 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:40:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:40:09 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2327709732461974\n",
      "\u001b[32m[01/11 20:40:12 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 8959  total_loss: 1.529  loss_cls: 0.3563  loss_box_reg: 0.5022  loss_mask: 0.2987  loss_rpn_cls: 0.09783  loss_rpn_loc: 0.2178  time: 0.6017  data_time: 0.3343  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:40:23 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 8979  total_loss: 1.728  loss_cls: 0.41  loss_box_reg: 0.5406  loss_mask: 0.3045  loss_rpn_cls: 0.1489  loss_rpn_loc: 0.2506  time: 0.6016  data_time: 0.2181  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:40:37 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 8999  total_loss: 1.512  loss_cls: 0.3856  loss_box_reg: 0.5319  loss_mask: 0.3044  loss_rpn_cls: 0.1101  loss_rpn_loc: 0.2273  time: 0.6018  data_time: 0.3011  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:40:50 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 9019  total_loss: 1.575  loss_cls: 0.3733  loss_box_reg: 0.5426  loss_mask: 0.2977  loss_rpn_cls: 0.124  loss_rpn_loc: 0.2225  time: 0.6019  data_time: 0.3114  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:41:02 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 9039  total_loss: 1.546  loss_cls: 0.3488  loss_box_reg: 0.5727  loss_mask: 0.3055  loss_rpn_cls: 0.08519  loss_rpn_loc: 0.207  time: 0.6019  data_time: 0.2490  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:41:12 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 9059  total_loss: 1.511  loss_cls: 0.3347  loss_box_reg: 0.5451  loss_mask: 0.3181  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2092  time: 0.6017  data_time: 0.2044  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:41:24 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 9079  total_loss: 1.511  loss_cls: 0.3263  loss_box_reg: 0.5492  loss_mask: 0.2998  loss_rpn_cls: 0.07684  loss_rpn_loc: 0.2237  time: 0.6017  data_time: 0.2417  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:41:35 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 9099  total_loss: 1.627  loss_cls: 0.339  loss_box_reg: 0.5793  loss_mask: 0.3059  loss_rpn_cls: 0.09379  loss_rpn_loc: 0.2198  time: 0.6016  data_time: 0.1898  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:41:48 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 9119  total_loss: 1.615  loss_cls: 0.3887  loss_box_reg: 0.5101  loss_mask: 0.3196  loss_rpn_cls: 0.1345  loss_rpn_loc: 0.2227  time: 0.6017  data_time: 0.3147  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:42:00 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9139  total_loss: 1.604  loss_cls: 0.3698  loss_box_reg: 0.5182  loss_mask: 0.3021  loss_rpn_cls: 0.09867  loss_rpn_loc: 0.2352  time: 0.6016  data_time: 0.2246  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:42:12 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 9159  total_loss: 1.551  loss_cls: 0.3581  loss_box_reg: 0.5308  loss_mask: 0.3163  loss_rpn_cls: 0.09941  loss_rpn_loc: 0.2372  time: 0.6017  data_time: 0.2740  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:42:22 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 9179  total_loss: 1.545  loss_cls: 0.376  loss_box_reg: 0.5252  loss_mask: 0.2973  loss_rpn_cls: 0.112  loss_rpn_loc: 0.224  time: 0.6015  data_time: 0.1731  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:42:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:42:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:42:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:42:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:42:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:42:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0011 s/iter. Inference: 0.0752 s/iter. Eval: 0.0111 s/iter. Total: 0.0875 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0008 s/iter. Inference: 0.0769 s/iter. Eval: 0.0122 s/iter. Total: 0.0900 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 20:42:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.330006 (0.089052 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:42:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076231 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:42:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:42:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22403862954971893\n",
      "\u001b[32m[01/11 20:42:44 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 9199  total_loss: 1.658  loss_cls: 0.3841  loss_box_reg: 0.5489  loss_mask: 0.3173  loss_rpn_cls: 0.07737  loss_rpn_loc: 0.2295  time: 0.6013  data_time: 0.1744  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:42:57 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 9219  total_loss: 1.529  loss_cls: 0.3496  loss_box_reg: 0.53  loss_mask: 0.3176  loss_rpn_cls: 0.1191  loss_rpn_loc: 0.2219  time: 0.6014  data_time: 0.3010  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:43:09 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 9239  total_loss: 1.518  loss_cls: 0.3315  loss_box_reg: 0.5335  loss_mask: 0.3043  loss_rpn_cls: 0.08803  loss_rpn_loc: 0.2227  time: 0.6013  data_time: 0.2342  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:43:21 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 9259  total_loss: 1.57  loss_cls: 0.3745  loss_box_reg: 0.5391  loss_mask: 0.3069  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.2377  time: 0.6013  data_time: 0.2463  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:43:31 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 9279  total_loss: 1.557  loss_cls: 0.3326  loss_box_reg: 0.555  loss_mask: 0.3238  loss_rpn_cls: 0.0828  loss_rpn_loc: 0.2209  time: 0.6011  data_time: 0.1548  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:43:44 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 9299  total_loss: 1.595  loss_cls: 0.3537  loss_box_reg: 0.5386  loss_mask: 0.2956  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.2427  time: 0.6012  data_time: 0.3126  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:43:57 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 9319  total_loss: 1.579  loss_cls: 0.4193  loss_box_reg: 0.5137  loss_mask: 0.3042  loss_rpn_cls: 0.129  loss_rpn_loc: 0.2397  time: 0.6013  data_time: 0.3122  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:44:07 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 9339  total_loss: 1.612  loss_cls: 0.3988  loss_box_reg: 0.5575  loss_mask: 0.2909  loss_rpn_cls: 0.08607  loss_rpn_loc: 0.2375  time: 0.6012  data_time: 0.1916  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:44:20 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 9359  total_loss: 1.543  loss_cls: 0.3539  loss_box_reg: 0.5223  loss_mask: 0.3066  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.2233  time: 0.6013  data_time: 0.3028  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:44:31 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 9379  total_loss: 1.625  loss_cls: 0.379  loss_box_reg: 0.5398  loss_mask: 0.2948  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2414  time: 0.6011  data_time: 0.1718  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:44:40 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 9399  total_loss: 1.614  loss_cls: 0.3922  loss_box_reg: 0.5616  loss_mask: 0.3047  loss_rpn_cls: 0.0871  loss_rpn_loc: 0.221  time: 0.6008  data_time: 0.1095  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:44:54 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 9419  total_loss: 1.535  loss_cls: 0.3455  loss_box_reg: 0.5382  loss_mask: 0.3177  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.2253  time: 0.6010  data_time: 0.3590  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:45:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:45:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:45:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:45:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:45:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:45:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0760 s/iter. Eval: 0.0101 s/iter. Total: 0.0868 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0786 s/iter. Eval: 0.0138 s/iter. Total: 0.0933 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:45:18 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0137 s/iter. Total: 0.0925 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:45:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.817043 (0.093250 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:45:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078036 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:45:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:45:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2201226828078228\n",
      "\u001b[32m[01/11 20:45:19 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 9439  total_loss: 1.6  loss_cls: 0.3496  loss_box_reg: 0.5284  loss_mask: 0.3215  loss_rpn_cls: 0.1333  loss_rpn_loc: 0.2365  time: 0.6011  data_time: 0.2889  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:45:34 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 9459  total_loss: 1.467  loss_cls: 0.3569  loss_box_reg: 0.5034  loss_mask: 0.3183  loss_rpn_cls: 0.09914  loss_rpn_loc: 0.2213  time: 0.6015  data_time: 0.4143  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:45:45 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 9479  total_loss: 1.52  loss_cls: 0.3625  loss_box_reg: 0.5286  loss_mask: 0.2997  loss_rpn_cls: 0.08361  loss_rpn_loc: 0.2069  time: 0.6013  data_time: 0.2029  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:46:00 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 9499  total_loss: 1.598  loss_cls: 0.3751  loss_box_reg: 0.5138  loss_mask: 0.3104  loss_rpn_cls: 0.09219  loss_rpn_loc: 0.2287  time: 0.6016  data_time: 0.3579  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:46:11 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 9519  total_loss: 1.45  loss_cls: 0.3405  loss_box_reg: 0.5368  loss_mask: 0.3023  loss_rpn_cls: 0.09225  loss_rpn_loc: 0.2067  time: 0.6015  data_time: 0.2149  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:46:22 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 9539  total_loss: 1.586  loss_cls: 0.3532  loss_box_reg: 0.5468  loss_mask: 0.313  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.2274  time: 0.6014  data_time: 0.2483  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:46:33 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 9559  total_loss: 1.572  loss_cls: 0.3957  loss_box_reg: 0.5555  loss_mask: 0.3145  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2324  time: 0.6013  data_time: 0.2076  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:46:47 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 9579  total_loss: 1.589  loss_cls: 0.3397  loss_box_reg: 0.5496  loss_mask: 0.3026  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.2358  time: 0.6015  data_time: 0.3272  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:46:58 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9599  total_loss: 1.704  loss_cls: 0.3894  loss_box_reg: 0.5851  loss_mask: 0.326  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.2503  time: 0.6014  data_time: 0.2006  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:47:07 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 9619  total_loss: 1.512  loss_cls: 0.3532  loss_box_reg: 0.5625  loss_mask: 0.2902  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.2261  time: 0.6011  data_time: 0.1214  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:47:19 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 9639  total_loss: 1.659  loss_cls: 0.3638  loss_box_reg: 0.5856  loss_mask: 0.3236  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.2558  time: 0.6010  data_time: 0.2474  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:47:29 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 9659  total_loss: 1.48  loss_cls: 0.3562  loss_box_reg: 0.5402  loss_mask: 0.3059  loss_rpn_cls: 0.08413  loss_rpn_loc: 0.2197  time: 0.6009  data_time: 0.1838  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:47:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:47:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:47:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:47:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:47:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:47:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0772 s/iter. Eval: 0.0123 s/iter. Total: 0.0903 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0158 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0785 s/iter. Eval: 0.0160 s/iter. Total: 0.0954 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:47:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.120790 (0.095869 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:47:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078421 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:47:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:47:55 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2407897495300547\n",
      "\u001b[32m[01/11 20:47:55 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9679  total_loss: 1.481  loss_cls: 0.3735  loss_box_reg: 0.5237  loss_mask: 0.2874  loss_rpn_cls: 0.1198  loss_rpn_loc: 0.2297  time: 0.6010  data_time: 0.2882  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:48:07 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 9699  total_loss: 1.569  loss_cls: 0.3428  loss_box_reg: 0.5675  loss_mask: 0.319  loss_rpn_cls: 0.09452  loss_rpn_loc: 0.2164  time: 0.6010  data_time: 0.2679  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:48:19 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 9719  total_loss: 1.532  loss_cls: 0.3473  loss_box_reg: 0.5288  loss_mask: 0.3271  loss_rpn_cls: 0.08863  loss_rpn_loc: 0.2062  time: 0.6010  data_time: 0.2449  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:48:30 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 9739  total_loss: 1.574  loss_cls: 0.3656  loss_box_reg: 0.5441  loss_mask: 0.3129  loss_rpn_cls: 0.09105  loss_rpn_loc: 0.2276  time: 0.6009  data_time: 0.2166  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:48:39 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 9759  total_loss: 1.535  loss_cls: 0.3582  loss_box_reg: 0.5263  loss_mask: 0.3114  loss_rpn_cls: 0.09761  loss_rpn_loc: 0.2176  time: 0.6006  data_time: 0.1143  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:48:52 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 9779  total_loss: 1.624  loss_cls: 0.3976  loss_box_reg: 0.5619  loss_mask: 0.3057  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.2312  time: 0.6007  data_time: 0.2954  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:49:04 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 9799  total_loss: 1.498  loss_cls: 0.3391  loss_box_reg: 0.5284  loss_mask: 0.3038  loss_rpn_cls: 0.06958  loss_rpn_loc: 0.2113  time: 0.6007  data_time: 0.2255  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:49:16 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 9819  total_loss: 1.678  loss_cls: 0.4007  loss_box_reg: 0.5683  loss_mask: 0.307  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.2451  time: 0.6007  data_time: 0.2471  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:49:30 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 9839  total_loss: 1.566  loss_cls: 0.3866  loss_box_reg: 0.5188  loss_mask: 0.3072  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.2302  time: 0.6009  data_time: 0.3651  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:49:44 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 9859  total_loss: 1.515  loss_cls: 0.3591  loss_box_reg: 0.5206  loss_mask: 0.2968  loss_rpn_cls: 0.1327  loss_rpn_loc: 0.2266  time: 0.6011  data_time: 0.3436  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:49:59 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 9879  total_loss: 1.637  loss_cls: 0.4011  loss_box_reg: 0.5469  loss_mask: 0.3026  loss_rpn_cls: 0.121  loss_rpn_loc: 0.261  time: 0.6014  data_time: 0.3602  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:50:12 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 9899  total_loss: 1.464  loss_cls: 0.354  loss_box_reg: 0.498  loss_mask: 0.2922  loss_rpn_cls: 0.08165  loss_rpn_loc: 0.2101  time: 0.6015  data_time: 0.3293  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:50:24 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 9919  total_loss: 1.551  loss_cls: 0.3586  loss_box_reg: 0.538  loss_mask: 0.3145  loss_rpn_cls: 0.1203  loss_rpn_loc: 0.2261  time: 0.6015  data_time: 0.2569  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:50:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:50:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:50:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:50:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:50:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:50:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0804 s/iter. Eval: 0.0132 s/iter. Total: 0.0944 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 20:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0786 s/iter. Eval: 0.0158 s/iter. Total: 0.0952 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0789 s/iter. Eval: 0.0154 s/iter. Total: 0.0952 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:50:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.125827 (0.095912 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:50:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078997 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:50:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:50:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23462798207204977\n",
      "\u001b[32m[01/11 20:50:48 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 9939  total_loss: 1.641  loss_cls: 0.3896  loss_box_reg: 0.5809  loss_mask: 0.3024  loss_rpn_cls: 0.1313  loss_rpn_loc: 0.2493  time: 0.6015  data_time: 0.2288  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:51:02 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 9959  total_loss: 1.633  loss_cls: 0.4068  loss_box_reg: 0.5602  loss_mask: 0.3118  loss_rpn_cls: 0.109  loss_rpn_loc: 0.2425  time: 0.6016  data_time: 0.3259  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:51:11 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 9979  total_loss: 1.603  loss_cls: 0.3776  loss_box_reg: 0.5853  loss_mask: 0.3074  loss_rpn_cls: 0.08946  loss_rpn_loc: 0.2138  time: 0.6013  data_time: 0.1191  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:51:21 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.557  loss_cls: 0.3778  loss_box_reg: 0.5242  loss_mask: 0.3022  loss_rpn_cls: 0.111  loss_rpn_loc: 0.2203  time: 0.6011  data_time: 0.1786  lr: 0.0005  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:51:21 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:40:10 (0.6011 s / it)\n",
      "\u001b[32m[01/11 20:51:21 d2.engine.hooks]: \u001b[0mTotal training time: 1:48:19 (0:08:09 on hooks)\n",
      "\u001b[32m[01/11 20:51:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:51:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:51:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:51:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:51:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:51:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:51:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0765 s/iter. Eval: 0.0115 s/iter. Total: 0.0888 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0791 s/iter. Eval: 0.0162 s/iter. Total: 0.0961 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0786 s/iter. Eval: 0.0163 s/iter. Total: 0.0957 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:51:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.177753 (0.096360 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:51:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078682 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:51:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:51:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23148887720710512\n"
     ]
    }
   ],
   "source": [
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d4e647-b081-49d5-9bc1-8f836d0e3694",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/11 20:57:15 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/11 20:57:15 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/11 20:57:16 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/11 20:57:17 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/11 20:57:17 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[01/11 20:57:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/11 20:57:17 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/11 20:57:17 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:57:17 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/11 20:57:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[01/11 20:57:31 d2.utils.events]: \u001b[0m eta: 0:59:27  iter: 19  total_loss: 3.009  loss_cls: 1.334  loss_box_reg: 0.3613  loss_mask: 0.6936  loss_rpn_cls: 0.3485  loss_rpn_loc: 0.2911  time: 0.6090  data_time: 0.3572  lr: 1.9981e-06  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:57:42 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 39  total_loss: 2.898  loss_cls: 1.212  loss_box_reg: 0.4695  loss_mask: 0.6907  loss_rpn_cls: 0.2531  loss_rpn_loc: 0.2342  time: 0.5847  data_time: 0.2348  lr: 3.9961e-06  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:57:55 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 59  total_loss: 2.536  loss_cls: 0.8507  loss_box_reg: 0.4812  loss_mask: 0.6875  loss_rpn_cls: 0.2113  loss_rpn_loc: 0.2519  time: 0.5997  data_time: 0.2851  lr: 5.9941e-06  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:58:06 d2.utils.events]: \u001b[0m eta: 0:59:07  iter: 79  total_loss: 2.316  loss_cls: 0.6433  loss_box_reg: 0.6081  loss_mask: 0.6719  loss_rpn_cls: 0.1401  loss_rpn_loc: 0.2123  time: 0.5892  data_time: 0.2210  lr: 7.9921e-06  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:58:21 d2.utils.events]: \u001b[0m eta: 0:59:32  iter: 99  total_loss: 2.233  loss_cls: 0.5691  loss_box_reg: 0.6327  loss_mask: 0.6265  loss_rpn_cls: 0.1437  loss_rpn_loc: 0.2453  time: 0.6150  data_time: 0.3693  lr: 9.9901e-06  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:58:33 d2.utils.events]: \u001b[0m eta: 0:59:25  iter: 119  total_loss: 2.048  loss_cls: 0.4973  loss_box_reg: 0.631  loss_mask: 0.5128  loss_rpn_cls: 0.1489  loss_rpn_loc: 0.2336  time: 0.6178  data_time: 0.2918  lr: 1.1988e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:58:46 d2.utils.events]: \u001b[0m eta: 0:59:45  iter: 139  total_loss: 1.879  loss_cls: 0.4429  loss_box_reg: 0.6645  loss_mask: 0.4342  loss_rpn_cls: 0.1228  loss_rpn_loc: 0.243  time: 0.6211  data_time: 0.2862  lr: 1.3986e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:58:56 d2.utils.events]: \u001b[0m eta: 0:59:30  iter: 159  total_loss: 1.786  loss_cls: 0.4438  loss_box_reg: 0.683  loss_mask: 0.3728  loss_rpn_cls: 0.08504  loss_rpn_loc: 0.1951  time: 0.6080  data_time: 0.1761  lr: 1.5984e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:59:12 d2.utils.events]: \u001b[0m eta: 1:00:01  iter: 179  total_loss: 1.825  loss_cls: 0.4293  loss_box_reg: 0.6  loss_mask: 0.3964  loss_rpn_cls: 0.1362  loss_rpn_loc: 0.2384  time: 0.6262  data_time: 0.4056  lr: 1.7982e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:59:22 d2.utils.events]: \u001b[0m eta: 0:59:53  iter: 199  total_loss: 1.768  loss_cls: 0.4042  loss_box_reg: 0.6893  loss_mask: 0.3681  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2092  time: 0.6145  data_time: 0.1715  lr: 1.998e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:59:35 d2.utils.events]: \u001b[0m eta: 1:00:27  iter: 219  total_loss: 1.85  loss_cls: 0.4645  loss_box_reg: 0.6659  loss_mask: 0.3684  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.2285  time: 0.6174  data_time: 0.2771  lr: 2.1978e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:59:46 d2.utils.events]: \u001b[0m eta: 0:59:52  iter: 239  total_loss: 1.737  loss_cls: 0.3939  loss_box_reg: 0.6008  loss_mask: 0.3458  loss_rpn_cls: 0.1153  loss_rpn_loc: 0.2097  time: 0.6123  data_time: 0.2144  lr: 2.3976e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 20:59:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:59:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 20:59:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 20:59:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 20:59:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 20:59:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 20:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0753 s/iter. Eval: 0.0115 s/iter. Total: 0.0875 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 20:59:54 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0775 s/iter. Eval: 0.0157 s/iter. Total: 0.0939 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 20:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0007 s/iter. Inference: 0.0777 s/iter. Eval: 0.0158 s/iter. Total: 0.0942 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 20:59:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.023834 (0.095033 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:59:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077817 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 20:59:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 20:59:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21515934198789652\n",
      "\u001b[32m[01/11 21:00:09 d2.utils.events]: \u001b[0m eta: 0:59:33  iter: 259  total_loss: 1.699  loss_cls: 0.4193  loss_box_reg: 0.6049  loss_mask: 0.3528  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.2134  time: 0.6059  data_time: 0.1790  lr: 2.5974e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:00:18 d2.utils.events]: \u001b[0m eta: 0:59:24  iter: 279  total_loss: 1.617  loss_cls: 0.3891  loss_box_reg: 0.6047  loss_mask: 0.3534  loss_rpn_cls: 0.07603  loss_rpn_loc: 0.1808  time: 0.5950  data_time: 0.1083  lr: 2.7972e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:00:32 d2.utils.events]: \u001b[0m eta: 0:59:17  iter: 299  total_loss: 1.585  loss_cls: 0.3778  loss_box_reg: 0.5776  loss_mask: 0.3319  loss_rpn_cls: 0.09401  loss_rpn_loc: 0.2068  time: 0.6028  data_time: 0.3586  lr: 2.997e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:00:51 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 319  total_loss: 1.693  loss_cls: 0.4023  loss_box_reg: 0.5487  loss_mask: 0.3472  loss_rpn_cls: 0.1302  loss_rpn_loc: 0.2198  time: 0.6231  data_time: 0.5542  lr: 3.1968e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:01:06 d2.utils.events]: \u001b[0m eta: 0:59:26  iter: 339  total_loss: 1.59  loss_cls: 0.4074  loss_box_reg: 0.5654  loss_mask: 0.3323  loss_rpn_cls: 0.1184  loss_rpn_loc: 0.2278  time: 0.6300  data_time: 0.3834  lr: 3.3966e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:01:16 d2.utils.events]: \u001b[0m eta: 0:59:09  iter: 359  total_loss: 1.606  loss_cls: 0.375  loss_box_reg: 0.6103  loss_mask: 0.3319  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.2225  time: 0.6228  data_time: 0.1673  lr: 3.5964e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:01:28 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 379  total_loss: 1.799  loss_cls: 0.4521  loss_box_reg: 0.6098  loss_mask: 0.3229  loss_rpn_cls: 0.1273  loss_rpn_loc: 0.2467  time: 0.6238  data_time: 0.2944  lr: 3.7962e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:01:39 d2.utils.events]: \u001b[0m eta: 0:58:59  iter: 399  total_loss: 1.592  loss_cls: 0.3877  loss_box_reg: 0.6076  loss_mask: 0.3211  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.2005  time: 0.6178  data_time: 0.1634  lr: 3.996e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:01:50 d2.utils.events]: \u001b[0m eta: 0:58:47  iter: 419  total_loss: 1.622  loss_cls: 0.3617  loss_box_reg: 0.6087  loss_mask: 0.3391  loss_rpn_cls: 0.09147  loss_rpn_loc: 0.2122  time: 0.6148  data_time: 0.2129  lr: 4.1958e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:02:00 d2.utils.events]: \u001b[0m eta: 0:58:38  iter: 439  total_loss: 1.622  loss_cls: 0.3634  loss_box_reg: 0.5763  loss_mask: 0.3237  loss_rpn_cls: 0.09823  loss_rpn_loc: 0.2149  time: 0.6103  data_time: 0.1830  lr: 4.3956e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:02:14 d2.utils.events]: \u001b[0m eta: 0:58:27  iter: 459  total_loss: 1.577  loss_cls: 0.378  loss_box_reg: 0.5552  loss_mask: 0.3254  loss_rpn_cls: 0.11  loss_rpn_loc: 0.2158  time: 0.6134  data_time: 0.3346  lr: 4.5954e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:02:24 d2.utils.events]: \u001b[0m eta: 0:58:11  iter: 479  total_loss: 1.64  loss_cls: 0.3492  loss_box_reg: 0.5689  loss_mask: 0.3347  loss_rpn_cls: 0.09938  loss_rpn_loc: 0.218  time: 0.6101  data_time: 0.2077  lr: 4.7952e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:02:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:02:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:02:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:02:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:02:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:02:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:02:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0735 s/iter. Eval: 0.0101 s/iter. Total: 0.0841 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:02:34 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0756 s/iter. Eval: 0.0136 s/iter. Total: 0.0899 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 21:02:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.543107 (0.090889 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:02:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075694 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:02:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:02:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22737131591073195\n",
      "\u001b[32m[01/11 21:02:49 d2.utils.events]: \u001b[0m eta: 0:58:08  iter: 499  total_loss: 1.608  loss_cls: 0.3894  loss_box_reg: 0.5768  loss_mask: 0.3285  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.2165  time: 0.6112  data_time: 0.2942  lr: 4.995e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:02:59 d2.utils.events]: \u001b[0m eta: 0:57:43  iter: 519  total_loss: 1.526  loss_cls: 0.3595  loss_box_reg: 0.5822  loss_mask: 0.3168  loss_rpn_cls: 0.07724  loss_rpn_loc: 0.1921  time: 0.6065  data_time: 0.1633  lr: 5.1948e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:03:08 d2.utils.events]: \u001b[0m eta: 0:57:17  iter: 539  total_loss: 1.56  loss_cls: 0.3582  loss_box_reg: 0.5795  loss_mask: 0.3151  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.2222  time: 0.6020  data_time: 0.1612  lr: 5.3946e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:03:19 d2.utils.events]: \u001b[0m eta: 0:57:04  iter: 559  total_loss: 1.544  loss_cls: 0.3588  loss_box_reg: 0.5696  loss_mask: 0.3105  loss_rpn_cls: 0.07291  loss_rpn_loc: 0.1899  time: 0.5989  data_time: 0.1819  lr: 5.5944e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:03:29 d2.utils.events]: \u001b[0m eta: 0:56:39  iter: 579  total_loss: 1.58  loss_cls: 0.3672  loss_box_reg: 0.5667  loss_mask: 0.3167  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.2132  time: 0.5958  data_time: 0.1776  lr: 5.7942e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:03:44 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 599  total_loss: 1.649  loss_cls: 0.4391  loss_box_reg: 0.5292  loss_mask: 0.3123  loss_rpn_cls: 0.1344  loss_rpn_loc: 0.22  time: 0.6011  data_time: 0.3957  lr: 5.994e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:03:56 d2.utils.events]: \u001b[0m eta: 0:56:45  iter: 619  total_loss: 1.631  loss_cls: 0.3931  loss_box_reg: 0.5345  loss_mask: 0.334  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.2171  time: 0.6015  data_time: 0.2680  lr: 6.1938e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:04:08 d2.utils.events]: \u001b[0m eta: 0:56:35  iter: 639  total_loss: 1.665  loss_cls: 0.3601  loss_box_reg: 0.5327  loss_mask: 0.3449  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.2285  time: 0.6005  data_time: 0.2311  lr: 6.3936e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:04:21 d2.utils.events]: \u001b[0m eta: 0:56:27  iter: 659  total_loss: 1.58  loss_cls: 0.3771  loss_box_reg: 0.5304  loss_mask: 0.3329  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.2207  time: 0.6025  data_time: 0.3267  lr: 6.5934e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:04:33 d2.utils.events]: \u001b[0m eta: 0:56:14  iter: 679  total_loss: 1.593  loss_cls: 0.4109  loss_box_reg: 0.5501  loss_mask: 0.3176  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.2322  time: 0.6032  data_time: 0.2838  lr: 6.7932e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:04:47 d2.utils.events]: \u001b[0m eta: 0:55:59  iter: 699  total_loss: 1.406  loss_cls: 0.2929  loss_box_reg: 0.5383  loss_mask: 0.306  loss_rpn_cls: 0.09351  loss_rpn_loc: 0.2071  time: 0.6046  data_time: 0.3256  lr: 6.993e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:05:00 d2.utils.events]: \u001b[0m eta: 0:56:08  iter: 719  total_loss: 1.494  loss_cls: 0.3682  loss_box_reg: 0.5469  loss_mask: 0.3307  loss_rpn_cls: 0.08221  loss_rpn_loc: 0.215  time: 0.6060  data_time: 0.3056  lr: 7.1928e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:05:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:05:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:05:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:05:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:05:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:05:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:05:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0727 s/iter. Eval: 0.0092 s/iter. Total: 0.0825 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0757 s/iter. Eval: 0.0144 s/iter. Total: 0.0908 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 21:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0007 s/iter. Inference: 0.0764 s/iter. Eval: 0.0150 s/iter. Total: 0.0921 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:05:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.733156 (0.092527 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:05:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076344 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:05:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:05:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2290359782002185\n",
      "\u001b[32m[01/11 21:05:23 d2.utils.events]: \u001b[0m eta: 0:55:52  iter: 739  total_loss: 1.608  loss_cls: 0.3831  loss_box_reg: 0.5354  loss_mask: 0.3346  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.2154  time: 0.6044  data_time: 0.2131  lr: 7.3926e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:05:37 d2.utils.events]: \u001b[0m eta: 0:55:38  iter: 759  total_loss: 1.624  loss_cls: 0.3877  loss_box_reg: 0.5424  loss_mask: 0.3134  loss_rpn_cls: 0.1212  loss_rpn_loc: 0.2223  time: 0.6068  data_time: 0.3549  lr: 7.5924e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:05:47 d2.utils.events]: \u001b[0m eta: 0:55:26  iter: 779  total_loss: 1.561  loss_cls: 0.394  loss_box_reg: 0.5663  loss_mask: 0.3285  loss_rpn_cls: 0.0824  loss_rpn_loc: 0.1986  time: 0.6052  data_time: 0.2117  lr: 7.7922e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:05:59 d2.utils.events]: \u001b[0m eta: 0:55:17  iter: 799  total_loss: 1.531  loss_cls: 0.351  loss_box_reg: 0.5515  loss_mask: 0.3084  loss_rpn_cls: 0.08764  loss_rpn_loc: 0.2005  time: 0.6051  data_time: 0.2706  lr: 7.992e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:06:11 d2.utils.events]: \u001b[0m eta: 0:55:07  iter: 819  total_loss: 1.453  loss_cls: 0.3426  loss_box_reg: 0.5488  loss_mask: 0.2856  loss_rpn_cls: 0.0923  loss_rpn_loc: 0.1964  time: 0.6049  data_time: 0.2569  lr: 8.1918e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:06:25 d2.utils.events]: \u001b[0m eta: 0:55:05  iter: 839  total_loss: 1.542  loss_cls: 0.3681  loss_box_reg: 0.5227  loss_mask: 0.3162  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.2166  time: 0.6071  data_time: 0.3424  lr: 8.3916e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:06:35 d2.utils.events]: \u001b[0m eta: 0:54:57  iter: 859  total_loss: 1.647  loss_cls: 0.4038  loss_box_reg: 0.5928  loss_mask: 0.3305  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.2133  time: 0.6044  data_time: 0.1546  lr: 8.5914e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:06:47 d2.utils.events]: \u001b[0m eta: 0:54:50  iter: 879  total_loss: 1.626  loss_cls: 0.3697  loss_box_reg: 0.5678  loss_mask: 0.3212  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2403  time: 0.6043  data_time: 0.2536  lr: 8.7912e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:06:58 d2.utils.events]: \u001b[0m eta: 0:54:42  iter: 899  total_loss: 1.609  loss_cls: 0.4065  loss_box_reg: 0.5386  loss_mask: 0.312  loss_rpn_cls: 0.1181  loss_rpn_loc: 0.233  time: 0.6031  data_time: 0.2090  lr: 8.991e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:07:12 d2.utils.events]: \u001b[0m eta: 0:54:37  iter: 919  total_loss: 1.588  loss_cls: 0.384  loss_box_reg: 0.5649  loss_mask: 0.3249  loss_rpn_cls: 0.1235  loss_rpn_loc: 0.2112  time: 0.6045  data_time: 0.3224  lr: 9.1908e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:07:24 d2.utils.events]: \u001b[0m eta: 0:54:29  iter: 939  total_loss: 1.554  loss_cls: 0.3838  loss_box_reg: 0.5549  loss_mask: 0.3086  loss_rpn_cls: 0.109  loss_rpn_loc: 0.2013  time: 0.6048  data_time: 0.2909  lr: 9.3906e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:07:37 d2.utils.events]: \u001b[0m eta: 0:54:21  iter: 959  total_loss: 1.585  loss_cls: 0.3704  loss_box_reg: 0.5689  loss_mask: 0.3189  loss_rpn_cls: 0.09626  loss_rpn_loc: 0.2213  time: 0.6054  data_time: 0.3040  lr: 9.5904e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:07:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:07:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:07:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:07:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:07:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:07:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0698 s/iter. Eval: 0.0110 s/iter. Total: 0.0814 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/11 21:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0155 s/iter. Total: 0.0888 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 21:07:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.373060 (0.089423 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:07:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072623 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:07:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:07:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22620121826396775\n",
      "\u001b[32m[01/11 21:08:01 d2.utils.events]: \u001b[0m eta: 0:54:08  iter: 979  total_loss: 1.621  loss_cls: 0.3533  loss_box_reg: 0.573  loss_mask: 0.3334  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.2251  time: 0.6058  data_time: 0.3092  lr: 9.7902e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:08:13 d2.utils.events]: \u001b[0m eta: 0:54:01  iter: 999  total_loss: 1.425  loss_cls: 0.3422  loss_box_reg: 0.5104  loss_mask: 0.3052  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2118  time: 0.6058  data_time: 0.2774  lr: 9.99e-05  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:08:26 d2.utils.events]: \u001b[0m eta: 0:53:52  iter: 1019  total_loss: 1.581  loss_cls: 0.321  loss_box_reg: 0.5427  loss_mask: 0.3091  loss_rpn_cls: 0.1185  loss_rpn_loc: 0.2112  time: 0.6073  data_time: 0.3636  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:08:38 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 1039  total_loss: 1.559  loss_cls: 0.3511  loss_box_reg: 0.5364  loss_mask: 0.3188  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2058  time: 0.6063  data_time: 0.2430  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:08:49 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 1059  total_loss: 1.582  loss_cls: 0.3897  loss_box_reg: 0.5592  loss_mask: 0.3231  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.208  time: 0.6061  data_time: 0.2751  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:09:03 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 1079  total_loss: 1.653  loss_cls: 0.4232  loss_box_reg: 0.532  loss_mask: 0.3277  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.2365  time: 0.6073  data_time: 0.3406  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:09:15 d2.utils.events]: \u001b[0m eta: 0:53:12  iter: 1099  total_loss: 1.592  loss_cls: 0.3568  loss_box_reg: 0.5716  loss_mask: 0.3168  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.217  time: 0.6069  data_time: 0.2665  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:09:25 d2.utils.events]: \u001b[0m eta: 0:52:58  iter: 1119  total_loss: 1.573  loss_cls: 0.3763  loss_box_reg: 0.5911  loss_mask: 0.3121  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.2074  time: 0.6052  data_time: 0.2037  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:09:38 d2.utils.events]: \u001b[0m eta: 0:52:47  iter: 1139  total_loss: 1.664  loss_cls: 0.3788  loss_box_reg: 0.5547  loss_mask: 0.33  loss_rpn_cls: 0.1307  loss_rpn_loc: 0.2117  time: 0.6065  data_time: 0.3567  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:09:51 d2.utils.events]: \u001b[0m eta: 0:52:38  iter: 1159  total_loss: 1.542  loss_cls: 0.347  loss_box_reg: 0.5268  loss_mask: 0.3211  loss_rpn_cls: 0.09312  loss_rpn_loc: 0.2265  time: 0.6065  data_time: 0.2736  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:10:00 d2.utils.events]: \u001b[0m eta: 0:52:21  iter: 1179  total_loss: 1.578  loss_cls: 0.3864  loss_box_reg: 0.596  loss_mask: 0.312  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2137  time: 0.6045  data_time: 0.1614  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:10:10 d2.utils.events]: \u001b[0m eta: 0:52:14  iter: 1199  total_loss: 1.525  loss_cls: 0.364  loss_box_reg: 0.5376  loss_mask: 0.2996  loss_rpn_cls: 0.09466  loss_rpn_loc: 0.2004  time: 0.6021  data_time: 0.1295  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:10:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:10:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:10:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:10:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:10:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:10:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:10:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0720 s/iter. Eval: 0.0095 s/iter. Total: 0.0820 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:10:23 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0131 s/iter. Total: 0.0908 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 21:10:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.571927 (0.091137 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:10:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077082 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:10:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:10:28 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22228437245318092\n",
      "\u001b[32m[01/11 21:10:35 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 1219  total_loss: 1.707  loss_cls: 0.4246  loss_box_reg: 0.5511  loss_mask: 0.3101  loss_rpn_cls: 0.1401  loss_rpn_loc: 0.2373  time: 0.6031  data_time: 0.3328  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:10:46 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 1239  total_loss: 1.487  loss_cls: 0.3552  loss_box_reg: 0.5209  loss_mask: 0.2929  loss_rpn_cls: 0.08897  loss_rpn_loc: 0.209  time: 0.6025  data_time: 0.2389  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:10:57 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 1259  total_loss: 1.452  loss_cls: 0.3458  loss_box_reg: 0.563  loss_mask: 0.3028  loss_rpn_cls: 0.08176  loss_rpn_loc: 0.2095  time: 0.6018  data_time: 0.2260  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:11:10 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 1279  total_loss: 1.518  loss_cls: 0.357  loss_box_reg: 0.5397  loss_mask: 0.3172  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2341  time: 0.6027  data_time: 0.3190  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:11:21 d2.utils.events]: \u001b[0m eta: 0:51:07  iter: 1299  total_loss: 1.749  loss_cls: 0.4285  loss_box_reg: 0.5413  loss_mask: 0.329  loss_rpn_cls: 0.1413  loss_rpn_loc: 0.2525  time: 0.6018  data_time: 0.2029  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:11:31 d2.utils.events]: \u001b[0m eta: 0:50:59  iter: 1319  total_loss: 1.571  loss_cls: 0.3756  loss_box_reg: 0.5494  loss_mask: 0.298  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.2139  time: 0.6004  data_time: 0.1644  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:11:43 d2.utils.events]: \u001b[0m eta: 0:50:44  iter: 1339  total_loss: 1.638  loss_cls: 0.4063  loss_box_reg: 0.5344  loss_mask: 0.3018  loss_rpn_cls: 0.1272  loss_rpn_loc: 0.2153  time: 0.6000  data_time: 0.2360  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:11:56 d2.utils.events]: \u001b[0m eta: 0:50:40  iter: 1359  total_loss: 1.651  loss_cls: 0.4202  loss_box_reg: 0.5722  loss_mask: 0.3084  loss_rpn_cls: 0.1312  loss_rpn_loc: 0.2212  time: 0.6009  data_time: 0.3242  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:12:08 d2.utils.events]: \u001b[0m eta: 0:50:31  iter: 1379  total_loss: 1.51  loss_cls: 0.359  loss_box_reg: 0.5487  loss_mask: 0.3223  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.2136  time: 0.6009  data_time: 0.2543  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:12:22 d2.utils.events]: \u001b[0m eta: 0:50:24  iter: 1399  total_loss: 1.509  loss_cls: 0.3588  loss_box_reg: 0.4944  loss_mask: 0.2949  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.2138  time: 0.6021  data_time: 0.3388  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:12:34 d2.utils.events]: \u001b[0m eta: 0:50:17  iter: 1419  total_loss: 1.582  loss_cls: 0.366  loss_box_reg: 0.5677  loss_mask: 0.3228  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.2102  time: 0.6021  data_time: 0.2689  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:12:48 d2.utils.events]: \u001b[0m eta: 0:50:10  iter: 1439  total_loss: 1.56  loss_cls: 0.3917  loss_box_reg: 0.5334  loss_mask: 0.3383  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.2184  time: 0.6038  data_time: 0.3794  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:12:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:12:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:12:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:12:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:12:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:12:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0118 s/iter. Total: 0.0868 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0761 s/iter. Eval: 0.0147 s/iter. Total: 0.0916 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:13:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.651699 (0.091825 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:13:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075935 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:13:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:13:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2414261689429634\n",
      "\u001b[32m[01/11 21:13:13 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 1459  total_loss: 1.447  loss_cls: 0.3404  loss_box_reg: 0.5221  loss_mask: 0.3095  loss_rpn_cls: 0.09486  loss_rpn_loc: 0.1879  time: 0.6042  data_time: 0.2990  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:13:25 d2.utils.events]: \u001b[0m eta: 0:49:59  iter: 1479  total_loss: 1.465  loss_cls: 0.3445  loss_box_reg: 0.5554  loss_mask: 0.2987  loss_rpn_cls: 0.1202  loss_rpn_loc: 0.2174  time: 0.6044  data_time: 0.2793  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:13:37 d2.utils.events]: \u001b[0m eta: 0:49:52  iter: 1499  total_loss: 1.568  loss_cls: 0.3688  loss_box_reg: 0.5313  loss_mask: 0.3119  loss_rpn_cls: 0.103  loss_rpn_loc: 0.2165  time: 0.6044  data_time: 0.2576  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:13:48 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 1519  total_loss: 1.516  loss_cls: 0.3418  loss_box_reg: 0.5497  loss_mask: 0.2861  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.1748  time: 0.6036  data_time: 0.2124  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:14:04 d2.utils.events]: \u001b[0m eta: 0:49:53  iter: 1539  total_loss: 1.562  loss_cls: 0.384  loss_box_reg: 0.5336  loss_mask: 0.3063  loss_rpn_cls: 0.1  loss_rpn_loc: 0.2058  time: 0.6061  data_time: 0.4358  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:14:14 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 1559  total_loss: 1.477  loss_cls: 0.3466  loss_box_reg: 0.5645  loss_mask: 0.3065  loss_rpn_cls: 0.06627  loss_rpn_loc: 0.1975  time: 0.6046  data_time: 0.1593  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:14:26 d2.utils.events]: \u001b[0m eta: 0:49:42  iter: 1579  total_loss: 1.619  loss_cls: 0.3848  loss_box_reg: 0.5773  loss_mask: 0.3172  loss_rpn_cls: 0.107  loss_rpn_loc: 0.2153  time: 0.6043  data_time: 0.2297  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:14:37 d2.utils.events]: \u001b[0m eta: 0:49:34  iter: 1599  total_loss: 1.594  loss_cls: 0.4153  loss_box_reg: 0.5427  loss_mask: 0.2948  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.2028  time: 0.6041  data_time: 0.2413  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:14:49 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 1619  total_loss: 1.53  loss_cls: 0.3727  loss_box_reg: 0.5491  loss_mask: 0.2872  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.2208  time: 0.6036  data_time: 0.2239  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:15:01 d2.utils.events]: \u001b[0m eta: 0:49:19  iter: 1639  total_loss: 1.563  loss_cls: 0.3557  loss_box_reg: 0.5431  loss_mask: 0.327  loss_rpn_cls: 0.09258  loss_rpn_loc: 0.1998  time: 0.6038  data_time: 0.2874  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:15:15 d2.utils.events]: \u001b[0m eta: 0:49:11  iter: 1659  total_loss: 1.63  loss_cls: 0.3917  loss_box_reg: 0.5295  loss_mask: 0.3266  loss_rpn_cls: 0.1135  loss_rpn_loc: 0.2219  time: 0.6049  data_time: 0.3631  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:15:26 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 1679  total_loss: 1.573  loss_cls: 0.3508  loss_box_reg: 0.5259  loss_mask: 0.319  loss_rpn_cls: 0.08325  loss_rpn_loc: 0.2195  time: 0.6044  data_time: 0.2235  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:15:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:15:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:15:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:15:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:15:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:15:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0116 s/iter. Total: 0.0858 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0783 s/iter. Eval: 0.0170 s/iter. Total: 0.0960 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0777 s/iter. Eval: 0.0176 s/iter. Total: 0.0961 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:15:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.266655 (0.097126 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:15:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077867 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:15:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:15:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25477806192601077\n",
      "\u001b[32m[01/11 21:15:51 d2.utils.events]: \u001b[0m eta: 0:48:46  iter: 1699  total_loss: 1.459  loss_cls: 0.3279  loss_box_reg: 0.5486  loss_mask: 0.3149  loss_rpn_cls: 0.09042  loss_rpn_loc: 0.1942  time: 0.6043  data_time: 0.2613  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:16:02 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 1719  total_loss: 1.507  loss_cls: 0.3402  loss_box_reg: 0.5327  loss_mask: 0.3178  loss_rpn_cls: 0.08281  loss_rpn_loc: 0.1928  time: 0.6040  data_time: 0.2444  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:16:13 d2.utils.events]: \u001b[0m eta: 0:48:33  iter: 1739  total_loss: 1.487  loss_cls: 0.337  loss_box_reg: 0.5423  loss_mask: 0.3105  loss_rpn_cls: 0.07874  loss_rpn_loc: 0.203  time: 0.6032  data_time: 0.2068  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:16:28 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 1759  total_loss: 1.591  loss_cls: 0.402  loss_box_reg: 0.5768  loss_mask: 0.3109  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.2305  time: 0.6049  data_time: 0.4068  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:16:38 d2.utils.events]: \u001b[0m eta: 0:48:33  iter: 1779  total_loss: 1.437  loss_cls: 0.3316  loss_box_reg: 0.5202  loss_mask: 0.2966  loss_rpn_cls: 0.0803  loss_rpn_loc: 0.1783  time: 0.6037  data_time: 0.1640  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:16:48 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 1799  total_loss: 1.643  loss_cls: 0.3834  loss_box_reg: 0.5672  loss_mask: 0.3114  loss_rpn_cls: 0.09209  loss_rpn_loc: 0.221  time: 0.6026  data_time: 0.1834  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:17:00 d2.utils.events]: \u001b[0m eta: 0:48:19  iter: 1819  total_loss: 1.498  loss_cls: 0.3696  loss_box_reg: 0.5335  loss_mask: 0.306  loss_rpn_cls: 0.09738  loss_rpn_loc: 0.2077  time: 0.6024  data_time: 0.2408  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:17:09 d2.utils.events]: \u001b[0m eta: 0:48:08  iter: 1839  total_loss: 1.467  loss_cls: 0.3391  loss_box_reg: 0.5373  loss_mask: 0.2952  loss_rpn_cls: 0.06082  loss_rpn_loc: 0.1954  time: 0.6010  data_time: 0.1356  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:17:19 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 1859  total_loss: 1.529  loss_cls: 0.3734  loss_box_reg: 0.53  loss_mask: 0.3041  loss_rpn_cls: 0.0938  loss_rpn_loc: 0.2113  time: 0.5999  data_time: 0.1582  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:17:32 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 1879  total_loss: 1.525  loss_cls: 0.4259  loss_box_reg: 0.5279  loss_mask: 0.3046  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.212  time: 0.6002  data_time: 0.2934  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:17:45 d2.utils.events]: \u001b[0m eta: 0:47:33  iter: 1899  total_loss: 1.525  loss_cls: 0.3477  loss_box_reg: 0.5276  loss_mask: 0.3083  loss_rpn_cls: 0.09596  loss_rpn_loc: 0.2167  time: 0.6008  data_time: 0.3221  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:17:59 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 1919  total_loss: 1.52  loss_cls: 0.3287  loss_box_reg: 0.5463  loss_mask: 0.3388  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.206  time: 0.6019  data_time: 0.3582  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:18:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:18:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:18:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:18:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:18:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:18:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0742 s/iter. Eval: 0.0115 s/iter. Total: 0.0863 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:18:17 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0772 s/iter. Eval: 0.0168 s/iter. Total: 0.0947 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0171 s/iter. Total: 0.0947 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:18:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.083688 (0.095549 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:18:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077023 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:18:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:18:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23714515786806237\n",
      "\u001b[32m[01/11 21:18:25 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 1939  total_loss: 1.684  loss_cls: 0.3935  loss_box_reg: 0.5545  loss_mask: 0.3391  loss_rpn_cls: 0.1202  loss_rpn_loc: 0.2411  time: 0.6025  data_time: 0.3229  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:18:38 d2.utils.events]: \u001b[0m eta: 0:47:11  iter: 1959  total_loss: 1.51  loss_cls: 0.3734  loss_box_reg: 0.5485  loss_mask: 0.3085  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.2075  time: 0.6030  data_time: 0.3133  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:18:47 d2.utils.events]: \u001b[0m eta: 0:47:02  iter: 1979  total_loss: 1.499  loss_cls: 0.364  loss_box_reg: 0.5695  loss_mask: 0.3144  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.197  time: 0.6016  data_time: 0.1381  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:19:02 d2.utils.events]: \u001b[0m eta: 0:46:59  iter: 1999  total_loss: 1.572  loss_cls: 0.3687  loss_box_reg: 0.5121  loss_mask: 0.3154  loss_rpn_cls: 0.0974  loss_rpn_loc: 0.2156  time: 0.6028  data_time: 0.3607  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:19:15 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 2019  total_loss: 1.586  loss_cls: 0.3929  loss_box_reg: 0.5376  loss_mask: 0.3166  loss_rpn_cls: 0.1282  loss_rpn_loc: 0.2228  time: 0.6033  data_time: 0.3087  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:19:24 d2.utils.events]: \u001b[0m eta: 0:46:45  iter: 2039  total_loss: 1.427  loss_cls: 0.2939  loss_box_reg: 0.5316  loss_mask: 0.2972  loss_rpn_cls: 0.07621  loss_rpn_loc: 0.189  time: 0.6018  data_time: 0.1213  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:19:38 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 2059  total_loss: 1.472  loss_cls: 0.3259  loss_box_reg: 0.5196  loss_mask: 0.3009  loss_rpn_cls: 0.08992  loss_rpn_loc: 0.2132  time: 0.6027  data_time: 0.3568  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:19:49 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 2079  total_loss: 1.407  loss_cls: 0.3027  loss_box_reg: 0.5206  loss_mask: 0.2967  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.2043  time: 0.6026  data_time: 0.2473  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:20:02 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 2099  total_loss: 1.5  loss_cls: 0.3424  loss_box_reg: 0.5363  loss_mask: 0.301  loss_rpn_cls: 0.0977  loss_rpn_loc: 0.2186  time: 0.6029  data_time: 0.2866  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:20:13 d2.utils.events]: \u001b[0m eta: 0:46:35  iter: 2119  total_loss: 1.522  loss_cls: 0.3726  loss_box_reg: 0.5593  loss_mask: 0.3081  loss_rpn_cls: 0.08232  loss_rpn_loc: 0.2175  time: 0.6024  data_time: 0.2281  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:20:27 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 2139  total_loss: 1.422  loss_cls: 0.3352  loss_box_reg: 0.5148  loss_mask: 0.2909  loss_rpn_cls: 0.0789  loss_rpn_loc: 0.1982  time: 0.6034  data_time: 0.3530  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:20:38 d2.utils.events]: \u001b[0m eta: 0:46:23  iter: 2159  total_loss: 1.464  loss_cls: 0.3512  loss_box_reg: 0.5312  loss_mask: 0.3056  loss_rpn_cls: 0.08417  loss_rpn_loc: 0.2017  time: 0.6030  data_time: 0.2282  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:20:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:20:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:20:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:20:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:20:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:20:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0103 s/iter. Total: 0.0843 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:20:55 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0783 s/iter. Eval: 0.0166 s/iter. Total: 0.0956 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0007 s/iter. Inference: 0.0783 s/iter. Eval: 0.0171 s/iter. Total: 0.0961 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:21:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.232125 (0.096829 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:21:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078325 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:21:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:21:01 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24603204009329877\n",
      "\u001b[32m[01/11 21:21:02 d2.utils.events]: \u001b[0m eta: 0:46:12  iter: 2179  total_loss: 1.51  loss_cls: 0.3112  loss_box_reg: 0.5336  loss_mask: 0.3262  loss_rpn_cls: 0.07402  loss_rpn_loc: 0.2086  time: 0.6022  data_time: 0.1986  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:21:14 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 2199  total_loss: 1.509  loss_cls: 0.384  loss_box_reg: 0.5248  loss_mask: 0.3013  loss_rpn_cls: 0.09742  loss_rpn_loc: 0.2113  time: 0.6022  data_time: 0.2562  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:21:24 d2.utils.events]: \u001b[0m eta: 0:46:06  iter: 2219  total_loss: 1.459  loss_cls: 0.3381  loss_box_reg: 0.5476  loss_mask: 0.2948  loss_rpn_cls: 0.08606  loss_rpn_loc: 0.2037  time: 0.6016  data_time: 0.1800  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:21:35 d2.utils.events]: \u001b[0m eta: 0:46:00  iter: 2239  total_loss: 1.444  loss_cls: 0.3743  loss_box_reg: 0.5402  loss_mask: 0.2959  loss_rpn_cls: 0.08317  loss_rpn_loc: 0.1936  time: 0.6013  data_time: 0.2301  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:21:52 d2.utils.events]: \u001b[0m eta: 0:46:01  iter: 2259  total_loss: 1.625  loss_cls: 0.3607  loss_box_reg: 0.545  loss_mask: 0.327  loss_rpn_cls: 0.1253  loss_rpn_loc: 0.2108  time: 0.6033  data_time: 0.4743  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:22:06 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 2279  total_loss: 1.392  loss_cls: 0.3103  loss_box_reg: 0.5227  loss_mask: 0.3124  loss_rpn_cls: 0.0784  loss_rpn_loc: 0.2114  time: 0.6040  data_time: 0.3512  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:22:20 d2.utils.events]: \u001b[0m eta: 0:45:51  iter: 2299  total_loss: 1.445  loss_cls: 0.347  loss_box_reg: 0.525  loss_mask: 0.288  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.1796  time: 0.6050  data_time: 0.3740  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:22:28 d2.utils.events]: \u001b[0m eta: 0:45:40  iter: 2319  total_loss: 1.404  loss_cls: 0.3432  loss_box_reg: 0.5366  loss_mask: 0.3048  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.1918  time: 0.6033  data_time: 0.0789  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:22:38 d2.utils.events]: \u001b[0m eta: 0:45:33  iter: 2339  total_loss: 1.554  loss_cls: 0.423  loss_box_reg: 0.5489  loss_mask: 0.3311  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.2126  time: 0.6024  data_time: 0.1661  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:22:50 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 2359  total_loss: 1.551  loss_cls: 0.3506  loss_box_reg: 0.5392  loss_mask: 0.3132  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.2158  time: 0.6023  data_time: 0.2575  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:23:01 d2.utils.events]: \u001b[0m eta: 0:45:15  iter: 2379  total_loss: 1.51  loss_cls: 0.3642  loss_box_reg: 0.565  loss_mask: 0.3068  loss_rpn_cls: 0.08487  loss_rpn_loc: 0.2195  time: 0.6017  data_time: 0.1943  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:23:15 d2.utils.events]: \u001b[0m eta: 0:45:11  iter: 2399  total_loss: 1.621  loss_cls: 0.4024  loss_box_reg: 0.5537  loss_mask: 0.3191  loss_rpn_cls: 0.08734  loss_rpn_loc: 0.2003  time: 0.6025  data_time: 0.3467  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:23:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:23:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:23:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:23:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:23:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:23:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0108 s/iter. Total: 0.0850 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0763 s/iter. Eval: 0.0158 s/iter. Total: 0.0929 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0765 s/iter. Eval: 0.0160 s/iter. Total: 0.0933 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:23:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.911866 (0.094068 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:23:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076536 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:23:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:23:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2450984476855216\n",
      "\u001b[32m[01/11 21:23:38 d2.utils.events]: \u001b[0m eta: 0:45:05  iter: 2419  total_loss: 1.508  loss_cls: 0.3839  loss_box_reg: 0.5174  loss_mask: 0.3029  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.1975  time: 0.6022  data_time: 0.2166  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:23:51 d2.utils.events]: \u001b[0m eta: 0:44:57  iter: 2439  total_loss: 1.477  loss_cls: 0.3439  loss_box_reg: 0.4847  loss_mask: 0.3012  loss_rpn_cls: 0.09405  loss_rpn_loc: 0.2171  time: 0.6023  data_time: 0.2696  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:24:03 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 2459  total_loss: 1.448  loss_cls: 0.3147  loss_box_reg: 0.5314  loss_mask: 0.3154  loss_rpn_cls: 0.0795  loss_rpn_loc: 0.1997  time: 0.6025  data_time: 0.2937  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:24:19 d2.utils.events]: \u001b[0m eta: 0:44:41  iter: 2479  total_loss: 1.508  loss_cls: 0.3594  loss_box_reg: 0.5171  loss_mask: 0.2892  loss_rpn_cls: 0.09134  loss_rpn_loc: 0.2008  time: 0.6041  data_time: 0.4560  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:24:32 d2.utils.events]: \u001b[0m eta: 0:44:36  iter: 2499  total_loss: 1.402  loss_cls: 0.3385  loss_box_reg: 0.5048  loss_mask: 0.2992  loss_rpn_cls: 0.09119  loss_rpn_loc: 0.2254  time: 0.6045  data_time: 0.3133  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:24:42 d2.utils.events]: \u001b[0m eta: 0:44:27  iter: 2519  total_loss: 1.44  loss_cls: 0.3089  loss_box_reg: 0.5614  loss_mask: 0.3009  loss_rpn_cls: 0.07336  loss_rpn_loc: 0.1936  time: 0.6036  data_time: 0.1717  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:24:54 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 2539  total_loss: 1.396  loss_cls: 0.3308  loss_box_reg: 0.4955  loss_mask: 0.2838  loss_rpn_cls: 0.07066  loss_rpn_loc: 0.1916  time: 0.6037  data_time: 0.2711  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:25:07 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 2559  total_loss: 1.544  loss_cls: 0.3495  loss_box_reg: 0.5413  loss_mask: 0.2971  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.2174  time: 0.6040  data_time: 0.2983  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:25:22 d2.utils.events]: \u001b[0m eta: 0:44:14  iter: 2579  total_loss: 1.561  loss_cls: 0.3686  loss_box_reg: 0.5155  loss_mask: 0.2861  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.2246  time: 0.6049  data_time: 0.3667  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:25:33 d2.utils.events]: \u001b[0m eta: 0:44:06  iter: 2599  total_loss: 1.516  loss_cls: 0.343  loss_box_reg: 0.5426  loss_mask: 0.3128  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2174  time: 0.6048  data_time: 0.2603  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:25:49 d2.utils.events]: \u001b[0m eta: 0:44:01  iter: 2619  total_loss: 1.432  loss_cls: 0.3542  loss_box_reg: 0.4995  loss_mask: 0.2908  loss_rpn_cls: 0.09475  loss_rpn_loc: 0.1964  time: 0.6063  data_time: 0.4570  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:26:00 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 2639  total_loss: 1.465  loss_cls: 0.321  loss_box_reg: 0.5497  loss_mask: 0.3042  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.2114  time: 0.6056  data_time: 0.1827  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:26:12 d2.utils.events]: \u001b[0m eta: 0:43:47  iter: 2659  total_loss: 1.523  loss_cls: 0.3487  loss_box_reg: 0.5091  loss_mask: 0.3147  loss_rpn_cls: 0.08785  loss_rpn_loc: 0.1986  time: 0.6055  data_time: 0.2449  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:26:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:26:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:26:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:26:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:26:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:26:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0734 s/iter. Eval: 0.0098 s/iter. Total: 0.0838 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0761 s/iter. Eval: 0.0144 s/iter. Total: 0.0913 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:26:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.638789 (0.091714 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:26:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076073 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:26:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:26:25 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24899514883260931\n",
      "\u001b[32m[01/11 21:26:35 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 2679  total_loss: 1.502  loss_cls: 0.3581  loss_box_reg: 0.5155  loss_mask: 0.3056  loss_rpn_cls: 0.0826  loss_rpn_loc: 0.1889  time: 0.6052  data_time: 0.2215  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:26:46 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 2699  total_loss: 1.388  loss_cls: 0.3221  loss_box_reg: 0.4945  loss_mask: 0.2915  loss_rpn_cls: 0.0595  loss_rpn_loc: 0.2024  time: 0.6050  data_time: 0.2480  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:26:58 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 2719  total_loss: 1.326  loss_cls: 0.3155  loss_box_reg: 0.4874  loss_mask: 0.2903  loss_rpn_cls: 0.05493  loss_rpn_loc: 0.1673  time: 0.6050  data_time: 0.2584  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:27:09 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 2739  total_loss: 1.381  loss_cls: 0.3213  loss_box_reg: 0.5366  loss_mask: 0.3148  loss_rpn_cls: 0.07687  loss_rpn_loc: 0.1886  time: 0.6042  data_time: 0.1594  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:27:19 d2.utils.events]: \u001b[0m eta: 0:43:08  iter: 2759  total_loss: 1.454  loss_cls: 0.3147  loss_box_reg: 0.5322  loss_mask: 0.3159  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.2021  time: 0.6035  data_time: 0.1727  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:27:36 d2.utils.events]: \u001b[0m eta: 0:43:03  iter: 2779  total_loss: 1.601  loss_cls: 0.395  loss_box_reg: 0.5066  loss_mask: 0.3279  loss_rpn_cls: 0.1203  loss_rpn_loc: 0.2354  time: 0.6054  data_time: 0.5040  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:27:49 d2.utils.events]: \u001b[0m eta: 0:42:58  iter: 2799  total_loss: 1.523  loss_cls: 0.3728  loss_box_reg: 0.5414  loss_mask: 0.3045  loss_rpn_cls: 0.08534  loss_rpn_loc: 0.2076  time: 0.6057  data_time: 0.3032  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:28:02 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 2819  total_loss: 1.534  loss_cls: 0.3493  loss_box_reg: 0.5582  loss_mask: 0.3125  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2235  time: 0.6062  data_time: 0.3296  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:28:11 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 2839  total_loss: 1.486  loss_cls: 0.3338  loss_box_reg: 0.5292  loss_mask: 0.2984  loss_rpn_cls: 0.07465  loss_rpn_loc: 0.1988  time: 0.6049  data_time: 0.1035  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:28:22 d2.utils.events]: \u001b[0m eta: 0:42:40  iter: 2859  total_loss: 1.51  loss_cls: 0.3747  loss_box_reg: 0.5578  loss_mask: 0.3025  loss_rpn_cls: 0.09512  loss_rpn_loc: 0.1978  time: 0.6046  data_time: 0.2098  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:28:32 d2.utils.events]: \u001b[0m eta: 0:42:33  iter: 2879  total_loss: 1.586  loss_cls: 0.3483  loss_box_reg: 0.5283  loss_mask: 0.2995  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.2142  time: 0.6039  data_time: 0.1784  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:28:42 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 2899  total_loss: 1.562  loss_cls: 0.347  loss_box_reg: 0.5222  loss_mask: 0.3126  loss_rpn_cls: 0.08334  loss_rpn_loc: 0.1938  time: 0.6032  data_time: 0.1637  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:28:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:28:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:28:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:28:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:28:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:28:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0772 s/iter. Eval: 0.0108 s/iter. Total: 0.0886 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0793 s/iter. Eval: 0.0145 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0793 s/iter. Eval: 0.0144 s/iter. Total: 0.0944 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:28:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.029056 (0.095078 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:28:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079258 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:28:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:28:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2395719532268334\n",
      "\u001b[32m[01/11 21:29:05 d2.utils.events]: \u001b[0m eta: 0:42:22  iter: 2919  total_loss: 1.613  loss_cls: 0.3755  loss_box_reg: 0.5347  loss_mask: 0.3262  loss_rpn_cls: 0.09733  loss_rpn_loc: 0.2077  time: 0.6027  data_time: 0.1735  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:29:19 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 2939  total_loss: 1.559  loss_cls: 0.37  loss_box_reg: 0.519  loss_mask: 0.319  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2075  time: 0.6031  data_time: 0.3229  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:29:33 d2.utils.events]: \u001b[0m eta: 0:42:10  iter: 2959  total_loss: 1.602  loss_cls: 0.4086  loss_box_reg: 0.5279  loss_mask: 0.3171  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.2236  time: 0.6041  data_time: 0.4009  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:29:49 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 2979  total_loss: 1.575  loss_cls: 0.3786  loss_box_reg: 0.5741  loss_mask: 0.3145  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.2099  time: 0.6053  data_time: 0.4275  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:30:01 d2.utils.events]: \u001b[0m eta: 0:42:05  iter: 2999  total_loss: 1.363  loss_cls: 0.2872  loss_box_reg: 0.5001  loss_mask: 0.2853  loss_rpn_cls: 0.0649  loss_rpn_loc: 0.1774  time: 0.6051  data_time: 0.2367  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:30:13 d2.utils.events]: \u001b[0m eta: 0:41:57  iter: 3019  total_loss: 1.521  loss_cls: 0.3795  loss_box_reg: 0.5101  loss_mask: 0.3094  loss_rpn_cls: 0.08702  loss_rpn_loc: 0.2115  time: 0.6051  data_time: 0.2530  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:30:26 d2.utils.events]: \u001b[0m eta: 0:41:54  iter: 3039  total_loss: 1.53  loss_cls: 0.3334  loss_box_reg: 0.5719  loss_mask: 0.3034  loss_rpn_cls: 0.07636  loss_rpn_loc: 0.2168  time: 0.6054  data_time: 0.3201  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:30:40 d2.utils.events]: \u001b[0m eta: 0:41:45  iter: 3059  total_loss: 1.384  loss_cls: 0.3283  loss_box_reg: 0.4808  loss_mask: 0.2847  loss_rpn_cls: 0.0913  loss_rpn_loc: 0.2046  time: 0.6060  data_time: 0.3524  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:30:52 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 3079  total_loss: 1.362  loss_cls: 0.3152  loss_box_reg: 0.5106  loss_mask: 0.2952  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.1863  time: 0.6061  data_time: 0.2827  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:31:02 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 3099  total_loss: 1.444  loss_cls: 0.3474  loss_box_reg: 0.4979  loss_mask: 0.3021  loss_rpn_cls: 0.08134  loss_rpn_loc: 0.216  time: 0.6055  data_time: 0.1736  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:31:14 d2.utils.events]: \u001b[0m eta: 0:41:21  iter: 3119  total_loss: 1.535  loss_cls: 0.34  loss_box_reg: 0.5263  loss_mask: 0.3051  loss_rpn_cls: 0.075  loss_rpn_loc: 0.2176  time: 0.6053  data_time: 0.2446  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:31:25 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 3139  total_loss: 1.475  loss_cls: 0.3361  loss_box_reg: 0.5293  loss_mask: 0.2954  loss_rpn_cls: 0.0742  loss_rpn_loc: 0.1961  time: 0.6050  data_time: 0.2272  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:31:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:31:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:31:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:31:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:31:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:31:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:31:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0729 s/iter. Eval: 0.0103 s/iter. Total: 0.0839 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:31:34 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0784 s/iter. Eval: 0.0161 s/iter. Total: 0.0953 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:31:39 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0793 s/iter. Eval: 0.0168 s/iter. Total: 0.0969 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:31:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.336651 (0.097730 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:31:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079235 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:31:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:31:40 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2534975073072325\n",
      "\u001b[32m[01/11 21:31:51 d2.utils.events]: \u001b[0m eta: 0:41:06  iter: 3159  total_loss: 1.522  loss_cls: 0.3533  loss_box_reg: 0.524  loss_mask: 0.3067  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.2162  time: 0.6052  data_time: 0.2868  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:32:03 d2.utils.events]: \u001b[0m eta: 0:41:01  iter: 3179  total_loss: 1.628  loss_cls: 0.3811  loss_box_reg: 0.5388  loss_mask: 0.3058  loss_rpn_cls: 0.09923  loss_rpn_loc: 0.2094  time: 0.6054  data_time: 0.2918  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:32:17 d2.utils.events]: \u001b[0m eta: 0:40:53  iter: 3199  total_loss: 1.403  loss_cls: 0.3038  loss_box_reg: 0.5075  loss_mask: 0.2954  loss_rpn_cls: 0.09297  loss_rpn_loc: 0.2082  time: 0.6058  data_time: 0.3290  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:32:28 d2.utils.events]: \u001b[0m eta: 0:40:42  iter: 3219  total_loss: 1.56  loss_cls: 0.3384  loss_box_reg: 0.5631  loss_mask: 0.3213  loss_rpn_cls: 0.09264  loss_rpn_loc: 0.1985  time: 0.6054  data_time: 0.2277  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:32:37 d2.utils.events]: \u001b[0m eta: 0:40:35  iter: 3239  total_loss: 1.382  loss_cls: 0.3  loss_box_reg: 0.5293  loss_mask: 0.3006  loss_rpn_cls: 0.04571  loss_rpn_loc: 0.185  time: 0.6046  data_time: 0.1221  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:32:49 d2.utils.events]: \u001b[0m eta: 0:40:26  iter: 3259  total_loss: 1.505  loss_cls: 0.3466  loss_box_reg: 0.5281  loss_mask: 0.3236  loss_rpn_cls: 0.08074  loss_rpn_loc: 0.2029  time: 0.6045  data_time: 0.2451  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:32:57 d2.utils.events]: \u001b[0m eta: 0:40:18  iter: 3279  total_loss: 1.414  loss_cls: 0.3198  loss_box_reg: 0.5302  loss_mask: 0.2811  loss_rpn_cls: 0.06954  loss_rpn_loc: 0.1991  time: 0.6032  data_time: 0.0776  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:33:08 d2.utils.events]: \u001b[0m eta: 0:40:11  iter: 3299  total_loss: 1.379  loss_cls: 0.3154  loss_box_reg: 0.5013  loss_mask: 0.2959  loss_rpn_cls: 0.07372  loss_rpn_loc: 0.2109  time: 0.6031  data_time: 0.2389  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:33:20 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 3319  total_loss: 1.457  loss_cls: 0.3141  loss_box_reg: 0.528  loss_mask: 0.3122  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.1919  time: 0.6030  data_time: 0.2599  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:33:34 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 3339  total_loss: 1.563  loss_cls: 0.344  loss_box_reg: 0.5367  loss_mask: 0.3184  loss_rpn_cls: 0.09817  loss_rpn_loc: 0.2285  time: 0.6034  data_time: 0.3228  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:33:45 d2.utils.events]: \u001b[0m eta: 0:39:49  iter: 3359  total_loss: 1.501  loss_cls: 0.3428  loss_box_reg: 0.5087  loss_mask: 0.2884  loss_rpn_cls: 0.08956  loss_rpn_loc: 0.2059  time: 0.6031  data_time: 0.2144  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:33:57 d2.utils.events]: \u001b[0m eta: 0:39:42  iter: 3379  total_loss: 1.586  loss_cls: 0.3982  loss_box_reg: 0.5342  loss_mask: 0.3201  loss_rpn_cls: 0.08736  loss_rpn_loc: 0.2085  time: 0.6033  data_time: 0.2679  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:34:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:34:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:34:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:34:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:34:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:34:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0742 s/iter. Eval: 0.0109 s/iter. Total: 0.0857 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0776 s/iter. Eval: 0.0154 s/iter. Total: 0.0937 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0771 s/iter. Eval: 0.0153 s/iter. Total: 0.0932 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:34:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.906005 (0.094017 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:34:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077140 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:34:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:34:13 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24311917427802102\n",
      "\u001b[32m[01/11 21:34:21 d2.utils.events]: \u001b[0m eta: 0:39:36  iter: 3399  total_loss: 1.504  loss_cls: 0.3581  loss_box_reg: 0.5299  loss_mask: 0.3136  loss_rpn_cls: 0.09645  loss_rpn_loc: 0.2198  time: 0.6030  data_time: 0.2175  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:34:31 d2.utils.events]: \u001b[0m eta: 0:39:25  iter: 3419  total_loss: 1.415  loss_cls: 0.3379  loss_box_reg: 0.5048  loss_mask: 0.2948  loss_rpn_cls: 0.07728  loss_rpn_loc: 0.1909  time: 0.6025  data_time: 0.1882  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:34:46 d2.utils.events]: \u001b[0m eta: 0:39:20  iter: 3439  total_loss: 1.449  loss_cls: 0.3315  loss_box_reg: 0.525  loss_mask: 0.2957  loss_rpn_cls: 0.06587  loss_rpn_loc: 0.1964  time: 0.6034  data_time: 0.4022  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:34:58 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 3459  total_loss: 1.38  loss_cls: 0.3286  loss_box_reg: 0.5076  loss_mask: 0.3081  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.1836  time: 0.6033  data_time: 0.2440  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:35:10 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 3479  total_loss: 1.444  loss_cls: 0.3084  loss_box_reg: 0.5512  loss_mask: 0.2968  loss_rpn_cls: 0.09856  loss_rpn_loc: 0.1937  time: 0.6032  data_time: 0.2550  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:35:23 d2.utils.events]: \u001b[0m eta: 0:38:59  iter: 3499  total_loss: 1.51  loss_cls: 0.3627  loss_box_reg: 0.514  loss_mask: 0.2983  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.205  time: 0.6036  data_time: 0.3131  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:35:35 d2.utils.events]: \u001b[0m eta: 0:38:55  iter: 3519  total_loss: 1.511  loss_cls: 0.3699  loss_box_reg: 0.5278  loss_mask: 0.315  loss_rpn_cls: 0.09964  loss_rpn_loc: 0.1913  time: 0.6036  data_time: 0.2508  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:35:49 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 3539  total_loss: 1.551  loss_cls: 0.3936  loss_box_reg: 0.5451  loss_mask: 0.2983  loss_rpn_cls: 0.08431  loss_rpn_loc: 0.2178  time: 0.6041  data_time: 0.3321  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:35:59 d2.utils.events]: \u001b[0m eta: 0:38:37  iter: 3559  total_loss: 1.434  loss_cls: 0.3275  loss_box_reg: 0.5142  loss_mask: 0.2914  loss_rpn_cls: 0.05462  loss_rpn_loc: 0.1997  time: 0.6036  data_time: 0.1700  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:36:10 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 3579  total_loss: 1.482  loss_cls: 0.3155  loss_box_reg: 0.537  loss_mask: 0.3048  loss_rpn_cls: 0.08423  loss_rpn_loc: 0.2075  time: 0.6033  data_time: 0.2026  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:36:23 d2.utils.events]: \u001b[0m eta: 0:38:22  iter: 3599  total_loss: 1.385  loss_cls: 0.3235  loss_box_reg: 0.4813  loss_mask: 0.2845  loss_rpn_cls: 0.0669  loss_rpn_loc: 0.1882  time: 0.6034  data_time: 0.2560  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:36:35 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 3619  total_loss: 1.495  loss_cls: 0.3554  loss_box_reg: 0.5188  loss_mask: 0.2914  loss_rpn_cls: 0.09186  loss_rpn_loc: 0.2058  time: 0.6034  data_time: 0.2646  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:36:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:36:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:36:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:36:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:36:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:36:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0764 s/iter. Eval: 0.0119 s/iter. Total: 0.0889 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0781 s/iter. Eval: 0.0173 s/iter. Total: 0.0962 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0007 s/iter. Inference: 0.0787 s/iter. Eval: 0.0179 s/iter. Total: 0.0974 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:36:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.402163 (0.098295 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:36:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078717 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:36:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:36:53 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25304521428213\n",
      "\u001b[32m[01/11 21:36:58 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 3639  total_loss: 1.394  loss_cls: 0.3177  loss_box_reg: 0.5448  loss_mask: 0.3047  loss_rpn_cls: 0.0707  loss_rpn_loc: 0.1919  time: 0.6029  data_time: 0.1735  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:37:13 d2.utils.events]: \u001b[0m eta: 0:38:03  iter: 3659  total_loss: 1.479  loss_cls: 0.3406  loss_box_reg: 0.5222  loss_mask: 0.3093  loss_rpn_cls: 0.0806  loss_rpn_loc: 0.2091  time: 0.6038  data_time: 0.4106  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:37:25 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 3679  total_loss: 1.307  loss_cls: 0.2842  loss_box_reg: 0.5189  loss_mask: 0.2934  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1678  time: 0.6037  data_time: 0.2264  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:37:38 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 3699  total_loss: 1.383  loss_cls: 0.3084  loss_box_reg: 0.4708  loss_mask: 0.2987  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.1965  time: 0.6040  data_time: 0.3261  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:37:54 d2.utils.events]: \u001b[0m eta: 0:37:49  iter: 3719  total_loss: 1.409  loss_cls: 0.3118  loss_box_reg: 0.5285  loss_mask: 0.2961  loss_rpn_cls: 0.08072  loss_rpn_loc: 0.1879  time: 0.6050  data_time: 0.4423  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:38:05 d2.utils.events]: \u001b[0m eta: 0:37:43  iter: 3739  total_loss: 1.535  loss_cls: 0.3617  loss_box_reg: 0.5415  loss_mask: 0.3037  loss_rpn_cls: 0.09081  loss_rpn_loc: 0.2141  time: 0.6048  data_time: 0.2170  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:38:16 d2.utils.events]: \u001b[0m eta: 0:37:36  iter: 3759  total_loss: 1.46  loss_cls: 0.3123  loss_box_reg: 0.5151  loss_mask: 0.3083  loss_rpn_cls: 0.08174  loss_rpn_loc: 0.2081  time: 0.6045  data_time: 0.2084  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:38:32 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 3779  total_loss: 1.547  loss_cls: 0.3453  loss_box_reg: 0.5344  loss_mask: 0.3081  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2082  time: 0.6054  data_time: 0.4200  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:38:39 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 3799  total_loss: 1.377  loss_cls: 0.3184  loss_box_reg: 0.5141  loss_mask: 0.2766  loss_rpn_cls: 0.07667  loss_rpn_loc: 0.1873  time: 0.6043  data_time: 0.0626  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:38:52 d2.utils.events]: \u001b[0m eta: 0:37:06  iter: 3819  total_loss: 1.361  loss_cls: 0.3366  loss_box_reg: 0.471  loss_mask: 0.2672  loss_rpn_cls: 0.09881  loss_rpn_loc: 0.1984  time: 0.6043  data_time: 0.2700  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:39:05 d2.utils.events]: \u001b[0m eta: 0:37:06  iter: 3839  total_loss: 1.472  loss_cls: 0.3495  loss_box_reg: 0.5312  loss_mask: 0.3012  loss_rpn_cls: 0.09221  loss_rpn_loc: 0.2035  time: 0.6047  data_time: 0.3511  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:39:18 d2.utils.events]: \u001b[0m eta: 0:36:55  iter: 3859  total_loss: 1.426  loss_cls: 0.3345  loss_box_reg: 0.5066  loss_mask: 0.292  loss_rpn_cls: 0.09654  loss_rpn_loc: 0.1861  time: 0.6049  data_time: 0.3058  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:39:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:39:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:39:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:39:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:39:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:39:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0780 s/iter. Eval: 0.0112 s/iter. Total: 0.0899 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.0807 s/iter. Eval: 0.0166 s/iter. Total: 0.0981 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0008 s/iter. Inference: 0.0804 s/iter. Eval: 0.0175 s/iter. Total: 0.0987 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:39:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.476198 (0.098933 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:39:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.080066 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:39:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:39:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24499021354985961\n",
      "\u001b[32m[01/11 21:39:43 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 3879  total_loss: 1.513  loss_cls: 0.3443  loss_box_reg: 0.5353  loss_mask: 0.3118  loss_rpn_cls: 0.08825  loss_rpn_loc: 0.2138  time: 0.6047  data_time: 0.2227  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:39:56 d2.utils.events]: \u001b[0m eta: 0:36:46  iter: 3899  total_loss: 1.418  loss_cls: 0.3219  loss_box_reg: 0.5473  loss_mask: 0.3051  loss_rpn_cls: 0.06167  loss_rpn_loc: 0.1831  time: 0.6051  data_time: 0.3245  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:40:06 d2.utils.events]: \u001b[0m eta: 0:36:37  iter: 3919  total_loss: 1.398  loss_cls: 0.2935  loss_box_reg: 0.5138  loss_mask: 0.2912  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.1925  time: 0.6047  data_time: 0.1888  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:40:20 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 3939  total_loss: 1.568  loss_cls: 0.4007  loss_box_reg: 0.5215  loss_mask: 0.3221  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.2089  time: 0.6050  data_time: 0.3179  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:40:33 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 3959  total_loss: 1.488  loss_cls: 0.3645  loss_box_reg: 0.4858  loss_mask: 0.3025  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.2094  time: 0.6053  data_time: 0.3318  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:40:43 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 3979  total_loss: 1.432  loss_cls: 0.332  loss_box_reg: 0.5271  loss_mask: 0.2991  loss_rpn_cls: 0.08316  loss_rpn_loc: 0.1876  time: 0.6048  data_time: 0.1568  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:40:59 d2.utils.events]: \u001b[0m eta: 0:36:08  iter: 3999  total_loss: 1.442  loss_cls: 0.3081  loss_box_reg: 0.5056  loss_mask: 0.3034  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.2144  time: 0.6058  data_time: 0.4475  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:41:13 d2.utils.events]: \u001b[0m eta: 0:36:02  iter: 4019  total_loss: 1.398  loss_cls: 0.2776  loss_box_reg: 0.5004  loss_mask: 0.2915  loss_rpn_cls: 0.08279  loss_rpn_loc: 0.2003  time: 0.6063  data_time: 0.3405  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:41:23 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 4039  total_loss: 1.385  loss_cls: 0.313  loss_box_reg: 0.5018  loss_mask: 0.2985  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.1881  time: 0.6058  data_time: 0.1551  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:41:37 d2.utils.events]: \u001b[0m eta: 0:35:55  iter: 4059  total_loss: 1.457  loss_cls: 0.3532  loss_box_reg: 0.4842  loss_mask: 0.3059  loss_rpn_cls: 0.09639  loss_rpn_loc: 0.2194  time: 0.6061  data_time: 0.3253  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:41:48 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 4079  total_loss: 1.49  loss_cls: 0.3228  loss_box_reg: 0.5256  loss_mask: 0.2955  loss_rpn_cls: 0.06579  loss_rpn_loc: 0.2053  time: 0.6058  data_time: 0.2073  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:41:57 d2.utils.events]: \u001b[0m eta: 0:35:32  iter: 4099  total_loss: 1.335  loss_cls: 0.297  loss_box_reg: 0.5244  loss_mask: 0.2847  loss_rpn_cls: 0.04519  loss_rpn_loc: 0.1722  time: 0.6050  data_time: 0.1095  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:42:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:42:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:42:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:42:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:42:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:42:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0735 s/iter. Eval: 0.0088 s/iter. Total: 0.0829 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0116 s/iter. Total: 0.0866 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/11 21:42:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.053246 (0.086666 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:42:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074131 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:42:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:42:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2212843944991506\n",
      "\u001b[32m[01/11 21:42:20 d2.utils.events]: \u001b[0m eta: 0:35:25  iter: 4119  total_loss: 1.395  loss_cls: 0.3087  loss_box_reg: 0.5099  loss_mask: 0.305  loss_rpn_cls: 0.08113  loss_rpn_loc: 0.1877  time: 0.6049  data_time: 0.2681  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:42:31 d2.utils.events]: \u001b[0m eta: 0:35:29  iter: 4139  total_loss: 1.491  loss_cls: 0.3301  loss_box_reg: 0.5048  loss_mask: 0.3091  loss_rpn_cls: 0.09453  loss_rpn_loc: 0.2203  time: 0.6048  data_time: 0.2253  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:42:43 d2.utils.events]: \u001b[0m eta: 0:35:18  iter: 4159  total_loss: 1.558  loss_cls: 0.3814  loss_box_reg: 0.5056  loss_mask: 0.3135  loss_rpn_cls: 0.1353  loss_rpn_loc: 0.1922  time: 0.6047  data_time: 0.2542  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:42:56 d2.utils.events]: \u001b[0m eta: 0:35:02  iter: 4179  total_loss: 1.44  loss_cls: 0.3317  loss_box_reg: 0.5292  loss_mask: 0.3047  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.2015  time: 0.6049  data_time: 0.3143  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:43:10 d2.utils.events]: \u001b[0m eta: 0:35:01  iter: 4199  total_loss: 1.467  loss_cls: 0.3466  loss_box_reg: 0.527  loss_mask: 0.2965  loss_rpn_cls: 0.08574  loss_rpn_loc: 0.2052  time: 0.6053  data_time: 0.3334  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:43:22 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 4219  total_loss: 1.438  loss_cls: 0.3038  loss_box_reg: 0.5225  loss_mask: 0.31  loss_rpn_cls: 0.08815  loss_rpn_loc: 0.2171  time: 0.6053  data_time: 0.2728  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:43:33 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 4239  total_loss: 1.404  loss_cls: 0.3157  loss_box_reg: 0.5218  loss_mask: 0.2943  loss_rpn_cls: 0.08187  loss_rpn_loc: 0.1798  time: 0.6050  data_time: 0.1954  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:43:46 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 4259  total_loss: 1.523  loss_cls: 0.3505  loss_box_reg: 0.5055  loss_mask: 0.3049  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.2248  time: 0.6053  data_time: 0.3169  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:43:59 d2.utils.events]: \u001b[0m eta: 0:34:39  iter: 4279  total_loss: 1.451  loss_cls: 0.3166  loss_box_reg: 0.5439  loss_mask: 0.3045  loss_rpn_cls: 0.0907  loss_rpn_loc: 0.2016  time: 0.6055  data_time: 0.3118  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:44:08 d2.utils.events]: \u001b[0m eta: 0:34:24  iter: 4299  total_loss: 1.407  loss_cls: 0.3043  loss_box_reg: 0.5346  loss_mask: 0.3077  loss_rpn_cls: 0.06652  loss_rpn_loc: 0.1932  time: 0.6048  data_time: 0.1101  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:44:18 d2.utils.events]: \u001b[0m eta: 0:34:24  iter: 4319  total_loss: 1.471  loss_cls: 0.3787  loss_box_reg: 0.5217  loss_mask: 0.3057  loss_rpn_cls: 0.08359  loss_rpn_loc: 0.2072  time: 0.6043  data_time: 0.1542  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:44:29 d2.utils.events]: \u001b[0m eta: 0:34:18  iter: 4339  total_loss: 1.431  loss_cls: 0.3706  loss_box_reg: 0.5065  loss_mask: 0.2889  loss_rpn_cls: 0.09261  loss_rpn_loc: 0.2011  time: 0.6039  data_time: 0.1799  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:44:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:44:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:44:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:44:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:44:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:44:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0776 s/iter. Eval: 0.0104 s/iter. Total: 0.0886 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0771 s/iter. Eval: 0.0157 s/iter. Total: 0.0936 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0775 s/iter. Eval: 0.0163 s/iter. Total: 0.0946 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:44:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.110808 (0.095783 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:44:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077723 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:44:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:44:53 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2541995321490576\n",
      "\u001b[32m[01/11 21:44:56 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 4359  total_loss: 1.431  loss_cls: 0.3465  loss_box_reg: 0.4746  loss_mask: 0.2981  loss_rpn_cls: 0.09164  loss_rpn_loc: 0.2151  time: 0.6045  data_time: 0.3830  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:45:09 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 4379  total_loss: 1.414  loss_cls: 0.3086  loss_box_reg: 0.4922  loss_mask: 0.2989  loss_rpn_cls: 0.08827  loss_rpn_loc: 0.205  time: 0.6047  data_time: 0.2871  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:45:21 d2.utils.events]: \u001b[0m eta: 0:33:57  iter: 4399  total_loss: 1.476  loss_cls: 0.3358  loss_box_reg: 0.5344  loss_mask: 0.3043  loss_rpn_cls: 0.08685  loss_rpn_loc: 0.2082  time: 0.6047  data_time: 0.2774  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:45:33 d2.utils.events]: \u001b[0m eta: 0:33:55  iter: 4419  total_loss: 1.461  loss_cls: 0.3301  loss_box_reg: 0.4851  loss_mask: 0.3044  loss_rpn_cls: 0.0789  loss_rpn_loc: 0.1961  time: 0.6047  data_time: 0.2435  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:45:45 d2.utils.events]: \u001b[0m eta: 0:33:48  iter: 4439  total_loss: 1.496  loss_cls: 0.3589  loss_box_reg: 0.5328  loss_mask: 0.3088  loss_rpn_cls: 0.101  loss_rpn_loc: 0.2113  time: 0.6046  data_time: 0.2422  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:45:56 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 4459  total_loss: 1.387  loss_cls: 0.3277  loss_box_reg: 0.5315  loss_mask: 0.2983  loss_rpn_cls: 0.06078  loss_rpn_loc: 0.1826  time: 0.6045  data_time: 0.2320  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:46:11 d2.utils.events]: \u001b[0m eta: 0:33:35  iter: 4479  total_loss: 1.467  loss_cls: 0.369  loss_box_reg: 0.4832  loss_mask: 0.2912  loss_rpn_cls: 0.09733  loss_rpn_loc: 0.2047  time: 0.6051  data_time: 0.3978  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:46:23 d2.utils.events]: \u001b[0m eta: 0:33:27  iter: 4499  total_loss: 1.427  loss_cls: 0.3446  loss_box_reg: 0.4844  loss_mask: 0.2908  loss_rpn_cls: 0.06989  loss_rpn_loc: 0.1819  time: 0.6052  data_time: 0.2673  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:46:34 d2.utils.events]: \u001b[0m eta: 0:33:19  iter: 4519  total_loss: 1.376  loss_cls: 0.3171  loss_box_reg: 0.5258  loss_mask: 0.2855  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.1699  time: 0.6047  data_time: 0.1703  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:46:46 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 4539  total_loss: 1.412  loss_cls: 0.3097  loss_box_reg: 0.5248  loss_mask: 0.3054  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.1865  time: 0.6047  data_time: 0.2691  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:46:56 d2.utils.events]: \u001b[0m eta: 0:33:01  iter: 4559  total_loss: 1.484  loss_cls: 0.3249  loss_box_reg: 0.5254  loss_mask: 0.3114  loss_rpn_cls: 0.08827  loss_rpn_loc: 0.2213  time: 0.6044  data_time: 0.2081  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:47:11 d2.utils.events]: \u001b[0m eta: 0:32:54  iter: 4579  total_loss: 1.471  loss_cls: 0.3313  loss_box_reg: 0.512  loss_mask: 0.3076  loss_rpn_cls: 0.09381  loss_rpn_loc: 0.1971  time: 0.6049  data_time: 0.3544  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:47:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:47:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:47:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:47:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:47:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:47:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0744 s/iter. Eval: 0.0098 s/iter. Total: 0.0848 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0796 s/iter. Eval: 0.0149 s/iter. Total: 0.0952 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0791 s/iter. Eval: 0.0151 s/iter. Total: 0.0950 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:47:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.076870 (0.095490 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:47:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079063 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:47:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:47:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24608423164380336\n",
      "\u001b[32m[01/11 21:47:35 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 4599  total_loss: 1.43  loss_cls: 0.3621  loss_box_reg: 0.5015  loss_mask: 0.3144  loss_rpn_cls: 0.0854  loss_rpn_loc: 0.2119  time: 0.6049  data_time: 0.2597  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:47:48 d2.utils.events]: \u001b[0m eta: 0:32:42  iter: 4619  total_loss: 1.43  loss_cls: 0.307  loss_box_reg: 0.5419  loss_mask: 0.2968  loss_rpn_cls: 0.06409  loss_rpn_loc: 0.1929  time: 0.6050  data_time: 0.2860  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:48:01 d2.utils.events]: \u001b[0m eta: 0:32:35  iter: 4639  total_loss: 1.478  loss_cls: 0.3458  loss_box_reg: 0.5205  loss_mask: 0.2962  loss_rpn_cls: 0.08761  loss_rpn_loc: 0.2  time: 0.6052  data_time: 0.2898  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:48:13 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 4659  total_loss: 1.442  loss_cls: 0.3498  loss_box_reg: 0.5239  loss_mask: 0.3158  loss_rpn_cls: 0.08933  loss_rpn_loc: 0.1905  time: 0.6052  data_time: 0.2511  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:48:25 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 4679  total_loss: 1.446  loss_cls: 0.322  loss_box_reg: 0.5232  loss_mask: 0.3201  loss_rpn_cls: 0.08802  loss_rpn_loc: 0.199  time: 0.6053  data_time: 0.2772  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:48:37 d2.utils.events]: \u001b[0m eta: 0:32:11  iter: 4699  total_loss: 1.484  loss_cls: 0.3468  loss_box_reg: 0.521  loss_mask: 0.3028  loss_rpn_cls: 0.07027  loss_rpn_loc: 0.1973  time: 0.6053  data_time: 0.2558  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:48:48 d2.utils.events]: \u001b[0m eta: 0:32:04  iter: 4719  total_loss: 1.384  loss_cls: 0.3138  loss_box_reg: 0.4905  loss_mask: 0.3043  loss_rpn_cls: 0.0895  loss_rpn_loc: 0.1932  time: 0.6049  data_time: 0.1743  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:48:59 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 4739  total_loss: 1.352  loss_cls: 0.2926  loss_box_reg: 0.5339  loss_mask: 0.2994  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1894  time: 0.6047  data_time: 0.2277  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:49:09 d2.utils.events]: \u001b[0m eta: 0:31:48  iter: 4759  total_loss: 1.401  loss_cls: 0.3515  loss_box_reg: 0.53  loss_mask: 0.2832  loss_rpn_cls: 0.06004  loss_rpn_loc: 0.1907  time: 0.6043  data_time: 0.1744  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:49:20 d2.utils.events]: \u001b[0m eta: 0:31:37  iter: 4779  total_loss: 1.462  loss_cls: 0.3444  loss_box_reg: 0.4938  loss_mask: 0.3054  loss_rpn_cls: 0.06803  loss_rpn_loc: 0.2049  time: 0.6040  data_time: 0.1968  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:49:35 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 4799  total_loss: 1.578  loss_cls: 0.3969  loss_box_reg: 0.5399  loss_mask: 0.3002  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.1962  time: 0.6046  data_time: 0.4046  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:49:47 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 4819  total_loss: 1.401  loss_cls: 0.3411  loss_box_reg: 0.4797  loss_mask: 0.3069  loss_rpn_cls: 0.07734  loss_rpn_loc: 0.1996  time: 0.6047  data_time: 0.2725  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:50:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:50:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:50:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:50:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:50:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:50:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0746 s/iter. Eval: 0.0090 s/iter. Total: 0.0842 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0772 s/iter. Eval: 0.0146 s/iter. Total: 0.0926 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0774 s/iter. Eval: 0.0146 s/iter. Total: 0.0927 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:50:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.819212 (0.093269 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:50:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077320 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:50:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:50:12 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24877299910632042\n",
      "\u001b[32m[01/11 21:50:12 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 4839  total_loss: 1.515  loss_cls: 0.348  loss_box_reg: 0.5171  loss_mask: 0.3182  loss_rpn_cls: 0.1181  loss_rpn_loc: 0.2192  time: 0.6047  data_time: 0.2640  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:50:24 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 4859  total_loss: 1.414  loss_cls: 0.2825  loss_box_reg: 0.4928  loss_mask: 0.3011  loss_rpn_cls: 0.08947  loss_rpn_loc: 0.2218  time: 0.6048  data_time: 0.2887  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:50:37 d2.utils.events]: \u001b[0m eta: 0:31:05  iter: 4879  total_loss: 1.448  loss_cls: 0.3414  loss_box_reg: 0.4851  loss_mask: 0.2966  loss_rpn_cls: 0.08481  loss_rpn_loc: 0.2128  time: 0.6049  data_time: 0.2808  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:50:47 d2.utils.events]: \u001b[0m eta: 0:30:57  iter: 4899  total_loss: 1.449  loss_cls: 0.311  loss_box_reg: 0.5129  loss_mask: 0.3094  loss_rpn_cls: 0.05517  loss_rpn_loc: 0.2028  time: 0.6045  data_time: 0.1640  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:50:57 d2.utils.events]: \u001b[0m eta: 0:30:49  iter: 4919  total_loss: 1.395  loss_cls: 0.3329  loss_box_reg: 0.5187  loss_mask: 0.2934  loss_rpn_cls: 0.05174  loss_rpn_loc: 0.1725  time: 0.6041  data_time: 0.1545  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:51:13 d2.utils.events]: \u001b[0m eta: 0:30:40  iter: 4939  total_loss: 1.385  loss_cls: 0.3052  loss_box_reg: 0.5173  loss_mask: 0.2985  loss_rpn_cls: 0.06728  loss_rpn_loc: 0.1843  time: 0.6050  data_time: 0.4838  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:51:26 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 4959  total_loss: 1.443  loss_cls: 0.3454  loss_box_reg: 0.509  loss_mask: 0.3022  loss_rpn_cls: 0.08558  loss_rpn_loc: 0.1967  time: 0.6052  data_time: 0.3015  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:51:36 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 4979  total_loss: 1.377  loss_cls: 0.3028  loss_box_reg: 0.5101  loss_mask: 0.2856  loss_rpn_cls: 0.05789  loss_rpn_loc: 0.1871  time: 0.6047  data_time: 0.1515  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:51:48 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 4999  total_loss: 1.456  loss_cls: 0.3608  loss_box_reg: 0.5232  loss_mask: 0.3114  loss_rpn_cls: 0.08743  loss_rpn_loc: 0.2163  time: 0.6046  data_time: 0.2427  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:51:59 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 5019  total_loss: 1.417  loss_cls: 0.3186  loss_box_reg: 0.5439  loss_mask: 0.3053  loss_rpn_cls: 0.06104  loss_rpn_loc: 0.193  time: 0.6044  data_time: 0.2121  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:52:11 d2.utils.events]: \u001b[0m eta: 0:29:58  iter: 5039  total_loss: 1.511  loss_cls: 0.3744  loss_box_reg: 0.5526  loss_mask: 0.3169  loss_rpn_cls: 0.09314  loss_rpn_loc: 0.1948  time: 0.6045  data_time: 0.2585  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:52:26 d2.utils.events]: \u001b[0m eta: 0:29:51  iter: 5059  total_loss: 1.388  loss_cls: 0.3341  loss_box_reg: 0.4903  loss_mask: 0.2899  loss_rpn_cls: 0.08043  loss_rpn_loc: 0.185  time: 0.6049  data_time: 0.3672  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:52:38 d2.utils.events]: \u001b[0m eta: 0:29:44  iter: 5079  total_loss: 1.3  loss_cls: 0.2832  loss_box_reg: 0.508  loss_mask: 0.2879  loss_rpn_cls: 0.06768  loss_rpn_loc: 0.1799  time: 0.6050  data_time: 0.2852  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:52:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:52:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:52:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:52:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:52:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:52:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:52:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0751 s/iter. Eval: 0.0143 s/iter. Total: 0.0902 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0798 s/iter. Eval: 0.0167 s/iter. Total: 0.0974 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0790 s/iter. Eval: 0.0166 s/iter. Total: 0.0964 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:52:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.253673 (0.097014 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:52:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079024 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:52:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:52:53 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2564403093006825\n",
      "\u001b[32m[01/11 21:53:04 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 5099  total_loss: 1.341  loss_cls: 0.3098  loss_box_reg: 0.4824  loss_mask: 0.287  loss_rpn_cls: 0.08002  loss_rpn_loc: 0.1944  time: 0.6051  data_time: 0.2809  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:53:16 d2.utils.events]: \u001b[0m eta: 0:29:32  iter: 5119  total_loss: 1.338  loss_cls: 0.3051  loss_box_reg: 0.5138  loss_mask: 0.2976  loss_rpn_cls: 0.04896  loss_rpn_loc: 0.1823  time: 0.6051  data_time: 0.2694  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:53:27 d2.utils.events]: \u001b[0m eta: 0:29:22  iter: 5139  total_loss: 1.314  loss_cls: 0.2885  loss_box_reg: 0.4849  loss_mask: 0.2703  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.1869  time: 0.6050  data_time: 0.2515  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:53:38 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 5159  total_loss: 1.462  loss_cls: 0.3243  loss_box_reg: 0.5172  loss_mask: 0.3018  loss_rpn_cls: 0.07942  loss_rpn_loc: 0.1992  time: 0.6048  data_time: 0.2123  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:53:50 d2.utils.events]: \u001b[0m eta: 0:29:13  iter: 5179  total_loss: 1.512  loss_cls: 0.3641  loss_box_reg: 0.5544  loss_mask: 0.3112  loss_rpn_cls: 0.08792  loss_rpn_loc: 0.189  time: 0.6047  data_time: 0.2180  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:54:06 d2.utils.events]: \u001b[0m eta: 0:29:08  iter: 5199  total_loss: 1.404  loss_cls: 0.3416  loss_box_reg: 0.4849  loss_mask: 0.2899  loss_rpn_cls: 0.08636  loss_rpn_loc: 0.1931  time: 0.6055  data_time: 0.4543  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:54:20 d2.utils.events]: \u001b[0m eta: 0:29:02  iter: 5219  total_loss: 1.4  loss_cls: 0.326  loss_box_reg: 0.5021  loss_mask: 0.2974  loss_rpn_cls: 0.06199  loss_rpn_loc: 0.1805  time: 0.6059  data_time: 0.3521  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:54:31 d2.utils.events]: \u001b[0m eta: 0:28:54  iter: 5239  total_loss: 1.445  loss_cls: 0.279  loss_box_reg: 0.5469  loss_mask: 0.3163  loss_rpn_cls: 0.05883  loss_rpn_loc: 0.202  time: 0.6056  data_time: 0.2167  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:54:40 d2.utils.events]: \u001b[0m eta: 0:28:46  iter: 5259  total_loss: 1.247  loss_cls: 0.2974  loss_box_reg: 0.4896  loss_mask: 0.3004  loss_rpn_cls: 0.08154  loss_rpn_loc: 0.1775  time: 0.6051  data_time: 0.1417  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:54:55 d2.utils.events]: \u001b[0m eta: 0:28:41  iter: 5279  total_loss: 1.406  loss_cls: 0.3423  loss_box_reg: 0.4957  loss_mask: 0.2983  loss_rpn_cls: 0.0884  loss_rpn_loc: 0.2057  time: 0.6055  data_time: 0.3589  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:55:08 d2.utils.events]: \u001b[0m eta: 0:28:38  iter: 5299  total_loss: 1.491  loss_cls: 0.3415  loss_box_reg: 0.5138  loss_mask: 0.2965  loss_rpn_cls: 0.08673  loss_rpn_loc: 0.2128  time: 0.6058  data_time: 0.3400  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:55:23 d2.utils.events]: \u001b[0m eta: 0:28:31  iter: 5319  total_loss: 1.471  loss_cls: 0.3343  loss_box_reg: 0.4819  loss_mask: 0.3051  loss_rpn_cls: 0.08567  loss_rpn_loc: 0.2147  time: 0.6063  data_time: 0.3713  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:55:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:55:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:55:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:55:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:55:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:55:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0772 s/iter. Eval: 0.0131 s/iter. Total: 0.0910 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 21:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.0794 s/iter. Eval: 0.0173 s/iter. Total: 0.0974 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0008 s/iter. Inference: 0.0809 s/iter. Eval: 0.0182 s/iter. Total: 0.0999 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:55:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.610873 (0.100094 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:55:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.080629 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:55:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:55:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24389359501494254\n",
      "\u001b[32m[01/11 21:55:44 d2.utils.events]: \u001b[0m eta: 0:28:18  iter: 5339  total_loss: 1.352  loss_cls: 0.2926  loss_box_reg: 0.497  loss_mask: 0.2914  loss_rpn_cls: 0.06195  loss_rpn_loc: 0.1779  time: 0.6056  data_time: 0.0807  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:55:59 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 5359  total_loss: 1.408  loss_cls: 0.3631  loss_box_reg: 0.5091  loss_mask: 0.2977  loss_rpn_cls: 0.08211  loss_rpn_loc: 0.1844  time: 0.6060  data_time: 0.3762  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:56:12 d2.utils.events]: \u001b[0m eta: 0:27:59  iter: 5379  total_loss: 1.38  loss_cls: 0.3306  loss_box_reg: 0.5341  loss_mask: 0.2934  loss_rpn_cls: 0.06792  loss_rpn_loc: 0.1764  time: 0.6063  data_time: 0.3425  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:56:24 d2.utils.events]: \u001b[0m eta: 0:27:49  iter: 5399  total_loss: 1.351  loss_cls: 0.2845  loss_box_reg: 0.5182  loss_mask: 0.311  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.1915  time: 0.6062  data_time: 0.2575  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:56:37 d2.utils.events]: \u001b[0m eta: 0:27:41  iter: 5419  total_loss: 1.413  loss_cls: 0.339  loss_box_reg: 0.5213  loss_mask: 0.306  loss_rpn_cls: 0.07155  loss_rpn_loc: 0.2006  time: 0.6063  data_time: 0.2912  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:56:48 d2.utils.events]: \u001b[0m eta: 0:27:31  iter: 5439  total_loss: 1.463  loss_cls: 0.3131  loss_box_reg: 0.5462  loss_mask: 0.3162  loss_rpn_cls: 0.08771  loss_rpn_loc: 0.2035  time: 0.6062  data_time: 0.2306  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:56:57 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 5459  total_loss: 1.362  loss_cls: 0.3019  loss_box_reg: 0.479  loss_mask: 0.2774  loss_rpn_cls: 0.05745  loss_rpn_loc: 0.1617  time: 0.6056  data_time: 0.1146  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:57:11 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 5479  total_loss: 1.498  loss_cls: 0.3718  loss_box_reg: 0.5362  loss_mask: 0.3062  loss_rpn_cls: 0.07726  loss_rpn_loc: 0.2125  time: 0.6059  data_time: 0.3189  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:57:26 d2.utils.events]: \u001b[0m eta: 0:27:13  iter: 5499  total_loss: 1.383  loss_cls: 0.3288  loss_box_reg: 0.5024  loss_mask: 0.2928  loss_rpn_cls: 0.08295  loss_rpn_loc: 0.2265  time: 0.6065  data_time: 0.3786  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:57:37 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 5519  total_loss: 1.509  loss_cls: 0.3394  loss_box_reg: 0.5131  loss_mask: 0.3105  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.2229  time: 0.6062  data_time: 0.2191  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:57:48 d2.utils.events]: \u001b[0m eta: 0:26:58  iter: 5539  total_loss: 1.354  loss_cls: 0.3061  loss_box_reg: 0.4965  loss_mask: 0.2967  loss_rpn_cls: 0.04483  loss_rpn_loc: 0.1905  time: 0.6060  data_time: 0.2138  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:57:58 d2.utils.events]: \u001b[0m eta: 0:26:51  iter: 5559  total_loss: 1.486  loss_cls: 0.3468  loss_box_reg: 0.528  loss_mask: 0.3133  loss_rpn_cls: 0.08715  loss_rpn_loc: 0.2015  time: 0.6056  data_time: 0.1540  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:58:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:58:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 21:58:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 21:58:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 21:58:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 21:58:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 21:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0758 s/iter. Eval: 0.0107 s/iter. Total: 0.0872 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 21:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0790 s/iter. Eval: 0.0172 s/iter. Total: 0.0971 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 21:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0786 s/iter. Eval: 0.0168 s/iter. Total: 0.0962 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 21:58:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.231206 (0.096821 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:58:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078464 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 21:58:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 21:58:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25131611603803583\n",
      "\u001b[32m[01/11 21:58:22 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 5579  total_loss: 1.409  loss_cls: 0.3316  loss_box_reg: 0.526  loss_mask: 0.3066  loss_rpn_cls: 0.08796  loss_rpn_loc: 0.1916  time: 0.6055  data_time: 0.2260  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:58:36 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 5599  total_loss: 1.411  loss_cls: 0.2973  loss_box_reg: 0.4765  loss_mask: 0.2996  loss_rpn_cls: 0.08768  loss_rpn_loc: 0.1925  time: 0.6058  data_time: 0.3625  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:58:50 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 5619  total_loss: 1.447  loss_cls: 0.3176  loss_box_reg: 0.5  loss_mask: 0.302  loss_rpn_cls: 0.0813  loss_rpn_loc: 0.2163  time: 0.6062  data_time: 0.3528  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:59:01 d2.utils.events]: \u001b[0m eta: 0:26:23  iter: 5639  total_loss: 1.433  loss_cls: 0.3224  loss_box_reg: 0.5325  loss_mask: 0.3142  loss_rpn_cls: 0.08594  loss_rpn_loc: 0.1992  time: 0.6060  data_time: 0.1917  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:59:14 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 5659  total_loss: 1.481  loss_cls: 0.3475  loss_box_reg: 0.5166  loss_mask: 0.2908  loss_rpn_cls: 0.0893  loss_rpn_loc: 0.2055  time: 0.6062  data_time: 0.3061  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:59:22 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 5679  total_loss: 1.354  loss_cls: 0.3217  loss_box_reg: 0.5186  loss_mask: 0.2795  loss_rpn_cls: 0.04446  loss_rpn_loc: 0.1639  time: 0.6054  data_time: 0.0581  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:59:36 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 5699  total_loss: 1.481  loss_cls: 0.3394  loss_box_reg: 0.5322  loss_mask: 0.3056  loss_rpn_cls: 0.07329  loss_rpn_loc: 0.209  time: 0.6058  data_time: 0.3740  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 21:59:51 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 5719  total_loss: 1.424  loss_cls: 0.3528  loss_box_reg: 0.4849  loss_mask: 0.3009  loss_rpn_cls: 0.07516  loss_rpn_loc: 0.2044  time: 0.6062  data_time: 0.3813  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:00:04 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 5739  total_loss: 1.332  loss_cls: 0.3005  loss_box_reg: 0.4839  loss_mask: 0.299  loss_rpn_cls: 0.0656  loss_rpn_loc: 0.1826  time: 0.6064  data_time: 0.3383  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:00:15 d2.utils.events]: \u001b[0m eta: 0:25:39  iter: 5759  total_loss: 1.305  loss_cls: 0.3286  loss_box_reg: 0.4989  loss_mask: 0.3055  loss_rpn_cls: 0.05911  loss_rpn_loc: 0.1932  time: 0.6062  data_time: 0.1954  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:00:25 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 5779  total_loss: 1.35  loss_cls: 0.3176  loss_box_reg: 0.5082  loss_mask: 0.295  loss_rpn_cls: 0.0887  loss_rpn_loc: 0.1857  time: 0.6059  data_time: 0.1627  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:00:34 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 5799  total_loss: 1.364  loss_cls: 0.3167  loss_box_reg: 0.495  loss_mask: 0.2861  loss_rpn_cls: 0.06592  loss_rpn_loc: 0.1814  time: 0.6054  data_time: 0.1316  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:00:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:00:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:00:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:00:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:00:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:00:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0750 s/iter. Eval: 0.0113 s/iter. Total: 0.0870 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:00:48 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0160 s/iter. Total: 0.0937 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0775 s/iter. Eval: 0.0161 s/iter. Total: 0.0944 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:00:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.041390 (0.095184 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:00:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077451 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:00:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:00:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24027219144877662\n",
      "\u001b[32m[01/11 22:00:59 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 5819  total_loss: 1.394  loss_cls: 0.3109  loss_box_reg: 0.4819  loss_mask: 0.3167  loss_rpn_cls: 0.07374  loss_rpn_loc: 0.1972  time: 0.6053  data_time: 0.2551  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:01:10 d2.utils.events]: \u001b[0m eta: 0:25:08  iter: 5839  total_loss: 1.386  loss_cls: 0.3085  loss_box_reg: 0.5129  loss_mask: 0.2862  loss_rpn_cls: 0.07675  loss_rpn_loc: 0.187  time: 0.6052  data_time: 0.2426  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:01:24 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 5859  total_loss: 1.508  loss_cls: 0.364  loss_box_reg: 0.4977  loss_mask: 0.2949  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.2088  time: 0.6056  data_time: 0.3322  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:01:35 d2.utils.events]: \u001b[0m eta: 0:24:55  iter: 5879  total_loss: 1.418  loss_cls: 0.3121  loss_box_reg: 0.4719  loss_mask: 0.2888  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.2125  time: 0.6053  data_time: 0.1841  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:01:48 d2.utils.events]: \u001b[0m eta: 0:24:47  iter: 5899  total_loss: 1.365  loss_cls: 0.2971  loss_box_reg: 0.4989  loss_mask: 0.2964  loss_rpn_cls: 0.05582  loss_rpn_loc: 0.179  time: 0.6055  data_time: 0.3272  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:01:59 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 5919  total_loss: 1.327  loss_cls: 0.2927  loss_box_reg: 0.499  loss_mask: 0.289  loss_rpn_cls: 0.03902  loss_rpn_loc: 0.1697  time: 0.6053  data_time: 0.2012  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:02:10 d2.utils.events]: \u001b[0m eta: 0:24:32  iter: 5939  total_loss: 1.372  loss_cls: 0.3195  loss_box_reg: 0.483  loss_mask: 0.2877  loss_rpn_cls: 0.04997  loss_rpn_loc: 0.1901  time: 0.6052  data_time: 0.2375  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:02:21 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 5959  total_loss: 1.368  loss_cls: 0.3201  loss_box_reg: 0.5171  loss_mask: 0.3043  loss_rpn_cls: 0.06427  loss_rpn_loc: 0.1843  time: 0.6048  data_time: 0.1780  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:02:33 d2.utils.events]: \u001b[0m eta: 0:24:17  iter: 5979  total_loss: 1.27  loss_cls: 0.2554  loss_box_reg: 0.472  loss_mask: 0.2856  loss_rpn_cls: 0.05076  loss_rpn_loc: 0.1812  time: 0.6048  data_time: 0.2518  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:02:49 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 5999  total_loss: 1.422  loss_cls: 0.3277  loss_box_reg: 0.4983  loss_mask: 0.3063  loss_rpn_cls: 0.0902  loss_rpn_loc: 0.202  time: 0.6055  data_time: 0.4462  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:03:00 d2.utils.events]: \u001b[0m eta: 0:24:03  iter: 6019  total_loss: 1.421  loss_cls: 0.3258  loss_box_reg: 0.4989  loss_mask: 0.3024  loss_rpn_cls: 0.07875  loss_rpn_loc: 0.1743  time: 0.6054  data_time: 0.2392  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:03:14 d2.utils.events]: \u001b[0m eta: 0:23:56  iter: 6039  total_loss: 1.472  loss_cls: 0.3577  loss_box_reg: 0.522  loss_mask: 0.3118  loss_rpn_cls: 0.08791  loss_rpn_loc: 0.1961  time: 0.6057  data_time: 0.3411  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:03:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:03:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:03:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:03:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:03:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:03:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0750 s/iter. Eval: 0.0105 s/iter. Total: 0.0861 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0777 s/iter. Eval: 0.0161 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:03:34 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0007 s/iter. Inference: 0.0782 s/iter. Eval: 0.0162 s/iter. Total: 0.0952 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:03:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.109737 (0.095774 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:03:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078132 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:03:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:03:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24789562946784974\n",
      "\u001b[32m[01/11 22:03:40 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 6059  total_loss: 1.448  loss_cls: 0.3301  loss_box_reg: 0.4886  loss_mask: 0.2944  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.1945  time: 0.6059  data_time: 0.3042  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:03:50 d2.utils.events]: \u001b[0m eta: 0:23:41  iter: 6079  total_loss: 1.48  loss_cls: 0.3359  loss_box_reg: 0.5169  loss_mask: 0.3045  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.1928  time: 0.6056  data_time: 0.1668  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:04:00 d2.utils.events]: \u001b[0m eta: 0:23:32  iter: 6099  total_loss: 1.492  loss_cls: 0.3455  loss_box_reg: 0.5321  loss_mask: 0.3024  loss_rpn_cls: 0.08707  loss_rpn_loc: 0.2006  time: 0.6052  data_time: 0.1780  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:04:12 d2.utils.events]: \u001b[0m eta: 0:23:27  iter: 6119  total_loss: 1.362  loss_cls: 0.2885  loss_box_reg: 0.5001  loss_mask: 0.2977  loss_rpn_cls: 0.08449  loss_rpn_loc: 0.2093  time: 0.6051  data_time: 0.2188  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:04:25 d2.utils.events]: \u001b[0m eta: 0:23:20  iter: 6139  total_loss: 1.421  loss_cls: 0.3184  loss_box_reg: 0.5007  loss_mask: 0.2885  loss_rpn_cls: 0.09093  loss_rpn_loc: 0.205  time: 0.6053  data_time: 0.3141  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:04:37 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 6159  total_loss: 1.516  loss_cls: 0.3428  loss_box_reg: 0.5189  loss_mask: 0.3218  loss_rpn_cls: 0.07014  loss_rpn_loc: 0.211  time: 0.6053  data_time: 0.2842  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:04:49 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 6179  total_loss: 1.401  loss_cls: 0.3293  loss_box_reg: 0.5188  loss_mask: 0.2913  loss_rpn_cls: 0.083  loss_rpn_loc: 0.182  time: 0.6053  data_time: 0.2516  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:05:01 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 6199  total_loss: 1.308  loss_cls: 0.3075  loss_box_reg: 0.5017  loss_mask: 0.2804  loss_rpn_cls: 0.06453  loss_rpn_loc: 0.1735  time: 0.6052  data_time: 0.2321  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:05:12 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 6219  total_loss: 1.488  loss_cls: 0.3089  loss_box_reg: 0.5236  loss_mask: 0.3129  loss_rpn_cls: 0.08541  loss_rpn_loc: 0.1988  time: 0.6051  data_time: 0.2440  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:05:29 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 6239  total_loss: 1.402  loss_cls: 0.3035  loss_box_reg: 0.4859  loss_mask: 0.3141  loss_rpn_cls: 0.08121  loss_rpn_loc: 0.2196  time: 0.6058  data_time: 0.4592  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:05:40 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 6259  total_loss: 1.35  loss_cls: 0.3025  loss_box_reg: 0.4934  loss_mask: 0.2817  loss_rpn_cls: 0.0706  loss_rpn_loc: 0.1929  time: 0.6057  data_time: 0.2297  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:05:52 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 6279  total_loss: 1.338  loss_cls: 0.2937  loss_box_reg: 0.5132  loss_mask: 0.3048  loss_rpn_cls: 0.0735  loss_rpn_loc: 0.191  time: 0.6057  data_time: 0.2647  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:06:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:06:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:06:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:06:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:06:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:06:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0756 s/iter. Eval: 0.0113 s/iter. Total: 0.0875 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0162 s/iter. Total: 0.0950 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0785 s/iter. Eval: 0.0164 s/iter. Total: 0.0958 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.197884 (0.096533 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078498 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:06:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:06:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25303066603955\n",
      "\u001b[32m[01/11 22:06:19 d2.utils.events]: \u001b[0m eta: 0:22:19  iter: 6299  total_loss: 1.451  loss_cls: 0.3742  loss_box_reg: 0.4736  loss_mask: 0.292  loss_rpn_cls: 0.09332  loss_rpn_loc: 0.2056  time: 0.6061  data_time: 0.3741  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:06:36 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 6319  total_loss: 1.468  loss_cls: 0.3408  loss_box_reg: 0.4949  loss_mask: 0.2965  loss_rpn_cls: 0.0846  loss_rpn_loc: 0.213  time: 0.6068  data_time: 0.4691  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:06:48 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 6339  total_loss: 1.398  loss_cls: 0.3229  loss_box_reg: 0.5111  loss_mask: 0.2963  loss_rpn_cls: 0.08785  loss_rpn_loc: 0.1819  time: 0.6068  data_time: 0.2853  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:06:59 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 6359  total_loss: 1.301  loss_cls: 0.29  loss_box_reg: 0.4732  loss_mask: 0.2881  loss_rpn_cls: 0.06728  loss_rpn_loc: 0.1729  time: 0.6066  data_time: 0.2081  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:07:10 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 6379  total_loss: 1.346  loss_cls: 0.2781  loss_box_reg: 0.5378  loss_mask: 0.2936  loss_rpn_cls: 0.07102  loss_rpn_loc: 0.1839  time: 0.6064  data_time: 0.1928  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:07:21 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 6399  total_loss: 1.233  loss_cls: 0.2661  loss_box_reg: 0.4749  loss_mask: 0.2922  loss_rpn_cls: 0.04781  loss_rpn_loc: 0.1804  time: 0.6063  data_time: 0.2234  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:07:35 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 6419  total_loss: 1.393  loss_cls: 0.3157  loss_box_reg: 0.4754  loss_mask: 0.2994  loss_rpn_cls: 0.08085  loss_rpn_loc: 0.1994  time: 0.6065  data_time: 0.3249  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:07:45 d2.utils.events]: \u001b[0m eta: 0:21:32  iter: 6439  total_loss: 1.39  loss_cls: 0.3128  loss_box_reg: 0.5019  loss_mask: 0.2997  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.1802  time: 0.6062  data_time: 0.1907  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:07:58 d2.utils.events]: \u001b[0m eta: 0:21:31  iter: 6459  total_loss: 1.466  loss_cls: 0.3573  loss_box_reg: 0.5169  loss_mask: 0.2954  loss_rpn_cls: 0.08046  loss_rpn_loc: 0.1992  time: 0.6064  data_time: 0.3157  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:08:09 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 6479  total_loss: 1.324  loss_cls: 0.2685  loss_box_reg: 0.4767  loss_mask: 0.2917  loss_rpn_cls: 0.03733  loss_rpn_loc: 0.1902  time: 0.6062  data_time: 0.2061  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:08:19 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 6499  total_loss: 1.317  loss_cls: 0.294  loss_box_reg: 0.5078  loss_mask: 0.2812  loss_rpn_cls: 0.06313  loss_rpn_loc: 0.1873  time: 0.6058  data_time: 0.1439  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:08:33 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 6519  total_loss: 1.399  loss_cls: 0.3317  loss_box_reg: 0.4919  loss_mask: 0.299  loss_rpn_cls: 0.08559  loss_rpn_loc: 0.2062  time: 0.6061  data_time: 0.3410  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:08:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:08:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:08:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:08:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:08:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:08:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0750 s/iter. Eval: 0.0145 s/iter. Total: 0.0903 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0007 s/iter. Inference: 0.0790 s/iter. Eval: 0.0180 s/iter. Total: 0.0978 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0007 s/iter. Inference: 0.0790 s/iter. Eval: 0.0187 s/iter. Total: 0.0985 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:09:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.475364 (0.098926 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:09:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078891 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:09:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:09:00 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24427446029104943\n",
      "\u001b[32m[01/11 22:09:04 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 6539  total_loss: 1.419  loss_cls: 0.3433  loss_box_reg: 0.5005  loss_mask: 0.3145  loss_rpn_cls: 0.08948  loss_rpn_loc: 0.1943  time: 0.6070  data_time: 0.5262  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:09:18 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 6559  total_loss: 1.365  loss_cls: 0.3345  loss_box_reg: 0.494  loss_mask: 0.2931  loss_rpn_cls: 0.07235  loss_rpn_loc: 0.1861  time: 0.6074  data_time: 0.3841  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:09:30 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 6579  total_loss: 1.371  loss_cls: 0.3275  loss_box_reg: 0.502  loss_mask: 0.2919  loss_rpn_cls: 0.08426  loss_rpn_loc: 0.1945  time: 0.6073  data_time: 0.2433  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:09:41 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 6599  total_loss: 1.33  loss_cls: 0.3101  loss_box_reg: 0.4822  loss_mask: 0.2891  loss_rpn_cls: 0.06501  loss_rpn_loc: 0.1825  time: 0.6072  data_time: 0.2165  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:09:55 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 6619  total_loss: 1.356  loss_cls: 0.3247  loss_box_reg: 0.4908  loss_mask: 0.2862  loss_rpn_cls: 0.09095  loss_rpn_loc: 0.2157  time: 0.6074  data_time: 0.3157  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:10:08 d2.utils.events]: \u001b[0m eta: 0:20:22  iter: 6639  total_loss: 1.376  loss_cls: 0.3103  loss_box_reg: 0.5041  loss_mask: 0.3078  loss_rpn_cls: 0.07305  loss_rpn_loc: 0.2044  time: 0.6075  data_time: 0.2922  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:10:21 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 6659  total_loss: 1.323  loss_cls: 0.2821  loss_box_reg: 0.4837  loss_mask: 0.293  loss_rpn_cls: 0.03701  loss_rpn_loc: 0.1727  time: 0.6077  data_time: 0.3346  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:10:32 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 6679  total_loss: 1.403  loss_cls: 0.3103  loss_box_reg: 0.5086  loss_mask: 0.2948  loss_rpn_cls: 0.08764  loss_rpn_loc: 0.2063  time: 0.6074  data_time: 0.1924  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:10:42 d2.utils.events]: \u001b[0m eta: 0:19:58  iter: 6699  total_loss: 1.505  loss_cls: 0.3359  loss_box_reg: 0.5073  loss_mask: 0.3109  loss_rpn_cls: 0.07961  loss_rpn_loc: 0.2115  time: 0.6072  data_time: 0.1984  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:10:54 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 6719  total_loss: 1.275  loss_cls: 0.2816  loss_box_reg: 0.4574  loss_mask: 0.2896  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.1747  time: 0.6072  data_time: 0.2620  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:11:06 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 6739  total_loss: 1.49  loss_cls: 0.3522  loss_box_reg: 0.5117  loss_mask: 0.3092  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.2012  time: 0.6070  data_time: 0.2165  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:11:15 d2.utils.events]: \u001b[0m eta: 0:19:37  iter: 6759  total_loss: 1.365  loss_cls: 0.3032  loss_box_reg: 0.5035  loss_mask: 0.3002  loss_rpn_cls: 0.05023  loss_rpn_loc: 0.1788  time: 0.6067  data_time: 0.1510  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:11:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:11:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:11:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:11:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:11:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:11:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0753 s/iter. Eval: 0.0115 s/iter. Total: 0.0873 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:11:32 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0785 s/iter. Eval: 0.0177 s/iter. Total: 0.0970 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:11:37 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0794 s/iter. Eval: 0.0180 s/iter. Total: 0.0982 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:11:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.455874 (0.098758 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:11:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079382 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:11:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:11:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25304292083782415\n",
      "\u001b[32m[01/11 22:11:41 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 6779  total_loss: 1.516  loss_cls: 0.3517  loss_box_reg: 0.5302  loss_mask: 0.3006  loss_rpn_cls: 0.0864  loss_rpn_loc: 0.2156  time: 0.6068  data_time: 0.2739  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:11:56 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 6799  total_loss: 1.393  loss_cls: 0.3113  loss_box_reg: 0.5002  loss_mask: 0.3006  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.1879  time: 0.6072  data_time: 0.4034  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:12:05 d2.utils.events]: \u001b[0m eta: 0:19:19  iter: 6819  total_loss: 1.352  loss_cls: 0.3308  loss_box_reg: 0.4857  loss_mask: 0.2739  loss_rpn_cls: 0.06697  loss_rpn_loc: 0.171  time: 0.6068  data_time: 0.1565  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:12:18 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 6839  total_loss: 1.342  loss_cls: 0.3341  loss_box_reg: 0.4933  loss_mask: 0.269  loss_rpn_cls: 0.06924  loss_rpn_loc: 0.1771  time: 0.6069  data_time: 0.3069  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:12:30 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 6859  total_loss: 1.485  loss_cls: 0.3514  loss_box_reg: 0.5096  loss_mask: 0.3021  loss_rpn_cls: 0.09909  loss_rpn_loc: 0.2069  time: 0.6068  data_time: 0.2378  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:12:42 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 6879  total_loss: 1.358  loss_cls: 0.3293  loss_box_reg: 0.4735  loss_mask: 0.3114  loss_rpn_cls: 0.07276  loss_rpn_loc: 0.1833  time: 0.6068  data_time: 0.2643  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:12:56 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 6899  total_loss: 1.399  loss_cls: 0.3132  loss_box_reg: 0.5015  loss_mask: 0.2922  loss_rpn_cls: 0.06179  loss_rpn_loc: 0.2128  time: 0.6071  data_time: 0.3473  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:13:07 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 6919  total_loss: 1.364  loss_cls: 0.3013  loss_box_reg: 0.4838  loss_mask: 0.2736  loss_rpn_cls: 0.09938  loss_rpn_loc: 0.2112  time: 0.6070  data_time: 0.2275  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:13:19 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 6939  total_loss: 1.394  loss_cls: 0.2996  loss_box_reg: 0.4885  loss_mask: 0.3086  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.1957  time: 0.6068  data_time: 0.2286  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:13:30 d2.utils.events]: \u001b[0m eta: 0:18:32  iter: 6959  total_loss: 1.517  loss_cls: 0.3798  loss_box_reg: 0.4968  loss_mask: 0.3066  loss_rpn_cls: 0.08847  loss_rpn_loc: 0.2082  time: 0.6067  data_time: 0.2243  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:13:39 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 6979  total_loss: 1.26  loss_cls: 0.2951  loss_box_reg: 0.5048  loss_mask: 0.2736  loss_rpn_cls: 0.05965  loss_rpn_loc: 0.1651  time: 0.6062  data_time: 0.1320  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:13:48 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 6999  total_loss: 1.415  loss_cls: 0.2997  loss_box_reg: 0.4868  loss_mask: 0.2929  loss_rpn_cls: 0.07542  loss_rpn_loc: 0.1809  time: 0.6059  data_time: 0.1463  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:14:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:14:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:14:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:14:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:14:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:14:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0118 s/iter. Total: 0.0863 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0795 s/iter. Eval: 0.0165 s/iter. Total: 0.0968 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0787 s/iter. Eval: 0.0167 s/iter. Total: 0.0963 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:14:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.258874 (0.097059 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:14:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078764 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:14:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:14:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2565444932096875\n",
      "\u001b[32m[01/11 22:14:17 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 7019  total_loss: 1.331  loss_cls: 0.279  loss_box_reg: 0.4435  loss_mask: 0.292  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.1944  time: 0.6064  data_time: 0.4571  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:14:31 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 7039  total_loss: 1.367  loss_cls: 0.3209  loss_box_reg: 0.4713  loss_mask: 0.3017  loss_rpn_cls: 0.09552  loss_rpn_loc: 0.1938  time: 0.6067  data_time: 0.3527  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:14:43 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 7059  total_loss: 1.253  loss_cls: 0.2804  loss_box_reg: 0.4571  loss_mask: 0.2729  loss_rpn_cls: 0.06007  loss_rpn_loc: 0.1774  time: 0.6066  data_time: 0.2471  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:14:56 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 7079  total_loss: 1.416  loss_cls: 0.3664  loss_box_reg: 0.5004  loss_mask: 0.2899  loss_rpn_cls: 0.08315  loss_rpn_loc: 0.1973  time: 0.6068  data_time: 0.3047  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:15:09 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 7099  total_loss: 1.326  loss_cls: 0.2873  loss_box_reg: 0.4655  loss_mask: 0.293  loss_rpn_cls: 0.05917  loss_rpn_loc: 0.1861  time: 0.6069  data_time: 0.3089  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:15:19 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 7119  total_loss: 1.346  loss_cls: 0.3011  loss_box_reg: 0.5209  loss_mask: 0.294  loss_rpn_cls: 0.04186  loss_rpn_loc: 0.1858  time: 0.6066  data_time: 0.1938  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:15:31 d2.utils.events]: \u001b[0m eta: 0:17:21  iter: 7139  total_loss: 1.369  loss_cls: 0.3081  loss_box_reg: 0.5199  loss_mask: 0.3054  loss_rpn_cls: 0.05243  loss_rpn_loc: 0.183  time: 0.6066  data_time: 0.2419  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:15:44 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 7159  total_loss: 1.471  loss_cls: 0.3426  loss_box_reg: 0.5335  loss_mask: 0.2972  loss_rpn_cls: 0.07949  loss_rpn_loc: 0.1947  time: 0.6068  data_time: 0.3308  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:15:58 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 7179  total_loss: 1.379  loss_cls: 0.3167  loss_box_reg: 0.502  loss_mask: 0.3103  loss_rpn_cls: 0.05317  loss_rpn_loc: 0.1794  time: 0.6070  data_time: 0.3388  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:16:08 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 7199  total_loss: 1.206  loss_cls: 0.2191  loss_box_reg: 0.455  loss_mask: 0.2841  loss_rpn_cls: 0.03927  loss_rpn_loc: 0.1705  time: 0.6067  data_time: 0.1723  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:16:20 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 7219  total_loss: 1.361  loss_cls: 0.2726  loss_box_reg: 0.502  loss_mask: 0.3068  loss_rpn_cls: 0.06428  loss_rpn_loc: 0.1771  time: 0.6067  data_time: 0.2455  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:16:31 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 7239  total_loss: 1.357  loss_cls: 0.2896  loss_box_reg: 0.5072  loss_mask: 0.2941  loss_rpn_cls: 0.06686  loss_rpn_loc: 0.1826  time: 0.6065  data_time: 0.2393  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:16:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:16:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:16:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:16:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:16:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:16:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:16:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0762 s/iter. Eval: 0.0120 s/iter. Total: 0.0888 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:16:51 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0789 s/iter. Eval: 0.0169 s/iter. Total: 0.0966 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0782 s/iter. Eval: 0.0170 s/iter. Total: 0.0960 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:16:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.199638 (0.096549 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:16:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078254 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:16:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:16:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24853547607307017\n",
      "\u001b[32m[01/11 22:16:56 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 7259  total_loss: 1.539  loss_cls: 0.3776  loss_box_reg: 0.527  loss_mask: 0.3177  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.1983  time: 0.6066  data_time: 0.2908  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:17:12 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 7279  total_loss: 1.33  loss_cls: 0.264  loss_box_reg: 0.4598  loss_mask: 0.3119  loss_rpn_cls: 0.07618  loss_rpn_loc: 0.1941  time: 0.6072  data_time: 0.4448  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:17:23 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 7299  total_loss: 1.366  loss_cls: 0.281  loss_box_reg: 0.4663  loss_mask: 0.298  loss_rpn_cls: 0.08572  loss_rpn_loc: 0.1908  time: 0.6069  data_time: 0.1758  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:17:32 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 7319  total_loss: 1.266  loss_cls: 0.2686  loss_box_reg: 0.4719  loss_mask: 0.2915  loss_rpn_cls: 0.0481  loss_rpn_loc: 0.1783  time: 0.6065  data_time: 0.1481  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:17:43 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 7339  total_loss: 1.238  loss_cls: 0.297  loss_box_reg: 0.4706  loss_mask: 0.2781  loss_rpn_cls: 0.05593  loss_rpn_loc: 0.185  time: 0.6063  data_time: 0.1767  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:17:54 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 7359  total_loss: 1.44  loss_cls: 0.29  loss_box_reg: 0.4903  loss_mask: 0.3019  loss_rpn_cls: 0.07385  loss_rpn_loc: 0.1862  time: 0.6063  data_time: 0.2576  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:18:05 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 7379  total_loss: 1.31  loss_cls: 0.2678  loss_box_reg: 0.5112  loss_mask: 0.3031  loss_rpn_cls: 0.038  loss_rpn_loc: 0.2019  time: 0.6060  data_time: 0.1692  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:18:20 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 7399  total_loss: 1.444  loss_cls: 0.3639  loss_box_reg: 0.4819  loss_mask: 0.2969  loss_rpn_cls: 0.0985  loss_rpn_loc: 0.1954  time: 0.6064  data_time: 0.3879  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:18:33 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 7419  total_loss: 1.332  loss_cls: 0.2954  loss_box_reg: 0.4791  loss_mask: 0.2926  loss_rpn_cls: 0.0508  loss_rpn_loc: 0.1789  time: 0.6066  data_time: 0.3410  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:18:44 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 7439  total_loss: 1.273  loss_cls: 0.2769  loss_box_reg: 0.4782  loss_mask: 0.2787  loss_rpn_cls: 0.04861  loss_rpn_loc: 0.1625  time: 0.6064  data_time: 0.2266  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:18:58 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 7459  total_loss: 1.375  loss_cls: 0.3304  loss_box_reg: 0.5111  loss_mask: 0.2881  loss_rpn_cls: 0.06405  loss_rpn_loc: 0.2017  time: 0.6066  data_time: 0.3096  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:19:10 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 7479  total_loss: 1.369  loss_cls: 0.3196  loss_box_reg: 0.4968  loss_mask: 0.2884  loss_rpn_cls: 0.08414  loss_rpn_loc: 0.1926  time: 0.6066  data_time: 0.2520  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:19:20 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 7499  total_loss: 1.415  loss_cls: 0.301  loss_box_reg: 0.5093  loss_mask: 0.3009  loss_rpn_cls: 0.07186  loss_rpn_loc: 0.2035  time: 0.6063  data_time: 0.1585  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:19:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:19:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:19:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:19:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:19:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:19:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0817 s/iter. Eval: 0.0128 s/iter. Total: 0.0951 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 22:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.0802 s/iter. Eval: 0.0172 s/iter. Total: 0.0982 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0792 s/iter. Eval: 0.0179 s/iter. Total: 0.0979 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:19:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.405242 (0.098321 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:19:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079094 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:19:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:19:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2550410784775309\n",
      "\u001b[32m[01/11 22:19:48 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 7519  total_loss: 1.421  loss_cls: 0.3379  loss_box_reg: 0.4864  loss_mask: 0.3011  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2135  time: 0.6067  data_time: 0.3897  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:20:02 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 7539  total_loss: 1.386  loss_cls: 0.3059  loss_box_reg: 0.4751  loss_mask: 0.2772  loss_rpn_cls: 0.08212  loss_rpn_loc: 0.1966  time: 0.6069  data_time: 0.3484  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:20:12 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 7559  total_loss: 1.322  loss_cls: 0.2898  loss_box_reg: 0.524  loss_mask: 0.3096  loss_rpn_cls: 0.04885  loss_rpn_loc: 0.1819  time: 0.6067  data_time: 0.1711  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:20:27 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 7579  total_loss: 1.321  loss_cls: 0.2859  loss_box_reg: 0.4748  loss_mask: 0.2974  loss_rpn_cls: 0.05107  loss_rpn_loc: 0.1831  time: 0.6070  data_time: 0.3942  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:20:38 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 7599  total_loss: 1.314  loss_cls: 0.3221  loss_box_reg: 0.47  loss_mask: 0.2897  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.1775  time: 0.6069  data_time: 0.2030  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:20:51 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 7619  total_loss: 1.373  loss_cls: 0.3258  loss_box_reg: 0.4871  loss_mask: 0.2925  loss_rpn_cls: 0.06517  loss_rpn_loc: 0.1758  time: 0.6071  data_time: 0.2968  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:21:03 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 7639  total_loss: 1.342  loss_cls: 0.3063  loss_box_reg: 0.4865  loss_mask: 0.281  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.1896  time: 0.6071  data_time: 0.2512  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:21:16 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 7659  total_loss: 1.415  loss_cls: 0.3335  loss_box_reg: 0.5097  loss_mask: 0.2992  loss_rpn_cls: 0.06674  loss_rpn_loc: 0.1906  time: 0.6072  data_time: 0.2995  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:21:29 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 7679  total_loss: 1.434  loss_cls: 0.297  loss_box_reg: 0.5094  loss_mask: 0.2963  loss_rpn_cls: 0.07911  loss_rpn_loc: 0.202  time: 0.6072  data_time: 0.2616  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:21:40 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 7699  total_loss: 1.339  loss_cls: 0.2784  loss_box_reg: 0.5004  loss_mask: 0.291  loss_rpn_cls: 0.04389  loss_rpn_loc: 0.165  time: 0.6071  data_time: 0.2568  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:21:50 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 7719  total_loss: 1.35  loss_cls: 0.2872  loss_box_reg: 0.506  loss_mask: 0.3069  loss_rpn_cls: 0.05114  loss_rpn_loc: 0.2028  time: 0.6068  data_time: 0.1648  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:22:01 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 7739  total_loss: 1.406  loss_cls: 0.3269  loss_box_reg: 0.5035  loss_mask: 0.3124  loss_rpn_cls: 0.08746  loss_rpn_loc: 0.186  time: 0.6067  data_time: 0.2072  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:22:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:22:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:22:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:22:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:22:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:22:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0747 s/iter. Eval: 0.0109 s/iter. Total: 0.0863 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0779 s/iter. Eval: 0.0159 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0007 s/iter. Inference: 0.0781 s/iter. Eval: 0.0161 s/iter. Total: 0.0950 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:22:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.132321 (0.095968 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:22:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078183 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:22:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:22:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25446819425263434\n",
      "\u001b[32m[01/11 22:22:27 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 7759  total_loss: 1.381  loss_cls: 0.3242  loss_box_reg: 0.4799  loss_mask: 0.3019  loss_rpn_cls: 0.08181  loss_rpn_loc: 0.1895  time: 0.6068  data_time: 0.3097  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:22:40 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 7779  total_loss: 1.365  loss_cls: 0.3314  loss_box_reg: 0.4768  loss_mask: 0.2918  loss_rpn_cls: 0.08329  loss_rpn_loc: 0.196  time: 0.6070  data_time: 0.3236  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:22:53 d2.utils.events]: \u001b[0m eta: 0:13:16  iter: 7799  total_loss: 1.355  loss_cls: 0.284  loss_box_reg: 0.5071  loss_mask: 0.3021  loss_rpn_cls: 0.05521  loss_rpn_loc: 0.1753  time: 0.6071  data_time: 0.2971  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:23:06 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 7819  total_loss: 1.311  loss_cls: 0.3115  loss_box_reg: 0.467  loss_mask: 0.277  loss_rpn_cls: 0.05647  loss_rpn_loc: 0.1718  time: 0.6071  data_time: 0.2619  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:23:17 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 7839  total_loss: 1.526  loss_cls: 0.3611  loss_box_reg: 0.494  loss_mask: 0.2862  loss_rpn_cls: 0.09355  loss_rpn_loc: 0.2268  time: 0.6070  data_time: 0.2189  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:23:27 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 7859  total_loss: 1.334  loss_cls: 0.2715  loss_box_reg: 0.4791  loss_mask: 0.2762  loss_rpn_cls: 0.05512  loss_rpn_loc: 0.1807  time: 0.6068  data_time: 0.2062  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:23:40 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 7879  total_loss: 1.393  loss_cls: 0.325  loss_box_reg: 0.4957  loss_mask: 0.3056  loss_rpn_cls: 0.07653  loss_rpn_loc: 0.2027  time: 0.6069  data_time: 0.3082  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:23:53 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 7899  total_loss: 1.365  loss_cls: 0.3299  loss_box_reg: 0.4994  loss_mask: 0.2794  loss_rpn_cls: 0.08486  loss_rpn_loc: 0.1862  time: 0.6069  data_time: 0.2781  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:24:03 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 7919  total_loss: 1.266  loss_cls: 0.2742  loss_box_reg: 0.4653  loss_mask: 0.283  loss_rpn_cls: 0.06312  loss_rpn_loc: 0.1702  time: 0.6067  data_time: 0.1919  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:24:18 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 7939  total_loss: 1.332  loss_cls: 0.3007  loss_box_reg: 0.4654  loss_mask: 0.3032  loss_rpn_cls: 0.09434  loss_rpn_loc: 0.1911  time: 0.6071  data_time: 0.4053  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:24:31 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 7959  total_loss: 1.307  loss_cls: 0.3015  loss_box_reg: 0.4625  loss_mask: 0.29  loss_rpn_cls: 0.08196  loss_rpn_loc: 0.1904  time: 0.6071  data_time: 0.2509  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:24:43 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 7979  total_loss: 1.449  loss_cls: 0.2936  loss_box_reg: 0.5375  loss_mask: 0.2897  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.1819  time: 0.6071  data_time: 0.2673  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:24:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:24:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:24:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:24:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:24:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:24:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:24:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0764 s/iter. Eval: 0.0145 s/iter. Total: 0.0916 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 22:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0772 s/iter. Eval: 0.0169 s/iter. Total: 0.0949 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0007 s/iter. Inference: 0.0774 s/iter. Eval: 0.0168 s/iter. Total: 0.0950 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:24:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.110741 (0.095782 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:24:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077534 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:24:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:24:58 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24723847125788395\n",
      "\u001b[32m[01/11 22:25:06 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 7999  total_loss: 1.463  loss_cls: 0.3372  loss_box_reg: 0.4843  loss_mask: 0.3043  loss_rpn_cls: 0.08554  loss_rpn_loc: 0.1905  time: 0.6069  data_time: 0.1814  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:25:18 d2.utils.events]: \u001b[0m eta: 0:11:56  iter: 8019  total_loss: 1.417  loss_cls: 0.3108  loss_box_reg: 0.5034  loss_mask: 0.2943  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.1961  time: 0.6069  data_time: 0.2485  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:25:27 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 8039  total_loss: 1.32  loss_cls: 0.3177  loss_box_reg: 0.4938  loss_mask: 0.2836  loss_rpn_cls: 0.05416  loss_rpn_loc: 0.1726  time: 0.6066  data_time: 0.1647  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:25:39 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 8059  total_loss: 1.332  loss_cls: 0.2889  loss_box_reg: 0.497  loss_mask: 0.3098  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.1803  time: 0.6065  data_time: 0.2500  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:25:55 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 8079  total_loss: 1.367  loss_cls: 0.332  loss_box_reg: 0.501  loss_mask: 0.283  loss_rpn_cls: 0.08692  loss_rpn_loc: 0.206  time: 0.6070  data_time: 0.4442  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:26:08 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 8099  total_loss: 1.27  loss_cls: 0.2708  loss_box_reg: 0.4856  loss_mask: 0.2844  loss_rpn_cls: 0.07237  loss_rpn_loc: 0.1707  time: 0.6070  data_time: 0.2720  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:26:19 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 8119  total_loss: 1.344  loss_cls: 0.2979  loss_box_reg: 0.4963  loss_mask: 0.2905  loss_rpn_cls: 0.08608  loss_rpn_loc: 0.1884  time: 0.6070  data_time: 0.2443  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:26:30 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 8139  total_loss: 1.437  loss_cls: 0.318  loss_box_reg: 0.4888  loss_mask: 0.3012  loss_rpn_cls: 0.07181  loss_rpn_loc: 0.1961  time: 0.6068  data_time: 0.2081  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:26:46 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 8159  total_loss: 1.343  loss_cls: 0.3081  loss_box_reg: 0.4665  loss_mask: 0.2829  loss_rpn_cls: 0.06993  loss_rpn_loc: 0.1927  time: 0.6073  data_time: 0.4477  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:26:57 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 8179  total_loss: 1.291  loss_cls: 0.3162  loss_box_reg: 0.5069  loss_mask: 0.2954  loss_rpn_cls: 0.05015  loss_rpn_loc: 0.1764  time: 0.6072  data_time: 0.2042  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:27:12 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 8199  total_loss: 1.505  loss_cls: 0.3759  loss_box_reg: 0.5052  loss_mask: 0.3019  loss_rpn_cls: 0.08884  loss_rpn_loc: 0.2101  time: 0.6075  data_time: 0.3801  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:27:25 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 8219  total_loss: 1.34  loss_cls: 0.3272  loss_box_reg: 0.4897  loss_mask: 0.2746  loss_rpn_cls: 0.05545  loss_rpn_loc: 0.1764  time: 0.6076  data_time: 0.3005  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:27:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:27:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:27:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:27:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:27:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:27:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0803 s/iter. Eval: 0.0153 s/iter. Total: 0.0964 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 22:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0798 s/iter. Eval: 0.0142 s/iter. Total: 0.0949 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0775 s/iter. Eval: 0.0131 s/iter. Total: 0.0914 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:27:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.692125 (0.092173 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:27:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077523 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:27:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:27:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22253265442758952\n",
      "\u001b[32m[01/11 22:27:46 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 8239  total_loss: 1.364  loss_cls: 0.2757  loss_box_reg: 0.4926  loss_mask: 0.287  loss_rpn_cls: 0.04691  loss_rpn_loc: 0.1784  time: 0.6072  data_time: 0.1033  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:28:00 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 8259  total_loss: 1.312  loss_cls: 0.2988  loss_box_reg: 0.4875  loss_mask: 0.2831  loss_rpn_cls: 0.07457  loss_rpn_loc: 0.176  time: 0.6074  data_time: 0.3572  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:28:12 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 8279  total_loss: 1.403  loss_cls: 0.3447  loss_box_reg: 0.4951  loss_mask: 0.2893  loss_rpn_cls: 0.08299  loss_rpn_loc: 0.1911  time: 0.6074  data_time: 0.2905  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:28:24 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 8299  total_loss: 1.209  loss_cls: 0.261  loss_box_reg: 0.453  loss_mask: 0.2683  loss_rpn_cls: 0.05277  loss_rpn_loc: 0.1503  time: 0.6073  data_time: 0.2374  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:28:38 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 8319  total_loss: 1.423  loss_cls: 0.3322  loss_box_reg: 0.4999  loss_mask: 0.3148  loss_rpn_cls: 0.09102  loss_rpn_loc: 0.1908  time: 0.6076  data_time: 0.3776  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:28:49 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 8339  total_loss: 1.411  loss_cls: 0.3419  loss_box_reg: 0.515  loss_mask: 0.2988  loss_rpn_cls: 0.09021  loss_rpn_loc: 0.1999  time: 0.6075  data_time: 0.2224  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:29:03 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 8359  total_loss: 1.306  loss_cls: 0.2832  loss_box_reg: 0.4825  loss_mask: 0.2814  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.1797  time: 0.6077  data_time: 0.3377  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:29:12 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 8379  total_loss: 1.28  loss_cls: 0.3027  loss_box_reg: 0.5094  loss_mask: 0.2752  loss_rpn_cls: 0.05864  loss_rpn_loc: 0.1714  time: 0.6073  data_time: 0.1201  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:29:24 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 8399  total_loss: 1.496  loss_cls: 0.3375  loss_box_reg: 0.4625  loss_mask: 0.3187  loss_rpn_cls: 0.06494  loss_rpn_loc: 0.2097  time: 0.6073  data_time: 0.2391  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:29:34 d2.utils.events]: \u001b[0m eta: 0:09:32  iter: 8419  total_loss: 1.199  loss_cls: 0.2492  loss_box_reg: 0.46  loss_mask: 0.2862  loss_rpn_cls: 0.05274  loss_rpn_loc: 0.1688  time: 0.6071  data_time: 0.1922  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:29:49 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 8439  total_loss: 1.374  loss_cls: 0.3199  loss_box_reg: 0.5082  loss_mask: 0.3155  loss_rpn_cls: 0.07083  loss_rpn_loc: 0.1835  time: 0.6074  data_time: 0.4009  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:30:02 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 8459  total_loss: 1.334  loss_cls: 0.2777  loss_box_reg: 0.4666  loss_mask: 0.2909  loss_rpn_cls: 0.06529  loss_rpn_loc: 0.1798  time: 0.6075  data_time: 0.2979  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:30:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:30:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:30:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:30:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:30:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:30:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0753 s/iter. Eval: 0.0149 s/iter. Total: 0.0909 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0781 s/iter. Eval: 0.0175 s/iter. Total: 0.0964 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0779 s/iter. Eval: 0.0172 s/iter. Total: 0.0960 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:30:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.241653 (0.096911 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:30:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078005 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:30:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:30:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25283635234064905\n",
      "\u001b[32m[01/11 22:30:24 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 8479  total_loss: 1.308  loss_cls: 0.2721  loss_box_reg: 0.5079  loss_mask: 0.2887  loss_rpn_cls: 0.04221  loss_rpn_loc: 0.1917  time: 0.6071  data_time: 0.1218  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:30:39 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 8499  total_loss: 1.421  loss_cls: 0.3472  loss_box_reg: 0.5034  loss_mask: 0.3028  loss_rpn_cls: 0.07905  loss_rpn_loc: 0.208  time: 0.6075  data_time: 0.4382  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:30:52 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 8519  total_loss: 1.232  loss_cls: 0.2696  loss_box_reg: 0.4898  loss_mask: 0.2701  loss_rpn_cls: 0.05613  loss_rpn_loc: 0.1852  time: 0.6076  data_time: 0.2779  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:31:02 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 8539  total_loss: 1.355  loss_cls: 0.2983  loss_box_reg: 0.4868  loss_mask: 0.3009  loss_rpn_cls: 0.08592  loss_rpn_loc: 0.184  time: 0.6074  data_time: 0.2016  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:31:15 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 8559  total_loss: 1.282  loss_cls: 0.2902  loss_box_reg: 0.4795  loss_mask: 0.2969  loss_rpn_cls: 0.06916  loss_rpn_loc: 0.1961  time: 0.6074  data_time: 0.2819  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:31:27 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 8579  total_loss: 1.373  loss_cls: 0.3315  loss_box_reg: 0.4952  loss_mask: 0.2943  loss_rpn_cls: 0.0747  loss_rpn_loc: 0.2035  time: 0.6075  data_time: 0.2841  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:31:39 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 8599  total_loss: 1.37  loss_cls: 0.3158  loss_box_reg: 0.4951  loss_mask: 0.291  loss_rpn_cls: 0.0667  loss_rpn_loc: 0.1851  time: 0.6075  data_time: 0.2629  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:31:55 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 8619  total_loss: 1.333  loss_cls: 0.3305  loss_box_reg: 0.4783  loss_mask: 0.2962  loss_rpn_cls: 0.07492  loss_rpn_loc: 0.1866  time: 0.6078  data_time: 0.3991  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:32:08 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 8639  total_loss: 1.299  loss_cls: 0.2851  loss_box_reg: 0.4893  loss_mask: 0.3045  loss_rpn_cls: 0.07109  loss_rpn_loc: 0.1842  time: 0.6079  data_time: 0.3190  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:32:19 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 8659  total_loss: 1.202  loss_cls: 0.2592  loss_box_reg: 0.4401  loss_mask: 0.2777  loss_rpn_cls: 0.04982  loss_rpn_loc: 0.1667  time: 0.6078  data_time: 0.2398  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:32:33 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 8679  total_loss: 1.381  loss_cls: 0.3197  loss_box_reg: 0.4813  loss_mask: 0.2981  loss_rpn_cls: 0.06644  loss_rpn_loc: 0.1847  time: 0.6080  data_time: 0.3225  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:32:41 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 8699  total_loss: 1.232  loss_cls: 0.3042  loss_box_reg: 0.4809  loss_mask: 0.2799  loss_rpn_cls: 0.04894  loss_rpn_loc: 0.1633  time: 0.6076  data_time: 0.1067  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:32:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:32:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:32:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:32:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:32:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:32:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0768 s/iter. Eval: 0.0116 s/iter. Total: 0.0889 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0156 s/iter. Total: 0.0937 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0771 s/iter. Eval: 0.0154 s/iter. Total: 0.0933 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:33:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.905326 (0.094011 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:33:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077117 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:33:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:33:01 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24210065593089442\n",
      "\u001b[32m[01/11 22:33:04 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 8719  total_loss: 1.351  loss_cls: 0.3045  loss_box_reg: 0.4906  loss_mask: 0.2889  loss_rpn_cls: 0.07621  loss_rpn_loc: 0.1972  time: 0.6074  data_time: 0.1707  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:33:14 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 8739  total_loss: 1.436  loss_cls: 0.3043  loss_box_reg: 0.5058  loss_mask: 0.2912  loss_rpn_cls: 0.08251  loss_rpn_loc: 0.2137  time: 0.6071  data_time: 0.1620  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:33:26 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 8759  total_loss: 1.261  loss_cls: 0.2691  loss_box_reg: 0.4866  loss_mask: 0.2842  loss_rpn_cls: 0.03862  loss_rpn_loc: 0.1767  time: 0.6071  data_time: 0.2667  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:33:38 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 8779  total_loss: 1.464  loss_cls: 0.3461  loss_box_reg: 0.5525  loss_mask: 0.2931  loss_rpn_cls: 0.0731  loss_rpn_loc: 0.1909  time: 0.6071  data_time: 0.2421  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:33:51 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 8799  total_loss: 1.41  loss_cls: 0.3309  loss_box_reg: 0.5081  loss_mask: 0.3079  loss_rpn_cls: 0.06776  loss_rpn_loc: 0.2182  time: 0.6072  data_time: 0.2961  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:34:05 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 8819  total_loss: 1.435  loss_cls: 0.3193  loss_box_reg: 0.4659  loss_mask: 0.2938  loss_rpn_cls: 0.08476  loss_rpn_loc: 0.2049  time: 0.6074  data_time: 0.3579  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:34:16 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 8839  total_loss: 1.371  loss_cls: 0.3148  loss_box_reg: 0.5055  loss_mask: 0.3015  loss_rpn_cls: 0.08814  loss_rpn_loc: 0.1856  time: 0.6073  data_time: 0.1902  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:34:26 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 8859  total_loss: 1.257  loss_cls: 0.2944  loss_box_reg: 0.4505  loss_mask: 0.2623  loss_rpn_cls: 0.06823  loss_rpn_loc: 0.1816  time: 0.6071  data_time: 0.1883  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:34:39 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 8879  total_loss: 1.225  loss_cls: 0.263  loss_box_reg: 0.4412  loss_mask: 0.2761  loss_rpn_cls: 0.07329  loss_rpn_loc: 0.1915  time: 0.6072  data_time: 0.3050  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:34:54 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 8899  total_loss: 1.332  loss_cls: 0.2832  loss_box_reg: 0.4424  loss_mask: 0.2632  loss_rpn_cls: 0.0901  loss_rpn_loc: 0.2034  time: 0.6075  data_time: 0.3910  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:35:06 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 8919  total_loss: 1.297  loss_cls: 0.2879  loss_box_reg: 0.4933  loss_mask: 0.2951  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.1783  time: 0.6074  data_time: 0.2275  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:35:16 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 8939  total_loss: 1.388  loss_cls: 0.2896  loss_box_reg: 0.5046  loss_mask: 0.2899  loss_rpn_cls: 0.0732  loss_rpn_loc: 0.1885  time: 0.6072  data_time: 0.1938  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:35:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:35:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:35:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:35:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:35:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:35:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0766 s/iter. Eval: 0.0151 s/iter. Total: 0.0924 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 22:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0164 s/iter. Total: 0.0952 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0164 s/iter. Total: 0.0949 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:35:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.107123 (0.095751 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:35:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077794 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:35:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:35:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25127282658822114\n",
      "\u001b[32m[01/11 22:35:39 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 8959  total_loss: 1.29  loss_cls: 0.2538  loss_box_reg: 0.4929  loss_mask: 0.2974  loss_rpn_cls: 0.0683  loss_rpn_loc: 0.1754  time: 0.6071  data_time: 0.1988  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:35:53 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 8979  total_loss: 1.351  loss_cls: 0.2813  loss_box_reg: 0.5018  loss_mask: 0.3009  loss_rpn_cls: 0.0567  loss_rpn_loc: 0.176  time: 0.6073  data_time: 0.3602  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:36:07 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 8999  total_loss: 1.314  loss_cls: 0.303  loss_box_reg: 0.4853  loss_mask: 0.2994  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.1725  time: 0.6075  data_time: 0.3450  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:36:19 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 9019  total_loss: 1.362  loss_cls: 0.3265  loss_box_reg: 0.4958  loss_mask: 0.3142  loss_rpn_cls: 0.05703  loss_rpn_loc: 0.1919  time: 0.6075  data_time: 0.2758  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:36:33 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 9039  total_loss: 1.271  loss_cls: 0.2905  loss_box_reg: 0.4392  loss_mask: 0.2933  loss_rpn_cls: 0.05845  loss_rpn_loc: 0.1699  time: 0.6076  data_time: 0.3546  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:36:45 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 9059  total_loss: 1.343  loss_cls: 0.3029  loss_box_reg: 0.4486  loss_mask: 0.2871  loss_rpn_cls: 0.06999  loss_rpn_loc: 0.178  time: 0.6076  data_time: 0.2257  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:36:55 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 9079  total_loss: 1.252  loss_cls: 0.2691  loss_box_reg: 0.4518  loss_mask: 0.287  loss_rpn_cls: 0.05153  loss_rpn_loc: 0.1749  time: 0.6074  data_time: 0.2063  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:37:04 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 9099  total_loss: 1.252  loss_cls: 0.2503  loss_box_reg: 0.4881  loss_mask: 0.2761  loss_rpn_cls: 0.03614  loss_rpn_loc: 0.1758  time: 0.6071  data_time: 0.1304  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:37:16 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 9119  total_loss: 1.345  loss_cls: 0.3122  loss_box_reg: 0.4819  loss_mask: 0.291  loss_rpn_cls: 0.07206  loss_rpn_loc: 0.1725  time: 0.6070  data_time: 0.2473  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:37:31 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 9139  total_loss: 1.405  loss_cls: 0.3374  loss_box_reg: 0.5011  loss_mask: 0.2947  loss_rpn_cls: 0.08867  loss_rpn_loc: 0.1883  time: 0.6073  data_time: 0.3726  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:37:46 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 9159  total_loss: 1.386  loss_cls: 0.324  loss_box_reg: 0.497  loss_mask: 0.2815  loss_rpn_cls: 0.0741  loss_rpn_loc: 0.1892  time: 0.6077  data_time: 0.4079  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:37:59 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 9179  total_loss: 1.298  loss_cls: 0.316  loss_box_reg: 0.4545  loss_mask: 0.2787  loss_rpn_cls: 0.06366  loss_rpn_loc: 0.1863  time: 0.6077  data_time: 0.2631  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:38:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:38:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:38:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:38:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:38:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:38:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0140 s/iter. Total: 0.0916 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 22:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0787 s/iter. Eval: 0.0178 s/iter. Total: 0.0973 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0007 s/iter. Inference: 0.0793 s/iter. Eval: 0.0179 s/iter. Total: 0.0980 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:38:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.431024 (0.098543 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:38:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079240 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:38:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:38:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25799888923558323\n",
      "\u001b[32m[01/11 22:38:25 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 9199  total_loss: 1.31  loss_cls: 0.2695  loss_box_reg: 0.4777  loss_mask: 0.3017  loss_rpn_cls: 0.06539  loss_rpn_loc: 0.1919  time: 0.6078  data_time: 0.3234  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:38:34 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 9219  total_loss: 1.394  loss_cls: 0.316  loss_box_reg: 0.5034  loss_mask: 0.2972  loss_rpn_cls: 0.05859  loss_rpn_loc: 0.1775  time: 0.6075  data_time: 0.1413  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:38:46 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 9239  total_loss: 1.308  loss_cls: 0.2819  loss_box_reg: 0.4641  loss_mask: 0.2893  loss_rpn_cls: 0.05706  loss_rpn_loc: 0.178  time: 0.6075  data_time: 0.2404  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:39:00 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 9259  total_loss: 1.308  loss_cls: 0.2844  loss_box_reg: 0.4515  loss_mask: 0.2809  loss_rpn_cls: 0.07728  loss_rpn_loc: 0.1864  time: 0.6076  data_time: 0.3454  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:39:13 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 9279  total_loss: 1.273  loss_cls: 0.2504  loss_box_reg: 0.4826  loss_mask: 0.295  loss_rpn_cls: 0.05719  loss_rpn_loc: 0.1839  time: 0.6077  data_time: 0.3097  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:39:23 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 9299  total_loss: 1.411  loss_cls: 0.3363  loss_box_reg: 0.5021  loss_mask: 0.296  loss_rpn_cls: 0.07002  loss_rpn_loc: 0.1951  time: 0.6075  data_time: 0.1652  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:39:37 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 9319  total_loss: 1.235  loss_cls: 0.2493  loss_box_reg: 0.455  loss_mask: 0.2926  loss_rpn_cls: 0.04784  loss_rpn_loc: 0.1631  time: 0.6077  data_time: 0.3642  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:39:48 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 9339  total_loss: 1.3  loss_cls: 0.2552  loss_box_reg: 0.483  loss_mask: 0.2971  loss_rpn_cls: 0.0562  loss_rpn_loc: 0.18  time: 0.6076  data_time: 0.2494  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:39:59 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 9359  total_loss: 1.293  loss_cls: 0.2826  loss_box_reg: 0.4846  loss_mask: 0.2776  loss_rpn_cls: 0.06438  loss_rpn_loc: 0.1631  time: 0.6075  data_time: 0.2099  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:40:12 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 9379  total_loss: 1.541  loss_cls: 0.3303  loss_box_reg: 0.4873  loss_mask: 0.3083  loss_rpn_cls: 0.08116  loss_rpn_loc: 0.2026  time: 0.6076  data_time: 0.2848  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:40:24 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 9399  total_loss: 1.374  loss_cls: 0.2872  loss_box_reg: 0.4707  loss_mask: 0.2976  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.1817  time: 0.6076  data_time: 0.2731  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:40:37 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 9419  total_loss: 1.355  loss_cls: 0.2959  loss_box_reg: 0.5034  loss_mask: 0.3086  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.198  time: 0.6077  data_time: 0.3061  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:40:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:40:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:40:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:40:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:40:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:40:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:40:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0744 s/iter. Eval: 0.0118 s/iter. Total: 0.0871 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0161 s/iter. Total: 0.0942 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0774 s/iter. Eval: 0.0161 s/iter. Total: 0.0943 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:41:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.996481 (0.094797 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:41:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077356 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:41:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:41:01 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24762889512101405\n",
      "\u001b[32m[01/11 22:41:02 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9439  total_loss: 1.373  loss_cls: 0.3214  loss_box_reg: 0.4944  loss_mask: 0.2887  loss_rpn_cls: 0.0983  loss_rpn_loc: 0.2005  time: 0.6077  data_time: 0.2612  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:41:15 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9459  total_loss: 1.327  loss_cls: 0.3151  loss_box_reg: 0.4603  loss_mask: 0.2906  loss_rpn_cls: 0.07426  loss_rpn_loc: 0.1772  time: 0.6078  data_time: 0.3334  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:41:23 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9479  total_loss: 1.306  loss_cls: 0.2966  loss_box_reg: 0.4833  loss_mask: 0.2906  loss_rpn_cls: 0.05951  loss_rpn_loc: 0.1666  time: 0.6074  data_time: 0.0697  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:41:38 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 9499  total_loss: 1.345  loss_cls: 0.3046  loss_box_reg: 0.4962  loss_mask: 0.2812  loss_rpn_cls: 0.07762  loss_rpn_loc: 0.1903  time: 0.6076  data_time: 0.3669  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:41:51 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 9519  total_loss: 1.207  loss_cls: 0.2723  loss_box_reg: 0.4677  loss_mask: 0.2765  loss_rpn_cls: 0.0505  loss_rpn_loc: 0.1615  time: 0.6077  data_time: 0.3192  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:42:00 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 9539  total_loss: 1.364  loss_cls: 0.2832  loss_box_reg: 0.4881  loss_mask: 0.2802  loss_rpn_cls: 0.04818  loss_rpn_loc: 0.1854  time: 0.6074  data_time: 0.1211  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:42:14 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 9559  total_loss: 1.432  loss_cls: 0.361  loss_box_reg: 0.5079  loss_mask: 0.3022  loss_rpn_cls: 0.08317  loss_rpn_loc: 0.2088  time: 0.6076  data_time: 0.3455  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:42:28 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 9579  total_loss: 1.298  loss_cls: 0.2934  loss_box_reg: 0.4709  loss_mask: 0.2786  loss_rpn_cls: 0.05227  loss_rpn_loc: 0.1751  time: 0.6077  data_time: 0.3489  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:42:37 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 9599  total_loss: 1.277  loss_cls: 0.2809  loss_box_reg: 0.4841  loss_mask: 0.2823  loss_rpn_cls: 0.03415  loss_rpn_loc: 0.1633  time: 0.6074  data_time: 0.0971  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:42:51 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 9619  total_loss: 1.281  loss_cls: 0.2832  loss_box_reg: 0.4513  loss_mask: 0.2849  loss_rpn_cls: 0.05793  loss_rpn_loc: 0.1697  time: 0.6076  data_time: 0.3490  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:43:08 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 9639  total_loss: 1.357  loss_cls: 0.2681  loss_box_reg: 0.4862  loss_mask: 0.2967  loss_rpn_cls: 0.08644  loss_rpn_loc: 0.1957  time: 0.6082  data_time: 0.5482  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:43:23 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 9659  total_loss: 1.448  loss_cls: 0.3404  loss_box_reg: 0.5013  loss_mask: 0.2998  loss_rpn_cls: 0.08902  loss_rpn_loc: 0.2136  time: 0.6085  data_time: 0.4076  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:43:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:43:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:43:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:43:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:43:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:43:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0756 s/iter. Eval: 0.0132 s/iter. Total: 0.0895 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0774 s/iter. Eval: 0.0168 s/iter. Total: 0.0950 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0782 s/iter. Eval: 0.0168 s/iter. Total: 0.0958 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:43:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.188416 (0.096452 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:43:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078235 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:43:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:43:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.247760904435054\n",
      "\u001b[32m[01/11 22:43:52 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9679  total_loss: 1.365  loss_cls: 0.315  loss_box_reg: 0.4536  loss_mask: 0.3083  loss_rpn_cls: 0.09383  loss_rpn_loc: 0.2212  time: 0.6089  data_time: 0.4317  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:44:03 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 9699  total_loss: 1.303  loss_cls: 0.2834  loss_box_reg: 0.4877  loss_mask: 0.2915  loss_rpn_cls: 0.06798  loss_rpn_loc: 0.1952  time: 0.6088  data_time: 0.2306  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:44:16 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 9719  total_loss: 1.282  loss_cls: 0.2734  loss_box_reg: 0.4433  loss_mask: 0.2885  loss_rpn_cls: 0.05517  loss_rpn_loc: 0.1888  time: 0.6088  data_time: 0.2789  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:44:25 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 9739  total_loss: 1.286  loss_cls: 0.2566  loss_box_reg: 0.4851  loss_mask: 0.2848  loss_rpn_cls: 0.06348  loss_rpn_loc: 0.1687  time: 0.6085  data_time: 0.1090  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:44:36 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 9759  total_loss: 1.292  loss_cls: 0.2419  loss_box_reg: 0.4678  loss_mask: 0.3021  loss_rpn_cls: 0.05074  loss_rpn_loc: 0.1888  time: 0.6084  data_time: 0.2216  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:44:48 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 9779  total_loss: 1.32  loss_cls: 0.3045  loss_box_reg: 0.4656  loss_mask: 0.2926  loss_rpn_cls: 0.07145  loss_rpn_loc: 0.1867  time: 0.6084  data_time: 0.2773  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:44:57 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 9799  total_loss: 1.255  loss_cls: 0.2876  loss_box_reg: 0.4646  loss_mask: 0.2804  loss_rpn_cls: 0.04666  loss_rpn_loc: 0.1726  time: 0.6081  data_time: 0.1086  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:45:12 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 9819  total_loss: 1.376  loss_cls: 0.3033  loss_box_reg: 0.4616  loss_mask: 0.2964  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.1955  time: 0.6084  data_time: 0.4124  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:45:24 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 9839  total_loss: 1.244  loss_cls: 0.2843  loss_box_reg: 0.4836  loss_mask: 0.2941  loss_rpn_cls: 0.05305  loss_rpn_loc: 0.1885  time: 0.6083  data_time: 0.2437  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:45:38 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 9859  total_loss: 1.231  loss_cls: 0.2672  loss_box_reg: 0.4557  loss_mask: 0.2741  loss_rpn_cls: 0.06621  loss_rpn_loc: 0.1734  time: 0.6085  data_time: 0.3507  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:45:50 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 9879  total_loss: 1.244  loss_cls: 0.2761  loss_box_reg: 0.468  loss_mask: 0.2912  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.1813  time: 0.6085  data_time: 0.2507  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:46:01 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 9899  total_loss: 1.387  loss_cls: 0.3362  loss_box_reg: 0.4961  loss_mask: 0.2975  loss_rpn_cls: 0.05086  loss_rpn_loc: 0.1716  time: 0.6084  data_time: 0.2127  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:46:16 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 9919  total_loss: 1.454  loss_cls: 0.3587  loss_box_reg: 0.4919  loss_mask: 0.3095  loss_rpn_cls: 0.08674  loss_rpn_loc: 0.1937  time: 0.6087  data_time: 0.3672  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:46:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:46:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:46:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:46:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:46:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:46:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0759 s/iter. Eval: 0.0138 s/iter. Total: 0.0905 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/11 22:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0774 s/iter. Eval: 0.0172 s/iter. Total: 0.0954 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0008 s/iter. Inference: 0.0784 s/iter. Eval: 0.0174 s/iter. Total: 0.0967 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:46:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.326216 (0.097640 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:46:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078621 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:46:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:46:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25306543790013586\n",
      "\u001b[32m[01/11 22:46:41 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 9939  total_loss: 1.304  loss_cls: 0.2742  loss_box_reg: 0.4821  loss_mask: 0.2838  loss_rpn_cls: 0.05487  loss_rpn_loc: 0.1677  time: 0.6086  data_time: 0.2636  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:46:55 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 9959  total_loss: 1.346  loss_cls: 0.2949  loss_box_reg: 0.4509  loss_mask: 0.2767  loss_rpn_cls: 0.08883  loss_rpn_loc: 0.1935  time: 0.6088  data_time: 0.3510  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:47:06 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 9979  total_loss: 1.358  loss_cls: 0.2786  loss_box_reg: 0.4805  loss_mask: 0.3156  loss_rpn_cls: 0.08359  loss_rpn_loc: 0.192  time: 0.6087  data_time: 0.1990  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:47:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.274  loss_cls: 0.2874  loss_box_reg: 0.4776  loss_mask: 0.2942  loss_rpn_cls: 0.03769  loss_rpn_loc: 0.1628  time: 0.6086  data_time: 0.2236  lr: 0.0001  max_mem: 7021M\n",
      "\u001b[32m[01/11 22:47:17 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:41:24 (0.6086 s / it)\n",
      "\u001b[32m[01/11 22:47:17 d2.engine.hooks]: \u001b[0mTotal training time: 1:49:57 (0:08:32 on hooks)\n",
      "\u001b[32m[01/11 22:47:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:47:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/11 22:47:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/11 22:47:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/11 22:47:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/11 22:47:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/11 22:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0794 s/iter. Eval: 0.0144 s/iter. Total: 0.0945 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/11 22:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.0796 s/iter. Eval: 0.0181 s/iter. Total: 0.0985 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/11 22:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0792 s/iter. Eval: 0.0179 s/iter. Total: 0.0979 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/11 22:47:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.445231 (0.098666 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:47:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.079123 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/11 22:47:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/11 22:47:30 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24684340830558887\n"
     ]
    }
   ],
   "source": [
    "# Try again with lower learning rate\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af643956-a02a-466a-862a-539a82d825f9",
   "metadata": {},
   "source": [
    "Highest mAP is 0.2580 obtained after 9190 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ed3bb-2411-4253-ada1-50e04daae2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ea194bd-2b42-4185-a2f7-bba8a0f99979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-82fd00b55dbfe5ba\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-82fd00b55dbfe5ba\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d62833e5-10a5-4a5f-8475-1c17968dc04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a472c107adac8ecf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a472c107adac8ecf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_1.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
