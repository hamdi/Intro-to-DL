{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf086819-9251-4568-9a04-72820de05204",
   "metadata": {},
   "source": [
    "### Notebook 1.2: training on the main data of the competition (the Sartorius dataset)\n",
    "We use the model pretrained in the notebook 1.1 and train it on the Sartorius dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70fc34b-2a62-4bb5-8750-e8a7f9bedb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953d3122-cb68-4a26-82d4-592f06ecfff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 18:09:20 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n"
     ]
    }
   ],
   "source": [
    "dataDir=Path('../')\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "register_coco_instances('sartorius_train',{}, '../sartorius-annotations-coco-format/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_val',{},'../sartorius-annotations-coco-format/annotations_val.json', dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042485c9-ad8b-4b14-9d19-873cca6335e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1\n",
    "    false_positives = np.sum(matches, axis=0) == 0\n",
    "    false_negatives = np.sum(matches, axis=1) == 0\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"MaP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e96589b-592e-4564-965b-912367c3c362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 18:13:38 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/03 18:13:39 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/03 18:13:40 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/03 18:13:40 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/03 18:13:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[01/03 18:13:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/03 18:13:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/03 18:13:41 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:13:41 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 18:13:41 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[01/03 18:13:52 d2.utils.events]: \u001b[0m eta: 0:51:41  iter: 19  total_loss: 3.084  loss_cls: 1.424  loss_box_reg: 0.4179  loss_mask: 0.6876  loss_rpn_cls: 0.3153  loss_rpn_loc: 0.2376  time: 0.4043  data_time: 0.2234  lr: 9.9905e-06  max_mem: 4652M\n",
      "\u001b[32m[01/03 18:14:03 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 39  total_loss: 3.08  loss_cls: 1.35  loss_box_reg: 0.4075  loss_mask: 0.6821  loss_rpn_cls: 0.2798  loss_rpn_loc: 0.2536  time: 0.4831  data_time: 0.2437  lr: 1.998e-05  max_mem: 4790M\n",
      "\u001b[32m[01/03 18:14:17 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 59  total_loss: 2.926  loss_cls: 1.216  loss_box_reg: 0.4607  loss_mask: 0.6761  loss_rpn_cls: 0.315  loss_rpn_loc: 0.2782  time: 0.5563  data_time: 0.3687  lr: 2.997e-05  max_mem: 5020M\n",
      "\u001b[32m[01/03 18:14:27 d2.utils.events]: \u001b[0m eta: 0:53:28  iter: 79  total_loss: 2.593  loss_cls: 1.019  loss_box_reg: 0.4638  loss_mask: 0.6466  loss_rpn_cls: 0.2256  loss_rpn_loc: 0.2291  time: 0.5390  data_time: 0.1798  lr: 3.9961e-05  max_mem: 5020M\n",
      "\u001b[32m[01/03 18:14:38 d2.utils.events]: \u001b[0m eta: 0:53:08  iter: 99  total_loss: 2.462  loss_cls: 0.8439  loss_box_reg: 0.4206  loss_mask: 0.6145  loss_rpn_cls: 0.237  loss_rpn_loc: 0.2765  time: 0.5443  data_time: 0.2575  lr: 4.9951e-05  max_mem: 5020M\n",
      "\u001b[32m[01/03 18:14:52 d2.utils.events]: \u001b[0m eta: 0:52:51  iter: 119  total_loss: 2.29  loss_cls: 0.7663  loss_box_reg: 0.501  loss_mask: 0.584  loss_rpn_cls: 0.196  loss_rpn_loc: 0.2325  time: 0.5712  data_time: 0.3833  lr: 5.9941e-05  max_mem: 5176M\n",
      "\u001b[32m[01/03 18:15:04 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 139  total_loss: 2.289  loss_cls: 0.7309  loss_box_reg: 0.5491  loss_mask: 0.552  loss_rpn_cls: 0.2073  loss_rpn_loc: 0.2442  time: 0.5749  data_time: 0.2742  lr: 6.993e-05  max_mem: 5176M\n",
      "\u001b[32m[01/03 18:15:15 d2.utils.events]: \u001b[0m eta: 0:52:59  iter: 159  total_loss: 2.334  loss_cls: 0.7043  loss_box_reg: 0.6164  loss_mask: 0.537  loss_rpn_cls: 0.1717  loss_rpn_loc: 0.2495  time: 0.5737  data_time: 0.2573  lr: 7.9921e-05  max_mem: 5176M\n",
      "\u001b[32m[01/03 18:15:28 d2.utils.events]: \u001b[0m eta: 0:53:28  iter: 179  total_loss: 2.118  loss_cls: 0.6682  loss_box_reg: 0.5322  loss_mask: 0.5117  loss_rpn_cls: 0.164  loss_rpn_loc: 0.2317  time: 0.5837  data_time: 0.3349  lr: 8.991e-05  max_mem: 5909M\n",
      "\u001b[32m[01/03 18:15:40 d2.utils.events]: \u001b[0m eta: 0:53:22  iter: 199  total_loss: 2.052  loss_cls: 0.6006  loss_box_reg: 0.6434  loss_mask: 0.4581  loss_rpn_cls: 0.134  loss_rpn_loc: 0.2365  time: 0.5840  data_time: 0.2702  lr: 9.9901e-05  max_mem: 5909M\n",
      "\u001b[32m[01/03 18:15:54 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 219  total_loss: 1.96  loss_cls: 0.5778  loss_box_reg: 0.5989  loss_mask: 0.4387  loss_rpn_cls: 0.1623  loss_rpn_loc: 0.2278  time: 0.5941  data_time: 0.3576  lr: 0.00010989  max_mem: 5909M\n",
      "\u001b[32m[01/03 18:16:06 d2.utils.events]: \u001b[0m eta: 0:54:09  iter: 239  total_loss: 2.073  loss_cls: 0.6291  loss_box_reg: 0.6673  loss_mask: 0.4313  loss_rpn_cls: 0.1417  loss_rpn_loc: 0.2359  time: 0.5930  data_time: 0.2636  lr: 0.00011988  max_mem: 5909M\n",
      "\u001b[32m[01/03 18:16:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:16:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:16:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:16:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:16:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:16:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0005 s/iter. Inference: 0.0639 s/iter. Eval: 0.0008 s/iter. Total: 0.0652 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/03 18:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0669 s/iter. Eval: 0.0007 s/iter. Total: 0.0683 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/03 18:16:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.010844 (0.069059 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:16:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.067259 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:16:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:16:17 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.019835772307529517\n",
      "\u001b[32m[01/03 18:16:25 d2.utils.events]: \u001b[0m eta: 0:53:41  iter: 259  total_loss: 1.96  loss_cls: 0.5398  loss_box_reg: 0.6848  loss_mask: 0.3991  loss_rpn_cls: 0.08454  loss_rpn_loc: 0.2227  time: 0.5876  data_time: 0.2152  lr: 0.00012987  max_mem: 5909M\n",
      "\u001b[32m[01/03 18:16:39 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 279  total_loss: 1.929  loss_cls: 0.5507  loss_box_reg: 0.5967  loss_mask: 0.3736  loss_rpn_cls: 0.1447  loss_rpn_loc: 0.2234  time: 0.5934  data_time: 0.3293  lr: 0.00013986  max_mem: 5909M\n",
      "\u001b[32m[01/03 18:16:53 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 299  total_loss: 1.81  loss_cls: 0.4864  loss_box_reg: 0.5928  loss_mask: 0.3439  loss_rpn_cls: 0.1506  loss_rpn_loc: 0.224  time: 0.6015  data_time: 0.3818  lr: 0.00014985  max_mem: 5909M\n",
      "\u001b[32m[01/03 18:17:03 d2.utils.events]: \u001b[0m eta: 0:53:54  iter: 319  total_loss: 1.823  loss_cls: 0.4819  loss_box_reg: 0.6147  loss_mask: 0.3345  loss_rpn_cls: 0.1368  loss_rpn_loc: 0.2552  time: 0.5939  data_time: 0.1770  lr: 0.00015984  max_mem: 5909M\n",
      "\u001b[32m[01/03 18:17:16 d2.utils.events]: \u001b[0m eta: 0:53:47  iter: 339  total_loss: 1.792  loss_cls: 0.4432  loss_box_reg: 0.6424  loss_mask: 0.3337  loss_rpn_cls: 0.1364  loss_rpn_loc: 0.2472  time: 0.5989  data_time: 0.3506  lr: 0.00016983  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:17:31 d2.utils.events]: \u001b[0m eta: 0:53:41  iter: 359  total_loss: 1.657  loss_cls: 0.3952  loss_box_reg: 0.649  loss_mask: 0.3244  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.2152  time: 0.6072  data_time: 0.4327  lr: 0.00017982  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:17:41 d2.utils.events]: \u001b[0m eta: 0:53:31  iter: 379  total_loss: 1.619  loss_cls: 0.3801  loss_box_reg: 0.5996  loss_mask: 0.311  loss_rpn_cls: 0.08204  loss_rpn_loc: 0.2207  time: 0.6020  data_time: 0.2045  lr: 0.00018981  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:17:54 d2.utils.events]: \u001b[0m eta: 0:53:25  iter: 399  total_loss: 1.646  loss_cls: 0.4431  loss_box_reg: 0.6329  loss_mask: 0.3219  loss_rpn_cls: 0.1118  loss_rpn_loc: 0.2101  time: 0.6025  data_time: 0.2863  lr: 0.0001998  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:18:06 d2.utils.events]: \u001b[0m eta: 0:53:18  iter: 419  total_loss: 1.697  loss_cls: 0.4481  loss_box_reg: 0.6022  loss_mask: 0.3107  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.2335  time: 0.6025  data_time: 0.2869  lr: 0.00020979  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:18:16 d2.utils.events]: \u001b[0m eta: 0:53:05  iter: 439  total_loss: 1.729  loss_cls: 0.4052  loss_box_reg: 0.6201  loss_mask: 0.3314  loss_rpn_cls: 0.1251  loss_rpn_loc: 0.2079  time: 0.5986  data_time: 0.2032  lr: 0.00021978  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:18:26 d2.utils.events]: \u001b[0m eta: 0:52:47  iter: 459  total_loss: 1.641  loss_cls: 0.4135  loss_box_reg: 0.604  loss_mask: 0.3126  loss_rpn_cls: 0.1257  loss_rpn_loc: 0.2153  time: 0.5947  data_time: 0.2109  lr: 0.00022977  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:18:36 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 479  total_loss: 1.672  loss_cls: 0.3961  loss_box_reg: 0.6072  loss_mask: 0.3214  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2085  time: 0.5894  data_time: 0.1594  lr: 0.00023976  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:18:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:18:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:18:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:18:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:18:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:18:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0664 s/iter. Eval: 0.0079 s/iter. Total: 0.0749 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0007 s/iter. Inference: 0.0695 s/iter. Eval: 0.0143 s/iter. Total: 0.0846 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:18:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.014714 (0.086334 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:18:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070472 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:18:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:18:49 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.20681060687439073\n",
      "\u001b[32m[01/03 18:18:59 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 499  total_loss: 1.641  loss_cls: 0.3898  loss_box_reg: 0.5591  loss_mask: 0.3132  loss_rpn_cls: 0.08748  loss_rpn_loc: 0.2151  time: 0.5901  data_time: 0.2913  lr: 0.00024975  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:19:14 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 519  total_loss: 1.658  loss_cls: 0.3969  loss_box_reg: 0.5578  loss_mask: 0.3367  loss_rpn_cls: 0.136  loss_rpn_loc: 0.2342  time: 0.5960  data_time: 0.3926  lr: 0.00025974  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:19:27 d2.utils.events]: \u001b[0m eta: 0:52:34  iter: 539  total_loss: 1.64  loss_cls: 0.3722  loss_box_reg: 0.5768  loss_mask: 0.3174  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.2285  time: 0.5994  data_time: 0.3584  lr: 0.00026973  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:19:39 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 559  total_loss: 1.698  loss_cls: 0.3878  loss_box_reg: 0.5822  loss_mask: 0.3147  loss_rpn_cls: 0.07893  loss_rpn_loc: 0.2223  time: 0.5978  data_time: 0.2425  lr: 0.00027972  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:19:50 d2.utils.events]: \u001b[0m eta: 0:52:14  iter: 579  total_loss: 1.536  loss_cls: 0.3719  loss_box_reg: 0.5417  loss_mask: 0.3119  loss_rpn_cls: 0.09919  loss_rpn_loc: 0.1946  time: 0.5972  data_time: 0.2631  lr: 0.00028971  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:20:00 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 599  total_loss: 1.619  loss_cls: 0.3307  loss_box_reg: 0.6  loss_mask: 0.3002  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2065  time: 0.5931  data_time: 0.1651  lr: 0.0002997  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:20:10 d2.utils.events]: \u001b[0m eta: 0:52:01  iter: 619  total_loss: 1.69  loss_cls: 0.3784  loss_box_reg: 0.5855  loss_mask: 0.3099  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.2099  time: 0.5901  data_time: 0.1748  lr: 0.00030969  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:20:22 d2.utils.events]: \u001b[0m eta: 0:51:54  iter: 639  total_loss: 1.729  loss_cls: 0.3796  loss_box_reg: 0.608  loss_mask: 0.3361  loss_rpn_cls: 0.1321  loss_rpn_loc: 0.2323  time: 0.5906  data_time: 0.2879  lr: 0.00031968  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:20:33 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 659  total_loss: 1.602  loss_cls: 0.383  loss_box_reg: 0.56  loss_mask: 0.3426  loss_rpn_cls: 0.08076  loss_rpn_loc: 0.1991  time: 0.5902  data_time: 0.2415  lr: 0.00032967  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:20:43 d2.utils.events]: \u001b[0m eta: 0:51:53  iter: 679  total_loss: 1.566  loss_cls: 0.3585  loss_box_reg: 0.5918  loss_mask: 0.3067  loss_rpn_cls: 0.09296  loss_rpn_loc: 0.211  time: 0.5863  data_time: 0.1416  lr: 0.00033966  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:20:54 d2.utils.events]: \u001b[0m eta: 0:51:44  iter: 699  total_loss: 1.471  loss_cls: 0.3593  loss_box_reg: 0.5697  loss_mask: 0.2952  loss_rpn_cls: 0.0795  loss_rpn_loc: 0.1896  time: 0.5863  data_time: 0.2734  lr: 0.00034965  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:21:05 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 719  total_loss: 1.511  loss_cls: 0.3632  loss_box_reg: 0.54  loss_mask: 0.3172  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.2005  time: 0.5855  data_time: 0.2480  lr: 0.00035964  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:21:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:21:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:21:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:21:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:21:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:21:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0101 s/iter. Total: 0.0818 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:21:18 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0136 s/iter. Total: 0.0855 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:21:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.825472 (0.084702 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:21:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070250 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:21:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:21:22 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22454615360135013\n",
      "\u001b[32m[01/03 18:21:30 d2.utils.events]: \u001b[0m eta: 0:51:32  iter: 739  total_loss: 1.606  loss_cls: 0.4029  loss_box_reg: 0.542  loss_mask: 0.3111  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.2213  time: 0.5880  data_time: 0.3474  lr: 0.00036963  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:21:40 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 759  total_loss: 1.534  loss_cls: 0.3465  loss_box_reg: 0.5411  loss_mask: 0.3035  loss_rpn_cls: 0.09343  loss_rpn_loc: 0.2227  time: 0.5859  data_time: 0.2029  lr: 0.00037962  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:21:54 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 779  total_loss: 1.535  loss_cls: 0.3488  loss_box_reg: 0.5045  loss_mask: 0.3082  loss_rpn_cls: 0.09537  loss_rpn_loc: 0.2237  time: 0.5885  data_time: 0.3680  lr: 0.00038961  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:22:06 d2.utils.events]: \u001b[0m eta: 0:51:07  iter: 799  total_loss: 1.499  loss_cls: 0.3901  loss_box_reg: 0.5451  loss_mask: 0.2879  loss_rpn_cls: 0.08392  loss_rpn_loc: 0.1925  time: 0.5887  data_time: 0.2785  lr: 0.0003996  max_mem: 6427M\n",
      "\u001b[32m[01/03 18:22:21 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 819  total_loss: 1.545  loss_cls: 0.3816  loss_box_reg: 0.5283  loss_mask: 0.3111  loss_rpn_cls: 0.08972  loss_rpn_loc: 0.2066  time: 0.5931  data_time: 0.4403  lr: 0.00040959  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:22:33 d2.utils.events]: \u001b[0m eta: 0:50:48  iter: 839  total_loss: 1.604  loss_cls: 0.3376  loss_box_reg: 0.5506  loss_mask: 0.3184  loss_rpn_cls: 0.09406  loss_rpn_loc: 0.2163  time: 0.5923  data_time: 0.2478  lr: 0.00041958  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:22:46 d2.utils.events]: \u001b[0m eta: 0:50:43  iter: 859  total_loss: 1.423  loss_cls: 0.3144  loss_box_reg: 0.5437  loss_mask: 0.3008  loss_rpn_cls: 0.09226  loss_rpn_loc: 0.196  time: 0.5940  data_time: 0.3415  lr: 0.00042957  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:22:56 d2.utils.events]: \u001b[0m eta: 0:50:37  iter: 879  total_loss: 1.568  loss_cls: 0.3707  loss_box_reg: 0.5961  loss_mask: 0.3137  loss_rpn_cls: 0.08956  loss_rpn_loc: 0.194  time: 0.5926  data_time: 0.2174  lr: 0.00043956  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:23:12 d2.utils.events]: \u001b[0m eta: 0:50:32  iter: 899  total_loss: 1.556  loss_cls: 0.3804  loss_box_reg: 0.5643  loss_mask: 0.3108  loss_rpn_cls: 0.09596  loss_rpn_loc: 0.207  time: 0.5964  data_time: 0.4443  lr: 0.00044955  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:23:20 d2.utils.events]: \u001b[0m eta: 0:50:25  iter: 919  total_loss: 1.503  loss_cls: 0.3304  loss_box_reg: 0.5859  loss_mask: 0.3223  loss_rpn_cls: 0.07832  loss_rpn_loc: 0.2028  time: 0.5922  data_time: 0.0879  lr: 0.00045954  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:23:31 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 939  total_loss: 1.574  loss_cls: 0.3397  loss_box_reg: 0.5611  loss_mask: 0.3122  loss_rpn_cls: 0.09075  loss_rpn_loc: 0.2009  time: 0.5909  data_time: 0.2143  lr: 0.00046953  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:23:42 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 959  total_loss: 1.525  loss_cls: 0.3609  loss_box_reg: 0.5485  loss_mask: 0.2948  loss_rpn_cls: 0.09193  loss_rpn_loc: 0.2038  time: 0.5904  data_time: 0.2425  lr: 0.00047952  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:23:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:23:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:23:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:23:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:23:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:23:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0680 s/iter. Eval: 0.0109 s/iter. Total: 0.0796 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:23:54 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.0143 s/iter. Total: 0.0848 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:23:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.904072 (0.085380 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:23:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069895 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:23:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:23:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23268364021338245\n",
      "\u001b[32m[01/03 18:24:06 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 979  total_loss: 1.547  loss_cls: 0.3442  loss_box_reg: 0.5582  loss_mask: 0.3121  loss_rpn_cls: 0.09814  loss_rpn_loc: 0.22  time: 0.5912  data_time: 0.3199  lr: 0.00048951  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:24:14 d2.utils.events]: \u001b[0m eta: 0:49:53  iter: 999  total_loss: 1.478  loss_cls: 0.37  loss_box_reg: 0.5603  loss_mask: 0.2957  loss_rpn_cls: 0.08576  loss_rpn_loc: 0.2041  time: 0.5879  data_time: 0.1219  lr: 0.0004995  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:24:27 d2.utils.events]: \u001b[0m eta: 0:49:55  iter: 1019  total_loss: 1.582  loss_cls: 0.3644  loss_box_reg: 0.5222  loss_mask: 0.3066  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.2106  time: 0.5888  data_time: 0.3074  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:24:40 d2.utils.events]: \u001b[0m eta: 0:49:53  iter: 1039  total_loss: 1.529  loss_cls: 0.3706  loss_box_reg: 0.5319  loss_mask: 0.3103  loss_rpn_cls: 0.0933  loss_rpn_loc: 0.2203  time: 0.5903  data_time: 0.3489  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:24:55 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 1059  total_loss: 1.634  loss_cls: 0.3964  loss_box_reg: 0.564  loss_mask: 0.3052  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.2064  time: 0.5936  data_time: 0.4356  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:25:05 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 1079  total_loss: 1.481  loss_cls: 0.3355  loss_box_reg: 0.5602  loss_mask: 0.3089  loss_rpn_cls: 0.07708  loss_rpn_loc: 0.2167  time: 0.5917  data_time: 0.1819  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:25:15 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 1099  total_loss: 1.455  loss_cls: 0.326  loss_box_reg: 0.5373  loss_mask: 0.3019  loss_rpn_cls: 0.09934  loss_rpn_loc: 0.1919  time: 0.5899  data_time: 0.1853  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:25:27 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 1119  total_loss: 1.458  loss_cls: 0.3392  loss_box_reg: 0.5371  loss_mask: 0.3119  loss_rpn_cls: 0.09907  loss_rpn_loc: 0.1924  time: 0.5903  data_time: 0.2996  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:25:37 d2.utils.events]: \u001b[0m eta: 0:49:08  iter: 1139  total_loss: 1.484  loss_cls: 0.3609  loss_box_reg: 0.5243  loss_mask: 0.3104  loss_rpn_cls: 0.09198  loss_rpn_loc: 0.1951  time: 0.5882  data_time: 0.1651  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:25:48 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 1159  total_loss: 1.545  loss_cls: 0.3822  loss_box_reg: 0.5395  loss_mask: 0.3125  loss_rpn_cls: 0.08823  loss_rpn_loc: 0.2204  time: 0.5881  data_time: 0.2749  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:26:01 d2.utils.events]: \u001b[0m eta: 0:48:59  iter: 1179  total_loss: 1.463  loss_cls: 0.3612  loss_box_reg: 0.5297  loss_mask: 0.2977  loss_rpn_cls: 0.08963  loss_rpn_loc: 0.2152  time: 0.5889  data_time: 0.3227  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:26:13 d2.utils.events]: \u001b[0m eta: 0:48:51  iter: 1199  total_loss: 1.383  loss_cls: 0.3095  loss_box_reg: 0.515  loss_mask: 0.2957  loss_rpn_cls: 0.07132  loss_rpn_loc: 0.2096  time: 0.5892  data_time: 0.2946  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:26:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:26:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:26:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:26:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:26:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:26:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0109 s/iter. Total: 0.0818 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 18:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0715 s/iter. Eval: 0.0156 s/iter. Total: 0.0878 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:26:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.305040 (0.088837 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:26:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071338 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:26:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:26:30 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24960018553338362\n",
      "\u001b[32m[01/03 18:26:36 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 1219  total_loss: 1.421  loss_cls: 0.3281  loss_box_reg: 0.5291  loss_mask: 0.3083  loss_rpn_cls: 0.1137  loss_rpn_loc: 0.1878  time: 0.5884  data_time: 0.2145  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:26:44 d2.utils.events]: \u001b[0m eta: 0:48:22  iter: 1239  total_loss: 1.489  loss_cls: 0.3353  loss_box_reg: 0.5611  loss_mask: 0.2919  loss_rpn_cls: 0.07109  loss_rpn_loc: 0.2088  time: 0.5852  data_time: 0.0908  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:26:58 d2.utils.events]: \u001b[0m eta: 0:48:20  iter: 1259  total_loss: 1.45  loss_cls: 0.313  loss_box_reg: 0.5271  loss_mask: 0.3232  loss_rpn_cls: 0.07721  loss_rpn_loc: 0.1836  time: 0.5874  data_time: 0.3962  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:27:10 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 1279  total_loss: 1.467  loss_cls: 0.3272  loss_box_reg: 0.5455  loss_mask: 0.3067  loss_rpn_cls: 0.09945  loss_rpn_loc: 0.2045  time: 0.5874  data_time: 0.2733  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:27:23 d2.utils.events]: \u001b[0m eta: 0:47:57  iter: 1299  total_loss: 1.54  loss_cls: 0.3247  loss_box_reg: 0.5199  loss_mask: 0.3061  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.2188  time: 0.5888  data_time: 0.3536  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:27:36 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 1319  total_loss: 1.591  loss_cls: 0.3692  loss_box_reg: 0.5801  loss_mask: 0.3171  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.1983  time: 0.5893  data_time: 0.3067  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:27:47 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 1339  total_loss: 1.48  loss_cls: 0.3829  loss_box_reg: 0.5017  loss_mask: 0.3074  loss_rpn_cls: 0.09879  loss_rpn_loc: 0.1969  time: 0.5889  data_time: 0.2529  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:28:00 d2.utils.events]: \u001b[0m eta: 0:47:38  iter: 1359  total_loss: 1.425  loss_cls: 0.3211  loss_box_reg: 0.5136  loss_mask: 0.3029  loss_rpn_cls: 0.08441  loss_rpn_loc: 0.2034  time: 0.5896  data_time: 0.3228  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:28:12 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 1379  total_loss: 1.645  loss_cls: 0.4109  loss_box_reg: 0.5474  loss_mask: 0.3123  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.2381  time: 0.5898  data_time: 0.2858  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:28:23 d2.utils.events]: \u001b[0m eta: 0:47:25  iter: 1399  total_loss: 1.475  loss_cls: 0.3728  loss_box_reg: 0.5577  loss_mask: 0.3007  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1892  time: 0.5892  data_time: 0.2362  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:28:35 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 1419  total_loss: 1.493  loss_cls: 0.3095  loss_box_reg: 0.5378  loss_mask: 0.3177  loss_rpn_cls: 0.09169  loss_rpn_loc: 0.2206  time: 0.5897  data_time: 0.3098  lr: 0.0005  max_mem: 6465M\n",
      "\u001b[32m[01/03 18:28:48 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 1439  total_loss: 1.594  loss_cls: 0.3889  loss_box_reg: 0.5364  loss_mask: 0.3199  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.2088  time: 0.5901  data_time: 0.2931  lr: 0.0005  max_mem: 6557M\n",
      "\u001b[32m[01/03 18:28:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:28:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:28:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:28:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:28:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:28:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0717 s/iter. Eval: 0.0106 s/iter. Total: 0.0829 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 18:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0727 s/iter. Eval: 0.0142 s/iter. Total: 0.0876 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.075115 (0.086854 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071672 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:29:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:29:04 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2438452155290158\n",
      "\u001b[32m[01/03 18:29:12 d2.utils.events]: \u001b[0m eta: 0:47:14  iter: 1459  total_loss: 1.571  loss_cls: 0.3876  loss_box_reg: 0.532  loss_mask: 0.2909  loss_rpn_cls: 0.09165  loss_rpn_loc: 0.2097  time: 0.5907  data_time: 0.3219  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:29:23 d2.utils.events]: \u001b[0m eta: 0:47:08  iter: 1479  total_loss: 1.574  loss_cls: 0.3397  loss_box_reg: 0.521  loss_mask: 0.309  loss_rpn_cls: 0.09487  loss_rpn_loc: 0.2248  time: 0.5901  data_time: 0.2327  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:29:32 d2.utils.events]: \u001b[0m eta: 0:46:59  iter: 1499  total_loss: 1.593  loss_cls: 0.4112  loss_box_reg: 0.5664  loss_mask: 0.3156  loss_rpn_cls: 0.08077  loss_rpn_loc: 0.1972  time: 0.5887  data_time: 0.1790  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:29:44 d2.utils.events]: \u001b[0m eta: 0:46:38  iter: 1519  total_loss: 1.466  loss_cls: 0.3277  loss_box_reg: 0.4975  loss_mask: 0.3005  loss_rpn_cls: 0.08334  loss_rpn_loc: 0.1829  time: 0.5885  data_time: 0.2590  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:29:54 d2.utils.events]: \u001b[0m eta: 0:46:31  iter: 1539  total_loss: 1.497  loss_cls: 0.3451  loss_box_reg: 0.5674  loss_mask: 0.3037  loss_rpn_cls: 0.09405  loss_rpn_loc: 0.1931  time: 0.5872  data_time: 0.1856  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:30:06 d2.utils.events]: \u001b[0m eta: 0:46:27  iter: 1559  total_loss: 1.441  loss_cls: 0.342  loss_box_reg: 0.5291  loss_mask: 0.3104  loss_rpn_cls: 0.09108  loss_rpn_loc: 0.217  time: 0.5878  data_time: 0.3164  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:30:17 d2.utils.events]: \u001b[0m eta: 0:46:20  iter: 1579  total_loss: 1.504  loss_cls: 0.3415  loss_box_reg: 0.539  loss_mask: 0.3044  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2179  time: 0.5874  data_time: 0.2361  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:30:28 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 1599  total_loss: 1.457  loss_cls: 0.3382  loss_box_reg: 0.5118  loss_mask: 0.296  loss_rpn_cls: 0.09135  loss_rpn_loc: 0.1991  time: 0.5868  data_time: 0.2312  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:30:42 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 1619  total_loss: 1.473  loss_cls: 0.3395  loss_box_reg: 0.4771  loss_mask: 0.2991  loss_rpn_cls: 0.09881  loss_rpn_loc: 0.2158  time: 0.5881  data_time: 0.3714  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:30:52 d2.utils.events]: \u001b[0m eta: 0:46:04  iter: 1639  total_loss: 1.46  loss_cls: 0.3532  loss_box_reg: 0.5134  loss_mask: 0.2876  loss_rpn_cls: 0.09052  loss_rpn_loc: 0.2072  time: 0.5869  data_time: 0.1789  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:31:05 d2.utils.events]: \u001b[0m eta: 0:45:52  iter: 1659  total_loss: 1.414  loss_cls: 0.3079  loss_box_reg: 0.5344  loss_mask: 0.3135  loss_rpn_cls: 0.07352  loss_rpn_loc: 0.201  time: 0.5878  data_time: 0.3335  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:31:15 d2.utils.events]: \u001b[0m eta: 0:45:47  iter: 1679  total_loss: 1.591  loss_cls: 0.3704  loss_box_reg: 0.5349  loss_mask: 0.3171  loss_rpn_cls: 0.09808  loss_rpn_loc: 0.2064  time: 0.5870  data_time: 0.1910  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:31:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:31:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:31:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:31:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:31:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:31:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:31:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.0108 s/iter. Total: 0.0797 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:31:31 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0154 s/iter. Total: 0.0865 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:31:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.176789 (0.087731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:31:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070717 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:31:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:31:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2497832647572008\n",
      "\u001b[32m[01/03 18:31:38 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 1699  total_loss: 1.426  loss_cls: 0.342  loss_box_reg: 0.5111  loss_mask: 0.3034  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.2193  time: 0.5868  data_time: 0.2556  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:31:50 d2.utils.events]: \u001b[0m eta: 0:45:37  iter: 1719  total_loss: 1.56  loss_cls: 0.3596  loss_box_reg: 0.5325  loss_mask: 0.3116  loss_rpn_cls: 0.08491  loss_rpn_loc: 0.2246  time: 0.5868  data_time: 0.2689  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:32:05 d2.utils.events]: \u001b[0m eta: 0:45:29  iter: 1739  total_loss: 1.432  loss_cls: 0.3058  loss_box_reg: 0.479  loss_mask: 0.3142  loss_rpn_cls: 0.08453  loss_rpn_loc: 0.212  time: 0.5885  data_time: 0.4104  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:32:16 d2.utils.events]: \u001b[0m eta: 0:45:25  iter: 1759  total_loss: 1.548  loss_cls: 0.3762  loss_box_reg: 0.5444  loss_mask: 0.3082  loss_rpn_cls: 0.08974  loss_rpn_loc: 0.2007  time: 0.5880  data_time: 0.2187  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:32:25 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 1779  total_loss: 1.541  loss_cls: 0.4053  loss_box_reg: 0.549  loss_mask: 0.2993  loss_rpn_cls: 0.09265  loss_rpn_loc: 0.2092  time: 0.5868  data_time: 0.1644  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:32:37 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 1799  total_loss: 1.43  loss_cls: 0.3044  loss_box_reg: 0.5119  loss_mask: 0.301  loss_rpn_cls: 0.06927  loss_rpn_loc: 0.1936  time: 0.5866  data_time: 0.2529  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:32:50 d2.utils.events]: \u001b[0m eta: 0:45:06  iter: 1819  total_loss: 1.522  loss_cls: 0.3564  loss_box_reg: 0.5383  loss_mask: 0.3198  loss_rpn_cls: 0.09589  loss_rpn_loc: 0.214  time: 0.5874  data_time: 0.3344  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:33:02 d2.utils.events]: \u001b[0m eta: 0:45:05  iter: 1839  total_loss: 1.569  loss_cls: 0.3776  loss_box_reg: 0.5794  loss_mask: 0.3167  loss_rpn_cls: 0.08288  loss_rpn_loc: 0.2097  time: 0.5877  data_time: 0.2869  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:33:13 d2.utils.events]: \u001b[0m eta: 0:44:57  iter: 1859  total_loss: 1.443  loss_cls: 0.3086  loss_box_reg: 0.541  loss_mask: 0.3102  loss_rpn_cls: 0.08313  loss_rpn_loc: 0.1865  time: 0.5873  data_time: 0.2289  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:33:28 d2.utils.events]: \u001b[0m eta: 0:44:57  iter: 1879  total_loss: 1.444  loss_cls: 0.3532  loss_box_reg: 0.52  loss_mask: 0.2912  loss_rpn_cls: 0.09253  loss_rpn_loc: 0.2014  time: 0.5888  data_time: 0.3865  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:33:38 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 1899  total_loss: 1.427  loss_cls: 0.3185  loss_box_reg: 0.5032  loss_mask: 0.3002  loss_rpn_cls: 0.08957  loss_rpn_loc: 0.1956  time: 0.5882  data_time: 0.2338  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:33:48 d2.utils.events]: \u001b[0m eta: 0:44:36  iter: 1919  total_loss: 1.424  loss_cls: 0.3192  loss_box_reg: 0.5427  loss_mask: 0.291  loss_rpn_cls: 0.08548  loss_rpn_loc: 0.1871  time: 0.5872  data_time: 0.1763  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:33:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:33:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:33:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:33:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:33:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:33:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0685 s/iter. Eval: 0.0118 s/iter. Total: 0.0808 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0152 s/iter. Total: 0.0865 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:34:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.139706 (0.087411 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:34:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070839 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:34:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:34:09 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24233828967810772\n",
      "\u001b[32m[01/03 18:34:11 d2.utils.events]: \u001b[0m eta: 0:44:24  iter: 1939  total_loss: 1.409  loss_cls: 0.3106  loss_box_reg: 0.4955  loss_mask: 0.2876  loss_rpn_cls: 0.08429  loss_rpn_loc: 0.192  time: 0.5869  data_time: 0.2523  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:34:21 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 1959  total_loss: 1.452  loss_cls: 0.3128  loss_box_reg: 0.5131  loss_mask: 0.3034  loss_rpn_cls: 0.08393  loss_rpn_loc: 0.1988  time: 0.5862  data_time: 0.2073  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:34:35 d2.utils.events]: \u001b[0m eta: 0:44:17  iter: 1979  total_loss: 1.444  loss_cls: 0.3417  loss_box_reg: 0.511  loss_mask: 0.2976  loss_rpn_cls: 0.0746  loss_rpn_loc: 0.2067  time: 0.5872  data_time: 0.3574  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:34:48 d2.utils.events]: \u001b[0m eta: 0:44:17  iter: 1999  total_loss: 1.439  loss_cls: 0.3398  loss_box_reg: 0.5008  loss_mask: 0.293  loss_rpn_cls: 0.07035  loss_rpn_loc: 0.2099  time: 0.5878  data_time: 0.3228  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:35:01 d2.utils.events]: \u001b[0m eta: 0:44:10  iter: 2019  total_loss: 1.472  loss_cls: 0.3532  loss_box_reg: 0.5317  loss_mask: 0.3008  loss_rpn_cls: 0.09364  loss_rpn_loc: 0.2132  time: 0.5884  data_time: 0.3282  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:35:12 d2.utils.events]: \u001b[0m eta: 0:44:00  iter: 2039  total_loss: 1.445  loss_cls: 0.3358  loss_box_reg: 0.5379  loss_mask: 0.3048  loss_rpn_cls: 0.09359  loss_rpn_loc: 0.1986  time: 0.5881  data_time: 0.2400  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:35:24 d2.utils.events]: \u001b[0m eta: 0:43:50  iter: 2059  total_loss: 1.4  loss_cls: 0.2781  loss_box_reg: 0.5304  loss_mask: 0.3169  loss_rpn_cls: 0.08506  loss_rpn_loc: 0.1905  time: 0.5882  data_time: 0.2785  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:35:35 d2.utils.events]: \u001b[0m eta: 0:43:50  iter: 2079  total_loss: 1.499  loss_cls: 0.3898  loss_box_reg: 0.5344  loss_mask: 0.312  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.2284  time: 0.5881  data_time: 0.2415  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:35:47 d2.utils.events]: \u001b[0m eta: 0:43:53  iter: 2099  total_loss: 1.486  loss_cls: 0.3312  loss_box_reg: 0.5075  loss_mask: 0.3103  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.2036  time: 0.5881  data_time: 0.2695  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:36:01 d2.utils.events]: \u001b[0m eta: 0:43:55  iter: 2119  total_loss: 1.541  loss_cls: 0.3848  loss_box_reg: 0.5379  loss_mask: 0.3194  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2075  time: 0.5891  data_time: 0.3605  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:36:11 d2.utils.events]: \u001b[0m eta: 0:43:48  iter: 2139  total_loss: 1.373  loss_cls: 0.2945  loss_box_reg: 0.5096  loss_mask: 0.2828  loss_rpn_cls: 0.05136  loss_rpn_loc: 0.1975  time: 0.5880  data_time: 0.1632  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:36:21 d2.utils.events]: \u001b[0m eta: 0:43:32  iter: 2159  total_loss: 1.371  loss_cls: 0.2867  loss_box_reg: 0.5323  loss_mask: 0.2939  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.1767  time: 0.5873  data_time: 0.2052  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:36:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:36:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:36:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:36:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:36:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:36:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0102 s/iter. Total: 0.0786 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0146 s/iter. Total: 0.0864 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:36:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.089959 (0.086982 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:36:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070878 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:36:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:36:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2528621572366671\n",
      "\u001b[32m[01/03 18:36:43 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 2179  total_loss: 1.448  loss_cls: 0.358  loss_box_reg: 0.5351  loss_mask: 0.3023  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.219  time: 0.5870  data_time: 0.2484  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:36:54 d2.utils.events]: \u001b[0m eta: 0:43:11  iter: 2199  total_loss: 1.397  loss_cls: 0.3023  loss_box_reg: 0.5131  loss_mask: 0.2992  loss_rpn_cls: 0.09226  loss_rpn_loc: 0.1919  time: 0.5865  data_time: 0.2195  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:37:08 d2.utils.events]: \u001b[0m eta: 0:43:12  iter: 2219  total_loss: 1.357  loss_cls: 0.311  loss_box_reg: 0.4811  loss_mask: 0.2915  loss_rpn_cls: 0.08804  loss_rpn_loc: 0.1989  time: 0.5876  data_time: 0.3828  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:37:18 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 2239  total_loss: 1.502  loss_cls: 0.3344  loss_box_reg: 0.5532  loss_mask: 0.3225  loss_rpn_cls: 0.07966  loss_rpn_loc: 0.2065  time: 0.5868  data_time: 0.1875  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:37:29 d2.utils.events]: \u001b[0m eta: 0:43:10  iter: 2259  total_loss: 1.517  loss_cls: 0.3357  loss_box_reg: 0.553  loss_mask: 0.3177  loss_rpn_cls: 0.09607  loss_rpn_loc: 0.2031  time: 0.5865  data_time: 0.2335  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:37:42 d2.utils.events]: \u001b[0m eta: 0:43:00  iter: 2279  total_loss: 1.436  loss_cls: 0.3247  loss_box_reg: 0.5281  loss_mask: 0.2994  loss_rpn_cls: 0.09409  loss_rpn_loc: 0.222  time: 0.5871  data_time: 0.3344  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:37:54 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 2299  total_loss: 1.48  loss_cls: 0.3375  loss_box_reg: 0.549  loss_mask: 0.3026  loss_rpn_cls: 0.09163  loss_rpn_loc: 0.2059  time: 0.5872  data_time: 0.2834  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:38:05 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 2319  total_loss: 1.452  loss_cls: 0.347  loss_box_reg: 0.5475  loss_mask: 0.3032  loss_rpn_cls: 0.07731  loss_rpn_loc: 0.1984  time: 0.5869  data_time: 0.2533  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:38:14 d2.utils.events]: \u001b[0m eta: 0:42:20  iter: 2339  total_loss: 1.24  loss_cls: 0.2553  loss_box_reg: 0.5014  loss_mask: 0.288  loss_rpn_cls: 0.05489  loss_rpn_loc: 0.1573  time: 0.5854  data_time: 0.1170  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:38:25 d2.utils.events]: \u001b[0m eta: 0:42:16  iter: 2359  total_loss: 1.498  loss_cls: 0.3522  loss_box_reg: 0.5269  loss_mask: 0.3166  loss_rpn_cls: 0.09391  loss_rpn_loc: 0.206  time: 0.5852  data_time: 0.2321  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:38:39 d2.utils.events]: \u001b[0m eta: 0:42:12  iter: 2379  total_loss: 1.498  loss_cls: 0.3055  loss_box_reg: 0.5145  loss_mask: 0.314  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.2185  time: 0.5862  data_time: 0.3966  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:38:54 d2.utils.events]: \u001b[0m eta: 0:42:19  iter: 2399  total_loss: 1.589  loss_cls: 0.3527  loss_box_reg: 0.5453  loss_mask: 0.3127  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.2308  time: 0.5877  data_time: 0.4286  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:39:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:39:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:39:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:39:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:39:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:39:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0108 s/iter. Total: 0.0793 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0166 s/iter. Total: 0.0907 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0730 s/iter. Eval: 0.0172 s/iter. Total: 0.0911 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 18:39:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.630409 (0.091641 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:39:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073045 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:39:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:39:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25471478253122043\n",
      "\u001b[32m[01/03 18:39:23 d2.utils.events]: \u001b[0m eta: 0:42:16  iter: 2419  total_loss: 1.538  loss_cls: 0.3714  loss_box_reg: 0.5358  loss_mask: 0.3151  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.2192  time: 0.5898  data_time: 0.4842  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:39:32 d2.utils.events]: \u001b[0m eta: 0:42:08  iter: 2439  total_loss: 1.511  loss_cls: 0.3598  loss_box_reg: 0.5618  loss_mask: 0.2874  loss_rpn_cls: 0.08831  loss_rpn_loc: 0.2028  time: 0.5887  data_time: 0.1597  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:39:41 d2.utils.events]: \u001b[0m eta: 0:42:02  iter: 2459  total_loss: 1.389  loss_cls: 0.3274  loss_box_reg: 0.5188  loss_mask: 0.2915  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.1895  time: 0.5875  data_time: 0.1310  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:39:50 d2.utils.events]: \u001b[0m eta: 0:41:53  iter: 2479  total_loss: 1.484  loss_cls: 0.3277  loss_box_reg: 0.5237  loss_mask: 0.2954  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.1922  time: 0.5866  data_time: 0.1670  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:40:02 d2.utils.events]: \u001b[0m eta: 0:41:49  iter: 2499  total_loss: 1.474  loss_cls: 0.3737  loss_box_reg: 0.5187  loss_mask: 0.2826  loss_rpn_cls: 0.07491  loss_rpn_loc: 0.2103  time: 0.5868  data_time: 0.2817  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:40:12 d2.utils.events]: \u001b[0m eta: 0:41:51  iter: 2519  total_loss: 1.529  loss_cls: 0.3222  loss_box_reg: 0.5312  loss_mask: 0.321  loss_rpn_cls: 0.1211  loss_rpn_loc: 0.2095  time: 0.5860  data_time: 0.1921  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:40:22 d2.utils.events]: \u001b[0m eta: 0:41:38  iter: 2539  total_loss: 1.356  loss_cls: 0.2942  loss_box_reg: 0.508  loss_mask: 0.2856  loss_rpn_cls: 0.05364  loss_rpn_loc: 0.1836  time: 0.5853  data_time: 0.1875  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:40:34 d2.utils.events]: \u001b[0m eta: 0:41:30  iter: 2559  total_loss: 1.4  loss_cls: 0.3285  loss_box_reg: 0.4702  loss_mask: 0.2901  loss_rpn_cls: 0.09303  loss_rpn_loc: 0.2058  time: 0.5854  data_time: 0.2795  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:40:48 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 2579  total_loss: 1.495  loss_cls: 0.3341  loss_box_reg: 0.5496  loss_mask: 0.3012  loss_rpn_cls: 0.0878  loss_rpn_loc: 0.1928  time: 0.5861  data_time: 0.3526  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:40:59 d2.utils.events]: \u001b[0m eta: 0:41:24  iter: 2599  total_loss: 1.437  loss_cls: 0.2848  loss_box_reg: 0.5347  loss_mask: 0.3086  loss_rpn_cls: 0.08354  loss_rpn_loc: 0.2173  time: 0.5861  data_time: 0.2700  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:41:15 d2.utils.events]: \u001b[0m eta: 0:41:17  iter: 2619  total_loss: 1.45  loss_cls: 0.3378  loss_box_reg: 0.493  loss_mask: 0.2936  loss_rpn_cls: 0.08643  loss_rpn_loc: 0.2041  time: 0.5875  data_time: 0.4433  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:41:28 d2.utils.events]: \u001b[0m eta: 0:41:05  iter: 2639  total_loss: 1.528  loss_cls: 0.3652  loss_box_reg: 0.5403  loss_mask: 0.3125  loss_rpn_cls: 0.08623  loss_rpn_loc: 0.2042  time: 0.5879  data_time: 0.3286  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:41:39 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 2659  total_loss: 1.404  loss_cls: 0.3095  loss_box_reg: 0.5056  loss_mask: 0.3053  loss_rpn_cls: 0.08326  loss_rpn_loc: 0.2088  time: 0.5876  data_time: 0.2155  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:41:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:41:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:41:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:41:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:41:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:41:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0101 s/iter. Total: 0.0785 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0153 s/iter. Total: 0.0877 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:41:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.356065 (0.089276 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:41:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071909 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:41:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:41:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2611684658570798\n",
      "\u001b[32m[01/03 18:41:59 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 2679  total_loss: 1.381  loss_cls: 0.3179  loss_box_reg: 0.525  loss_mask: 0.2837  loss_rpn_cls: 0.06434  loss_rpn_loc: 0.1878  time: 0.5865  data_time: 0.1333  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:42:12 d2.utils.events]: \u001b[0m eta: 0:40:42  iter: 2699  total_loss: 1.507  loss_cls: 0.3349  loss_box_reg: 0.5491  loss_mask: 0.3125  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.2035  time: 0.5869  data_time: 0.3183  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:42:21 d2.utils.events]: \u001b[0m eta: 0:40:36  iter: 2719  total_loss: 1.318  loss_cls: 0.2833  loss_box_reg: 0.5151  loss_mask: 0.2878  loss_rpn_cls: 0.05222  loss_rpn_loc: 0.1776  time: 0.5860  data_time: 0.1468  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:42:31 d2.utils.events]: \u001b[0m eta: 0:40:25  iter: 2739  total_loss: 1.378  loss_cls: 0.3087  loss_box_reg: 0.5006  loss_mask: 0.3031  loss_rpn_cls: 0.08269  loss_rpn_loc: 0.2082  time: 0.5854  data_time: 0.2147  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:42:41 d2.utils.events]: \u001b[0m eta: 0:40:16  iter: 2759  total_loss: 1.42  loss_cls: 0.3168  loss_box_reg: 0.5294  loss_mask: 0.2885  loss_rpn_cls: 0.07612  loss_rpn_loc: 0.1807  time: 0.5846  data_time: 0.1665  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:42:49 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 2779  total_loss: 1.399  loss_cls: 0.3284  loss_box_reg: 0.5375  loss_mask: 0.2938  loss_rpn_cls: 0.08449  loss_rpn_loc: 0.1908  time: 0.5834  data_time: 0.1261  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:43:03 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 2799  total_loss: 1.409  loss_cls: 0.3263  loss_box_reg: 0.5059  loss_mask: 0.2943  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.2  time: 0.5843  data_time: 0.3633  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:43:14 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 2819  total_loss: 1.496  loss_cls: 0.3422  loss_box_reg: 0.5027  loss_mask: 0.3011  loss_rpn_cls: 0.07628  loss_rpn_loc: 0.1962  time: 0.5841  data_time: 0.2403  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:43:27 d2.utils.events]: \u001b[0m eta: 0:39:50  iter: 2839  total_loss: 1.537  loss_cls: 0.3212  loss_box_reg: 0.5161  loss_mask: 0.3033  loss_rpn_cls: 0.09988  loss_rpn_loc: 0.2148  time: 0.5844  data_time: 0.3035  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:43:40 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 2859  total_loss: 1.441  loss_cls: 0.3122  loss_box_reg: 0.539  loss_mask: 0.3171  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.1899  time: 0.5847  data_time: 0.3123  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:43:53 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 2879  total_loss: 1.552  loss_cls: 0.3449  loss_box_reg: 0.5389  loss_mask: 0.3075  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2224  time: 0.5854  data_time: 0.3463  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:44:09 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 2899  total_loss: 1.453  loss_cls: 0.3282  loss_box_reg: 0.487  loss_mask: 0.321  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.2065  time: 0.5868  data_time: 0.4463  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:44:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:44:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:44:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:44:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:44:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:44:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0113 s/iter. Total: 0.0799 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0157 s/iter. Total: 0.0871 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:44:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.480595 (0.090350 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:44:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072274 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:44:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:44:22 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.260302568805093\n",
      "\u001b[32m[01/03 18:44:34 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 2919  total_loss: 1.493  loss_cls: 0.3402  loss_box_reg: 0.5317  loss_mask: 0.3043  loss_rpn_cls: 0.08826  loss_rpn_loc: 0.1962  time: 0.5872  data_time: 0.3166  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:44:45 d2.utils.events]: \u001b[0m eta: 0:39:25  iter: 2939  total_loss: 1.452  loss_cls: 0.3482  loss_box_reg: 0.5043  loss_mask: 0.2909  loss_rpn_cls: 0.09346  loss_rpn_loc: 0.2017  time: 0.5871  data_time: 0.2557  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:44:58 d2.utils.events]: \u001b[0m eta: 0:39:19  iter: 2959  total_loss: 1.433  loss_cls: 0.3251  loss_box_reg: 0.522  loss_mask: 0.3011  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2147  time: 0.5876  data_time: 0.3507  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:45:10 d2.utils.events]: \u001b[0m eta: 0:39:11  iter: 2979  total_loss: 1.378  loss_cls: 0.3011  loss_box_reg: 0.4789  loss_mask: 0.2967  loss_rpn_cls: 0.07045  loss_rpn_loc: 0.1924  time: 0.5876  data_time: 0.2724  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:45:22 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 2999  total_loss: 1.398  loss_cls: 0.3154  loss_box_reg: 0.5143  loss_mask: 0.2954  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.2034  time: 0.5877  data_time: 0.2778  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:45:33 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 3019  total_loss: 1.408  loss_cls: 0.3016  loss_box_reg: 0.5214  loss_mask: 0.3023  loss_rpn_cls: 0.08521  loss_rpn_loc: 0.198  time: 0.5874  data_time: 0.2429  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:45:45 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 3039  total_loss: 1.442  loss_cls: 0.3075  loss_box_reg: 0.4955  loss_mask: 0.3009  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.192  time: 0.5875  data_time: 0.2795  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:45:57 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 3059  total_loss: 1.421  loss_cls: 0.3371  loss_box_reg: 0.5285  loss_mask: 0.3006  loss_rpn_cls: 0.07372  loss_rpn_loc: 0.1986  time: 0.5875  data_time: 0.2814  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:46:06 d2.utils.events]: \u001b[0m eta: 0:38:37  iter: 3079  total_loss: 1.318  loss_cls: 0.3207  loss_box_reg: 0.485  loss_mask: 0.2842  loss_rpn_cls: 0.06551  loss_rpn_loc: 0.1672  time: 0.5867  data_time: 0.1635  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:46:19 d2.utils.events]: \u001b[0m eta: 0:38:30  iter: 3099  total_loss: 1.419  loss_cls: 0.3113  loss_box_reg: 0.5173  loss_mask: 0.2947  loss_rpn_cls: 0.09248  loss_rpn_loc: 0.2118  time: 0.5871  data_time: 0.3458  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:46:29 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 3119  total_loss: 1.48  loss_cls: 0.3385  loss_box_reg: 0.5452  loss_mask: 0.3036  loss_rpn_cls: 0.0679  loss_rpn_loc: 0.2014  time: 0.5866  data_time: 0.2086  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:46:39 d2.utils.events]: \u001b[0m eta: 0:38:14  iter: 3139  total_loss: 1.485  loss_cls: 0.3467  loss_box_reg: 0.5515  loss_mask: 0.3013  loss_rpn_cls: 0.06665  loss_rpn_loc: 0.1913  time: 0.5860  data_time: 0.1893  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:46:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:46:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:46:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:46:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:46:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:46:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0695 s/iter. Eval: 0.0110 s/iter. Total: 0.0810 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0714 s/iter. Eval: 0.0158 s/iter. Total: 0.0879 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:46:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.400464 (0.089659 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:46:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071592 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:46:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:46:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25876060582115906\n",
      "\u001b[32m[01/03 18:47:03 d2.utils.events]: \u001b[0m eta: 0:38:14  iter: 3159  total_loss: 1.459  loss_cls: 0.3388  loss_box_reg: 0.4851  loss_mask: 0.2994  loss_rpn_cls: 0.09734  loss_rpn_loc: 0.2379  time: 0.5863  data_time: 0.2878  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:47:16 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 3179  total_loss: 1.424  loss_cls: 0.3064  loss_box_reg: 0.5226  loss_mask: 0.3017  loss_rpn_cls: 0.09304  loss_rpn_loc: 0.2108  time: 0.5865  data_time: 0.2936  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:47:27 d2.utils.events]: \u001b[0m eta: 0:38:01  iter: 3199  total_loss: 1.41  loss_cls: 0.2868  loss_box_reg: 0.5147  loss_mask: 0.3041  loss_rpn_cls: 0.05131  loss_rpn_loc: 0.1774  time: 0.5863  data_time: 0.2411  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:47:36 d2.utils.events]: \u001b[0m eta: 0:37:53  iter: 3219  total_loss: 1.474  loss_cls: 0.3533  loss_box_reg: 0.5218  loss_mask: 0.2978  loss_rpn_cls: 0.0865  loss_rpn_loc: 0.2149  time: 0.5855  data_time: 0.1525  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:47:50 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 3239  total_loss: 1.506  loss_cls: 0.3869  loss_box_reg: 0.4801  loss_mask: 0.3017  loss_rpn_cls: 0.09324  loss_rpn_loc: 0.2105  time: 0.5861  data_time: 0.3585  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:48:00 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 3259  total_loss: 1.51  loss_cls: 0.3628  loss_box_reg: 0.5566  loss_mask: 0.2927  loss_rpn_cls: 0.09604  loss_rpn_loc: 0.2005  time: 0.5857  data_time: 0.1915  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:48:09 d2.utils.events]: \u001b[0m eta: 0:37:35  iter: 3279  total_loss: 1.387  loss_cls: 0.2872  loss_box_reg: 0.5089  loss_mask: 0.2974  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.1948  time: 0.5848  data_time: 0.1471  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:48:21 d2.utils.events]: \u001b[0m eta: 0:37:28  iter: 3299  total_loss: 1.396  loss_cls: 0.2886  loss_box_reg: 0.495  loss_mask: 0.2932  loss_rpn_cls: 0.06354  loss_rpn_loc: 0.1959  time: 0.5850  data_time: 0.2828  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:48:34 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 3319  total_loss: 1.364  loss_cls: 0.3162  loss_box_reg: 0.4951  loss_mask: 0.2935  loss_rpn_cls: 0.06669  loss_rpn_loc: 0.1943  time: 0.5853  data_time: 0.3290  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:48:45 d2.utils.events]: \u001b[0m eta: 0:37:21  iter: 3339  total_loss: 1.449  loss_cls: 0.3309  loss_box_reg: 0.5329  loss_mask: 0.2942  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.1897  time: 0.5850  data_time: 0.2195  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:48:57 d2.utils.events]: \u001b[0m eta: 0:37:14  iter: 3359  total_loss: 1.381  loss_cls: 0.3161  loss_box_reg: 0.4929  loss_mask: 0.298  loss_rpn_cls: 0.08411  loss_rpn_loc: 0.189  time: 0.5852  data_time: 0.2913  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:49:09 d2.utils.events]: \u001b[0m eta: 0:37:06  iter: 3379  total_loss: 1.455  loss_cls: 0.3354  loss_box_reg: 0.505  loss_mask: 0.3129  loss_rpn_cls: 0.05612  loss_rpn_loc: 0.2079  time: 0.5852  data_time: 0.2665  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:49:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:49:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:49:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:49:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:49:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0702 s/iter. Eval: 0.0119 s/iter. Total: 0.0827 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 18:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0157 s/iter. Total: 0.0873 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:49:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.264050 (0.088483 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:49:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071043 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:49:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:49:25 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25823578499773403\n",
      "\u001b[32m[01/03 18:49:29 d2.utils.events]: \u001b[0m eta: 0:36:53  iter: 3399  total_loss: 1.531  loss_cls: 0.3753  loss_box_reg: 0.5029  loss_mask: 0.3002  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.1921  time: 0.5844  data_time: 0.1370  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:49:39 d2.utils.events]: \u001b[0m eta: 0:36:40  iter: 3419  total_loss: 1.368  loss_cls: 0.2902  loss_box_reg: 0.5389  loss_mask: 0.2959  loss_rpn_cls: 0.06617  loss_rpn_loc: 0.1728  time: 0.5838  data_time: 0.1837  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:49:51 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 3439  total_loss: 1.423  loss_cls: 0.3599  loss_box_reg: 0.4885  loss_mask: 0.2952  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.1903  time: 0.5838  data_time: 0.2636  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:50:01 d2.utils.events]: \u001b[0m eta: 0:36:25  iter: 3459  total_loss: 1.38  loss_cls: 0.3103  loss_box_reg: 0.4958  loss_mask: 0.2953  loss_rpn_cls: 0.07043  loss_rpn_loc: 0.2106  time: 0.5833  data_time: 0.1822  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:50:13 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 3479  total_loss: 1.536  loss_cls: 0.3617  loss_box_reg: 0.5067  loss_mask: 0.3169  loss_rpn_cls: 0.09885  loss_rpn_loc: 0.2178  time: 0.5835  data_time: 0.2979  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:50:24 d2.utils.events]: \u001b[0m eta: 0:36:13  iter: 3499  total_loss: 1.386  loss_cls: 0.3186  loss_box_reg: 0.528  loss_mask: 0.2987  loss_rpn_cls: 0.05049  loss_rpn_loc: 0.1879  time: 0.5833  data_time: 0.2268  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:50:35 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 3519  total_loss: 1.475  loss_cls: 0.3526  loss_box_reg: 0.5326  loss_mask: 0.3034  loss_rpn_cls: 0.08642  loss_rpn_loc: 0.2009  time: 0.5832  data_time: 0.2652  lr: 0.0005  max_mem: 6565M\n",
      "\u001b[32m[01/03 18:50:47 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 3539  total_loss: 1.462  loss_cls: 0.3497  loss_box_reg: 0.5217  loss_mask: 0.295  loss_rpn_cls: 0.07983  loss_rpn_loc: 0.2069  time: 0.5833  data_time: 0.2745  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:51:03 d2.utils.events]: \u001b[0m eta: 0:35:58  iter: 3559  total_loss: 1.441  loss_cls: 0.3265  loss_box_reg: 0.4924  loss_mask: 0.2964  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.1976  time: 0.5845  data_time: 0.4532  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:51:13 d2.utils.events]: \u001b[0m eta: 0:35:49  iter: 3579  total_loss: 1.401  loss_cls: 0.3086  loss_box_reg: 0.539  loss_mask: 0.3041  loss_rpn_cls: 0.05697  loss_rpn_loc: 0.2021  time: 0.5840  data_time: 0.2021  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:51:25 d2.utils.events]: \u001b[0m eta: 0:35:42  iter: 3599  total_loss: 1.317  loss_cls: 0.2859  loss_box_reg: 0.5003  loss_mask: 0.2899  loss_rpn_cls: 0.08063  loss_rpn_loc: 0.1753  time: 0.5841  data_time: 0.2796  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:51:38 d2.utils.events]: \u001b[0m eta: 0:35:35  iter: 3619  total_loss: 1.432  loss_cls: 0.3436  loss_box_reg: 0.5202  loss_mask: 0.2887  loss_rpn_cls: 0.08426  loss_rpn_loc: 0.1914  time: 0.5844  data_time: 0.3166  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:51:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:51:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:51:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:51:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:51:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:51:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.0097 s/iter. Total: 0.0786 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0150 s/iter. Total: 0.0866 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:51:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.281952 (0.088638 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:51:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071435 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:51:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:51:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26348527217853024\n",
      "\u001b[32m[01/03 18:52:01 d2.utils.events]: \u001b[0m eta: 0:35:28  iter: 3639  total_loss: 1.344  loss_cls: 0.3318  loss_box_reg: 0.4869  loss_mask: 0.2777  loss_rpn_cls: 0.08014  loss_rpn_loc: 0.1853  time: 0.5843  data_time: 0.2516  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:52:12 d2.utils.events]: \u001b[0m eta: 0:35:20  iter: 3659  total_loss: 1.428  loss_cls: 0.3798  loss_box_reg: 0.5108  loss_mask: 0.2901  loss_rpn_cls: 0.08023  loss_rpn_loc: 0.1909  time: 0.5843  data_time: 0.2553  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:52:23 d2.utils.events]: \u001b[0m eta: 0:35:12  iter: 3679  total_loss: 1.543  loss_cls: 0.3367  loss_box_reg: 0.5575  loss_mask: 0.3002  loss_rpn_cls: 0.08212  loss_rpn_loc: 0.2028  time: 0.5839  data_time: 0.2113  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:52:34 d2.utils.events]: \u001b[0m eta: 0:35:05  iter: 3699  total_loss: 1.327  loss_cls: 0.2679  loss_box_reg: 0.5167  loss_mask: 0.3112  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.1827  time: 0.5836  data_time: 0.2082  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:52:45 d2.utils.events]: \u001b[0m eta: 0:35:00  iter: 3719  total_loss: 1.571  loss_cls: 0.3365  loss_box_reg: 0.5155  loss_mask: 0.3031  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2191  time: 0.5837  data_time: 0.2770  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:52:58 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 3739  total_loss: 1.408  loss_cls: 0.3198  loss_box_reg: 0.5035  loss_mask: 0.3075  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.2077  time: 0.5840  data_time: 0.3254  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:53:08 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 3759  total_loss: 1.441  loss_cls: 0.3652  loss_box_reg: 0.5176  loss_mask: 0.301  loss_rpn_cls: 0.06955  loss_rpn_loc: 0.1849  time: 0.5836  data_time: 0.1862  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:53:20 d2.utils.events]: \u001b[0m eta: 0:34:55  iter: 3779  total_loss: 1.546  loss_cls: 0.3872  loss_box_reg: 0.546  loss_mask: 0.2993  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.2224  time: 0.5835  data_time: 0.2304  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:53:32 d2.utils.events]: \u001b[0m eta: 0:34:50  iter: 3799  total_loss: 1.436  loss_cls: 0.3086  loss_box_reg: 0.5323  loss_mask: 0.3099  loss_rpn_cls: 0.07972  loss_rpn_loc: 0.1852  time: 0.5836  data_time: 0.2652  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:53:46 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 3819  total_loss: 1.411  loss_cls: 0.3226  loss_box_reg: 0.5025  loss_mask: 0.2983  loss_rpn_cls: 0.09944  loss_rpn_loc: 0.1938  time: 0.5842  data_time: 0.3789  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:54:00 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 3839  total_loss: 1.39  loss_cls: 0.3134  loss_box_reg: 0.504  loss_mask: 0.3072  loss_rpn_cls: 0.09372  loss_rpn_loc: 0.2014  time: 0.5849  data_time: 0.3921  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:54:12 d2.utils.events]: \u001b[0m eta: 0:34:39  iter: 3859  total_loss: 1.354  loss_cls: 0.3491  loss_box_reg: 0.4608  loss_mask: 0.284  loss_rpn_cls: 0.08097  loss_rpn_loc: 0.1882  time: 0.5850  data_time: 0.2742  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:54:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:54:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:54:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:54:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:54:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:54:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0686 s/iter. Eval: 0.0113 s/iter. Total: 0.0804 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0161 s/iter. Total: 0.0888 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:54:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.447973 (0.090069 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:54:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072231 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:54:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:54:30 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26421907540167383\n",
      "\u001b[32m[01/03 18:54:33 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 3879  total_loss: 1.369  loss_cls: 0.278  loss_box_reg: 0.4919  loss_mask: 0.2912  loss_rpn_cls: 0.07728  loss_rpn_loc: 0.1959  time: 0.5843  data_time: 0.1318  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:54:47 d2.utils.events]: \u001b[0m eta: 0:34:17  iter: 3899  total_loss: 1.424  loss_cls: 0.3238  loss_box_reg: 0.5002  loss_mask: 0.3085  loss_rpn_cls: 0.08345  loss_rpn_loc: 0.1786  time: 0.5850  data_time: 0.3985  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:54:56 d2.utils.events]: \u001b[0m eta: 0:34:07  iter: 3919  total_loss: 1.536  loss_cls: 0.334  loss_box_reg: 0.5445  loss_mask: 0.3059  loss_rpn_cls: 0.0803  loss_rpn_loc: 0.2023  time: 0.5842  data_time: 0.1244  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:55:07 d2.utils.events]: \u001b[0m eta: 0:33:59  iter: 3939  total_loss: 1.436  loss_cls: 0.3337  loss_box_reg: 0.4978  loss_mask: 0.3008  loss_rpn_cls: 0.08664  loss_rpn_loc: 0.1928  time: 0.5842  data_time: 0.2580  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:55:17 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 3959  total_loss: 1.359  loss_cls: 0.3106  loss_box_reg: 0.4921  loss_mask: 0.2953  loss_rpn_cls: 0.08336  loss_rpn_loc: 0.1952  time: 0.5836  data_time: 0.1690  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:55:28 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 3979  total_loss: 1.456  loss_cls: 0.3442  loss_box_reg: 0.5177  loss_mask: 0.3004  loss_rpn_cls: 0.08633  loss_rpn_loc: 0.1931  time: 0.5834  data_time: 0.2431  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:55:40 d2.utils.events]: \u001b[0m eta: 0:33:35  iter: 3999  total_loss: 1.401  loss_cls: 0.2864  loss_box_reg: 0.502  loss_mask: 0.3088  loss_rpn_cls: 0.08388  loss_rpn_loc: 0.2159  time: 0.5836  data_time: 0.2975  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:55:52 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 4019  total_loss: 1.331  loss_cls: 0.317  loss_box_reg: 0.482  loss_mask: 0.2938  loss_rpn_cls: 0.06886  loss_rpn_loc: 0.1762  time: 0.5837  data_time: 0.2761  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:56:05 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 4039  total_loss: 1.528  loss_cls: 0.3252  loss_box_reg: 0.5294  loss_mask: 0.3097  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.2258  time: 0.5839  data_time: 0.3130  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:56:16 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 4059  total_loss: 1.484  loss_cls: 0.3234  loss_box_reg: 0.517  loss_mask: 0.3065  loss_rpn_cls: 0.09333  loss_rpn_loc: 0.2315  time: 0.5837  data_time: 0.2330  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:56:26 d2.utils.events]: \u001b[0m eta: 0:33:17  iter: 4079  total_loss: 1.404  loss_cls: 0.3346  loss_box_reg: 0.5338  loss_mask: 0.2983  loss_rpn_cls: 0.08882  loss_rpn_loc: 0.1844  time: 0.5833  data_time: 0.2027  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:56:40 d2.utils.events]: \u001b[0m eta: 0:33:10  iter: 4099  total_loss: 1.393  loss_cls: 0.3327  loss_box_reg: 0.5068  loss_mask: 0.3044  loss_rpn_cls: 0.0614  loss_rpn_loc: 0.1783  time: 0.5840  data_time: 0.3962  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:56:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:56:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:56:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:56:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:56:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:56:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0729 s/iter. Eval: 0.0112 s/iter. Total: 0.0847 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 18:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0714 s/iter. Eval: 0.0155 s/iter. Total: 0.0877 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:56:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.345516 (0.089185 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:56:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071607 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:56:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:56:57 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26371097281028505\n",
      "\u001b[32m[01/03 18:57:00 d2.utils.events]: \u001b[0m eta: 0:33:01  iter: 4119  total_loss: 1.431  loss_cls: 0.3188  loss_box_reg: 0.5311  loss_mask: 0.3126  loss_rpn_cls: 0.06177  loss_rpn_loc: 0.1903  time: 0.5830  data_time: 0.0784  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:57:09 d2.utils.events]: \u001b[0m eta: 0:32:52  iter: 4139  total_loss: 1.378  loss_cls: 0.3038  loss_box_reg: 0.5103  loss_mask: 0.284  loss_rpn_cls: 0.05611  loss_rpn_loc: 0.1871  time: 0.5824  data_time: 0.1518  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:57:21 d2.utils.events]: \u001b[0m eta: 0:32:40  iter: 4159  total_loss: 1.418  loss_cls: 0.3555  loss_box_reg: 0.4753  loss_mask: 0.2991  loss_rpn_cls: 0.08276  loss_rpn_loc: 0.2063  time: 0.5825  data_time: 0.2777  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:57:34 d2.utils.events]: \u001b[0m eta: 0:32:35  iter: 4179  total_loss: 1.465  loss_cls: 0.3349  loss_box_reg: 0.5123  loss_mask: 0.2986  loss_rpn_cls: 0.08382  loss_rpn_loc: 0.2121  time: 0.5828  data_time: 0.3283  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:57:46 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 4199  total_loss: 1.462  loss_cls: 0.3382  loss_box_reg: 0.504  loss_mask: 0.2969  loss_rpn_cls: 0.09266  loss_rpn_loc: 0.2035  time: 0.5829  data_time: 0.2890  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:58:01 d2.utils.events]: \u001b[0m eta: 0:32:33  iter: 4219  total_loss: 1.478  loss_cls: 0.3407  loss_box_reg: 0.5157  loss_mask: 0.3042  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.2182  time: 0.5836  data_time: 0.3975  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:58:13 d2.utils.events]: \u001b[0m eta: 0:32:22  iter: 4239  total_loss: 1.47  loss_cls: 0.3565  loss_box_reg: 0.5356  loss_mask: 0.3152  loss_rpn_cls: 0.06724  loss_rpn_loc: 0.1935  time: 0.5838  data_time: 0.2949  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:58:22 d2.utils.events]: \u001b[0m eta: 0:32:16  iter: 4259  total_loss: 1.308  loss_cls: 0.2885  loss_box_reg: 0.5157  loss_mask: 0.2874  loss_rpn_cls: 0.06195  loss_rpn_loc: 0.1819  time: 0.5832  data_time: 0.1548  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:58:33 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 4279  total_loss: 1.402  loss_cls: 0.3244  loss_box_reg: 0.5118  loss_mask: 0.2993  loss_rpn_cls: 0.09409  loss_rpn_loc: 0.1959  time: 0.5830  data_time: 0.2229  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:58:46 d2.utils.events]: \u001b[0m eta: 0:32:08  iter: 4299  total_loss: 1.283  loss_cls: 0.3014  loss_box_reg: 0.464  loss_mask: 0.2768  loss_rpn_cls: 0.06855  loss_rpn_loc: 0.1978  time: 0.5834  data_time: 0.3545  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:58:57 d2.utils.events]: \u001b[0m eta: 0:31:59  iter: 4319  total_loss: 1.377  loss_cls: 0.3059  loss_box_reg: 0.505  loss_mask: 0.299  loss_rpn_cls: 0.0918  loss_rpn_loc: 0.2038  time: 0.5831  data_time: 0.2243  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:59:05 d2.utils.events]: \u001b[0m eta: 0:31:52  iter: 4339  total_loss: 1.345  loss_cls: 0.2943  loss_box_reg: 0.5464  loss_mask: 0.3094  loss_rpn_cls: 0.05641  loss_rpn_loc: 0.1796  time: 0.5823  data_time: 0.1006  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:59:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:59:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 18:59:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 18:59:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 18:59:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 18:59:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 18:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0105 s/iter. Total: 0.0793 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 18:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0152 s/iter. Total: 0.0866 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 18:59:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.207622 (0.087997 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:59:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071022 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 18:59:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 18:59:28 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26257868182952404\n",
      "\u001b[32m[01/03 18:59:31 d2.utils.events]: \u001b[0m eta: 0:31:45  iter: 4359  total_loss: 1.457  loss_cls: 0.3127  loss_box_reg: 0.5298  loss_mask: 0.3057  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.2206  time: 0.5829  data_time: 0.3864  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:59:40 d2.utils.events]: \u001b[0m eta: 0:31:34  iter: 4379  total_loss: 1.351  loss_cls: 0.2882  loss_box_reg: 0.5078  loss_mask: 0.2997  loss_rpn_cls: 0.05388  loss_rpn_loc: 0.1795  time: 0.5824  data_time: 0.1681  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 18:59:53 d2.utils.events]: \u001b[0m eta: 0:31:29  iter: 4399  total_loss: 1.549  loss_cls: 0.3694  loss_box_reg: 0.4921  loss_mask: 0.3101  loss_rpn_cls: 0.103  loss_rpn_loc: 0.2141  time: 0.5828  data_time: 0.3392  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:00:05 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 4419  total_loss: 1.371  loss_cls: 0.3402  loss_box_reg: 0.4956  loss_mask: 0.2994  loss_rpn_cls: 0.07994  loss_rpn_loc: 0.1848  time: 0.5828  data_time: 0.2737  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:00:17 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 4439  total_loss: 1.389  loss_cls: 0.3177  loss_box_reg: 0.4934  loss_mask: 0.3086  loss_rpn_cls: 0.09811  loss_rpn_loc: 0.1956  time: 0.5827  data_time: 0.2588  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:00:29 d2.utils.events]: \u001b[0m eta: 0:31:16  iter: 4459  total_loss: 1.505  loss_cls: 0.3426  loss_box_reg: 0.5245  loss_mask: 0.3179  loss_rpn_cls: 0.07537  loss_rpn_loc: 0.2024  time: 0.5829  data_time: 0.2855  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:00:40 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 4479  total_loss: 1.377  loss_cls: 0.3075  loss_box_reg: 0.4926  loss_mask: 0.2938  loss_rpn_cls: 0.05924  loss_rpn_loc: 0.1752  time: 0.5828  data_time: 0.2419  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:00:51 d2.utils.events]: \u001b[0m eta: 0:31:02  iter: 4499  total_loss: 1.366  loss_cls: 0.3093  loss_box_reg: 0.4827  loss_mask: 0.2876  loss_rpn_cls: 0.07655  loss_rpn_loc: 0.2017  time: 0.5826  data_time: 0.2292  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:01:02 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 4519  total_loss: 1.407  loss_cls: 0.3138  loss_box_reg: 0.5252  loss_mask: 0.3185  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.1825  time: 0.5824  data_time: 0.2310  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:01:15 d2.utils.events]: \u001b[0m eta: 0:30:47  iter: 4539  total_loss: 1.46  loss_cls: 0.3245  loss_box_reg: 0.5029  loss_mask: 0.3042  loss_rpn_cls: 0.0809  loss_rpn_loc: 0.1995  time: 0.5827  data_time: 0.3516  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:01:26 d2.utils.events]: \u001b[0m eta: 0:30:35  iter: 4559  total_loss: 1.41  loss_cls: 0.3136  loss_box_reg: 0.5215  loss_mask: 0.3036  loss_rpn_cls: 0.08328  loss_rpn_loc: 0.1996  time: 0.5827  data_time: 0.2481  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:01:38 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 4579  total_loss: 1.473  loss_cls: 0.3549  loss_box_reg: 0.5293  loss_mask: 0.2917  loss_rpn_cls: 0.06639  loss_rpn_loc: 0.1851  time: 0.5826  data_time: 0.2553  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:01:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:01:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:01:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:01:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:01:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:01:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0688 s/iter. Eval: 0.0106 s/iter. Total: 0.0800 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0155 s/iter. Total: 0.0873 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:01:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.306628 (0.088850 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:01:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071329 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:01:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:01:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2612718682156752\n",
      "\u001b[32m[01/03 19:02:00 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 4599  total_loss: 1.375  loss_cls: 0.3121  loss_box_reg: 0.4902  loss_mask: 0.2931  loss_rpn_cls: 0.06405  loss_rpn_loc: 0.181  time: 0.5824  data_time: 0.2173  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:02:11 d2.utils.events]: \u001b[0m eta: 0:30:12  iter: 4619  total_loss: 1.353  loss_cls: 0.3067  loss_box_reg: 0.5207  loss_mask: 0.287  loss_rpn_cls: 0.06121  loss_rpn_loc: 0.1754  time: 0.5823  data_time: 0.2396  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:02:23 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 4639  total_loss: 1.294  loss_cls: 0.2636  loss_box_reg: 0.4806  loss_mask: 0.2911  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.19  time: 0.5824  data_time: 0.3046  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:02:33 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 4659  total_loss: 1.393  loss_cls: 0.2928  loss_box_reg: 0.5326  loss_mask: 0.2977  loss_rpn_cls: 0.06099  loss_rpn_loc: 0.192  time: 0.5819  data_time: 0.1693  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:02:42 d2.utils.events]: \u001b[0m eta: 0:29:51  iter: 4679  total_loss: 1.36  loss_cls: 0.2957  loss_box_reg: 0.5132  loss_mask: 0.2863  loss_rpn_cls: 0.072  loss_rpn_loc: 0.1769  time: 0.5815  data_time: 0.1810  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:02:54 d2.utils.events]: \u001b[0m eta: 0:29:45  iter: 4699  total_loss: 1.529  loss_cls: 0.3258  loss_box_reg: 0.5278  loss_mask: 0.3059  loss_rpn_cls: 0.08615  loss_rpn_loc: 0.2147  time: 0.5816  data_time: 0.2812  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:03:05 d2.utils.events]: \u001b[0m eta: 0:29:37  iter: 4719  total_loss: 1.432  loss_cls: 0.3416  loss_box_reg: 0.5465  loss_mask: 0.3077  loss_rpn_cls: 0.08662  loss_rpn_loc: 0.1929  time: 0.5815  data_time: 0.2474  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:03:15 d2.utils.events]: \u001b[0m eta: 0:29:30  iter: 4739  total_loss: 1.413  loss_cls: 0.3454  loss_box_reg: 0.4893  loss_mask: 0.3002  loss_rpn_cls: 0.08043  loss_rpn_loc: 0.1982  time: 0.5810  data_time: 0.1529  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:03:27 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 4759  total_loss: 1.308  loss_cls: 0.2997  loss_box_reg: 0.476  loss_mask: 0.2834  loss_rpn_cls: 0.07156  loss_rpn_loc: 0.1832  time: 0.5812  data_time: 0.3060  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:03:39 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 4779  total_loss: 1.343  loss_cls: 0.3318  loss_box_reg: 0.4819  loss_mask: 0.2943  loss_rpn_cls: 0.06063  loss_rpn_loc: 0.1879  time: 0.5812  data_time: 0.2531  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:03:51 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 4799  total_loss: 1.433  loss_cls: 0.3099  loss_box_reg: 0.5351  loss_mask: 0.3145  loss_rpn_cls: 0.06977  loss_rpn_loc: 0.1977  time: 0.5814  data_time: 0.3056  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:04:04 d2.utils.events]: \u001b[0m eta: 0:29:00  iter: 4819  total_loss: 1.388  loss_cls: 0.3226  loss_box_reg: 0.5101  loss_mask: 0.2993  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.1942  time: 0.5816  data_time: 0.3081  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:04:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:04:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:04:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:04:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:04:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:04:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:04:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0694 s/iter. Eval: 0.0109 s/iter. Total: 0.0808 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:04:30 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0729 s/iter. Eval: 0.0160 s/iter. Total: 0.0897 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:04:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.549729 (0.090946 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:04:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073262 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:04:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:04:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2669540526957906\n",
      "\u001b[32m[01/03 19:04:35 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 4839  total_loss: 1.488  loss_cls: 0.3572  loss_box_reg: 0.4932  loss_mask: 0.3087  loss_rpn_cls: 0.1214  loss_rpn_loc: 0.2124  time: 0.5831  data_time: 0.5765  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:04:45 d2.utils.events]: \u001b[0m eta: 0:28:44  iter: 4859  total_loss: 1.448  loss_cls: 0.3493  loss_box_reg: 0.5036  loss_mask: 0.3029  loss_rpn_cls: 0.09331  loss_rpn_loc: 0.2111  time: 0.5828  data_time: 0.2048  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:04:57 d2.utils.events]: \u001b[0m eta: 0:28:35  iter: 4879  total_loss: 1.393  loss_cls: 0.3337  loss_box_reg: 0.4916  loss_mask: 0.2956  loss_rpn_cls: 0.06117  loss_rpn_loc: 0.2033  time: 0.5829  data_time: 0.2679  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:05:06 d2.utils.events]: \u001b[0m eta: 0:28:28  iter: 4899  total_loss: 1.459  loss_cls: 0.345  loss_box_reg: 0.547  loss_mask: 0.2954  loss_rpn_cls: 0.06655  loss_rpn_loc: 0.2119  time: 0.5823  data_time: 0.1394  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:05:17 d2.utils.events]: \u001b[0m eta: 0:28:24  iter: 4919  total_loss: 1.313  loss_cls: 0.2856  loss_box_reg: 0.4753  loss_mask: 0.2877  loss_rpn_cls: 0.06162  loss_rpn_loc: 0.1814  time: 0.5822  data_time: 0.2253  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:05:31 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 4939  total_loss: 1.441  loss_cls: 0.3293  loss_box_reg: 0.4852  loss_mask: 0.3012  loss_rpn_cls: 0.08652  loss_rpn_loc: 0.21  time: 0.5825  data_time: 0.3465  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:05:43 d2.utils.events]: \u001b[0m eta: 0:28:15  iter: 4959  total_loss: 1.369  loss_cls: 0.3332  loss_box_reg: 0.5086  loss_mask: 0.3135  loss_rpn_cls: 0.0585  loss_rpn_loc: 0.1811  time: 0.5827  data_time: 0.3076  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:06:00 d2.utils.events]: \u001b[0m eta: 0:28:11  iter: 4979  total_loss: 1.589  loss_cls: 0.3783  loss_box_reg: 0.4954  loss_mask: 0.3254  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.204  time: 0.5837  data_time: 0.4779  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:06:11 d2.utils.events]: \u001b[0m eta: 0:28:02  iter: 4999  total_loss: 1.404  loss_cls: 0.2812  loss_box_reg: 0.5175  loss_mask: 0.303  loss_rpn_cls: 0.07735  loss_rpn_loc: 0.1978  time: 0.5836  data_time: 0.2535  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:06:23 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 5019  total_loss: 1.282  loss_cls: 0.2749  loss_box_reg: 0.4781  loss_mask: 0.2832  loss_rpn_cls: 0.05757  loss_rpn_loc: 0.1814  time: 0.5837  data_time: 0.3038  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:06:34 d2.utils.events]: \u001b[0m eta: 0:27:42  iter: 5039  total_loss: 1.274  loss_cls: 0.3297  loss_box_reg: 0.4967  loss_mask: 0.2924  loss_rpn_cls: 0.04769  loss_rpn_loc: 0.1736  time: 0.5835  data_time: 0.2042  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:06:46 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 5059  total_loss: 1.379  loss_cls: 0.3154  loss_box_reg: 0.4724  loss_mask: 0.294  loss_rpn_cls: 0.08288  loss_rpn_loc: 0.1948  time: 0.5836  data_time: 0.3047  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:06:57 d2.utils.events]: \u001b[0m eta: 0:27:30  iter: 5079  total_loss: 1.308  loss_cls: 0.2924  loss_box_reg: 0.5131  loss_mask: 0.2886  loss_rpn_cls: 0.06135  loss_rpn_loc: 0.1817  time: 0.5835  data_time: 0.2385  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:06:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:06:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:06:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:06:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:06:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:06:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:07:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.0108 s/iter. Total: 0.0797 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:07:05 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0159 s/iter. Total: 0.0871 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:07:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.303791 (0.088826 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:07:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070909 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:07:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:07:10 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2675423839341109\n",
      "\u001b[32m[01/03 19:07:21 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 5099  total_loss: 1.464  loss_cls: 0.3576  loss_box_reg: 0.4772  loss_mask: 0.2958  loss_rpn_cls: 0.08838  loss_rpn_loc: 0.2175  time: 0.5836  data_time: 0.2796  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:07:37 d2.utils.events]: \u001b[0m eta: 0:27:21  iter: 5119  total_loss: 1.412  loss_cls: 0.3301  loss_box_reg: 0.4534  loss_mask: 0.2962  loss_rpn_cls: 0.08532  loss_rpn_loc: 0.1948  time: 0.5845  data_time: 0.4928  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:07:48 d2.utils.events]: \u001b[0m eta: 0:27:16  iter: 5139  total_loss: 1.36  loss_cls: 0.3221  loss_box_reg: 0.5091  loss_mask: 0.285  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1908  time: 0.5843  data_time: 0.2256  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:08:00 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 5159  total_loss: 1.367  loss_cls: 0.3002  loss_box_reg: 0.5067  loss_mask: 0.2912  loss_rpn_cls: 0.06699  loss_rpn_loc: 0.1977  time: 0.5844  data_time: 0.3134  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:08:10 d2.utils.events]: \u001b[0m eta: 0:26:56  iter: 5179  total_loss: 1.449  loss_cls: 0.3625  loss_box_reg: 0.5187  loss_mask: 0.2825  loss_rpn_cls: 0.0769  loss_rpn_loc: 0.1919  time: 0.5840  data_time: 0.1689  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:08:23 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 5199  total_loss: 1.294  loss_cls: 0.2788  loss_box_reg: 0.4815  loss_mask: 0.2967  loss_rpn_cls: 0.06951  loss_rpn_loc: 0.1654  time: 0.5844  data_time: 0.3654  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:08:35 d2.utils.events]: \u001b[0m eta: 0:26:41  iter: 5219  total_loss: 1.301  loss_cls: 0.2683  loss_box_reg: 0.4706  loss_mask: 0.3067  loss_rpn_cls: 0.07461  loss_rpn_loc: 0.1854  time: 0.5843  data_time: 0.2528  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:08:48 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 5239  total_loss: 1.487  loss_cls: 0.358  loss_box_reg: 0.5313  loss_mask: 0.2993  loss_rpn_cls: 0.07941  loss_rpn_loc: 0.2079  time: 0.5846  data_time: 0.3217  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:08:56 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 5259  total_loss: 1.383  loss_cls: 0.2813  loss_box_reg: 0.5275  loss_mask: 0.2956  loss_rpn_cls: 0.05406  loss_rpn_loc: 0.1841  time: 0.5839  data_time: 0.1149  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:09:04 d2.utils.events]: \u001b[0m eta: 0:26:17  iter: 5279  total_loss: 1.445  loss_cls: 0.3011  loss_box_reg: 0.5167  loss_mask: 0.2929  loss_rpn_cls: 0.05273  loss_rpn_loc: 0.1769  time: 0.5832  data_time: 0.0893  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:09:16 d2.utils.events]: \u001b[0m eta: 0:26:12  iter: 5299  total_loss: 1.419  loss_cls: 0.326  loss_box_reg: 0.4901  loss_mask: 0.2966  loss_rpn_cls: 0.08599  loss_rpn_loc: 0.1865  time: 0.5833  data_time: 0.2810  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:09:28 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 5319  total_loss: 1.418  loss_cls: 0.3403  loss_box_reg: 0.5194  loss_mask: 0.2977  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.198  time: 0.5834  data_time: 0.2738  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:09:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:09:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:09:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:09:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:09:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:09:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0765 s/iter. Eval: 0.0119 s/iter. Total: 0.0890 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0008 s/iter. Inference: 0.0742 s/iter. Eval: 0.0153 s/iter. Total: 0.0903 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:09:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.472929 (0.090284 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:09:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073491 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:09:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:09:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25755043768260427\n",
      "\u001b[32m[01/03 19:09:52 d2.utils.events]: \u001b[0m eta: 0:26:02  iter: 5339  total_loss: 1.412  loss_cls: 0.2986  loss_box_reg: 0.4934  loss_mask: 0.3112  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.1971  time: 0.5836  data_time: 0.3103  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:10:06 d2.utils.events]: \u001b[0m eta: 0:25:56  iter: 5359  total_loss: 1.396  loss_cls: 0.3069  loss_box_reg: 0.4958  loss_mask: 0.3023  loss_rpn_cls: 0.0972  loss_rpn_loc: 0.1952  time: 0.5839  data_time: 0.3530  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:10:18 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 5379  total_loss: 1.361  loss_cls: 0.3092  loss_box_reg: 0.5245  loss_mask: 0.2994  loss_rpn_cls: 0.05508  loss_rpn_loc: 0.1866  time: 0.5839  data_time: 0.2453  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:10:29 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 5399  total_loss: 1.515  loss_cls: 0.3276  loss_box_reg: 0.507  loss_mask: 0.3105  loss_rpn_cls: 0.09883  loss_rpn_loc: 0.2118  time: 0.5838  data_time: 0.2382  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:10:39 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 5419  total_loss: 1.31  loss_cls: 0.3016  loss_box_reg: 0.5157  loss_mask: 0.292  loss_rpn_cls: 0.05304  loss_rpn_loc: 0.1847  time: 0.5834  data_time: 0.1577  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:10:49 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 5439  total_loss: 1.343  loss_cls: 0.275  loss_box_reg: 0.5091  loss_mask: 0.2904  loss_rpn_cls: 0.0612  loss_rpn_loc: 0.1824  time: 0.5833  data_time: 0.2358  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:11:03 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 5459  total_loss: 1.372  loss_cls: 0.3186  loss_box_reg: 0.4943  loss_mask: 0.2872  loss_rpn_cls: 0.05877  loss_rpn_loc: 0.1919  time: 0.5836  data_time: 0.3548  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:11:17 d2.utils.events]: \u001b[0m eta: 0:25:21  iter: 5479  total_loss: 1.323  loss_cls: 0.3051  loss_box_reg: 0.4602  loss_mask: 0.3006  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.2096  time: 0.5841  data_time: 0.3929  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:11:29 d2.utils.events]: \u001b[0m eta: 0:25:13  iter: 5499  total_loss: 1.281  loss_cls: 0.2855  loss_box_reg: 0.4912  loss_mask: 0.2843  loss_rpn_cls: 0.0547  loss_rpn_loc: 0.1659  time: 0.5841  data_time: 0.2537  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:11:42 d2.utils.events]: \u001b[0m eta: 0:25:09  iter: 5519  total_loss: 1.519  loss_cls: 0.3717  loss_box_reg: 0.533  loss_mask: 0.2996  loss_rpn_cls: 0.08699  loss_rpn_loc: 0.1967  time: 0.5843  data_time: 0.3253  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:11:55 d2.utils.events]: \u001b[0m eta: 0:25:05  iter: 5539  total_loss: 1.448  loss_cls: 0.3584  loss_box_reg: 0.5203  loss_mask: 0.3052  loss_rpn_cls: 0.09806  loss_rpn_loc: 0.1962  time: 0.5846  data_time: 0.3409  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:12:05 d2.utils.events]: \u001b[0m eta: 0:24:56  iter: 5559  total_loss: 1.419  loss_cls: 0.3263  loss_box_reg: 0.5091  loss_mask: 0.3021  loss_rpn_cls: 0.06977  loss_rpn_loc: 0.1842  time: 0.5843  data_time: 0.1810  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:12:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:12:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:12:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:12:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:12:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:12:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:12:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0150 s/iter. Total: 0.0860 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:12:15 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0731 s/iter. Eval: 0.0173 s/iter. Total: 0.0912 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/03 19:12:20 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0737 s/iter. Eval: 0.0181 s/iter. Total: 0.0926 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:12:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.808684 (0.093178 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:12:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073698 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:12:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:12:20 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.263612732980733\n",
      "\u001b[32m[01/03 19:12:30 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 5579  total_loss: 1.399  loss_cls: 0.3081  loss_box_reg: 0.5004  loss_mask: 0.3187  loss_rpn_cls: 0.0941  loss_rpn_loc: 0.1974  time: 0.5845  data_time: 0.3033  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:12:45 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 5599  total_loss: 1.381  loss_cls: 0.3212  loss_box_reg: 0.5128  loss_mask: 0.3031  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.2013  time: 0.5851  data_time: 0.4367  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:13:00 d2.utils.events]: \u001b[0m eta: 0:24:43  iter: 5619  total_loss: 1.502  loss_cls: 0.3466  loss_box_reg: 0.5068  loss_mask: 0.3146  loss_rpn_cls: 0.08146  loss_rpn_loc: 0.1999  time: 0.5856  data_time: 0.4054  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:13:10 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 5639  total_loss: 1.321  loss_cls: 0.2758  loss_box_reg: 0.4976  loss_mask: 0.2887  loss_rpn_cls: 0.05825  loss_rpn_loc: 0.1746  time: 0.5853  data_time: 0.1792  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:13:24 d2.utils.events]: \u001b[0m eta: 0:24:31  iter: 5659  total_loss: 1.346  loss_cls: 0.3042  loss_box_reg: 0.5008  loss_mask: 0.2807  loss_rpn_cls: 0.07289  loss_rpn_loc: 0.1814  time: 0.5857  data_time: 0.3683  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:13:34 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 5679  total_loss: 1.364  loss_cls: 0.3175  loss_box_reg: 0.5245  loss_mask: 0.2999  loss_rpn_cls: 0.05729  loss_rpn_loc: 0.1667  time: 0.5854  data_time: 0.1634  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:13:47 d2.utils.events]: \u001b[0m eta: 0:24:20  iter: 5699  total_loss: 1.285  loss_cls: 0.2743  loss_box_reg: 0.4952  loss_mask: 0.298  loss_rpn_cls: 0.05647  loss_rpn_loc: 0.1922  time: 0.5857  data_time: 0.3401  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:13:59 d2.utils.events]: \u001b[0m eta: 0:24:15  iter: 5719  total_loss: 1.401  loss_cls: 0.3431  loss_box_reg: 0.4965  loss_mask: 0.3079  loss_rpn_cls: 0.07923  loss_rpn_loc: 0.1984  time: 0.5858  data_time: 0.2835  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:14:11 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 5739  total_loss: 1.374  loss_cls: 0.3035  loss_box_reg: 0.5272  loss_mask: 0.3083  loss_rpn_cls: 0.07808  loss_rpn_loc: 0.1968  time: 0.5857  data_time: 0.2543  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:14:24 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 5759  total_loss: 1.368  loss_cls: 0.3051  loss_box_reg: 0.5068  loss_mask: 0.3124  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1989  time: 0.5861  data_time: 0.3684  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:14:35 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 5779  total_loss: 1.373  loss_cls: 0.3104  loss_box_reg: 0.5151  loss_mask: 0.2917  loss_rpn_cls: 0.06206  loss_rpn_loc: 0.1742  time: 0.5859  data_time: 0.2123  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:14:46 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 5799  total_loss: 1.405  loss_cls: 0.3246  loss_box_reg: 0.5115  loss_mask: 0.3002  loss_rpn_cls: 0.0917  loss_rpn_loc: 0.1956  time: 0.5858  data_time: 0.2413  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:14:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:14:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:14:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:14:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:14:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:14:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0732 s/iter. Eval: 0.0122 s/iter. Total: 0.0860 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0011 s/iter. Inference: 0.0745 s/iter. Eval: 0.0206 s/iter. Total: 0.0963 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/03 19:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0010 s/iter. Inference: 0.0739 s/iter. Eval: 0.0202 s/iter. Total: 0.0951 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:15:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.124600 (0.095902 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:15:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073902 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:15:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:15:04 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2681563603188805\n",
      "\u001b[32m[01/03 19:15:14 d2.utils.events]: \u001b[0m eta: 0:23:39  iter: 5819  total_loss: 1.395  loss_cls: 0.3411  loss_box_reg: 0.4886  loss_mask: 0.2864  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.1903  time: 0.5863  data_time: 0.3932  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:15:29 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 5839  total_loss: 1.411  loss_cls: 0.3467  loss_box_reg: 0.4866  loss_mask: 0.3092  loss_rpn_cls: 0.07716  loss_rpn_loc: 0.2091  time: 0.5870  data_time: 0.4490  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:15:43 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 5859  total_loss: 1.368  loss_cls: 0.3122  loss_box_reg: 0.474  loss_mask: 0.3098  loss_rpn_cls: 0.09012  loss_rpn_loc: 0.2032  time: 0.5874  data_time: 0.3742  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:15:54 d2.utils.events]: \u001b[0m eta: 0:23:17  iter: 5879  total_loss: 1.407  loss_cls: 0.3157  loss_box_reg: 0.5146  loss_mask: 0.2782  loss_rpn_cls: 0.071  loss_rpn_loc: 0.1782  time: 0.5871  data_time: 0.2014  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:16:07 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 5899  total_loss: 1.428  loss_cls: 0.3045  loss_box_reg: 0.4731  loss_mask: 0.2917  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.2025  time: 0.5874  data_time: 0.3252  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:16:20 d2.utils.events]: \u001b[0m eta: 0:23:07  iter: 5919  total_loss: 1.4  loss_cls: 0.3227  loss_box_reg: 0.5239  loss_mask: 0.3004  loss_rpn_cls: 0.07893  loss_rpn_loc: 0.1914  time: 0.5876  data_time: 0.3015  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:16:30 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 5939  total_loss: 1.359  loss_cls: 0.2817  loss_box_reg: 0.525  loss_mask: 0.2668  loss_rpn_cls: 0.05738  loss_rpn_loc: 0.1639  time: 0.5874  data_time: 0.2123  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:16:43 d2.utils.events]: \u001b[0m eta: 0:22:52  iter: 5959  total_loss: 1.253  loss_cls: 0.2864  loss_box_reg: 0.4699  loss_mask: 0.2737  loss_rpn_cls: 0.05881  loss_rpn_loc: 0.1717  time: 0.5876  data_time: 0.3127  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:16:54 d2.utils.events]: \u001b[0m eta: 0:22:41  iter: 5979  total_loss: 1.393  loss_cls: 0.3009  loss_box_reg: 0.5109  loss_mask: 0.292  loss_rpn_cls: 0.06365  loss_rpn_loc: 0.1928  time: 0.5874  data_time: 0.2100  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:17:08 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 5999  total_loss: 1.369  loss_cls: 0.2762  loss_box_reg: 0.4886  loss_mask: 0.3007  loss_rpn_cls: 0.07626  loss_rpn_loc: 0.1997  time: 0.5877  data_time: 0.3400  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:17:18 d2.utils.events]: \u001b[0m eta: 0:22:28  iter: 6019  total_loss: 1.429  loss_cls: 0.3037  loss_box_reg: 0.5227  loss_mask: 0.313  loss_rpn_cls: 0.07941  loss_rpn_loc: 0.2014  time: 0.5875  data_time: 0.2102  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:17:31 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 6039  total_loss: 1.374  loss_cls: 0.2735  loss_box_reg: 0.5041  loss_mask: 0.2933  loss_rpn_cls: 0.06196  loss_rpn_loc: 0.1848  time: 0.5877  data_time: 0.3142  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:17:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:17:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:17:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:17:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:17:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:17:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0743 s/iter. Eval: 0.0131 s/iter. Total: 0.0882 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0759 s/iter. Eval: 0.0177 s/iter. Total: 0.0944 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/03 19:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0761 s/iter. Eval: 0.0180 s/iter. Total: 0.0950 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:17:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.107748 (0.095756 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:17:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076209 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:17:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:17:51 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2674511515977241\n",
      "\u001b[32m[01/03 19:17:59 d2.utils.events]: \u001b[0m eta: 0:22:19  iter: 6059  total_loss: 1.438  loss_cls: 0.3211  loss_box_reg: 0.5235  loss_mask: 0.3081  loss_rpn_cls: 0.09338  loss_rpn_loc: 0.1835  time: 0.5883  data_time: 0.4253  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:18:11 d2.utils.events]: \u001b[0m eta: 0:22:14  iter: 6079  total_loss: 1.339  loss_cls: 0.3055  loss_box_reg: 0.4665  loss_mask: 0.2817  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.1732  time: 0.5884  data_time: 0.2841  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:18:24 d2.utils.events]: \u001b[0m eta: 0:22:09  iter: 6099  total_loss: 1.427  loss_cls: 0.3267  loss_box_reg: 0.5078  loss_mask: 0.3069  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2073  time: 0.5886  data_time: 0.3176  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:18:39 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 6119  total_loss: 1.372  loss_cls: 0.3164  loss_box_reg: 0.4867  loss_mask: 0.2863  loss_rpn_cls: 0.08387  loss_rpn_loc: 0.1762  time: 0.5890  data_time: 0.3980  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:18:50 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 6139  total_loss: 1.234  loss_cls: 0.2764  loss_box_reg: 0.4875  loss_mask: 0.2765  loss_rpn_cls: 0.04584  loss_rpn_loc: 0.1666  time: 0.5889  data_time: 0.2448  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:19:01 d2.utils.events]: \u001b[0m eta: 0:21:50  iter: 6159  total_loss: 1.462  loss_cls: 0.334  loss_box_reg: 0.5406  loss_mask: 0.3074  loss_rpn_cls: 0.07438  loss_rpn_loc: 0.203  time: 0.5888  data_time: 0.2249  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:19:09 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 6179  total_loss: 1.305  loss_cls: 0.2802  loss_box_reg: 0.5015  loss_mask: 0.2841  loss_rpn_cls: 0.03919  loss_rpn_loc: 0.1966  time: 0.5882  data_time: 0.0886  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:19:22 d2.utils.events]: \u001b[0m eta: 0:21:35  iter: 6199  total_loss: 1.428  loss_cls: 0.3142  loss_box_reg: 0.487  loss_mask: 0.2851  loss_rpn_cls: 0.08872  loss_rpn_loc: 0.1965  time: 0.5885  data_time: 0.3825  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:19:31 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 6219  total_loss: 1.324  loss_cls: 0.2968  loss_box_reg: 0.5068  loss_mask: 0.2973  loss_rpn_cls: 0.05791  loss_rpn_loc: 0.1908  time: 0.5880  data_time: 0.1245  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:19:42 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 6239  total_loss: 1.471  loss_cls: 0.3187  loss_box_reg: 0.5567  loss_mask: 0.3104  loss_rpn_cls: 0.05952  loss_rpn_loc: 0.18  time: 0.5878  data_time: 0.2336  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:19:54 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 6259  total_loss: 1.438  loss_cls: 0.3334  loss_box_reg: 0.5246  loss_mask: 0.3017  loss_rpn_cls: 0.07369  loss_rpn_loc: 0.1882  time: 0.5879  data_time: 0.2724  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:20:07 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 6279  total_loss: 1.276  loss_cls: 0.3106  loss_box_reg: 0.4616  loss_mask: 0.2866  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.1773  time: 0.5880  data_time: 0.3059  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:20:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:20:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:20:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:20:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:20:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:20:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0731 s/iter. Eval: 0.0137 s/iter. Total: 0.0876 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0759 s/iter. Eval: 0.0174 s/iter. Total: 0.0941 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/03 19:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0179 s/iter. Total: 0.0947 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:20:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.089272 (0.095597 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:20:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076099 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:20:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:20:27 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27044429169316847\n",
      "\u001b[32m[01/03 19:20:34 d2.utils.events]: \u001b[0m eta: 0:21:05  iter: 6299  total_loss: 1.385  loss_cls: 0.3235  loss_box_reg: 0.4978  loss_mask: 0.2908  loss_rpn_cls: 0.084  loss_rpn_loc: 0.1787  time: 0.5884  data_time: 0.3751  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:20:48 d2.utils.events]: \u001b[0m eta: 0:20:59  iter: 6319  total_loss: 1.453  loss_cls: 0.3185  loss_box_reg: 0.5302  loss_mask: 0.3128  loss_rpn_cls: 0.07795  loss_rpn_loc: 0.2052  time: 0.5889  data_time: 0.3942  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:21:02 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 6339  total_loss: 1.302  loss_cls: 0.2883  loss_box_reg: 0.4664  loss_mask: 0.2794  loss_rpn_cls: 0.05039  loss_rpn_loc: 0.1627  time: 0.5893  data_time: 0.3857  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:21:14 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 6359  total_loss: 1.343  loss_cls: 0.3002  loss_box_reg: 0.4736  loss_mask: 0.2833  loss_rpn_cls: 0.04447  loss_rpn_loc: 0.2049  time: 0.5892  data_time: 0.2481  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:21:27 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 6379  total_loss: 1.426  loss_cls: 0.3316  loss_box_reg: 0.5246  loss_mask: 0.3084  loss_rpn_cls: 0.06693  loss_rpn_loc: 0.2055  time: 0.5894  data_time: 0.3277  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:21:40 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 6399  total_loss: 1.382  loss_cls: 0.3027  loss_box_reg: 0.5185  loss_mask: 0.2974  loss_rpn_cls: 0.06822  loss_rpn_loc: 0.1889  time: 0.5896  data_time: 0.3241  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:21:53 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 6419  total_loss: 1.462  loss_cls: 0.3403  loss_box_reg: 0.4873  loss_mask: 0.3007  loss_rpn_cls: 0.0962  loss_rpn_loc: 0.2045  time: 0.5897  data_time: 0.2996  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:22:05 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 6439  total_loss: 1.382  loss_cls: 0.3035  loss_box_reg: 0.481  loss_mask: 0.3209  loss_rpn_cls: 0.07755  loss_rpn_loc: 0.1959  time: 0.5898  data_time: 0.2801  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:22:14 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 6459  total_loss: 1.404  loss_cls: 0.2889  loss_box_reg: 0.4996  loss_mask: 0.2834  loss_rpn_cls: 0.06754  loss_rpn_loc: 0.1967  time: 0.5894  data_time: 0.1770  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:22:25 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 6479  total_loss: 1.409  loss_cls: 0.3204  loss_box_reg: 0.5346  loss_mask: 0.2932  loss_rpn_cls: 0.06619  loss_rpn_loc: 0.1823  time: 0.5893  data_time: 0.2321  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:22:36 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 6499  total_loss: 1.388  loss_cls: 0.3269  loss_box_reg: 0.5229  loss_mask: 0.2897  loss_rpn_cls: 0.07317  loss_rpn_loc: 0.2073  time: 0.5891  data_time: 0.2209  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:22:45 d2.utils.events]: \u001b[0m eta: 0:19:52  iter: 6519  total_loss: 1.252  loss_cls: 0.2519  loss_box_reg: 0.4733  loss_mask: 0.2872  loss_rpn_cls: 0.04942  loss_rpn_loc: 0.1672  time: 0.5887  data_time: 0.1547  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:22:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:22:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:22:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:22:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:22:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:22:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0102 s/iter. Total: 0.0784 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0169 s/iter. Total: 0.0883 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:23:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.427887 (0.089896 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:23:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071123 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:23:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:23:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2655377128421721\n",
      "\u001b[32m[01/03 19:23:11 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 6539  total_loss: 1.295  loss_cls: 0.319  loss_box_reg: 0.4921  loss_mask: 0.3075  loss_rpn_cls: 0.06697  loss_rpn_loc: 0.1818  time: 0.5892  data_time: 0.4232  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:23:23 d2.utils.events]: \u001b[0m eta: 0:19:40  iter: 6559  total_loss: 1.388  loss_cls: 0.3177  loss_box_reg: 0.4751  loss_mask: 0.2992  loss_rpn_cls: 0.09958  loss_rpn_loc: 0.2027  time: 0.5891  data_time: 0.2506  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:23:32 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 6579  total_loss: 1.364  loss_cls: 0.3346  loss_box_reg: 0.5178  loss_mask: 0.2989  loss_rpn_cls: 0.05977  loss_rpn_loc: 0.1855  time: 0.5888  data_time: 0.1854  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:23:44 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 6599  total_loss: 1.307  loss_cls: 0.2788  loss_box_reg: 0.4847  loss_mask: 0.2827  loss_rpn_cls: 0.07611  loss_rpn_loc: 0.1686  time: 0.5888  data_time: 0.2660  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:24:02 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 6619  total_loss: 1.408  loss_cls: 0.3281  loss_box_reg: 0.4544  loss_mask: 0.3086  loss_rpn_cls: 0.08468  loss_rpn_loc: 0.2002  time: 0.5897  data_time: 0.5657  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:24:12 d2.utils.events]: \u001b[0m eta: 0:19:09  iter: 6639  total_loss: 1.415  loss_cls: 0.3008  loss_box_reg: 0.5421  loss_mask: 0.3039  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.1968  time: 0.5894  data_time: 0.1664  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:24:26 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 6659  total_loss: 1.364  loss_cls: 0.297  loss_box_reg: 0.4631  loss_mask: 0.3012  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.2009  time: 0.5898  data_time: 0.4040  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:24:37 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 6679  total_loss: 1.395  loss_cls: 0.3253  loss_box_reg: 0.501  loss_mask: 0.2746  loss_rpn_cls: 0.08173  loss_rpn_loc: 0.1944  time: 0.5896  data_time: 0.2394  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:24:49 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 6699  total_loss: 1.373  loss_cls: 0.2986  loss_box_reg: 0.497  loss_mask: 0.2978  loss_rpn_cls: 0.05864  loss_rpn_loc: 0.1932  time: 0.5896  data_time: 0.2715  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:24:58 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 6719  total_loss: 1.35  loss_cls: 0.3155  loss_box_reg: 0.4943  loss_mask: 0.2952  loss_rpn_cls: 0.06069  loss_rpn_loc: 0.188  time: 0.5893  data_time: 0.1565  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:25:10 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 6739  total_loss: 1.312  loss_cls: 0.2894  loss_box_reg: 0.4869  loss_mask: 0.284  loss_rpn_cls: 0.04699  loss_rpn_loc: 0.1846  time: 0.5893  data_time: 0.2854  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:25:23 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 6759  total_loss: 1.432  loss_cls: 0.3152  loss_box_reg: 0.5077  loss_mask: 0.3032  loss_rpn_cls: 0.0845  loss_rpn_loc: 0.1874  time: 0.5895  data_time: 0.3597  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:25:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:25:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:25:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:25:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:25:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:25:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:25:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0681 s/iter. Eval: 0.0116 s/iter. Total: 0.0804 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:25:37 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0153 s/iter. Total: 0.0862 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:25:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.186635 (0.087816 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:25:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070510 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:25:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:25:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26816187147420445\n",
      "\u001b[32m[01/03 19:25:44 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 6779  total_loss: 1.337  loss_cls: 0.2969  loss_box_reg: 0.499  loss_mask: 0.3002  loss_rpn_cls: 0.04719  loss_rpn_loc: 0.1767  time: 0.5892  data_time: 0.1682  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:26:00 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 6799  total_loss: 1.424  loss_cls: 0.3195  loss_box_reg: 0.4994  loss_mask: 0.3043  loss_rpn_cls: 0.07271  loss_rpn_loc: 0.1843  time: 0.5897  data_time: 0.4576  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:26:10 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 6819  total_loss: 1.328  loss_cls: 0.3118  loss_box_reg: 0.4925  loss_mask: 0.2917  loss_rpn_cls: 0.0729  loss_rpn_loc: 0.1699  time: 0.5894  data_time: 0.1764  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:26:25 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 6839  total_loss: 1.308  loss_cls: 0.2804  loss_box_reg: 0.4853  loss_mask: 0.2995  loss_rpn_cls: 0.07777  loss_rpn_loc: 0.1877  time: 0.5899  data_time: 0.4225  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:26:34 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 6859  total_loss: 1.474  loss_cls: 0.3382  loss_box_reg: 0.5321  loss_mask: 0.3088  loss_rpn_cls: 0.0828  loss_rpn_loc: 0.2029  time: 0.5896  data_time: 0.1715  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:26:47 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 6879  total_loss: 1.388  loss_cls: 0.3073  loss_box_reg: 0.4922  loss_mask: 0.3106  loss_rpn_cls: 0.07208  loss_rpn_loc: 0.206  time: 0.5897  data_time: 0.3043  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:26:58 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 6899  total_loss: 1.285  loss_cls: 0.3276  loss_box_reg: 0.4873  loss_mask: 0.2807  loss_rpn_cls: 0.06724  loss_rpn_loc: 0.1743  time: 0.5895  data_time: 0.2412  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:27:05 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 6919  total_loss: 1.362  loss_cls: 0.2876  loss_box_reg: 0.5123  loss_mask: 0.2925  loss_rpn_cls: 0.05307  loss_rpn_loc: 0.1727  time: 0.5889  data_time: 0.0799  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:27:17 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 6939  total_loss: 1.448  loss_cls: 0.3176  loss_box_reg: 0.4945  loss_mask: 0.3029  loss_rpn_cls: 0.08577  loss_rpn_loc: 0.2038  time: 0.5890  data_time: 0.3016  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:27:27 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 6959  total_loss: 1.371  loss_cls: 0.3291  loss_box_reg: 0.4895  loss_mask: 0.295  loss_rpn_cls: 0.05481  loss_rpn_loc: 0.1792  time: 0.5887  data_time: 0.1608  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:27:37 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 6979  total_loss: 1.438  loss_cls: 0.3437  loss_box_reg: 0.5102  loss_mask: 0.2915  loss_rpn_cls: 0.07041  loss_rpn_loc: 0.1827  time: 0.5884  data_time: 0.1840  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:27:52 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 6999  total_loss: 1.435  loss_cls: 0.3047  loss_box_reg: 0.5324  loss_mask: 0.2869  loss_rpn_cls: 0.08887  loss_rpn_loc: 0.201  time: 0.5888  data_time: 0.4258  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:28:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:28:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:28:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:28:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:28:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:28:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0684 s/iter. Eval: 0.0112 s/iter. Total: 0.0802 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0163 s/iter. Total: 0.0877 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:28:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.410840 (0.089749 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:28:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071171 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:28:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:28:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26290572566434145\n",
      "\u001b[32m[01/03 19:28:15 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 7019  total_loss: 1.433  loss_cls: 0.3439  loss_box_reg: 0.5278  loss_mask: 0.2955  loss_rpn_cls: 0.08164  loss_rpn_loc: 0.2043  time: 0.5888  data_time: 0.2552  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:28:27 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 7039  total_loss: 1.326  loss_cls: 0.3106  loss_box_reg: 0.482  loss_mask: 0.2901  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.1766  time: 0.5889  data_time: 0.3115  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:28:39 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 7059  total_loss: 1.414  loss_cls: 0.3715  loss_box_reg: 0.5004  loss_mask: 0.2932  loss_rpn_cls: 0.06895  loss_rpn_loc: 0.1816  time: 0.5889  data_time: 0.2487  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:28:51 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 7079  total_loss: 1.447  loss_cls: 0.3408  loss_box_reg: 0.5079  loss_mask: 0.2798  loss_rpn_cls: 0.08749  loss_rpn_loc: 0.2024  time: 0.5889  data_time: 0.2773  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:29:01 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 7099  total_loss: 1.445  loss_cls: 0.3118  loss_box_reg: 0.5021  loss_mask: 0.3091  loss_rpn_cls: 0.06164  loss_rpn_loc: 0.1826  time: 0.5887  data_time: 0.2181  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:29:09 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 7119  total_loss: 1.311  loss_cls: 0.267  loss_box_reg: 0.5064  loss_mask: 0.2852  loss_rpn_cls: 0.05216  loss_rpn_loc: 0.1835  time: 0.5882  data_time: 0.1086  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:29:21 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 7139  total_loss: 1.381  loss_cls: 0.3215  loss_box_reg: 0.4864  loss_mask: 0.2857  loss_rpn_cls: 0.08362  loss_rpn_loc: 0.1886  time: 0.5881  data_time: 0.2657  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:29:32 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 7159  total_loss: 1.446  loss_cls: 0.3251  loss_box_reg: 0.505  loss_mask: 0.3106  loss_rpn_cls: 0.0743  loss_rpn_loc: 0.1924  time: 0.5881  data_time: 0.2555  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:29:45 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 7179  total_loss: 1.247  loss_cls: 0.2484  loss_box_reg: 0.4633  loss_mask: 0.2929  loss_rpn_cls: 0.06553  loss_rpn_loc: 0.1805  time: 0.5882  data_time: 0.3318  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:29:58 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 7199  total_loss: 1.444  loss_cls: 0.2962  loss_box_reg: 0.5042  loss_mask: 0.3184  loss_rpn_cls: 0.06331  loss_rpn_loc: 0.187  time: 0.5885  data_time: 0.3507  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:30:12 d2.utils.events]: \u001b[0m eta: 0:15:39  iter: 7219  total_loss: 1.581  loss_cls: 0.3275  loss_box_reg: 0.5047  loss_mask: 0.3105  loss_rpn_cls: 0.113  loss_rpn_loc: 0.2189  time: 0.5887  data_time: 0.3428  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:30:24 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 7239  total_loss: 1.351  loss_cls: 0.3128  loss_box_reg: 0.4819  loss_mask: 0.2982  loss_rpn_cls: 0.0745  loss_rpn_loc: 0.1779  time: 0.5887  data_time: 0.2924  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:30:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:30:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:30:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:30:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:30:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:30:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:30:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0102 s/iter. Total: 0.0784 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:30:41 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0157 s/iter. Total: 0.0869 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:30:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.304473 (0.088832 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:30:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:30:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:30:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.264436582354972\n",
      "\u001b[32m[01/03 19:30:46 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 7259  total_loss: 1.415  loss_cls: 0.3134  loss_box_reg: 0.4907  loss_mask: 0.2926  loss_rpn_cls: 0.07258  loss_rpn_loc: 0.1734  time: 0.5885  data_time: 0.2024  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:30:59 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 7279  total_loss: 1.313  loss_cls: 0.294  loss_box_reg: 0.4823  loss_mask: 0.2969  loss_rpn_cls: 0.069  loss_rpn_loc: 0.1875  time: 0.5887  data_time: 0.3432  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:31:08 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 7299  total_loss: 1.428  loss_cls: 0.3359  loss_box_reg: 0.5365  loss_mask: 0.2956  loss_rpn_cls: 0.07707  loss_rpn_loc: 0.185  time: 0.5883  data_time: 0.1470  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:31:18 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 7319  total_loss: 1.385  loss_cls: 0.3162  loss_box_reg: 0.4665  loss_mask: 0.2947  loss_rpn_cls: 0.06234  loss_rpn_loc: 0.1884  time: 0.5881  data_time: 0.2075  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:31:30 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 7339  total_loss: 1.369  loss_cls: 0.3103  loss_box_reg: 0.5131  loss_mask: 0.2986  loss_rpn_cls: 0.06975  loss_rpn_loc: 0.1996  time: 0.5882  data_time: 0.2993  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:31:45 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 7359  total_loss: 1.399  loss_cls: 0.3286  loss_box_reg: 0.5059  loss_mask: 0.3045  loss_rpn_cls: 0.08886  loss_rpn_loc: 0.2088  time: 0.5886  data_time: 0.4182  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:31:56 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 7379  total_loss: 1.308  loss_cls: 0.2885  loss_box_reg: 0.4905  loss_mask: 0.2993  loss_rpn_cls: 0.06424  loss_rpn_loc: 0.1687  time: 0.5884  data_time: 0.2028  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:32:06 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 7399  total_loss: 1.393  loss_cls: 0.283  loss_box_reg: 0.5255  loss_mask: 0.2947  loss_rpn_cls: 0.07295  loss_rpn_loc: 0.1823  time: 0.5882  data_time: 0.2057  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:32:20 d2.utils.events]: \u001b[0m eta: 0:14:15  iter: 7419  total_loss: 1.354  loss_cls: 0.3079  loss_box_reg: 0.4862  loss_mask: 0.3072  loss_rpn_cls: 0.07686  loss_rpn_loc: 0.2036  time: 0.5885  data_time: 0.3609  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:32:31 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 7439  total_loss: 1.323  loss_cls: 0.3054  loss_box_reg: 0.4693  loss_mask: 0.2947  loss_rpn_cls: 0.05611  loss_rpn_loc: 0.1799  time: 0.5885  data_time: 0.2616  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:32:42 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 7459  total_loss: 1.32  loss_cls: 0.2963  loss_box_reg: 0.4883  loss_mask: 0.287  loss_rpn_cls: 0.06311  loss_rpn_loc: 0.1754  time: 0.5884  data_time: 0.2423  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:32:58 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 7479  total_loss: 1.459  loss_cls: 0.329  loss_box_reg: 0.5023  loss_mask: 0.2936  loss_rpn_cls: 0.08871  loss_rpn_loc: 0.2116  time: 0.5889  data_time: 0.4518  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:33:09 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 7499  total_loss: 1.456  loss_cls: 0.3455  loss_box_reg: 0.5092  loss_mask: 0.3055  loss_rpn_cls: 0.08426  loss_rpn_loc: 0.2077  time: 0.5888  data_time: 0.2618  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:33:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:33:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:33:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:33:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:33:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:33:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0100 s/iter. Total: 0.0808 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0153 s/iter. Total: 0.0887 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:33:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.327761 (0.089032 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:33:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071983 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:33:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:33:22 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26550362496073915\n",
      "\u001b[32m[01/03 19:33:32 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 7519  total_loss: 1.404  loss_cls: 0.3029  loss_box_reg: 0.5149  loss_mask: 0.2821  loss_rpn_cls: 0.08366  loss_rpn_loc: 0.1923  time: 0.5887  data_time: 0.2396  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:33:47 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 7539  total_loss: 1.408  loss_cls: 0.3122  loss_box_reg: 0.4978  loss_mask: 0.2963  loss_rpn_cls: 0.07488  loss_rpn_loc: 0.1929  time: 0.5891  data_time: 0.4114  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:33:57 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 7559  total_loss: 1.434  loss_cls: 0.3389  loss_box_reg: 0.5227  loss_mask: 0.3142  loss_rpn_cls: 0.07961  loss_rpn_loc: 0.1964  time: 0.5889  data_time: 0.1897  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:34:09 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 7579  total_loss: 1.421  loss_cls: 0.3059  loss_box_reg: 0.5109  loss_mask: 0.297  loss_rpn_cls: 0.07528  loss_rpn_loc: 0.2084  time: 0.5890  data_time: 0.3224  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:34:18 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 7599  total_loss: 1.439  loss_cls: 0.323  loss_box_reg: 0.5149  loss_mask: 0.3008  loss_rpn_cls: 0.07059  loss_rpn_loc: 0.2042  time: 0.5886  data_time: 0.1578  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:34:27 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 7619  total_loss: 1.349  loss_cls: 0.281  loss_box_reg: 0.5031  loss_mask: 0.2942  loss_rpn_cls: 0.05368  loss_rpn_loc: 0.1698  time: 0.5882  data_time: 0.1497  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:34:39 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 7639  total_loss: 1.441  loss_cls: 0.3122  loss_box_reg: 0.4908  loss_mask: 0.2909  loss_rpn_cls: 0.0785  loss_rpn_loc: 0.206  time: 0.5882  data_time: 0.2459  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:34:50 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 7659  total_loss: 1.384  loss_cls: 0.3199  loss_box_reg: 0.497  loss_mask: 0.2868  loss_rpn_cls: 0.06309  loss_rpn_loc: 0.1804  time: 0.5881  data_time: 0.2583  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:35:02 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 7679  total_loss: 1.259  loss_cls: 0.2518  loss_box_reg: 0.4431  loss_mask: 0.2794  loss_rpn_cls: 0.06601  loss_rpn_loc: 0.1757  time: 0.5881  data_time: 0.2844  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:35:16 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 7699  total_loss: 1.428  loss_cls: 0.3308  loss_box_reg: 0.5022  loss_mask: 0.2953  loss_rpn_cls: 0.09667  loss_rpn_loc: 0.2059  time: 0.5884  data_time: 0.3702  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:35:29 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 7719  total_loss: 1.42  loss_cls: 0.3553  loss_box_reg: 0.4862  loss_mask: 0.2939  loss_rpn_cls: 0.08287  loss_rpn_loc: 0.2013  time: 0.5887  data_time: 0.3535  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:35:41 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 7739  total_loss: 1.393  loss_cls: 0.3159  loss_box_reg: 0.4986  loss_mask: 0.3107  loss_rpn_cls: 0.07917  loss_rpn_loc: 0.1872  time: 0.5887  data_time: 0.2818  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:35:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:35:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:35:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:35:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:35:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:35:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:35:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0112 s/iter. Total: 0.0800 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0718 s/iter. Eval: 0.0161 s/iter. Total: 0.0887 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:35:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.445468 (0.090047 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:35:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072018 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:35:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2610309542149342\n",
      "\u001b[32m[01/03 19:36:03 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 7759  total_loss: 1.287  loss_cls: 0.2652  loss_box_reg: 0.4761  loss_mask: 0.303  loss_rpn_cls: 0.04841  loss_rpn_loc: 0.1815  time: 0.5885  data_time: 0.1945  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:36:14 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 7779  total_loss: 1.392  loss_cls: 0.3126  loss_box_reg: 0.4951  loss_mask: 0.2973  loss_rpn_cls: 0.06738  loss_rpn_loc: 0.1916  time: 0.5883  data_time: 0.2215  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:36:28 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 7799  total_loss: 1.421  loss_cls: 0.3046  loss_box_reg: 0.4867  loss_mask: 0.2928  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1956  time: 0.5886  data_time: 0.3516  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:36:40 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 7819  total_loss: 1.416  loss_cls: 0.3131  loss_box_reg: 0.4878  loss_mask: 0.3021  loss_rpn_cls: 0.05395  loss_rpn_loc: 0.194  time: 0.5887  data_time: 0.3096  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:36:54 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 7839  total_loss: 1.394  loss_cls: 0.3178  loss_box_reg: 0.5027  loss_mask: 0.3064  loss_rpn_cls: 0.071  loss_rpn_loc: 0.1935  time: 0.5889  data_time: 0.3492  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:37:05 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 7859  total_loss: 1.329  loss_cls: 0.2941  loss_box_reg: 0.4907  loss_mask: 0.294  loss_rpn_cls: 0.04966  loss_rpn_loc: 0.1818  time: 0.5888  data_time: 0.2248  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:37:17 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 7879  total_loss: 1.431  loss_cls: 0.3187  loss_box_reg: 0.5311  loss_mask: 0.3155  loss_rpn_cls: 0.07885  loss_rpn_loc: 0.2061  time: 0.5889  data_time: 0.3059  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:37:29 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 7899  total_loss: 1.327  loss_cls: 0.2911  loss_box_reg: 0.5125  loss_mask: 0.2833  loss_rpn_cls: 0.06395  loss_rpn_loc: 0.1767  time: 0.5889  data_time: 0.2507  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:37:40 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 7919  total_loss: 1.344  loss_cls: 0.2944  loss_box_reg: 0.4915  loss_mask: 0.2979  loss_rpn_cls: 0.03971  loss_rpn_loc: 0.1777  time: 0.5888  data_time: 0.2373  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:37:50 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 7939  total_loss: 1.344  loss_cls: 0.2886  loss_box_reg: 0.5061  loss_mask: 0.2986  loss_rpn_cls: 0.05477  loss_rpn_loc: 0.175  time: 0.5886  data_time: 0.2065  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:38:02 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 7959  total_loss: 1.392  loss_cls: 0.3357  loss_box_reg: 0.4657  loss_mask: 0.2794  loss_rpn_cls: 0.06077  loss_rpn_loc: 0.186  time: 0.5886  data_time: 0.2451  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:38:15 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 7979  total_loss: 1.381  loss_cls: 0.309  loss_box_reg: 0.4841  loss_mask: 0.2885  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.2013  time: 0.5888  data_time: 0.3422  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:38:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:38:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:38:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:38:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:38:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:38:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0752 s/iter. Eval: 0.0130 s/iter. Total: 0.0891 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0764 s/iter. Eval: 0.0169 s/iter. Total: 0.0940 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/03 19:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0754 s/iter. Eval: 0.0169 s/iter. Total: 0.0931 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:38:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.871412 (0.093719 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:38:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075456 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:38:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:38:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2668315583198088\n",
      "\u001b[32m[01/03 19:38:39 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 7999  total_loss: 1.333  loss_cls: 0.3019  loss_box_reg: 0.4709  loss_mask: 0.2901  loss_rpn_cls: 0.08435  loss_rpn_loc: 0.1912  time: 0.5888  data_time: 0.2338  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:38:52 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 8019  total_loss: 1.384  loss_cls: 0.3094  loss_box_reg: 0.5047  loss_mask: 0.3035  loss_rpn_cls: 0.07554  loss_rpn_loc: 0.1823  time: 0.5889  data_time: 0.2884  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:39:02 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 8039  total_loss: 1.307  loss_cls: 0.3261  loss_box_reg: 0.4861  loss_mask: 0.2787  loss_rpn_cls: 0.08195  loss_rpn_loc: 0.1889  time: 0.5887  data_time: 0.2131  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:39:17 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 8059  total_loss: 1.304  loss_cls: 0.3021  loss_box_reg: 0.4739  loss_mask: 0.2948  loss_rpn_cls: 0.08752  loss_rpn_loc: 0.1868  time: 0.5890  data_time: 0.3836  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:39:29 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 8079  total_loss: 1.419  loss_cls: 0.3368  loss_box_reg: 0.5221  loss_mask: 0.3116  loss_rpn_cls: 0.06776  loss_rpn_loc: 0.1886  time: 0.5891  data_time: 0.3003  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:39:41 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 8099  total_loss: 1.331  loss_cls: 0.3221  loss_box_reg: 0.5098  loss_mask: 0.2856  loss_rpn_cls: 0.0787  loss_rpn_loc: 0.2055  time: 0.5892  data_time: 0.2911  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:39:54 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 8119  total_loss: 1.432  loss_cls: 0.3048  loss_box_reg: 0.496  loss_mask: 0.3188  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.1827  time: 0.5893  data_time: 0.3202  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:40:07 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 8139  total_loss: 1.438  loss_cls: 0.3267  loss_box_reg: 0.5213  loss_mask: 0.313  loss_rpn_cls: 0.09617  loss_rpn_loc: 0.1968  time: 0.5894  data_time: 0.3054  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:40:19 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 8159  total_loss: 1.401  loss_cls: 0.3142  loss_box_reg: 0.4825  loss_mask: 0.3013  loss_rpn_cls: 0.09003  loss_rpn_loc: 0.2097  time: 0.5895  data_time: 0.3015  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:40:31 d2.utils.events]: \u001b[0m eta: 0:10:17  iter: 8179  total_loss: 1.436  loss_cls: 0.3596  loss_box_reg: 0.5146  loss_mask: 0.3009  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.1943  time: 0.5895  data_time: 0.2533  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:40:41 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 8199  total_loss: 1.284  loss_cls: 0.2674  loss_box_reg: 0.4825  loss_mask: 0.2822  loss_rpn_cls: 0.05859  loss_rpn_loc: 0.1862  time: 0.5893  data_time: 0.2135  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:40:52 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 8219  total_loss: 1.343  loss_cls: 0.3242  loss_box_reg: 0.494  loss_mask: 0.2892  loss_rpn_cls: 0.05488  loss_rpn_loc: 0.184  time: 0.5892  data_time: 0.2256  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:40:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:40:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:40:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:40:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:40:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:40:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:40:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0736 s/iter. Eval: 0.0122 s/iter. Total: 0.0867 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:41:03 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0771 s/iter. Eval: 0.0169 s/iter. Total: 0.0948 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/03 19:41:08 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0771 s/iter. Eval: 0.0172 s/iter. Total: 0.0951 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:41:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.104530 (0.095729 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:41:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077145 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:41:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:41:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2680701150419449\n",
      "\u001b[32m[01/03 19:41:12 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 8239  total_loss: 1.311  loss_cls: 0.2824  loss_box_reg: 0.5027  loss_mask: 0.2861  loss_rpn_cls: 0.04986  loss_rpn_loc: 0.1673  time: 0.5887  data_time: 0.0617  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:41:24 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 8259  total_loss: 1.237  loss_cls: 0.2558  loss_box_reg: 0.4812  loss_mask: 0.2842  loss_rpn_cls: 0.04325  loss_rpn_loc: 0.1535  time: 0.5887  data_time: 0.2564  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:41:38 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 8279  total_loss: 1.385  loss_cls: 0.3102  loss_box_reg: 0.4653  loss_mask: 0.3006  loss_rpn_cls: 0.08317  loss_rpn_loc: 0.1874  time: 0.5890  data_time: 0.3881  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:41:51 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 8299  total_loss: 1.284  loss_cls: 0.2989  loss_box_reg: 0.4734  loss_mask: 0.2856  loss_rpn_cls: 0.05947  loss_rpn_loc: 0.1787  time: 0.5891  data_time: 0.2943  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:42:04 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 8319  total_loss: 1.34  loss_cls: 0.297  loss_box_reg: 0.4866  loss_mask: 0.2824  loss_rpn_cls: 0.07341  loss_rpn_loc: 0.176  time: 0.5892  data_time: 0.3444  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:42:14 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 8339  total_loss: 1.354  loss_cls: 0.3162  loss_box_reg: 0.476  loss_mask: 0.27  loss_rpn_cls: 0.07424  loss_rpn_loc: 0.1851  time: 0.5890  data_time: 0.1905  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:42:28 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 8359  total_loss: 1.356  loss_cls: 0.3117  loss_box_reg: 0.4716  loss_mask: 0.2998  loss_rpn_cls: 0.07066  loss_rpn_loc: 0.1996  time: 0.5893  data_time: 0.3707  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:42:35 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 8379  total_loss: 1.262  loss_cls: 0.2788  loss_box_reg: 0.4924  loss_mask: 0.302  loss_rpn_cls: 0.03578  loss_rpn_loc: 0.1797  time: 0.5887  data_time: 0.0430  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:42:48 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 8399  total_loss: 1.341  loss_cls: 0.3155  loss_box_reg: 0.4881  loss_mask: 0.2961  loss_rpn_cls: 0.06702  loss_rpn_loc: 0.1883  time: 0.5888  data_time: 0.3017  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:43:01 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 8419  total_loss: 1.501  loss_cls: 0.3516  loss_box_reg: 0.5186  loss_mask: 0.3092  loss_rpn_cls: 0.07936  loss_rpn_loc: 0.1992  time: 0.5889  data_time: 0.3060  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:43:11 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 8439  total_loss: 1.468  loss_cls: 0.3328  loss_box_reg: 0.5461  loss_mask: 0.2903  loss_rpn_cls: 0.07289  loss_rpn_loc: 0.1808  time: 0.5888  data_time: 0.1928  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:43:22 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 8459  total_loss: 1.421  loss_cls: 0.3165  loss_box_reg: 0.5407  loss_mask: 0.2992  loss_rpn_cls: 0.06667  loss_rpn_loc: 0.183  time: 0.5887  data_time: 0.2372  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:43:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:43:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:43:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:43:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:43:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:43:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0683 s/iter. Eval: 0.0108 s/iter. Total: 0.0798 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0165 s/iter. Total: 0.0893 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0734 s/iter. Eval: 0.0173 s/iter. Total: 0.0915 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:43:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.669967 (0.091982 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:43:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073377 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:43:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:43:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25759229123411614\n",
      "\u001b[32m[01/03 19:43:45 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 8479  total_loss: 1.43  loss_cls: 0.3025  loss_box_reg: 0.4949  loss_mask: 0.313  loss_rpn_cls: 0.08061  loss_rpn_loc: 0.2013  time: 0.5886  data_time: 0.2040  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:43:55 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 8499  total_loss: 1.324  loss_cls: 0.2731  loss_box_reg: 0.5209  loss_mask: 0.2985  loss_rpn_cls: 0.05666  loss_rpn_loc: 0.157  time: 0.5885  data_time: 0.2006  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:44:06 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 8519  total_loss: 1.323  loss_cls: 0.3001  loss_box_reg: 0.4943  loss_mask: 0.285  loss_rpn_cls: 0.06001  loss_rpn_loc: 0.1775  time: 0.5883  data_time: 0.1797  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:44:15 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 8539  total_loss: 1.276  loss_cls: 0.2789  loss_box_reg: 0.4928  loss_mask: 0.2787  loss_rpn_cls: 0.04945  loss_rpn_loc: 0.1747  time: 0.5880  data_time: 0.1429  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:44:26 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 8559  total_loss: 1.385  loss_cls: 0.3064  loss_box_reg: 0.5106  loss_mask: 0.2903  loss_rpn_cls: 0.08245  loss_rpn_loc: 0.1736  time: 0.5879  data_time: 0.2244  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:44:39 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 8579  total_loss: 1.368  loss_cls: 0.2762  loss_box_reg: 0.4847  loss_mask: 0.2981  loss_rpn_cls: 0.06394  loss_rpn_loc: 0.1887  time: 0.5881  data_time: 0.3324  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:44:52 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 8599  total_loss: 1.334  loss_cls: 0.2591  loss_box_reg: 0.5057  loss_mask: 0.3014  loss_rpn_cls: 0.04791  loss_rpn_loc: 0.1798  time: 0.5882  data_time: 0.3226  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:45:06 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 8619  total_loss: 1.407  loss_cls: 0.3316  loss_box_reg: 0.4623  loss_mask: 0.2914  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.2107  time: 0.5884  data_time: 0.3298  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:45:26 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 8639  total_loss: 1.461  loss_cls: 0.3584  loss_box_reg: 0.5235  loss_mask: 0.3048  loss_rpn_cls: 0.09284  loss_rpn_loc: 0.2163  time: 0.5894  data_time: 0.6667  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:45:37 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 8659  total_loss: 1.283  loss_cls: 0.3282  loss_box_reg: 0.477  loss_mask: 0.2889  loss_rpn_cls: 0.05073  loss_rpn_loc: 0.172  time: 0.5893  data_time: 0.2361  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:45:50 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 8679  total_loss: 1.438  loss_cls: 0.3219  loss_box_reg: 0.5218  loss_mask: 0.3254  loss_rpn_cls: 0.09999  loss_rpn_loc: 0.1804  time: 0.5894  data_time: 0.2923  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:46:03 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 8699  total_loss: 1.423  loss_cls: 0.3005  loss_box_reg: 0.471  loss_mask: 0.3056  loss_rpn_cls: 0.06675  loss_rpn_loc: 0.2066  time: 0.5896  data_time: 0.3371  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:46:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:46:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:46:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:46:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:46:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:46:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0695 s/iter. Eval: 0.0114 s/iter. Total: 0.0816 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0727 s/iter. Eval: 0.0162 s/iter. Total: 0.0897 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0749 s/iter. Eval: 0.0170 s/iter. Total: 0.0927 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:46:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.831698 (0.093377 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:46:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075016 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:46:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:46:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2686402816484507\n",
      "\u001b[32m[01/03 19:46:26 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 8719  total_loss: 1.332  loss_cls: 0.2897  loss_box_reg: 0.5045  loss_mask: 0.2892  loss_rpn_cls: 0.06383  loss_rpn_loc: 0.1806  time: 0.5894  data_time: 0.1851  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:46:35 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 8739  total_loss: 1.343  loss_cls: 0.3003  loss_box_reg: 0.4863  loss_mask: 0.2772  loss_rpn_cls: 0.07788  loss_rpn_loc: 0.1786  time: 0.5891  data_time: 0.1456  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:46:50 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 8759  total_loss: 1.398  loss_cls: 0.305  loss_box_reg: 0.4812  loss_mask: 0.3033  loss_rpn_cls: 0.07972  loss_rpn_loc: 0.1924  time: 0.5895  data_time: 0.3938  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:47:01 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 8779  total_loss: 1.349  loss_cls: 0.2985  loss_box_reg: 0.4699  loss_mask: 0.3048  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.1951  time: 0.5894  data_time: 0.2037  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:47:10 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 8799  total_loss: 1.362  loss_cls: 0.3373  loss_box_reg: 0.499  loss_mask: 0.2996  loss_rpn_cls: 0.05846  loss_rpn_loc: 0.1846  time: 0.5890  data_time: 0.1405  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:47:23 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 8819  total_loss: 1.265  loss_cls: 0.2673  loss_box_reg: 0.4461  loss_mask: 0.2737  loss_rpn_cls: 0.06492  loss_rpn_loc: 0.1835  time: 0.5892  data_time: 0.3642  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:47:39 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 8839  total_loss: 1.351  loss_cls: 0.3225  loss_box_reg: 0.4819  loss_mask: 0.2881  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.19  time: 0.5897  data_time: 0.4580  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:47:52 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 8859  total_loss: 1.403  loss_cls: 0.3314  loss_box_reg: 0.5191  loss_mask: 0.3021  loss_rpn_cls: 0.07743  loss_rpn_loc: 0.2012  time: 0.5899  data_time: 0.3472  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:48:04 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 8879  total_loss: 1.415  loss_cls: 0.3212  loss_box_reg: 0.5115  loss_mask: 0.288  loss_rpn_cls: 0.07926  loss_rpn_loc: 0.2019  time: 0.5899  data_time: 0.2750  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:48:20 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 8899  total_loss: 1.394  loss_cls: 0.3093  loss_box_reg: 0.4891  loss_mask: 0.3071  loss_rpn_cls: 0.08253  loss_rpn_loc: 0.2046  time: 0.5903  data_time: 0.4631  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:48:30 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 8919  total_loss: 1.274  loss_cls: 0.2628  loss_box_reg: 0.4989  loss_mask: 0.2862  loss_rpn_cls: 0.06299  loss_rpn_loc: 0.1842  time: 0.5901  data_time: 0.1943  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:48:39 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 8939  total_loss: 1.424  loss_cls: 0.2799  loss_box_reg: 0.5054  loss_mask: 0.3073  loss_rpn_cls: 0.07623  loss_rpn_loc: 0.1983  time: 0.5898  data_time: 0.1578  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:48:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:48:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:48:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:48:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:48:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:48:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0694 s/iter. Eval: 0.0137 s/iter. Total: 0.0839 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:48:52 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0723 s/iter. Eval: 0.0163 s/iter. Total: 0.0893 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:48:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.513842 (0.090637 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:48:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072423 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:48:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:48:57 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26589887628208075\n",
      "\u001b[32m[01/03 19:49:00 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 8959  total_loss: 1.365  loss_cls: 0.296  loss_box_reg: 0.524  loss_mask: 0.2868  loss_rpn_cls: 0.07305  loss_rpn_loc: 0.1779  time: 0.5895  data_time: 0.1271  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:49:08 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 8979  total_loss: 1.416  loss_cls: 0.2661  loss_box_reg: 0.5265  loss_mask: 0.3  loss_rpn_cls: 0.05839  loss_rpn_loc: 0.1861  time: 0.5891  data_time: 0.1428  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:49:20 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 8999  total_loss: 1.338  loss_cls: 0.3155  loss_box_reg: 0.5049  loss_mask: 0.298  loss_rpn_cls: 0.0819  loss_rpn_loc: 0.1948  time: 0.5891  data_time: 0.2611  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:49:30 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 9019  total_loss: 1.316  loss_cls: 0.3075  loss_box_reg: 0.4891  loss_mask: 0.2844  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.1706  time: 0.5889  data_time: 0.1865  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:49:43 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 9039  total_loss: 1.273  loss_cls: 0.3047  loss_box_reg: 0.4501  loss_mask: 0.28  loss_rpn_cls: 0.05867  loss_rpn_loc: 0.1971  time: 0.5890  data_time: 0.3187  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:49:56 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 9059  total_loss: 1.271  loss_cls: 0.3109  loss_box_reg: 0.4757  loss_mask: 0.2795  loss_rpn_cls: 0.06252  loss_rpn_loc: 0.1847  time: 0.5892  data_time: 0.3489  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:50:06 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 9079  total_loss: 1.403  loss_cls: 0.3336  loss_box_reg: 0.4898  loss_mask: 0.2919  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.1848  time: 0.5890  data_time: 0.1955  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:50:18 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 9099  total_loss: 1.383  loss_cls: 0.3064  loss_box_reg: 0.4779  loss_mask: 0.2849  loss_rpn_cls: 0.08512  loss_rpn_loc: 0.1982  time: 0.5890  data_time: 0.2464  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:50:32 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 9119  total_loss: 1.395  loss_cls: 0.3168  loss_box_reg: 0.5129  loss_mask: 0.3005  loss_rpn_cls: 0.07102  loss_rpn_loc: 0.1926  time: 0.5892  data_time: 0.3910  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:50:48 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 9139  total_loss: 1.402  loss_cls: 0.3101  loss_box_reg: 0.4691  loss_mask: 0.2992  loss_rpn_cls: 0.08101  loss_rpn_loc: 0.2193  time: 0.5897  data_time: 0.4750  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:51:00 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 9159  total_loss: 1.337  loss_cls: 0.3281  loss_box_reg: 0.5082  loss_mask: 0.2855  loss_rpn_cls: 0.06029  loss_rpn_loc: 0.1678  time: 0.5897  data_time: 0.2666  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:51:13 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 9179  total_loss: 1.293  loss_cls: 0.2727  loss_box_reg: 0.4459  loss_mask: 0.2851  loss_rpn_cls: 0.06876  loss_rpn_loc: 0.1809  time: 0.5898  data_time: 0.3042  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:51:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:51:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:51:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:51:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:51:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:51:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0124 s/iter. Total: 0.0881 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/03 19:51:26 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0008 s/iter. Inference: 0.0733 s/iter. Eval: 0.0157 s/iter. Total: 0.0898 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:51:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.576219 (0.091174 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:51:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073624 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:51:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:51:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2667761997252979\n",
      "\u001b[32m[01/03 19:51:33 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 9199  total_loss: 1.256  loss_cls: 0.2607  loss_box_reg: 0.474  loss_mask: 0.2846  loss_rpn_cls: 0.06181  loss_rpn_loc: 0.1862  time: 0.5895  data_time: 0.1205  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:51:42 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 9219  total_loss: 1.436  loss_cls: 0.3071  loss_box_reg: 0.5282  loss_mask: 0.2996  loss_rpn_cls: 0.07015  loss_rpn_loc: 0.188  time: 0.5891  data_time: 0.1118  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:51:54 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 9239  total_loss: 1.504  loss_cls: 0.3584  loss_box_reg: 0.4962  loss_mask: 0.2979  loss_rpn_cls: 0.08378  loss_rpn_loc: 0.1927  time: 0.5892  data_time: 0.2763  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:52:03 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 9259  total_loss: 1.336  loss_cls: 0.2808  loss_box_reg: 0.5037  loss_mask: 0.2823  loss_rpn_cls: 0.04383  loss_rpn_loc: 0.1823  time: 0.5889  data_time: 0.1522  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:52:12 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 9279  total_loss: 1.294  loss_cls: 0.3263  loss_box_reg: 0.513  loss_mask: 0.2884  loss_rpn_cls: 0.04839  loss_rpn_loc: 0.1774  time: 0.5886  data_time: 0.1537  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:52:23 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 9299  total_loss: 1.332  loss_cls: 0.3147  loss_box_reg: 0.4813  loss_mask: 0.2877  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.1768  time: 0.5885  data_time: 0.2399  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:52:39 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 9319  total_loss: 1.536  loss_cls: 0.3454  loss_box_reg: 0.5028  loss_mask: 0.3106  loss_rpn_cls: 0.08112  loss_rpn_loc: 0.206  time: 0.5889  data_time: 0.4405  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:52:50 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 9339  total_loss: 1.234  loss_cls: 0.2581  loss_box_reg: 0.4561  loss_mask: 0.2865  loss_rpn_cls: 0.07236  loss_rpn_loc: 0.1897  time: 0.5889  data_time: 0.2673  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:52:57 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 9359  total_loss: 1.299  loss_cls: 0.2927  loss_box_reg: 0.4987  loss_mask: 0.2818  loss_rpn_cls: 0.05755  loss_rpn_loc: 0.1611  time: 0.5884  data_time: 0.0739  lr: 0.0005  max_mem: 6623M\n",
      "\u001b[32m[01/03 19:53:09 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 9379  total_loss: 1.367  loss_cls: 0.3147  loss_box_reg: 0.4727  loss_mask: 0.3038  loss_rpn_cls: 0.07995  loss_rpn_loc: 0.2001  time: 0.5883  data_time: 0.2540  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:53:22 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 9399  total_loss: 1.472  loss_cls: 0.3035  loss_box_reg: 0.4886  loss_mask: 0.3152  loss_rpn_cls: 0.09436  loss_rpn_loc: 0.2164  time: 0.5885  data_time: 0.3674  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:53:32 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 9419  total_loss: 1.334  loss_cls: 0.3121  loss_box_reg: 0.4732  loss_mask: 0.2861  loss_rpn_cls: 0.06303  loss_rpn_loc: 0.1775  time: 0.5883  data_time: 0.1640  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:53:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:53:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:53:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:53:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:53:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:53:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0686 s/iter. Eval: 0.0118 s/iter. Total: 0.0811 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0150 s/iter. Total: 0.0860 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:53:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.134937 (0.087370 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:53:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070487 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:53:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:53:55 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26516078530587467\n",
      "\u001b[32m[01/03 19:53:56 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 9439  total_loss: 1.339  loss_cls: 0.3182  loss_box_reg: 0.4596  loss_mask: 0.2967  loss_rpn_cls: 0.08509  loss_rpn_loc: 0.1869  time: 0.5884  data_time: 0.3124  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:54:07 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 9459  total_loss: 1.321  loss_cls: 0.2919  loss_box_reg: 0.4922  loss_mask: 0.3027  loss_rpn_cls: 0.09942  loss_rpn_loc: 0.2021  time: 0.5883  data_time: 0.2537  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:54:19 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 9479  total_loss: 1.212  loss_cls: 0.2676  loss_box_reg: 0.4426  loss_mask: 0.2726  loss_rpn_cls: 0.05324  loss_rpn_loc: 0.1525  time: 0.5883  data_time: 0.2591  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:54:34 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 9499  total_loss: 1.302  loss_cls: 0.3073  loss_box_reg: 0.431  loss_mask: 0.2994  loss_rpn_cls: 0.07428  loss_rpn_loc: 0.1833  time: 0.5887  data_time: 0.4479  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:54:47 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 9519  total_loss: 1.327  loss_cls: 0.2837  loss_box_reg: 0.4787  loss_mask: 0.3091  loss_rpn_cls: 0.05738  loss_rpn_loc: 0.2066  time: 0.5888  data_time: 0.2915  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:54:56 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9539  total_loss: 1.298  loss_cls: 0.2803  loss_box_reg: 0.4666  loss_mask: 0.2887  loss_rpn_cls: 0.06546  loss_rpn_loc: 0.1956  time: 0.5885  data_time: 0.1636  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:55:08 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 9559  total_loss: 1.345  loss_cls: 0.283  loss_box_reg: 0.4845  loss_mask: 0.2944  loss_rpn_cls: 0.07043  loss_rpn_loc: 0.1794  time: 0.5885  data_time: 0.2632  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:55:18 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 9579  total_loss: 1.333  loss_cls: 0.3173  loss_box_reg: 0.4911  loss_mask: 0.2842  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.1742  time: 0.5884  data_time: 0.2109  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:55:29 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 9599  total_loss: 1.361  loss_cls: 0.2933  loss_box_reg: 0.4765  loss_mask: 0.2897  loss_rpn_cls: 0.07631  loss_rpn_loc: 0.1827  time: 0.5882  data_time: 0.2133  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:55:41 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 9619  total_loss: 1.448  loss_cls: 0.3459  loss_box_reg: 0.5029  loss_mask: 0.3032  loss_rpn_cls: 0.07694  loss_rpn_loc: 0.2251  time: 0.5883  data_time: 0.2798  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:55:51 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 9639  total_loss: 1.318  loss_cls: 0.3125  loss_box_reg: 0.4913  loss_mask: 0.2855  loss_rpn_cls: 0.06831  loss_rpn_loc: 0.1778  time: 0.5881  data_time: 0.2225  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:56:01 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 9659  total_loss: 1.364  loss_cls: 0.253  loss_box_reg: 0.5068  loss_mask: 0.3028  loss_rpn_cls: 0.05388  loss_rpn_loc: 0.1809  time: 0.5879  data_time: 0.1824  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:56:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:56:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:56:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:56:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:56:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:56:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0690 s/iter. Eval: 0.0102 s/iter. Total: 0.0799 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0724 s/iter. Eval: 0.0155 s/iter. Total: 0.0888 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0737 s/iter. Eval: 0.0167 s/iter. Total: 0.0912 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/03 19:56:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.626832 (0.091611 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:56:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073653 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:56:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:56:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2609292367556028\n",
      "\u001b[32m[01/03 19:56:23 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 9679  total_loss: 1.296  loss_cls: 0.2759  loss_box_reg: 0.4825  loss_mask: 0.311  loss_rpn_cls: 0.05497  loss_rpn_loc: 0.1681  time: 0.5878  data_time: 0.1922  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:56:37 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 9699  total_loss: 1.358  loss_cls: 0.2975  loss_box_reg: 0.499  loss_mask: 0.2978  loss_rpn_cls: 0.05802  loss_rpn_loc: 0.1841  time: 0.5880  data_time: 0.3631  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:56:51 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9719  total_loss: 1.373  loss_cls: 0.2913  loss_box_reg: 0.4633  loss_mask: 0.3118  loss_rpn_cls: 0.09244  loss_rpn_loc: 0.2034  time: 0.5882  data_time: 0.3949  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:57:01 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 9739  total_loss: 1.348  loss_cls: 0.299  loss_box_reg: 0.4919  loss_mask: 0.2931  loss_rpn_cls: 0.0603  loss_rpn_loc: 0.1722  time: 0.5880  data_time: 0.1915  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:57:11 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 9759  total_loss: 1.337  loss_cls: 0.2614  loss_box_reg: 0.4856  loss_mask: 0.2985  loss_rpn_cls: 0.06719  loss_rpn_loc: 0.1836  time: 0.5879  data_time: 0.1996  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:57:25 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 9779  total_loss: 1.343  loss_cls: 0.3001  loss_box_reg: 0.4968  loss_mask: 0.299  loss_rpn_cls: 0.06883  loss_rpn_loc: 0.1906  time: 0.5881  data_time: 0.3582  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:57:35 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 9799  total_loss: 1.362  loss_cls: 0.2882  loss_box_reg: 0.4868  loss_mask: 0.2993  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.1983  time: 0.5879  data_time: 0.2065  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:57:49 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 9819  total_loss: 1.335  loss_cls: 0.3154  loss_box_reg: 0.4743  loss_mask: 0.2784  loss_rpn_cls: 0.07446  loss_rpn_loc: 0.1659  time: 0.5881  data_time: 0.3439  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:58:00 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 9839  total_loss: 1.325  loss_cls: 0.3053  loss_box_reg: 0.4969  loss_mask: 0.2903  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.1828  time: 0.5881  data_time: 0.2516  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:58:10 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 9859  total_loss: 1.255  loss_cls: 0.2683  loss_box_reg: 0.4862  loss_mask: 0.2816  loss_rpn_cls: 0.05742  loss_rpn_loc: 0.1794  time: 0.5878  data_time: 0.1870  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:58:22 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9879  total_loss: 1.367  loss_cls: 0.2998  loss_box_reg: 0.4865  loss_mask: 0.2903  loss_rpn_cls: 0.05635  loss_rpn_loc: 0.194  time: 0.5879  data_time: 0.3299  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:58:34 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 9899  total_loss: 1.288  loss_cls: 0.2844  loss_box_reg: 0.4703  loss_mask: 0.2935  loss_rpn_cls: 0.06563  loss_rpn_loc: 0.1809  time: 0.5880  data_time: 0.2974  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:58:48 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 9919  total_loss: 1.485  loss_cls: 0.3598  loss_box_reg: 0.4658  loss_mask: 0.297  loss_rpn_cls: 0.08794  loss_rpn_loc: 0.212  time: 0.5882  data_time: 0.3689  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:58:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:58:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:58:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:58:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:58:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:58:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:58:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0687 s/iter. Eval: 0.0115 s/iter. Total: 0.0809 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0159 s/iter. Total: 0.0873 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:59:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.419567 (0.089824 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:59:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071028 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:59:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:59:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2704886119276957\n",
      "\u001b[32m[01/03 19:59:10 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9939  total_loss: 1.41  loss_cls: 0.3118  loss_box_reg: 0.4853  loss_mask: 0.2968  loss_rpn_cls: 0.05944  loss_rpn_loc: 0.1801  time: 0.5880  data_time: 0.1832  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:59:21 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 9959  total_loss: 1.244  loss_cls: 0.2642  loss_box_reg: 0.4508  loss_mask: 0.27  loss_rpn_cls: 0.06632  loss_rpn_loc: 0.1736  time: 0.5879  data_time: 0.2473  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:59:31 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 9979  total_loss: 1.297  loss_cls: 0.2959  loss_box_reg: 0.4816  loss_mask: 0.3027  loss_rpn_cls: 0.05061  loss_rpn_loc: 0.1668  time: 0.5878  data_time: 0.2084  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:59:43 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.366  loss_cls: 0.308  loss_box_reg: 0.4638  loss_mask: 0.2814  loss_rpn_cls: 0.06531  loss_rpn_loc: 0.1861  time: 0.5877  data_time: 0.2444  lr: 0.0005  max_mem: 6632M\n",
      "\u001b[32m[01/03 19:59:43 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:37:55 (0.5877 s / it)\n",
      "\u001b[32m[01/03 19:59:43 d2.engine.hooks]: \u001b[0mTotal training time: 1:45:58 (0:08:02 on hooks)\n",
      "\u001b[32m[01/03 19:59:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:59:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 19:59:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 19:59:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/03 19:59:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/03 19:59:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/03 19:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0684 s/iter. Eval: 0.0109 s/iter. Total: 0.0800 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/03 19:59:50 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.0702 s/iter. Eval: 0.0155 s/iter. Total: 0.0865 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/03 19:59:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.184960 (0.087801 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:59:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070578 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/03 19:59:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/03 19:59:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2610541524315157\n"
     ]
    }
   ],
   "source": [
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593ce47-d199-4835-8161-c1fc17fa9f63",
   "metadata": {},
   "source": [
    "We choose the model obtained after iteration 6291."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
