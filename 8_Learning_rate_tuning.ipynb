{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13466de-94f0-40b5-88c3-76f9d5631034",
   "metadata": {},
   "source": [
    "### Notebook 8: Solver (learning rate) tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5557107f-dfe5-4337-b30e-98d6bff6d95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pycocotools.mask as mask_util\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf4586-9bac-45bd-b5c5-3d002ccd99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=Path('../')\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "register_coco_instances('sartorius_train',{}, '../sartorius-annotations-coco-format/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_val',{},'../sartorius-annotations-coco-format/annotations_val.json', dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e51ca4b-119f-40b5-9982-e1d17cba6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = [0.204, 0.386, 0.568]\n",
    "min_mask_area = [75, 180, 75]\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1\n",
    "    false_positives = np.sum(matches, axis=0) == 0\n",
    "    false_negatives = np.sum(matches, axis=1) == 0\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n",
    "    take = pred['instances'].scores >= score_threshold[pred_class]\n",
    "    pred_masks = pred['instances'].pred_masks[take].cpu().numpy()\n",
    "    if len(pred_masks)==0:\n",
    "        return 0.\n",
    "    else:\n",
    "        enc_preds = []\n",
    "        used = np.zeros(pred_masks[0].shape, dtype=int)\n",
    "        for mask in pred_masks:\n",
    "            mask = (mask * (1-used)).astype(bool)\n",
    "            if mask.sum() >= min_mask_area[pred_class]:\n",
    "                used += mask\n",
    "                enc_preds.append(mask_util.encode(np.asarray(mask, order='F')) )\n",
    "        enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "        ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "        prec = []\n",
    "        for t in np.arange(0.5, 1.0, 0.05):\n",
    "            tp, fp, fn = precision_at(t, ious)\n",
    "            p = tp / (tp + fp + fn)\n",
    "            prec.append(p)\n",
    "        return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"mAP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afefd31c-e279-4a25-a014-95f6f72e691c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/01 19:38:05 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/01 19:38:06 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/01 19:38:09 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/01 19:38:09 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/01 19:38:10 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/01 19:38:10 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/01 19:38:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/01 19:38:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/01 19:38:10 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:38:10 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/01 19:38:10 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/01 19:38:24 d2.utils.events]: \u001b[0m eta: 1:00:42  iter: 19  total_loss: 3.078  loss_cls: 1.381  loss_box_reg: 0.3886  loss_mask: 0.6933  loss_rpn_cls: 0.3497  loss_rpn_loc: 0.2589  time: 0.6826  data_time: 0.3387  lr: 1.9981e-05  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:38:36 d2.utils.events]: \u001b[0m eta: 0:58:15  iter: 39  total_loss: 2.901  loss_cls: 1.239  loss_box_reg: 0.4499  loss_mask: 0.6791  loss_rpn_cls: 0.2923  loss_rpn_loc: 0.2585  time: 0.6259  data_time: 0.2776  lr: 3.9961e-05  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:38:47 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 59  total_loss: 2.596  loss_cls: 0.9934  loss_box_reg: 0.5051  loss_mask: 0.6508  loss_rpn_cls: 0.2319  loss_rpn_loc: 0.2518  time: 0.6024  data_time: 0.2445  lr: 5.9941e-05  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:38:56 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 79  total_loss: 2.371  loss_cls: 0.7882  loss_box_reg: 0.5218  loss_mask: 0.594  loss_rpn_cls: 0.2065  loss_rpn_loc: 0.2304  time: 0.5712  data_time: 0.1790  lr: 7.9921e-05  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:39:08 d2.utils.events]: \u001b[0m eta: 0:54:38  iter: 99  total_loss: 2.215  loss_cls: 0.6731  loss_box_reg: 0.5708  loss_mask: 0.5509  loss_rpn_cls: 0.1805  loss_rpn_loc: 0.2381  time: 0.5777  data_time: 0.2781  lr: 9.9901e-05  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:39:21 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 119  total_loss: 2.133  loss_cls: 0.6375  loss_box_reg: 0.5152  loss_mask: 0.518  loss_rpn_cls: 0.1716  loss_rpn_loc: 0.2383  time: 0.5873  data_time: 0.3193  lr: 0.00011988  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:39:36 d2.utils.events]: \u001b[0m eta: 0:54:50  iter: 139  total_loss: 2.174  loss_cls: 0.6568  loss_box_reg: 0.6355  loss_mask: 0.5126  loss_rpn_cls: 0.1461  loss_rpn_loc: 0.2415  time: 0.6080  data_time: 0.4047  lr: 0.00013986  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:39:49 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 159  total_loss: 2.012  loss_cls: 0.5626  loss_box_reg: 0.6077  loss_mask: 0.4455  loss_rpn_cls: 0.1422  loss_rpn_loc: 0.2196  time: 0.6143  data_time: 0.3417  lr: 0.00015984  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:40:00 d2.utils.events]: \u001b[0m eta: 0:54:25  iter: 179  total_loss: 1.955  loss_cls: 0.5739  loss_box_reg: 0.644  loss_mask: 0.3961  loss_rpn_cls: 0.1241  loss_rpn_loc: 0.2072  time: 0.6053  data_time: 0.2251  lr: 0.00017982  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:40:10 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 199  total_loss: 1.923  loss_cls: 0.5022  loss_box_reg: 0.6773  loss_mask: 0.3635  loss_rpn_cls: 0.126  loss_rpn_loc: 0.2191  time: 0.5967  data_time: 0.2104  lr: 0.0001998  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:40:20 d2.utils.events]: \u001b[0m eta: 0:54:08  iter: 219  total_loss: 1.829  loss_cls: 0.4563  loss_box_reg: 0.6839  loss_mask: 0.3488  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.2259  time: 0.5891  data_time: 0.2032  lr: 0.00021978  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:40:33 d2.utils.events]: \u001b[0m eta: 0:54:05  iter: 239  total_loss: 1.739  loss_cls: 0.4582  loss_box_reg: 0.5969  loss_mask: 0.3263  loss_rpn_cls: 0.125  loss_rpn_loc: 0.2209  time: 0.5913  data_time: 0.2909  lr: 0.00023976  max_mem: 5115M\n",
      "\u001b[32m[02/01 19:40:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:40:36 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/01 19:40:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 19:40:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:40:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 19:40:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:40:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 19:40:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0691 s/iter. Eval: 0.0241 s/iter. Total: 0.0938 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 19:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0007 s/iter. Inference: 0.0694 s/iter. Eval: 0.0289 s/iter. Total: 0.0990 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 19:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0691 s/iter. Eval: 0.0263 s/iter. Total: 0.0961 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 19:40:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.134364 (0.095986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:40:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069075 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:40:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 19:40:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.15754212233969883\n",
      "\u001b[32m[02/01 19:41:00 d2.utils.events]: \u001b[0m eta: 0:54:47  iter: 259  total_loss: 1.768  loss_cls: 0.4423  loss_box_reg: 0.6164  loss_mask: 0.3505  loss_rpn_cls: 0.1394  loss_rpn_loc: 0.2392  time: 0.6013  data_time: 0.3754  lr: 0.00025974  max_mem: 5638M\n",
      "\u001b[32m[02/01 19:41:09 d2.utils.events]: \u001b[0m eta: 0:54:31  iter: 279  total_loss: 1.705  loss_cls: 0.4152  loss_box_reg: 0.6568  loss_mask: 0.3193  loss_rpn_cls: 0.105  loss_rpn_loc: 0.2154  time: 0.5925  data_time: 0.1599  lr: 0.00027972  max_mem: 5638M\n",
      "\u001b[32m[02/01 19:41:23 d2.utils.events]: \u001b[0m eta: 0:54:33  iter: 299  total_loss: 1.673  loss_cls: 0.3683  loss_box_reg: 0.585  loss_mask: 0.3123  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.2331  time: 0.5988  data_time: 0.3648  lr: 0.0002997  max_mem: 5638M\n",
      "\u001b[32m[02/01 19:41:33 d2.utils.events]: \u001b[0m eta: 0:54:09  iter: 319  total_loss: 1.652  loss_cls: 0.3487  loss_box_reg: 0.6516  loss_mask: 0.3237  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.2151  time: 0.5925  data_time: 0.1883  lr: 0.00031968  max_mem: 5638M\n",
      "\u001b[32m[02/01 19:41:46 d2.utils.events]: \u001b[0m eta: 0:53:52  iter: 339  total_loss: 1.582  loss_cls: 0.4019  loss_box_reg: 0.6051  loss_mask: 0.3175  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.2034  time: 0.5952  data_time: 0.3010  lr: 0.00033966  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:41:58 d2.utils.events]: \u001b[0m eta: 0:53:56  iter: 359  total_loss: 1.612  loss_cls: 0.3741  loss_box_reg: 0.5635  loss_mask: 0.3234  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.2226  time: 0.5964  data_time: 0.2909  lr: 0.00035964  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:42:10 d2.utils.events]: \u001b[0m eta: 0:53:54  iter: 379  total_loss: 1.746  loss_cls: 0.459  loss_box_reg: 0.6013  loss_mask: 0.3352  loss_rpn_cls: 0.1307  loss_rpn_loc: 0.2401  time: 0.5964  data_time: 0.2761  lr: 0.00037962  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:42:19 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 399  total_loss: 1.666  loss_cls: 0.3902  loss_box_reg: 0.6159  loss_mask: 0.3087  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.2095  time: 0.5901  data_time: 0.1544  lr: 0.0003996  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:42:29 d2.utils.events]: \u001b[0m eta: 0:53:19  iter: 419  total_loss: 1.637  loss_cls: 0.3564  loss_box_reg: 0.6444  loss_mask: 0.301  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.2086  time: 0.5857  data_time: 0.1821  lr: 0.00041958  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:42:43 d2.utils.events]: \u001b[0m eta: 0:53:52  iter: 439  total_loss: 1.607  loss_cls: 0.4126  loss_box_reg: 0.5591  loss_mask: 0.3056  loss_rpn_cls: 0.1283  loss_rpn_loc: 0.2226  time: 0.5908  data_time: 0.3497  lr: 0.00043956  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:42:55 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 459  total_loss: 1.451  loss_cls: 0.3318  loss_box_reg: 0.5618  loss_mask: 0.3216  loss_rpn_cls: 0.07651  loss_rpn_loc: 0.2044  time: 0.5902  data_time: 0.2487  lr: 0.00045954  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:43:06 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 479  total_loss: 1.566  loss_cls: 0.337  loss_box_reg: 0.5634  loss_mask: 0.3141  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.2121  time: 0.5896  data_time: 0.2393  lr: 0.00047952  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:43:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:43:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 19:43:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:43:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 19:43:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:43:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 19:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0304 s/iter. Total: 0.1047 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 19:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 58/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0335 s/iter. Total: 0.1078 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/01 19:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0007 s/iter. Inference: 0.0732 s/iter. Eval: 0.0303 s/iter. Total: 0.1042 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/01 19:43:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.180968 (0.105008 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:43:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073210 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:43:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 19:43:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2163175883719717\n",
      "\u001b[32m[02/01 19:43:29 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 499  total_loss: 1.544  loss_cls: 0.3784  loss_box_reg: 0.5794  loss_mask: 0.3048  loss_rpn_cls: 0.07776  loss_rpn_loc: 0.2014  time: 0.5842  data_time: 0.1242  lr: 0.0004995  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:43:41 d2.utils.events]: \u001b[0m eta: 0:53:34  iter: 519  total_loss: 1.539  loss_cls: 0.3953  loss_box_reg: 0.5682  loss_mask: 0.2976  loss_rpn_cls: 0.09425  loss_rpn_loc: 0.2192  time: 0.5837  data_time: 0.2439  lr: 0.00051948  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:43:53 d2.utils.events]: \u001b[0m eta: 0:53:31  iter: 539  total_loss: 1.485  loss_cls: 0.3435  loss_box_reg: 0.5368  loss_mask: 0.3045  loss_rpn_cls: 0.08632  loss_rpn_loc: 0.2047  time: 0.5850  data_time: 0.2783  lr: 0.00053946  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:44:06 d2.utils.events]: \u001b[0m eta: 0:53:47  iter: 559  total_loss: 1.578  loss_cls: 0.37  loss_box_reg: 0.5575  loss_mask: 0.3117  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2128  time: 0.5871  data_time: 0.2978  lr: 0.00055944  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:44:21 d2.utils.events]: \u001b[0m eta: 0:53:45  iter: 579  total_loss: 1.686  loss_cls: 0.4244  loss_box_reg: 0.5755  loss_mask: 0.3187  loss_rpn_cls: 0.1306  loss_rpn_loc: 0.247  time: 0.5934  data_time: 0.4223  lr: 0.00057942  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:44:30 d2.utils.events]: \u001b[0m eta: 0:53:29  iter: 599  total_loss: 1.583  loss_cls: 0.3579  loss_box_reg: 0.5696  loss_mask: 0.2993  loss_rpn_cls: 0.0849  loss_rpn_loc: 0.1935  time: 0.5881  data_time: 0.1146  lr: 0.0005994  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:44:43 d2.utils.events]: \u001b[0m eta: 0:53:31  iter: 619  total_loss: 1.486  loss_cls: 0.3821  loss_box_reg: 0.5164  loss_mask: 0.3165  loss_rpn_cls: 0.09731  loss_rpn_loc: 0.1993  time: 0.5903  data_time: 0.3126  lr: 0.00061938  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:44:54 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 639  total_loss: 1.648  loss_cls: 0.418  loss_box_reg: 0.5961  loss_mask: 0.3121  loss_rpn_cls: 0.116  loss_rpn_loc: 0.2349  time: 0.5897  data_time: 0.2442  lr: 0.00063936  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:45:08 d2.utils.events]: \u001b[0m eta: 0:53:18  iter: 659  total_loss: 1.438  loss_cls: 0.3281  loss_box_reg: 0.5449  loss_mask: 0.3117  loss_rpn_cls: 0.1172  loss_rpn_loc: 0.1973  time: 0.5920  data_time: 0.3287  lr: 0.00065934  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:45:18 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 679  total_loss: 1.556  loss_cls: 0.3473  loss_box_reg: 0.5557  loss_mask: 0.3088  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.2172  time: 0.5892  data_time: 0.1740  lr: 0.00067932  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:45:32 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 699  total_loss: 1.484  loss_cls: 0.3347  loss_box_reg: 0.5417  loss_mask: 0.3009  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.2237  time: 0.5931  data_time: 0.3786  lr: 0.0006993  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:45:44 d2.utils.events]: \u001b[0m eta: 0:52:56  iter: 719  total_loss: 1.572  loss_cls: 0.3707  loss_box_reg: 0.579  loss_mask: 0.3116  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.22  time: 0.5923  data_time: 0.2283  lr: 0.00071928  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:45:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:45:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 19:45:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:45:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 19:45:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:45:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 19:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0351 s/iter. Total: 0.1098 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 19:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 56/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0377 s/iter. Total: 0.1127 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/01 19:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0007 s/iter. Inference: 0.0741 s/iter. Eval: 0.0352 s/iter. Total: 0.1101 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/01 19:46:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.882382 (0.111055 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:46:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074132 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:46:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 19:46:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2208605816122257\n",
      "\u001b[32m[02/01 19:46:09 d2.utils.events]: \u001b[0m eta: 0:52:56  iter: 739  total_loss: 1.518  loss_cls: 0.3665  loss_box_reg: 0.5531  loss_mask: 0.3182  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.2172  time: 0.5917  data_time: 0.2364  lr: 0.00073926  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:46:21 d2.utils.events]: \u001b[0m eta: 0:52:54  iter: 759  total_loss: 1.491  loss_cls: 0.3417  loss_box_reg: 0.5368  loss_mask: 0.299  loss_rpn_cls: 0.09038  loss_rpn_loc: 0.2029  time: 0.5912  data_time: 0.2369  lr: 0.00075924  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:46:31 d2.utils.events]: \u001b[0m eta: 0:52:51  iter: 779  total_loss: 1.529  loss_cls: 0.3596  loss_box_reg: 0.5582  loss_mask: 0.3078  loss_rpn_cls: 0.08591  loss_rpn_loc: 0.2  time: 0.5895  data_time: 0.1854  lr: 0.00077922  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:46:41 d2.utils.events]: \u001b[0m eta: 0:52:45  iter: 799  total_loss: 1.473  loss_cls: 0.3195  loss_box_reg: 0.5318  loss_mask: 0.303  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.2261  time: 0.5878  data_time: 0.1930  lr: 0.0007992  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:46:53 d2.utils.events]: \u001b[0m eta: 0:52:39  iter: 819  total_loss: 1.52  loss_cls: 0.3429  loss_box_reg: 0.5325  loss_mask: 0.3016  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.2124  time: 0.5869  data_time: 0.2259  lr: 0.00081918  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:47:04 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 839  total_loss: 1.605  loss_cls: 0.355  loss_box_reg: 0.5476  loss_mask: 0.3173  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.226  time: 0.5872  data_time: 0.2657  lr: 0.00083916  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:47:18 d2.utils.events]: \u001b[0m eta: 0:52:30  iter: 859  total_loss: 1.585  loss_cls: 0.4108  loss_box_reg: 0.5462  loss_mask: 0.3197  loss_rpn_cls: 0.09446  loss_rpn_loc: 0.2135  time: 0.5894  data_time: 0.3400  lr: 0.00085914  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:47:32 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 879  total_loss: 1.515  loss_cls: 0.3135  loss_box_reg: 0.5125  loss_mask: 0.3028  loss_rpn_cls: 0.09376  loss_rpn_loc: 0.2296  time: 0.5912  data_time: 0.3265  lr: 0.00087912  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:47:43 d2.utils.events]: \u001b[0m eta: 0:52:21  iter: 899  total_loss: 1.434  loss_cls: 0.3372  loss_box_reg: 0.5187  loss_mask: 0.29  loss_rpn_cls: 0.09084  loss_rpn_loc: 0.1895  time: 0.5910  data_time: 0.2552  lr: 0.0008991  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:47:55 d2.utils.events]: \u001b[0m eta: 0:52:20  iter: 919  total_loss: 1.638  loss_cls: 0.3806  loss_box_reg: 0.5479  loss_mask: 0.3186  loss_rpn_cls: 0.08989  loss_rpn_loc: 0.2377  time: 0.5914  data_time: 0.2621  lr: 0.00091908  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:48:12 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 939  total_loss: 1.508  loss_cls: 0.3404  loss_box_reg: 0.5483  loss_mask: 0.3095  loss_rpn_cls: 0.09592  loss_rpn_loc: 0.2219  time: 0.5961  data_time: 0.4576  lr: 0.00093906  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:48:25 d2.utils.events]: \u001b[0m eta: 0:52:19  iter: 959  total_loss: 1.621  loss_cls: 0.4094  loss_box_reg: 0.5381  loss_mask: 0.2992  loss_rpn_cls: 0.1127  loss_rpn_loc: 0.2231  time: 0.5973  data_time: 0.3112  lr: 0.00095904  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:48:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:48:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 19:48:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:48:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 19:48:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:48:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 19:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0730 s/iter. Eval: 0.0296 s/iter. Total: 0.1031 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 19:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0755 s/iter. Eval: 0.0461 s/iter. Total: 0.1223 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 19:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0760 s/iter. Eval: 0.0487 s/iter. Total: 0.1254 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/01 19:48:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.452528 (0.124591 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:48:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075803 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:48:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 19:48:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2307153624171502\n",
      "\u001b[32m[02/01 19:48:52 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 979  total_loss: 1.466  loss_cls: 0.367  loss_box_reg: 0.561  loss_mask: 0.2923  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2015  time: 0.5971  data_time: 0.2577  lr: 0.00097902  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:49:08 d2.utils.events]: \u001b[0m eta: 0:52:11  iter: 999  total_loss: 1.565  loss_cls: 0.3702  loss_box_reg: 0.5546  loss_mask: 0.3091  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.2079  time: 0.6005  data_time: 0.4157  lr: 0.000999  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:49:18 d2.utils.events]: \u001b[0m eta: 0:51:59  iter: 1019  total_loss: 1.557  loss_cls: 0.3428  loss_box_reg: 0.5894  loss_mask: 0.298  loss_rpn_cls: 0.07298  loss_rpn_loc: 0.1958  time: 0.5994  data_time: 0.2251  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:49:30 d2.utils.events]: \u001b[0m eta: 0:51:52  iter: 1039  total_loss: 1.42  loss_cls: 0.3254  loss_box_reg: 0.5236  loss_mask: 0.2957  loss_rpn_cls: 0.08439  loss_rpn_loc: 0.1936  time: 0.5991  data_time: 0.2466  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:49:42 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 1059  total_loss: 1.566  loss_cls: 0.3939  loss_box_reg: 0.5786  loss_mask: 0.3126  loss_rpn_cls: 0.08678  loss_rpn_loc: 0.2032  time: 0.5993  data_time: 0.2749  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:49:54 d2.utils.events]: \u001b[0m eta: 0:51:50  iter: 1079  total_loss: 1.443  loss_cls: 0.3361  loss_box_reg: 0.5248  loss_mask: 0.3029  loss_rpn_cls: 0.07727  loss_rpn_loc: 0.1871  time: 0.5994  data_time: 0.2644  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:50:08 d2.utils.events]: \u001b[0m eta: 0:51:50  iter: 1099  total_loss: 1.432  loss_cls: 0.3296  loss_box_reg: 0.5263  loss_mask: 0.3004  loss_rpn_cls: 0.08218  loss_rpn_loc: 0.1999  time: 0.6007  data_time: 0.3339  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:50:21 d2.utils.events]: \u001b[0m eta: 0:51:43  iter: 1119  total_loss: 1.58  loss_cls: 0.4118  loss_box_reg: 0.5303  loss_mask: 0.3035  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.2373  time: 0.6016  data_time: 0.3117  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:50:31 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 1139  total_loss: 1.656  loss_cls: 0.4337  loss_box_reg: 0.5795  loss_mask: 0.2997  loss_rpn_cls: 0.08518  loss_rpn_loc: 0.2083  time: 0.6003  data_time: 0.2108  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:50:44 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 1159  total_loss: 1.426  loss_cls: 0.3203  loss_box_reg: 0.5221  loss_mask: 0.2968  loss_rpn_cls: 0.08543  loss_rpn_loc: 0.1951  time: 0.6009  data_time: 0.3202  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:50:56 d2.utils.events]: \u001b[0m eta: 0:51:17  iter: 1179  total_loss: 1.458  loss_cls: 0.3424  loss_box_reg: 0.5473  loss_mask: 0.3252  loss_rpn_cls: 0.07106  loss_rpn_loc: 0.21  time: 0.6006  data_time: 0.2727  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:51:08 d2.utils.events]: \u001b[0m eta: 0:51:16  iter: 1199  total_loss: 1.538  loss_cls: 0.3479  loss_box_reg: 0.5393  loss_mask: 0.3005  loss_rpn_cls: 0.09129  loss_rpn_loc: 0.2028  time: 0.6011  data_time: 0.3129  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:51:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:51:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 19:51:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:51:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 19:51:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:51:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 19:51:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0700 s/iter. Eval: 0.0300 s/iter. Total: 0.1006 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 19:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0724 s/iter. Eval: 0.0501 s/iter. Total: 0.1233 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 19:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0552 s/iter. Total: 0.1299 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 19:51:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.897227 (0.128424 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:51:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073591 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:51:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 19:51:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24411755484746778\n",
      "\u001b[32m[02/01 19:51:38 d2.utils.events]: \u001b[0m eta: 0:51:20  iter: 1219  total_loss: 1.629  loss_cls: 0.4214  loss_box_reg: 0.5655  loss_mask: 0.3126  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.2284  time: 0.6017  data_time: 0.3011  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:51:48 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 1239  total_loss: 1.438  loss_cls: 0.3472  loss_box_reg: 0.5385  loss_mask: 0.302  loss_rpn_cls: 0.08431  loss_rpn_loc: 0.1944  time: 0.6000  data_time: 0.1783  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:52:01 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 1259  total_loss: 1.483  loss_cls: 0.3501  loss_box_reg: 0.5398  loss_mask: 0.3126  loss_rpn_cls: 0.09965  loss_rpn_loc: 0.2043  time: 0.6010  data_time: 0.3324  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:52:11 d2.utils.events]: \u001b[0m eta: 0:50:47  iter: 1279  total_loss: 1.423  loss_cls: 0.3185  loss_box_reg: 0.5371  loss_mask: 0.296  loss_rpn_cls: 0.09021  loss_rpn_loc: 0.2095  time: 0.6000  data_time: 0.2133  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:52:21 d2.utils.events]: \u001b[0m eta: 0:50:40  iter: 1299  total_loss: 1.602  loss_cls: 0.3735  loss_box_reg: 0.5448  loss_mask: 0.3146  loss_rpn_cls: 0.08639  loss_rpn_loc: 0.2006  time: 0.5983  data_time: 0.1647  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:52:34 d2.utils.events]: \u001b[0m eta: 0:50:37  iter: 1319  total_loss: 1.474  loss_cls: 0.3324  loss_box_reg: 0.5224  loss_mask: 0.3159  loss_rpn_cls: 0.08561  loss_rpn_loc: 0.1981  time: 0.5989  data_time: 0.3052  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:52:42 d2.utils.events]: \u001b[0m eta: 0:50:28  iter: 1339  total_loss: 1.449  loss_cls: 0.3322  loss_box_reg: 0.5968  loss_mask: 0.3143  loss_rpn_cls: 0.06913  loss_rpn_loc: 0.1777  time: 0.5962  data_time: 0.1103  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:52:55 d2.utils.events]: \u001b[0m eta: 0:50:17  iter: 1359  total_loss: 1.469  loss_cls: 0.3305  loss_box_reg: 0.5262  loss_mask: 0.299  loss_rpn_cls: 0.06761  loss_rpn_loc: 0.2221  time: 0.5965  data_time: 0.2967  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:53:07 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 1379  total_loss: 1.536  loss_cls: 0.38  loss_box_reg: 0.5293  loss_mask: 0.3047  loss_rpn_cls: 0.09046  loss_rpn_loc: 0.211  time: 0.5966  data_time: 0.2834  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:53:18 d2.utils.events]: \u001b[0m eta: 0:50:01  iter: 1399  total_loss: 1.532  loss_cls: 0.3629  loss_box_reg: 0.5271  loss_mask: 0.2976  loss_rpn_cls: 0.08871  loss_rpn_loc: 0.2037  time: 0.5961  data_time: 0.2377  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:53:29 d2.utils.events]: \u001b[0m eta: 0:49:58  iter: 1419  total_loss: 1.526  loss_cls: 0.3372  loss_box_reg: 0.5557  loss_mask: 0.3181  loss_rpn_cls: 0.09489  loss_rpn_loc: 0.2263  time: 0.5952  data_time: 0.2141  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:53:45 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 1439  total_loss: 1.532  loss_cls: 0.3516  loss_box_reg: 0.4809  loss_mask: 0.305  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.2362  time: 0.5983  data_time: 0.4757  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:53:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:53:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 19:53:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:53:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 19:53:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:53:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 19:53:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0701 s/iter. Eval: 0.0327 s/iter. Total: 0.1034 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 19:53:59 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0732 s/iter. Eval: 0.0491 s/iter. Total: 0.1231 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 19:54:04 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0730 s/iter. Eval: 0.0506 s/iter. Total: 0.1245 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/01 19:54:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.245557 (0.122807 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:54:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072733 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:54:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 19:54:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2502466556110284\n",
      "\u001b[32m[02/01 19:54:12 d2.utils.events]: \u001b[0m eta: 0:49:39  iter: 1459  total_loss: 1.421  loss_cls: 0.3337  loss_box_reg: 0.5328  loss_mask: 0.3017  loss_rpn_cls: 0.07331  loss_rpn_loc: 0.192  time: 0.5978  data_time: 0.2502  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:54:25 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 1479  total_loss: 1.411  loss_cls: 0.3162  loss_box_reg: 0.5067  loss_mask: 0.3093  loss_rpn_cls: 0.07637  loss_rpn_loc: 0.1795  time: 0.5985  data_time: 0.3031  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:54:37 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 1499  total_loss: 1.601  loss_cls: 0.3688  loss_box_reg: 0.5465  loss_mask: 0.3112  loss_rpn_cls: 0.08505  loss_rpn_loc: 0.2198  time: 0.5987  data_time: 0.2877  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:54:49 d2.utils.events]: \u001b[0m eta: 0:49:19  iter: 1519  total_loss: 1.476  loss_cls: 0.3306  loss_box_reg: 0.5174  loss_mask: 0.2965  loss_rpn_cls: 0.09335  loss_rpn_loc: 0.1986  time: 0.5985  data_time: 0.2621  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:55:02 d2.utils.events]: \u001b[0m eta: 0:49:10  iter: 1539  total_loss: 1.543  loss_cls: 0.3593  loss_box_reg: 0.5519  loss_mask: 0.3156  loss_rpn_cls: 0.09466  loss_rpn_loc: 0.2135  time: 0.5995  data_time: 0.3464  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:55:14 d2.utils.events]: \u001b[0m eta: 0:49:02  iter: 1559  total_loss: 1.595  loss_cls: 0.3914  loss_box_reg: 0.5669  loss_mask: 0.3005  loss_rpn_cls: 0.09092  loss_rpn_loc: 0.2111  time: 0.5992  data_time: 0.2449  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:55:27 d2.utils.events]: \u001b[0m eta: 0:48:55  iter: 1579  total_loss: 1.382  loss_cls: 0.334  loss_box_reg: 0.5277  loss_mask: 0.2977  loss_rpn_cls: 0.07048  loss_rpn_loc: 0.2034  time: 0.5996  data_time: 0.3065  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:55:36 d2.utils.events]: \u001b[0m eta: 0:48:47  iter: 1599  total_loss: 1.47  loss_cls: 0.3613  loss_box_reg: 0.5505  loss_mask: 0.2911  loss_rpn_cls: 0.07699  loss_rpn_loc: 0.2295  time: 0.5979  data_time: 0.1492  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:55:48 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 1619  total_loss: 1.329  loss_cls: 0.2964  loss_box_reg: 0.5049  loss_mask: 0.2769  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.229  time: 0.5981  data_time: 0.3099  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:56:00 d2.utils.events]: \u001b[0m eta: 0:48:31  iter: 1639  total_loss: 1.498  loss_cls: 0.3234  loss_box_reg: 0.5435  loss_mask: 0.299  loss_rpn_cls: 0.09092  loss_rpn_loc: 0.2189  time: 0.5981  data_time: 0.2778  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:56:14 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 1659  total_loss: 1.478  loss_cls: 0.3301  loss_box_reg: 0.5296  loss_mask: 0.3202  loss_rpn_cls: 0.06277  loss_rpn_loc: 0.2193  time: 0.5993  data_time: 0.3688  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:56:25 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 1679  total_loss: 1.434  loss_cls: 0.3443  loss_box_reg: 0.5099  loss_mask: 0.2908  loss_rpn_cls: 0.07729  loss_rpn_loc: 0.1993  time: 0.5988  data_time: 0.2459  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:56:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:56:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 19:56:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:56:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 19:56:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:56:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 19:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0297 s/iter. Total: 0.1013 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 19:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0728 s/iter. Eval: 0.0496 s/iter. Total: 0.1232 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 19:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0735 s/iter. Eval: 0.0546 s/iter. Total: 0.1289 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 19:56:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.790786 (0.127507 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:56:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073387 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:56:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 19:56:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2394829213835406\n",
      "\u001b[32m[02/01 19:56:53 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 1699  total_loss: 1.526  loss_cls: 0.3127  loss_box_reg: 0.5291  loss_mask: 0.3135  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.2199  time: 0.5984  data_time: 0.2371  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:57:02 d2.utils.events]: \u001b[0m eta: 0:47:55  iter: 1719  total_loss: 1.582  loss_cls: 0.4048  loss_box_reg: 0.543  loss_mask: 0.3135  loss_rpn_cls: 0.09394  loss_rpn_loc: 0.2247  time: 0.5967  data_time: 0.1463  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:57:11 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 1739  total_loss: 1.291  loss_cls: 0.2787  loss_box_reg: 0.5168  loss_mask: 0.2842  loss_rpn_cls: 0.05526  loss_rpn_loc: 0.1577  time: 0.5953  data_time: 0.1669  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:57:23 d2.utils.events]: \u001b[0m eta: 0:47:33  iter: 1759  total_loss: 1.471  loss_cls: 0.3752  loss_box_reg: 0.5506  loss_mask: 0.3001  loss_rpn_cls: 0.05558  loss_rpn_loc: 0.1996  time: 0.5952  data_time: 0.2587  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:57:37 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 1779  total_loss: 1.466  loss_cls: 0.3557  loss_box_reg: 0.5369  loss_mask: 0.3113  loss_rpn_cls: 0.09528  loss_rpn_loc: 0.2187  time: 0.5963  data_time: 0.3694  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:57:49 d2.utils.events]: \u001b[0m eta: 0:47:21  iter: 1799  total_loss: 1.387  loss_cls: 0.3172  loss_box_reg: 0.497  loss_mask: 0.2948  loss_rpn_cls: 0.08251  loss_rpn_loc: 0.1975  time: 0.5965  data_time: 0.2882  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:58:01 d2.utils.events]: \u001b[0m eta: 0:47:10  iter: 1819  total_loss: 1.446  loss_cls: 0.3302  loss_box_reg: 0.5505  loss_mask: 0.3118  loss_rpn_cls: 0.09756  loss_rpn_loc: 0.1901  time: 0.5966  data_time: 0.2870  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:58:14 d2.utils.events]: \u001b[0m eta: 0:47:02  iter: 1839  total_loss: 1.407  loss_cls: 0.3183  loss_box_reg: 0.4723  loss_mask: 0.2773  loss_rpn_cls: 0.07964  loss_rpn_loc: 0.1856  time: 0.5972  data_time: 0.3142  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:58:25 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 1859  total_loss: 1.526  loss_cls: 0.3804  loss_box_reg: 0.5248  loss_mask: 0.3092  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.2116  time: 0.5967  data_time: 0.2205  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:58:35 d2.utils.events]: \u001b[0m eta: 0:46:31  iter: 1879  total_loss: 1.476  loss_cls: 0.3526  loss_box_reg: 0.5506  loss_mask: 0.3055  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.1911  time: 0.5954  data_time: 0.1619  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:58:46 d2.utils.events]: \u001b[0m eta: 0:46:35  iter: 1899  total_loss: 1.424  loss_cls: 0.3364  loss_box_reg: 0.5262  loss_mask: 0.2976  loss_rpn_cls: 0.09398  loss_rpn_loc: 0.2135  time: 0.5949  data_time: 0.2070  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:58:58 d2.utils.events]: \u001b[0m eta: 0:46:15  iter: 1919  total_loss: 1.497  loss_cls: 0.3026  loss_box_reg: 0.513  loss_mask: 0.3113  loss_rpn_cls: 0.09698  loss_rpn_loc: 0.2024  time: 0.5952  data_time: 0.2909  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:59:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:59:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 19:59:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 19:59:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 19:59:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 19:59:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 19:59:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0708 s/iter. Eval: 0.0373 s/iter. Total: 0.1086 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 19:59:16 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0731 s/iter. Eval: 0.0537 s/iter. Total: 0.1276 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 19:59:21 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0558 s/iter. Total: 0.1300 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 19:59:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.901478 (0.128461 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:59:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073100 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 19:59:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 19:59:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2517356688767718\n",
      "\u001b[32m[02/01 19:59:28 d2.utils.events]: \u001b[0m eta: 0:46:07  iter: 1939  total_loss: 1.569  loss_cls: 0.3824  loss_box_reg: 0.5465  loss_mask: 0.3198  loss_rpn_cls: 0.08999  loss_rpn_loc: 0.2228  time: 0.5959  data_time: 0.3273  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:59:37 d2.utils.events]: \u001b[0m eta: 0:45:53  iter: 1959  total_loss: 1.455  loss_cls: 0.3216  loss_box_reg: 0.5532  loss_mask: 0.3051  loss_rpn_cls: 0.07712  loss_rpn_loc: 0.203  time: 0.5944  data_time: 0.1286  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 19:59:48 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 1979  total_loss: 1.453  loss_cls: 0.3218  loss_box_reg: 0.5324  loss_mask: 0.3047  loss_rpn_cls: 0.08745  loss_rpn_loc: 0.2053  time: 0.5941  data_time: 0.2413  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:00:03 d2.utils.events]: \u001b[0m eta: 0:45:35  iter: 1999  total_loss: 1.458  loss_cls: 0.3219  loss_box_reg: 0.4943  loss_mask: 0.3157  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.2096  time: 0.5954  data_time: 0.3969  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:00:13 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 2019  total_loss: 1.355  loss_cls: 0.3385  loss_box_reg: 0.5167  loss_mask: 0.2827  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.1925  time: 0.5947  data_time: 0.2084  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:00:26 d2.utils.events]: \u001b[0m eta: 0:45:21  iter: 2039  total_loss: 1.473  loss_cls: 0.3637  loss_box_reg: 0.5209  loss_mask: 0.3033  loss_rpn_cls: 0.06622  loss_rpn_loc: 0.1973  time: 0.5952  data_time: 0.3208  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:00:38 d2.utils.events]: \u001b[0m eta: 0:45:15  iter: 2059  total_loss: 1.474  loss_cls: 0.3431  loss_box_reg: 0.5173  loss_mask: 0.289  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.2001  time: 0.5951  data_time: 0.2640  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:00:50 d2.utils.events]: \u001b[0m eta: 0:44:59  iter: 2079  total_loss: 1.449  loss_cls: 0.3219  loss_box_reg: 0.5131  loss_mask: 0.2896  loss_rpn_cls: 0.07543  loss_rpn_loc: 0.1982  time: 0.5950  data_time: 0.2746  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:01:03 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 2099  total_loss: 1.531  loss_cls: 0.3614  loss_box_reg: 0.5294  loss_mask: 0.2968  loss_rpn_cls: 0.08294  loss_rpn_loc: 0.2231  time: 0.5958  data_time: 0.3505  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:01:15 d2.utils.events]: \u001b[0m eta: 0:44:32  iter: 2119  total_loss: 1.44  loss_cls: 0.3326  loss_box_reg: 0.5427  loss_mask: 0.2975  loss_rpn_cls: 0.07442  loss_rpn_loc: 0.1977  time: 0.5958  data_time: 0.2883  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:01:25 d2.utils.events]: \u001b[0m eta: 0:44:23  iter: 2139  total_loss: 1.358  loss_cls: 0.2957  loss_box_reg: 0.5051  loss_mask: 0.3017  loss_rpn_cls: 0.05422  loss_rpn_loc: 0.191  time: 0.5949  data_time: 0.1834  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:01:40 d2.utils.events]: \u001b[0m eta: 0:44:16  iter: 2159  total_loss: 1.571  loss_cls: 0.3538  loss_box_reg: 0.5529  loss_mask: 0.3122  loss_rpn_cls: 0.1291  loss_rpn_loc: 0.2275  time: 0.5963  data_time: 0.4124  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:01:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:01:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:01:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:01:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:01:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:01:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0366 s/iter. Total: 0.1081 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 20:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0733 s/iter. Eval: 0.0535 s/iter. Total: 0.1275 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:02:01 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0735 s/iter. Eval: 0.0558 s/iter. Total: 0.1300 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:02:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.920222 (0.128623 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:02:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073239 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:02:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:02:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25606036651477365\n",
      "\u001b[32m[02/01 20:02:06 d2.utils.events]: \u001b[0m eta: 0:44:08  iter: 2179  total_loss: 1.422  loss_cls: 0.3278  loss_box_reg: 0.5398  loss_mask: 0.296  loss_rpn_cls: 0.06287  loss_rpn_loc: 0.183  time: 0.5954  data_time: 0.1853  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:02:18 d2.utils.events]: \u001b[0m eta: 0:43:59  iter: 2199  total_loss: 1.599  loss_cls: 0.382  loss_box_reg: 0.5369  loss_mask: 0.2948  loss_rpn_cls: 0.08993  loss_rpn_loc: 0.204  time: 0.5955  data_time: 0.2702  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:02:32 d2.utils.events]: \u001b[0m eta: 0:43:44  iter: 2219  total_loss: 1.358  loss_cls: 0.3007  loss_box_reg: 0.4928  loss_mask: 0.293  loss_rpn_cls: 0.08306  loss_rpn_loc: 0.2096  time: 0.5962  data_time: 0.3538  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:02:39 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 2239  total_loss: 1.393  loss_cls: 0.2877  loss_box_reg: 0.5504  loss_mask: 0.298  loss_rpn_cls: 0.06101  loss_rpn_loc: 0.1907  time: 0.5942  data_time: 0.0682  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:02:49 d2.utils.events]: \u001b[0m eta: 0:43:25  iter: 2259  total_loss: 1.454  loss_cls: 0.3232  loss_box_reg: 0.5021  loss_mask: 0.2852  loss_rpn_cls: 0.07895  loss_rpn_loc: 0.1909  time: 0.5930  data_time: 0.1376  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:03:02 d2.utils.events]: \u001b[0m eta: 0:43:20  iter: 2279  total_loss: 1.45  loss_cls: 0.3437  loss_box_reg: 0.5277  loss_mask: 0.2869  loss_rpn_cls: 0.08891  loss_rpn_loc: 0.2017  time: 0.5936  data_time: 0.3276  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:03:13 d2.utils.events]: \u001b[0m eta: 0:43:11  iter: 2299  total_loss: 1.447  loss_cls: 0.3587  loss_box_reg: 0.5477  loss_mask: 0.2923  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.1944  time: 0.5934  data_time: 0.2578  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:03:25 d2.utils.events]: \u001b[0m eta: 0:43:02  iter: 2319  total_loss: 1.478  loss_cls: 0.3272  loss_box_reg: 0.5135  loss_mask: 0.308  loss_rpn_cls: 0.08477  loss_rpn_loc: 0.2155  time: 0.5934  data_time: 0.2762  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:03:39 d2.utils.events]: \u001b[0m eta: 0:42:56  iter: 2339  total_loss: 1.457  loss_cls: 0.3342  loss_box_reg: 0.5283  loss_mask: 0.3226  loss_rpn_cls: 0.07762  loss_rpn_loc: 0.1982  time: 0.5942  data_time: 0.3708  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:03:48 d2.utils.events]: \u001b[0m eta: 0:42:47  iter: 2359  total_loss: 1.433  loss_cls: 0.2906  loss_box_reg: 0.5506  loss_mask: 0.3069  loss_rpn_cls: 0.06227  loss_rpn_loc: 0.1806  time: 0.5931  data_time: 0.1496  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:04:01 d2.utils.events]: \u001b[0m eta: 0:42:41  iter: 2379  total_loss: 1.402  loss_cls: 0.3189  loss_box_reg: 0.5349  loss_mask: 0.2944  loss_rpn_cls: 0.09805  loss_rpn_loc: 0.215  time: 0.5937  data_time: 0.3464  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:04:15 d2.utils.events]: \u001b[0m eta: 0:42:37  iter: 2399  total_loss: 1.516  loss_cls: 0.3803  loss_box_reg: 0.5282  loss_mask: 0.3027  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.2158  time: 0.5945  data_time: 0.3511  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:04:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:04:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:04:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:04:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:04:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:04:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0700 s/iter. Eval: 0.0356 s/iter. Total: 0.1062 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 20:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0724 s/iter. Eval: 0.0501 s/iter. Total: 0.1232 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 20:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0727 s/iter. Eval: 0.0520 s/iter. Total: 0.1255 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/01 20:04:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.345252 (0.123666 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:04:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072374 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:04:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:04:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2516091207684288\n",
      "\u001b[32m[02/01 20:04:42 d2.utils.events]: \u001b[0m eta: 0:42:32  iter: 2419  total_loss: 1.456  loss_cls: 0.3863  loss_box_reg: 0.5184  loss_mask: 0.294  loss_rpn_cls: 0.07995  loss_rpn_loc: 0.2083  time: 0.5943  data_time: 0.2609  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:04:50 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 2439  total_loss: 1.337  loss_cls: 0.2859  loss_box_reg: 0.5362  loss_mask: 0.2907  loss_rpn_cls: 0.0622  loss_rpn_loc: 0.1878  time: 0.5927  data_time: 0.0945  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:05:02 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 2459  total_loss: 1.461  loss_cls: 0.3679  loss_box_reg: 0.5496  loss_mask: 0.3032  loss_rpn_cls: 0.09821  loss_rpn_loc: 0.2094  time: 0.5926  data_time: 0.2689  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:05:15 d2.utils.events]: \u001b[0m eta: 0:42:08  iter: 2479  total_loss: 1.376  loss_cls: 0.3181  loss_box_reg: 0.4724  loss_mask: 0.2969  loss_rpn_cls: 0.08684  loss_rpn_loc: 0.193  time: 0.5932  data_time: 0.3406  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:05:27 d2.utils.events]: \u001b[0m eta: 0:42:02  iter: 2499  total_loss: 1.373  loss_cls: 0.3216  loss_box_reg: 0.5067  loss_mask: 0.3064  loss_rpn_cls: 0.08952  loss_rpn_loc: 0.2115  time: 0.5932  data_time: 0.2782  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:05:40 d2.utils.events]: \u001b[0m eta: 0:41:56  iter: 2519  total_loss: 1.461  loss_cls: 0.3166  loss_box_reg: 0.5188  loss_mask: 0.3044  loss_rpn_cls: 0.09441  loss_rpn_loc: 0.2159  time: 0.5934  data_time: 0.3017  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:05:54 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 2539  total_loss: 1.54  loss_cls: 0.3617  loss_box_reg: 0.5378  loss_mask: 0.3005  loss_rpn_cls: 0.08269  loss_rpn_loc: 0.2044  time: 0.5945  data_time: 0.4043  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:06:08 d2.utils.events]: \u001b[0m eta: 0:41:42  iter: 2559  total_loss: 1.431  loss_cls: 0.3252  loss_box_reg: 0.5043  loss_mask: 0.2961  loss_rpn_cls: 0.08394  loss_rpn_loc: 0.2044  time: 0.5953  data_time: 0.3738  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:06:16 d2.utils.events]: \u001b[0m eta: 0:41:33  iter: 2579  total_loss: 1.396  loss_cls: 0.3494  loss_box_reg: 0.5059  loss_mask: 0.2753  loss_rpn_cls: 0.06807  loss_rpn_loc: 0.1924  time: 0.5937  data_time: 0.0833  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:06:28 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 2599  total_loss: 1.419  loss_cls: 0.3155  loss_box_reg: 0.5167  loss_mask: 0.3187  loss_rpn_cls: 0.09592  loss_rpn_loc: 0.2178  time: 0.5936  data_time: 0.2582  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:06:40 d2.utils.events]: \u001b[0m eta: 0:41:22  iter: 2619  total_loss: 1.425  loss_cls: 0.3243  loss_box_reg: 0.5297  loss_mask: 0.2933  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.1963  time: 0.5940  data_time: 0.3150  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:06:50 d2.utils.events]: \u001b[0m eta: 0:41:12  iter: 2639  total_loss: 1.482  loss_cls: 0.364  loss_box_reg: 0.5646  loss_mask: 0.3062  loss_rpn_cls: 0.06751  loss_rpn_loc: 0.1957  time: 0.5930  data_time: 0.1659  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:07:02 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 2659  total_loss: 1.484  loss_cls: 0.3559  loss_box_reg: 0.5221  loss_mask: 0.3102  loss_rpn_cls: 0.09089  loss_rpn_loc: 0.2074  time: 0.5931  data_time: 0.2834  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:07:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:07:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:07:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:07:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:07:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:07:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:07:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0714 s/iter. Eval: 0.0406 s/iter. Total: 0.1126 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:07:10 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0007 s/iter. Inference: 0.0745 s/iter. Eval: 0.0603 s/iter. Total: 0.1355 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 20:07:15 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.0766 s/iter. Eval: 0.0635 s/iter. Total: 0.1409 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:07:20 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0770 s/iter. Eval: 0.0607 s/iter. Total: 0.1385 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:07:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.180912 (0.139491 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:07:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077148 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:07:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:07:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25953794216347315\n",
      "\u001b[32m[02/01 20:07:30 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 2679  total_loss: 1.471  loss_cls: 0.3527  loss_box_reg: 0.5268  loss_mask: 0.2998  loss_rpn_cls: 0.07794  loss_rpn_loc: 0.1929  time: 0.5925  data_time: 0.1664  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:07:44 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 2699  total_loss: 1.559  loss_cls: 0.371  loss_box_reg: 0.5044  loss_mask: 0.2904  loss_rpn_cls: 0.08289  loss_rpn_loc: 0.2162  time: 0.5933  data_time: 0.3698  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:07:54 d2.utils.events]: \u001b[0m eta: 0:41:00  iter: 2719  total_loss: 1.319  loss_cls: 0.2963  loss_box_reg: 0.5025  loss_mask: 0.2909  loss_rpn_cls: 0.06959  loss_rpn_loc: 0.1876  time: 0.5926  data_time: 0.1645  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:08:03 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 2739  total_loss: 1.404  loss_cls: 0.3204  loss_box_reg: 0.5146  loss_mask: 0.2971  loss_rpn_cls: 0.07745  loss_rpn_loc: 0.1792  time: 0.5916  data_time: 0.1302  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:08:17 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 2759  total_loss: 1.51  loss_cls: 0.3554  loss_box_reg: 0.5303  loss_mask: 0.3048  loss_rpn_cls: 0.08916  loss_rpn_loc: 0.2119  time: 0.5924  data_time: 0.3522  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:08:26 d2.utils.events]: \u001b[0m eta: 0:40:55  iter: 2779  total_loss: 1.413  loss_cls: 0.2825  loss_box_reg: 0.5162  loss_mask: 0.3053  loss_rpn_cls: 0.0596  loss_rpn_loc: 0.1867  time: 0.5913  data_time: 0.1221  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:08:38 d2.utils.events]: \u001b[0m eta: 0:40:51  iter: 2799  total_loss: 1.446  loss_cls: 0.3284  loss_box_reg: 0.4951  loss_mask: 0.2912  loss_rpn_cls: 0.07905  loss_rpn_loc: 0.1927  time: 0.5912  data_time: 0.2503  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:08:52 d2.utils.events]: \u001b[0m eta: 0:40:51  iter: 2819  total_loss: 1.349  loss_cls: 0.2901  loss_box_reg: 0.4961  loss_mask: 0.2958  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.1963  time: 0.5921  data_time: 0.3693  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:09:02 d2.utils.events]: \u001b[0m eta: 0:40:38  iter: 2839  total_loss: 1.457  loss_cls: 0.3418  loss_box_reg: 0.4995  loss_mask: 0.2827  loss_rpn_cls: 0.07126  loss_rpn_loc: 0.1981  time: 0.5915  data_time: 0.1814  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:09:14 d2.utils.events]: \u001b[0m eta: 0:40:28  iter: 2859  total_loss: 1.384  loss_cls: 0.3042  loss_box_reg: 0.5156  loss_mask: 0.3051  loss_rpn_cls: 0.06629  loss_rpn_loc: 0.1878  time: 0.5916  data_time: 0.2868  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:09:26 d2.utils.events]: \u001b[0m eta: 0:40:24  iter: 2879  total_loss: 1.447  loss_cls: 0.3182  loss_box_reg: 0.5104  loss_mask: 0.3067  loss_rpn_cls: 0.0864  loss_rpn_loc: 0.2135  time: 0.5915  data_time: 0.2542  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:09:38 d2.utils.events]: \u001b[0m eta: 0:40:19  iter: 2899  total_loss: 1.462  loss_cls: 0.3455  loss_box_reg: 0.5117  loss_mask: 0.3016  loss_rpn_cls: 0.08986  loss_rpn_loc: 0.2037  time: 0.5916  data_time: 0.2498  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:09:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:09:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:09:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:09:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:09:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:09:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:09:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0340 s/iter. Total: 0.1087 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 20:09:50 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0761 s/iter. Eval: 0.0521 s/iter. Total: 0.1291 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:09:55 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0767 s/iter. Eval: 0.0565 s/iter. Total: 0.1340 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:09:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.296813 (0.131869 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:09:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076326 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:09:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:09:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2486290753072497\n",
      "\u001b[32m[02/01 20:10:07 d2.utils.events]: \u001b[0m eta: 0:40:16  iter: 2919  total_loss: 1.52  loss_cls: 0.3446  loss_box_reg: 0.5245  loss_mask: 0.2995  loss_rpn_cls: 0.07568  loss_rpn_loc: 0.2063  time: 0.5919  data_time: 0.3020  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:10:22 d2.utils.events]: \u001b[0m eta: 0:40:11  iter: 2939  total_loss: 1.516  loss_cls: 0.3687  loss_box_reg: 0.5387  loss_mask: 0.309  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.2273  time: 0.5929  data_time: 0.3915  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:10:35 d2.utils.events]: \u001b[0m eta: 0:40:09  iter: 2959  total_loss: 1.371  loss_cls: 0.3032  loss_box_reg: 0.5163  loss_mask: 0.3015  loss_rpn_cls: 0.08153  loss_rpn_loc: 0.2203  time: 0.5933  data_time: 0.3247  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:10:46 d2.utils.events]: \u001b[0m eta: 0:40:04  iter: 2979  total_loss: 1.461  loss_cls: 0.3443  loss_box_reg: 0.5058  loss_mask: 0.3043  loss_rpn_cls: 0.09202  loss_rpn_loc: 0.1958  time: 0.5932  data_time: 0.2480  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:10:57 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 2999  total_loss: 1.438  loss_cls: 0.3256  loss_box_reg: 0.5142  loss_mask: 0.299  loss_rpn_cls: 0.08188  loss_rpn_loc: 0.1984  time: 0.5927  data_time: 0.1967  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:11:10 d2.utils.events]: \u001b[0m eta: 0:39:52  iter: 3019  total_loss: 1.415  loss_cls: 0.3376  loss_box_reg: 0.49  loss_mask: 0.3001  loss_rpn_cls: 0.09004  loss_rpn_loc: 0.1944  time: 0.5932  data_time: 0.3189  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:11:20 d2.utils.events]: \u001b[0m eta: 0:39:45  iter: 3039  total_loss: 1.387  loss_cls: 0.3053  loss_box_reg: 0.5047  loss_mask: 0.2912  loss_rpn_cls: 0.04783  loss_rpn_loc: 0.2018  time: 0.5924  data_time: 0.1544  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:11:31 d2.utils.events]: \u001b[0m eta: 0:39:39  iter: 3059  total_loss: 1.428  loss_cls: 0.3215  loss_box_reg: 0.4924  loss_mask: 0.2858  loss_rpn_cls: 0.08288  loss_rpn_loc: 0.1889  time: 0.5921  data_time: 0.2073  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:11:45 d2.utils.events]: \u001b[0m eta: 0:39:41  iter: 3079  total_loss: 1.467  loss_cls: 0.3466  loss_box_reg: 0.5079  loss_mask: 0.3202  loss_rpn_cls: 0.0977  loss_rpn_loc: 0.2037  time: 0.5928  data_time: 0.3530  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:11:56 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 3099  total_loss: 1.463  loss_cls: 0.3253  loss_box_reg: 0.499  loss_mask: 0.3014  loss_rpn_cls: 0.09678  loss_rpn_loc: 0.2052  time: 0.5925  data_time: 0.2108  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:12:10 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 3119  total_loss: 1.383  loss_cls: 0.3132  loss_box_reg: 0.481  loss_mask: 0.2971  loss_rpn_cls: 0.06497  loss_rpn_loc: 0.2047  time: 0.5932  data_time: 0.3541  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:12:21 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 3139  total_loss: 1.447  loss_cls: 0.3513  loss_box_reg: 0.4982  loss_mask: 0.2927  loss_rpn_cls: 0.07683  loss_rpn_loc: 0.2047  time: 0.5931  data_time: 0.2438  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:12:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:12:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:12:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:12:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:12:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:12:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0350 s/iter. Total: 0.1097 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0771 s/iter. Eval: 0.0554 s/iter. Total: 0.1333 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0778 s/iter. Eval: 0.0604 s/iter. Total: 0.1390 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0585 s/iter. Total: 0.1369 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:12:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.944125 (0.137449 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:12:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077565 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:12:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:12:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2664379209705635\n",
      "\u001b[32m[02/01 20:12:49 d2.utils.events]: \u001b[0m eta: 0:39:31  iter: 3159  total_loss: 1.31  loss_cls: 0.3332  loss_box_reg: 0.492  loss_mask: 0.2868  loss_rpn_cls: 0.06016  loss_rpn_loc: 0.188  time: 0.5925  data_time: 0.1669  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:12:59 d2.utils.events]: \u001b[0m eta: 0:39:29  iter: 3179  total_loss: 1.452  loss_cls: 0.3334  loss_box_reg: 0.5092  loss_mask: 0.2994  loss_rpn_cls: 0.07964  loss_rpn_loc: 0.211  time: 0.5921  data_time: 0.1969  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:13:12 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 3199  total_loss: 1.46  loss_cls: 0.314  loss_box_reg: 0.5212  loss_mask: 0.3059  loss_rpn_cls: 0.08731  loss_rpn_loc: 0.2045  time: 0.5924  data_time: 0.2843  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:13:22 d2.utils.events]: \u001b[0m eta: 0:39:15  iter: 3219  total_loss: 1.362  loss_cls: 0.2898  loss_box_reg: 0.4919  loss_mask: 0.2834  loss_rpn_cls: 0.06034  loss_rpn_loc: 0.1799  time: 0.5918  data_time: 0.1659  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:13:37 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 3239  total_loss: 1.423  loss_cls: 0.3508  loss_box_reg: 0.5133  loss_mask: 0.2945  loss_rpn_cls: 0.101  loss_rpn_loc: 0.2044  time: 0.5928  data_time: 0.3976  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:13:51 d2.utils.events]: \u001b[0m eta: 0:39:15  iter: 3259  total_loss: 1.486  loss_cls: 0.3537  loss_box_reg: 0.4892  loss_mask: 0.296  loss_rpn_cls: 0.09259  loss_rpn_loc: 0.1971  time: 0.5934  data_time: 0.3619  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:14:01 d2.utils.events]: \u001b[0m eta: 0:39:03  iter: 3279  total_loss: 1.374  loss_cls: 0.3047  loss_box_reg: 0.5527  loss_mask: 0.2796  loss_rpn_cls: 0.07685  loss_rpn_loc: 0.1929  time: 0.5928  data_time: 0.1658  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:14:14 d2.utils.events]: \u001b[0m eta: 0:39:01  iter: 3299  total_loss: 1.452  loss_cls: 0.3093  loss_box_reg: 0.5137  loss_mask: 0.3148  loss_rpn_cls: 0.07988  loss_rpn_loc: 0.2075  time: 0.5934  data_time: 0.3448  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:14:24 d2.utils.events]: \u001b[0m eta: 0:38:56  iter: 3319  total_loss: 1.402  loss_cls: 0.2999  loss_box_reg: 0.5258  loss_mask: 0.3036  loss_rpn_cls: 0.08565  loss_rpn_loc: 0.19  time: 0.5927  data_time: 0.1500  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:14:38 d2.utils.events]: \u001b[0m eta: 0:38:55  iter: 3339  total_loss: 1.434  loss_cls: 0.2939  loss_box_reg: 0.5158  loss_mask: 0.3104  loss_rpn_cls: 0.08775  loss_rpn_loc: 0.1899  time: 0.5933  data_time: 0.3523  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:14:51 d2.utils.events]: \u001b[0m eta: 0:38:55  iter: 3359  total_loss: 1.315  loss_cls: 0.3051  loss_box_reg: 0.4581  loss_mask: 0.2688  loss_rpn_cls: 0.06018  loss_rpn_loc: 0.1829  time: 0.5936  data_time: 0.3164  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:15:03 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 3379  total_loss: 1.414  loss_cls: 0.3373  loss_box_reg: 0.5048  loss_mask: 0.3144  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.2032  time: 0.5938  data_time: 0.2826  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:15:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:15:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:15:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:15:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:15:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:15:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:15:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0340 s/iter. Total: 0.1085 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 20:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0545 s/iter. Total: 0.1321 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:15:18 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0572 s/iter. Total: 0.1353 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:15:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.515225 (0.133752 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:15:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077058 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:15:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:15:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26400218414589943\n",
      "\u001b[32m[02/01 20:15:29 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 3399  total_loss: 1.46  loss_cls: 0.3135  loss_box_reg: 0.5464  loss_mask: 0.2956  loss_rpn_cls: 0.07016  loss_rpn_loc: 0.2031  time: 0.5927  data_time: 0.0960  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:15:42 d2.utils.events]: \u001b[0m eta: 0:38:23  iter: 3419  total_loss: 1.391  loss_cls: 0.2951  loss_box_reg: 0.4829  loss_mask: 0.3026  loss_rpn_cls: 0.08427  loss_rpn_loc: 0.196  time: 0.5931  data_time: 0.3246  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:15:51 d2.utils.events]: \u001b[0m eta: 0:38:21  iter: 3439  total_loss: 1.374  loss_cls: 0.3011  loss_box_reg: 0.5094  loss_mask: 0.3002  loss_rpn_cls: 0.04488  loss_rpn_loc: 0.1726  time: 0.5922  data_time: 0.1142  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:16:01 d2.utils.events]: \u001b[0m eta: 0:38:07  iter: 3459  total_loss: 1.318  loss_cls: 0.2949  loss_box_reg: 0.4936  loss_mask: 0.2821  loss_rpn_cls: 0.06525  loss_rpn_loc: 0.1803  time: 0.5917  data_time: 0.1816  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:16:12 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 3479  total_loss: 1.419  loss_cls: 0.3226  loss_box_reg: 0.5402  loss_mask: 0.2941  loss_rpn_cls: 0.08475  loss_rpn_loc: 0.1849  time: 0.5916  data_time: 0.2318  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:16:24 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 3499  total_loss: 1.478  loss_cls: 0.3441  loss_box_reg: 0.5283  loss_mask: 0.2999  loss_rpn_cls: 0.09069  loss_rpn_loc: 0.2062  time: 0.5915  data_time: 0.2495  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:16:36 d2.utils.events]: \u001b[0m eta: 0:37:44  iter: 3519  total_loss: 1.434  loss_cls: 0.3296  loss_box_reg: 0.4869  loss_mask: 0.2897  loss_rpn_cls: 0.0868  loss_rpn_loc: 0.1995  time: 0.5916  data_time: 0.2767  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:16:52 d2.utils.events]: \u001b[0m eta: 0:37:38  iter: 3539  total_loss: 1.417  loss_cls: 0.3316  loss_box_reg: 0.4802  loss_mask: 0.2877  loss_rpn_cls: 0.08935  loss_rpn_loc: 0.2124  time: 0.5929  data_time: 0.4570  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:17:04 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 3559  total_loss: 1.407  loss_cls: 0.3232  loss_box_reg: 0.5405  loss_mask: 0.2951  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.1919  time: 0.5927  data_time: 0.2300  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:17:17 d2.utils.events]: \u001b[0m eta: 0:37:33  iter: 3579  total_loss: 1.436  loss_cls: 0.3129  loss_box_reg: 0.5093  loss_mask: 0.3109  loss_rpn_cls: 0.09602  loss_rpn_loc: 0.2121  time: 0.5932  data_time: 0.3268  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:17:28 d2.utils.events]: \u001b[0m eta: 0:37:27  iter: 3599  total_loss: 1.452  loss_cls: 0.3411  loss_box_reg: 0.4799  loss_mask: 0.303  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.2075  time: 0.5930  data_time: 0.2226  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:17:41 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 3619  total_loss: 1.453  loss_cls: 0.3041  loss_box_reg: 0.5556  loss_mask: 0.3134  loss_rpn_cls: 0.06794  loss_rpn_loc: 0.208  time: 0.5931  data_time: 0.2785  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:17:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:17:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:17:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:17:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:17:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:17:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0753 s/iter. Eval: 0.0411 s/iter. Total: 0.1170 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0007 s/iter. Inference: 0.0784 s/iter. Eval: 0.0615 s/iter. Total: 0.1407 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 20:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.0785 s/iter. Eval: 0.0633 s/iter. Total: 0.1427 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0782 s/iter. Eval: 0.0613 s/iter. Total: 0.1404 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:18:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.361590 (0.141048 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:18:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078295 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:18:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:18:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26472456802399985\n",
      "\u001b[32m[02/01 20:18:08 d2.utils.events]: \u001b[0m eta: 0:37:21  iter: 3639  total_loss: 1.309  loss_cls: 0.3247  loss_box_reg: 0.4951  loss_mask: 0.2954  loss_rpn_cls: 0.05713  loss_rpn_loc: 0.1755  time: 0.5923  data_time: 0.1229  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:18:21 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 3659  total_loss: 1.567  loss_cls: 0.3617  loss_box_reg: 0.5294  loss_mask: 0.3088  loss_rpn_cls: 0.08482  loss_rpn_loc: 0.2082  time: 0.5928  data_time: 0.3304  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:18:32 d2.utils.events]: \u001b[0m eta: 0:37:08  iter: 3679  total_loss: 1.515  loss_cls: 0.3572  loss_box_reg: 0.5106  loss_mask: 0.3136  loss_rpn_cls: 0.0931  loss_rpn_loc: 0.2219  time: 0.5926  data_time: 0.2099  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:18:45 d2.utils.events]: \u001b[0m eta: 0:37:01  iter: 3699  total_loss: 1.369  loss_cls: 0.2911  loss_box_reg: 0.4766  loss_mask: 0.3022  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.21  time: 0.5930  data_time: 0.3224  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:18:56 d2.utils.events]: \u001b[0m eta: 0:36:54  iter: 3719  total_loss: 1.384  loss_cls: 0.3035  loss_box_reg: 0.4892  loss_mask: 0.2912  loss_rpn_cls: 0.07306  loss_rpn_loc: 0.18  time: 0.5927  data_time: 0.2080  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:19:07 d2.utils.events]: \u001b[0m eta: 0:36:46  iter: 3739  total_loss: 1.396  loss_cls: 0.2983  loss_box_reg: 0.5132  loss_mask: 0.3038  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.1826  time: 0.5924  data_time: 0.2069  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:19:22 d2.utils.events]: \u001b[0m eta: 0:36:40  iter: 3759  total_loss: 1.465  loss_cls: 0.3645  loss_box_reg: 0.5109  loss_mask: 0.2984  loss_rpn_cls: 0.09464  loss_rpn_loc: 0.2348  time: 0.5932  data_time: 0.4049  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:19:33 d2.utils.events]: \u001b[0m eta: 0:36:34  iter: 3779  total_loss: 1.273  loss_cls: 0.308  loss_box_reg: 0.4859  loss_mask: 0.2818  loss_rpn_cls: 0.05823  loss_rpn_loc: 0.1865  time: 0.5929  data_time: 0.2082  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:19:46 d2.utils.events]: \u001b[0m eta: 0:36:27  iter: 3799  total_loss: 1.52  loss_cls: 0.3657  loss_box_reg: 0.5184  loss_mask: 0.2861  loss_rpn_cls: 0.08641  loss_rpn_loc: 0.2028  time: 0.5932  data_time: 0.3106  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:19:58 d2.utils.events]: \u001b[0m eta: 0:36:19  iter: 3819  total_loss: 1.44  loss_cls: 0.3046  loss_box_reg: 0.5097  loss_mask: 0.2872  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1973  time: 0.5932  data_time: 0.2623  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:20:10 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 3839  total_loss: 1.366  loss_cls: 0.3165  loss_box_reg: 0.4638  loss_mask: 0.276  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1922  time: 0.5933  data_time: 0.2719  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:20:23 d2.utils.events]: \u001b[0m eta: 0:36:13  iter: 3859  total_loss: 1.359  loss_cls: 0.2848  loss_box_reg: 0.5037  loss_mask: 0.2904  loss_rpn_cls: 0.0586  loss_rpn_loc: 0.1899  time: 0.5936  data_time: 0.3072  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:20:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:20:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:20:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:20:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:20:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:20:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0747 s/iter. Eval: 0.0382 s/iter. Total: 0.1135 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0007 s/iter. Inference: 0.0781 s/iter. Eval: 0.0606 s/iter. Total: 0.1395 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 20:20:41 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0007 s/iter. Inference: 0.0783 s/iter. Eval: 0.0630 s/iter. Total: 0.1420 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:20:46 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0780 s/iter. Eval: 0.0607 s/iter. Total: 0.1395 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:20:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.270276 (0.140261 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:20:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078103 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:20:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:20:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2638093378873082\n",
      "\u001b[32m[02/01 20:20:50 d2.utils.events]: \u001b[0m eta: 0:36:02  iter: 3879  total_loss: 1.415  loss_cls: 0.3338  loss_box_reg: 0.5124  loss_mask: 0.2835  loss_rpn_cls: 0.081  loss_rpn_loc: 0.1921  time: 0.5930  data_time: 0.1639  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:21:04 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 3899  total_loss: 1.395  loss_cls: 0.3027  loss_box_reg: 0.4999  loss_mask: 0.3017  loss_rpn_cls: 0.07346  loss_rpn_loc: 0.1923  time: 0.5936  data_time: 0.3534  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:21:13 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 3919  total_loss: 1.307  loss_cls: 0.3122  loss_box_reg: 0.5082  loss_mask: 0.2909  loss_rpn_cls: 0.06218  loss_rpn_loc: 0.1791  time: 0.5929  data_time: 0.1130  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:21:24 d2.utils.events]: \u001b[0m eta: 0:35:33  iter: 3939  total_loss: 1.39  loss_cls: 0.3254  loss_box_reg: 0.532  loss_mask: 0.3039  loss_rpn_cls: 0.07195  loss_rpn_loc: 0.1867  time: 0.5927  data_time: 0.2254  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:21:36 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 3959  total_loss: 1.345  loss_cls: 0.2785  loss_box_reg: 0.4871  loss_mask: 0.2928  loss_rpn_cls: 0.06349  loss_rpn_loc: 0.1751  time: 0.5926  data_time: 0.2343  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:21:49 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 3979  total_loss: 1.413  loss_cls: 0.3286  loss_box_reg: 0.5176  loss_mask: 0.3089  loss_rpn_cls: 0.06112  loss_rpn_loc: 0.2016  time: 0.5928  data_time: 0.3082  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:22:01 d2.utils.events]: \u001b[0m eta: 0:35:22  iter: 3999  total_loss: 1.387  loss_cls: 0.2897  loss_box_reg: 0.5286  loss_mask: 0.296  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.1925  time: 0.5928  data_time: 0.2573  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:22:14 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 4019  total_loss: 1.448  loss_cls: 0.3582  loss_box_reg: 0.5145  loss_mask: 0.2875  loss_rpn_cls: 0.09082  loss_rpn_loc: 0.1952  time: 0.5931  data_time: 0.3062  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:22:24 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 4039  total_loss: 1.427  loss_cls: 0.327  loss_box_reg: 0.539  loss_mask: 0.2954  loss_rpn_cls: 0.07194  loss_rpn_loc: 0.1973  time: 0.5928  data_time: 0.2017  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:22:36 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 4059  total_loss: 1.398  loss_cls: 0.2969  loss_box_reg: 0.4927  loss_mask: 0.309  loss_rpn_cls: 0.08525  loss_rpn_loc: 0.1953  time: 0.5928  data_time: 0.2618  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:22:47 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 4079  total_loss: 1.4  loss_cls: 0.3582  loss_box_reg: 0.4833  loss_mask: 0.2864  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.1982  time: 0.5925  data_time: 0.2035  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:22:58 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 4099  total_loss: 1.387  loss_cls: 0.3091  loss_box_reg: 0.4988  loss_mask: 0.2956  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.2072  time: 0.5923  data_time: 0.2060  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:23:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:23:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:23:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:23:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:23:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:23:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0379 s/iter. Total: 0.1126 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0584 s/iter. Total: 0.1364 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 20:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0007 s/iter. Inference: 0.0779 s/iter. Eval: 0.0622 s/iter. Total: 0.1410 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0596 s/iter. Total: 0.1379 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:23:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.075922 (0.138586 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:23:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077625 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:23:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:23:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2644712628206618\n",
      "\u001b[32m[02/01 20:23:31 d2.utils.events]: \u001b[0m eta: 0:34:38  iter: 4119  total_loss: 1.502  loss_cls: 0.3479  loss_box_reg: 0.5125  loss_mask: 0.3082  loss_rpn_cls: 0.08706  loss_rpn_loc: 0.2134  time: 0.5932  data_time: 0.4335  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:23:43 d2.utils.events]: \u001b[0m eta: 0:34:24  iter: 4139  total_loss: 1.301  loss_cls: 0.2652  loss_box_reg: 0.488  loss_mask: 0.2876  loss_rpn_cls: 0.05105  loss_rpn_loc: 0.1742  time: 0.5933  data_time: 0.2979  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:23:53 d2.utils.events]: \u001b[0m eta: 0:34:11  iter: 4159  total_loss: 1.329  loss_cls: 0.3086  loss_box_reg: 0.4884  loss_mask: 0.2926  loss_rpn_cls: 0.05992  loss_rpn_loc: 0.1905  time: 0.5929  data_time: 0.1891  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:24:06 d2.utils.events]: \u001b[0m eta: 0:34:04  iter: 4179  total_loss: 1.342  loss_cls: 0.304  loss_box_reg: 0.4859  loss_mask: 0.2935  loss_rpn_cls: 0.07761  loss_rpn_loc: 0.201  time: 0.5931  data_time: 0.3270  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:24:19 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 4199  total_loss: 1.348  loss_cls: 0.3171  loss_box_reg: 0.4846  loss_mask: 0.3016  loss_rpn_cls: 0.06993  loss_rpn_loc: 0.189  time: 0.5934  data_time: 0.3231  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:24:31 d2.utils.events]: \u001b[0m eta: 0:33:48  iter: 4219  total_loss: 1.51  loss_cls: 0.3617  loss_box_reg: 0.524  loss_mask: 0.2943  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.2077  time: 0.5933  data_time: 0.2581  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:24:43 d2.utils.events]: \u001b[0m eta: 0:33:36  iter: 4239  total_loss: 1.416  loss_cls: 0.3346  loss_box_reg: 0.5033  loss_mask: 0.2969  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.1965  time: 0.5934  data_time: 0.2816  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:24:52 d2.utils.events]: \u001b[0m eta: 0:33:28  iter: 4259  total_loss: 1.294  loss_cls: 0.2641  loss_box_reg: 0.4779  loss_mask: 0.2966  loss_rpn_cls: 0.05913  loss_rpn_loc: 0.1736  time: 0.5927  data_time: 0.1513  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:25:05 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 4279  total_loss: 1.483  loss_cls: 0.3774  loss_box_reg: 0.5338  loss_mask: 0.3058  loss_rpn_cls: 0.0961  loss_rpn_loc: 0.2152  time: 0.5930  data_time: 0.3143  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:25:14 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 4299  total_loss: 1.457  loss_cls: 0.3658  loss_box_reg: 0.4999  loss_mask: 0.3098  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.203  time: 0.5924  data_time: 0.1435  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:25:26 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 4319  total_loss: 1.46  loss_cls: 0.3387  loss_box_reg: 0.5138  loss_mask: 0.2897  loss_rpn_cls: 0.065  loss_rpn_loc: 0.1935  time: 0.5922  data_time: 0.2319  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:25:39 d2.utils.events]: \u001b[0m eta: 0:32:58  iter: 4339  total_loss: 1.348  loss_cls: 0.2931  loss_box_reg: 0.4954  loss_mask: 0.2994  loss_rpn_cls: 0.06458  loss_rpn_loc: 0.1996  time: 0.5925  data_time: 0.3239  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:25:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:25:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:25:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:25:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:25:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:25:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0350 s/iter. Total: 0.1059 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 20:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0737 s/iter. Eval: 0.0541 s/iter. Total: 0.1286 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0744 s/iter. Eval: 0.0597 s/iter. Total: 0.1349 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:26:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.409367 (0.132839 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:26:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074058 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:26:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:26:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2633209328186665\n",
      "\u001b[32m[02/01 20:26:07 d2.utils.events]: \u001b[0m eta: 0:32:52  iter: 4359  total_loss: 1.379  loss_cls: 0.3081  loss_box_reg: 0.4841  loss_mask: 0.2873  loss_rpn_cls: 0.06425  loss_rpn_loc: 0.202  time: 0.5925  data_time: 0.2677  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:26:17 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 4379  total_loss: 1.352  loss_cls: 0.2829  loss_box_reg: 0.521  loss_mask: 0.3098  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.1893  time: 0.5919  data_time: 0.1472  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:26:27 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 4399  total_loss: 1.4  loss_cls: 0.3389  loss_box_reg: 0.4901  loss_mask: 0.2818  loss_rpn_cls: 0.073  loss_rpn_loc: 0.1862  time: 0.5916  data_time: 0.2035  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:26:40 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 4419  total_loss: 1.368  loss_cls: 0.2808  loss_box_reg: 0.4742  loss_mask: 0.2783  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1983  time: 0.5918  data_time: 0.3154  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:26:51 d2.utils.events]: \u001b[0m eta: 0:32:22  iter: 4439  total_loss: 1.452  loss_cls: 0.3307  loss_box_reg: 0.5232  loss_mask: 0.299  loss_rpn_cls: 0.07496  loss_rpn_loc: 0.1832  time: 0.5917  data_time: 0.2308  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:27:03 d2.utils.events]: \u001b[0m eta: 0:32:15  iter: 4459  total_loss: 1.383  loss_cls: 0.2883  loss_box_reg: 0.5045  loss_mask: 0.2959  loss_rpn_cls: 0.07041  loss_rpn_loc: 0.1938  time: 0.5917  data_time: 0.2640  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:27:15 d2.utils.events]: \u001b[0m eta: 0:32:08  iter: 4479  total_loss: 1.311  loss_cls: 0.3285  loss_box_reg: 0.4547  loss_mask: 0.2993  loss_rpn_cls: 0.09817  loss_rpn_loc: 0.1921  time: 0.5918  data_time: 0.2839  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:27:26 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 4499  total_loss: 1.432  loss_cls: 0.297  loss_box_reg: 0.5109  loss_mask: 0.3112  loss_rpn_cls: 0.06826  loss_rpn_loc: 0.1897  time: 0.5915  data_time: 0.2187  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:27:37 d2.utils.events]: \u001b[0m eta: 0:31:49  iter: 4519  total_loss: 1.29  loss_cls: 0.2998  loss_box_reg: 0.4723  loss_mask: 0.2878  loss_rpn_cls: 0.06909  loss_rpn_loc: 0.2035  time: 0.5913  data_time: 0.2236  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:27:47 d2.utils.events]: \u001b[0m eta: 0:31:37  iter: 4539  total_loss: 1.522  loss_cls: 0.3519  loss_box_reg: 0.5222  loss_mask: 0.2925  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.2082  time: 0.5910  data_time: 0.1982  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:28:02 d2.utils.events]: \u001b[0m eta: 0:31:30  iter: 4559  total_loss: 1.345  loss_cls: 0.299  loss_box_reg: 0.4959  loss_mask: 0.2879  loss_rpn_cls: 0.05141  loss_rpn_loc: 0.1949  time: 0.5917  data_time: 0.4171  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:28:14 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 4579  total_loss: 1.533  loss_cls: 0.3412  loss_box_reg: 0.519  loss_mask: 0.3099  loss_rpn_cls: 0.07803  loss_rpn_loc: 0.2009  time: 0.5917  data_time: 0.2826  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:28:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:28:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:28:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:28:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:28:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:28:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0373 s/iter. Total: 0.1090 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 20:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0542 s/iter. Total: 0.1284 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:28:38 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0571 s/iter. Total: 0.1318 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:28:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.110514 (0.130263 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:28:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073626 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:28:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:28:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25876398681573026\n",
      "\u001b[32m[02/01 20:28:43 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 4599  total_loss: 1.406  loss_cls: 0.3514  loss_box_reg: 0.5007  loss_mask: 0.2886  loss_rpn_cls: 0.09065  loss_rpn_loc: 0.1956  time: 0.5919  data_time: 0.3357  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:28:54 d2.utils.events]: \u001b[0m eta: 0:31:03  iter: 4619  total_loss: 1.416  loss_cls: 0.3177  loss_box_reg: 0.5071  loss_mask: 0.2933  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.1906  time: 0.5917  data_time: 0.2352  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:29:07 d2.utils.events]: \u001b[0m eta: 0:30:57  iter: 4639  total_loss: 1.418  loss_cls: 0.3409  loss_box_reg: 0.5056  loss_mask: 0.2822  loss_rpn_cls: 0.07206  loss_rpn_loc: 0.1988  time: 0.5919  data_time: 0.3005  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:29:19 d2.utils.events]: \u001b[0m eta: 0:30:48  iter: 4659  total_loss: 1.356  loss_cls: 0.3046  loss_box_reg: 0.4933  loss_mask: 0.2906  loss_rpn_cls: 0.07765  loss_rpn_loc: 0.1925  time: 0.5918  data_time: 0.2630  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:29:31 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 4679  total_loss: 1.424  loss_cls: 0.3178  loss_box_reg: 0.4931  loss_mask: 0.2938  loss_rpn_cls: 0.07733  loss_rpn_loc: 0.1995  time: 0.5919  data_time: 0.2741  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:29:41 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 4699  total_loss: 1.391  loss_cls: 0.3108  loss_box_reg: 0.5072  loss_mask: 0.3146  loss_rpn_cls: 0.07799  loss_rpn_loc: 0.2017  time: 0.5916  data_time: 0.1941  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:29:53 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 4719  total_loss: 1.434  loss_cls: 0.3458  loss_box_reg: 0.5079  loss_mask: 0.298  loss_rpn_cls: 0.08151  loss_rpn_loc: 0.1876  time: 0.5915  data_time: 0.2519  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:30:06 d2.utils.events]: \u001b[0m eta: 0:30:18  iter: 4739  total_loss: 1.364  loss_cls: 0.3494  loss_box_reg: 0.4742  loss_mask: 0.2921  loss_rpn_cls: 0.06899  loss_rpn_loc: 0.1888  time: 0.5919  data_time: 0.3666  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:30:19 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 4759  total_loss: 1.384  loss_cls: 0.3195  loss_box_reg: 0.5253  loss_mask: 0.3006  loss_rpn_cls: 0.07093  loss_rpn_loc: 0.2096  time: 0.5920  data_time: 0.2958  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:30:32 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 4779  total_loss: 1.417  loss_cls: 0.3156  loss_box_reg: 0.4954  loss_mask: 0.2977  loss_rpn_cls: 0.08039  loss_rpn_loc: 0.2021  time: 0.5923  data_time: 0.3429  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:30:45 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 4799  total_loss: 1.286  loss_cls: 0.2786  loss_box_reg: 0.4755  loss_mask: 0.296  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.1771  time: 0.5926  data_time: 0.3130  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:30:56 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 4819  total_loss: 1.403  loss_cls: 0.2966  loss_box_reg: 0.5152  loss_mask: 0.2949  loss_rpn_cls: 0.0685  loss_rpn_loc: 0.1861  time: 0.5923  data_time: 0.2159  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:31:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:31:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:31:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:31:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:31:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:31:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0713 s/iter. Eval: 0.0384 s/iter. Total: 0.1103 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0587 s/iter. Total: 0.1337 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0748 s/iter. Eval: 0.0628 s/iter. Total: 0.1384 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:31:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.828760 (0.136455 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:31:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074560 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:31:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:31:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.268022907418063\n",
      "\u001b[32m[02/01 20:31:23 d2.utils.events]: \u001b[0m eta: 0:29:32  iter: 4839  total_loss: 1.305  loss_cls: 0.2694  loss_box_reg: 0.4966  loss_mask: 0.2896  loss_rpn_cls: 0.05596  loss_rpn_loc: 0.1798  time: 0.5919  data_time: 0.1875  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:31:35 d2.utils.events]: \u001b[0m eta: 0:29:21  iter: 4859  total_loss: 1.386  loss_cls: 0.3196  loss_box_reg: 0.5167  loss_mask: 0.2835  loss_rpn_cls: 0.07113  loss_rpn_loc: 0.1749  time: 0.5919  data_time: 0.2642  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:31:47 d2.utils.events]: \u001b[0m eta: 0:29:10  iter: 4879  total_loss: 1.331  loss_cls: 0.3069  loss_box_reg: 0.4905  loss_mask: 0.2932  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.1911  time: 0.5920  data_time: 0.2833  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:32:00 d2.utils.events]: \u001b[0m eta: 0:29:06  iter: 4899  total_loss: 1.439  loss_cls: 0.3275  loss_box_reg: 0.485  loss_mask: 0.3071  loss_rpn_cls: 0.0898  loss_rpn_loc: 0.2068  time: 0.5923  data_time: 0.3359  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:32:16 d2.utils.events]: \u001b[0m eta: 0:28:59  iter: 4919  total_loss: 1.379  loss_cls: 0.3001  loss_box_reg: 0.4732  loss_mask: 0.3096  loss_rpn_cls: 0.0887  loss_rpn_loc: 0.1977  time: 0.5930  data_time: 0.4369  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:32:27 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 4939  total_loss: 1.417  loss_cls: 0.3229  loss_box_reg: 0.5278  loss_mask: 0.2915  loss_rpn_cls: 0.05958  loss_rpn_loc: 0.1945  time: 0.5928  data_time: 0.2148  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:32:38 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 4959  total_loss: 1.347  loss_cls: 0.3183  loss_box_reg: 0.4684  loss_mask: 0.302  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.189  time: 0.5928  data_time: 0.2600  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:32:48 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 4979  total_loss: 1.394  loss_cls: 0.2974  loss_box_reg: 0.5247  loss_mask: 0.3004  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.1745  time: 0.5923  data_time: 0.1575  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:32:57 d2.utils.events]: \u001b[0m eta: 0:28:24  iter: 4999  total_loss: 1.319  loss_cls: 0.3133  loss_box_reg: 0.4882  loss_mask: 0.2986  loss_rpn_cls: 0.063  loss_rpn_loc: 0.1957  time: 0.5918  data_time: 0.1758  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:33:07 d2.utils.events]: \u001b[0m eta: 0:28:14  iter: 5019  total_loss: 1.335  loss_cls: 0.3061  loss_box_reg: 0.5126  loss_mask: 0.3011  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.185  time: 0.5914  data_time: 0.1650  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:33:25 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 5039  total_loss: 1.436  loss_cls: 0.3416  loss_box_reg: 0.4865  loss_mask: 0.303  loss_rpn_cls: 0.08609  loss_rpn_loc: 0.1969  time: 0.5927  data_time: 0.5708  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:33:37 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 5059  total_loss: 1.381  loss_cls: 0.2897  loss_box_reg: 0.4854  loss_mask: 0.2947  loss_rpn_cls: 0.08294  loss_rpn_loc: 0.1985  time: 0.5927  data_time: 0.2506  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:33:49 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 5079  total_loss: 1.348  loss_cls: 0.3271  loss_box_reg: 0.4687  loss_mask: 0.2928  loss_rpn_cls: 0.06447  loss_rpn_loc: 0.1944  time: 0.5926  data_time: 0.2539  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:33:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:33:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:33:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:33:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:33:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:33:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:33:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0712 s/iter. Eval: 0.0378 s/iter. Total: 0.1096 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0560 s/iter. Total: 0.1304 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:34:02 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0744 s/iter. Eval: 0.0609 s/iter. Total: 0.1361 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:34:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.535760 (0.133929 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:34:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074046 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:34:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:34:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27002962417767407\n",
      "\u001b[32m[02/01 20:34:14 d2.utils.events]: \u001b[0m eta: 0:27:42  iter: 5099  total_loss: 1.329  loss_cls: 0.3039  loss_box_reg: 0.5229  loss_mask: 0.2904  loss_rpn_cls: 0.06669  loss_rpn_loc: 0.1918  time: 0.5919  data_time: 0.1078  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:34:27 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 5119  total_loss: 1.46  loss_cls: 0.3131  loss_box_reg: 0.49  loss_mask: 0.3078  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.212  time: 0.5922  data_time: 0.3368  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:34:36 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 5139  total_loss: 1.343  loss_cls: 0.312  loss_box_reg: 0.5122  loss_mask: 0.2994  loss_rpn_cls: 0.06065  loss_rpn_loc: 0.1804  time: 0.5916  data_time: 0.1188  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:34:45 d2.utils.events]: \u001b[0m eta: 0:27:21  iter: 5159  total_loss: 1.436  loss_cls: 0.3213  loss_box_reg: 0.5389  loss_mask: 0.3005  loss_rpn_cls: 0.07298  loss_rpn_loc: 0.202  time: 0.5911  data_time: 0.1651  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:34:58 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 5179  total_loss: 1.433  loss_cls: 0.3194  loss_box_reg: 0.4688  loss_mask: 0.2899  loss_rpn_cls: 0.0742  loss_rpn_loc: 0.1761  time: 0.5912  data_time: 0.2863  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:35:09 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 5199  total_loss: 1.403  loss_cls: 0.345  loss_box_reg: 0.5101  loss_mask: 0.2859  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.1826  time: 0.5910  data_time: 0.2265  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:35:19 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 5219  total_loss: 1.445  loss_cls: 0.3093  loss_box_reg: 0.4937  loss_mask: 0.2936  loss_rpn_cls: 0.08835  loss_rpn_loc: 0.1976  time: 0.5908  data_time: 0.2008  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:35:31 d2.utils.events]: \u001b[0m eta: 0:26:52  iter: 5239  total_loss: 1.302  loss_cls: 0.2623  loss_box_reg: 0.4921  loss_mask: 0.2917  loss_rpn_cls: 0.05999  loss_rpn_loc: 0.1812  time: 0.5909  data_time: 0.2920  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:35:43 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 5259  total_loss: 1.435  loss_cls: 0.3356  loss_box_reg: 0.4947  loss_mask: 0.288  loss_rpn_cls: 0.07243  loss_rpn_loc: 0.1987  time: 0.5908  data_time: 0.2556  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:35:57 d2.utils.events]: \u001b[0m eta: 0:26:40  iter: 5279  total_loss: 1.443  loss_cls: 0.3162  loss_box_reg: 0.503  loss_mask: 0.3057  loss_rpn_cls: 0.07799  loss_rpn_loc: 0.1983  time: 0.5913  data_time: 0.3718  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:36:08 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 5299  total_loss: 1.441  loss_cls: 0.3697  loss_box_reg: 0.4893  loss_mask: 0.2813  loss_rpn_cls: 0.06234  loss_rpn_loc: 0.185  time: 0.5910  data_time: 0.1895  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:36:18 d2.utils.events]: \u001b[0m eta: 0:26:25  iter: 5319  total_loss: 1.375  loss_cls: 0.3219  loss_box_reg: 0.5005  loss_mask: 0.2967  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.199  time: 0.5908  data_time: 0.2139  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:36:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:36:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:36:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:36:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:36:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:36:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0392 s/iter. Total: 0.1108 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0593 s/iter. Total: 0.1339 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0746 s/iter. Eval: 0.0627 s/iter. Total: 0.1381 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0743 s/iter. Eval: 0.0610 s/iter. Total: 0.1361 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:36:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.836854 (0.136525 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:36:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074312 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:36:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:36:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2561946422404616\n",
      "\u001b[32m[02/01 20:36:47 d2.utils.events]: \u001b[0m eta: 0:26:19  iter: 5339  total_loss: 1.32  loss_cls: 0.3122  loss_box_reg: 0.5196  loss_mask: 0.2868  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.164  time: 0.5907  data_time: 0.2448  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:36:58 d2.utils.events]: \u001b[0m eta: 0:26:11  iter: 5359  total_loss: 1.375  loss_cls: 0.3335  loss_box_reg: 0.5152  loss_mask: 0.2884  loss_rpn_cls: 0.06479  loss_rpn_loc: 0.1959  time: 0.5906  data_time: 0.2555  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:37:13 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 5379  total_loss: 1.441  loss_cls: 0.3322  loss_box_reg: 0.4866  loss_mask: 0.2943  loss_rpn_cls: 0.07212  loss_rpn_loc: 0.2102  time: 0.5911  data_time: 0.3797  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:37:23 d2.utils.events]: \u001b[0m eta: 0:25:59  iter: 5399  total_loss: 1.365  loss_cls: 0.2961  loss_box_reg: 0.4908  loss_mask: 0.2863  loss_rpn_cls: 0.0497  loss_rpn_loc: 0.1936  time: 0.5909  data_time: 0.2225  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:37:36 d2.utils.events]: \u001b[0m eta: 0:25:53  iter: 5419  total_loss: 1.491  loss_cls: 0.3365  loss_box_reg: 0.5302  loss_mask: 0.3128  loss_rpn_cls: 0.08939  loss_rpn_loc: 0.2077  time: 0.5910  data_time: 0.3101  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:37:47 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 5439  total_loss: 1.394  loss_cls: 0.3235  loss_box_reg: 0.5156  loss_mask: 0.3048  loss_rpn_cls: 0.08528  loss_rpn_loc: 0.1922  time: 0.5908  data_time: 0.2252  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:38:02 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 5459  total_loss: 1.355  loss_cls: 0.3232  loss_box_reg: 0.4512  loss_mask: 0.2934  loss_rpn_cls: 0.08206  loss_rpn_loc: 0.2074  time: 0.5914  data_time: 0.4145  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:38:13 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 5479  total_loss: 1.394  loss_cls: 0.3182  loss_box_reg: 0.53  loss_mask: 0.2865  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.19  time: 0.5913  data_time: 0.2423  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:38:25 d2.utils.events]: \u001b[0m eta: 0:25:28  iter: 5499  total_loss: 1.405  loss_cls: 0.3253  loss_box_reg: 0.5055  loss_mask: 0.2923  loss_rpn_cls: 0.07408  loss_rpn_loc: 0.1829  time: 0.5914  data_time: 0.2861  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:38:36 d2.utils.events]: \u001b[0m eta: 0:25:21  iter: 5519  total_loss: 1.47  loss_cls: 0.3475  loss_box_reg: 0.4956  loss_mask: 0.3056  loss_rpn_cls: 0.08155  loss_rpn_loc: 0.2076  time: 0.5911  data_time: 0.2161  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:38:44 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 5539  total_loss: 1.258  loss_cls: 0.285  loss_box_reg: 0.4793  loss_mask: 0.2699  loss_rpn_cls: 0.0487  loss_rpn_loc: 0.1568  time: 0.5905  data_time: 0.0900  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:38:57 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 5559  total_loss: 1.328  loss_cls: 0.2769  loss_box_reg: 0.4816  loss_mask: 0.2958  loss_rpn_cls: 0.04861  loss_rpn_loc: 0.1864  time: 0.5907  data_time: 0.3262  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:38:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:38:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:38:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:38:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:39:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:39:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0389 s/iter. Total: 0.1105 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0550 s/iter. Total: 0.1296 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0739 s/iter. Eval: 0.0567 s/iter. Total: 0.1314 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:39:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.123874 (0.130378 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:39:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073743 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:39:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:39:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611135865158244\n",
      "\u001b[32m[02/01 20:39:25 d2.utils.events]: \u001b[0m eta: 0:24:57  iter: 5579  total_loss: 1.41  loss_cls: 0.309  loss_box_reg: 0.4872  loss_mask: 0.3007  loss_rpn_cls: 0.06593  loss_rpn_loc: 0.2004  time: 0.5906  data_time: 0.2324  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:39:35 d2.utils.events]: \u001b[0m eta: 0:24:50  iter: 5599  total_loss: 1.4  loss_cls: 0.2986  loss_box_reg: 0.5065  loss_mask: 0.2961  loss_rpn_cls: 0.07113  loss_rpn_loc: 0.1903  time: 0.5902  data_time: 0.1557  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:39:46 d2.utils.events]: \u001b[0m eta: 0:24:43  iter: 5619  total_loss: 1.366  loss_cls: 0.3344  loss_box_reg: 0.5153  loss_mask: 0.2823  loss_rpn_cls: 0.0691  loss_rpn_loc: 0.1768  time: 0.5902  data_time: 0.2753  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:39:58 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 5639  total_loss: 1.403  loss_cls: 0.3146  loss_box_reg: 0.4965  loss_mask: 0.3045  loss_rpn_cls: 0.07545  loss_rpn_loc: 0.1945  time: 0.5902  data_time: 0.2738  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:40:11 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 5659  total_loss: 1.375  loss_cls: 0.298  loss_box_reg: 0.4907  loss_mask: 0.308  loss_rpn_cls: 0.07227  loss_rpn_loc: 0.1955  time: 0.5903  data_time: 0.3115  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:40:24 d2.utils.events]: \u001b[0m eta: 0:24:21  iter: 5679  total_loss: 1.451  loss_cls: 0.327  loss_box_reg: 0.5138  loss_mask: 0.3009  loss_rpn_cls: 0.06858  loss_rpn_loc: 0.2  time: 0.5906  data_time: 0.3384  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:40:37 d2.utils.events]: \u001b[0m eta: 0:24:15  iter: 5699  total_loss: 1.373  loss_cls: 0.3043  loss_box_reg: 0.4684  loss_mask: 0.2946  loss_rpn_cls: 0.06682  loss_rpn_loc: 0.1927  time: 0.5908  data_time: 0.3056  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:40:48 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 5719  total_loss: 1.372  loss_cls: 0.3081  loss_box_reg: 0.5206  loss_mask: 0.2975  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.1903  time: 0.5906  data_time: 0.2193  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:41:02 d2.utils.events]: \u001b[0m eta: 0:24:02  iter: 5739  total_loss: 1.454  loss_cls: 0.3512  loss_box_reg: 0.4973  loss_mask: 0.2959  loss_rpn_cls: 0.08661  loss_rpn_loc: 0.2036  time: 0.5910  data_time: 0.3885  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:41:15 d2.utils.events]: \u001b[0m eta: 0:23:56  iter: 5759  total_loss: 1.485  loss_cls: 0.3694  loss_box_reg: 0.5158  loss_mask: 0.2991  loss_rpn_cls: 0.09719  loss_rpn_loc: 0.2057  time: 0.5912  data_time: 0.3172  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:41:26 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 5779  total_loss: 1.346  loss_cls: 0.2914  loss_box_reg: 0.5203  loss_mask: 0.2976  loss_rpn_cls: 0.04466  loss_rpn_loc: 0.1815  time: 0.5910  data_time: 0.2159  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:41:37 d2.utils.events]: \u001b[0m eta: 0:23:45  iter: 5799  total_loss: 1.414  loss_cls: 0.3036  loss_box_reg: 0.4904  loss_mask: 0.3143  loss_rpn_cls: 0.05997  loss_rpn_loc: 0.1921  time: 0.5910  data_time: 0.2586  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:41:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:41:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:41:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:41:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:41:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:41:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0708 s/iter. Eval: 0.0372 s/iter. Total: 0.1086 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 20:41:48 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0570 s/iter. Total: 0.1318 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0745 s/iter. Eval: 0.0600 s/iter. Total: 0.1353 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:41:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.466091 (0.133328 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:41:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074176 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:41:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:41:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2659158762852925\n",
      "\u001b[32m[02/01 20:42:02 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 5819  total_loss: 1.234  loss_cls: 0.2793  loss_box_reg: 0.5004  loss_mask: 0.2671  loss_rpn_cls: 0.03086  loss_rpn_loc: 0.1566  time: 0.5903  data_time: 0.0915  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:42:14 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 5839  total_loss: 1.359  loss_cls: 0.264  loss_box_reg: 0.4861  loss_mask: 0.2945  loss_rpn_cls: 0.07657  loss_rpn_loc: 0.1926  time: 0.5903  data_time: 0.2731  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:42:27 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 5859  total_loss: 1.381  loss_cls: 0.2877  loss_box_reg: 0.4575  loss_mask: 0.3002  loss_rpn_cls: 0.08001  loss_rpn_loc: 0.1963  time: 0.5905  data_time: 0.3349  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:42:41 d2.utils.events]: \u001b[0m eta: 0:23:20  iter: 5879  total_loss: 1.37  loss_cls: 0.2832  loss_box_reg: 0.5031  loss_mask: 0.3063  loss_rpn_cls: 0.0502  loss_rpn_loc: 0.1964  time: 0.5909  data_time: 0.3592  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:42:52 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 5899  total_loss: 1.409  loss_cls: 0.3066  loss_box_reg: 0.5011  loss_mask: 0.3008  loss_rpn_cls: 0.04796  loss_rpn_loc: 0.196  time: 0.5907  data_time: 0.2220  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:43:01 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 5919  total_loss: 1.358  loss_cls: 0.3028  loss_box_reg: 0.5194  loss_mask: 0.295  loss_rpn_cls: 0.06268  loss_rpn_loc: 0.1859  time: 0.5903  data_time: 0.1698  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:43:14 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 5939  total_loss: 1.41  loss_cls: 0.3152  loss_box_reg: 0.4795  loss_mask: 0.2967  loss_rpn_cls: 0.07511  loss_rpn_loc: 0.1688  time: 0.5904  data_time: 0.2917  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:43:25 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 5959  total_loss: 1.336  loss_cls: 0.2873  loss_box_reg: 0.4747  loss_mask: 0.2944  loss_rpn_cls: 0.07776  loss_rpn_loc: 0.1809  time: 0.5904  data_time: 0.2648  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:43:34 d2.utils.events]: \u001b[0m eta: 0:22:41  iter: 5979  total_loss: 1.252  loss_cls: 0.291  loss_box_reg: 0.4892  loss_mask: 0.2897  loss_rpn_cls: 0.05381  loss_rpn_loc: 0.1588  time: 0.5899  data_time: 0.1396  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:43:47 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 5999  total_loss: 1.438  loss_cls: 0.3255  loss_box_reg: 0.5195  loss_mask: 0.2962  loss_rpn_cls: 0.08011  loss_rpn_loc: 0.2079  time: 0.5900  data_time: 0.3020  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:43:57 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 6019  total_loss: 1.31  loss_cls: 0.2914  loss_box_reg: 0.4738  loss_mask: 0.2849  loss_rpn_cls: 0.06206  loss_rpn_loc: 0.1958  time: 0.5898  data_time: 0.2141  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:44:07 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 6039  total_loss: 1.371  loss_cls: 0.3128  loss_box_reg: 0.5282  loss_mask: 0.2913  loss_rpn_cls: 0.05508  loss_rpn_loc: 0.1871  time: 0.5895  data_time: 0.1595  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:44:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:44:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:44:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:44:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:44:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:44:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0705 s/iter. Eval: 0.0381 s/iter. Total: 0.1092 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0733 s/iter. Eval: 0.0540 s/iter. Total: 0.1281 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0557 s/iter. Total: 0.1302 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:44:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.956631 (0.128936 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:44:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073573 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:44:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:44:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25346597601896204\n",
      "\u001b[32m[02/01 20:44:35 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 6059  total_loss: 1.438  loss_cls: 0.3487  loss_box_reg: 0.5206  loss_mask: 0.3083  loss_rpn_cls: 0.0833  loss_rpn_loc: 0.1965  time: 0.5894  data_time: 0.2613  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:44:46 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 6079  total_loss: 1.309  loss_cls: 0.2876  loss_box_reg: 0.4906  loss_mask: 0.2908  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.1831  time: 0.5893  data_time: 0.2095  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:44:59 d2.utils.events]: \u001b[0m eta: 0:22:00  iter: 6099  total_loss: 1.508  loss_cls: 0.3673  loss_box_reg: 0.5328  loss_mask: 0.3162  loss_rpn_cls: 0.07135  loss_rpn_loc: 0.2019  time: 0.5894  data_time: 0.3130  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:45:14 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 6119  total_loss: 1.521  loss_cls: 0.3678  loss_box_reg: 0.4881  loss_mask: 0.3082  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.2183  time: 0.5900  data_time: 0.4228  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:45:26 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 6139  total_loss: 1.389  loss_cls: 0.3331  loss_box_reg: 0.483  loss_mask: 0.3003  loss_rpn_cls: 0.07894  loss_rpn_loc: 0.2016  time: 0.5900  data_time: 0.2802  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:45:37 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 6159  total_loss: 1.317  loss_cls: 0.2947  loss_box_reg: 0.4923  loss_mask: 0.2854  loss_rpn_cls: 0.0696  loss_rpn_loc: 0.1948  time: 0.5900  data_time: 0.2570  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:45:50 d2.utils.events]: \u001b[0m eta: 0:21:37  iter: 6179  total_loss: 1.363  loss_cls: 0.2932  loss_box_reg: 0.4729  loss_mask: 0.2799  loss_rpn_cls: 0.08456  loss_rpn_loc: 0.1901  time: 0.5901  data_time: 0.3171  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:46:01 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 6199  total_loss: 1.406  loss_cls: 0.3244  loss_box_reg: 0.5179  loss_mask: 0.2883  loss_rpn_cls: 0.05918  loss_rpn_loc: 0.1911  time: 0.5899  data_time: 0.1946  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:46:12 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 6219  total_loss: 1.342  loss_cls: 0.3101  loss_box_reg: 0.4658  loss_mask: 0.2842  loss_rpn_cls: 0.05432  loss_rpn_loc: 0.1887  time: 0.5899  data_time: 0.2462  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:46:22 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 6239  total_loss: 1.323  loss_cls: 0.292  loss_box_reg: 0.4621  loss_mask: 0.2874  loss_rpn_cls: 0.06512  loss_rpn_loc: 0.1775  time: 0.5895  data_time: 0.1433  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:46:34 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 6259  total_loss: 1.368  loss_cls: 0.3031  loss_box_reg: 0.4982  loss_mask: 0.3067  loss_rpn_cls: 0.05002  loss_rpn_loc: 0.1657  time: 0.5896  data_time: 0.2957  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:46:45 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 6279  total_loss: 1.361  loss_cls: 0.2957  loss_box_reg: 0.5054  loss_mask: 0.3006  loss_rpn_cls: 0.07691  loss_rpn_loc: 0.1997  time: 0.5895  data_time: 0.2252  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:46:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:46:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:46:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:46:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:46:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:46:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0398 s/iter. Total: 0.1115 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0007 s/iter. Inference: 0.0762 s/iter. Eval: 0.0599 s/iter. Total: 0.1368 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 20:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0758 s/iter. Eval: 0.0620 s/iter. Total: 0.1386 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0752 s/iter. Eval: 0.0604 s/iter. Total: 0.1365 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:47:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.868339 (0.136796 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:47:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075237 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:47:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:47:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26780743615106073\n",
      "\u001b[32m[02/01 20:47:14 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 6299  total_loss: 1.357  loss_cls: 0.2997  loss_box_reg: 0.4985  loss_mask: 0.2811  loss_rpn_cls: 0.08324  loss_rpn_loc: 0.1824  time: 0.5894  data_time: 0.2286  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:47:27 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 6319  total_loss: 1.444  loss_cls: 0.335  loss_box_reg: 0.5091  loss_mask: 0.3126  loss_rpn_cls: 0.07697  loss_rpn_loc: 0.2116  time: 0.5897  data_time: 0.3686  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:47:40 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 6339  total_loss: 1.465  loss_cls: 0.3163  loss_box_reg: 0.4718  loss_mask: 0.3006  loss_rpn_cls: 0.09821  loss_rpn_loc: 0.2124  time: 0.5899  data_time: 0.3244  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:47:53 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 6359  total_loss: 1.459  loss_cls: 0.3447  loss_box_reg: 0.488  loss_mask: 0.2844  loss_rpn_cls: 0.08745  loss_rpn_loc: 0.2019  time: 0.5901  data_time: 0.3216  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:48:08 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 6379  total_loss: 1.383  loss_cls: 0.2912  loss_box_reg: 0.5035  loss_mask: 0.3062  loss_rpn_cls: 0.06585  loss_rpn_loc: 0.1908  time: 0.5906  data_time: 0.4200  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:48:19 d2.utils.events]: \u001b[0m eta: 0:20:26  iter: 6399  total_loss: 1.326  loss_cls: 0.3053  loss_box_reg: 0.4855  loss_mask: 0.3074  loss_rpn_cls: 0.05798  loss_rpn_loc: 0.1826  time: 0.5903  data_time: 0.2126  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:48:32 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 6419  total_loss: 1.319  loss_cls: 0.3111  loss_box_reg: 0.5062  loss_mask: 0.2883  loss_rpn_cls: 0.0699  loss_rpn_loc: 0.1804  time: 0.5906  data_time: 0.3419  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:48:41 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 6439  total_loss: 1.241  loss_cls: 0.2816  loss_box_reg: 0.4804  loss_mask: 0.2856  loss_rpn_cls: 0.04649  loss_rpn_loc: 0.1591  time: 0.5901  data_time: 0.1073  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:48:51 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 6459  total_loss: 1.366  loss_cls: 0.3431  loss_box_reg: 0.4894  loss_mask: 0.2799  loss_rpn_cls: 0.06385  loss_rpn_loc: 0.1862  time: 0.5899  data_time: 0.2207  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:49:02 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 6479  total_loss: 1.403  loss_cls: 0.3426  loss_box_reg: 0.505  loss_mask: 0.2949  loss_rpn_cls: 0.05904  loss_rpn_loc: 0.1656  time: 0.5897  data_time: 0.2211  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:49:15 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 6499  total_loss: 1.499  loss_cls: 0.366  loss_box_reg: 0.5337  loss_mask: 0.3022  loss_rpn_cls: 0.07444  loss_rpn_loc: 0.222  time: 0.5898  data_time: 0.2791  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:49:25 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 6519  total_loss: 1.341  loss_cls: 0.2887  loss_box_reg: 0.4826  loss_mask: 0.3039  loss_rpn_cls: 0.06537  loss_rpn_loc: 0.1985  time: 0.5897  data_time: 0.2024  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:49:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:49:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:49:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:49:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:49:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:49:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0739 s/iter. Eval: 0.0382 s/iter. Total: 0.1127 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.0782 s/iter. Eval: 0.0628 s/iter. Total: 0.1418 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 20:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0008 s/iter. Inference: 0.0784 s/iter. Eval: 0.0651 s/iter. Total: 0.1443 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0767 s/iter. Eval: 0.0629 s/iter. Total: 0.1404 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.370268 (0.141123 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076683 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:49:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:49:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2709614737098636\n",
      "\u001b[32m[02/01 20:49:54 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 6539  total_loss: 1.303  loss_cls: 0.2797  loss_box_reg: 0.4846  loss_mask: 0.2934  loss_rpn_cls: 0.05113  loss_rpn_loc: 0.1749  time: 0.5895  data_time: 0.2113  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:50:06 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 6559  total_loss: 1.358  loss_cls: 0.3187  loss_box_reg: 0.4754  loss_mask: 0.2893  loss_rpn_cls: 0.0595  loss_rpn_loc: 0.1904  time: 0.5895  data_time: 0.2648  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:50:19 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 6579  total_loss: 1.334  loss_cls: 0.2677  loss_box_reg: 0.4536  loss_mask: 0.2996  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.1848  time: 0.5898  data_time: 0.3302  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:50:29 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 6599  total_loss: 1.274  loss_cls: 0.2778  loss_box_reg: 0.4847  loss_mask: 0.2761  loss_rpn_cls: 0.05811  loss_rpn_loc: 0.1576  time: 0.5894  data_time: 0.1481  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:50:38 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 6619  total_loss: 1.283  loss_cls: 0.29  loss_box_reg: 0.468  loss_mask: 0.2889  loss_rpn_cls: 0.05065  loss_rpn_loc: 0.1901  time: 0.5890  data_time: 0.1667  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:50:50 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 6639  total_loss: 1.377  loss_cls: 0.3025  loss_box_reg: 0.4802  loss_mask: 0.2987  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.1996  time: 0.5890  data_time: 0.2599  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:51:00 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 6659  total_loss: 1.328  loss_cls: 0.2947  loss_box_reg: 0.5011  loss_mask: 0.2748  loss_rpn_cls: 0.05456  loss_rpn_loc: 0.1746  time: 0.5888  data_time: 0.2134  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:51:12 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 6679  total_loss: 1.441  loss_cls: 0.3434  loss_box_reg: 0.5153  loss_mask: 0.3049  loss_rpn_cls: 0.08786  loss_rpn_loc: 0.1998  time: 0.5888  data_time: 0.2703  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:51:24 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 6699  total_loss: 1.365  loss_cls: 0.3254  loss_box_reg: 0.4704  loss_mask: 0.2806  loss_rpn_cls: 0.07354  loss_rpn_loc: 0.1859  time: 0.5888  data_time: 0.2666  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:51:36 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 6719  total_loss: 1.435  loss_cls: 0.3379  loss_box_reg: 0.4816  loss_mask: 0.3021  loss_rpn_cls: 0.06814  loss_rpn_loc: 0.1865  time: 0.5889  data_time: 0.2708  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:51:51 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 6739  total_loss: 1.434  loss_cls: 0.3011  loss_box_reg: 0.4608  loss_mask: 0.3107  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.2226  time: 0.5893  data_time: 0.3959  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:52:04 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 6759  total_loss: 1.382  loss_cls: 0.2983  loss_box_reg: 0.4788  loss_mask: 0.2989  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.1847  time: 0.5895  data_time: 0.3187  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:52:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:52:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:52:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:52:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:52:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:52:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0727 s/iter. Eval: 0.0374 s/iter. Total: 0.1106 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0585 s/iter. Total: 0.1353 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 20:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0766 s/iter. Eval: 0.0626 s/iter. Total: 0.1400 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0761 s/iter. Eval: 0.0604 s/iter. Total: 0.1373 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 20:52:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.976394 (0.137728 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:52:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076106 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:52:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:52:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26963801073916815\n",
      "\u001b[32m[02/01 20:52:34 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 6779  total_loss: 1.289  loss_cls: 0.2875  loss_box_reg: 0.4798  loss_mask: 0.2849  loss_rpn_cls: 0.05641  loss_rpn_loc: 0.18  time: 0.5895  data_time: 0.2810  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:52:44 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 6799  total_loss: 1.292  loss_cls: 0.2784  loss_box_reg: 0.4922  loss_mask: 0.2814  loss_rpn_cls: 0.06768  loss_rpn_loc: 0.1707  time: 0.5893  data_time: 0.1929  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:52:57 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 6819  total_loss: 1.365  loss_cls: 0.2875  loss_box_reg: 0.4894  loss_mask: 0.2949  loss_rpn_cls: 0.06696  loss_rpn_loc: 0.1728  time: 0.5895  data_time: 0.3065  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:53:07 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 6839  total_loss: 1.391  loss_cls: 0.3006  loss_box_reg: 0.5105  loss_mask: 0.3117  loss_rpn_cls: 0.07269  loss_rpn_loc: 0.2031  time: 0.5892  data_time: 0.1536  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:53:18 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 6859  total_loss: 1.262  loss_cls: 0.2819  loss_box_reg: 0.4729  loss_mask: 0.2841  loss_rpn_cls: 0.06219  loss_rpn_loc: 0.1725  time: 0.5891  data_time: 0.2320  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:53:27 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 6879  total_loss: 1.414  loss_cls: 0.2961  loss_box_reg: 0.5185  loss_mask: 0.2961  loss_rpn_cls: 0.05799  loss_rpn_loc: 0.1902  time: 0.5888  data_time: 0.1386  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:53:39 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 6899  total_loss: 1.437  loss_cls: 0.3292  loss_box_reg: 0.5094  loss_mask: 0.303  loss_rpn_cls: 0.06658  loss_rpn_loc: 0.1857  time: 0.5888  data_time: 0.2730  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:53:53 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 6919  total_loss: 1.389  loss_cls: 0.3201  loss_box_reg: 0.4936  loss_mask: 0.2845  loss_rpn_cls: 0.07777  loss_rpn_loc: 0.1848  time: 0.5891  data_time: 0.3406  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:54:06 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 6939  total_loss: 1.331  loss_cls: 0.289  loss_box_reg: 0.449  loss_mask: 0.295  loss_rpn_cls: 0.06731  loss_rpn_loc: 0.1896  time: 0.5892  data_time: 0.3121  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:54:20 d2.utils.events]: \u001b[0m eta: 0:17:33  iter: 6959  total_loss: 1.328  loss_cls: 0.3167  loss_box_reg: 0.4422  loss_mask: 0.2861  loss_rpn_cls: 0.054  loss_rpn_loc: 0.181  time: 0.5896  data_time: 0.3703  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:54:34 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 6979  total_loss: 1.442  loss_cls: 0.3375  loss_box_reg: 0.4793  loss_mask: 0.2888  loss_rpn_cls: 0.08594  loss_rpn_loc: 0.1845  time: 0.5899  data_time: 0.3543  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:54:44 d2.utils.events]: \u001b[0m eta: 0:17:21  iter: 6999  total_loss: 1.336  loss_cls: 0.2988  loss_box_reg: 0.4509  loss_mask: 0.2866  loss_rpn_cls: 0.0676  loss_rpn_loc: 0.1905  time: 0.5897  data_time: 0.1934  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:54:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:54:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:54:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:54:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:54:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:54:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0768 s/iter. Eval: 0.0374 s/iter. Total: 0.1149 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 20:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0773 s/iter. Eval: 0.0555 s/iter. Total: 0.1336 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:55:10 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0768 s/iter. Eval: 0.0591 s/iter. Total: 0.1367 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 20:55:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.540868 (0.133973 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:55:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075739 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:55:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:55:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25918290845363257\n",
      "\u001b[32m[02/01 20:55:16 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 7019  total_loss: 1.338  loss_cls: 0.2903  loss_box_reg: 0.4887  loss_mask: 0.3036  loss_rpn_cls: 0.07743  loss_rpn_loc: 0.1972  time: 0.5900  data_time: 0.3934  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:55:27 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 7039  total_loss: 1.408  loss_cls: 0.2915  loss_box_reg: 0.4977  loss_mask: 0.2993  loss_rpn_cls: 0.0596  loss_rpn_loc: 0.1881  time: 0.5899  data_time: 0.2394  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:55:38 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 7059  total_loss: 1.376  loss_cls: 0.3041  loss_box_reg: 0.4996  loss_mask: 0.2956  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.1672  time: 0.5898  data_time: 0.2239  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:55:53 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 7079  total_loss: 1.421  loss_cls: 0.326  loss_box_reg: 0.4769  loss_mask: 0.2985  loss_rpn_cls: 0.07572  loss_rpn_loc: 0.2001  time: 0.5903  data_time: 0.4101  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:56:07 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 7099  total_loss: 1.306  loss_cls: 0.2853  loss_box_reg: 0.4617  loss_mask: 0.2887  loss_rpn_cls: 0.07618  loss_rpn_loc: 0.1914  time: 0.5906  data_time: 0.3511  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:56:18 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 7119  total_loss: 1.3  loss_cls: 0.2805  loss_box_reg: 0.5074  loss_mask: 0.2969  loss_rpn_cls: 0.04756  loss_rpn_loc: 0.1805  time: 0.5905  data_time: 0.2392  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:56:29 d2.utils.events]: \u001b[0m eta: 0:16:33  iter: 7139  total_loss: 1.344  loss_cls: 0.3243  loss_box_reg: 0.4845  loss_mask: 0.2892  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.1844  time: 0.5904  data_time: 0.2317  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:56:42 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 7159  total_loss: 1.355  loss_cls: 0.2678  loss_box_reg: 0.4829  loss_mask: 0.2946  loss_rpn_cls: 0.07138  loss_rpn_loc: 0.1946  time: 0.5906  data_time: 0.3324  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:56:52 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 7179  total_loss: 1.489  loss_cls: 0.3409  loss_box_reg: 0.5364  loss_mask: 0.2956  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.1919  time: 0.5904  data_time: 0.1853  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:57:04 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 7199  total_loss: 1.314  loss_cls: 0.2862  loss_box_reg: 0.4884  loss_mask: 0.2884  loss_rpn_cls: 0.05878  loss_rpn_loc: 0.177  time: 0.5903  data_time: 0.2319  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:57:14 d2.utils.events]: \u001b[0m eta: 0:16:06  iter: 7219  total_loss: 1.338  loss_cls: 0.3154  loss_box_reg: 0.491  loss_mask: 0.2885  loss_rpn_cls: 0.05405  loss_rpn_loc: 0.1774  time: 0.5901  data_time: 0.1915  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:57:26 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 7239  total_loss: 1.354  loss_cls: 0.2863  loss_box_reg: 0.4896  loss_mask: 0.2995  loss_rpn_cls: 0.07158  loss_rpn_loc: 0.1949  time: 0.5901  data_time: 0.2816  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:57:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:57:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 20:57:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 20:57:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 20:57:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 20:57:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 20:57:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0362 s/iter. Total: 0.1072 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 20:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0732 s/iter. Eval: 0.0536 s/iter. Total: 0.1276 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 20:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0571 s/iter. Total: 0.1314 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 20:57:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.178930 (0.130853 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:57:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073446 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 20:57:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 20:57:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2639013387723886\n",
      "\u001b[32m[02/01 20:57:56 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 7259  total_loss: 1.35  loss_cls: 0.293  loss_box_reg: 0.4763  loss_mask: 0.2903  loss_rpn_cls: 0.06185  loss_rpn_loc: 0.1885  time: 0.5903  data_time: 0.3303  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:58:06 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 7279  total_loss: 1.277  loss_cls: 0.3039  loss_box_reg: 0.4901  loss_mask: 0.2854  loss_rpn_cls: 0.04221  loss_rpn_loc: 0.176  time: 0.5901  data_time: 0.2016  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:58:15 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 7299  total_loss: 1.336  loss_cls: 0.3167  loss_box_reg: 0.4915  loss_mask: 0.272  loss_rpn_cls: 0.04874  loss_rpn_loc: 0.1843  time: 0.5897  data_time: 0.1345  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:58:28 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 7319  total_loss: 1.363  loss_cls: 0.3037  loss_box_reg: 0.4703  loss_mask: 0.3048  loss_rpn_cls: 0.06075  loss_rpn_loc: 0.1908  time: 0.5898  data_time: 0.2991  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:58:39 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 7339  total_loss: 1.224  loss_cls: 0.2881  loss_box_reg: 0.4445  loss_mask: 0.2823  loss_rpn_cls: 0.0405  loss_rpn_loc: 0.1779  time: 0.5898  data_time: 0.2520  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:58:56 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 7359  total_loss: 1.394  loss_cls: 0.303  loss_box_reg: 0.4788  loss_mask: 0.3009  loss_rpn_cls: 0.07624  loss_rpn_loc: 0.2095  time: 0.5904  data_time: 0.4863  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:59:07 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 7379  total_loss: 1.376  loss_cls: 0.3087  loss_box_reg: 0.4771  loss_mask: 0.296  loss_rpn_cls: 0.08326  loss_rpn_loc: 0.1939  time: 0.5903  data_time: 0.2346  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:59:19 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 7399  total_loss: 1.369  loss_cls: 0.2888  loss_box_reg: 0.4987  loss_mask: 0.3022  loss_rpn_cls: 0.06267  loss_rpn_loc: 0.1995  time: 0.5904  data_time: 0.2836  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:59:31 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 7419  total_loss: 1.341  loss_cls: 0.3159  loss_box_reg: 0.4823  loss_mask: 0.2872  loss_rpn_cls: 0.08978  loss_rpn_loc: 0.1958  time: 0.5903  data_time: 0.2420  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:59:41 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 7439  total_loss: 1.302  loss_cls: 0.3108  loss_box_reg: 0.4778  loss_mask: 0.2947  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.1966  time: 0.5901  data_time: 0.1623  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 20:59:51 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 7459  total_loss: 1.439  loss_cls: 0.3414  loss_box_reg: 0.489  loss_mask: 0.3008  loss_rpn_cls: 0.06718  loss_rpn_loc: 0.1837  time: 0.5899  data_time: 0.1925  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:00:02 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 7479  total_loss: 1.336  loss_cls: 0.2848  loss_box_reg: 0.4663  loss_mask: 0.2946  loss_rpn_cls: 0.05806  loss_rpn_loc: 0.1813  time: 0.5897  data_time: 0.2318  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:00:13 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 7499  total_loss: 1.338  loss_cls: 0.286  loss_box_reg: 0.4931  loss_mask: 0.2959  loss_rpn_cls: 0.06355  loss_rpn_loc: 0.1823  time: 0.5897  data_time: 0.2621  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:00:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:00:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:00:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:00:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:00:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:00:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0360 s/iter. Total: 0.1069 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 21:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0733 s/iter. Eval: 0.0549 s/iter. Total: 0.1289 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0736 s/iter. Eval: 0.0581 s/iter. Total: 0.1325 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 21:00:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.236640 (0.131350 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:00:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073479 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:00:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:00:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25792607076263924\n",
      "\u001b[32m[02/01 21:00:42 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 7519  total_loss: 1.3  loss_cls: 0.3095  loss_box_reg: 0.4561  loss_mask: 0.2867  loss_rpn_cls: 0.07119  loss_rpn_loc: 0.1916  time: 0.5898  data_time: 0.2914  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:00:55 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 7539  total_loss: 1.462  loss_cls: 0.3539  loss_box_reg: 0.5047  loss_mask: 0.2967  loss_rpn_cls: 0.09725  loss_rpn_loc: 0.2058  time: 0.5899  data_time: 0.3174  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:01:05 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 7559  total_loss: 1.376  loss_cls: 0.3271  loss_box_reg: 0.5011  loss_mask: 0.2863  loss_rpn_cls: 0.07734  loss_rpn_loc: 0.1963  time: 0.5897  data_time: 0.1831  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:01:15 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 7579  total_loss: 1.416  loss_cls: 0.3284  loss_box_reg: 0.5061  loss_mask: 0.286  loss_rpn_cls: 0.05097  loss_rpn_loc: 0.1974  time: 0.5894  data_time: 0.1551  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:01:23 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 7599  total_loss: 1.304  loss_cls: 0.2784  loss_box_reg: 0.4868  loss_mask: 0.2975  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.1524  time: 0.5890  data_time: 0.1413  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:01:35 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 7619  total_loss: 1.357  loss_cls: 0.3129  loss_box_reg: 0.4951  loss_mask: 0.2831  loss_rpn_cls: 0.06742  loss_rpn_loc: 0.1832  time: 0.5889  data_time: 0.2393  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:01:46 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 7639  total_loss: 1.417  loss_cls: 0.2801  loss_box_reg: 0.5049  loss_mask: 0.3066  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.186  time: 0.5889  data_time: 0.2562  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:01:59 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 7659  total_loss: 1.434  loss_cls: 0.3188  loss_box_reg: 0.5242  loss_mask: 0.2936  loss_rpn_cls: 0.08989  loss_rpn_loc: 0.2075  time: 0.5890  data_time: 0.2916  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:02:11 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 7679  total_loss: 1.395  loss_cls: 0.3186  loss_box_reg: 0.5  loss_mask: 0.2876  loss_rpn_cls: 0.07181  loss_rpn_loc: 0.1992  time: 0.5891  data_time: 0.3075  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:02:25 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 7699  total_loss: 1.291  loss_cls: 0.3021  loss_box_reg: 0.4405  loss_mask: 0.3062  loss_rpn_cls: 0.05366  loss_rpn_loc: 0.1818  time: 0.5894  data_time: 0.3844  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:02:35 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 7719  total_loss: 1.377  loss_cls: 0.3372  loss_box_reg: 0.4744  loss_mask: 0.2753  loss_rpn_cls: 0.07505  loss_rpn_loc: 0.1844  time: 0.5891  data_time: 0.1704  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:02:50 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 7739  total_loss: 1.437  loss_cls: 0.3531  loss_box_reg: 0.509  loss_mask: 0.2967  loss_rpn_cls: 0.0864  loss_rpn_loc: 0.2086  time: 0.5894  data_time: 0.3902  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:02:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:02:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:02:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:02:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:02:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:02:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0761 s/iter. Eval: 0.0388 s/iter. Total: 0.1155 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 21:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0572 s/iter. Total: 0.1340 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0757 s/iter. Eval: 0.0575 s/iter. Total: 0.1340 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 21:03:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.308847 (0.131973 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:03:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075169 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:03:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:03:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25531996645590277\n",
      "\u001b[32m[02/01 21:03:18 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 7759  total_loss: 1.339  loss_cls: 0.3232  loss_box_reg: 0.4754  loss_mask: 0.2822  loss_rpn_cls: 0.05111  loss_rpn_loc: 0.1844  time: 0.5894  data_time: 0.2488  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:03:32 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 7779  total_loss: 1.38  loss_cls: 0.3084  loss_box_reg: 0.4849  loss_mask: 0.3004  loss_rpn_cls: 0.07576  loss_rpn_loc: 0.1902  time: 0.5898  data_time: 0.3909  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:03:46 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 7799  total_loss: 1.394  loss_cls: 0.3195  loss_box_reg: 0.4758  loss_mask: 0.302  loss_rpn_cls: 0.06051  loss_rpn_loc: 0.1969  time: 0.5899  data_time: 0.3345  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:03:56 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 7819  total_loss: 1.225  loss_cls: 0.2492  loss_box_reg: 0.4787  loss_mask: 0.2883  loss_rpn_cls: 0.03804  loss_rpn_loc: 0.1452  time: 0.5897  data_time: 0.1910  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:04:11 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 7839  total_loss: 1.45  loss_cls: 0.3352  loss_box_reg: 0.4884  loss_mask: 0.3004  loss_rpn_cls: 0.09569  loss_rpn_loc: 0.2067  time: 0.5902  data_time: 0.4474  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:04:24 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 7859  total_loss: 1.455  loss_cls: 0.3605  loss_box_reg: 0.4958  loss_mask: 0.2954  loss_rpn_cls: 0.08904  loss_rpn_loc: 0.1942  time: 0.5903  data_time: 0.2945  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:04:36 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 7879  total_loss: 1.299  loss_cls: 0.2906  loss_box_reg: 0.4627  loss_mask: 0.2772  loss_rpn_cls: 0.07495  loss_rpn_loc: 0.177  time: 0.5903  data_time: 0.2676  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:04:45 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 7899  total_loss: 1.184  loss_cls: 0.2945  loss_box_reg: 0.4532  loss_mask: 0.2691  loss_rpn_cls: 0.05574  loss_rpn_loc: 0.1668  time: 0.5900  data_time: 0.1742  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:04:57 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 7919  total_loss: 1.337  loss_cls: 0.3006  loss_box_reg: 0.4835  loss_mask: 0.2748  loss_rpn_cls: 0.07252  loss_rpn_loc: 0.189  time: 0.5900  data_time: 0.2863  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:05:09 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 7939  total_loss: 1.349  loss_cls: 0.3151  loss_box_reg: 0.4855  loss_mask: 0.2892  loss_rpn_cls: 0.07382  loss_rpn_loc: 0.1756  time: 0.5900  data_time: 0.2507  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:05:22 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 7959  total_loss: 1.307  loss_cls: 0.2776  loss_box_reg: 0.4822  loss_mask: 0.3062  loss_rpn_cls: 0.06478  loss_rpn_loc: 0.1788  time: 0.5902  data_time: 0.3652  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:05:33 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 7979  total_loss: 1.41  loss_cls: 0.3546  loss_box_reg: 0.5131  loss_mask: 0.297  loss_rpn_cls: 0.07817  loss_rpn_loc: 0.192  time: 0.5901  data_time: 0.2178  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:05:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:05:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:05:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:05:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:05:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:05:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0730 s/iter. Eval: 0.0396 s/iter. Total: 0.1132 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 21:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0757 s/iter. Eval: 0.0573 s/iter. Total: 0.1338 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0757 s/iter. Eval: 0.0601 s/iter. Total: 0.1367 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 21:05:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.570582 (0.134229 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:05:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075029 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:05:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:05:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26256535992540203\n",
      "\u001b[32m[02/01 21:06:00 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 7999  total_loss: 1.271  loss_cls: 0.2481  loss_box_reg: 0.4592  loss_mask: 0.293  loss_rpn_cls: 0.0415  loss_rpn_loc: 0.1815  time: 0.5898  data_time: 0.1475  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:06:11 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 8019  total_loss: 1.328  loss_cls: 0.306  loss_box_reg: 0.5005  loss_mask: 0.295  loss_rpn_cls: 0.07039  loss_rpn_loc: 0.1884  time: 0.5898  data_time: 0.2552  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:06:22 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 8039  total_loss: 1.276  loss_cls: 0.2735  loss_box_reg: 0.4646  loss_mask: 0.2857  loss_rpn_cls: 0.05586  loss_rpn_loc: 0.1898  time: 0.5896  data_time: 0.2035  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:06:32 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 8059  total_loss: 1.355  loss_cls: 0.2935  loss_box_reg: 0.4806  loss_mask: 0.2744  loss_rpn_cls: 0.06275  loss_rpn_loc: 0.1844  time: 0.5894  data_time: 0.2058  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:06:45 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 8079  total_loss: 1.305  loss_cls: 0.2803  loss_box_reg: 0.4778  loss_mask: 0.2767  loss_rpn_cls: 0.04947  loss_rpn_loc: 0.174  time: 0.5895  data_time: 0.2889  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:06:58 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 8099  total_loss: 1.322  loss_cls: 0.3079  loss_box_reg: 0.5013  loss_mask: 0.2902  loss_rpn_cls: 0.06275  loss_rpn_loc: 0.1778  time: 0.5897  data_time: 0.3596  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:07:11 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 8119  total_loss: 1.388  loss_cls: 0.3118  loss_box_reg: 0.5248  loss_mask: 0.2862  loss_rpn_cls: 0.06716  loss_rpn_loc: 0.1797  time: 0.5898  data_time: 0.2938  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:07:25 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 8139  total_loss: 1.283  loss_cls: 0.281  loss_box_reg: 0.4639  loss_mask: 0.2918  loss_rpn_cls: 0.06639  loss_rpn_loc: 0.1629  time: 0.5901  data_time: 0.3906  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:07:36 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 8159  total_loss: 1.263  loss_cls: 0.2601  loss_box_reg: 0.4718  loss_mask: 0.2943  loss_rpn_cls: 0.04787  loss_rpn_loc: 0.1656  time: 0.5900  data_time: 0.2055  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:07:48 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 8179  total_loss: 1.295  loss_cls: 0.2831  loss_box_reg: 0.4916  loss_mask: 0.3071  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.1861  time: 0.5900  data_time: 0.3037  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:07:59 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 8199  total_loss: 1.335  loss_cls: 0.2867  loss_box_reg: 0.4962  loss_mask: 0.2986  loss_rpn_cls: 0.07078  loss_rpn_loc: 0.1815  time: 0.5899  data_time: 0.2271  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:08:12 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 8219  total_loss: 1.352  loss_cls: 0.2996  loss_box_reg: 0.4722  loss_mask: 0.2931  loss_rpn_cls: 0.07044  loss_rpn_loc: 0.1901  time: 0.5901  data_time: 0.3383  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:08:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:08:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:08:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:08:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:08:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:08:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0384 s/iter. Total: 0.1101 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 21:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0730 s/iter. Eval: 0.0515 s/iter. Total: 0.1253 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 21:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.0730 s/iter. Eval: 0.0524 s/iter. Total: 0.1262 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/01 21:08:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.442479 (0.124504 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:08:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072691 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:08:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:08:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2586150639861195\n",
      "\u001b[32m[02/01 21:08:41 d2.utils.events]: \u001b[0m eta: 0:10:01  iter: 8239  total_loss: 1.389  loss_cls: 0.3393  loss_box_reg: 0.4521  loss_mask: 0.2864  loss_rpn_cls: 0.08337  loss_rpn_loc: 0.2052  time: 0.5902  data_time: 0.3035  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:08:53 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 8259  total_loss: 1.283  loss_cls: 0.3087  loss_box_reg: 0.4638  loss_mask: 0.2832  loss_rpn_cls: 0.07221  loss_rpn_loc: 0.1829  time: 0.5903  data_time: 0.3098  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:09:08 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 8279  total_loss: 1.326  loss_cls: 0.3  loss_box_reg: 0.4659  loss_mask: 0.2853  loss_rpn_cls: 0.07444  loss_rpn_loc: 0.1799  time: 0.5906  data_time: 0.4048  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:09:24 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 8299  total_loss: 1.456  loss_cls: 0.329  loss_box_reg: 0.4802  loss_mask: 0.3056  loss_rpn_cls: 0.07274  loss_rpn_loc: 0.1971  time: 0.5912  data_time: 0.4677  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:09:36 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 8319  total_loss: 1.379  loss_cls: 0.2941  loss_box_reg: 0.4863  loss_mask: 0.3107  loss_rpn_cls: 0.06054  loss_rpn_loc: 0.1779  time: 0.5911  data_time: 0.2663  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:09:45 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 8339  total_loss: 1.277  loss_cls: 0.291  loss_box_reg: 0.4811  loss_mask: 0.2963  loss_rpn_cls: 0.05034  loss_rpn_loc: 0.1795  time: 0.5909  data_time: 0.1567  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:09:59 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 8359  total_loss: 1.381  loss_cls: 0.3146  loss_box_reg: 0.4852  loss_mask: 0.2836  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.1919  time: 0.5911  data_time: 0.3617  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:10:08 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 8379  total_loss: 1.352  loss_cls: 0.3036  loss_box_reg: 0.4953  loss_mask: 0.2947  loss_rpn_cls: 0.06427  loss_rpn_loc: 0.179  time: 0.5908  data_time: 0.1687  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:10:22 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 8399  total_loss: 1.27  loss_cls: 0.2896  loss_box_reg: 0.4702  loss_mask: 0.2781  loss_rpn_cls: 0.04921  loss_rpn_loc: 0.1756  time: 0.5910  data_time: 0.3233  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:10:33 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 8419  total_loss: 1.319  loss_cls: 0.2992  loss_box_reg: 0.488  loss_mask: 0.2892  loss_rpn_cls: 0.06712  loss_rpn_loc: 0.1885  time: 0.5909  data_time: 0.2557  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:10:44 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 8439  total_loss: 1.265  loss_cls: 0.2728  loss_box_reg: 0.4877  loss_mask: 0.2894  loss_rpn_cls: 0.07344  loss_rpn_loc: 0.1861  time: 0.5908  data_time: 0.2321  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:10:55 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 8459  total_loss: 1.338  loss_cls: 0.277  loss_box_reg: 0.4987  loss_mask: 0.2936  loss_rpn_cls: 0.0561  loss_rpn_loc: 0.1902  time: 0.5907  data_time: 0.1975  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:11:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:11:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:11:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:11:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:11:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:11:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:11:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0750 s/iter. Eval: 0.0357 s/iter. Total: 0.1113 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 21:11:10 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0525 s/iter. Total: 0.1285 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0556 s/iter. Total: 0.1317 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 21:11:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.125326 (0.130391 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:11:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074779 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:11:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:11:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2605491923203496\n",
      "\u001b[32m[02/01 21:11:25 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 8479  total_loss: 1.365  loss_cls: 0.3116  loss_box_reg: 0.4982  loss_mask: 0.3  loss_rpn_cls: 0.07078  loss_rpn_loc: 0.2035  time: 0.5909  data_time: 0.3370  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:11:38 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 8499  total_loss: 1.313  loss_cls: 0.2762  loss_box_reg: 0.5045  loss_mask: 0.2974  loss_rpn_cls: 0.04952  loss_rpn_loc: 0.1886  time: 0.5910  data_time: 0.2925  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:11:46 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 8519  total_loss: 1.345  loss_cls: 0.313  loss_box_reg: 0.5173  loss_mask: 0.2752  loss_rpn_cls: 0.05127  loss_rpn_loc: 0.1774  time: 0.5906  data_time: 0.1324  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:11:59 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 8539  total_loss: 1.312  loss_cls: 0.3039  loss_box_reg: 0.4847  loss_mask: 0.2853  loss_rpn_cls: 0.07395  loss_rpn_loc: 0.1703  time: 0.5907  data_time: 0.3084  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:12:12 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 8559  total_loss: 1.312  loss_cls: 0.2914  loss_box_reg: 0.4965  loss_mask: 0.2864  loss_rpn_cls: 0.06255  loss_rpn_loc: 0.1848  time: 0.5909  data_time: 0.3424  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:12:22 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 8579  total_loss: 1.196  loss_cls: 0.2735  loss_box_reg: 0.4629  loss_mask: 0.2761  loss_rpn_cls: 0.0501  loss_rpn_loc: 0.1549  time: 0.5906  data_time: 0.1435  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:12:34 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 8599  total_loss: 1.288  loss_cls: 0.2755  loss_box_reg: 0.4933  loss_mask: 0.2959  loss_rpn_cls: 0.06877  loss_rpn_loc: 0.1983  time: 0.5906  data_time: 0.2798  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:12:48 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 8619  total_loss: 1.5  loss_cls: 0.3659  loss_box_reg: 0.5157  loss_mask: 0.3279  loss_rpn_cls: 0.09191  loss_rpn_loc: 0.2119  time: 0.5909  data_time: 0.3648  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:12:58 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 8639  total_loss: 1.315  loss_cls: 0.3071  loss_box_reg: 0.4936  loss_mask: 0.2902  loss_rpn_cls: 0.04815  loss_rpn_loc: 0.1746  time: 0.5907  data_time: 0.1905  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:13:10 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 8659  total_loss: 1.357  loss_cls: 0.2974  loss_box_reg: 0.4854  loss_mask: 0.2943  loss_rpn_cls: 0.08833  loss_rpn_loc: 0.1951  time: 0.5907  data_time: 0.2718  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:13:22 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 8679  total_loss: 1.396  loss_cls: 0.3196  loss_box_reg: 0.4951  loss_mask: 0.2914  loss_rpn_cls: 0.08219  loss_rpn_loc: 0.189  time: 0.5907  data_time: 0.2461  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:13:34 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 8699  total_loss: 1.282  loss_cls: 0.2566  loss_box_reg: 0.4744  loss_mask: 0.3044  loss_rpn_cls: 0.07004  loss_rpn_loc: 0.1747  time: 0.5907  data_time: 0.2897  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:13:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:13:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:13:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:13:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:13:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:13:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:13:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0723 s/iter. Eval: 0.0432 s/iter. Total: 0.1161 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 21:13:48 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0526 s/iter. Total: 0.1274 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:13:53 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0737 s/iter. Eval: 0.0535 s/iter. Total: 0.1279 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/01 21:13:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.647195 (0.126269 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:13:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073305 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:13:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:13:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24836724718041722\n",
      "\u001b[32m[02/01 21:14:01 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 8719  total_loss: 1.292  loss_cls: 0.2875  loss_box_reg: 0.4606  loss_mask: 0.2964  loss_rpn_cls: 0.0372  loss_rpn_loc: 0.1928  time: 0.5906  data_time: 0.2350  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:14:13 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 8739  total_loss: 1.266  loss_cls: 0.2723  loss_box_reg: 0.494  loss_mask: 0.2826  loss_rpn_cls: 0.04925  loss_rpn_loc: 0.1674  time: 0.5907  data_time: 0.2748  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:14:27 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 8759  total_loss: 1.473  loss_cls: 0.3784  loss_box_reg: 0.5067  loss_mask: 0.3034  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.2093  time: 0.5910  data_time: 0.3819  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:14:40 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 8779  total_loss: 1.269  loss_cls: 0.2513  loss_box_reg: 0.4601  loss_mask: 0.2977  loss_rpn_cls: 0.04977  loss_rpn_loc: 0.1783  time: 0.5910  data_time: 0.2950  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:14:54 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 8799  total_loss: 1.36  loss_cls: 0.3247  loss_box_reg: 0.4771  loss_mask: 0.2759  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1946  time: 0.5913  data_time: 0.3993  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:15:07 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 8819  total_loss: 1.406  loss_cls: 0.3026  loss_box_reg: 0.4854  loss_mask: 0.2915  loss_rpn_cls: 0.05631  loss_rpn_loc: 0.1778  time: 0.5914  data_time: 0.3036  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:15:17 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 8839  total_loss: 1.355  loss_cls: 0.3204  loss_box_reg: 0.491  loss_mask: 0.2914  loss_rpn_cls: 0.06719  loss_rpn_loc: 0.1807  time: 0.5912  data_time: 0.1924  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:15:31 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 8859  total_loss: 1.312  loss_cls: 0.2983  loss_box_reg: 0.4493  loss_mask: 0.2886  loss_rpn_cls: 0.06459  loss_rpn_loc: 0.185  time: 0.5915  data_time: 0.3929  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:15:45 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 8879  total_loss: 1.319  loss_cls: 0.2939  loss_box_reg: 0.4647  loss_mask: 0.3014  loss_rpn_cls: 0.0696  loss_rpn_loc: 0.1896  time: 0.5917  data_time: 0.3612  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:15:55 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 8899  total_loss: 1.263  loss_cls: 0.2647  loss_box_reg: 0.4527  loss_mask: 0.3008  loss_rpn_cls: 0.06519  loss_rpn_loc: 0.1645  time: 0.5916  data_time: 0.2064  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:16:08 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 8919  total_loss: 1.248  loss_cls: 0.2765  loss_box_reg: 0.4831  loss_mask: 0.2844  loss_rpn_cls: 0.05912  loss_rpn_loc: 0.1849  time: 0.5916  data_time: 0.2910  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:16:19 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 8939  total_loss: 1.375  loss_cls: 0.3056  loss_box_reg: 0.4684  loss_mask: 0.288  loss_rpn_cls: 0.05777  loss_rpn_loc: 0.2021  time: 0.5915  data_time: 0.2479  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:16:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:16:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:16:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:16:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:16:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:16:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:16:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0748 s/iter. Eval: 0.0405 s/iter. Total: 0.1160 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 21:16:35 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0007 s/iter. Inference: 0.0777 s/iter. Eval: 0.0583 s/iter. Total: 0.1368 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 21:16:40 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0769 s/iter. Eval: 0.0609 s/iter. Total: 0.1387 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 21:16:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.798314 (0.136192 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:16:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076102 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:16:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:16:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.267307136552999\n",
      "\u001b[32m[02/01 21:16:49 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 8959  total_loss: 1.428  loss_cls: 0.3392  loss_box_reg: 0.4899  loss_mask: 0.2945  loss_rpn_cls: 0.07809  loss_rpn_loc: 0.1915  time: 0.5916  data_time: 0.2954  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:16:58 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 8979  total_loss: 1.2  loss_cls: 0.279  loss_box_reg: 0.4815  loss_mask: 0.2764  loss_rpn_cls: 0.04926  loss_rpn_loc: 0.1657  time: 0.5913  data_time: 0.1584  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:17:13 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 8999  total_loss: 1.334  loss_cls: 0.296  loss_box_reg: 0.4623  loss_mask: 0.2898  loss_rpn_cls: 0.06442  loss_rpn_loc: 0.1768  time: 0.5917  data_time: 0.4057  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:17:24 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 9019  total_loss: 1.352  loss_cls: 0.2981  loss_box_reg: 0.5118  loss_mask: 0.2989  loss_rpn_cls: 0.04992  loss_rpn_loc: 0.1778  time: 0.5915  data_time: 0.2088  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:17:34 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 9039  total_loss: 1.304  loss_cls: 0.2739  loss_box_reg: 0.4936  loss_mask: 0.2829  loss_rpn_cls: 0.05654  loss_rpn_loc: 0.1911  time: 0.5914  data_time: 0.2126  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:17:44 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 9059  total_loss: 1.374  loss_cls: 0.3223  loss_box_reg: 0.4811  loss_mask: 0.2917  loss_rpn_cls: 0.07342  loss_rpn_loc: 0.1882  time: 0.5912  data_time: 0.1937  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:17:57 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 9079  total_loss: 1.271  loss_cls: 0.3093  loss_box_reg: 0.4584  loss_mask: 0.2799  loss_rpn_cls: 0.07147  loss_rpn_loc: 0.1775  time: 0.5913  data_time: 0.2980  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:18:10 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 9099  total_loss: 1.318  loss_cls: 0.3093  loss_box_reg: 0.4722  loss_mask: 0.289  loss_rpn_cls: 0.07036  loss_rpn_loc: 0.1811  time: 0.5914  data_time: 0.2954  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:18:22 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 9119  total_loss: 1.426  loss_cls: 0.3498  loss_box_reg: 0.4913  loss_mask: 0.2782  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.1918  time: 0.5915  data_time: 0.3003  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:18:36 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 9139  total_loss: 1.352  loss_cls: 0.3093  loss_box_reg: 0.4834  loss_mask: 0.2868  loss_rpn_cls: 0.06492  loss_rpn_loc: 0.1761  time: 0.5917  data_time: 0.3428  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:18:50 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 9159  total_loss: 1.285  loss_cls: 0.3026  loss_box_reg: 0.446  loss_mask: 0.2884  loss_rpn_cls: 0.07763  loss_rpn_loc: 0.1759  time: 0.5919  data_time: 0.3469  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:19:02 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 9179  total_loss: 1.417  loss_cls: 0.3194  loss_box_reg: 0.4703  loss_mask: 0.2894  loss_rpn_cls: 0.06655  loss_rpn_loc: 0.1917  time: 0.5919  data_time: 0.2696  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:19:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:19:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:19:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:19:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:19:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:19:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0731 s/iter. Eval: 0.0421 s/iter. Total: 0.1160 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 21:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0764 s/iter. Eval: 0.0543 s/iter. Total: 0.1315 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:19:24 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0768 s/iter. Eval: 0.0566 s/iter. Total: 0.1342 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 21:19:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.369305 (0.132494 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:19:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076351 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:19:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:19:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2563701619181447\n",
      "\u001b[32m[02/01 21:19:31 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 9199  total_loss: 1.352  loss_cls: 0.3073  loss_box_reg: 0.4915  loss_mask: 0.2747  loss_rpn_cls: 0.05595  loss_rpn_loc: 0.1954  time: 0.5919  data_time: 0.2612  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:19:43 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 9219  total_loss: 1.286  loss_cls: 0.2934  loss_box_reg: 0.4887  loss_mask: 0.2987  loss_rpn_cls: 0.05525  loss_rpn_loc: 0.1808  time: 0.5920  data_time: 0.2744  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:19:54 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 9239  total_loss: 1.241  loss_cls: 0.2558  loss_box_reg: 0.4817  loss_mask: 0.2954  loss_rpn_cls: 0.03634  loss_rpn_loc: 0.1779  time: 0.5919  data_time: 0.2180  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:20:06 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 9259  total_loss: 1.235  loss_cls: 0.2925  loss_box_reg: 0.4732  loss_mask: 0.2683  loss_rpn_cls: 0.03985  loss_rpn_loc: 0.1694  time: 0.5918  data_time: 0.2507  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:20:19 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 9279  total_loss: 1.302  loss_cls: 0.2902  loss_box_reg: 0.4758  loss_mask: 0.2842  loss_rpn_cls: 0.051  loss_rpn_loc: 0.1765  time: 0.5920  data_time: 0.3200  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:20:30 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 9299  total_loss: 1.395  loss_cls: 0.3039  loss_box_reg: 0.5136  loss_mask: 0.2834  loss_rpn_cls: 0.06585  loss_rpn_loc: 0.2018  time: 0.5919  data_time: 0.2454  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:20:41 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 9319  total_loss: 1.256  loss_cls: 0.2763  loss_box_reg: 0.4665  loss_mask: 0.2904  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.185  time: 0.5918  data_time: 0.2256  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:20:53 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 9339  total_loss: 1.316  loss_cls: 0.2797  loss_box_reg: 0.471  loss_mask: 0.2835  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.1781  time: 0.5919  data_time: 0.3077  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:21:05 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 9359  total_loss: 1.39  loss_cls: 0.3575  loss_box_reg: 0.5047  loss_mask: 0.2924  loss_rpn_cls: 0.08351  loss_rpn_loc: 0.1907  time: 0.5918  data_time: 0.2418  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:21:16 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 9379  total_loss: 1.371  loss_cls: 0.3073  loss_box_reg: 0.5061  loss_mask: 0.2995  loss_rpn_cls: 0.05966  loss_rpn_loc: 0.1924  time: 0.5917  data_time: 0.2287  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:21:29 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 9399  total_loss: 1.346  loss_cls: 0.2931  loss_box_reg: 0.4916  loss_mask: 0.3007  loss_rpn_cls: 0.07589  loss_rpn_loc: 0.2046  time: 0.5919  data_time: 0.3178  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:21:38 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 9419  total_loss: 1.39  loss_cls: 0.3246  loss_box_reg: 0.504  loss_mask: 0.2938  loss_rpn_cls: 0.08339  loss_rpn_loc: 0.1921  time: 0.5916  data_time: 0.1670  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:21:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:21:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:21:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:21:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:21:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:21:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0735 s/iter. Eval: 0.0589 s/iter. Total: 0.1333 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/01 21:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0739 s/iter. Eval: 0.0603 s/iter. Total: 0.1351 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0613 s/iter. Total: 0.1370 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 21:22:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.569605 (0.134221 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:22:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074275 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:22:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:22:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25868047056855237\n",
      "\u001b[32m[02/01 21:22:10 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 9439  total_loss: 1.347  loss_cls: 0.282  loss_box_reg: 0.4606  loss_mask: 0.289  loss_rpn_cls: 0.05677  loss_rpn_loc: 0.1916  time: 0.5920  data_time: 0.4161  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:22:23 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9459  total_loss: 1.362  loss_cls: 0.304  loss_box_reg: 0.4736  loss_mask: 0.2847  loss_rpn_cls: 0.06106  loss_rpn_loc: 0.1959  time: 0.5921  data_time: 0.3096  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:22:36 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 9479  total_loss: 1.329  loss_cls: 0.2874  loss_box_reg: 0.4701  loss_mask: 0.311  loss_rpn_cls: 0.07054  loss_rpn_loc: 0.1881  time: 0.5921  data_time: 0.2908  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:22:45 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 9499  total_loss: 1.274  loss_cls: 0.2858  loss_box_reg: 0.4693  loss_mask: 0.2817  loss_rpn_cls: 0.05147  loss_rpn_loc: 0.1631  time: 0.5919  data_time: 0.1562  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:22:57 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 9519  total_loss: 1.315  loss_cls: 0.3107  loss_box_reg: 0.4865  loss_mask: 0.2968  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1756  time: 0.5919  data_time: 0.2737  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:23:10 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 9539  total_loss: 1.328  loss_cls: 0.3335  loss_box_reg: 0.4847  loss_mask: 0.2877  loss_rpn_cls: 0.07442  loss_rpn_loc: 0.1918  time: 0.5919  data_time: 0.2850  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:23:21 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 9559  total_loss: 1.297  loss_cls: 0.2848  loss_box_reg: 0.4733  loss_mask: 0.2802  loss_rpn_cls: 0.0511  loss_rpn_loc: 0.1814  time: 0.5918  data_time: 0.2319  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:23:31 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9579  total_loss: 1.356  loss_cls: 0.2864  loss_box_reg: 0.4785  loss_mask: 0.2792  loss_rpn_cls: 0.05949  loss_rpn_loc: 0.1909  time: 0.5917  data_time: 0.2170  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:23:42 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 9599  total_loss: 1.316  loss_cls: 0.2861  loss_box_reg: 0.4992  loss_mask: 0.2922  loss_rpn_cls: 0.06957  loss_rpn_loc: 0.1925  time: 0.5916  data_time: 0.2209  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:23:54 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 9619  total_loss: 1.331  loss_cls: 0.2702  loss_box_reg: 0.4943  loss_mask: 0.2966  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.2008  time: 0.5917  data_time: 0.2999  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:24:06 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 9639  total_loss: 1.349  loss_cls: 0.305  loss_box_reg: 0.4784  loss_mask: 0.2995  loss_rpn_cls: 0.077  loss_rpn_loc: 0.1814  time: 0.5917  data_time: 0.2528  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:24:18 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9659  total_loss: 1.407  loss_cls: 0.33  loss_box_reg: 0.5174  loss_mask: 0.283  loss_rpn_cls: 0.07951  loss_rpn_loc: 0.2077  time: 0.5916  data_time: 0.2718  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:24:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:24:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:24:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:24:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:24:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:24:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0716 s/iter. Eval: 0.0453 s/iter. Total: 0.1175 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 21:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0752 s/iter. Eval: 0.0604 s/iter. Total: 0.1364 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 21:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0630 s/iter. Total: 0.1389 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 21:24:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.830449 (0.136469 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:24:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074616 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:24:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26271876374750797\n",
      "\u001b[32m[02/01 21:24:49 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 9679  total_loss: 1.343  loss_cls: 0.2986  loss_box_reg: 0.4808  loss_mask: 0.3055  loss_rpn_cls: 0.05383  loss_rpn_loc: 0.1816  time: 0.5919  data_time: 0.3755  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:24:58 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 9699  total_loss: 1.263  loss_cls: 0.2652  loss_box_reg: 0.4577  loss_mask: 0.2795  loss_rpn_cls: 0.04054  loss_rpn_loc: 0.174  time: 0.5915  data_time: 0.1098  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:25:09 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 9719  total_loss: 1.36  loss_cls: 0.2825  loss_box_reg: 0.4989  loss_mask: 0.2845  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.1829  time: 0.5915  data_time: 0.2266  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:25:21 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 9739  total_loss: 1.244  loss_cls: 0.262  loss_box_reg: 0.4812  loss_mask: 0.287  loss_rpn_cls: 0.0567  loss_rpn_loc: 0.1848  time: 0.5915  data_time: 0.2918  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:25:34 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 9759  total_loss: 1.294  loss_cls: 0.2866  loss_box_reg: 0.4743  loss_mask: 0.2881  loss_rpn_cls: 0.05524  loss_rpn_loc: 0.1744  time: 0.5916  data_time: 0.3142  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:25:47 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 9779  total_loss: 1.323  loss_cls: 0.29  loss_box_reg: 0.4867  loss_mask: 0.282  loss_rpn_cls: 0.063  loss_rpn_loc: 0.1865  time: 0.5917  data_time: 0.2969  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:25:55 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 9799  total_loss: 1.398  loss_cls: 0.3099  loss_box_reg: 0.4914  loss_mask: 0.2963  loss_rpn_cls: 0.07123  loss_rpn_loc: 0.177  time: 0.5914  data_time: 0.1358  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:26:08 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 9819  total_loss: 1.362  loss_cls: 0.2752  loss_box_reg: 0.4612  loss_mask: 0.2938  loss_rpn_cls: 0.06232  loss_rpn_loc: 0.1713  time: 0.5914  data_time: 0.2873  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:26:21 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 9839  total_loss: 1.35  loss_cls: 0.2926  loss_box_reg: 0.4614  loss_mask: 0.2781  loss_rpn_cls: 0.06066  loss_rpn_loc: 0.182  time: 0.5916  data_time: 0.3530  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:26:34 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 9859  total_loss: 1.288  loss_cls: 0.2704  loss_box_reg: 0.4703  loss_mask: 0.2929  loss_rpn_cls: 0.08259  loss_rpn_loc: 0.1979  time: 0.5917  data_time: 0.3134  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:26:48 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 9879  total_loss: 1.307  loss_cls: 0.3054  loss_box_reg: 0.4757  loss_mask: 0.2882  loss_rpn_cls: 0.08885  loss_rpn_loc: 0.1928  time: 0.5919  data_time: 0.3593  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:26:57 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 9899  total_loss: 1.22  loss_cls: 0.2242  loss_box_reg: 0.4969  loss_mask: 0.2848  loss_rpn_cls: 0.03384  loss_rpn_loc: 0.1552  time: 0.5916  data_time: 0.1124  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:27:08 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 9919  total_loss: 1.3  loss_cls: 0.2957  loss_box_reg: 0.4729  loss_mask: 0.2778  loss_rpn_cls: 0.05357  loss_rpn_loc: 0.1732  time: 0.5915  data_time: 0.2452  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:27:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:27:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:27:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:27:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:27:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:27:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0466 s/iter. Total: 0.1200 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/01 21:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0741 s/iter. Eval: 0.0576 s/iter. Total: 0.1325 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0751 s/iter. Eval: 0.0614 s/iter. Total: 0.1373 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 21:27:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.854665 (0.136678 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:27:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075327 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:27:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:27:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26423883350849464\n",
      "\u001b[32m[02/01 21:27:39 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 9939  total_loss: 1.375  loss_cls: 0.3396  loss_box_reg: 0.4863  loss_mask: 0.2925  loss_rpn_cls: 0.06531  loss_rpn_loc: 0.1819  time: 0.5917  data_time: 0.3329  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:27:50 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 9959  total_loss: 1.323  loss_cls: 0.2916  loss_box_reg: 0.4817  loss_mask: 0.2962  loss_rpn_cls: 0.06649  loss_rpn_loc: 0.1731  time: 0.5917  data_time: 0.2605  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:28:03 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 9979  total_loss: 1.428  loss_cls: 0.3302  loss_box_reg: 0.4871  loss_mask: 0.3045  loss_rpn_cls: 0.08723  loss_rpn_loc: 0.2048  time: 0.5917  data_time: 0.2916  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:28:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.347  loss_cls: 0.2871  loss_box_reg: 0.4796  loss_mask: 0.2869  loss_rpn_cls: 0.06095  loss_rpn_loc: 0.1984  time: 0.5920  data_time: 0.4002  lr: 0.001  max_mem: 6475M\n",
      "\u001b[32m[02/01 21:28:18 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:38:38 (0.5920 s / it)\n",
      "\u001b[32m[02/01 21:28:18 d2.engine.hooks]: \u001b[0mTotal training time: 1:50:05 (0:11:26 on hooks)\n",
      "\u001b[32m[02/01 21:28:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:28:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:28:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:28:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:28:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:28:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:28:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0024 s/iter. Inference: 0.0749 s/iter. Eval: 0.0505 s/iter. Total: 0.1278 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/01 21:28:25 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0011 s/iter. Inference: 0.0761 s/iter. Eval: 0.0649 s/iter. Total: 0.1422 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 21:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0010 s/iter. Inference: 0.0762 s/iter. Eval: 0.0657 s/iter. Total: 0.1428 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 21:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0009 s/iter. Inference: 0.0759 s/iter. Eval: 0.0630 s/iter. Total: 0.1398 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 21:28:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.330919 (0.140784 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:28:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075964 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:28:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:28:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26475525430435143\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.001\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_8.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9cb94d-ffb7-42cd-a17e-9220030773e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/01 21:45:36 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/01 21:45:37 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/01 21:45:39 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/01 21:45:40 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/01 21:45:40 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/01 21:45:40 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/01 21:45:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/01 21:45:40 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/01 21:45:40 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:45:40 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/01 21:45:40 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/01 21:45:53 d2.utils.events]: \u001b[0m eta: 0:55:37  iter: 19  total_loss: 3.118  loss_cls: 1.448  loss_box_reg: 0.328  loss_mask: 0.6905  loss_rpn_cls: 0.353  loss_rpn_loc: 0.2658  time: 0.6283  data_time: 0.2861  lr: 9.9905e-06  max_mem: 4775M\n",
      "\u001b[32m[02/01 21:46:05 d2.utils.events]: \u001b[0m eta: 0:56:37  iter: 39  total_loss: 3.039  loss_cls: 1.367  loss_box_reg: 0.402  loss_mask: 0.6856  loss_rpn_cls: 0.3087  loss_rpn_loc: 0.2504  time: 0.6039  data_time: 0.2556  lr: 1.998e-05  max_mem: 4775M\n",
      "\u001b[32m[02/01 21:46:18 d2.utils.events]: \u001b[0m eta: 0:58:04  iter: 59  total_loss: 2.88  loss_cls: 1.226  loss_box_reg: 0.3949  loss_mask: 0.6678  loss_rpn_cls: 0.2798  loss_rpn_loc: 0.2832  time: 0.6321  data_time: 0.3609  lr: 2.997e-05  max_mem: 4775M\n",
      "\u001b[32m[02/01 21:46:30 d2.utils.events]: \u001b[0m eta: 0:58:29  iter: 79  total_loss: 2.645  loss_cls: 1.042  loss_box_reg: 0.4243  loss_mask: 0.6509  loss_rpn_cls: 0.2782  loss_rpn_loc: 0.2497  time: 0.6229  data_time: 0.2703  lr: 3.9961e-05  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:46:41 d2.utils.events]: \u001b[0m eta: 0:58:22  iter: 99  total_loss: 2.493  loss_cls: 0.8868  loss_box_reg: 0.5511  loss_mask: 0.6265  loss_rpn_cls: 0.1995  loss_rpn_loc: 0.2202  time: 0.6072  data_time: 0.2108  lr: 4.9951e-05  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:46:51 d2.utils.events]: \u001b[0m eta: 0:58:00  iter: 119  total_loss: 2.312  loss_cls: 0.7628  loss_box_reg: 0.4763  loss_mask: 0.5894  loss_rpn_cls: 0.1755  loss_rpn_loc: 0.2278  time: 0.5905  data_time: 0.1871  lr: 5.9941e-05  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:47:01 d2.utils.events]: \u001b[0m eta: 0:56:40  iter: 139  total_loss: 2.208  loss_cls: 0.7095  loss_box_reg: 0.5365  loss_mask: 0.5338  loss_rpn_cls: 0.1599  loss_rpn_loc: 0.2178  time: 0.5733  data_time: 0.1573  lr: 6.993e-05  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:47:13 d2.utils.events]: \u001b[0m eta: 0:56:33  iter: 159  total_loss: 2.167  loss_cls: 0.6871  loss_box_reg: 0.5614  loss_mask: 0.5161  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.2184  time: 0.5758  data_time: 0.2651  lr: 7.9921e-05  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:47:25 d2.utils.events]: \u001b[0m eta: 0:56:05  iter: 179  total_loss: 2.177  loss_cls: 0.6555  loss_box_reg: 0.6454  loss_mask: 0.4834  loss_rpn_cls: 0.1381  loss_rpn_loc: 0.2332  time: 0.5802  data_time: 0.2920  lr: 8.991e-05  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:47:38 d2.utils.events]: \u001b[0m eta: 0:56:23  iter: 199  total_loss: 2.178  loss_cls: 0.6659  loss_box_reg: 0.6198  loss_mask: 0.4821  loss_rpn_cls: 0.1629  loss_rpn_loc: 0.2356  time: 0.5868  data_time: 0.3193  lr: 9.9901e-05  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:47:49 d2.utils.events]: \u001b[0m eta: 0:56:00  iter: 219  total_loss: 1.958  loss_cls: 0.5609  loss_box_reg: 0.6226  loss_mask: 0.4484  loss_rpn_cls: 0.1266  loss_rpn_loc: 0.2344  time: 0.5856  data_time: 0.2549  lr: 0.00010989  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:48:02 d2.utils.events]: \u001b[0m eta: 0:55:44  iter: 239  total_loss: 2.07  loss_cls: 0.5824  loss_box_reg: 0.6758  loss_mask: 0.4422  loss_rpn_cls: 0.1338  loss_rpn_loc: 0.2191  time: 0.5872  data_time: 0.2857  lr: 0.00011988  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:48:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:48:03 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/01 21:48:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:48:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:48:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:48:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:48:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0705 s/iter. Eval: 0.0097 s/iter. Total: 0.0808 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 21:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.0106 s/iter. Total: 0.0795 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/01 21:48:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.121523 (0.078634 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:48:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.068592 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:48:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:48:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.07026840110474554\n",
      "\u001b[32m[02/01 21:48:23 d2.utils.events]: \u001b[0m eta: 0:55:46  iter: 259  total_loss: 1.952  loss_cls: 0.5274  loss_box_reg: 0.6031  loss_mask: 0.4195  loss_rpn_cls: 0.1483  loss_rpn_loc: 0.2459  time: 0.5834  data_time: 0.2101  lr: 0.00012987  max_mem: 5190M\n",
      "\u001b[32m[02/01 21:48:33 d2.utils.events]: \u001b[0m eta: 0:55:13  iter: 279  total_loss: 1.788  loss_cls: 0.4434  loss_box_reg: 0.6562  loss_mask: 0.3627  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2143  time: 0.5781  data_time: 0.1943  lr: 0.00013986  max_mem: 5292M\n",
      "\u001b[32m[02/01 21:48:46 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 299  total_loss: 1.726  loss_cls: 0.4151  loss_box_reg: 0.6094  loss_mask: 0.3609  loss_rpn_cls: 0.143  loss_rpn_loc: 0.2206  time: 0.5833  data_time: 0.3373  lr: 0.00014985  max_mem: 5292M\n",
      "\u001b[32m[02/01 21:48:55 d2.utils.events]: \u001b[0m eta: 0:54:55  iter: 319  total_loss: 1.845  loss_cls: 0.4627  loss_box_reg: 0.6361  loss_mask: 0.3466  loss_rpn_cls: 0.1219  loss_rpn_loc: 0.2308  time: 0.5756  data_time: 0.1431  lr: 0.00015984  max_mem: 5292M\n",
      "\u001b[32m[02/01 21:49:08 d2.utils.events]: \u001b[0m eta: 0:54:58  iter: 339  total_loss: 1.775  loss_cls: 0.4612  loss_box_reg: 0.6192  loss_mask: 0.352  loss_rpn_cls: 0.107  loss_rpn_loc: 0.2289  time: 0.5807  data_time: 0.3132  lr: 0.00016983  max_mem: 5292M\n",
      "\u001b[32m[02/01 21:49:21 d2.utils.events]: \u001b[0m eta: 0:55:03  iter: 359  total_loss: 1.722  loss_cls: 0.4326  loss_box_reg: 0.6825  loss_mask: 0.3228  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.212  time: 0.5836  data_time: 0.2886  lr: 0.00017982  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:49:32 d2.utils.events]: \u001b[0m eta: 0:54:50  iter: 379  total_loss: 1.64  loss_cls: 0.4536  loss_box_reg: 0.6056  loss_mask: 0.3047  loss_rpn_cls: 0.09884  loss_rpn_loc: 0.1929  time: 0.5827  data_time: 0.2439  lr: 0.00018981  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:49:43 d2.utils.events]: \u001b[0m eta: 0:54:38  iter: 399  total_loss: 1.71  loss_cls: 0.3913  loss_box_reg: 0.6109  loss_mask: 0.3354  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.2352  time: 0.5806  data_time: 0.2147  lr: 0.0001998  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:49:55 d2.utils.events]: \u001b[0m eta: 0:54:36  iter: 419  total_loss: 1.654  loss_cls: 0.3876  loss_box_reg: 0.5569  loss_mask: 0.3194  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.2239  time: 0.5818  data_time: 0.2777  lr: 0.00020979  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:50:08 d2.utils.events]: \u001b[0m eta: 0:54:18  iter: 439  total_loss: 1.734  loss_cls: 0.4242  loss_box_reg: 0.595  loss_mask: 0.3164  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2298  time: 0.5841  data_time: 0.3109  lr: 0.00021978  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:50:20 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 459  total_loss: 1.643  loss_cls: 0.4035  loss_box_reg: 0.5795  loss_mask: 0.3252  loss_rpn_cls: 0.09838  loss_rpn_loc: 0.2084  time: 0.5850  data_time: 0.2996  lr: 0.00022977  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:50:32 d2.utils.events]: \u001b[0m eta: 0:53:50  iter: 479  total_loss: 1.64  loss_cls: 0.3891  loss_box_reg: 0.5692  loss_mask: 0.3101  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.2238  time: 0.5853  data_time: 0.2735  lr: 0.00023976  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:50:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:50:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:50:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:50:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:50:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:50:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0692 s/iter. Eval: 0.0293 s/iter. Total: 0.0991 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 21:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 55/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0422 s/iter. Total: 0.1141 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/01 21:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0446 s/iter. Total: 0.1170 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/01 21:50:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.300480 (0.114659 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:50:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071321 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:50:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:50:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20761543151681894\n",
      "\u001b[32m[02/01 21:50:59 d2.utils.events]: \u001b[0m eta: 0:53:27  iter: 499  total_loss: 1.646  loss_cls: 0.3604  loss_box_reg: 0.5752  loss_mask: 0.3232  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.2368  time: 0.5865  data_time: 0.2981  lr: 0.00024975  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:51:09 d2.utils.events]: \u001b[0m eta: 0:53:13  iter: 519  total_loss: 1.555  loss_cls: 0.3335  loss_box_reg: 0.5942  loss_mask: 0.3106  loss_rpn_cls: 0.07838  loss_rpn_loc: 0.1828  time: 0.5830  data_time: 0.1804  lr: 0.00025974  max_mem: 5495M\n",
      "\u001b[32m[02/01 21:51:20 d2.utils.events]: \u001b[0m eta: 0:52:59  iter: 539  total_loss: 1.532  loss_cls: 0.3503  loss_box_reg: 0.536  loss_mask: 0.3195  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2146  time: 0.5811  data_time: 0.2179  lr: 0.00026973  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:51:29 d2.utils.events]: \u001b[0m eta: 0:52:54  iter: 559  total_loss: 1.552  loss_cls: 0.4099  loss_box_reg: 0.5853  loss_mask: 0.2935  loss_rpn_cls: 0.09073  loss_rpn_loc: 0.2048  time: 0.5779  data_time: 0.1807  lr: 0.00027972  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:51:38 d2.utils.events]: \u001b[0m eta: 0:52:35  iter: 579  total_loss: 1.59  loss_cls: 0.3829  loss_box_reg: 0.5948  loss_mask: 0.3074  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.201  time: 0.5732  data_time: 0.1436  lr: 0.00028971  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:51:53 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 599  total_loss: 1.728  loss_cls: 0.4145  loss_box_reg: 0.5596  loss_mask: 0.328  loss_rpn_cls: 0.1226  loss_rpn_loc: 0.2441  time: 0.5791  data_time: 0.4126  lr: 0.0002997  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:52:05 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 619  total_loss: 1.663  loss_cls: 0.3936  loss_box_reg: 0.5797  loss_mask: 0.309  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2249  time: 0.5800  data_time: 0.2778  lr: 0.00030969  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:52:19 d2.utils.events]: \u001b[0m eta: 0:52:26  iter: 639  total_loss: 1.599  loss_cls: 0.3721  loss_box_reg: 0.5532  loss_mask: 0.3209  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.2308  time: 0.5829  data_time: 0.3375  lr: 0.00031968  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:52:32 d2.utils.events]: \u001b[0m eta: 0:52:27  iter: 659  total_loss: 1.555  loss_cls: 0.3735  loss_box_reg: 0.5271  loss_mask: 0.2958  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.2248  time: 0.5851  data_time: 0.3201  lr: 0.00032967  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:52:44 d2.utils.events]: \u001b[0m eta: 0:52:22  iter: 679  total_loss: 1.592  loss_cls: 0.3663  loss_box_reg: 0.5591  loss_mask: 0.3197  loss_rpn_cls: 0.115  loss_rpn_loc: 0.2133  time: 0.5854  data_time: 0.2813  lr: 0.00033966  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:52:59 d2.utils.events]: \u001b[0m eta: 0:52:39  iter: 699  total_loss: 1.5  loss_cls: 0.3587  loss_box_reg: 0.546  loss_mask: 0.3152  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.2084  time: 0.5903  data_time: 0.4097  lr: 0.00034965  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:53:11 d2.utils.events]: \u001b[0m eta: 0:52:42  iter: 719  total_loss: 1.664  loss_cls: 0.3957  loss_box_reg: 0.5919  loss_mask: 0.3166  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.2267  time: 0.5909  data_time: 0.2700  lr: 0.00035964  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:53:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:53:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:53:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:53:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:53:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:53:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:53:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0332 s/iter. Total: 0.1047 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 21:53:21 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0497 s/iter. Total: 0.1243 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 21:53:26 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0518 s/iter. Total: 0.1265 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/01 21:53:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.515862 (0.125137 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:53:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073363 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:53:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:53:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2198199857892429\n",
      "\u001b[32m[02/01 21:53:38 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 739  total_loss: 1.536  loss_cls: 0.3467  loss_box_reg: 0.5326  loss_mask: 0.3072  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.2097  time: 0.5903  data_time: 0.2504  lr: 0.00036963  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:53:49 d2.utils.events]: \u001b[0m eta: 0:52:25  iter: 759  total_loss: 1.554  loss_cls: 0.3534  loss_box_reg: 0.5965  loss_mask: 0.3223  loss_rpn_cls: 0.08712  loss_rpn_loc: 0.2168  time: 0.5889  data_time: 0.2321  lr: 0.00037962  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:54:00 d2.utils.events]: \u001b[0m eta: 0:52:12  iter: 779  total_loss: 1.545  loss_cls: 0.3454  loss_box_reg: 0.547  loss_mask: 0.3032  loss_rpn_cls: 0.09565  loss_rpn_loc: 0.2042  time: 0.5871  data_time: 0.2003  lr: 0.00038961  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:54:13 d2.utils.events]: \u001b[0m eta: 0:52:12  iter: 799  total_loss: 1.665  loss_cls: 0.3932  loss_box_reg: 0.5617  loss_mask: 0.3093  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2117  time: 0.5893  data_time: 0.3414  lr: 0.0003996  max_mem: 5870M\n",
      "\u001b[32m[02/01 21:54:26 d2.utils.events]: \u001b[0m eta: 0:52:08  iter: 819  total_loss: 1.55  loss_cls: 0.4133  loss_box_reg: 0.5644  loss_mask: 0.3093  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.1951  time: 0.5903  data_time: 0.2964  lr: 0.00040959  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:54:39 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 839  total_loss: 1.605  loss_cls: 0.3946  loss_box_reg: 0.5319  loss_mask: 0.3195  loss_rpn_cls: 0.1271  loss_rpn_loc: 0.206  time: 0.5923  data_time: 0.3378  lr: 0.00041958  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:54:52 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 859  total_loss: 1.539  loss_cls: 0.3832  loss_box_reg: 0.5302  loss_mask: 0.306  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.2022  time: 0.5934  data_time: 0.3093  lr: 0.00042957  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:55:04 d2.utils.events]: \u001b[0m eta: 0:52:03  iter: 879  total_loss: 1.605  loss_cls: 0.4077  loss_box_reg: 0.549  loss_mask: 0.3051  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.2161  time: 0.5941  data_time: 0.2927  lr: 0.00043956  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:55:14 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 899  total_loss: 1.537  loss_cls: 0.3512  loss_box_reg: 0.5442  loss_mask: 0.2978  loss_rpn_cls: 0.09917  loss_rpn_loc: 0.204  time: 0.5917  data_time: 0.1867  lr: 0.00044955  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:55:26 d2.utils.events]: \u001b[0m eta: 0:51:36  iter: 919  total_loss: 1.471  loss_cls: 0.3406  loss_box_reg: 0.5407  loss_mask: 0.2961  loss_rpn_cls: 0.08248  loss_rpn_loc: 0.2122  time: 0.5914  data_time: 0.2701  lr: 0.00045954  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:55:35 d2.utils.events]: \u001b[0m eta: 0:51:26  iter: 939  total_loss: 1.622  loss_cls: 0.381  loss_box_reg: 0.6016  loss_mask: 0.3162  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.2326  time: 0.5882  data_time: 0.1323  lr: 0.00046953  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:55:47 d2.utils.events]: \u001b[0m eta: 0:51:19  iter: 959  total_loss: 1.632  loss_cls: 0.396  loss_box_reg: 0.5652  loss_mask: 0.3231  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.2121  time: 0.5893  data_time: 0.3160  lr: 0.00047952  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:55:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:55:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:55:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:55:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:55:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:55:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0723 s/iter. Eval: 0.0304 s/iter. Total: 0.1034 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 21:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0745 s/iter. Eval: 0.0526 s/iter. Total: 0.1278 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 21:56:04 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0585 s/iter. Total: 0.1346 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 21:56:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.368990 (0.132491 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:56:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074816 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:56:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:56:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24455343344463307\n",
      "\u001b[32m[02/01 21:56:16 d2.utils.events]: \u001b[0m eta: 0:51:12  iter: 979  total_loss: 1.421  loss_cls: 0.3221  loss_box_reg: 0.5476  loss_mask: 0.306  loss_rpn_cls: 0.09227  loss_rpn_loc: 0.1888  time: 0.5896  data_time: 0.2829  lr: 0.00048951  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:56:25 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 999  total_loss: 1.468  loss_cls: 0.3333  loss_box_reg: 0.5716  loss_mask: 0.2908  loss_rpn_cls: 0.07717  loss_rpn_loc: 0.1786  time: 0.5869  data_time: 0.1472  lr: 0.0004995  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:56:35 d2.utils.events]: \u001b[0m eta: 0:50:50  iter: 1019  total_loss: 1.53  loss_cls: 0.3593  loss_box_reg: 0.5203  loss_mask: 0.299  loss_rpn_cls: 0.09383  loss_rpn_loc: 0.2216  time: 0.5852  data_time: 0.1850  lr: 0.0005  max_mem: 5871M\n",
      "\u001b[32m[02/01 21:56:48 d2.utils.events]: \u001b[0m eta: 0:50:40  iter: 1039  total_loss: 1.484  loss_cls: 0.3399  loss_box_reg: 0.5418  loss_mask: 0.3133  loss_rpn_cls: 0.09804  loss_rpn_loc: 0.2191  time: 0.5857  data_time: 0.2819  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:56:59 d2.utils.events]: \u001b[0m eta: 0:50:29  iter: 1059  total_loss: 1.516  loss_cls: 0.3381  loss_box_reg: 0.5504  loss_mask: 0.2931  loss_rpn_cls: 0.0974  loss_rpn_loc: 0.1891  time: 0.5849  data_time: 0.2266  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:57:09 d2.utils.events]: \u001b[0m eta: 0:50:16  iter: 1079  total_loss: 1.496  loss_cls: 0.3475  loss_box_reg: 0.5692  loss_mask: 0.3016  loss_rpn_cls: 0.09303  loss_rpn_loc: 0.1999  time: 0.5834  data_time: 0.1980  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:57:20 d2.utils.events]: \u001b[0m eta: 0:50:02  iter: 1099  total_loss: 1.604  loss_cls: 0.3426  loss_box_reg: 0.5853  loss_mask: 0.3108  loss_rpn_cls: 0.08344  loss_rpn_loc: 0.2204  time: 0.5831  data_time: 0.2491  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:57:34 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 1119  total_loss: 1.608  loss_cls: 0.3673  loss_box_reg: 0.5585  loss_mask: 0.3214  loss_rpn_cls: 0.07746  loss_rpn_loc: 0.2263  time: 0.5853  data_time: 0.3805  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:57:49 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 1139  total_loss: 1.497  loss_cls: 0.3369  loss_box_reg: 0.5012  loss_mask: 0.3136  loss_rpn_cls: 0.08163  loss_rpn_loc: 0.2239  time: 0.5880  data_time: 0.3940  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:58:02 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 1159  total_loss: 1.516  loss_cls: 0.3547  loss_box_reg: 0.5392  loss_mask: 0.3007  loss_rpn_cls: 0.09558  loss_rpn_loc: 0.2064  time: 0.5892  data_time: 0.3450  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:58:14 d2.utils.events]: \u001b[0m eta: 0:49:44  iter: 1179  total_loss: 1.647  loss_cls: 0.3781  loss_box_reg: 0.5688  loss_mask: 0.3146  loss_rpn_cls: 0.09791  loss_rpn_loc: 0.2014  time: 0.5890  data_time: 0.2512  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:58:26 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 1199  total_loss: 1.61  loss_cls: 0.3616  loss_box_reg: 0.5761  loss_mask: 0.3028  loss_rpn_cls: 0.1228  loss_rpn_loc: 0.2059  time: 0.5892  data_time: 0.2744  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:58:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:58:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 21:58:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 21:58:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 21:58:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 21:58:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 21:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0344 s/iter. Total: 0.1053 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 21:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0495 s/iter. Total: 0.1230 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 21:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0728 s/iter. Eval: 0.0512 s/iter. Total: 0.1248 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/01 21:58:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.263172 (0.122958 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:58:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072526 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 21:58:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 21:58:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24172428295944512\n",
      "\u001b[32m[02/01 21:58:54 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 1219  total_loss: 1.548  loss_cls: 0.3657  loss_box_reg: 0.5382  loss_mask: 0.3135  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.2225  time: 0.5896  data_time: 0.2777  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:59:06 d2.utils.events]: \u001b[0m eta: 0:49:30  iter: 1239  total_loss: 1.571  loss_cls: 0.3683  loss_box_reg: 0.5279  loss_mask: 0.3195  loss_rpn_cls: 0.1131  loss_rpn_loc: 0.2195  time: 0.5903  data_time: 0.3081  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:59:21 d2.utils.events]: \u001b[0m eta: 0:49:28  iter: 1259  total_loss: 1.457  loss_cls: 0.3422  loss_box_reg: 0.5116  loss_mask: 0.3028  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2066  time: 0.5927  data_time: 0.4057  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:59:32 d2.utils.events]: \u001b[0m eta: 0:49:24  iter: 1279  total_loss: 1.557  loss_cls: 0.3661  loss_box_reg: 0.5591  loss_mask: 0.2977  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.2122  time: 0.5923  data_time: 0.2581  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:59:43 d2.utils.events]: \u001b[0m eta: 0:49:15  iter: 1299  total_loss: 1.426  loss_cls: 0.3117  loss_box_reg: 0.5457  loss_mask: 0.2945  loss_rpn_cls: 0.08675  loss_rpn_loc: 0.1977  time: 0.5910  data_time: 0.1896  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 21:59:55 d2.utils.events]: \u001b[0m eta: 0:49:10  iter: 1319  total_loss: 1.472  loss_cls: 0.3579  loss_box_reg: 0.5285  loss_mask: 0.3133  loss_rpn_cls: 0.07897  loss_rpn_loc: 0.2027  time: 0.5917  data_time: 0.3218  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 22:00:10 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 1339  total_loss: 1.429  loss_cls: 0.3208  loss_box_reg: 0.5223  loss_mask: 0.3042  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.1938  time: 0.5934  data_time: 0.3717  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 22:00:20 d2.utils.events]: \u001b[0m eta: 0:48:51  iter: 1359  total_loss: 1.476  loss_cls: 0.3273  loss_box_reg: 0.5535  loss_mask: 0.3047  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.1765  time: 0.5921  data_time: 0.1827  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 22:00:29 d2.utils.events]: \u001b[0m eta: 0:48:49  iter: 1379  total_loss: 1.551  loss_cls: 0.364  loss_box_reg: 0.5561  loss_mask: 0.313  loss_rpn_cls: 0.08627  loss_rpn_loc: 0.2046  time: 0.5907  data_time: 0.1720  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[02/01 22:00:45 d2.utils.events]: \u001b[0m eta: 0:48:47  iter: 1399  total_loss: 1.504  loss_cls: 0.3417  loss_box_reg: 0.5344  loss_mask: 0.3039  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.2073  time: 0.5932  data_time: 0.4319  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:00:52 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 1419  total_loss: 1.495  loss_cls: 0.3281  loss_box_reg: 0.5781  loss_mask: 0.2989  loss_rpn_cls: 0.07747  loss_rpn_loc: 0.1968  time: 0.5900  data_time: 0.0629  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:01:06 d2.utils.events]: \u001b[0m eta: 0:48:30  iter: 1439  total_loss: 1.408  loss_cls: 0.3102  loss_box_reg: 0.5023  loss_mask: 0.2949  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.209  time: 0.5916  data_time: 0.3809  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:01:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:01:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:01:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:01:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:01:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:01:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0712 s/iter. Eval: 0.0348 s/iter. Total: 0.1066 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0531 s/iter. Total: 0.1282 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0752 s/iter. Eval: 0.0576 s/iter. Total: 0.1335 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:01:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.279042 (0.131716 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:01:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075037 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:01:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:01:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2482725825791396\n",
      "\u001b[32m[02/01 22:01:33 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 1459  total_loss: 1.558  loss_cls: 0.3512  loss_box_reg: 0.5579  loss_mask: 0.3043  loss_rpn_cls: 0.09735  loss_rpn_loc: 0.2178  time: 0.5903  data_time: 0.1786  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:01:44 d2.utils.events]: \u001b[0m eta: 0:48:20  iter: 1479  total_loss: 1.424  loss_cls: 0.3107  loss_box_reg: 0.5321  loss_mask: 0.3105  loss_rpn_cls: 0.09059  loss_rpn_loc: 0.2083  time: 0.5899  data_time: 0.2446  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:01:56 d2.utils.events]: \u001b[0m eta: 0:48:22  iter: 1499  total_loss: 1.518  loss_cls: 0.3826  loss_box_reg: 0.5586  loss_mask: 0.3144  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.205  time: 0.5901  data_time: 0.2727  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:02:10 d2.utils.events]: \u001b[0m eta: 0:48:26  iter: 1519  total_loss: 1.542  loss_cls: 0.3678  loss_box_reg: 0.5068  loss_mask: 0.3215  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.2196  time: 0.5912  data_time: 0.3381  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:02:22 d2.utils.events]: \u001b[0m eta: 0:48:28  iter: 1539  total_loss: 1.511  loss_cls: 0.3181  loss_box_reg: 0.538  loss_mask: 0.3027  loss_rpn_cls: 0.0843  loss_rpn_loc: 0.21  time: 0.5912  data_time: 0.2571  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:02:35 d2.utils.events]: \u001b[0m eta: 0:48:21  iter: 1559  total_loss: 1.415  loss_cls: 0.3319  loss_box_reg: 0.531  loss_mask: 0.3009  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.2071  time: 0.5920  data_time: 0.3265  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:02:47 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 1579  total_loss: 1.513  loss_cls: 0.3691  loss_box_reg: 0.5141  loss_mask: 0.2901  loss_rpn_cls: 0.09037  loss_rpn_loc: 0.1934  time: 0.5925  data_time: 0.2839  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:03:00 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 1599  total_loss: 1.446  loss_cls: 0.3427  loss_box_reg: 0.5091  loss_mask: 0.2924  loss_rpn_cls: 0.0974  loss_rpn_loc: 0.2104  time: 0.5932  data_time: 0.3310  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:03:10 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 1619  total_loss: 1.469  loss_cls: 0.3424  loss_box_reg: 0.5132  loss_mask: 0.3015  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.1919  time: 0.5921  data_time: 0.1875  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:03:25 d2.utils.events]: \u001b[0m eta: 0:48:01  iter: 1639  total_loss: 1.557  loss_cls: 0.3697  loss_box_reg: 0.5096  loss_mask: 0.3123  loss_rpn_cls: 0.09293  loss_rpn_loc: 0.2272  time: 0.5939  data_time: 0.3874  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:03:36 d2.utils.events]: \u001b[0m eta: 0:47:54  iter: 1659  total_loss: 1.483  loss_cls: 0.3459  loss_box_reg: 0.5411  loss_mask: 0.2967  loss_rpn_cls: 0.08299  loss_rpn_loc: 0.1862  time: 0.5933  data_time: 0.2195  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:03:46 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 1679  total_loss: 1.529  loss_cls: 0.3419  loss_box_reg: 0.5226  loss_mask: 0.3194  loss_rpn_cls: 0.08072  loss_rpn_loc: 0.2251  time: 0.5923  data_time: 0.2006  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:03:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:03:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:03:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:03:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:03:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:03:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0701 s/iter. Eval: 0.0325 s/iter. Total: 0.1032 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:04:01 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0758 s/iter. Eval: 0.0546 s/iter. Total: 0.1312 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:04:06 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0757 s/iter. Eval: 0.0583 s/iter. Total: 0.1348 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:04:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.427205 (0.132993 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:04:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075336 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:04:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:04:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25358404516796806\n",
      "\u001b[32m[02/01 22:04:13 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 1699  total_loss: 1.473  loss_cls: 0.3735  loss_box_reg: 0.523  loss_mask: 0.3144  loss_rpn_cls: 0.08695  loss_rpn_loc: 0.2007  time: 0.5913  data_time: 0.1822  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:04:25 d2.utils.events]: \u001b[0m eta: 0:47:07  iter: 1719  total_loss: 1.557  loss_cls: 0.3496  loss_box_reg: 0.5427  loss_mask: 0.3141  loss_rpn_cls: 0.07822  loss_rpn_loc: 0.1999  time: 0.5911  data_time: 0.2558  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:04:37 d2.utils.events]: \u001b[0m eta: 0:47:00  iter: 1739  total_loss: 1.556  loss_cls: 0.3673  loss_box_reg: 0.5325  loss_mask: 0.3218  loss_rpn_cls: 0.08347  loss_rpn_loc: 0.2083  time: 0.5913  data_time: 0.2887  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:04:45 d2.utils.events]: \u001b[0m eta: 0:46:51  iter: 1759  total_loss: 1.316  loss_cls: 0.2936  loss_box_reg: 0.5232  loss_mask: 0.2904  loss_rpn_cls: 0.06672  loss_rpn_loc: 0.186  time: 0.5895  data_time: 0.1264  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:04:59 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 1779  total_loss: 1.597  loss_cls: 0.386  loss_box_reg: 0.558  loss_mask: 0.3124  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2172  time: 0.5906  data_time: 0.3530  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:05:14 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 1799  total_loss: 1.39  loss_cls: 0.3175  loss_box_reg: 0.5023  loss_mask: 0.288  loss_rpn_cls: 0.101  loss_rpn_loc: 0.193  time: 0.5924  data_time: 0.4191  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:05:27 d2.utils.events]: \u001b[0m eta: 0:46:41  iter: 1819  total_loss: 1.515  loss_cls: 0.3208  loss_box_reg: 0.559  loss_mask: 0.3015  loss_rpn_cls: 0.08168  loss_rpn_loc: 0.1873  time: 0.5930  data_time: 0.2995  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:05:36 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 1839  total_loss: 1.473  loss_cls: 0.3624  loss_box_reg: 0.5159  loss_mask: 0.2882  loss_rpn_cls: 0.07995  loss_rpn_loc: 0.1932  time: 0.5915  data_time: 0.1495  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:05:46 d2.utils.events]: \u001b[0m eta: 0:46:18  iter: 1859  total_loss: 1.363  loss_cls: 0.318  loss_box_reg: 0.512  loss_mask: 0.2803  loss_rpn_cls: 0.07337  loss_rpn_loc: 0.1731  time: 0.5901  data_time: 0.1393  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:06:01 d2.utils.events]: \u001b[0m eta: 0:46:11  iter: 1879  total_loss: 1.535  loss_cls: 0.344  loss_box_reg: 0.5324  loss_mask: 0.3157  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2078  time: 0.5919  data_time: 0.4093  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:06:14 d2.utils.events]: \u001b[0m eta: 0:46:15  iter: 1899  total_loss: 1.592  loss_cls: 0.3818  loss_box_reg: 0.5283  loss_mask: 0.3108  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.209  time: 0.5925  data_time: 0.3254  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:06:23 d2.utils.events]: \u001b[0m eta: 0:46:08  iter: 1919  total_loss: 1.434  loss_cls: 0.3127  loss_box_reg: 0.5488  loss_mask: 0.2927  loss_rpn_cls: 0.06484  loss_rpn_loc: 0.1932  time: 0.5912  data_time: 0.1546  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:06:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:06:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:06:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:06:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:06:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:06:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:06:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0343 s/iter. Total: 0.1056 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:06:42 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0542 s/iter. Total: 0.1290 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:06:47 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0746 s/iter. Eval: 0.0590 s/iter. Total: 0.1345 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:06:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.340826 (0.132249 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:06:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074214 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:06:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:06:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.256119764095111\n",
      "\u001b[32m[02/01 22:06:54 d2.utils.events]: \u001b[0m eta: 0:46:13  iter: 1939  total_loss: 1.508  loss_cls: 0.3305  loss_box_reg: 0.5269  loss_mask: 0.2992  loss_rpn_cls: 0.07709  loss_rpn_loc: 0.2271  time: 0.5924  data_time: 0.3674  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:07:05 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 1959  total_loss: 1.476  loss_cls: 0.3485  loss_box_reg: 0.5121  loss_mask: 0.3036  loss_rpn_cls: 0.08903  loss_rpn_loc: 0.1936  time: 0.5918  data_time: 0.2064  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:07:16 d2.utils.events]: \u001b[0m eta: 0:45:56  iter: 1979  total_loss: 1.435  loss_cls: 0.3349  loss_box_reg: 0.5442  loss_mask: 0.3101  loss_rpn_cls: 0.09323  loss_rpn_loc: 0.1989  time: 0.5913  data_time: 0.2225  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:07:26 d2.utils.events]: \u001b[0m eta: 0:45:56  iter: 1999  total_loss: 1.426  loss_cls: 0.3379  loss_box_reg: 0.5101  loss_mask: 0.2921  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2173  time: 0.5907  data_time: 0.2192  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:07:39 d2.utils.events]: \u001b[0m eta: 0:45:50  iter: 2019  total_loss: 1.331  loss_cls: 0.3097  loss_box_reg: 0.4957  loss_mask: 0.2872  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.1695  time: 0.5910  data_time: 0.3000  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:07:48 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 2039  total_loss: 1.474  loss_cls: 0.3083  loss_box_reg: 0.5547  loss_mask: 0.2986  loss_rpn_cls: 0.08475  loss_rpn_loc: 0.2004  time: 0.5896  data_time: 0.1358  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:08:01 d2.utils.events]: \u001b[0m eta: 0:45:36  iter: 2059  total_loss: 1.419  loss_cls: 0.2993  loss_box_reg: 0.5064  loss_mask: 0.3048  loss_rpn_cls: 0.08805  loss_rpn_loc: 0.2126  time: 0.5901  data_time: 0.3160  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:08:13 d2.utils.events]: \u001b[0m eta: 0:45:36  iter: 2079  total_loss: 1.558  loss_cls: 0.3804  loss_box_reg: 0.5452  loss_mask: 0.3048  loss_rpn_cls: 0.08876  loss_rpn_loc: 0.2307  time: 0.5903  data_time: 0.2883  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:08:24 d2.utils.events]: \u001b[0m eta: 0:45:29  iter: 2099  total_loss: 1.553  loss_cls: 0.3411  loss_box_reg: 0.5031  loss_mask: 0.3058  loss_rpn_cls: 0.08756  loss_rpn_loc: 0.2164  time: 0.5902  data_time: 0.2704  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:08:34 d2.utils.events]: \u001b[0m eta: 0:45:21  iter: 2119  total_loss: 1.446  loss_cls: 0.3277  loss_box_reg: 0.5222  loss_mask: 0.3025  loss_rpn_cls: 0.09244  loss_rpn_loc: 0.2214  time: 0.5894  data_time: 0.1943  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:08:47 d2.utils.events]: \u001b[0m eta: 0:45:12  iter: 2139  total_loss: 1.449  loss_cls: 0.3059  loss_box_reg: 0.516  loss_mask: 0.2967  loss_rpn_cls: 0.06775  loss_rpn_loc: 0.2035  time: 0.5899  data_time: 0.3219  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:09:02 d2.utils.events]: \u001b[0m eta: 0:45:06  iter: 2159  total_loss: 1.462  loss_cls: 0.3505  loss_box_reg: 0.5166  loss_mask: 0.3043  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.2011  time: 0.5913  data_time: 0.4074  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:09:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:09:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:09:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:09:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:09:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:09:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0351 s/iter. Total: 0.1064 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0542 s/iter. Total: 0.1283 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0585 s/iter. Total: 0.1332 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:09:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.219606 (0.131203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:09:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073566 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:09:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:09:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2588060965733169\n",
      "\u001b[32m[02/01 22:09:27 d2.utils.events]: \u001b[0m eta: 0:44:54  iter: 2179  total_loss: 1.384  loss_cls: 0.333  loss_box_reg: 0.5322  loss_mask: 0.2781  loss_rpn_cls: 0.08311  loss_rpn_loc: 0.1809  time: 0.5898  data_time: 0.1134  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:09:37 d2.utils.events]: \u001b[0m eta: 0:44:42  iter: 2199  total_loss: 1.429  loss_cls: 0.3346  loss_box_reg: 0.5328  loss_mask: 0.312  loss_rpn_cls: 0.0827  loss_rpn_loc: 0.1919  time: 0.5891  data_time: 0.1933  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:09:53 d2.utils.events]: \u001b[0m eta: 0:44:25  iter: 2219  total_loss: 1.552  loss_cls: 0.3861  loss_box_reg: 0.5353  loss_mask: 0.3073  loss_rpn_cls: 0.09477  loss_rpn_loc: 0.2011  time: 0.5905  data_time: 0.4284  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:10:03 d2.utils.events]: \u001b[0m eta: 0:44:14  iter: 2239  total_loss: 1.385  loss_cls: 0.2982  loss_box_reg: 0.5413  loss_mask: 0.3004  loss_rpn_cls: 0.09259  loss_rpn_loc: 0.191  time: 0.5899  data_time: 0.2085  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:10:17 d2.utils.events]: \u001b[0m eta: 0:44:01  iter: 2259  total_loss: 1.347  loss_cls: 0.3164  loss_box_reg: 0.5294  loss_mask: 0.2859  loss_rpn_cls: 0.09778  loss_rpn_loc: 0.2003  time: 0.5908  data_time: 0.3614  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:10:28 d2.utils.events]: \u001b[0m eta: 0:44:01  iter: 2279  total_loss: 1.591  loss_cls: 0.3851  loss_box_reg: 0.5556  loss_mask: 0.3012  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.2019  time: 0.5906  data_time: 0.2489  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:10:37 d2.utils.events]: \u001b[0m eta: 0:43:57  iter: 2299  total_loss: 1.491  loss_cls: 0.3387  loss_box_reg: 0.5522  loss_mask: 0.2957  loss_rpn_cls: 0.08639  loss_rpn_loc: 0.2015  time: 0.5894  data_time: 0.1458  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:10:49 d2.utils.events]: \u001b[0m eta: 0:43:51  iter: 2319  total_loss: 1.589  loss_cls: 0.3594  loss_box_reg: 0.5414  loss_mask: 0.3087  loss_rpn_cls: 0.09307  loss_rpn_loc: 0.217  time: 0.5894  data_time: 0.2550  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:11:02 d2.utils.events]: \u001b[0m eta: 0:43:42  iter: 2339  total_loss: 1.403  loss_cls: 0.3031  loss_box_reg: 0.5024  loss_mask: 0.3089  loss_rpn_cls: 0.06813  loss_rpn_loc: 0.1989  time: 0.5900  data_time: 0.3397  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:11:14 d2.utils.events]: \u001b[0m eta: 0:43:43  iter: 2359  total_loss: 1.383  loss_cls: 0.3272  loss_box_reg: 0.4697  loss_mask: 0.3069  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.1987  time: 0.5901  data_time: 0.2724  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:11:25 d2.utils.events]: \u001b[0m eta: 0:43:25  iter: 2379  total_loss: 1.374  loss_cls: 0.298  loss_box_reg: 0.5253  loss_mask: 0.2964  loss_rpn_cls: 0.07663  loss_rpn_loc: 0.2009  time: 0.5895  data_time: 0.2131  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:11:38 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 2399  total_loss: 1.477  loss_cls: 0.3517  loss_box_reg: 0.5154  loss_mask: 0.3  loss_rpn_cls: 0.08888  loss_rpn_loc: 0.1841  time: 0.5902  data_time: 0.3432  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:11:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:11:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:11:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:11:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:11:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0349 s/iter. Total: 0.1059 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0731 s/iter. Eval: 0.0523 s/iter. Total: 0.1262 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 22:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0735 s/iter. Eval: 0.0560 s/iter. Total: 0.1302 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:12:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.970038 (0.129052 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:12:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073288 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:12:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:12:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2559633704047775\n",
      "\u001b[32m[02/01 22:12:07 d2.utils.events]: \u001b[0m eta: 0:43:20  iter: 2419  total_loss: 1.434  loss_cls: 0.3174  loss_box_reg: 0.5173  loss_mask: 0.2922  loss_rpn_cls: 0.08916  loss_rpn_loc: 0.2161  time: 0.5904  data_time: 0.2983  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:12:19 d2.utils.events]: \u001b[0m eta: 0:43:08  iter: 2439  total_loss: 1.399  loss_cls: 0.3122  loss_box_reg: 0.5124  loss_mask: 0.2902  loss_rpn_cls: 0.07634  loss_rpn_loc: 0.1768  time: 0.5906  data_time: 0.2861  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:12:31 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 2459  total_loss: 1.462  loss_cls: 0.3499  loss_box_reg: 0.481  loss_mask: 0.3129  loss_rpn_cls: 0.08136  loss_rpn_loc: 0.2102  time: 0.5905  data_time: 0.2437  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:12:42 d2.utils.events]: \u001b[0m eta: 0:42:59  iter: 2479  total_loss: 1.477  loss_cls: 0.3266  loss_box_reg: 0.5169  loss_mask: 0.3096  loss_rpn_cls: 0.08913  loss_rpn_loc: 0.2099  time: 0.5903  data_time: 0.2528  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:12:55 d2.utils.events]: \u001b[0m eta: 0:42:55  iter: 2499  total_loss: 1.584  loss_cls: 0.363  loss_box_reg: 0.5138  loss_mask: 0.3057  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2272  time: 0.5909  data_time: 0.3198  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:13:05 d2.utils.events]: \u001b[0m eta: 0:42:41  iter: 2519  total_loss: 1.509  loss_cls: 0.3241  loss_box_reg: 0.5528  loss_mask: 0.2953  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.2072  time: 0.5901  data_time: 0.1736  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:13:17 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 2539  total_loss: 1.359  loss_cls: 0.2877  loss_box_reg: 0.4842  loss_mask: 0.2954  loss_rpn_cls: 0.06356  loss_rpn_loc: 0.1965  time: 0.5899  data_time: 0.2678  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:13:29 d2.utils.events]: \u001b[0m eta: 0:42:22  iter: 2559  total_loss: 1.479  loss_cls: 0.3599  loss_box_reg: 0.5272  loss_mask: 0.3072  loss_rpn_cls: 0.08948  loss_rpn_loc: 0.2072  time: 0.5902  data_time: 0.3023  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:13:40 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 2579  total_loss: 1.51  loss_cls: 0.341  loss_box_reg: 0.5393  loss_mask: 0.3154  loss_rpn_cls: 0.07457  loss_rpn_loc: 0.2059  time: 0.5898  data_time: 0.2157  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:13:50 d2.utils.events]: \u001b[0m eta: 0:41:53  iter: 2599  total_loss: 1.499  loss_cls: 0.3504  loss_box_reg: 0.5399  loss_mask: 0.3169  loss_rpn_cls: 0.08226  loss_rpn_loc: 0.2079  time: 0.5893  data_time: 0.2124  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:14:03 d2.utils.events]: \u001b[0m eta: 0:41:57  iter: 2619  total_loss: 1.36  loss_cls: 0.3034  loss_box_reg: 0.492  loss_mask: 0.2973  loss_rpn_cls: 0.08947  loss_rpn_loc: 0.1996  time: 0.5897  data_time: 0.3194  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:14:16 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 2639  total_loss: 1.42  loss_cls: 0.3236  loss_box_reg: 0.4869  loss_mask: 0.2806  loss_rpn_cls: 0.08639  loss_rpn_loc: 0.1958  time: 0.5900  data_time: 0.2875  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:14:26 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 2659  total_loss: 1.471  loss_cls: 0.3731  loss_box_reg: 0.5318  loss_mask: 0.2993  loss_rpn_cls: 0.08555  loss_rpn_loc: 0.1987  time: 0.5894  data_time: 0.1879  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:14:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:14:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:14:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:14:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:14:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:14:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0748 s/iter. Eval: 0.0431 s/iter. Total: 0.1186 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/01 22:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0767 s/iter. Eval: 0.0543 s/iter. Total: 0.1317 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:14:40 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0770 s/iter. Eval: 0.0566 s/iter. Total: 0.1344 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:14:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.437980 (0.133086 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:14:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076834 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:14:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:14:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2520911115327923\n",
      "\u001b[32m[02/01 22:14:52 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 2679  total_loss: 1.44  loss_cls: 0.3165  loss_box_reg: 0.5172  loss_mask: 0.2849  loss_rpn_cls: 0.08046  loss_rpn_loc: 0.1894  time: 0.5884  data_time: 0.1177  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:15:04 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 2699  total_loss: 1.424  loss_cls: 0.2865  loss_box_reg: 0.4785  loss_mask: 0.3017  loss_rpn_cls: 0.0712  loss_rpn_loc: 0.2011  time: 0.5886  data_time: 0.2850  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:15:17 d2.utils.events]: \u001b[0m eta: 0:41:29  iter: 2719  total_loss: 1.479  loss_cls: 0.3631  loss_box_reg: 0.5576  loss_mask: 0.2964  loss_rpn_cls: 0.09203  loss_rpn_loc: 0.1839  time: 0.5890  data_time: 0.2846  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:15:28 d2.utils.events]: \u001b[0m eta: 0:41:22  iter: 2739  total_loss: 1.474  loss_cls: 0.3407  loss_box_reg: 0.5133  loss_mask: 0.2996  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.2075  time: 0.5887  data_time: 0.2278  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:15:40 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 2759  total_loss: 1.399  loss_cls: 0.3361  loss_box_reg: 0.5019  loss_mask: 0.302  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.1819  time: 0.5889  data_time: 0.2573  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:15:53 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 2779  total_loss: 1.505  loss_cls: 0.32  loss_box_reg: 0.5395  loss_mask: 0.3093  loss_rpn_cls: 0.0847  loss_rpn_loc: 0.1891  time: 0.5890  data_time: 0.2849  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:16:04 d2.utils.events]: \u001b[0m eta: 0:41:03  iter: 2799  total_loss: 1.408  loss_cls: 0.3018  loss_box_reg: 0.4936  loss_mask: 0.2995  loss_rpn_cls: 0.06083  loss_rpn_loc: 0.1989  time: 0.5889  data_time: 0.2353  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:16:15 d2.utils.events]: \u001b[0m eta: 0:40:50  iter: 2819  total_loss: 1.467  loss_cls: 0.3076  loss_box_reg: 0.5284  loss_mask: 0.2969  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.2039  time: 0.5887  data_time: 0.2484  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:16:26 d2.utils.events]: \u001b[0m eta: 0:40:48  iter: 2839  total_loss: 1.417  loss_cls: 0.3152  loss_box_reg: 0.522  loss_mask: 0.3063  loss_rpn_cls: 0.07033  loss_rpn_loc: 0.2  time: 0.5883  data_time: 0.1964  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:16:38 d2.utils.events]: \u001b[0m eta: 0:40:47  iter: 2859  total_loss: 1.497  loss_cls: 0.3828  loss_box_reg: 0.5105  loss_mask: 0.2971  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1912  time: 0.5883  data_time: 0.2397  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:16:48 d2.utils.events]: \u001b[0m eta: 0:40:30  iter: 2879  total_loss: 1.342  loss_cls: 0.2943  loss_box_reg: 0.4815  loss_mask: 0.2957  loss_rpn_cls: 0.05697  loss_rpn_loc: 0.1765  time: 0.5879  data_time: 0.2194  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:17:02 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 2899  total_loss: 1.605  loss_cls: 0.3846  loss_box_reg: 0.5185  loss_mask: 0.3012  loss_rpn_cls: 0.09504  loss_rpn_loc: 0.2189  time: 0.5887  data_time: 0.3594  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:17:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:17:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:17:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:17:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:17:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:17:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0744 s/iter. Eval: 0.0377 s/iter. Total: 0.1127 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0544 s/iter. Total: 0.1325 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0776 s/iter. Eval: 0.0568 s/iter. Total: 0.1352 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:17:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.430421 (0.133021 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:17:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077261 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:17:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:17:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25578513504740047\n",
      "\u001b[32m[02/01 22:17:31 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 2919  total_loss: 1.376  loss_cls: 0.2961  loss_box_reg: 0.5316  loss_mask: 0.2885  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.1866  time: 0.5885  data_time: 0.2172  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:17:44 d2.utils.events]: \u001b[0m eta: 0:40:11  iter: 2939  total_loss: 1.54  loss_cls: 0.3461  loss_box_reg: 0.5476  loss_mask: 0.3004  loss_rpn_cls: 0.0956  loss_rpn_loc: 0.2066  time: 0.5889  data_time: 0.3157  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:17:57 d2.utils.events]: \u001b[0m eta: 0:40:10  iter: 2959  total_loss: 1.595  loss_cls: 0.3555  loss_box_reg: 0.5439  loss_mask: 0.3242  loss_rpn_cls: 0.09272  loss_rpn_loc: 0.1942  time: 0.5894  data_time: 0.3104  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:18:11 d2.utils.events]: \u001b[0m eta: 0:40:10  iter: 2979  total_loss: 1.477  loss_cls: 0.3461  loss_box_reg: 0.5129  loss_mask: 0.3095  loss_rpn_cls: 0.09461  loss_rpn_loc: 0.1929  time: 0.5903  data_time: 0.3813  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:18:27 d2.utils.events]: \u001b[0m eta: 0:40:10  iter: 2999  total_loss: 1.416  loss_cls: 0.3233  loss_box_reg: 0.5213  loss_mask: 0.3144  loss_rpn_cls: 0.08789  loss_rpn_loc: 0.1944  time: 0.5917  data_time: 0.4475  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:18:37 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 3019  total_loss: 1.316  loss_cls: 0.246  loss_box_reg: 0.5171  loss_mask: 0.3046  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.1736  time: 0.5909  data_time: 0.1409  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:18:46 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 3039  total_loss: 1.357  loss_cls: 0.3133  loss_box_reg: 0.4923  loss_mask: 0.2876  loss_rpn_cls: 0.06693  loss_rpn_loc: 0.1806  time: 0.5901  data_time: 0.1375  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:18:57 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 3059  total_loss: 1.436  loss_cls: 0.3272  loss_box_reg: 0.5147  loss_mask: 0.2926  loss_rpn_cls: 0.09016  loss_rpn_loc: 0.2032  time: 0.5899  data_time: 0.2300  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:19:08 d2.utils.events]: \u001b[0m eta: 0:39:52  iter: 3079  total_loss: 1.476  loss_cls: 0.3382  loss_box_reg: 0.5333  loss_mask: 0.3026  loss_rpn_cls: 0.06446  loss_rpn_loc: 0.2047  time: 0.5896  data_time: 0.1996  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:19:21 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 3099  total_loss: 1.466  loss_cls: 0.3446  loss_box_reg: 0.5387  loss_mask: 0.3075  loss_rpn_cls: 0.07158  loss_rpn_loc: 0.1971  time: 0.5899  data_time: 0.2943  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:19:33 d2.utils.events]: \u001b[0m eta: 0:39:52  iter: 3119  total_loss: 1.457  loss_cls: 0.3299  loss_box_reg: 0.4878  loss_mask: 0.2928  loss_rpn_cls: 0.08034  loss_rpn_loc: 0.2131  time: 0.5901  data_time: 0.2905  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:19:44 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 3139  total_loss: 1.442  loss_cls: 0.3421  loss_box_reg: 0.5495  loss_mask: 0.2831  loss_rpn_cls: 0.06873  loss_rpn_loc: 0.1949  time: 0.5898  data_time: 0.2192  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:19:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:19:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:19:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:19:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:19:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:19:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0738 s/iter. Eval: 0.0353 s/iter. Total: 0.1097 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0769 s/iter. Eval: 0.0539 s/iter. Total: 0.1316 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0773 s/iter. Eval: 0.0568 s/iter. Total: 0.1349 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:20:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.429656 (0.133014 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:20:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077012 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:20:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:20:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25571038620608466\n",
      "\u001b[32m[02/01 22:20:13 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 3159  total_loss: 1.499  loss_cls: 0.3379  loss_box_reg: 0.5367  loss_mask: 0.3079  loss_rpn_cls: 0.09464  loss_rpn_loc: 0.1873  time: 0.5898  data_time: 0.2455  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:20:25 d2.utils.events]: \u001b[0m eta: 0:39:43  iter: 3179  total_loss: 1.434  loss_cls: 0.3362  loss_box_reg: 0.5068  loss_mask: 0.3017  loss_rpn_cls: 0.07817  loss_rpn_loc: 0.1994  time: 0.5898  data_time: 0.2507  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:20:38 d2.utils.events]: \u001b[0m eta: 0:39:41  iter: 3199  total_loss: 1.327  loss_cls: 0.2918  loss_box_reg: 0.5046  loss_mask: 0.309  loss_rpn_cls: 0.05391  loss_rpn_loc: 0.1891  time: 0.5903  data_time: 0.3218  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:20:49 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 3219  total_loss: 1.382  loss_cls: 0.3094  loss_box_reg: 0.515  loss_mask: 0.2964  loss_rpn_cls: 0.08246  loss_rpn_loc: 0.1795  time: 0.5900  data_time: 0.2224  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:21:03 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 3239  total_loss: 1.398  loss_cls: 0.3282  loss_box_reg: 0.4988  loss_mask: 0.2935  loss_rpn_cls: 0.09709  loss_rpn_loc: 0.2007  time: 0.5907  data_time: 0.3546  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:21:12 d2.utils.events]: \u001b[0m eta: 0:39:21  iter: 3259  total_loss: 1.441  loss_cls: 0.3166  loss_box_reg: 0.5387  loss_mask: 0.2878  loss_rpn_cls: 0.05557  loss_rpn_loc: 0.1913  time: 0.5899  data_time: 0.1462  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:21:26 d2.utils.events]: \u001b[0m eta: 0:39:14  iter: 3279  total_loss: 1.409  loss_cls: 0.3378  loss_box_reg: 0.5201  loss_mask: 0.2964  loss_rpn_cls: 0.09345  loss_rpn_loc: 0.189  time: 0.5905  data_time: 0.3498  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:21:37 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 3299  total_loss: 1.455  loss_cls: 0.3187  loss_box_reg: 0.5167  loss_mask: 0.3052  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2055  time: 0.5904  data_time: 0.2407  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:21:49 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 3319  total_loss: 1.49  loss_cls: 0.3622  loss_box_reg: 0.5261  loss_mask: 0.3005  loss_rpn_cls: 0.09438  loss_rpn_loc: 0.2057  time: 0.5902  data_time: 0.2198  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:21:58 d2.utils.events]: \u001b[0m eta: 0:38:53  iter: 3339  total_loss: 1.321  loss_cls: 0.2955  loss_box_reg: 0.5219  loss_mask: 0.2918  loss_rpn_cls: 0.05514  loss_rpn_loc: 0.1936  time: 0.5896  data_time: 0.1684  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:22:10 d2.utils.events]: \u001b[0m eta: 0:38:45  iter: 3359  total_loss: 1.378  loss_cls: 0.2993  loss_box_reg: 0.4947  loss_mask: 0.3022  loss_rpn_cls: 0.06636  loss_rpn_loc: 0.1986  time: 0.5896  data_time: 0.2513  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:22:22 d2.utils.events]: \u001b[0m eta: 0:38:41  iter: 3379  total_loss: 1.507  loss_cls: 0.3463  loss_box_reg: 0.5191  loss_mask: 0.3113  loss_rpn_cls: 0.1213  loss_rpn_loc: 0.2057  time: 0.5897  data_time: 0.2681  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:22:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:22:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:22:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:22:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:22:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:22:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0330 s/iter. Total: 0.1073 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0768 s/iter. Eval: 0.0484 s/iter. Total: 0.1260 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/01 22:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0507 s/iter. Total: 0.1284 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:22:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.687838 (0.126619 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:22:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076485 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:22:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:22:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25421897343995287\n",
      "\u001b[32m[02/01 22:22:52 d2.utils.events]: \u001b[0m eta: 0:38:38  iter: 3399  total_loss: 1.416  loss_cls: 0.312  loss_box_reg: 0.4963  loss_mask: 0.3081  loss_rpn_cls: 0.07466  loss_rpn_loc: 0.2092  time: 0.5902  data_time: 0.3384  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:23:05 d2.utils.events]: \u001b[0m eta: 0:38:27  iter: 3419  total_loss: 1.348  loss_cls: 0.3033  loss_box_reg: 0.5179  loss_mask: 0.305  loss_rpn_cls: 0.06201  loss_rpn_loc: 0.1909  time: 0.5905  data_time: 0.3110  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:23:15 d2.utils.events]: \u001b[0m eta: 0:38:18  iter: 3439  total_loss: 1.356  loss_cls: 0.3153  loss_box_reg: 0.5006  loss_mask: 0.2835  loss_rpn_cls: 0.06244  loss_rpn_loc: 0.1861  time: 0.5899  data_time: 0.1887  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:23:29 d2.utils.events]: \u001b[0m eta: 0:38:11  iter: 3459  total_loss: 1.352  loss_cls: 0.3179  loss_box_reg: 0.4729  loss_mask: 0.2915  loss_rpn_cls: 0.06713  loss_rpn_loc: 0.1796  time: 0.5906  data_time: 0.3877  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:23:42 d2.utils.events]: \u001b[0m eta: 0:38:01  iter: 3479  total_loss: 1.381  loss_cls: 0.3104  loss_box_reg: 0.5117  loss_mask: 0.297  loss_rpn_cls: 0.07624  loss_rpn_loc: 0.1913  time: 0.5909  data_time: 0.3119  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:23:56 d2.utils.events]: \u001b[0m eta: 0:37:57  iter: 3499  total_loss: 1.477  loss_cls: 0.3639  loss_box_reg: 0.5386  loss_mask: 0.3028  loss_rpn_cls: 0.09641  loss_rpn_loc: 0.2069  time: 0.5915  data_time: 0.3689  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:24:09 d2.utils.events]: \u001b[0m eta: 0:37:56  iter: 3519  total_loss: 1.57  loss_cls: 0.3584  loss_box_reg: 0.5499  loss_mask: 0.3083  loss_rpn_cls: 0.08306  loss_rpn_loc: 0.219  time: 0.5920  data_time: 0.3409  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:24:19 d2.utils.events]: \u001b[0m eta: 0:37:50  iter: 3539  total_loss: 1.379  loss_cls: 0.3175  loss_box_reg: 0.5237  loss_mask: 0.2948  loss_rpn_cls: 0.06087  loss_rpn_loc: 0.1803  time: 0.5914  data_time: 0.1624  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:24:33 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 3559  total_loss: 1.469  loss_cls: 0.3394  loss_box_reg: 0.5043  loss_mask: 0.2968  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.2274  time: 0.5919  data_time: 0.3379  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:24:48 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 3579  total_loss: 1.411  loss_cls: 0.3072  loss_box_reg: 0.4965  loss_mask: 0.2963  loss_rpn_cls: 0.083  loss_rpn_loc: 0.1842  time: 0.5929  data_time: 0.4262  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:24:57 d2.utils.events]: \u001b[0m eta: 0:37:40  iter: 3599  total_loss: 1.475  loss_cls: 0.3263  loss_box_reg: 0.4943  loss_mask: 0.2961  loss_rpn_cls: 0.08356  loss_rpn_loc: 0.1872  time: 0.5922  data_time: 0.1614  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:25:09 d2.utils.events]: \u001b[0m eta: 0:37:33  iter: 3619  total_loss: 1.392  loss_cls: 0.2812  loss_box_reg: 0.5309  loss_mask: 0.3065  loss_rpn_cls: 0.0813  loss_rpn_loc: 0.2004  time: 0.5923  data_time: 0.2788  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:25:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:25:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:25:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:25:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:25:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:25:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0720 s/iter. Eval: 0.0387 s/iter. Total: 0.1113 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0748 s/iter. Eval: 0.0538 s/iter. Total: 0.1295 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0768 s/iter. Eval: 0.0573 s/iter. Total: 0.1349 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:25:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.438012 (0.133086 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:25:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076711 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:25:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:25:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25965877480277605\n",
      "\u001b[32m[02/01 22:25:35 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 3639  total_loss: 1.445  loss_cls: 0.354  loss_box_reg: 0.523  loss_mask: 0.3054  loss_rpn_cls: 0.06757  loss_rpn_loc: 0.1974  time: 0.5913  data_time: 0.1123  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:25:47 d2.utils.events]: \u001b[0m eta: 0:37:13  iter: 3659  total_loss: 1.418  loss_cls: 0.3389  loss_box_reg: 0.5017  loss_mask: 0.3013  loss_rpn_cls: 0.07009  loss_rpn_loc: 0.199  time: 0.5914  data_time: 0.2708  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:26:02 d2.utils.events]: \u001b[0m eta: 0:37:12  iter: 3679  total_loss: 1.524  loss_cls: 0.3672  loss_box_reg: 0.5045  loss_mask: 0.3094  loss_rpn_cls: 0.09361  loss_rpn_loc: 0.2034  time: 0.5922  data_time: 0.3801  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:26:13 d2.utils.events]: \u001b[0m eta: 0:37:07  iter: 3699  total_loss: 1.601  loss_cls: 0.3947  loss_box_reg: 0.5298  loss_mask: 0.3016  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.2224  time: 0.5919  data_time: 0.2280  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:26:26 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 3719  total_loss: 1.43  loss_cls: 0.3251  loss_box_reg: 0.5179  loss_mask: 0.3182  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.1944  time: 0.5925  data_time: 0.3619  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:26:39 d2.utils.events]: \u001b[0m eta: 0:36:51  iter: 3739  total_loss: 1.429  loss_cls: 0.319  loss_box_reg: 0.5019  loss_mask: 0.3105  loss_rpn_cls: 0.09632  loss_rpn_loc: 0.2109  time: 0.5925  data_time: 0.2888  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:26:50 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 3759  total_loss: 1.516  loss_cls: 0.3441  loss_box_reg: 0.5317  loss_mask: 0.312  loss_rpn_cls: 0.05907  loss_rpn_loc: 0.1994  time: 0.5924  data_time: 0.2496  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:27:02 d2.utils.events]: \u001b[0m eta: 0:36:34  iter: 3779  total_loss: 1.401  loss_cls: 0.3624  loss_box_reg: 0.5001  loss_mask: 0.2842  loss_rpn_cls: 0.09492  loss_rpn_loc: 0.1953  time: 0.5924  data_time: 0.2590  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:27:12 d2.utils.events]: \u001b[0m eta: 0:36:23  iter: 3799  total_loss: 1.421  loss_cls: 0.3311  loss_box_reg: 0.5197  loss_mask: 0.2948  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.1829  time: 0.5920  data_time: 0.2087  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:27:23 d2.utils.events]: \u001b[0m eta: 0:36:16  iter: 3819  total_loss: 1.345  loss_cls: 0.315  loss_box_reg: 0.5031  loss_mask: 0.2894  loss_rpn_cls: 0.06097  loss_rpn_loc: 0.1783  time: 0.5917  data_time: 0.2190  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:27:33 d2.utils.events]: \u001b[0m eta: 0:36:03  iter: 3839  total_loss: 1.445  loss_cls: 0.2955  loss_box_reg: 0.5273  loss_mask: 0.3049  loss_rpn_cls: 0.05029  loss_rpn_loc: 0.1961  time: 0.5913  data_time: 0.2070  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:27:47 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 3859  total_loss: 1.436  loss_cls: 0.3129  loss_box_reg: 0.5496  loss_mask: 0.3027  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.2073  time: 0.5918  data_time: 0.3487  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:27:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:27:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:27:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:27:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:27:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:27:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0353 s/iter. Total: 0.1065 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0739 s/iter. Eval: 0.0553 s/iter. Total: 0.1300 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0746 s/iter. Eval: 0.0600 s/iter. Total: 0.1354 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:28:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.463481 (0.133306 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:28:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074308 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:28:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:28:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2578379788969259\n",
      "\u001b[32m[02/01 22:28:15 d2.utils.events]: \u001b[0m eta: 0:35:47  iter: 3879  total_loss: 1.413  loss_cls: 0.3279  loss_box_reg: 0.5184  loss_mask: 0.3026  loss_rpn_cls: 0.06063  loss_rpn_loc: 0.1848  time: 0.5917  data_time: 0.2595  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:28:27 d2.utils.events]: \u001b[0m eta: 0:35:38  iter: 3899  total_loss: 1.443  loss_cls: 0.3305  loss_box_reg: 0.4915  loss_mask: 0.2904  loss_rpn_cls: 0.06699  loss_rpn_loc: 0.1849  time: 0.5917  data_time: 0.2691  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:28:37 d2.utils.events]: \u001b[0m eta: 0:35:30  iter: 3919  total_loss: 1.424  loss_cls: 0.3317  loss_box_reg: 0.5119  loss_mask: 0.295  loss_rpn_cls: 0.07401  loss_rpn_loc: 0.1891  time: 0.5913  data_time: 0.1919  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:28:49 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 3939  total_loss: 1.371  loss_cls: 0.2985  loss_box_reg: 0.5182  loss_mask: 0.3118  loss_rpn_cls: 0.06857  loss_rpn_loc: 0.1985  time: 0.5912  data_time: 0.2348  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:29:00 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 3959  total_loss: 1.324  loss_cls: 0.3166  loss_box_reg: 0.5198  loss_mask: 0.2903  loss_rpn_cls: 0.05889  loss_rpn_loc: 0.1772  time: 0.5910  data_time: 0.2295  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:29:11 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 3979  total_loss: 1.425  loss_cls: 0.3153  loss_box_reg: 0.5212  loss_mask: 0.3043  loss_rpn_cls: 0.08666  loss_rpn_loc: 0.2037  time: 0.5909  data_time: 0.2606  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:29:22 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 3999  total_loss: 1.484  loss_cls: 0.3244  loss_box_reg: 0.5062  loss_mask: 0.3139  loss_rpn_cls: 0.08952  loss_rpn_loc: 0.2041  time: 0.5906  data_time: 0.2268  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:29:35 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 4019  total_loss: 1.428  loss_cls: 0.3482  loss_box_reg: 0.5156  loss_mask: 0.276  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1827  time: 0.5909  data_time: 0.3025  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:29:46 d2.utils.events]: \u001b[0m eta: 0:34:38  iter: 4039  total_loss: 1.392  loss_cls: 0.3188  loss_box_reg: 0.5009  loss_mask: 0.3055  loss_rpn_cls: 0.07833  loss_rpn_loc: 0.1876  time: 0.5907  data_time: 0.2232  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:29:58 d2.utils.events]: \u001b[0m eta: 0:34:30  iter: 4059  total_loss: 1.474  loss_cls: 0.336  loss_box_reg: 0.5345  loss_mask: 0.3232  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.2158  time: 0.5908  data_time: 0.2632  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:30:09 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 4079  total_loss: 1.399  loss_cls: 0.3283  loss_box_reg: 0.51  loss_mask: 0.2897  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.1916  time: 0.5907  data_time: 0.2522  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:30:23 d2.utils.events]: \u001b[0m eta: 0:34:16  iter: 4099  total_loss: 1.496  loss_cls: 0.3123  loss_box_reg: 0.5296  loss_mask: 0.3233  loss_rpn_cls: 0.07683  loss_rpn_loc: 0.2105  time: 0.5912  data_time: 0.3668  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:30:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:30:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:30:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:30:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:30:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:30:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0750 s/iter. Eval: 0.0358 s/iter. Total: 0.1114 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0007 s/iter. Inference: 0.0781 s/iter. Eval: 0.0563 s/iter. Total: 0.1352 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 22:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0590 s/iter. Total: 0.1375 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 22:30:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.537527 (0.133944 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:30:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076034 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:30:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:30:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2655605563352623\n",
      "\u001b[32m[02/01 22:30:51 d2.utils.events]: \u001b[0m eta: 0:34:09  iter: 4119  total_loss: 1.404  loss_cls: 0.312  loss_box_reg: 0.5188  loss_mask: 0.2998  loss_rpn_cls: 0.09856  loss_rpn_loc: 0.2141  time: 0.5909  data_time: 0.2191  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:31:05 d2.utils.events]: \u001b[0m eta: 0:34:04  iter: 4139  total_loss: 1.428  loss_cls: 0.3204  loss_box_reg: 0.5175  loss_mask: 0.3004  loss_rpn_cls: 0.06977  loss_rpn_loc: 0.193  time: 0.5915  data_time: 0.3731  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:31:20 d2.utils.events]: \u001b[0m eta: 0:33:56  iter: 4159  total_loss: 1.391  loss_cls: 0.3616  loss_box_reg: 0.4865  loss_mask: 0.2907  loss_rpn_cls: 0.0696  loss_rpn_loc: 0.2042  time: 0.5923  data_time: 0.4097  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:31:33 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 4179  total_loss: 1.411  loss_cls: 0.3194  loss_box_reg: 0.512  loss_mask: 0.3066  loss_rpn_cls: 0.07894  loss_rpn_loc: 0.2112  time: 0.5924  data_time: 0.2997  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:31:45 d2.utils.events]: \u001b[0m eta: 0:33:37  iter: 4199  total_loss: 1.371  loss_cls: 0.3169  loss_box_reg: 0.5085  loss_mask: 0.2791  loss_rpn_cls: 0.09182  loss_rpn_loc: 0.1708  time: 0.5924  data_time: 0.2692  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:31:57 d2.utils.events]: \u001b[0m eta: 0:33:29  iter: 4219  total_loss: 1.418  loss_cls: 0.3128  loss_box_reg: 0.4768  loss_mask: 0.2966  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.1804  time: 0.5926  data_time: 0.3103  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:32:11 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 4239  total_loss: 1.381  loss_cls: 0.3141  loss_box_reg: 0.5039  loss_mask: 0.3025  loss_rpn_cls: 0.08435  loss_rpn_loc: 0.2015  time: 0.5930  data_time: 0.3384  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:32:21 d2.utils.events]: \u001b[0m eta: 0:33:15  iter: 4259  total_loss: 1.377  loss_cls: 0.3096  loss_box_reg: 0.5292  loss_mask: 0.3033  loss_rpn_cls: 0.0666  loss_rpn_loc: 0.1904  time: 0.5926  data_time: 0.2042  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:32:33 d2.utils.events]: \u001b[0m eta: 0:33:04  iter: 4279  total_loss: 1.314  loss_cls: 0.2981  loss_box_reg: 0.4619  loss_mask: 0.2795  loss_rpn_cls: 0.06413  loss_rpn_loc: 0.1813  time: 0.5927  data_time: 0.2841  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:32:45 d2.utils.events]: \u001b[0m eta: 0:32:57  iter: 4299  total_loss: 1.517  loss_cls: 0.3591  loss_box_reg: 0.4917  loss_mask: 0.3069  loss_rpn_cls: 0.09121  loss_rpn_loc: 0.1901  time: 0.5927  data_time: 0.2780  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:32:54 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 4319  total_loss: 1.372  loss_cls: 0.3264  loss_box_reg: 0.5057  loss_mask: 0.291  loss_rpn_cls: 0.06255  loss_rpn_loc: 0.1756  time: 0.5919  data_time: 0.1038  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:33:08 d2.utils.events]: \u001b[0m eta: 0:32:42  iter: 4339  total_loss: 1.507  loss_cls: 0.3693  loss_box_reg: 0.485  loss_mask: 0.2921  loss_rpn_cls: 0.08916  loss_rpn_loc: 0.2012  time: 0.5925  data_time: 0.3890  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:33:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:33:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:33:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:33:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:33:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:33:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:33:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0357 s/iter. Total: 0.1072 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0556 s/iter. Total: 0.1304 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:33:30 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0747 s/iter. Eval: 0.0609 s/iter. Total: 0.1364 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:33:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.768726 (0.135937 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:33:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075257 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:33:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:33:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2648587419882272\n",
      "\u001b[32m[02/01 22:33:37 d2.utils.events]: \u001b[0m eta: 0:32:34  iter: 4359  total_loss: 1.478  loss_cls: 0.2999  loss_box_reg: 0.518  loss_mask: 0.3087  loss_rpn_cls: 0.08215  loss_rpn_loc: 0.2177  time: 0.5923  data_time: 0.2280  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:33:51 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 4379  total_loss: 1.465  loss_cls: 0.3366  loss_box_reg: 0.5125  loss_mask: 0.302  loss_rpn_cls: 0.07903  loss_rpn_loc: 0.2069  time: 0.5929  data_time: 0.3620  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:34:01 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 4399  total_loss: 1.447  loss_cls: 0.3331  loss_box_reg: 0.5625  loss_mask: 0.2963  loss_rpn_cls: 0.08513  loss_rpn_loc: 0.1952  time: 0.5926  data_time: 0.2038  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:34:17 d2.utils.events]: \u001b[0m eta: 0:32:13  iter: 4419  total_loss: 1.408  loss_cls: 0.3107  loss_box_reg: 0.4634  loss_mask: 0.297  loss_rpn_cls: 0.0864  loss_rpn_loc: 0.2102  time: 0.5933  data_time: 0.4308  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:34:26 d2.utils.events]: \u001b[0m eta: 0:32:06  iter: 4439  total_loss: 1.38  loss_cls: 0.315  loss_box_reg: 0.4982  loss_mask: 0.2872  loss_rpn_cls: 0.06433  loss_rpn_loc: 0.1873  time: 0.5928  data_time: 0.1698  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:34:35 d2.utils.events]: \u001b[0m eta: 0:31:54  iter: 4459  total_loss: 1.237  loss_cls: 0.2559  loss_box_reg: 0.4935  loss_mask: 0.2933  loss_rpn_cls: 0.0491  loss_rpn_loc: 0.1699  time: 0.5921  data_time: 0.1147  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:34:46 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 4479  total_loss: 1.494  loss_cls: 0.3519  loss_box_reg: 0.5589  loss_mask: 0.3053  loss_rpn_cls: 0.09573  loss_rpn_loc: 0.2013  time: 0.5920  data_time: 0.2443  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:34:58 d2.utils.events]: \u001b[0m eta: 0:31:41  iter: 4499  total_loss: 1.462  loss_cls: 0.3422  loss_box_reg: 0.5179  loss_mask: 0.2936  loss_rpn_cls: 0.09672  loss_rpn_loc: 0.2055  time: 0.5919  data_time: 0.2574  lr: 0.0005  max_mem: 6342M\n",
      "\u001b[32m[02/01 22:35:12 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 4519  total_loss: 1.4  loss_cls: 0.3251  loss_box_reg: 0.5222  loss_mask: 0.3115  loss_rpn_cls: 0.05607  loss_rpn_loc: 0.1868  time: 0.5924  data_time: 0.3695  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:35:23 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 4539  total_loss: 1.42  loss_cls: 0.3347  loss_box_reg: 0.5029  loss_mask: 0.2806  loss_rpn_cls: 0.06437  loss_rpn_loc: 0.1895  time: 0.5923  data_time: 0.2601  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:35:38 d2.utils.events]: \u001b[0m eta: 0:31:06  iter: 4559  total_loss: 1.32  loss_cls: 0.2785  loss_box_reg: 0.4748  loss_mask: 0.2995  loss_rpn_cls: 0.06339  loss_rpn_loc: 0.1881  time: 0.5930  data_time: 0.4100  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:35:49 d2.utils.events]: \u001b[0m eta: 0:30:56  iter: 4579  total_loss: 1.468  loss_cls: 0.3517  loss_box_reg: 0.5376  loss_mask: 0.302  loss_rpn_cls: 0.073  loss_rpn_loc: 0.2  time: 0.5928  data_time: 0.2250  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:36:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:36:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:36:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:36:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:36:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:36:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0705 s/iter. Eval: 0.0358 s/iter. Total: 0.1069 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0735 s/iter. Eval: 0.0538 s/iter. Total: 0.1281 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0735 s/iter. Eval: 0.0560 s/iter. Total: 0.1303 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:36:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.996021 (0.129276 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:36:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073626 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:36:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:36:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2641564905324911\n",
      "\u001b[32m[02/01 22:36:16 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 4599  total_loss: 1.398  loss_cls: 0.3188  loss_box_reg: 0.4959  loss_mask: 0.3026  loss_rpn_cls: 0.09787  loss_rpn_loc: 0.183  time: 0.5926  data_time: 0.2308  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:36:30 d2.utils.events]: \u001b[0m eta: 0:30:44  iter: 4619  total_loss: 1.505  loss_cls: 0.3248  loss_box_reg: 0.552  loss_mask: 0.3164  loss_rpn_cls: 0.08194  loss_rpn_loc: 0.2037  time: 0.5929  data_time: 0.3262  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:36:39 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 4639  total_loss: 1.519  loss_cls: 0.3439  loss_box_reg: 0.5612  loss_mask: 0.307  loss_rpn_cls: 0.06159  loss_rpn_loc: 0.2076  time: 0.5923  data_time: 0.1213  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:36:49 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 4659  total_loss: 1.401  loss_cls: 0.3246  loss_box_reg: 0.505  loss_mask: 0.3033  loss_rpn_cls: 0.08099  loss_rpn_loc: 0.1906  time: 0.5920  data_time: 0.2140  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:37:02 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 4679  total_loss: 1.49  loss_cls: 0.3598  loss_box_reg: 0.5164  loss_mask: 0.2984  loss_rpn_cls: 0.08786  loss_rpn_loc: 0.2148  time: 0.5922  data_time: 0.3217  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:37:11 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 4699  total_loss: 1.411  loss_cls: 0.302  loss_box_reg: 0.5527  loss_mask: 0.3127  loss_rpn_cls: 0.06071  loss_rpn_loc: 0.1962  time: 0.5916  data_time: 0.1351  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:37:24 d2.utils.events]: \u001b[0m eta: 0:30:06  iter: 4719  total_loss: 1.392  loss_cls: 0.2935  loss_box_reg: 0.5019  loss_mask: 0.3074  loss_rpn_cls: 0.07451  loss_rpn_loc: 0.1932  time: 0.5918  data_time: 0.3050  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:37:35 d2.utils.events]: \u001b[0m eta: 0:29:58  iter: 4739  total_loss: 1.425  loss_cls: 0.3381  loss_box_reg: 0.5306  loss_mask: 0.2994  loss_rpn_cls: 0.07946  loss_rpn_loc: 0.1856  time: 0.5916  data_time: 0.2423  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:37:47 d2.utils.events]: \u001b[0m eta: 0:29:53  iter: 4759  total_loss: 1.362  loss_cls: 0.2995  loss_box_reg: 0.4891  loss_mask: 0.3022  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.2022  time: 0.5918  data_time: 0.3039  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:38:00 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 4779  total_loss: 1.375  loss_cls: 0.2809  loss_box_reg: 0.4749  loss_mask: 0.2948  loss_rpn_cls: 0.08124  loss_rpn_loc: 0.1938  time: 0.5920  data_time: 0.3177  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:38:14 d2.utils.events]: \u001b[0m eta: 0:29:44  iter: 4799  total_loss: 1.432  loss_cls: 0.3228  loss_box_reg: 0.5211  loss_mask: 0.2904  loss_rpn_cls: 0.0867  loss_rpn_loc: 0.2027  time: 0.5924  data_time: 0.3536  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:38:27 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 4819  total_loss: 1.42  loss_cls: 0.319  loss_box_reg: 0.5178  loss_mask: 0.2938  loss_rpn_cls: 0.08606  loss_rpn_loc: 0.1954  time: 0.5926  data_time: 0.3191  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:38:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:38:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:38:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:38:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:38:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:38:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0388 s/iter. Total: 0.1139 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0754 s/iter. Eval: 0.0557 s/iter. Total: 0.1318 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0763 s/iter. Eval: 0.0601 s/iter. Total: 0.1371 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 22:38:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.690711 (0.135265 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:38:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075507 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:38:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:38:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2652781388279829\n",
      "\u001b[32m[02/01 22:38:55 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 4839  total_loss: 1.301  loss_cls: 0.3017  loss_box_reg: 0.5186  loss_mask: 0.2888  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.1943  time: 0.5925  data_time: 0.2324  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:39:05 d2.utils.events]: \u001b[0m eta: 0:29:34  iter: 4859  total_loss: 1.491  loss_cls: 0.3463  loss_box_reg: 0.5408  loss_mask: 0.3127  loss_rpn_cls: 0.076  loss_rpn_loc: 0.2083  time: 0.5921  data_time: 0.1675  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:39:15 d2.utils.events]: \u001b[0m eta: 0:29:25  iter: 4879  total_loss: 1.427  loss_cls: 0.3571  loss_box_reg: 0.5198  loss_mask: 0.2876  loss_rpn_cls: 0.07952  loss_rpn_loc: 0.1735  time: 0.5915  data_time: 0.1427  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:39:25 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 4899  total_loss: 1.393  loss_cls: 0.3213  loss_box_reg: 0.5  loss_mask: 0.2982  loss_rpn_cls: 0.08318  loss_rpn_loc: 0.2044  time: 0.5912  data_time: 0.1857  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:39:37 d2.utils.events]: \u001b[0m eta: 0:29:10  iter: 4919  total_loss: 1.304  loss_cls: 0.2733  loss_box_reg: 0.4871  loss_mask: 0.2863  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.1817  time: 0.5913  data_time: 0.2908  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:39:49 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 4939  total_loss: 1.433  loss_cls: 0.3384  loss_box_reg: 0.5181  loss_mask: 0.3083  loss_rpn_cls: 0.07581  loss_rpn_loc: 0.1961  time: 0.5914  data_time: 0.2874  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:40:01 d2.utils.events]: \u001b[0m eta: 0:29:02  iter: 4959  total_loss: 1.41  loss_cls: 0.333  loss_box_reg: 0.5056  loss_mask: 0.2911  loss_rpn_cls: 0.0788  loss_rpn_loc: 0.1861  time: 0.5914  data_time: 0.2641  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:40:14 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 4979  total_loss: 1.479  loss_cls: 0.3252  loss_box_reg: 0.4907  loss_mask: 0.3032  loss_rpn_cls: 0.07997  loss_rpn_loc: 0.2032  time: 0.5916  data_time: 0.3155  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:40:27 d2.utils.events]: \u001b[0m eta: 0:28:49  iter: 4999  total_loss: 1.412  loss_cls: 0.3174  loss_box_reg: 0.5198  loss_mask: 0.297  loss_rpn_cls: 0.09002  loss_rpn_loc: 0.1964  time: 0.5918  data_time: 0.3107  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:40:38 d2.utils.events]: \u001b[0m eta: 0:28:37  iter: 5019  total_loss: 1.347  loss_cls: 0.2996  loss_box_reg: 0.5165  loss_mask: 0.2989  loss_rpn_cls: 0.08022  loss_rpn_loc: 0.2013  time: 0.5917  data_time: 0.2355  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:40:50 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 5039  total_loss: 1.418  loss_cls: 0.3081  loss_box_reg: 0.5119  loss_mask: 0.315  loss_rpn_cls: 0.0699  loss_rpn_loc: 0.1978  time: 0.5918  data_time: 0.2761  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:41:03 d2.utils.events]: \u001b[0m eta: 0:28:19  iter: 5059  total_loss: 1.39  loss_cls: 0.2752  loss_box_reg: 0.521  loss_mask: 0.3141  loss_rpn_cls: 0.05535  loss_rpn_loc: 0.1999  time: 0.5919  data_time: 0.2858  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:41:15 d2.utils.events]: \u001b[0m eta: 0:28:10  iter: 5079  total_loss: 1.407  loss_cls: 0.3186  loss_box_reg: 0.5091  loss_mask: 0.293  loss_rpn_cls: 0.06915  loss_rpn_loc: 0.1875  time: 0.5920  data_time: 0.2819  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:41:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:41:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:41:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:41:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:41:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:41:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:41:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0765 s/iter. Eval: 0.0386 s/iter. Total: 0.1157 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.0786 s/iter. Eval: 0.0620 s/iter. Total: 0.1414 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 22:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.0787 s/iter. Eval: 0.0631 s/iter. Total: 0.1426 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 22:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0785 s/iter. Eval: 0.0605 s/iter. Total: 0.1398 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 22:41:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.322284 (0.140709 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:41:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078579 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:41:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:41:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2662164081001133\n",
      "\u001b[32m[02/01 22:41:42 d2.utils.events]: \u001b[0m eta: 0:28:03  iter: 5099  total_loss: 1.494  loss_cls: 0.3355  loss_box_reg: 0.5459  loss_mask: 0.3129  loss_rpn_cls: 0.06473  loss_rpn_loc: 0.1989  time: 0.5914  data_time: 0.1327  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:41:55 d2.utils.events]: \u001b[0m eta: 0:27:55  iter: 5119  total_loss: 1.416  loss_cls: 0.3069  loss_box_reg: 0.4959  loss_mask: 0.2737  loss_rpn_cls: 0.07224  loss_rpn_loc: 0.1881  time: 0.5916  data_time: 0.3070  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:42:06 d2.utils.events]: \u001b[0m eta: 0:27:48  iter: 5139  total_loss: 1.505  loss_cls: 0.352  loss_box_reg: 0.5005  loss_mask: 0.2993  loss_rpn_cls: 0.08335  loss_rpn_loc: 0.183  time: 0.5915  data_time: 0.2389  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:42:17 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 5159  total_loss: 1.415  loss_cls: 0.3459  loss_box_reg: 0.5217  loss_mask: 0.3042  loss_rpn_cls: 0.06481  loss_rpn_loc: 0.1981  time: 0.5913  data_time: 0.2081  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:42:31 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 5179  total_loss: 1.406  loss_cls: 0.3223  loss_box_reg: 0.5379  loss_mask: 0.3052  loss_rpn_cls: 0.07786  loss_rpn_loc: 0.2023  time: 0.5916  data_time: 0.3615  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:42:44 d2.utils.events]: \u001b[0m eta: 0:27:21  iter: 5199  total_loss: 1.446  loss_cls: 0.3445  loss_box_reg: 0.5217  loss_mask: 0.3119  loss_rpn_cls: 0.08449  loss_rpn_loc: 0.2128  time: 0.5919  data_time: 0.3176  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:42:56 d2.utils.events]: \u001b[0m eta: 0:27:13  iter: 5219  total_loss: 1.385  loss_cls: 0.3228  loss_box_reg: 0.4973  loss_mask: 0.2995  loss_rpn_cls: 0.07653  loss_rpn_loc: 0.1932  time: 0.5919  data_time: 0.2799  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:43:09 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 5239  total_loss: 1.504  loss_cls: 0.3572  loss_box_reg: 0.4951  loss_mask: 0.3013  loss_rpn_cls: 0.08403  loss_rpn_loc: 0.1884  time: 0.5921  data_time: 0.3176  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:43:20 d2.utils.events]: \u001b[0m eta: 0:27:05  iter: 5259  total_loss: 1.313  loss_cls: 0.2754  loss_box_reg: 0.4836  loss_mask: 0.2854  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1783  time: 0.5920  data_time: 0.2446  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:43:30 d2.utils.events]: \u001b[0m eta: 0:26:56  iter: 5279  total_loss: 1.309  loss_cls: 0.2625  loss_box_reg: 0.5147  loss_mask: 0.2822  loss_rpn_cls: 0.05936  loss_rpn_loc: 0.1758  time: 0.5916  data_time: 0.1826  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:43:43 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 5299  total_loss: 1.404  loss_cls: 0.2833  loss_box_reg: 0.5156  loss_mask: 0.307  loss_rpn_cls: 0.06176  loss_rpn_loc: 0.1983  time: 0.5920  data_time: 0.3534  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:43:53 d2.utils.events]: \u001b[0m eta: 0:26:44  iter: 5319  total_loss: 1.332  loss_cls: 0.2793  loss_box_reg: 0.5096  loss_mask: 0.2884  loss_rpn_cls: 0.06457  loss_rpn_loc: 0.1734  time: 0.5915  data_time: 0.1443  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:43:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:43:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:43:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:43:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:43:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:43:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0357 s/iter. Total: 0.1066 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0735 s/iter. Eval: 0.0557 s/iter. Total: 0.1300 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0742 s/iter. Eval: 0.0607 s/iter. Total: 0.1357 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:44:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.488633 (0.133523 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:44:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073843 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:44:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:44:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2623845838444956\n",
      "\u001b[32m[02/01 22:44:22 d2.utils.events]: \u001b[0m eta: 0:26:32  iter: 5339  total_loss: 1.353  loss_cls: 0.3404  loss_box_reg: 0.4787  loss_mask: 0.2724  loss_rpn_cls: 0.06857  loss_rpn_loc: 0.1977  time: 0.5915  data_time: 0.2628  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:44:34 d2.utils.events]: \u001b[0m eta: 0:26:28  iter: 5359  total_loss: 1.496  loss_cls: 0.3535  loss_box_reg: 0.5153  loss_mask: 0.2904  loss_rpn_cls: 0.09625  loss_rpn_loc: 0.2052  time: 0.5917  data_time: 0.3037  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:44:47 d2.utils.events]: \u001b[0m eta: 0:26:21  iter: 5379  total_loss: 1.455  loss_cls: 0.3234  loss_box_reg: 0.5119  loss_mask: 0.3069  loss_rpn_cls: 0.07529  loss_rpn_loc: 0.212  time: 0.5917  data_time: 0.2800  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:44:56 d2.utils.events]: \u001b[0m eta: 0:26:11  iter: 5399  total_loss: 1.34  loss_cls: 0.3045  loss_box_reg: 0.5017  loss_mask: 0.3019  loss_rpn_cls: 0.04854  loss_rpn_loc: 0.1691  time: 0.5912  data_time: 0.1439  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:45:04 d2.utils.events]: \u001b[0m eta: 0:26:01  iter: 5419  total_loss: 1.344  loss_cls: 0.3086  loss_box_reg: 0.5119  loss_mask: 0.2793  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.1838  time: 0.5906  data_time: 0.1130  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:45:16 d2.utils.events]: \u001b[0m eta: 0:25:55  iter: 5439  total_loss: 1.485  loss_cls: 0.3389  loss_box_reg: 0.5147  loss_mask: 0.2885  loss_rpn_cls: 0.09701  loss_rpn_loc: 0.1988  time: 0.5906  data_time: 0.2530  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:45:29 d2.utils.events]: \u001b[0m eta: 0:25:50  iter: 5459  total_loss: 1.403  loss_cls: 0.3226  loss_box_reg: 0.5391  loss_mask: 0.2999  loss_rpn_cls: 0.08003  loss_rpn_loc: 0.1846  time: 0.5908  data_time: 0.3227  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:45:45 d2.utils.events]: \u001b[0m eta: 0:25:43  iter: 5479  total_loss: 1.429  loss_cls: 0.3348  loss_box_reg: 0.506  loss_mask: 0.3067  loss_rpn_cls: 0.08931  loss_rpn_loc: 0.196  time: 0.5915  data_time: 0.4490  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:45:57 d2.utils.events]: \u001b[0m eta: 0:25:35  iter: 5499  total_loss: 1.417  loss_cls: 0.3167  loss_box_reg: 0.4729  loss_mask: 0.2908  loss_rpn_cls: 0.09368  loss_rpn_loc: 0.1991  time: 0.5917  data_time: 0.3022  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:46:08 d2.utils.events]: \u001b[0m eta: 0:25:30  iter: 5519  total_loss: 1.434  loss_cls: 0.3192  loss_box_reg: 0.5354  loss_mask: 0.2964  loss_rpn_cls: 0.09451  loss_rpn_loc: 0.1906  time: 0.5915  data_time: 0.2298  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:46:17 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 5539  total_loss: 1.33  loss_cls: 0.2685  loss_box_reg: 0.5156  loss_mask: 0.2882  loss_rpn_cls: 0.04598  loss_rpn_loc: 0.1786  time: 0.5909  data_time: 0.1054  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:46:34 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 5559  total_loss: 1.379  loss_cls: 0.296  loss_box_reg: 0.4376  loss_mask: 0.2884  loss_rpn_cls: 0.08413  loss_rpn_loc: 0.1971  time: 0.5919  data_time: 0.5093  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:46:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:46:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:46:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:46:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:46:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:46:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0362 s/iter. Total: 0.1079 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0751 s/iter. Eval: 0.0578 s/iter. Total: 0.1337 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0643 s/iter. Total: 0.1411 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 22:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0761 s/iter. Eval: 0.0615 s/iter. Total: 0.1385 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 22:46:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.164455 (0.139349 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:46:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076155 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:46:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:46:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2704440044671976\n",
      "\u001b[32m[02/01 22:47:03 d2.utils.events]: \u001b[0m eta: 0:25:08  iter: 5579  total_loss: 1.371  loss_cls: 0.3249  loss_box_reg: 0.4882  loss_mask: 0.2983  loss_rpn_cls: 0.06888  loss_rpn_loc: 0.1823  time: 0.5917  data_time: 0.2206  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:47:13 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 5599  total_loss: 1.266  loss_cls: 0.2704  loss_box_reg: 0.4961  loss_mask: 0.2856  loss_rpn_cls: 0.04907  loss_rpn_loc: 0.1741  time: 0.5914  data_time: 0.1793  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:47:25 d2.utils.events]: \u001b[0m eta: 0:24:54  iter: 5619  total_loss: 1.374  loss_cls: 0.319  loss_box_reg: 0.491  loss_mask: 0.2884  loss_rpn_cls: 0.08465  loss_rpn_loc: 0.1972  time: 0.5915  data_time: 0.2900  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:47:34 d2.utils.events]: \u001b[0m eta: 0:24:46  iter: 5639  total_loss: 1.385  loss_cls: 0.3112  loss_box_reg: 0.4996  loss_mask: 0.2988  loss_rpn_cls: 0.07185  loss_rpn_loc: 0.1906  time: 0.5910  data_time: 0.1409  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:47:48 d2.utils.events]: \u001b[0m eta: 0:24:42  iter: 5659  total_loss: 1.512  loss_cls: 0.3516  loss_box_reg: 0.5086  loss_mask: 0.309  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.1974  time: 0.5914  data_time: 0.3744  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:48:01 d2.utils.events]: \u001b[0m eta: 0:24:35  iter: 5679  total_loss: 1.37  loss_cls: 0.3108  loss_box_reg: 0.4745  loss_mask: 0.3022  loss_rpn_cls: 0.07507  loss_rpn_loc: 0.1887  time: 0.5916  data_time: 0.3247  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:48:12 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 5699  total_loss: 1.268  loss_cls: 0.3001  loss_box_reg: 0.4784  loss_mask: 0.3  loss_rpn_cls: 0.0457  loss_rpn_loc: 0.1659  time: 0.5915  data_time: 0.2280  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:48:25 d2.utils.events]: \u001b[0m eta: 0:24:24  iter: 5719  total_loss: 1.322  loss_cls: 0.2935  loss_box_reg: 0.4856  loss_mask: 0.2905  loss_rpn_cls: 0.0679  loss_rpn_loc: 0.1847  time: 0.5916  data_time: 0.3017  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:48:36 d2.utils.events]: \u001b[0m eta: 0:24:16  iter: 5739  total_loss: 1.412  loss_cls: 0.3217  loss_box_reg: 0.5099  loss_mask: 0.3129  loss_rpn_cls: 0.09894  loss_rpn_loc: 0.191  time: 0.5915  data_time: 0.2286  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:48:45 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 5759  total_loss: 1.419  loss_cls: 0.2943  loss_box_reg: 0.4838  loss_mask: 0.2989  loss_rpn_cls: 0.06805  loss_rpn_loc: 0.1964  time: 0.5910  data_time: 0.1622  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:48:59 d2.utils.events]: \u001b[0m eta: 0:24:01  iter: 5779  total_loss: 1.497  loss_cls: 0.3425  loss_box_reg: 0.4936  loss_mask: 0.3199  loss_rpn_cls: 0.07531  loss_rpn_loc: 0.2197  time: 0.5914  data_time: 0.3572  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:49:11 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 5799  total_loss: 1.407  loss_cls: 0.3218  loss_box_reg: 0.4865  loss_mask: 0.292  loss_rpn_cls: 0.08387  loss_rpn_loc: 0.1836  time: 0.5913  data_time: 0.2446  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:49:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:49:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:49:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:49:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:49:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:49:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0735 s/iter. Eval: 0.0364 s/iter. Total: 0.1105 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0756 s/iter. Eval: 0.0555 s/iter. Total: 0.1319 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:49:29 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0755 s/iter. Eval: 0.0582 s/iter. Total: 0.1346 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:49:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.302610 (0.131919 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:49:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074554 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:49:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:49:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25850522534151094\n",
      "\u001b[32m[02/01 22:49:39 d2.utils.events]: \u001b[0m eta: 0:23:46  iter: 5819  total_loss: 1.383  loss_cls: 0.3121  loss_box_reg: 0.5134  loss_mask: 0.2936  loss_rpn_cls: 0.07522  loss_rpn_loc: 0.1804  time: 0.5912  data_time: 0.2351  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:49:52 d2.utils.events]: \u001b[0m eta: 0:23:41  iter: 5839  total_loss: 1.541  loss_cls: 0.3919  loss_box_reg: 0.5015  loss_mask: 0.2912  loss_rpn_cls: 0.115  loss_rpn_loc: 0.2059  time: 0.5915  data_time: 0.3506  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:50:03 d2.utils.events]: \u001b[0m eta: 0:23:34  iter: 5859  total_loss: 1.462  loss_cls: 0.3572  loss_box_reg: 0.506  loss_mask: 0.3006  loss_rpn_cls: 0.07441  loss_rpn_loc: 0.2026  time: 0.5913  data_time: 0.2152  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:50:16 d2.utils.events]: \u001b[0m eta: 0:23:28  iter: 5879  total_loss: 1.427  loss_cls: 0.3391  loss_box_reg: 0.4849  loss_mask: 0.2864  loss_rpn_cls: 0.09622  loss_rpn_loc: 0.1951  time: 0.5915  data_time: 0.3334  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:50:29 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 5899  total_loss: 1.324  loss_cls: 0.283  loss_box_reg: 0.5283  loss_mask: 0.2992  loss_rpn_cls: 0.06459  loss_rpn_loc: 0.1997  time: 0.5917  data_time: 0.3141  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:50:44 d2.utils.events]: \u001b[0m eta: 0:23:18  iter: 5919  total_loss: 1.36  loss_cls: 0.313  loss_box_reg: 0.4667  loss_mask: 0.2919  loss_rpn_cls: 0.08469  loss_rpn_loc: 0.2001  time: 0.5923  data_time: 0.4458  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:50:56 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 5939  total_loss: 1.452  loss_cls: 0.3143  loss_box_reg: 0.5249  loss_mask: 0.3148  loss_rpn_cls: 0.07952  loss_rpn_loc: 0.1951  time: 0.5922  data_time: 0.2429  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:51:06 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 5959  total_loss: 1.329  loss_cls: 0.3125  loss_box_reg: 0.4954  loss_mask: 0.2992  loss_rpn_cls: 0.06368  loss_rpn_loc: 0.1706  time: 0.5920  data_time: 0.2013  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:51:19 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 5979  total_loss: 1.45  loss_cls: 0.3112  loss_box_reg: 0.5104  loss_mask: 0.2989  loss_rpn_cls: 0.09561  loss_rpn_loc: 0.2062  time: 0.5921  data_time: 0.2933  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:51:31 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 5999  total_loss: 1.383  loss_cls: 0.3051  loss_box_reg: 0.5192  loss_mask: 0.3079  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.2064  time: 0.5921  data_time: 0.2574  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:51:39 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 6019  total_loss: 1.352  loss_cls: 0.31  loss_box_reg: 0.4961  loss_mask: 0.277  loss_rpn_cls: 0.0446  loss_rpn_loc: 0.1757  time: 0.5916  data_time: 0.1132  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:51:51 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 6039  total_loss: 1.404  loss_cls: 0.3125  loss_box_reg: 0.494  loss_mask: 0.3021  loss_rpn_cls: 0.08149  loss_rpn_loc: 0.1957  time: 0.5916  data_time: 0.2825  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:51:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:51:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:51:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:51:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:51:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:51:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0713 s/iter. Eval: 0.0348 s/iter. Total: 0.1067 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 22:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0752 s/iter. Eval: 0.0532 s/iter. Total: 0.1291 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0565 s/iter. Total: 0.1323 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 22:52:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.123252 (0.130373 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:52:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074506 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:52:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:52:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2666749925707959\n",
      "\u001b[32m[02/01 22:52:18 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 6059  total_loss: 1.332  loss_cls: 0.2994  loss_box_reg: 0.5141  loss_mask: 0.2887  loss_rpn_cls: 0.05211  loss_rpn_loc: 0.1711  time: 0.5913  data_time: 0.1771  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:52:28 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 6079  total_loss: 1.294  loss_cls: 0.2821  loss_box_reg: 0.4721  loss_mask: 0.2967  loss_rpn_cls: 0.07445  loss_rpn_loc: 0.1744  time: 0.5910  data_time: 0.1945  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:52:39 d2.utils.events]: \u001b[0m eta: 0:22:09  iter: 6099  total_loss: 1.392  loss_cls: 0.3104  loss_box_reg: 0.5231  loss_mask: 0.3128  loss_rpn_cls: 0.07062  loss_rpn_loc: 0.2013  time: 0.5908  data_time: 0.2146  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:52:51 d2.utils.events]: \u001b[0m eta: 0:22:02  iter: 6119  total_loss: 1.5  loss_cls: 0.3497  loss_box_reg: 0.5107  loss_mask: 0.2916  loss_rpn_cls: 0.09644  loss_rpn_loc: 0.2042  time: 0.5909  data_time: 0.2772  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:53:03 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 6139  total_loss: 1.351  loss_cls: 0.3161  loss_box_reg: 0.4922  loss_mask: 0.2881  loss_rpn_cls: 0.07316  loss_rpn_loc: 0.192  time: 0.5909  data_time: 0.2733  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:53:13 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 6159  total_loss: 1.463  loss_cls: 0.324  loss_box_reg: 0.5426  loss_mask: 0.3074  loss_rpn_cls: 0.0762  loss_rpn_loc: 0.191  time: 0.5907  data_time: 0.1964  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:53:25 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 6179  total_loss: 1.457  loss_cls: 0.3379  loss_box_reg: 0.5212  loss_mask: 0.2965  loss_rpn_cls: 0.07087  loss_rpn_loc: 0.1896  time: 0.5907  data_time: 0.2514  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:53:39 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 6199  total_loss: 1.41  loss_cls: 0.3239  loss_box_reg: 0.4743  loss_mask: 0.2892  loss_rpn_cls: 0.07832  loss_rpn_loc: 0.2038  time: 0.5910  data_time: 0.3590  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:53:50 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 6219  total_loss: 1.345  loss_cls: 0.2898  loss_box_reg: 0.4933  loss_mask: 0.3089  loss_rpn_cls: 0.08347  loss_rpn_loc: 0.1885  time: 0.5908  data_time: 0.2099  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:53:59 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 6239  total_loss: 1.331  loss_cls: 0.2923  loss_box_reg: 0.4815  loss_mask: 0.2912  loss_rpn_cls: 0.07432  loss_rpn_loc: 0.1967  time: 0.5905  data_time: 0.1644  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:54:13 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 6259  total_loss: 1.413  loss_cls: 0.3472  loss_box_reg: 0.5071  loss_mask: 0.2965  loss_rpn_cls: 0.08135  loss_rpn_loc: 0.1921  time: 0.5908  data_time: 0.3488  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:54:23 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 6279  total_loss: 1.276  loss_cls: 0.2697  loss_box_reg: 0.494  loss_mask: 0.2745  loss_rpn_cls: 0.05836  loss_rpn_loc: 0.1667  time: 0.5904  data_time: 0.1508  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:54:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:54:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:54:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:54:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:54:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:54:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0712 s/iter. Eval: 0.0373 s/iter. Total: 0.1091 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0744 s/iter. Eval: 0.0580 s/iter. Total: 0.1331 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0759 s/iter. Eval: 0.0619 s/iter. Total: 0.1386 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 22:54:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.725635 (0.135566 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:54:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075015 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:54:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:54:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2650440980929615\n",
      "\u001b[32m[02/01 22:54:50 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 6299  total_loss: 1.415  loss_cls: 0.3277  loss_box_reg: 0.5077  loss_mask: 0.3032  loss_rpn_cls: 0.0679  loss_rpn_loc: 0.178  time: 0.5902  data_time: 0.2009  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:55:03 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 6319  total_loss: 1.271  loss_cls: 0.2801  loss_box_reg: 0.4833  loss_mask: 0.2796  loss_rpn_cls: 0.06937  loss_rpn_loc: 0.177  time: 0.5904  data_time: 0.3235  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:55:15 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 6339  total_loss: 1.371  loss_cls: 0.3197  loss_box_reg: 0.5173  loss_mask: 0.2828  loss_rpn_cls: 0.0783  loss_rpn_loc: 0.1884  time: 0.5904  data_time: 0.2709  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:55:28 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 6359  total_loss: 1.364  loss_cls: 0.2963  loss_box_reg: 0.4835  loss_mask: 0.2996  loss_rpn_cls: 0.06395  loss_rpn_loc: 0.1942  time: 0.5905  data_time: 0.3034  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:55:44 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 6379  total_loss: 1.425  loss_cls: 0.3445  loss_box_reg: 0.4977  loss_mask: 0.3116  loss_rpn_cls: 0.07765  loss_rpn_loc: 0.202  time: 0.5912  data_time: 0.4613  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:55:58 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 6399  total_loss: 1.418  loss_cls: 0.3378  loss_box_reg: 0.5127  loss_mask: 0.3134  loss_rpn_cls: 0.08836  loss_rpn_loc: 0.2001  time: 0.5915  data_time: 0.3643  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:56:11 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 6419  total_loss: 1.392  loss_cls: 0.301  loss_box_reg: 0.4819  loss_mask: 0.2873  loss_rpn_cls: 0.08192  loss_rpn_loc: 0.2018  time: 0.5917  data_time: 0.3178  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:56:20 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 6439  total_loss: 1.339  loss_cls: 0.3148  loss_box_reg: 0.4932  loss_mask: 0.2794  loss_rpn_cls: 0.05168  loss_rpn_loc: 0.18  time: 0.5912  data_time: 0.1161  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:56:32 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 6459  total_loss: 1.38  loss_cls: 0.297  loss_box_reg: 0.4749  loss_mask: 0.2998  loss_rpn_cls: 0.07827  loss_rpn_loc: 0.2019  time: 0.5913  data_time: 0.2821  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:56:44 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 6479  total_loss: 1.375  loss_cls: 0.3266  loss_box_reg: 0.5059  loss_mask: 0.2849  loss_rpn_cls: 0.06407  loss_rpn_loc: 0.1849  time: 0.5914  data_time: 0.3060  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:56:58 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 6499  total_loss: 1.384  loss_cls: 0.3308  loss_box_reg: 0.4614  loss_mask: 0.2915  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1942  time: 0.5916  data_time: 0.3365  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:57:07 d2.utils.events]: \u001b[0m eta: 0:19:59  iter: 6519  total_loss: 1.319  loss_cls: 0.2836  loss_box_reg: 0.4792  loss_mask: 0.3105  loss_rpn_cls: 0.05028  loss_rpn_loc: 0.1818  time: 0.5913  data_time: 0.1766  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:57:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:57:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:57:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:57:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:57:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:57:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0414 s/iter. Total: 0.1130 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 22:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0752 s/iter. Eval: 0.0587 s/iter. Total: 0.1346 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 22:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0643 s/iter. Total: 0.1411 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 22:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0763 s/iter. Eval: 0.0621 s/iter. Total: 0.1392 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 22:57:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.226974 (0.139888 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:57:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076286 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 22:57:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 22:57:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2646840111040122\n",
      "\u001b[32m[02/01 22:57:35 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 6539  total_loss: 1.486  loss_cls: 0.3474  loss_box_reg: 0.5423  loss_mask: 0.2969  loss_rpn_cls: 0.07256  loss_rpn_loc: 0.1858  time: 0.5909  data_time: 0.1595  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:57:48 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 6559  total_loss: 1.344  loss_cls: 0.3103  loss_box_reg: 0.4889  loss_mask: 0.3027  loss_rpn_cls: 0.07297  loss_rpn_loc: 0.1982  time: 0.5912  data_time: 0.3488  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:58:00 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 6579  total_loss: 1.385  loss_cls: 0.3175  loss_box_reg: 0.5061  loss_mask: 0.3146  loss_rpn_cls: 0.08492  loss_rpn_loc: 0.2143  time: 0.5912  data_time: 0.2858  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:58:14 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 6599  total_loss: 1.381  loss_cls: 0.2924  loss_box_reg: 0.4835  loss_mask: 0.2931  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.2051  time: 0.5915  data_time: 0.3488  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:58:23 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 6619  total_loss: 1.373  loss_cls: 0.3083  loss_box_reg: 0.5074  loss_mask: 0.3017  loss_rpn_cls: 0.05779  loss_rpn_loc: 0.1726  time: 0.5911  data_time: 0.1329  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:58:35 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 6639  total_loss: 1.492  loss_cls: 0.3647  loss_box_reg: 0.5166  loss_mask: 0.3174  loss_rpn_cls: 0.08014  loss_rpn_loc: 0.2009  time: 0.5911  data_time: 0.2644  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:58:46 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 6659  total_loss: 1.387  loss_cls: 0.3184  loss_box_reg: 0.5281  loss_mask: 0.3088  loss_rpn_cls: 0.06827  loss_rpn_loc: 0.2002  time: 0.5910  data_time: 0.2508  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:58:59 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 6679  total_loss: 1.351  loss_cls: 0.3516  loss_box_reg: 0.4973  loss_mask: 0.2854  loss_rpn_cls: 0.07212  loss_rpn_loc: 0.1859  time: 0.5912  data_time: 0.3098  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:59:10 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 6699  total_loss: 1.41  loss_cls: 0.3269  loss_box_reg: 0.5328  loss_mask: 0.2878  loss_rpn_cls: 0.07231  loss_rpn_loc: 0.1951  time: 0.5910  data_time: 0.2301  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:59:25 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 6719  total_loss: 1.456  loss_cls: 0.3499  loss_box_reg: 0.4661  loss_mask: 0.3046  loss_rpn_cls: 0.09046  loss_rpn_loc: 0.2138  time: 0.5915  data_time: 0.3940  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:59:38 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 6739  total_loss: 1.377  loss_cls: 0.2928  loss_box_reg: 0.4891  loss_mask: 0.3016  loss_rpn_cls: 0.06687  loss_rpn_loc: 0.2025  time: 0.5917  data_time: 0.3382  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:59:47 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 6759  total_loss: 1.368  loss_cls: 0.2743  loss_box_reg: 0.5286  loss_mask: 0.3082  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.1734  time: 0.5913  data_time: 0.1392  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 22:59:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:59:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 22:59:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 22:59:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 22:59:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 22:59:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 22:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0712 s/iter. Eval: 0.0384 s/iter. Total: 0.1103 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 23:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0757 s/iter. Eval: 0.0581 s/iter. Total: 0.1346 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0754 s/iter. Eval: 0.0607 s/iter. Total: 0.1370 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 23:00:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.649856 (0.134913 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:00:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075201 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:00:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:00:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2618651765716242\n",
      "\u001b[32m[02/01 23:00:14 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 6779  total_loss: 1.288  loss_cls: 0.2819  loss_box_reg: 0.4779  loss_mask: 0.2782  loss_rpn_cls: 0.05622  loss_rpn_loc: 0.161  time: 0.5909  data_time: 0.1467  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:00:23 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 6799  total_loss: 1.381  loss_cls: 0.3174  loss_box_reg: 0.5516  loss_mask: 0.2987  loss_rpn_cls: 0.06522  loss_rpn_loc: 0.1809  time: 0.5905  data_time: 0.1272  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:00:33 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 6819  total_loss: 1.226  loss_cls: 0.2656  loss_box_reg: 0.473  loss_mask: 0.2837  loss_rpn_cls: 0.05832  loss_rpn_loc: 0.1657  time: 0.5903  data_time: 0.2085  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:00:46 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 6839  total_loss: 1.358  loss_cls: 0.2943  loss_box_reg: 0.5082  loss_mask: 0.3097  loss_rpn_cls: 0.05606  loss_rpn_loc: 0.1816  time: 0.5904  data_time: 0.2953  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:00:57 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 6859  total_loss: 1.446  loss_cls: 0.3348  loss_box_reg: 0.5117  loss_mask: 0.3125  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.213  time: 0.5903  data_time: 0.2691  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:01:11 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 6879  total_loss: 1.43  loss_cls: 0.3405  loss_box_reg: 0.4895  loss_mask: 0.3028  loss_rpn_cls: 0.09714  loss_rpn_loc: 0.2045  time: 0.5906  data_time: 0.3580  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:01:26 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 6899  total_loss: 1.297  loss_cls: 0.2978  loss_box_reg: 0.4604  loss_mask: 0.2904  loss_rpn_cls: 0.0572  loss_rpn_loc: 0.1912  time: 0.5911  data_time: 0.4026  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:01:38 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 6919  total_loss: 1.405  loss_cls: 0.2786  loss_box_reg: 0.5182  loss_mask: 0.2984  loss_rpn_cls: 0.09491  loss_rpn_loc: 0.1952  time: 0.5911  data_time: 0.2776  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:01:48 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 6939  total_loss: 1.351  loss_cls: 0.2969  loss_box_reg: 0.5086  loss_mask: 0.2969  loss_rpn_cls: 0.05837  loss_rpn_loc: 0.1731  time: 0.5908  data_time: 0.1674  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:02:02 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 6959  total_loss: 1.356  loss_cls: 0.2819  loss_box_reg: 0.4607  loss_mask: 0.3082  loss_rpn_cls: 0.08128  loss_rpn_loc: 0.1908  time: 0.5912  data_time: 0.3927  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:02:12 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 6979  total_loss: 1.338  loss_cls: 0.3064  loss_box_reg: 0.4956  loss_mask: 0.2863  loss_rpn_cls: 0.07204  loss_rpn_loc: 0.1886  time: 0.5909  data_time: 0.1777  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:02:24 d2.utils.events]: \u001b[0m eta: 0:17:11  iter: 6999  total_loss: 1.395  loss_cls: 0.3392  loss_box_reg: 0.4856  loss_mask: 0.2936  loss_rpn_cls: 0.0871  loss_rpn_loc: 0.1916  time: 0.5910  data_time: 0.2915  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:02:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:02:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:02:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:02:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:02:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:02:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0723 s/iter. Eval: 0.0374 s/iter. Total: 0.1103 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 23:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0549 s/iter. Total: 0.1296 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0746 s/iter. Eval: 0.0579 s/iter. Total: 0.1333 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 23:02:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.341823 (0.132257 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:02:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074327 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:02:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:02:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2657679636363904\n",
      "\u001b[32m[02/01 23:02:52 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 7019  total_loss: 1.425  loss_cls: 0.3299  loss_box_reg: 0.4924  loss_mask: 0.2955  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.1971  time: 0.5908  data_time: 0.2027  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:03:04 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 7039  total_loss: 1.509  loss_cls: 0.293  loss_box_reg: 0.5184  loss_mask: 0.3027  loss_rpn_cls: 0.07648  loss_rpn_loc: 0.1933  time: 0.5908  data_time: 0.2740  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:03:17 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 7059  total_loss: 1.351  loss_cls: 0.3171  loss_box_reg: 0.4966  loss_mask: 0.2937  loss_rpn_cls: 0.06813  loss_rpn_loc: 0.1906  time: 0.5911  data_time: 0.3424  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:03:28 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 7079  total_loss: 1.322  loss_cls: 0.2919  loss_box_reg: 0.4756  loss_mask: 0.2834  loss_rpn_cls: 0.07097  loss_rpn_loc: 0.1744  time: 0.5910  data_time: 0.2234  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:03:41 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 7099  total_loss: 1.362  loss_cls: 0.3026  loss_box_reg: 0.4832  loss_mask: 0.2954  loss_rpn_cls: 0.07067  loss_rpn_loc: 0.1881  time: 0.5910  data_time: 0.2814  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:03:53 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 7119  total_loss: 1.394  loss_cls: 0.3082  loss_box_reg: 0.5276  loss_mask: 0.3163  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.1776  time: 0.5910  data_time: 0.2757  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:04:05 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 7139  total_loss: 1.302  loss_cls: 0.2789  loss_box_reg: 0.464  loss_mask: 0.2832  loss_rpn_cls: 0.0706  loss_rpn_loc: 0.1886  time: 0.5911  data_time: 0.2895  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:04:17 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 7159  total_loss: 1.549  loss_cls: 0.3773  loss_box_reg: 0.5128  loss_mask: 0.3008  loss_rpn_cls: 0.09171  loss_rpn_loc: 0.2186  time: 0.5912  data_time: 0.2959  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:04:29 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 7179  total_loss: 1.494  loss_cls: 0.3568  loss_box_reg: 0.5272  loss_mask: 0.2976  loss_rpn_cls: 0.08013  loss_rpn_loc: 0.2042  time: 0.5911  data_time: 0.2675  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:04:43 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 7199  total_loss: 1.452  loss_cls: 0.357  loss_box_reg: 0.4984  loss_mask: 0.2972  loss_rpn_cls: 0.08901  loss_rpn_loc: 0.206  time: 0.5914  data_time: 0.3512  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:04:55 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 7219  total_loss: 1.374  loss_cls: 0.3283  loss_box_reg: 0.5054  loss_mask: 0.2974  loss_rpn_cls: 0.07292  loss_rpn_loc: 0.1917  time: 0.5915  data_time: 0.2759  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:05:03 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 7239  total_loss: 1.255  loss_cls: 0.2872  loss_box_reg: 0.4671  loss_mask: 0.2819  loss_rpn_cls: 0.04008  loss_rpn_loc: 0.163  time: 0.5910  data_time: 0.1100  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:05:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:05:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:05:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:05:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:05:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:05:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:05:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0756 s/iter. Eval: 0.0377 s/iter. Total: 0.1140 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 23:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0779 s/iter. Eval: 0.0579 s/iter. Total: 0.1366 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 23:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0605 s/iter. Total: 0.1390 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 23:05:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.831381 (0.136477 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:05:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077108 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:05:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:05:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26403196788003525\n",
      "\u001b[32m[02/01 23:05:33 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 7259  total_loss: 1.263  loss_cls: 0.2663  loss_box_reg: 0.4803  loss_mask: 0.2911  loss_rpn_cls: 0.05243  loss_rpn_loc: 0.1861  time: 0.5910  data_time: 0.2799  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:05:44 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 7279  total_loss: 1.331  loss_cls: 0.3088  loss_box_reg: 0.4686  loss_mask: 0.2997  loss_rpn_cls: 0.08669  loss_rpn_loc: 0.1861  time: 0.5910  data_time: 0.2438  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:05:59 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 7299  total_loss: 1.289  loss_cls: 0.2712  loss_box_reg: 0.483  loss_mask: 0.2962  loss_rpn_cls: 0.08536  loss_rpn_loc: 0.1887  time: 0.5913  data_time: 0.3703  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:06:10 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 7319  total_loss: 1.349  loss_cls: 0.2779  loss_box_reg: 0.5011  loss_mask: 0.2881  loss_rpn_cls: 0.04088  loss_rpn_loc: 0.1716  time: 0.5913  data_time: 0.2519  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:06:23 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 7339  total_loss: 1.528  loss_cls: 0.3652  loss_box_reg: 0.5126  loss_mask: 0.3137  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.201  time: 0.5914  data_time: 0.2804  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:06:34 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 7359  total_loss: 1.447  loss_cls: 0.3349  loss_box_reg: 0.51  loss_mask: 0.3151  loss_rpn_cls: 0.08561  loss_rpn_loc: 0.1914  time: 0.5914  data_time: 0.2693  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:06:47 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 7379  total_loss: 1.425  loss_cls: 0.3077  loss_box_reg: 0.506  loss_mask: 0.2982  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.1961  time: 0.5915  data_time: 0.2985  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:06:57 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 7399  total_loss: 1.414  loss_cls: 0.3394  loss_box_reg: 0.4893  loss_mask: 0.2877  loss_rpn_cls: 0.07616  loss_rpn_loc: 0.1874  time: 0.5912  data_time: 0.1956  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:07:07 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 7419  total_loss: 1.291  loss_cls: 0.2708  loss_box_reg: 0.4944  loss_mask: 0.2968  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.1777  time: 0.5910  data_time: 0.2124  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:07:20 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 7439  total_loss: 1.468  loss_cls: 0.3286  loss_box_reg: 0.4768  loss_mask: 0.3058  loss_rpn_cls: 0.0933  loss_rpn_loc: 0.2082  time: 0.5912  data_time: 0.3132  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:07:31 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 7459  total_loss: 1.296  loss_cls: 0.2734  loss_box_reg: 0.4793  loss_mask: 0.2864  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.1908  time: 0.5911  data_time: 0.2267  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:07:41 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 7479  total_loss: 1.337  loss_cls: 0.3147  loss_box_reg: 0.5036  loss_mask: 0.2956  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.184  time: 0.5907  data_time: 0.1547  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:07:53 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 7499  total_loss: 1.391  loss_cls: 0.3383  loss_box_reg: 0.4946  loss_mask: 0.2886  loss_rpn_cls: 0.06451  loss_rpn_loc: 0.1904  time: 0.5909  data_time: 0.3000  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:07:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:07:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:07:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:07:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:07:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:07:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0718 s/iter. Eval: 0.0359 s/iter. Total: 0.1082 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 23:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0553 s/iter. Total: 0.1297 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0744 s/iter. Eval: 0.0603 s/iter. Total: 0.1356 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 23:08:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.721117 (0.135527 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:08:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074805 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:08:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:08:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2697944027554296\n",
      "\u001b[32m[02/01 23:08:24 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 7519  total_loss: 1.409  loss_cls: 0.3126  loss_box_reg: 0.4589  loss_mask: 0.2863  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.2163  time: 0.5911  data_time: 0.3500  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:08:36 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 7539  total_loss: 1.351  loss_cls: 0.3023  loss_box_reg: 0.4744  loss_mask: 0.291  loss_rpn_cls: 0.07404  loss_rpn_loc: 0.1792  time: 0.5911  data_time: 0.2675  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:08:46 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 7559  total_loss: 1.434  loss_cls: 0.3123  loss_box_reg: 0.5172  loss_mask: 0.3034  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.1934  time: 0.5908  data_time: 0.1737  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:09:01 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 7579  total_loss: 1.469  loss_cls: 0.352  loss_box_reg: 0.4991  loss_mask: 0.3018  loss_rpn_cls: 0.07946  loss_rpn_loc: 0.2132  time: 0.5912  data_time: 0.3933  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:09:14 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 7599  total_loss: 1.354  loss_cls: 0.2954  loss_box_reg: 0.4985  loss_mask: 0.2925  loss_rpn_cls: 0.07079  loss_rpn_loc: 0.1801  time: 0.5914  data_time: 0.3177  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:09:28 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 7619  total_loss: 1.379  loss_cls: 0.2946  loss_box_reg: 0.5065  loss_mask: 0.2821  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.1762  time: 0.5917  data_time: 0.3797  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:09:42 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 7639  total_loss: 1.37  loss_cls: 0.3334  loss_box_reg: 0.4825  loss_mask: 0.2915  loss_rpn_cls: 0.08529  loss_rpn_loc: 0.1965  time: 0.5919  data_time: 0.3805  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:09:53 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 7659  total_loss: 1.397  loss_cls: 0.2965  loss_box_reg: 0.4936  loss_mask: 0.3104  loss_rpn_cls: 0.06728  loss_rpn_loc: 0.2068  time: 0.5919  data_time: 0.2600  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:10:06 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 7679  total_loss: 1.348  loss_cls: 0.2912  loss_box_reg: 0.4758  loss_mask: 0.2943  loss_rpn_cls: 0.06094  loss_rpn_loc: 0.1944  time: 0.5920  data_time: 0.3134  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:10:17 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 7699  total_loss: 1.409  loss_cls: 0.3294  loss_box_reg: 0.4965  loss_mask: 0.2951  loss_rpn_cls: 0.08037  loss_rpn_loc: 0.2031  time: 0.5919  data_time: 0.2223  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:10:28 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 7719  total_loss: 1.314  loss_cls: 0.2714  loss_box_reg: 0.5104  loss_mask: 0.3059  loss_rpn_cls: 0.04666  loss_rpn_loc: 0.182  time: 0.5918  data_time: 0.2377  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:10:39 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 7739  total_loss: 1.303  loss_cls: 0.2808  loss_box_reg: 0.5051  loss_mask: 0.2876  loss_rpn_cls: 0.05794  loss_rpn_loc: 0.1736  time: 0.5917  data_time: 0.1954  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:10:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:10:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:10:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:10:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:10:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:10:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0366 s/iter. Total: 0.1083 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 23:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0754 s/iter. Eval: 0.0561 s/iter. Total: 0.1324 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:10:53 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0757 s/iter. Eval: 0.0592 s/iter. Total: 0.1357 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 23:10:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.628464 (0.134728 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:10:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075541 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:10:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:10:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26908642576364056\n",
      "\u001b[32m[02/01 23:11:06 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 7759  total_loss: 1.426  loss_cls: 0.3347  loss_box_reg: 0.5183  loss_mask: 0.2899  loss_rpn_cls: 0.0808  loss_rpn_loc: 0.1989  time: 0.5915  data_time: 0.1968  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:11:17 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 7779  total_loss: 1.267  loss_cls: 0.2655  loss_box_reg: 0.4671  loss_mask: 0.2921  loss_rpn_cls: 0.04601  loss_rpn_loc: 0.1777  time: 0.5913  data_time: 0.2162  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:11:26 d2.utils.events]: \u001b[0m eta: 0:12:40  iter: 7799  total_loss: 1.328  loss_cls: 0.2853  loss_box_reg: 0.5035  loss_mask: 0.2924  loss_rpn_cls: 0.04787  loss_rpn_loc: 0.1832  time: 0.5909  data_time: 0.1233  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:11:36 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 7819  total_loss: 1.287  loss_cls: 0.309  loss_box_reg: 0.4816  loss_mask: 0.283  loss_rpn_cls: 0.05331  loss_rpn_loc: 0.1601  time: 0.5907  data_time: 0.1831  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:11:47 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 7839  total_loss: 1.322  loss_cls: 0.2719  loss_box_reg: 0.4874  loss_mask: 0.2998  loss_rpn_cls: 0.06141  loss_rpn_loc: 0.19  time: 0.5906  data_time: 0.2305  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:12:03 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 7859  total_loss: 1.48  loss_cls: 0.3456  loss_box_reg: 0.4792  loss_mask: 0.3061  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.2152  time: 0.5912  data_time: 0.4625  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:12:16 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 7879  total_loss: 1.394  loss_cls: 0.3154  loss_box_reg: 0.4897  loss_mask: 0.2963  loss_rpn_cls: 0.06424  loss_rpn_loc: 0.1996  time: 0.5912  data_time: 0.3055  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:12:27 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 7899  total_loss: 1.464  loss_cls: 0.362  loss_box_reg: 0.4872  loss_mask: 0.2927  loss_rpn_cls: 0.07688  loss_rpn_loc: 0.1984  time: 0.5912  data_time: 0.2537  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:12:39 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 7919  total_loss: 1.317  loss_cls: 0.3081  loss_box_reg: 0.4952  loss_mask: 0.2828  loss_rpn_cls: 0.06106  loss_rpn_loc: 0.1643  time: 0.5912  data_time: 0.2579  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:12:51 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 7939  total_loss: 1.344  loss_cls: 0.2759  loss_box_reg: 0.5026  loss_mask: 0.2831  loss_rpn_cls: 0.05937  loss_rpn_loc: 0.1924  time: 0.5912  data_time: 0.2459  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:13:05 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 7959  total_loss: 1.447  loss_cls: 0.3209  loss_box_reg: 0.4877  loss_mask: 0.291  loss_rpn_cls: 0.09278  loss_rpn_loc: 0.2065  time: 0.5915  data_time: 0.3652  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:13:18 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 7979  total_loss: 1.408  loss_cls: 0.3349  loss_box_reg: 0.5112  loss_mask: 0.3123  loss_rpn_cls: 0.0678  loss_rpn_loc: 0.1868  time: 0.5917  data_time: 0.3125  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:13:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:13:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:13:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:13:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:13:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:13:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0726 s/iter. Eval: 0.0397 s/iter. Total: 0.1128 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 23:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0544 s/iter. Total: 0.1295 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0577 s/iter. Total: 0.1338 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 23:13:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.448482 (0.133177 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:13:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075497 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:13:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:13:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26511492224784505\n",
      "\u001b[32m[02/01 23:13:48 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 7999  total_loss: 1.453  loss_cls: 0.3537  loss_box_reg: 0.5025  loss_mask: 0.2981  loss_rpn_cls: 0.0579  loss_rpn_loc: 0.1962  time: 0.5918  data_time: 0.2860  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:14:02 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 8019  total_loss: 1.358  loss_cls: 0.2826  loss_box_reg: 0.4927  loss_mask: 0.3018  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.1926  time: 0.5920  data_time: 0.3655  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:14:13 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 8039  total_loss: 1.354  loss_cls: 0.285  loss_box_reg: 0.4655  loss_mask: 0.3001  loss_rpn_cls: 0.058  loss_rpn_loc: 0.1636  time: 0.5920  data_time: 0.2539  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:14:28 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 8059  total_loss: 1.477  loss_cls: 0.361  loss_box_reg: 0.4911  loss_mask: 0.3037  loss_rpn_cls: 0.08329  loss_rpn_loc: 0.1952  time: 0.5924  data_time: 0.4120  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:14:39 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 8079  total_loss: 1.366  loss_cls: 0.3027  loss_box_reg: 0.5012  loss_mask: 0.2866  loss_rpn_cls: 0.05433  loss_rpn_loc: 0.1901  time: 0.5922  data_time: 0.2174  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:14:50 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 8099  total_loss: 1.3  loss_cls: 0.2714  loss_box_reg: 0.5067  loss_mask: 0.304  loss_rpn_cls: 0.04405  loss_rpn_loc: 0.1786  time: 0.5921  data_time: 0.2066  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:15:03 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 8119  total_loss: 1.358  loss_cls: 0.3105  loss_box_reg: 0.4785  loss_mask: 0.2978  loss_rpn_cls: 0.07167  loss_rpn_loc: 0.1911  time: 0.5923  data_time: 0.3305  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:15:14 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 8139  total_loss: 1.263  loss_cls: 0.288  loss_box_reg: 0.4581  loss_mask: 0.2834  loss_rpn_cls: 0.0474  loss_rpn_loc: 0.1839  time: 0.5922  data_time: 0.2179  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:15:27 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 8159  total_loss: 1.33  loss_cls: 0.3352  loss_box_reg: 0.5006  loss_mask: 0.2866  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.1757  time: 0.5923  data_time: 0.3154  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:15:41 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 8179  total_loss: 1.243  loss_cls: 0.2873  loss_box_reg: 0.4557  loss_mask: 0.2793  loss_rpn_cls: 0.07161  loss_rpn_loc: 0.1738  time: 0.5926  data_time: 0.3742  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:15:54 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 8199  total_loss: 1.401  loss_cls: 0.3366  loss_box_reg: 0.5247  loss_mask: 0.2977  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.1966  time: 0.5927  data_time: 0.3053  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:16:03 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 8219  total_loss: 1.453  loss_cls: 0.3489  loss_box_reg: 0.511  loss_mask: 0.2927  loss_rpn_cls: 0.05551  loss_rpn_loc: 0.1858  time: 0.5924  data_time: 0.1661  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:16:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:16:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:16:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:16:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:16:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:16:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0372 s/iter. Total: 0.1091 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 23:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0768 s/iter. Eval: 0.0565 s/iter. Total: 0.1341 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0604 s/iter. Total: 0.1388 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 23:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0590 s/iter. Total: 0.1374 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 23:16:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.985354 (0.137805 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:16:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077600 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:16:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:16:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25322536638741844\n",
      "\u001b[32m[02/01 23:16:32 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 8239  total_loss: 1.355  loss_cls: 0.2953  loss_box_reg: 0.4903  loss_mask: 0.2725  loss_rpn_cls: 0.06423  loss_rpn_loc: 0.1887  time: 0.5923  data_time: 0.2241  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:16:43 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 8259  total_loss: 1.357  loss_cls: 0.275  loss_box_reg: 0.521  loss_mask: 0.3092  loss_rpn_cls: 0.06689  loss_rpn_loc: 0.177  time: 0.5922  data_time: 0.2302  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:16:52 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 8279  total_loss: 1.422  loss_cls: 0.3198  loss_box_reg: 0.4985  loss_mask: 0.3043  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.2015  time: 0.5919  data_time: 0.1373  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:17:06 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 8299  total_loss: 1.435  loss_cls: 0.3416  loss_box_reg: 0.4651  loss_mask: 0.2961  loss_rpn_cls: 0.06357  loss_rpn_loc: 0.1857  time: 0.5921  data_time: 0.3315  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:17:16 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 8319  total_loss: 1.402  loss_cls: 0.309  loss_box_reg: 0.5053  loss_mask: 0.3212  loss_rpn_cls: 0.07485  loss_rpn_loc: 0.1946  time: 0.5919  data_time: 0.1819  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:17:29 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 8339  total_loss: 1.336  loss_cls: 0.3115  loss_box_reg: 0.4911  loss_mask: 0.2817  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.1711  time: 0.5920  data_time: 0.3004  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:17:40 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 8359  total_loss: 1.408  loss_cls: 0.3187  loss_box_reg: 0.5209  loss_mask: 0.3068  loss_rpn_cls: 0.07172  loss_rpn_loc: 0.1934  time: 0.5919  data_time: 0.2135  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:17:51 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 8379  total_loss: 1.359  loss_cls: 0.2746  loss_box_reg: 0.5008  loss_mask: 0.2959  loss_rpn_cls: 0.073  loss_rpn_loc: 0.1873  time: 0.5918  data_time: 0.2136  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:18:05 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 8399  total_loss: 1.372  loss_cls: 0.3147  loss_box_reg: 0.4688  loss_mask: 0.2804  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.1936  time: 0.5921  data_time: 0.3899  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:18:16 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 8419  total_loss: 1.359  loss_cls: 0.2622  loss_box_reg: 0.4507  loss_mask: 0.282  loss_rpn_cls: 0.07115  loss_rpn_loc: 0.1863  time: 0.5920  data_time: 0.2239  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:18:28 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 8439  total_loss: 1.411  loss_cls: 0.3323  loss_box_reg: 0.508  loss_mask: 0.3026  loss_rpn_cls: 0.07411  loss_rpn_loc: 0.1921  time: 0.5921  data_time: 0.3008  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:18:42 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 8459  total_loss: 1.382  loss_cls: 0.3154  loss_box_reg: 0.482  loss_mask: 0.2979  loss_rpn_cls: 0.07497  loss_rpn_loc: 0.1765  time: 0.5923  data_time: 0.3458  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:18:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:18:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:18:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:18:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:18:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:18:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0713 s/iter. Eval: 0.0368 s/iter. Total: 0.1088 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/01 23:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0751 s/iter. Eval: 0.0567 s/iter. Total: 0.1326 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0616 s/iter. Total: 0.1385 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 23:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0756 s/iter. Eval: 0.0601 s/iter. Total: 0.1365 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 23:19:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.898550 (0.137056 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:19:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075626 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:19:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:19:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26826079242330764\n",
      "\u001b[32m[02/01 23:19:12 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 8479  total_loss: 1.334  loss_cls: 0.3145  loss_box_reg: 0.4652  loss_mask: 0.2878  loss_rpn_cls: 0.07449  loss_rpn_loc: 0.1839  time: 0.5923  data_time: 0.2802  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:19:25 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 8499  total_loss: 1.38  loss_cls: 0.3033  loss_box_reg: 0.5021  loss_mask: 0.2991  loss_rpn_cls: 0.06653  loss_rpn_loc: 0.202  time: 0.5924  data_time: 0.2953  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:19:34 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 8519  total_loss: 1.362  loss_cls: 0.2921  loss_box_reg: 0.4884  loss_mask: 0.2976  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.1798  time: 0.5922  data_time: 0.1752  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:19:47 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 8539  total_loss: 1.303  loss_cls: 0.2822  loss_box_reg: 0.4592  loss_mask: 0.3014  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.171  time: 0.5923  data_time: 0.2742  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:20:01 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 8559  total_loss: 1.36  loss_cls: 0.3128  loss_box_reg: 0.445  loss_mask: 0.2928  loss_rpn_cls: 0.08243  loss_rpn_loc: 0.2028  time: 0.5925  data_time: 0.3433  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:20:12 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 8579  total_loss: 1.42  loss_cls: 0.3186  loss_box_reg: 0.496  loss_mask: 0.3047  loss_rpn_cls: 0.08161  loss_rpn_loc: 0.2047  time: 0.5925  data_time: 0.2688  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:20:25 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 8599  total_loss: 1.388  loss_cls: 0.3188  loss_box_reg: 0.4798  loss_mask: 0.2905  loss_rpn_cls: 0.06691  loss_rpn_loc: 0.191  time: 0.5925  data_time: 0.2923  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:20:35 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 8619  total_loss: 1.398  loss_cls: 0.3539  loss_box_reg: 0.5043  loss_mask: 0.2906  loss_rpn_cls: 0.07782  loss_rpn_loc: 0.1975  time: 0.5923  data_time: 0.1838  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:20:46 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 8639  total_loss: 1.314  loss_cls: 0.3146  loss_box_reg: 0.4771  loss_mask: 0.2809  loss_rpn_cls: 0.0699  loss_rpn_loc: 0.169  time: 0.5923  data_time: 0.2510  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:20:58 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 8659  total_loss: 1.29  loss_cls: 0.2727  loss_box_reg: 0.4577  loss_mask: 0.2869  loss_rpn_cls: 0.05181  loss_rpn_loc: 0.1852  time: 0.5922  data_time: 0.2482  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:21:10 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 8679  total_loss: 1.403  loss_cls: 0.3107  loss_box_reg: 0.4854  loss_mask: 0.3003  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.1945  time: 0.5923  data_time: 0.2836  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:21:21 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 8699  total_loss: 1.384  loss_cls: 0.3222  loss_box_reg: 0.5083  loss_mask: 0.28  loss_rpn_cls: 0.07849  loss_rpn_loc: 0.1815  time: 0.5922  data_time: 0.2220  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:21:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:21:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:21:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:21:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:21:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:21:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0747 s/iter. Eval: 0.0408 s/iter. Total: 0.1162 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 23:21:37 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0759 s/iter. Eval: 0.0601 s/iter. Total: 0.1369 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 23:21:42 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.0766 s/iter. Eval: 0.0643 s/iter. Total: 0.1418 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 23:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0616 s/iter. Total: 0.1384 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/01 23:21:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.226474 (0.139883 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:21:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076063 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:21:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:21:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2623409996635989\n",
      "\u001b[32m[02/01 23:21:53 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 8719  total_loss: 1.336  loss_cls: 0.2956  loss_box_reg: 0.4933  loss_mask: 0.3053  loss_rpn_cls: 0.07605  loss_rpn_loc: 0.1841  time: 0.5925  data_time: 0.3906  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:22:11 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 8739  total_loss: 1.464  loss_cls: 0.3432  loss_box_reg: 0.5141  loss_mask: 0.3061  loss_rpn_cls: 0.08854  loss_rpn_loc: 0.2047  time: 0.5932  data_time: 0.5544  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:22:23 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 8759  total_loss: 1.463  loss_cls: 0.324  loss_box_reg: 0.5292  loss_mask: 0.3069  loss_rpn_cls: 0.08801  loss_rpn_loc: 0.1981  time: 0.5931  data_time: 0.2433  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:22:35 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 8779  total_loss: 1.389  loss_cls: 0.3406  loss_box_reg: 0.5067  loss_mask: 0.2756  loss_rpn_cls: 0.07177  loss_rpn_loc: 0.1802  time: 0.5931  data_time: 0.2621  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:22:47 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 8799  total_loss: 1.375  loss_cls: 0.2895  loss_box_reg: 0.477  loss_mask: 0.2878  loss_rpn_cls: 0.05323  loss_rpn_loc: 0.1643  time: 0.5931  data_time: 0.2762  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:22:58 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 8819  total_loss: 1.284  loss_cls: 0.2683  loss_box_reg: 0.4483  loss_mask: 0.2985  loss_rpn_cls: 0.06666  loss_rpn_loc: 0.1783  time: 0.5931  data_time: 0.2290  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:23:11 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 8839  total_loss: 1.268  loss_cls: 0.2886  loss_box_reg: 0.473  loss_mask: 0.2857  loss_rpn_cls: 0.06586  loss_rpn_loc: 0.191  time: 0.5932  data_time: 0.3262  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:23:19 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 8859  total_loss: 1.254  loss_cls: 0.2722  loss_box_reg: 0.511  loss_mask: 0.2763  loss_rpn_cls: 0.03817  loss_rpn_loc: 0.1537  time: 0.5928  data_time: 0.1009  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:23:30 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 8879  total_loss: 1.317  loss_cls: 0.2905  loss_box_reg: 0.4753  loss_mask: 0.286  loss_rpn_cls: 0.06762  loss_rpn_loc: 0.1937  time: 0.5927  data_time: 0.2435  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:23:45 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 8899  total_loss: 1.379  loss_cls: 0.3158  loss_box_reg: 0.5096  loss_mask: 0.3046  loss_rpn_cls: 0.06588  loss_rpn_loc: 0.196  time: 0.5931  data_time: 0.4347  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:23:56 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 8919  total_loss: 1.419  loss_cls: 0.32  loss_box_reg: 0.5045  loss_mask: 0.292  loss_rpn_cls: 0.0652  loss_rpn_loc: 0.1769  time: 0.5930  data_time: 0.2197  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:24:09 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 8939  total_loss: 1.382  loss_cls: 0.3226  loss_box_reg: 0.5055  loss_mask: 0.3009  loss_rpn_cls: 0.08206  loss_rpn_loc: 0.1969  time: 0.5931  data_time: 0.3099  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:24:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:24:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:24:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:24:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:24:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:24:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:24:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0739 s/iter. Eval: 0.0402 s/iter. Total: 0.1147 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 23:24:25 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0740 s/iter. Eval: 0.0551 s/iter. Total: 0.1299 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:24:30 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0744 s/iter. Eval: 0.0583 s/iter. Total: 0.1335 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 23:24:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.386134 (0.132639 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:24:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074372 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:24:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:24:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26417055065197625\n",
      "\u001b[32m[02/01 23:24:39 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 8959  total_loss: 1.413  loss_cls: 0.3447  loss_box_reg: 0.5094  loss_mask: 0.3034  loss_rpn_cls: 0.07323  loss_rpn_loc: 0.2105  time: 0.5932  data_time: 0.3290  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:24:52 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 8979  total_loss: 1.288  loss_cls: 0.2957  loss_box_reg: 0.4822  loss_mask: 0.2818  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.176  time: 0.5933  data_time: 0.2980  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:25:04 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 8999  total_loss: 1.311  loss_cls: 0.293  loss_box_reg: 0.4645  loss_mask: 0.2898  loss_rpn_cls: 0.08045  loss_rpn_loc: 0.1912  time: 0.5933  data_time: 0.2601  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:25:13 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 9019  total_loss: 1.285  loss_cls: 0.2558  loss_box_reg: 0.4844  loss_mask: 0.2953  loss_rpn_cls: 0.0427  loss_rpn_loc: 0.1656  time: 0.5930  data_time: 0.1352  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:25:27 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 9039  total_loss: 1.38  loss_cls: 0.2782  loss_box_reg: 0.4874  loss_mask: 0.3091  loss_rpn_cls: 0.07653  loss_rpn_loc: 0.1966  time: 0.5933  data_time: 0.3763  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:25:38 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 9059  total_loss: 1.454  loss_cls: 0.3361  loss_box_reg: 0.5219  loss_mask: 0.3076  loss_rpn_cls: 0.08199  loss_rpn_loc: 0.1979  time: 0.5932  data_time: 0.2453  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:25:47 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 9079  total_loss: 1.334  loss_cls: 0.2714  loss_box_reg: 0.494  loss_mask: 0.2752  loss_rpn_cls: 0.0575  loss_rpn_loc: 0.178  time: 0.5928  data_time: 0.1337  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:25:58 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 9099  total_loss: 1.368  loss_cls: 0.3055  loss_box_reg: 0.5105  loss_mask: 0.3051  loss_rpn_cls: 0.06998  loss_rpn_loc: 0.1917  time: 0.5927  data_time: 0.2047  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:26:07 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 9119  total_loss: 1.353  loss_cls: 0.2826  loss_box_reg: 0.5017  loss_mask: 0.2848  loss_rpn_cls: 0.06143  loss_rpn_loc: 0.166  time: 0.5924  data_time: 0.1409  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:26:17 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 9139  total_loss: 1.371  loss_cls: 0.3173  loss_box_reg: 0.494  loss_mask: 0.2892  loss_rpn_cls: 0.06769  loss_rpn_loc: 0.1825  time: 0.5923  data_time: 0.2121  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:26:27 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 9159  total_loss: 1.346  loss_cls: 0.2962  loss_box_reg: 0.5066  loss_mask: 0.3021  loss_rpn_cls: 0.05815  loss_rpn_loc: 0.1815  time: 0.5920  data_time: 0.1799  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:26:45 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 9179  total_loss: 1.358  loss_cls: 0.3178  loss_box_reg: 0.4325  loss_mask: 0.2916  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.1889  time: 0.5927  data_time: 0.5362  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:26:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:26:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:26:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:26:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:26:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:26:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0721 s/iter. Eval: 0.0451 s/iter. Total: 0.1180 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/01 23:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0547 s/iter. Total: 0.1298 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0742 s/iter. Eval: 0.0564 s/iter. Total: 0.1314 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 23:27:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.113206 (0.130286 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:27:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073883 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:27:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:27:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26525933551542785\n",
      "\u001b[32m[02/01 23:27:14 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 9199  total_loss: 1.348  loss_cls: 0.3255  loss_box_reg: 0.4717  loss_mask: 0.275  loss_rpn_cls: 0.07913  loss_rpn_loc: 0.1908  time: 0.5927  data_time: 0.2849  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:27:30 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 9219  total_loss: 1.441  loss_cls: 0.3395  loss_box_reg: 0.4694  loss_mask: 0.2987  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.2056  time: 0.5932  data_time: 0.4818  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:27:43 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 9239  total_loss: 1.331  loss_cls: 0.2785  loss_box_reg: 0.4529  loss_mask: 0.2971  loss_rpn_cls: 0.05999  loss_rpn_loc: 0.1972  time: 0.5933  data_time: 0.2773  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:27:52 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 9259  total_loss: 1.238  loss_cls: 0.2792  loss_box_reg: 0.4854  loss_mask: 0.2957  loss_rpn_cls: 0.04317  loss_rpn_loc: 0.1609  time: 0.5931  data_time: 0.1799  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:28:06 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 9279  total_loss: 1.427  loss_cls: 0.3353  loss_box_reg: 0.4663  loss_mask: 0.3096  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.1958  time: 0.5932  data_time: 0.3302  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:28:16 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 9299  total_loss: 1.361  loss_cls: 0.3034  loss_box_reg: 0.5105  loss_mask: 0.2822  loss_rpn_cls: 0.06537  loss_rpn_loc: 0.1906  time: 0.5931  data_time: 0.2086  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:28:29 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 9319  total_loss: 1.408  loss_cls: 0.3236  loss_box_reg: 0.4404  loss_mask: 0.3027  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.2006  time: 0.5931  data_time: 0.2904  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:28:39 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 9339  total_loss: 1.355  loss_cls: 0.302  loss_box_reg: 0.4555  loss_mask: 0.2916  loss_rpn_cls: 0.0757  loss_rpn_loc: 0.1782  time: 0.5930  data_time: 0.2249  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:28:52 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 9359  total_loss: 1.356  loss_cls: 0.2705  loss_box_reg: 0.4937  loss_mask: 0.2946  loss_rpn_cls: 0.08829  loss_rpn_loc: 0.1894  time: 0.5930  data_time: 0.2845  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:29:02 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 9379  total_loss: 1.292  loss_cls: 0.2821  loss_box_reg: 0.4755  loss_mask: 0.2858  loss_rpn_cls: 0.06226  loss_rpn_loc: 0.173  time: 0.5929  data_time: 0.2153  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:29:16 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 9399  total_loss: 1.401  loss_cls: 0.319  loss_box_reg: 0.4944  loss_mask: 0.2874  loss_rpn_cls: 0.07123  loss_rpn_loc: 0.1766  time: 0.5931  data_time: 0.3103  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:29:30 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9419  total_loss: 1.327  loss_cls: 0.28  loss_box_reg: 0.4432  loss_mask: 0.2884  loss_rpn_cls: 0.07502  loss_rpn_loc: 0.1916  time: 0.5934  data_time: 0.3958  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:29:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:29:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:29:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:29:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:29:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:29:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0716 s/iter. Eval: 0.0477 s/iter. Total: 0.1201 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/01 23:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0740 s/iter. Eval: 0.0578 s/iter. Total: 0.1326 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0748 s/iter. Eval: 0.0621 s/iter. Total: 0.1377 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 23:29:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.763641 (0.135893 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:29:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:29:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:29:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2668554576815722\n",
      "\u001b[32m[02/01 23:29:58 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 9439  total_loss: 1.398  loss_cls: 0.3105  loss_box_reg: 0.513  loss_mask: 0.3  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.2096  time: 0.5932  data_time: 0.2028  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:30:10 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 9459  total_loss: 1.246  loss_cls: 0.2754  loss_box_reg: 0.4898  loss_mask: 0.2906  loss_rpn_cls: 0.05198  loss_rpn_loc: 0.1992  time: 0.5932  data_time: 0.2848  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:30:24 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 9479  total_loss: 1.31  loss_cls: 0.2907  loss_box_reg: 0.4826  loss_mask: 0.286  loss_rpn_cls: 0.08315  loss_rpn_loc: 0.1867  time: 0.5934  data_time: 0.3461  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:30:33 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 9499  total_loss: 1.291  loss_cls: 0.2677  loss_box_reg: 0.4885  loss_mask: 0.2807  loss_rpn_cls: 0.04093  loss_rpn_loc: 0.1729  time: 0.5931  data_time: 0.1233  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:30:44 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 9519  total_loss: 1.345  loss_cls: 0.303  loss_box_reg: 0.4966  loss_mask: 0.2878  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.1874  time: 0.5930  data_time: 0.2453  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:30:54 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 9539  total_loss: 1.366  loss_cls: 0.312  loss_box_reg: 0.4888  loss_mask: 0.2881  loss_rpn_cls: 0.06756  loss_rpn_loc: 0.1917  time: 0.5929  data_time: 0.2141  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:31:06 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 9559  total_loss: 1.358  loss_cls: 0.2975  loss_box_reg: 0.506  loss_mask: 0.2976  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.1914  time: 0.5929  data_time: 0.2605  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:31:19 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9579  total_loss: 1.36  loss_cls: 0.2797  loss_box_reg: 0.4897  loss_mask: 0.2952  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.1797  time: 0.5929  data_time: 0.2971  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:31:34 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 9599  total_loss: 1.415  loss_cls: 0.3074  loss_box_reg: 0.4909  loss_mask: 0.2938  loss_rpn_cls: 0.07729  loss_rpn_loc: 0.192  time: 0.5933  data_time: 0.4326  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:31:47 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 9619  total_loss: 1.298  loss_cls: 0.29  loss_box_reg: 0.5144  loss_mask: 0.298  loss_rpn_cls: 0.09342  loss_rpn_loc: 0.1799  time: 0.5934  data_time: 0.3285  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:31:54 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 9639  total_loss: 1.353  loss_cls: 0.3051  loss_box_reg: 0.5046  loss_mask: 0.289  loss_rpn_cls: 0.05768  loss_rpn_loc: 0.1743  time: 0.5929  data_time: 0.0483  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:32:05 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 9659  total_loss: 1.292  loss_cls: 0.2899  loss_box_reg: 0.4687  loss_mask: 0.2962  loss_rpn_cls: 0.05745  loss_rpn_loc: 0.1862  time: 0.5929  data_time: 0.2367  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:32:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:32:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:32:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:32:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:32:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:32:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0737 s/iter. Eval: 0.0465 s/iter. Total: 0.1209 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/01 23:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0756 s/iter. Eval: 0.0581 s/iter. Total: 0.1345 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0756 s/iter. Eval: 0.0603 s/iter. Total: 0.1367 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 23:32:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.652986 (0.134940 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:32:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075095 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:32:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:32:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26977299798115906\n",
      "\u001b[32m[02/01 23:32:36 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 9679  total_loss: 1.342  loss_cls: 0.3262  loss_box_reg: 0.4943  loss_mask: 0.3074  loss_rpn_cls: 0.07694  loss_rpn_loc: 0.1967  time: 0.5930  data_time: 0.3301  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:32:49 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 9699  total_loss: 1.233  loss_cls: 0.2626  loss_box_reg: 0.4779  loss_mask: 0.2894  loss_rpn_cls: 0.07978  loss_rpn_loc: 0.1912  time: 0.5931  data_time: 0.3098  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:33:01 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 9719  total_loss: 1.412  loss_cls: 0.3089  loss_box_reg: 0.4802  loss_mask: 0.292  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1994  time: 0.5932  data_time: 0.3033  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:33:11 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 9739  total_loss: 1.269  loss_cls: 0.303  loss_box_reg: 0.4856  loss_mask: 0.2953  loss_rpn_cls: 0.0524  loss_rpn_loc: 0.1701  time: 0.5930  data_time: 0.1764  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:33:22 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 9759  total_loss: 1.296  loss_cls: 0.2719  loss_box_reg: 0.4945  loss_mask: 0.2971  loss_rpn_cls: 0.05345  loss_rpn_loc: 0.1755  time: 0.5929  data_time: 0.2266  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:33:35 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 9779  total_loss: 1.329  loss_cls: 0.3073  loss_box_reg: 0.4676  loss_mask: 0.3026  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.1799  time: 0.5930  data_time: 0.2975  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:33:46 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 9799  total_loss: 1.378  loss_cls: 0.3006  loss_box_reg: 0.4844  loss_mask: 0.2882  loss_rpn_cls: 0.06545  loss_rpn_loc: 0.2029  time: 0.5930  data_time: 0.2731  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:33:59 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 9819  total_loss: 1.437  loss_cls: 0.3243  loss_box_reg: 0.5288  loss_mask: 0.302  loss_rpn_cls: 0.09123  loss_rpn_loc: 0.1957  time: 0.5930  data_time: 0.3009  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:34:14 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 9839  total_loss: 1.379  loss_cls: 0.3136  loss_box_reg: 0.4895  loss_mask: 0.2815  loss_rpn_cls: 0.0585  loss_rpn_loc: 0.1712  time: 0.5933  data_time: 0.3951  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:34:25 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 9859  total_loss: 1.351  loss_cls: 0.3128  loss_box_reg: 0.4695  loss_mask: 0.2854  loss_rpn_cls: 0.06039  loss_rpn_loc: 0.185  time: 0.5932  data_time: 0.2366  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:34:36 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 9879  total_loss: 1.336  loss_cls: 0.2881  loss_box_reg: 0.4791  loss_mask: 0.2948  loss_rpn_cls: 0.05617  loss_rpn_loc: 0.189  time: 0.5932  data_time: 0.2484  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:34:47 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 9899  total_loss: 1.213  loss_cls: 0.2737  loss_box_reg: 0.4624  loss_mask: 0.2809  loss_rpn_cls: 0.04939  loss_rpn_loc: 0.1794  time: 0.5930  data_time: 0.2035  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:34:56 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 9919  total_loss: 1.429  loss_cls: 0.3274  loss_box_reg: 0.5144  loss_mask: 0.3038  loss_rpn_cls: 0.06312  loss_rpn_loc: 0.186  time: 0.5927  data_time: 0.1324  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:34:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:34:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:34:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:34:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:34:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:34:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0730 s/iter. Eval: 0.0453 s/iter. Total: 0.1191 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/01 23:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0746 s/iter. Eval: 0.0554 s/iter. Total: 0.1309 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/01 23:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0581 s/iter. Total: 0.1336 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/01 23:35:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.324476 (0.132108 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:35:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074101 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:35:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:35:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26030272639693325\n",
      "\u001b[32m[02/01 23:35:25 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 9939  total_loss: 1.412  loss_cls: 0.3349  loss_box_reg: 0.4862  loss_mask: 0.3014  loss_rpn_cls: 0.09832  loss_rpn_loc: 0.2142  time: 0.5928  data_time: 0.3211  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:35:36 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 9959  total_loss: 1.346  loss_cls: 0.2967  loss_box_reg: 0.5082  loss_mask: 0.3096  loss_rpn_cls: 0.0486  loss_rpn_loc: 0.1957  time: 0.5928  data_time: 0.2458  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:35:48 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 9979  total_loss: 1.286  loss_cls: 0.2819  loss_box_reg: 0.4887  loss_mask: 0.2737  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.1726  time: 0.5927  data_time: 0.2473  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:36:00 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.337  loss_cls: 0.3018  loss_box_reg: 0.4731  loss_mask: 0.2768  loss_rpn_cls: 0.04561  loss_rpn_loc: 0.1711  time: 0.5927  data_time: 0.2636  lr: 0.0005  max_mem: 6469M\n",
      "\u001b[32m[02/01 23:36:00 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:38:46 (0.5927 s / it)\n",
      "\u001b[32m[02/01 23:36:00 d2.engine.hooks]: \u001b[0mTotal training time: 1:50:18 (0:11:32 on hooks)\n",
      "\u001b[32m[02/01 23:36:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:36:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/01 23:36:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/01 23:36:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/01 23:36:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/01 23:36:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/01 23:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0733 s/iter. Eval: 0.0565 s/iter. Total: 0.1307 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/01 23:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0746 s/iter. Eval: 0.0626 s/iter. Total: 0.1380 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/01 23:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0637 s/iter. Total: 0.1394 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/01 23:36:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.905189 (0.137114 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:36:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074668 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/01 23:36:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/01 23:36:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.268255823446608\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.0005\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_8.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33147649-a9b3-4287-a4d0-6945a84c9632",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 09:16:59 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 09:16:59 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 09:17:03 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/02 09:17:04 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 09:17:04 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/02 09:17:04 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/02 09:17:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/02 09:17:04 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/02 09:17:04 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:17:04 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 09:17:04 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 09:17:17 d2.utils.events]: \u001b[0m eta: 0:58:58  iter: 19  total_loss: 3.105  loss_cls: 1.473  loss_box_reg: 0.3957  loss_mask: 0.6937  loss_rpn_cls: 0.3369  loss_rpn_loc: 0.2583  time: 0.5612  data_time: 0.2377  lr: 1.9981e-06  max_mem: 4664M\n",
      "\u001b[32m[02/02 09:17:28 d2.utils.events]: \u001b[0m eta: 0:55:27  iter: 39  total_loss: 3.152  loss_cls: 1.463  loss_box_reg: 0.3548  loss_mask: 0.692  loss_rpn_cls: 0.331  loss_rpn_loc: 0.2538  time: 0.5611  data_time: 0.2547  lr: 3.9961e-06  max_mem: 4664M\n",
      "\u001b[32m[02/02 09:17:40 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 59  total_loss: 3.099  loss_cls: 1.421  loss_box_reg: 0.4539  loss_mask: 0.6878  loss_rpn_cls: 0.2877  loss_rpn_loc: 0.2332  time: 0.5710  data_time: 0.2770  lr: 5.9941e-06  max_mem: 4664M\n",
      "\u001b[32m[02/02 09:17:52 d2.utils.events]: \u001b[0m eta: 0:54:30  iter: 79  total_loss: 3  loss_cls: 1.364  loss_box_reg: 0.3917  loss_mask: 0.6829  loss_rpn_cls: 0.3409  loss_rpn_loc: 0.2737  time: 0.5776  data_time: 0.2926  lr: 7.9921e-06  max_mem: 4664M\n",
      "\u001b[32m[02/02 09:18:05 d2.utils.events]: \u001b[0m eta: 0:55:03  iter: 99  total_loss: 2.974  loss_cls: 1.3  loss_box_reg: 0.3828  loss_mask: 0.6788  loss_rpn_cls: 0.3003  loss_rpn_loc: 0.2785  time: 0.5980  data_time: 0.3555  lr: 9.9901e-06  max_mem: 4664M\n",
      "\u001b[32m[02/02 09:18:16 d2.utils.events]: \u001b[0m eta: 0:54:22  iter: 119  total_loss: 2.944  loss_cls: 1.226  loss_box_reg: 0.4201  loss_mask: 0.669  loss_rpn_cls: 0.2809  loss_rpn_loc: 0.2576  time: 0.5913  data_time: 0.2557  lr: 1.1988e-05  max_mem: 4766M\n",
      "\u001b[32m[02/02 09:18:29 d2.utils.events]: \u001b[0m eta: 0:54:29  iter: 139  total_loss: 2.76  loss_cls: 1.134  loss_box_reg: 0.4252  loss_mask: 0.6604  loss_rpn_cls: 0.2914  loss_rpn_loc: 0.2693  time: 0.5945  data_time: 0.3044  lr: 1.3986e-05  max_mem: 5117M\n",
      "\u001b[32m[02/02 09:18:43 d2.utils.events]: \u001b[0m eta: 0:54:22  iter: 159  total_loss: 2.687  loss_cls: 1.081  loss_box_reg: 0.4529  loss_mask: 0.6498  loss_rpn_cls: 0.2884  loss_rpn_loc: 0.2403  time: 0.6098  data_time: 0.3965  lr: 1.5984e-05  max_mem: 5138M\n",
      "\u001b[32m[02/02 09:18:51 d2.utils.events]: \u001b[0m eta: 0:53:23  iter: 179  total_loss: 2.603  loss_cls: 0.9828  loss_box_reg: 0.5076  loss_mask: 0.63  loss_rpn_cls: 0.224  loss_rpn_loc: 0.2229  time: 0.5878  data_time: 0.1201  lr: 1.7982e-05  max_mem: 5138M\n",
      "\u001b[32m[02/02 09:19:03 d2.utils.events]: \u001b[0m eta: 0:53:19  iter: 199  total_loss: 2.492  loss_cls: 0.8948  loss_box_reg: 0.4595  loss_mask: 0.6293  loss_rpn_cls: 0.2234  loss_rpn_loc: 0.248  time: 0.5865  data_time: 0.2621  lr: 1.998e-05  max_mem: 5138M\n",
      "\u001b[32m[02/02 09:19:13 d2.utils.events]: \u001b[0m eta: 0:53:10  iter: 219  total_loss: 2.362  loss_cls: 0.8237  loss_box_reg: 0.5309  loss_mask: 0.6043  loss_rpn_cls: 0.2379  loss_rpn_loc: 0.2485  time: 0.5804  data_time: 0.2027  lr: 2.1978e-05  max_mem: 5762M\n",
      "\u001b[32m[02/02 09:19:28 d2.utils.events]: \u001b[0m eta: 0:53:10  iter: 239  total_loss: 2.433  loss_cls: 0.8036  loss_box_reg: 0.5302  loss_mask: 0.6045  loss_rpn_cls: 0.2057  loss_rpn_loc: 0.2417  time: 0.5929  data_time: 0.4016  lr: 2.3976e-05  max_mem: 5762M\n",
      "\u001b[32m[02/02 09:19:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:19:29 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/02 09:19:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:19:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:19:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:19:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:19:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0005 s/iter. Inference: 0.0613 s/iter. Eval: 0.0000 s/iter. Total: 0.0619 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/02 09:19:35 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0006 s/iter. Inference: 0.0613 s/iter. Eval: 0.0000 s/iter. Total: 0.0620 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/02 09:19:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.234933 (0.062370 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:19:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.061353 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:19:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:19:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.0\n",
      "\u001b[32m[02/02 09:19:44 d2.utils.events]: \u001b[0m eta: 0:52:57  iter: 259  total_loss: 2.306  loss_cls: 0.7441  loss_box_reg: 0.5098  loss_mask: 0.589  loss_rpn_cls: 0.2004  loss_rpn_loc: 0.2339  time: 0.5793  data_time: 0.1168  lr: 2.5974e-05  max_mem: 5762M\n",
      "\u001b[32m[02/02 09:19:55 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 279  total_loss: 2.28  loss_cls: 0.7457  loss_box_reg: 0.5636  loss_mask: 0.5687  loss_rpn_cls: 0.1683  loss_rpn_loc: 0.2454  time: 0.5751  data_time: 0.2192  lr: 2.7972e-05  max_mem: 5762M\n",
      "\u001b[32m[02/02 09:20:05 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 299  total_loss: 2.293  loss_cls: 0.7099  loss_box_reg: 0.5627  loss_mask: 0.5488  loss_rpn_cls: 0.2018  loss_rpn_loc: 0.237  time: 0.5717  data_time: 0.2184  lr: 2.997e-05  max_mem: 5762M\n",
      "\u001b[32m[02/02 09:20:17 d2.utils.events]: \u001b[0m eta: 0:52:30  iter: 319  total_loss: 2.207  loss_cls: 0.6867  loss_box_reg: 0.5247  loss_mask: 0.5385  loss_rpn_cls: 0.2009  loss_rpn_loc: 0.2428  time: 0.5735  data_time: 0.2965  lr: 3.1968e-05  max_mem: 5762M\n",
      "\u001b[32m[02/02 09:20:27 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 339  total_loss: 2.19  loss_cls: 0.6829  loss_box_reg: 0.6122  loss_mask: 0.5175  loss_rpn_cls: 0.1473  loss_rpn_loc: 0.2  time: 0.5684  data_time: 0.1881  lr: 3.3966e-05  max_mem: 5762M\n",
      "\u001b[32m[02/02 09:20:42 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 359  total_loss: 2.132  loss_cls: 0.6491  loss_box_reg: 0.5519  loss_mask: 0.5356  loss_rpn_cls: 0.1706  loss_rpn_loc: 0.264  time: 0.5777  data_time: 0.4143  lr: 3.5964e-05  max_mem: 5762M\n",
      "\u001b[32m[02/02 09:20:56 d2.utils.events]: \u001b[0m eta: 0:52:21  iter: 379  total_loss: 2.156  loss_cls: 0.6597  loss_box_reg: 0.5444  loss_mask: 0.519  loss_rpn_cls: 0.1683  loss_rpn_loc: 0.2226  time: 0.5840  data_time: 0.3702  lr: 3.7962e-05  max_mem: 5806M\n",
      "\u001b[32m[02/02 09:21:06 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 399  total_loss: 2.114  loss_cls: 0.6186  loss_box_reg: 0.5722  loss_mask: 0.4925  loss_rpn_cls: 0.1423  loss_rpn_loc: 0.2349  time: 0.5809  data_time: 0.2093  lr: 3.996e-05  max_mem: 5806M\n",
      "\u001b[32m[02/02 09:21:17 d2.utils.events]: \u001b[0m eta: 0:52:08  iter: 419  total_loss: 2.085  loss_cls: 0.5846  loss_box_reg: 0.586  loss_mask: 0.4962  loss_rpn_cls: 0.1694  loss_rpn_loc: 0.221  time: 0.5784  data_time: 0.2142  lr: 4.1958e-05  max_mem: 5806M\n",
      "\u001b[32m[02/02 09:21:27 d2.utils.events]: \u001b[0m eta: 0:52:00  iter: 439  total_loss: 2.132  loss_cls: 0.6991  loss_box_reg: 0.6108  loss_mask: 0.4816  loss_rpn_cls: 0.1468  loss_rpn_loc: 0.233  time: 0.5752  data_time: 0.1996  lr: 4.3956e-05  max_mem: 5806M\n",
      "\u001b[32m[02/02 09:21:36 d2.utils.events]: \u001b[0m eta: 0:51:48  iter: 459  total_loss: 2.109  loss_cls: 0.634  loss_box_reg: 0.6229  loss_mask: 0.477  loss_rpn_cls: 0.1381  loss_rpn_loc: 0.2308  time: 0.5694  data_time: 0.1420  lr: 4.5954e-05  max_mem: 5806M\n",
      "\u001b[32m[02/02 09:21:50 d2.utils.events]: \u001b[0m eta: 0:51:42  iter: 479  total_loss: 1.959  loss_cls: 0.5946  loss_box_reg: 0.5996  loss_mask: 0.4526  loss_rpn_cls: 0.1267  loss_rpn_loc: 0.2198  time: 0.5756  data_time: 0.3903  lr: 4.7952e-05  max_mem: 5849M\n",
      "\u001b[32m[02/02 09:21:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:21:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:21:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:21:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:21:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:21:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0614 s/iter. Eval: 0.0000 s/iter. Total: 0.0620 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/02 09:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0617 s/iter. Eval: 0.0000 s/iter. Total: 0.0624 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/02 09:22:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.282801 (0.062783 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:22:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.061653 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:22:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:22:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.0\n",
      "\u001b[32m[02/02 09:22:10 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 499  total_loss: 2.116  loss_cls: 0.6409  loss_box_reg: 0.624  loss_mask: 0.4328  loss_rpn_cls: 0.145  loss_rpn_loc: 0.2395  time: 0.5745  data_time: 0.2343  lr: 4.995e-05  max_mem: 5849M\n",
      "\u001b[32m[02/02 09:22:19 d2.utils.events]: \u001b[0m eta: 0:51:29  iter: 519  total_loss: 2.016  loss_cls: 0.6207  loss_box_reg: 0.631  loss_mask: 0.4279  loss_rpn_cls: 0.1309  loss_rpn_loc: 0.2214  time: 0.5708  data_time: 0.1716  lr: 5.1948e-05  max_mem: 5849M\n",
      "\u001b[32m[02/02 09:22:29 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 539  total_loss: 1.854  loss_cls: 0.5035  loss_box_reg: 0.6455  loss_mask: 0.4026  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.2208  time: 0.5677  data_time: 0.1842  lr: 5.3946e-05  max_mem: 5849M\n",
      "\u001b[32m[02/02 09:22:42 d2.utils.events]: \u001b[0m eta: 0:51:19  iter: 559  total_loss: 1.882  loss_cls: 0.522  loss_box_reg: 0.6744  loss_mask: 0.3933  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.2194  time: 0.5715  data_time: 0.3559  lr: 5.5944e-05  max_mem: 5849M\n",
      "\u001b[32m[02/02 09:22:57 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 579  total_loss: 2.017  loss_cls: 0.5655  loss_box_reg: 0.6168  loss_mask: 0.4142  loss_rpn_cls: 0.1487  loss_rpn_loc: 0.2355  time: 0.5765  data_time: 0.3956  lr: 5.7942e-05  max_mem: 5849M\n",
      "\u001b[32m[02/02 09:23:08 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 599  total_loss: 1.931  loss_cls: 0.5523  loss_box_reg: 0.6029  loss_mask: 0.3927  loss_rpn_cls: 0.1494  loss_rpn_loc: 0.2296  time: 0.5768  data_time: 0.2649  lr: 5.994e-05  max_mem: 6083M\n",
      "\u001b[32m[02/02 09:23:25 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 619  total_loss: 1.747  loss_cls: 0.4686  loss_box_reg: 0.5664  loss_mask: 0.363  loss_rpn_cls: 0.1398  loss_rpn_loc: 0.2323  time: 0.5842  data_time: 0.4760  lr: 6.1938e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:23:36 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 639  total_loss: 1.889  loss_cls: 0.4544  loss_box_reg: 0.6327  loss_mask: 0.3757  loss_rpn_cls: 0.1411  loss_rpn_loc: 0.2268  time: 0.5835  data_time: 0.2482  lr: 6.3936e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:23:46 d2.utils.events]: \u001b[0m eta: 0:51:04  iter: 659  total_loss: 1.67  loss_cls: 0.3999  loss_box_reg: 0.6413  loss_mask: 0.3438  loss_rpn_cls: 0.1236  loss_rpn_loc: 0.2086  time: 0.5811  data_time: 0.2020  lr: 6.5934e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:23:56 d2.utils.events]: \u001b[0m eta: 0:50:51  iter: 679  total_loss: 1.733  loss_cls: 0.4852  loss_box_reg: 0.6443  loss_mask: 0.3397  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.211  time: 0.5796  data_time: 0.2249  lr: 6.7932e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:24:08 d2.utils.events]: \u001b[0m eta: 0:50:44  iter: 699  total_loss: 1.686  loss_cls: 0.4408  loss_box_reg: 0.6094  loss_mask: 0.3368  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.2178  time: 0.5790  data_time: 0.2546  lr: 6.993e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:24:19 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 719  total_loss: 1.748  loss_cls: 0.4751  loss_box_reg: 0.6433  loss_mask: 0.3315  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.2132  time: 0.5788  data_time: 0.2634  lr: 7.1928e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:24:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:24:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:24:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:24:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:24:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:24:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0653 s/iter. Eval: 0.0189 s/iter. Total: 0.0848 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 09:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0007 s/iter. Inference: 0.0670 s/iter. Eval: 0.0306 s/iter. Total: 0.0983 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 09:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0007 s/iter. Inference: 0.0669 s/iter. Eval: 0.0303 s/iter. Total: 0.0979 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/02 09:24:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.282667 (0.097264 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:24:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.066765 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:24:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:24:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.16522879787325387\n",
      "\u001b[32m[02/02 09:24:44 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 739  total_loss: 1.722  loss_cls: 0.4205  loss_box_reg: 0.6314  loss_mask: 0.3368  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2109  time: 0.5792  data_time: 0.2798  lr: 7.3926e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:24:55 d2.utils.events]: \u001b[0m eta: 0:50:24  iter: 759  total_loss: 1.695  loss_cls: 0.4151  loss_box_reg: 0.6494  loss_mask: 0.3426  loss_rpn_cls: 0.1334  loss_rpn_loc: 0.209  time: 0.5791  data_time: 0.2575  lr: 7.5924e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:25:05 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 779  total_loss: 1.701  loss_cls: 0.4558  loss_box_reg: 0.677  loss_mask: 0.3207  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.2098  time: 0.5771  data_time: 0.1953  lr: 7.7922e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:25:16 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 799  total_loss: 1.691  loss_cls: 0.422  loss_box_reg: 0.6021  loss_mask: 0.3376  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.2195  time: 0.5764  data_time: 0.2454  lr: 7.992e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:25:25 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 819  total_loss: 1.783  loss_cls: 0.4495  loss_box_reg: 0.6443  loss_mask: 0.3183  loss_rpn_cls: 0.1277  loss_rpn_loc: 0.2243  time: 0.5736  data_time: 0.1533  lr: 8.1918e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:25:34 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 839  total_loss: 1.685  loss_cls: 0.3906  loss_box_reg: 0.602  loss_mask: 0.3124  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.1981  time: 0.5702  data_time: 0.1347  lr: 8.3916e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:25:46 d2.utils.events]: \u001b[0m eta: 0:49:43  iter: 859  total_loss: 1.581  loss_cls: 0.3825  loss_box_reg: 0.5754  loss_mask: 0.3128  loss_rpn_cls: 0.1203  loss_rpn_loc: 0.2146  time: 0.5715  data_time: 0.3091  lr: 8.5914e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:25:59 d2.utils.events]: \u001b[0m eta: 0:49:39  iter: 879  total_loss: 1.715  loss_cls: 0.3809  loss_box_reg: 0.5854  loss_mask: 0.3266  loss_rpn_cls: 0.1336  loss_rpn_loc: 0.2206  time: 0.5726  data_time: 0.3027  lr: 8.7912e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:26:08 d2.utils.events]: \u001b[0m eta: 0:49:32  iter: 899  total_loss: 1.616  loss_cls: 0.3785  loss_box_reg: 0.5859  loss_mask: 0.3123  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.208  time: 0.5704  data_time: 0.1676  lr: 8.991e-05  max_mem: 6295M\n",
      "\u001b[32m[02/02 09:26:23 d2.utils.events]: \u001b[0m eta: 0:49:28  iter: 919  total_loss: 1.622  loss_cls: 0.4026  loss_box_reg: 0.5654  loss_mask: 0.3327  loss_rpn_cls: 0.1193  loss_rpn_loc: 0.2254  time: 0.5737  data_time: 0.4032  lr: 9.1908e-05  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:26:36 d2.utils.events]: \u001b[0m eta: 0:49:25  iter: 939  total_loss: 1.614  loss_cls: 0.4008  loss_box_reg: 0.5435  loss_mask: 0.331  loss_rpn_cls: 0.1289  loss_rpn_loc: 0.2328  time: 0.5759  data_time: 0.3529  lr: 9.3906e-05  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:26:46 d2.utils.events]: \u001b[0m eta: 0:49:17  iter: 959  total_loss: 1.679  loss_cls: 0.3843  loss_box_reg: 0.6113  loss_mask: 0.3262  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.2096  time: 0.5738  data_time: 0.1817  lr: 9.5904e-05  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:26:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:26:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:26:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:26:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:26:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:26:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0674 s/iter. Eval: 0.0309 s/iter. Total: 0.0989 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 09:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 56/121. Dataloading: 0.0007 s/iter. Inference: 0.0688 s/iter. Eval: 0.0421 s/iter. Total: 0.1116 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/02 09:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0007 s/iter. Inference: 0.0692 s/iter. Eval: 0.0452 s/iter. Total: 0.1152 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/02 09:27:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.998672 (0.112058 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:27:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.068793 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:27:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:27:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20141539735829964\n",
      "\u001b[32m[02/02 09:27:13 d2.utils.events]: \u001b[0m eta: 0:49:09  iter: 979  total_loss: 1.595  loss_cls: 0.3873  loss_box_reg: 0.5364  loss_mask: 0.3102  loss_rpn_cls: 0.1342  loss_rpn_loc: 0.2154  time: 0.5750  data_time: 0.3261  lr: 9.7902e-05  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:27:25 d2.utils.events]: \u001b[0m eta: 0:49:02  iter: 999  total_loss: 1.584  loss_cls: 0.3758  loss_box_reg: 0.5725  loss_mask: 0.3109  loss_rpn_cls: 0.09343  loss_rpn_loc: 0.192  time: 0.5758  data_time: 0.3031  lr: 9.99e-05  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:27:37 d2.utils.events]: \u001b[0m eta: 0:48:47  iter: 1019  total_loss: 1.625  loss_cls: 0.3947  loss_box_reg: 0.5831  loss_mask: 0.3235  loss_rpn_cls: 0.08997  loss_rpn_loc: 0.2347  time: 0.5763  data_time: 0.2955  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:27:51 d2.utils.events]: \u001b[0m eta: 0:48:49  iter: 1039  total_loss: 1.625  loss_cls: 0.3839  loss_box_reg: 0.6076  loss_mask: 0.3063  loss_rpn_cls: 0.1212  loss_rpn_loc: 0.2082  time: 0.5781  data_time: 0.3579  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:28:04 d2.utils.events]: \u001b[0m eta: 0:48:42  iter: 1059  total_loss: 1.534  loss_cls: 0.3328  loss_box_reg: 0.5612  loss_mask: 0.3157  loss_rpn_cls: 0.1288  loss_rpn_loc: 0.2293  time: 0.5796  data_time: 0.3472  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:28:14 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 1079  total_loss: 1.632  loss_cls: 0.3752  loss_box_reg: 0.6198  loss_mask: 0.3173  loss_rpn_cls: 0.1153  loss_rpn_loc: 0.2197  time: 0.5786  data_time: 0.2211  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:28:25 d2.utils.events]: \u001b[0m eta: 0:48:22  iter: 1099  total_loss: 1.603  loss_cls: 0.3759  loss_box_reg: 0.548  loss_mask: 0.3063  loss_rpn_cls: 0.1255  loss_rpn_loc: 0.2039  time: 0.5780  data_time: 0.2473  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:28:40 d2.utils.events]: \u001b[0m eta: 0:48:24  iter: 1119  total_loss: 1.69  loss_cls: 0.4465  loss_box_reg: 0.543  loss_mask: 0.3121  loss_rpn_cls: 0.1375  loss_rpn_loc: 0.2265  time: 0.5808  data_time: 0.4152  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:28:49 d2.utils.events]: \u001b[0m eta: 0:48:10  iter: 1139  total_loss: 1.64  loss_cls: 0.4049  loss_box_reg: 0.5813  loss_mask: 0.3084  loss_rpn_cls: 0.104  loss_rpn_loc: 0.2194  time: 0.5785  data_time: 0.1522  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:29:00 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 1159  total_loss: 1.585  loss_cls: 0.3894  loss_box_reg: 0.5879  loss_mask: 0.3142  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.1882  time: 0.5779  data_time: 0.2380  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:29:14 d2.utils.events]: \u001b[0m eta: 0:48:07  iter: 1179  total_loss: 1.607  loss_cls: 0.3755  loss_box_reg: 0.5611  loss_mask: 0.3198  loss_rpn_cls: 0.126  loss_rpn_loc: 0.2117  time: 0.5798  data_time: 0.3635  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:29:24 d2.utils.events]: \u001b[0m eta: 0:48:01  iter: 1199  total_loss: 1.599  loss_cls: 0.3588  loss_box_reg: 0.5507  loss_mask: 0.3149  loss_rpn_cls: 0.08754  loss_rpn_loc: 0.2201  time: 0.5792  data_time: 0.2312  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:29:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:29:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:29:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:29:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:29:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:29:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0669 s/iter. Eval: 0.0281 s/iter. Total: 0.0956 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 09:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 54/121. Dataloading: 0.0007 s/iter. Inference: 0.0693 s/iter. Eval: 0.0460 s/iter. Total: 0.1160 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/02 09:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0007 s/iter. Inference: 0.0696 s/iter. Eval: 0.0490 s/iter. Total: 0.1193 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 09:29:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.588338 (0.117141 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:29:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069311 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:29:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:29:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21831890881541385\n",
      "\u001b[32m[02/02 09:29:49 d2.utils.events]: \u001b[0m eta: 0:48:00  iter: 1219  total_loss: 1.709  loss_cls: 0.4068  loss_box_reg: 0.5953  loss_mask: 0.3339  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.2181  time: 0.5775  data_time: 0.1744  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:30:01 d2.utils.events]: \u001b[0m eta: 0:47:53  iter: 1239  total_loss: 1.581  loss_cls: 0.3995  loss_box_reg: 0.5487  loss_mask: 0.3006  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2015  time: 0.5781  data_time: 0.3083  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:30:13 d2.utils.events]: \u001b[0m eta: 0:47:49  iter: 1259  total_loss: 1.587  loss_cls: 0.3793  loss_box_reg: 0.5548  loss_mask: 0.2995  loss_rpn_cls: 0.112  loss_rpn_loc: 0.2124  time: 0.5784  data_time: 0.2892  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:30:23 d2.utils.events]: \u001b[0m eta: 0:47:43  iter: 1279  total_loss: 1.524  loss_cls: 0.3491  loss_box_reg: 0.5827  loss_mask: 0.3066  loss_rpn_cls: 0.08859  loss_rpn_loc: 0.1946  time: 0.5774  data_time: 0.2040  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:30:35 d2.utils.events]: \u001b[0m eta: 0:47:37  iter: 1299  total_loss: 1.575  loss_cls: 0.3633  loss_box_reg: 0.5373  loss_mask: 0.3202  loss_rpn_cls: 0.1213  loss_rpn_loc: 0.2123  time: 0.5772  data_time: 0.2517  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:30:47 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 1319  total_loss: 1.588  loss_cls: 0.3511  loss_box_reg: 0.5522  loss_mask: 0.3264  loss_rpn_cls: 0.1258  loss_rpn_loc: 0.2199  time: 0.5776  data_time: 0.2851  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:30:59 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 1339  total_loss: 1.671  loss_cls: 0.3997  loss_box_reg: 0.592  loss_mask: 0.3306  loss_rpn_cls: 0.147  loss_rpn_loc: 0.2165  time: 0.5782  data_time: 0.3146  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:31:10 d2.utils.events]: \u001b[0m eta: 0:47:17  iter: 1359  total_loss: 1.443  loss_cls: 0.2993  loss_box_reg: 0.5279  loss_mask: 0.3009  loss_rpn_cls: 0.0917  loss_rpn_loc: 0.1777  time: 0.5773  data_time: 0.2191  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:31:22 d2.utils.events]: \u001b[0m eta: 0:47:07  iter: 1379  total_loss: 1.535  loss_cls: 0.3612  loss_box_reg: 0.5347  loss_mask: 0.3107  loss_rpn_cls: 0.09731  loss_rpn_loc: 0.2029  time: 0.5778  data_time: 0.3012  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:31:34 d2.utils.events]: \u001b[0m eta: 0:47:03  iter: 1399  total_loss: 1.714  loss_cls: 0.4112  loss_box_reg: 0.5832  loss_mask: 0.3216  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.2287  time: 0.5787  data_time: 0.3302  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:31:45 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 1419  total_loss: 1.541  loss_cls: 0.3635  loss_box_reg: 0.5737  loss_mask: 0.3006  loss_rpn_cls: 0.0964  loss_rpn_loc: 0.2009  time: 0.5778  data_time: 0.2076  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:31:59 d2.utils.events]: \u001b[0m eta: 0:46:50  iter: 1439  total_loss: 1.58  loss_cls: 0.3628  loss_box_reg: 0.5471  loss_mask: 0.3207  loss_rpn_cls: 0.09294  loss_rpn_loc: 0.2287  time: 0.5795  data_time: 0.3740  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:32:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:32:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:32:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:32:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:32:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:32:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:32:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0673 s/iter. Eval: 0.0313 s/iter. Total: 0.0992 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 09:32:13 d2.evaluation.evaluator]: \u001b[0mInference done 54/121. Dataloading: 0.0007 s/iter. Inference: 0.0692 s/iter. Eval: 0.0459 s/iter. Total: 0.1159 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/02 09:32:18 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0007 s/iter. Inference: 0.0696 s/iter. Eval: 0.0484 s/iter. Total: 0.1187 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 09:32:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.558794 (0.116886 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:32:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069334 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:32:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:32:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22765863049420668\n",
      "\u001b[32m[02/02 09:32:23 d2.utils.events]: \u001b[0m eta: 0:46:43  iter: 1459  total_loss: 1.588  loss_cls: 0.3967  loss_box_reg: 0.6106  loss_mask: 0.3029  loss_rpn_cls: 0.09026  loss_rpn_loc: 0.1856  time: 0.5778  data_time: 0.1573  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:32:37 d2.utils.events]: \u001b[0m eta: 0:46:37  iter: 1479  total_loss: 1.535  loss_cls: 0.3673  loss_box_reg: 0.5524  loss_mask: 0.333  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.2149  time: 0.5798  data_time: 0.4081  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:32:49 d2.utils.events]: \u001b[0m eta: 0:46:31  iter: 1499  total_loss: 1.539  loss_cls: 0.346  loss_box_reg: 0.5501  loss_mask: 0.3165  loss_rpn_cls: 0.08986  loss_rpn_loc: 0.2006  time: 0.5795  data_time: 0.2454  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:32:58 d2.utils.events]: \u001b[0m eta: 0:46:23  iter: 1519  total_loss: 1.493  loss_cls: 0.3849  loss_box_reg: 0.5591  loss_mask: 0.303  loss_rpn_cls: 0.1176  loss_rpn_loc: 0.1932  time: 0.5782  data_time: 0.1870  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:33:11 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 1539  total_loss: 1.465  loss_cls: 0.3329  loss_box_reg: 0.5368  loss_mask: 0.3074  loss_rpn_cls: 0.09505  loss_rpn_loc: 0.2054  time: 0.5789  data_time: 0.3283  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:33:21 d2.utils.events]: \u001b[0m eta: 0:46:05  iter: 1559  total_loss: 1.611  loss_cls: 0.3706  loss_box_reg: 0.5694  loss_mask: 0.3097  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.2025  time: 0.5780  data_time: 0.2078  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:33:34 d2.utils.events]: \u001b[0m eta: 0:45:55  iter: 1579  total_loss: 1.583  loss_cls: 0.3588  loss_box_reg: 0.5836  loss_mask: 0.3121  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.2145  time: 0.5789  data_time: 0.3305  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:33:44 d2.utils.events]: \u001b[0m eta: 0:45:39  iter: 1599  total_loss: 1.517  loss_cls: 0.3695  loss_box_reg: 0.5634  loss_mask: 0.3085  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.2057  time: 0.5779  data_time: 0.1948  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:33:57 d2.utils.events]: \u001b[0m eta: 0:45:33  iter: 1619  total_loss: 1.494  loss_cls: 0.3706  loss_box_reg: 0.5441  loss_mask: 0.302  loss_rpn_cls: 0.08914  loss_rpn_loc: 0.2053  time: 0.5788  data_time: 0.3395  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:34:11 d2.utils.events]: \u001b[0m eta: 0:45:20  iter: 1639  total_loss: 1.732  loss_cls: 0.4095  loss_box_reg: 0.5692  loss_mask: 0.3479  loss_rpn_cls: 0.1497  loss_rpn_loc: 0.2252  time: 0.5803  data_time: 0.3776  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:34:22 d2.utils.events]: \u001b[0m eta: 0:45:13  iter: 1659  total_loss: 1.552  loss_cls: 0.3686  loss_box_reg: 0.5298  loss_mask: 0.3038  loss_rpn_cls: 0.09857  loss_rpn_loc: 0.2017  time: 0.5799  data_time: 0.2332  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:34:33 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 1679  total_loss: 1.468  loss_cls: 0.3407  loss_box_reg: 0.5336  loss_mask: 0.2971  loss_rpn_cls: 0.0764  loss_rpn_loc: 0.2103  time: 0.5795  data_time: 0.2410  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:34:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:34:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:34:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:34:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:34:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:34:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0349 s/iter. Total: 0.1036 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0533 s/iter. Total: 0.1243 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0557 s/iter. Total: 0.1271 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 09:34:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.581366 (0.125701 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:34:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070400 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:34:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:34:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23494410183029624\n",
      "\u001b[32m[02/02 09:35:02 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 1699  total_loss: 1.568  loss_cls: 0.3571  loss_box_reg: 0.5663  loss_mask: 0.3087  loss_rpn_cls: 0.08806  loss_rpn_loc: 0.2426  time: 0.5801  data_time: 0.3099  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:35:14 d2.utils.events]: \u001b[0m eta: 0:44:59  iter: 1719  total_loss: 1.471  loss_cls: 0.3204  loss_box_reg: 0.5381  loss_mask: 0.2906  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2197  time: 0.5808  data_time: 0.3228  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:35:26 d2.utils.events]: \u001b[0m eta: 0:44:54  iter: 1739  total_loss: 1.58  loss_cls: 0.3801  loss_box_reg: 0.5716  loss_mask: 0.3064  loss_rpn_cls: 0.0731  loss_rpn_loc: 0.2149  time: 0.5809  data_time: 0.2838  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:35:38 d2.utils.events]: \u001b[0m eta: 0:44:49  iter: 1759  total_loss: 1.571  loss_cls: 0.3876  loss_box_reg: 0.5459  loss_mask: 0.3194  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2204  time: 0.5811  data_time: 0.2805  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:35:50 d2.utils.events]: \u001b[0m eta: 0:44:48  iter: 1779  total_loss: 1.545  loss_cls: 0.337  loss_box_reg: 0.5548  loss_mask: 0.3124  loss_rpn_cls: 0.09253  loss_rpn_loc: 0.2061  time: 0.5814  data_time: 0.2947  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:36:04 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 1799  total_loss: 1.598  loss_cls: 0.3693  loss_box_reg: 0.5481  loss_mask: 0.325  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.217  time: 0.5825  data_time: 0.3546  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:36:14 d2.utils.events]: \u001b[0m eta: 0:44:48  iter: 1819  total_loss: 1.576  loss_cls: 0.4165  loss_box_reg: 0.5544  loss_mask: 0.2943  loss_rpn_cls: 0.09931  loss_rpn_loc: 0.2027  time: 0.5818  data_time: 0.1974  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:36:26 d2.utils.events]: \u001b[0m eta: 0:44:43  iter: 1839  total_loss: 1.635  loss_cls: 0.3983  loss_box_reg: 0.5721  loss_mask: 0.2943  loss_rpn_cls: 0.09179  loss_rpn_loc: 0.2003  time: 0.5818  data_time: 0.2708  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:36:38 d2.utils.events]: \u001b[0m eta: 0:44:36  iter: 1859  total_loss: 1.507  loss_cls: 0.3437  loss_box_reg: 0.5308  loss_mask: 0.3179  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.1964  time: 0.5822  data_time: 0.3073  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:36:49 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 1879  total_loss: 1.514  loss_cls: 0.3679  loss_box_reg: 0.5669  loss_mask: 0.309  loss_rpn_cls: 0.08918  loss_rpn_loc: 0.2013  time: 0.5815  data_time: 0.2100  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:37:02 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 1899  total_loss: 1.585  loss_cls: 0.3653  loss_box_reg: 0.5184  loss_mask: 0.2978  loss_rpn_cls: 0.09283  loss_rpn_loc: 0.2002  time: 0.5823  data_time: 0.3453  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:37:11 d2.utils.events]: \u001b[0m eta: 0:44:01  iter: 1919  total_loss: 1.525  loss_cls: 0.3575  loss_box_reg: 0.5573  loss_mask: 0.3071  loss_rpn_cls: 0.08725  loss_rpn_loc: 0.2028  time: 0.5811  data_time: 0.1621  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:37:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:37:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:37:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:37:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:37:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:37:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:37:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0339 s/iter. Total: 0.1022 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:37:25 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0696 s/iter. Eval: 0.0491 s/iter. Total: 0.1195 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:37:30 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0525 s/iter. Total: 0.1234 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 09:37:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.975359 (0.120477 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:37:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069769 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:37:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:37:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23882302755067528\n",
      "\u001b[32m[02/02 09:37:34 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 1939  total_loss: 1.441  loss_cls: 0.3283  loss_box_reg: 0.5726  loss_mask: 0.3188  loss_rpn_cls: 0.08639  loss_rpn_loc: 0.1904  time: 0.5791  data_time: 0.0877  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:37:44 d2.utils.events]: \u001b[0m eta: 0:43:38  iter: 1959  total_loss: 1.504  loss_cls: 0.341  loss_box_reg: 0.5489  loss_mask: 0.3158  loss_rpn_cls: 0.07639  loss_rpn_loc: 0.1958  time: 0.5782  data_time: 0.1933  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:37:54 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 1979  total_loss: 1.512  loss_cls: 0.3481  loss_box_reg: 0.5186  loss_mask: 0.2945  loss_rpn_cls: 0.07862  loss_rpn_loc: 0.194  time: 0.5773  data_time: 0.1814  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:38:07 d2.utils.events]: \u001b[0m eta: 0:43:29  iter: 1999  total_loss: 1.474  loss_cls: 0.3421  loss_box_reg: 0.544  loss_mask: 0.2998  loss_rpn_cls: 0.08191  loss_rpn_loc: 0.1999  time: 0.5780  data_time: 0.3366  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:38:16 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 2019  total_loss: 1.581  loss_cls: 0.3654  loss_box_reg: 0.5774  loss_mask: 0.3061  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2231  time: 0.5770  data_time: 0.1716  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:38:31 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 2039  total_loss: 1.563  loss_cls: 0.3926  loss_box_reg: 0.5302  loss_mask: 0.3162  loss_rpn_cls: 0.12  loss_rpn_loc: 0.2141  time: 0.5785  data_time: 0.4128  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:38:43 d2.utils.events]: \u001b[0m eta: 0:43:07  iter: 2059  total_loss: 1.562  loss_cls: 0.3115  loss_box_reg: 0.5483  loss_mask: 0.3085  loss_rpn_cls: 0.08309  loss_rpn_loc: 0.1984  time: 0.5785  data_time: 0.2684  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:38:55 d2.utils.events]: \u001b[0m eta: 0:43:02  iter: 2079  total_loss: 1.65  loss_cls: 0.413  loss_box_reg: 0.5795  loss_mask: 0.3099  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2268  time: 0.5790  data_time: 0.3062  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:39:05 d2.utils.events]: \u001b[0m eta: 0:42:54  iter: 2099  total_loss: 1.393  loss_cls: 0.3364  loss_box_reg: 0.539  loss_mask: 0.3126  loss_rpn_cls: 0.0912  loss_rpn_loc: 0.2036  time: 0.5784  data_time: 0.2102  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:39:18 d2.utils.events]: \u001b[0m eta: 0:42:46  iter: 2119  total_loss: 1.559  loss_cls: 0.3697  loss_box_reg: 0.5662  loss_mask: 0.3204  loss_rpn_cls: 0.09788  loss_rpn_loc: 0.1998  time: 0.5788  data_time: 0.3053  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:39:32 d2.utils.events]: \u001b[0m eta: 0:42:46  iter: 2139  total_loss: 1.493  loss_cls: 0.3515  loss_box_reg: 0.5071  loss_mask: 0.3008  loss_rpn_cls: 0.1227  loss_rpn_loc: 0.2227  time: 0.5799  data_time: 0.3846  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:39:45 d2.utils.events]: \u001b[0m eta: 0:42:47  iter: 2159  total_loss: 1.51  loss_cls: 0.3807  loss_box_reg: 0.526  loss_mask: 0.3162  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.2086  time: 0.5805  data_time: 0.3294  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:39:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:39:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:39:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:39:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:39:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:39:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:39:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0671 s/iter. Eval: 0.0313 s/iter. Total: 0.0989 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 09:40:01 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.0504 s/iter. Total: 0.1210 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:40:06 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0548 s/iter. Total: 0.1260 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 09:40:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.358032 (0.123776 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:40:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070120 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:40:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:40:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2395190269252722\n",
      "\u001b[32m[02/02 09:40:10 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 2179  total_loss: 1.671  loss_cls: 0.3764  loss_box_reg: 0.541  loss_mask: 0.3095  loss_rpn_cls: 0.09196  loss_rpn_loc: 0.2289  time: 0.5796  data_time: 0.1780  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:40:19 d2.utils.events]: \u001b[0m eta: 0:42:20  iter: 2199  total_loss: 1.725  loss_cls: 0.4256  loss_box_reg: 0.551  loss_mask: 0.3203  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.2197  time: 0.5782  data_time: 0.1242  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:40:28 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 2219  total_loss: 1.471  loss_cls: 0.3734  loss_box_reg: 0.523  loss_mask: 0.2943  loss_rpn_cls: 0.08686  loss_rpn_loc: 0.1946  time: 0.5770  data_time: 0.1452  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:40:39 d2.utils.events]: \u001b[0m eta: 0:42:02  iter: 2239  total_loss: 1.506  loss_cls: 0.3533  loss_box_reg: 0.5332  loss_mask: 0.3039  loss_rpn_cls: 0.0793  loss_rpn_loc: 0.2072  time: 0.5767  data_time: 0.2481  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:40:52 d2.utils.events]: \u001b[0m eta: 0:41:56  iter: 2259  total_loss: 1.524  loss_cls: 0.3305  loss_box_reg: 0.5057  loss_mask: 0.3049  loss_rpn_cls: 0.09754  loss_rpn_loc: 0.2161  time: 0.5778  data_time: 0.3731  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:41:05 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 2279  total_loss: 1.568  loss_cls: 0.3723  loss_box_reg: 0.5406  loss_mask: 0.2964  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.2181  time: 0.5782  data_time: 0.3043  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:41:14 d2.utils.events]: \u001b[0m eta: 0:41:40  iter: 2299  total_loss: 1.457  loss_cls: 0.3289  loss_box_reg: 0.5282  loss_mask: 0.3035  loss_rpn_cls: 0.09838  loss_rpn_loc: 0.1917  time: 0.5772  data_time: 0.1616  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:41:32 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 2319  total_loss: 1.627  loss_cls: 0.3464  loss_box_reg: 0.5322  loss_mask: 0.3242  loss_rpn_cls: 0.148  loss_rpn_loc: 0.2353  time: 0.5799  data_time: 0.5630  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:41:42 d2.utils.events]: \u001b[0m eta: 0:41:29  iter: 2339  total_loss: 1.51  loss_cls: 0.3595  loss_box_reg: 0.5409  loss_mask: 0.3091  loss_rpn_cls: 0.08757  loss_rpn_loc: 0.2096  time: 0.5792  data_time: 0.2005  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:41:53 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 2359  total_loss: 1.436  loss_cls: 0.3445  loss_box_reg: 0.5476  loss_mask: 0.2908  loss_rpn_cls: 0.08648  loss_rpn_loc: 0.1895  time: 0.5789  data_time: 0.2347  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:42:04 d2.utils.events]: \u001b[0m eta: 0:41:20  iter: 2379  total_loss: 1.478  loss_cls: 0.3154  loss_box_reg: 0.5514  loss_mask: 0.313  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.2072  time: 0.5788  data_time: 0.2486  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:42:14 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 2399  total_loss: 1.481  loss_cls: 0.315  loss_box_reg: 0.5582  loss_mask: 0.2909  loss_rpn_cls: 0.07387  loss_rpn_loc: 0.1955  time: 0.5781  data_time: 0.1852  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:42:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:42:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:42:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:42:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:42:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:42:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0358 s/iter. Total: 0.1045 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0533 s/iter. Total: 0.1244 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0562 s/iter. Total: 0.1277 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 09:42:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.648059 (0.126276 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:42:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070534 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:42:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:42:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2469230542113812\n",
      "\u001b[32m[02/02 09:42:45 d2.utils.events]: \u001b[0m eta: 0:41:06  iter: 2419  total_loss: 1.561  loss_cls: 0.3562  loss_box_reg: 0.5599  loss_mask: 0.3253  loss_rpn_cls: 0.1187  loss_rpn_loc: 0.2239  time: 0.5793  data_time: 0.4023  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:42:56 d2.utils.events]: \u001b[0m eta: 0:40:59  iter: 2439  total_loss: 1.513  loss_cls: 0.3449  loss_box_reg: 0.5324  loss_mask: 0.3254  loss_rpn_cls: 0.09054  loss_rpn_loc: 0.2113  time: 0.5790  data_time: 0.2183  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:43:05 d2.utils.events]: \u001b[0m eta: 0:40:53  iter: 2459  total_loss: 1.458  loss_cls: 0.3582  loss_box_reg: 0.5376  loss_mask: 0.3102  loss_rpn_cls: 0.09352  loss_rpn_loc: 0.195  time: 0.5781  data_time: 0.1793  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:43:18 d2.utils.events]: \u001b[0m eta: 0:40:47  iter: 2479  total_loss: 1.51  loss_cls: 0.3651  loss_box_reg: 0.5074  loss_mask: 0.3073  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.2045  time: 0.5787  data_time: 0.3307  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:43:31 d2.utils.events]: \u001b[0m eta: 0:40:38  iter: 2499  total_loss: 1.557  loss_cls: 0.3645  loss_box_reg: 0.5356  loss_mask: 0.3011  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2087  time: 0.5793  data_time: 0.3386  lr: 0.0001  max_mem: 6352M\n",
      "\u001b[32m[02/02 09:43:45 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 2519  total_loss: 1.512  loss_cls: 0.3216  loss_box_reg: 0.5387  loss_mask: 0.315  loss_rpn_cls: 0.08018  loss_rpn_loc: 0.2034  time: 0.5804  data_time: 0.4035  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:43:57 d2.utils.events]: \u001b[0m eta: 0:40:28  iter: 2539  total_loss: 1.502  loss_cls: 0.3762  loss_box_reg: 0.5768  loss_mask: 0.3107  loss_rpn_cls: 0.08696  loss_rpn_loc: 0.1941  time: 0.5804  data_time: 0.2605  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:44:08 d2.utils.events]: \u001b[0m eta: 0:40:21  iter: 2559  total_loss: 1.43  loss_cls: 0.2981  loss_box_reg: 0.5399  loss_mask: 0.3144  loss_rpn_cls: 0.0691  loss_rpn_loc: 0.1908  time: 0.5803  data_time: 0.2624  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:44:18 d2.utils.events]: \u001b[0m eta: 0:40:14  iter: 2579  total_loss: 1.502  loss_cls: 0.3598  loss_box_reg: 0.5519  loss_mask: 0.3001  loss_rpn_cls: 0.09095  loss_rpn_loc: 0.1953  time: 0.5797  data_time: 0.1921  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:44:30 d2.utils.events]: \u001b[0m eta: 0:40:12  iter: 2599  total_loss: 1.563  loss_cls: 0.3547  loss_box_reg: 0.565  loss_mask: 0.3076  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.1956  time: 0.5798  data_time: 0.2761  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:44:41 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 2619  total_loss: 1.454  loss_cls: 0.3391  loss_box_reg: 0.5231  loss_mask: 0.3102  loss_rpn_cls: 0.07461  loss_rpn_loc: 0.1772  time: 0.5795  data_time: 0.2444  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:44:53 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 2639  total_loss: 1.485  loss_cls: 0.3107  loss_box_reg: 0.5195  loss_mask: 0.3019  loss_rpn_cls: 0.08808  loss_rpn_loc: 0.2052  time: 0.5794  data_time: 0.2595  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:45:04 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 2659  total_loss: 1.565  loss_cls: 0.3879  loss_box_reg: 0.5614  loss_mask: 0.3107  loss_rpn_cls: 0.09827  loss_rpn_loc: 0.2165  time: 0.5793  data_time: 0.2504  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:45:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:45:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:45:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:45:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:45:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:45:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0352 s/iter. Total: 0.1035 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0535 s/iter. Total: 0.1246 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0560 s/iter. Total: 0.1275 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 09:45:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.615611 (0.125997 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:45:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070501 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:45:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:45:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2513982548213651\n",
      "\u001b[32m[02/02 09:45:27 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 2679  total_loss: 1.467  loss_cls: 0.3468  loss_box_reg: 0.5775  loss_mask: 0.3025  loss_rpn_cls: 0.0864  loss_rpn_loc: 0.1748  time: 0.5777  data_time: 0.0710  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:45:39 d2.utils.events]: \u001b[0m eta: 0:39:36  iter: 2699  total_loss: 1.386  loss_cls: 0.2948  loss_box_reg: 0.5205  loss_mask: 0.3086  loss_rpn_cls: 0.09132  loss_rpn_loc: 0.188  time: 0.5778  data_time: 0.2894  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:45:55 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 2719  total_loss: 1.505  loss_cls: 0.3829  loss_box_reg: 0.5192  loss_mask: 0.2967  loss_rpn_cls: 0.08876  loss_rpn_loc: 0.2149  time: 0.5795  data_time: 0.4804  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:46:05 d2.utils.events]: \u001b[0m eta: 0:39:25  iter: 2739  total_loss: 1.625  loss_cls: 0.4037  loss_box_reg: 0.5706  loss_mask: 0.3174  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.2129  time: 0.5787  data_time: 0.1700  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:46:14 d2.utils.events]: \u001b[0m eta: 0:39:15  iter: 2759  total_loss: 1.548  loss_cls: 0.3767  loss_box_reg: 0.5387  loss_mask: 0.307  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.2093  time: 0.5781  data_time: 0.1868  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:46:22 d2.utils.events]: \u001b[0m eta: 0:39:05  iter: 2779  total_loss: 1.457  loss_cls: 0.3456  loss_box_reg: 0.57  loss_mask: 0.3021  loss_rpn_cls: 0.05601  loss_rpn_loc: 0.193  time: 0.5766  data_time: 0.0799  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:46:31 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 2799  total_loss: 1.441  loss_cls: 0.351  loss_box_reg: 0.5602  loss_mask: 0.3054  loss_rpn_cls: 0.09554  loss_rpn_loc: 0.2063  time: 0.5757  data_time: 0.1505  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:46:45 d2.utils.events]: \u001b[0m eta: 0:38:54  iter: 2819  total_loss: 1.652  loss_cls: 0.406  loss_box_reg: 0.5514  loss_mask: 0.3105  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2108  time: 0.5765  data_time: 0.3698  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:46:59 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 2839  total_loss: 1.598  loss_cls: 0.3707  loss_box_reg: 0.5229  loss_mask: 0.3062  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.2202  time: 0.5776  data_time: 0.4068  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:47:14 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 2859  total_loss: 1.463  loss_cls: 0.3162  loss_box_reg: 0.5222  loss_mask: 0.3036  loss_rpn_cls: 0.08091  loss_rpn_loc: 0.2037  time: 0.5787  data_time: 0.4179  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:47:24 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 2879  total_loss: 1.438  loss_cls: 0.3134  loss_box_reg: 0.5418  loss_mask: 0.3082  loss_rpn_cls: 0.08855  loss_rpn_loc: 0.1893  time: 0.5783  data_time: 0.2094  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:47:37 d2.utils.events]: \u001b[0m eta: 0:38:32  iter: 2899  total_loss: 1.487  loss_cls: 0.3492  loss_box_reg: 0.5447  loss_mask: 0.3  loss_rpn_cls: 0.07898  loss_rpn_loc: 0.2142  time: 0.5786  data_time: 0.3129  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:47:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:47:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:47:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:47:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:47:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:47:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0347 s/iter. Total: 0.1033 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0528 s/iter. Total: 0.1238 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0560 s/iter. Total: 0.1274 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 09:47:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.581920 (0.125706 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:47:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070381 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:47:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:47:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2504441342506244\n",
      "\u001b[32m[02/02 09:48:03 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 2919  total_loss: 1.406  loss_cls: 0.2918  loss_box_reg: 0.5254  loss_mask: 0.3026  loss_rpn_cls: 0.08069  loss_rpn_loc: 0.2025  time: 0.5782  data_time: 0.1965  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:48:15 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 2939  total_loss: 1.354  loss_cls: 0.2949  loss_box_reg: 0.4852  loss_mask: 0.2994  loss_rpn_cls: 0.08017  loss_rpn_loc: 0.2068  time: 0.5781  data_time: 0.2622  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:48:24 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 2959  total_loss: 1.44  loss_cls: 0.3167  loss_box_reg: 0.5476  loss_mask: 0.3042  loss_rpn_cls: 0.09026  loss_rpn_loc: 0.2095  time: 0.5773  data_time: 0.1690  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:48:34 d2.utils.events]: \u001b[0m eta: 0:38:12  iter: 2979  total_loss: 1.467  loss_cls: 0.3578  loss_box_reg: 0.5412  loss_mask: 0.307  loss_rpn_cls: 0.07677  loss_rpn_loc: 0.2063  time: 0.5768  data_time: 0.1971  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:48:43 d2.utils.events]: \u001b[0m eta: 0:38:02  iter: 2999  total_loss: 1.482  loss_cls: 0.3159  loss_box_reg: 0.5385  loss_mask: 0.2912  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1895  time: 0.5761  data_time: 0.1737  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:48:54 d2.utils.events]: \u001b[0m eta: 0:37:54  iter: 3019  total_loss: 1.496  loss_cls: 0.3153  loss_box_reg: 0.5625  loss_mask: 0.3073  loss_rpn_cls: 0.08102  loss_rpn_loc: 0.1973  time: 0.5758  data_time: 0.2334  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:49:04 d2.utils.events]: \u001b[0m eta: 0:37:42  iter: 3039  total_loss: 1.378  loss_cls: 0.3339  loss_box_reg: 0.5223  loss_mask: 0.2881  loss_rpn_cls: 0.09098  loss_rpn_loc: 0.2145  time: 0.5752  data_time: 0.1709  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:49:16 d2.utils.events]: \u001b[0m eta: 0:37:42  iter: 3059  total_loss: 1.587  loss_cls: 0.3985  loss_box_reg: 0.5705  loss_mask: 0.3063  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.222  time: 0.5755  data_time: 0.3023  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:49:28 d2.utils.events]: \u001b[0m eta: 0:37:35  iter: 3079  total_loss: 1.425  loss_cls: 0.3234  loss_box_reg: 0.5133  loss_mask: 0.299  loss_rpn_cls: 0.08228  loss_rpn_loc: 0.1974  time: 0.5756  data_time: 0.2770  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:49:40 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 3099  total_loss: 1.51  loss_cls: 0.3772  loss_box_reg: 0.519  loss_mask: 0.3173  loss_rpn_cls: 0.0828  loss_rpn_loc: 0.2032  time: 0.5759  data_time: 0.3115  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:49:57 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 3119  total_loss: 1.497  loss_cls: 0.3591  loss_box_reg: 0.4845  loss_mask: 0.3074  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.1944  time: 0.5776  data_time: 0.4915  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:50:12 d2.utils.events]: \u001b[0m eta: 0:37:21  iter: 3139  total_loss: 1.491  loss_cls: 0.3771  loss_box_reg: 0.4926  loss_mask: 0.3067  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.1854  time: 0.5786  data_time: 0.4077  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:50:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:50:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:50:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:50:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:50:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:50:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0366 s/iter. Total: 0.1055 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:50:23 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0519 s/iter. Total: 0.1229 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:50:28 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0544 s/iter. Total: 0.1256 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 09:50:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.465530 (0.124703 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:50:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070340 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:50:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:50:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24981185730784514\n",
      "\u001b[32m[02/02 09:50:38 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 3159  total_loss: 1.469  loss_cls: 0.3425  loss_box_reg: 0.5404  loss_mask: 0.3178  loss_rpn_cls: 0.07101  loss_rpn_loc: 0.2013  time: 0.5783  data_time: 0.2260  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:50:51 d2.utils.events]: \u001b[0m eta: 0:37:06  iter: 3179  total_loss: 1.401  loss_cls: 0.3066  loss_box_reg: 0.5214  loss_mask: 0.3006  loss_rpn_cls: 0.0876  loss_rpn_loc: 0.1877  time: 0.5787  data_time: 0.3246  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:51:02 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 3199  total_loss: 1.496  loss_cls: 0.3469  loss_box_reg: 0.5605  loss_mask: 0.3097  loss_rpn_cls: 0.08732  loss_rpn_loc: 0.2095  time: 0.5784  data_time: 0.2297  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:51:13 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 3219  total_loss: 1.341  loss_cls: 0.3006  loss_box_reg: 0.5034  loss_mask: 0.301  loss_rpn_cls: 0.06325  loss_rpn_loc: 0.1834  time: 0.5782  data_time: 0.2501  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:51:26 d2.utils.events]: \u001b[0m eta: 0:36:47  iter: 3239  total_loss: 1.444  loss_cls: 0.3272  loss_box_reg: 0.5302  loss_mask: 0.3188  loss_rpn_cls: 0.06984  loss_rpn_loc: 0.1833  time: 0.5787  data_time: 0.3470  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:51:39 d2.utils.events]: \u001b[0m eta: 0:36:41  iter: 3259  total_loss: 1.593  loss_cls: 0.3887  loss_box_reg: 0.5304  loss_mask: 0.3158  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.2194  time: 0.5792  data_time: 0.3371  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:51:54 d2.utils.events]: \u001b[0m eta: 0:36:36  iter: 3279  total_loss: 1.586  loss_cls: 0.3701  loss_box_reg: 0.527  loss_mask: 0.2977  loss_rpn_cls: 0.1297  loss_rpn_loc: 0.2299  time: 0.5801  data_time: 0.3933  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:52:08 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 3299  total_loss: 1.551  loss_cls: 0.3607  loss_box_reg: 0.5072  loss_mask: 0.3074  loss_rpn_cls: 0.09644  loss_rpn_loc: 0.2116  time: 0.5809  data_time: 0.3922  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:52:20 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 3319  total_loss: 1.442  loss_cls: 0.3374  loss_box_reg: 0.5197  loss_mask: 0.3044  loss_rpn_cls: 0.08137  loss_rpn_loc: 0.1945  time: 0.5810  data_time: 0.2844  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:52:32 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 3339  total_loss: 1.512  loss_cls: 0.3716  loss_box_reg: 0.5529  loss_mask: 0.3128  loss_rpn_cls: 0.09843  loss_rpn_loc: 0.2061  time: 0.5811  data_time: 0.2833  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:52:44 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 3359  total_loss: 1.524  loss_cls: 0.3363  loss_box_reg: 0.5556  loss_mask: 0.3083  loss_rpn_cls: 0.0765  loss_rpn_loc: 0.2084  time: 0.5812  data_time: 0.2940  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:52:56 d2.utils.events]: \u001b[0m eta: 0:36:02  iter: 3379  total_loss: 1.353  loss_cls: 0.3105  loss_box_reg: 0.5146  loss_mask: 0.2919  loss_rpn_cls: 0.04753  loss_rpn_loc: 0.1769  time: 0.5812  data_time: 0.2747  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:53:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:53:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:53:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:53:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:53:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:53:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.0356 s/iter. Total: 0.1045 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0526 s/iter. Total: 0.1236 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0549 s/iter. Total: 0.1262 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 09:53:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.505240 (0.125045 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:53:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070389 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:53:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:53:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2517613996936377\n",
      "\u001b[32m[02/02 09:53:24 d2.utils.events]: \u001b[0m eta: 0:35:59  iter: 3399  total_loss: 1.569  loss_cls: 0.393  loss_box_reg: 0.5562  loss_mask: 0.3121  loss_rpn_cls: 0.09755  loss_rpn_loc: 0.2031  time: 0.5814  data_time: 0.2769  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:53:35 d2.utils.events]: \u001b[0m eta: 0:35:50  iter: 3419  total_loss: 1.516  loss_cls: 0.3564  loss_box_reg: 0.5073  loss_mask: 0.2974  loss_rpn_cls: 0.08749  loss_rpn_loc: 0.2154  time: 0.5814  data_time: 0.2825  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:53:46 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 3439  total_loss: 1.51  loss_cls: 0.3555  loss_box_reg: 0.5302  loss_mask: 0.311  loss_rpn_cls: 0.09353  loss_rpn_loc: 0.2241  time: 0.5812  data_time: 0.2278  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:53:56 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 3459  total_loss: 1.546  loss_cls: 0.3462  loss_box_reg: 0.5766  loss_mask: 0.3036  loss_rpn_cls: 0.08025  loss_rpn_loc: 0.1912  time: 0.5806  data_time: 0.1747  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:54:07 d2.utils.events]: \u001b[0m eta: 0:35:29  iter: 3479  total_loss: 1.466  loss_cls: 0.297  loss_box_reg: 0.5134  loss_mask: 0.3027  loss_rpn_cls: 0.1191  loss_rpn_loc: 0.2321  time: 0.5804  data_time: 0.2308  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:54:17 d2.utils.events]: \u001b[0m eta: 0:35:22  iter: 3499  total_loss: 1.532  loss_cls: 0.3278  loss_box_reg: 0.5561  loss_mask: 0.3077  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.2034  time: 0.5799  data_time: 0.1862  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:54:25 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 3519  total_loss: 1.353  loss_cls: 0.294  loss_box_reg: 0.5207  loss_mask: 0.3055  loss_rpn_cls: 0.04823  loss_rpn_loc: 0.1795  time: 0.5790  data_time: 0.1331  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:54:41 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 3539  total_loss: 1.512  loss_cls: 0.3181  loss_box_reg: 0.535  loss_mask: 0.3165  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2185  time: 0.5802  data_time: 0.4575  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:54:53 d2.utils.events]: \u001b[0m eta: 0:35:05  iter: 3559  total_loss: 1.49  loss_cls: 0.3409  loss_box_reg: 0.5283  loss_mask: 0.2972  loss_rpn_cls: 0.09224  loss_rpn_loc: 0.1881  time: 0.5804  data_time: 0.3019  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:55:05 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 3579  total_loss: 1.507  loss_cls: 0.3431  loss_box_reg: 0.5282  loss_mask: 0.316  loss_rpn_cls: 0.09183  loss_rpn_loc: 0.1875  time: 0.5805  data_time: 0.2953  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:55:16 d2.utils.events]: \u001b[0m eta: 0:34:51  iter: 3599  total_loss: 1.563  loss_cls: 0.3741  loss_box_reg: 0.5202  loss_mask: 0.3073  loss_rpn_cls: 0.09455  loss_rpn_loc: 0.1943  time: 0.5802  data_time: 0.2150  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:55:28 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 3619  total_loss: 1.39  loss_cls: 0.3378  loss_box_reg: 0.5298  loss_mask: 0.32  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.195  time: 0.5803  data_time: 0.2832  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:55:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:55:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:55:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:55:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:55:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:55:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0675 s/iter. Eval: 0.0332 s/iter. Total: 0.1012 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:55:43 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0530 s/iter. Total: 0.1240 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0566 s/iter. Total: 0.1281 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 09:55:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.684804 (0.126593 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:55:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070523 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:55:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:55:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2539841479338462\n",
      "\u001b[32m[02/02 09:55:57 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 3639  total_loss: 1.409  loss_cls: 0.3336  loss_box_reg: 0.4902  loss_mask: 0.2932  loss_rpn_cls: 0.08624  loss_rpn_loc: 0.1827  time: 0.5808  data_time: 0.3457  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:56:08 d2.utils.events]: \u001b[0m eta: 0:34:31  iter: 3659  total_loss: 1.408  loss_cls: 0.3336  loss_box_reg: 0.5492  loss_mask: 0.299  loss_rpn_cls: 0.08292  loss_rpn_loc: 0.1909  time: 0.5807  data_time: 0.2532  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:56:22 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 3679  total_loss: 1.46  loss_cls: 0.3487  loss_box_reg: 0.5213  loss_mask: 0.2882  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.1938  time: 0.5811  data_time: 0.3315  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:56:32 d2.utils.events]: \u001b[0m eta: 0:34:22  iter: 3699  total_loss: 1.608  loss_cls: 0.3902  loss_box_reg: 0.5599  loss_mask: 0.3006  loss_rpn_cls: 0.09822  loss_rpn_loc: 0.2055  time: 0.5809  data_time: 0.2388  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:56:44 d2.utils.events]: \u001b[0m eta: 0:34:12  iter: 3719  total_loss: 1.431  loss_cls: 0.3083  loss_box_reg: 0.5226  loss_mask: 0.2974  loss_rpn_cls: 0.09741  loss_rpn_loc: 0.1969  time: 0.5809  data_time: 0.2804  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:56:56 d2.utils.events]: \u001b[0m eta: 0:34:07  iter: 3739  total_loss: 1.405  loss_cls: 0.3359  loss_box_reg: 0.483  loss_mask: 0.3022  loss_rpn_cls: 0.08758  loss_rpn_loc: 0.1905  time: 0.5809  data_time: 0.2770  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:57:05 d2.utils.events]: \u001b[0m eta: 0:33:59  iter: 3759  total_loss: 1.533  loss_cls: 0.3547  loss_box_reg: 0.562  loss_mask: 0.3096  loss_rpn_cls: 0.07928  loss_rpn_loc: 0.1913  time: 0.5804  data_time: 0.1669  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:57:15 d2.utils.events]: \u001b[0m eta: 0:33:55  iter: 3779  total_loss: 1.447  loss_cls: 0.3225  loss_box_reg: 0.5531  loss_mask: 0.313  loss_rpn_cls: 0.07917  loss_rpn_loc: 0.2066  time: 0.5799  data_time: 0.1950  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:57:27 d2.utils.events]: \u001b[0m eta: 0:33:48  iter: 3799  total_loss: 1.464  loss_cls: 0.3358  loss_box_reg: 0.5395  loss_mask: 0.3071  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1889  time: 0.5799  data_time: 0.2636  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:57:39 d2.utils.events]: \u001b[0m eta: 0:33:39  iter: 3819  total_loss: 1.502  loss_cls: 0.3339  loss_box_reg: 0.555  loss_mask: 0.3195  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.2123  time: 0.5801  data_time: 0.3163  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:57:51 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 3839  total_loss: 1.483  loss_cls: 0.3459  loss_box_reg: 0.5247  loss_mask: 0.295  loss_rpn_cls: 0.08277  loss_rpn_loc: 0.2008  time: 0.5802  data_time: 0.2611  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:58:03 d2.utils.events]: \u001b[0m eta: 0:33:27  iter: 3859  total_loss: 1.47  loss_cls: 0.3406  loss_box_reg: 0.4971  loss_mask: 0.3122  loss_rpn_cls: 0.09449  loss_rpn_loc: 0.2135  time: 0.5804  data_time: 0.2930  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:58:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:58:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 09:58:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 09:58:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 09:58:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 09:58:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 09:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0675 s/iter. Eval: 0.0334 s/iter. Total: 0.1015 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 09:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0520 s/iter. Total: 0.1227 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 09:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0555 s/iter. Total: 0.1267 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 09:58:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.583939 (0.125724 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:58:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070285 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 09:58:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 09:58:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25325431714493146\n",
      "\u001b[32m[02/02 09:58:30 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 3879  total_loss: 1.433  loss_cls: 0.3175  loss_box_reg: 0.5175  loss_mask: 0.2952  loss_rpn_cls: 0.07163  loss_rpn_loc: 0.1989  time: 0.5801  data_time: 0.2103  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:58:41 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 3899  total_loss: 1.476  loss_cls: 0.3435  loss_box_reg: 0.5278  loss_mask: 0.2889  loss_rpn_cls: 0.0976  loss_rpn_loc: 0.2075  time: 0.5799  data_time: 0.2490  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:58:52 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 3919  total_loss: 1.428  loss_cls: 0.3293  loss_box_reg: 0.5109  loss_mask: 0.3038  loss_rpn_cls: 0.06649  loss_rpn_loc: 0.1955  time: 0.5799  data_time: 0.2620  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:59:03 d2.utils.events]: \u001b[0m eta: 0:33:01  iter: 3939  total_loss: 1.52  loss_cls: 0.3664  loss_box_reg: 0.5438  loss_mask: 0.3167  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.1964  time: 0.5797  data_time: 0.2298  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:59:14 d2.utils.events]: \u001b[0m eta: 0:32:56  iter: 3959  total_loss: 1.533  loss_cls: 0.3454  loss_box_reg: 0.5939  loss_mask: 0.2962  loss_rpn_cls: 0.09957  loss_rpn_loc: 0.1853  time: 0.5794  data_time: 0.2061  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:59:25 d2.utils.events]: \u001b[0m eta: 0:32:51  iter: 3979  total_loss: 1.504  loss_cls: 0.3618  loss_box_reg: 0.5087  loss_mask: 0.3132  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2338  time: 0.5794  data_time: 0.2742  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:59:36 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 3999  total_loss: 1.441  loss_cls: 0.3272  loss_box_reg: 0.5163  loss_mask: 0.2987  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.205  time: 0.5793  data_time: 0.2468  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 09:59:49 d2.utils.events]: \u001b[0m eta: 0:32:48  iter: 4019  total_loss: 1.476  loss_cls: 0.3445  loss_box_reg: 0.4991  loss_mask: 0.3205  loss_rpn_cls: 0.09393  loss_rpn_loc: 0.2096  time: 0.5796  data_time: 0.3293  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:00:02 d2.utils.events]: \u001b[0m eta: 0:32:46  iter: 4039  total_loss: 1.49  loss_cls: 0.3249  loss_box_reg: 0.5237  loss_mask: 0.2984  loss_rpn_cls: 0.09993  loss_rpn_loc: 0.1975  time: 0.5798  data_time: 0.2997  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:00:17 d2.utils.events]: \u001b[0m eta: 0:32:40  iter: 4059  total_loss: 1.398  loss_cls: 0.3396  loss_box_reg: 0.5114  loss_mask: 0.2949  loss_rpn_cls: 0.09364  loss_rpn_loc: 0.1981  time: 0.5807  data_time: 0.4426  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:00:29 d2.utils.events]: \u001b[0m eta: 0:32:30  iter: 4079  total_loss: 1.337  loss_cls: 0.2944  loss_box_reg: 0.4995  loss_mask: 0.297  loss_rpn_cls: 0.07455  loss_rpn_loc: 0.1728  time: 0.5808  data_time: 0.2967  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:00:39 d2.utils.events]: \u001b[0m eta: 0:32:22  iter: 4099  total_loss: 1.399  loss_cls: 0.3188  loss_box_reg: 0.5118  loss_mask: 0.2901  loss_rpn_cls: 0.08299  loss_rpn_loc: 0.1836  time: 0.5803  data_time: 0.1913  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:00:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:00:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:00:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:00:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:00:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:00:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:00:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0672 s/iter. Eval: 0.0320 s/iter. Total: 0.0998 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 10:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0516 s/iter. Total: 0.1223 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0550 s/iter. Total: 0.1260 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:01:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.521455 (0.125185 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:01:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070198 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:01:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:01:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2537743177513292\n",
      "\u001b[32m[02/02 10:01:05 d2.utils.events]: \u001b[0m eta: 0:32:11  iter: 4119  total_loss: 1.359  loss_cls: 0.3145  loss_box_reg: 0.5066  loss_mask: 0.2963  loss_rpn_cls: 0.06335  loss_rpn_loc: 0.1858  time: 0.5800  data_time: 0.2093  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:01:16 d2.utils.events]: \u001b[0m eta: 0:32:02  iter: 4139  total_loss: 1.514  loss_cls: 0.3569  loss_box_reg: 0.5309  loss_mask: 0.3086  loss_rpn_cls: 0.0867  loss_rpn_loc: 0.2006  time: 0.5800  data_time: 0.2511  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:01:29 d2.utils.events]: \u001b[0m eta: 0:31:58  iter: 4159  total_loss: 1.522  loss_cls: 0.3831  loss_box_reg: 0.5178  loss_mask: 0.2972  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.2197  time: 0.5802  data_time: 0.3075  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:01:42 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 4179  total_loss: 1.489  loss_cls: 0.3575  loss_box_reg: 0.4917  loss_mask: 0.3026  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.2107  time: 0.5806  data_time: 0.3436  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:01:52 d2.utils.events]: \u001b[0m eta: 0:31:45  iter: 4199  total_loss: 1.521  loss_cls: 0.3396  loss_box_reg: 0.5407  loss_mask: 0.2976  loss_rpn_cls: 0.07322  loss_rpn_loc: 0.2005  time: 0.5801  data_time: 0.1668  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:02:00 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 4219  total_loss: 1.328  loss_cls: 0.287  loss_box_reg: 0.5114  loss_mask: 0.3018  loss_rpn_cls: 0.068  loss_rpn_loc: 0.1929  time: 0.5794  data_time: 0.1348  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:02:13 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 4239  total_loss: 1.434  loss_cls: 0.3144  loss_box_reg: 0.5078  loss_mask: 0.3045  loss_rpn_cls: 0.08976  loss_rpn_loc: 0.2128  time: 0.5796  data_time: 0.3191  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:02:23 d2.utils.events]: \u001b[0m eta: 0:31:22  iter: 4259  total_loss: 1.465  loss_cls: 0.3525  loss_box_reg: 0.5156  loss_mask: 0.3113  loss_rpn_cls: 0.08867  loss_rpn_loc: 0.1929  time: 0.5792  data_time: 0.1908  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:02:37 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 4279  total_loss: 1.515  loss_cls: 0.3478  loss_box_reg: 0.509  loss_mask: 0.3119  loss_rpn_cls: 0.1182  loss_rpn_loc: 0.2125  time: 0.5798  data_time: 0.3869  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:02:46 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 4299  total_loss: 1.474  loss_cls: 0.3721  loss_box_reg: 0.5185  loss_mask: 0.3138  loss_rpn_cls: 0.07516  loss_rpn_loc: 0.2123  time: 0.5792  data_time: 0.1552  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:03:00 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 4319  total_loss: 1.487  loss_cls: 0.3346  loss_box_reg: 0.5273  loss_mask: 0.3138  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.2126  time: 0.5797  data_time: 0.3678  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:03:09 d2.utils.events]: \u001b[0m eta: 0:30:53  iter: 4339  total_loss: 1.464  loss_cls: 0.3432  loss_box_reg: 0.5305  loss_mask: 0.2962  loss_rpn_cls: 0.06771  loss_rpn_loc: 0.1851  time: 0.5792  data_time: 0.1658  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:03:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:03:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:03:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:03:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:03:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:03:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0675 s/iter. Eval: 0.0339 s/iter. Total: 0.1019 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0696 s/iter. Eval: 0.0495 s/iter. Total: 0.1199 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:03:32 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0532 s/iter. Total: 0.1241 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:03:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.111813 (0.121654 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:03:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069782 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:03:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:03:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2485004384579553\n",
      "\u001b[32m[02/02 10:03:36 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 4359  total_loss: 1.341  loss_cls: 0.3121  loss_box_reg: 0.4764  loss_mask: 0.2929  loss_rpn_cls: 0.08493  loss_rpn_loc: 0.1881  time: 0.5792  data_time: 0.2764  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:03:48 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 4379  total_loss: 1.46  loss_cls: 0.3376  loss_box_reg: 0.4909  loss_mask: 0.3187  loss_rpn_cls: 0.09127  loss_rpn_loc: 0.2006  time: 0.5792  data_time: 0.2640  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:03:56 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 4399  total_loss: 1.426  loss_cls: 0.3395  loss_box_reg: 0.5353  loss_mask: 0.2956  loss_rpn_cls: 0.0538  loss_rpn_loc: 0.1737  time: 0.5784  data_time: 0.1173  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:04:08 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 4419  total_loss: 1.479  loss_cls: 0.3501  loss_box_reg: 0.5298  loss_mask: 0.3194  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.2151  time: 0.5784  data_time: 0.2715  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:04:16 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 4439  total_loss: 1.414  loss_cls: 0.3179  loss_box_reg: 0.5192  loss_mask: 0.2985  loss_rpn_cls: 0.08275  loss_rpn_loc: 0.192  time: 0.5778  data_time: 0.1317  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:04:28 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 4459  total_loss: 1.538  loss_cls: 0.3535  loss_box_reg: 0.5266  loss_mask: 0.3138  loss_rpn_cls: 0.08254  loss_rpn_loc: 0.2133  time: 0.5778  data_time: 0.2585  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:04:44 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 4479  total_loss: 1.348  loss_cls: 0.2969  loss_box_reg: 0.4493  loss_mask: 0.3045  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.2064  time: 0.5789  data_time: 0.4955  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:04:57 d2.utils.events]: \u001b[0m eta: 0:30:05  iter: 4499  total_loss: 1.445  loss_cls: 0.3319  loss_box_reg: 0.518  loss_mask: 0.3086  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2068  time: 0.5791  data_time: 0.3079  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:05:07 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 4519  total_loss: 1.429  loss_cls: 0.3343  loss_box_reg: 0.5119  loss_mask: 0.3027  loss_rpn_cls: 0.07897  loss_rpn_loc: 0.2059  time: 0.5787  data_time: 0.1771  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:05:18 d2.utils.events]: \u001b[0m eta: 0:29:52  iter: 4539  total_loss: 1.465  loss_cls: 0.331  loss_box_reg: 0.517  loss_mask: 0.311  loss_rpn_cls: 0.09448  loss_rpn_loc: 0.1962  time: 0.5786  data_time: 0.2644  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:05:28 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 4559  total_loss: 1.304  loss_cls: 0.2769  loss_box_reg: 0.5073  loss_mask: 0.2788  loss_rpn_cls: 0.06516  loss_rpn_loc: 0.1652  time: 0.5784  data_time: 0.2125  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:05:41 d2.utils.events]: \u001b[0m eta: 0:29:34  iter: 4579  total_loss: 1.586  loss_cls: 0.3639  loss_box_reg: 0.5708  loss_mask: 0.3138  loss_rpn_cls: 0.07412  loss_rpn_loc: 0.2048  time: 0.5787  data_time: 0.3375  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:05:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:05:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:05:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:05:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:05:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:05:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:05:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0339 s/iter. Total: 0.1022 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0538 s/iter. Total: 0.1248 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0570 s/iter. Total: 0.1284 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:06:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.761096 (0.127251 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:06:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070455 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:06:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:06:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2550846515440348\n",
      "\u001b[32m[02/02 10:06:07 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 4599  total_loss: 1.467  loss_cls: 0.3174  loss_box_reg: 0.5334  loss_mask: 0.2977  loss_rpn_cls: 0.07394  loss_rpn_loc: 0.2009  time: 0.5782  data_time: 0.1778  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:06:20 d2.utils.events]: \u001b[0m eta: 0:29:21  iter: 4619  total_loss: 1.38  loss_cls: 0.3455  loss_box_reg: 0.4877  loss_mask: 0.292  loss_rpn_cls: 0.09705  loss_rpn_loc: 0.2007  time: 0.5785  data_time: 0.3194  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:06:31 d2.utils.events]: \u001b[0m eta: 0:29:13  iter: 4639  total_loss: 1.39  loss_cls: 0.2625  loss_box_reg: 0.4882  loss_mask: 0.3068  loss_rpn_cls: 0.08091  loss_rpn_loc: 0.2094  time: 0.5784  data_time: 0.2770  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:06:43 d2.utils.events]: \u001b[0m eta: 0:29:07  iter: 4659  total_loss: 1.432  loss_cls: 0.309  loss_box_reg: 0.5173  loss_mask: 0.2991  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2022  time: 0.5786  data_time: 0.2959  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:06:52 d2.utils.events]: \u001b[0m eta: 0:28:54  iter: 4679  total_loss: 1.447  loss_cls: 0.3414  loss_box_reg: 0.5404  loss_mask: 0.3021  loss_rpn_cls: 0.07062  loss_rpn_loc: 0.1853  time: 0.5779  data_time: 0.1296  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:07:03 d2.utils.events]: \u001b[0m eta: 0:28:49  iter: 4699  total_loss: 1.534  loss_cls: 0.3434  loss_box_reg: 0.5176  loss_mask: 0.3106  loss_rpn_cls: 0.0927  loss_rpn_loc: 0.2216  time: 0.5779  data_time: 0.2659  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:07:15 d2.utils.events]: \u001b[0m eta: 0:28:43  iter: 4719  total_loss: 1.445  loss_cls: 0.3256  loss_box_reg: 0.5475  loss_mask: 0.3137  loss_rpn_cls: 0.09831  loss_rpn_loc: 0.2127  time: 0.5780  data_time: 0.2865  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:07:29 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 4739  total_loss: 1.382  loss_cls: 0.3304  loss_box_reg: 0.5048  loss_mask: 0.2919  loss_rpn_cls: 0.09931  loss_rpn_loc: 0.2093  time: 0.5783  data_time: 0.3310  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:07:40 d2.utils.events]: \u001b[0m eta: 0:28:35  iter: 4759  total_loss: 1.522  loss_cls: 0.3785  loss_box_reg: 0.542  loss_mask: 0.307  loss_rpn_cls: 0.09271  loss_rpn_loc: 0.1981  time: 0.5783  data_time: 0.2608  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:07:49 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 4779  total_loss: 1.364  loss_cls: 0.3171  loss_box_reg: 0.5129  loss_mask: 0.2922  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.1829  time: 0.5779  data_time: 0.1750  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:08:04 d2.utils.events]: \u001b[0m eta: 0:28:23  iter: 4799  total_loss: 1.447  loss_cls: 0.3248  loss_box_reg: 0.5152  loss_mask: 0.3096  loss_rpn_cls: 0.08375  loss_rpn_loc: 0.1945  time: 0.5784  data_time: 0.3817  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:08:16 d2.utils.events]: \u001b[0m eta: 0:28:17  iter: 4819  total_loss: 1.483  loss_cls: 0.3381  loss_box_reg: 0.5668  loss_mask: 0.3041  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.1665  time: 0.5786  data_time: 0.3060  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:08:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:08:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:08:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:08:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:08:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:08:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0357 s/iter. Total: 0.1041 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0538 s/iter. Total: 0.1248 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0561 s/iter. Total: 0.1274 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:08:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.673610 (0.126497 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:08:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070386 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:08:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:08:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2549315706818894\n",
      "\u001b[32m[02/02 10:08:41 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 4839  total_loss: 1.446  loss_cls: 0.3391  loss_box_reg: 0.5321  loss_mask: 0.3081  loss_rpn_cls: 0.0774  loss_rpn_loc: 0.1897  time: 0.5780  data_time: 0.1267  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:08:52 d2.utils.events]: \u001b[0m eta: 0:27:59  iter: 4859  total_loss: 1.439  loss_cls: 0.3089  loss_box_reg: 0.5084  loss_mask: 0.3111  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.2021  time: 0.5779  data_time: 0.2573  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:09:01 d2.utils.events]: \u001b[0m eta: 0:27:49  iter: 4879  total_loss: 1.471  loss_cls: 0.3443  loss_box_reg: 0.5142  loss_mask: 0.3029  loss_rpn_cls: 0.0681  loss_rpn_loc: 0.2047  time: 0.5774  data_time: 0.1596  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:09:13 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 4899  total_loss: 1.423  loss_cls: 0.3343  loss_box_reg: 0.5254  loss_mask: 0.323  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.204  time: 0.5775  data_time: 0.2747  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:09:22 d2.utils.events]: \u001b[0m eta: 0:27:36  iter: 4919  total_loss: 1.523  loss_cls: 0.3377  loss_box_reg: 0.5698  loss_mask: 0.3022  loss_rpn_cls: 0.07447  loss_rpn_loc: 0.2041  time: 0.5770  data_time: 0.1533  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:09:32 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 4939  total_loss: 1.529  loss_cls: 0.3868  loss_box_reg: 0.5553  loss_mask: 0.306  loss_rpn_cls: 0.0894  loss_rpn_loc: 0.2011  time: 0.5766  data_time: 0.1687  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:09:42 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 4959  total_loss: 1.437  loss_cls: 0.344  loss_box_reg: 0.5352  loss_mask: 0.3048  loss_rpn_cls: 0.0704  loss_rpn_loc: 0.1872  time: 0.5763  data_time: 0.1776  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:09:54 d2.utils.events]: \u001b[0m eta: 0:27:15  iter: 4979  total_loss: 1.487  loss_cls: 0.3459  loss_box_reg: 0.5205  loss_mask: 0.3108  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.207  time: 0.5765  data_time: 0.3125  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:10:06 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 4999  total_loss: 1.391  loss_cls: 0.3272  loss_box_reg: 0.5096  loss_mask: 0.2928  loss_rpn_cls: 0.07583  loss_rpn_loc: 0.1967  time: 0.5765  data_time: 0.2625  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:10:17 d2.utils.events]: \u001b[0m eta: 0:26:57  iter: 5019  total_loss: 1.44  loss_cls: 0.3192  loss_box_reg: 0.537  loss_mask: 0.2983  loss_rpn_cls: 0.09662  loss_rpn_loc: 0.1886  time: 0.5764  data_time: 0.2519  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:10:31 d2.utils.events]: \u001b[0m eta: 0:26:51  iter: 5039  total_loss: 1.361  loss_cls: 0.2816  loss_box_reg: 0.5085  loss_mask: 0.3075  loss_rpn_cls: 0.08387  loss_rpn_loc: 0.1856  time: 0.5770  data_time: 0.3827  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:10:46 d2.utils.events]: \u001b[0m eta: 0:26:46  iter: 5059  total_loss: 1.516  loss_cls: 0.352  loss_box_reg: 0.5325  loss_mask: 0.3034  loss_rpn_cls: 0.115  loss_rpn_loc: 0.2242  time: 0.5776  data_time: 0.4177  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:10:56 d2.utils.events]: \u001b[0m eta: 0:26:37  iter: 5079  total_loss: 1.445  loss_cls: 0.2999  loss_box_reg: 0.5083  loss_mask: 0.3074  loss_rpn_cls: 0.0762  loss_rpn_loc: 0.1926  time: 0.5773  data_time: 0.2052  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:10:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:10:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:10:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:10:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:10:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:10:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0358 s/iter. Total: 0.1042 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0543 s/iter. Total: 0.1254 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0571 s/iter. Total: 0.1285 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:11:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.765813 (0.127291 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:11:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070409 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:11:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:11:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25770571456103586\n",
      "\u001b[32m[02/02 10:11:21 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 5099  total_loss: 1.536  loss_cls: 0.3619  loss_box_reg: 0.5573  loss_mask: 0.3099  loss_rpn_cls: 0.08607  loss_rpn_loc: 0.1807  time: 0.5767  data_time: 0.1137  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:11:30 d2.utils.events]: \u001b[0m eta: 0:26:26  iter: 5119  total_loss: 1.37  loss_cls: 0.297  loss_box_reg: 0.5292  loss_mask: 0.3104  loss_rpn_cls: 0.08107  loss_rpn_loc: 0.1855  time: 0.5762  data_time: 0.1543  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:11:42 d2.utils.events]: \u001b[0m eta: 0:26:19  iter: 5139  total_loss: 1.433  loss_cls: 0.33  loss_box_reg: 0.5401  loss_mask: 0.3082  loss_rpn_cls: 0.08044  loss_rpn_loc: 0.1978  time: 0.5763  data_time: 0.2979  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:11:53 d2.utils.events]: \u001b[0m eta: 0:26:12  iter: 5159  total_loss: 1.456  loss_cls: 0.3499  loss_box_reg: 0.5242  loss_mask: 0.3088  loss_rpn_cls: 0.09917  loss_rpn_loc: 0.1978  time: 0.5762  data_time: 0.2275  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:12:03 d2.utils.events]: \u001b[0m eta: 0:26:04  iter: 5179  total_loss: 1.401  loss_cls: 0.3053  loss_box_reg: 0.5347  loss_mask: 0.2902  loss_rpn_cls: 0.08128  loss_rpn_loc: 0.182  time: 0.5759  data_time: 0.2054  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:12:15 d2.utils.events]: \u001b[0m eta: 0:25:59  iter: 5199  total_loss: 1.4  loss_cls: 0.3142  loss_box_reg: 0.4955  loss_mask: 0.2946  loss_rpn_cls: 0.1101  loss_rpn_loc: 0.206  time: 0.5759  data_time: 0.2741  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:12:23 d2.utils.events]: \u001b[0m eta: 0:25:53  iter: 5219  total_loss: 1.388  loss_cls: 0.2802  loss_box_reg: 0.5197  loss_mask: 0.2886  loss_rpn_cls: 0.07551  loss_rpn_loc: 0.1774  time: 0.5753  data_time: 0.1090  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:12:37 d2.utils.events]: \u001b[0m eta: 0:25:47  iter: 5239  total_loss: 1.53  loss_cls: 0.3785  loss_box_reg: 0.5216  loss_mask: 0.3208  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.2198  time: 0.5758  data_time: 0.3931  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:12:50 d2.utils.events]: \u001b[0m eta: 0:25:44  iter: 5259  total_loss: 1.498  loss_cls: 0.3615  loss_box_reg: 0.5141  loss_mask: 0.3119  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.2132  time: 0.5761  data_time: 0.3295  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:13:02 d2.utils.events]: \u001b[0m eta: 0:25:35  iter: 5279  total_loss: 1.418  loss_cls: 0.3174  loss_box_reg: 0.4997  loss_mask: 0.2798  loss_rpn_cls: 0.08292  loss_rpn_loc: 0.1784  time: 0.5761  data_time: 0.2738  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:13:13 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 5299  total_loss: 1.376  loss_cls: 0.2751  loss_box_reg: 0.5124  loss_mask: 0.3124  loss_rpn_cls: 0.0796  loss_rpn_loc: 0.201  time: 0.5760  data_time: 0.2437  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:13:26 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 5319  total_loss: 1.41  loss_cls: 0.3153  loss_box_reg: 0.5337  loss_mask: 0.3066  loss_rpn_cls: 0.07262  loss_rpn_loc: 0.1919  time: 0.5764  data_time: 0.3574  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:13:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:13:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:13:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:13:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:13:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:13:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0372 s/iter. Total: 0.1058 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0542 s/iter. Total: 0.1253 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0010 s/iter. Inference: 0.0707 s/iter. Eval: 0.0570 s/iter. Total: 0.1287 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:13:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.747774 (0.127136 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:13:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070460 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:13:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:13:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25867257512090175\n",
      "\u001b[32m[02/02 10:13:57 d2.utils.events]: \u001b[0m eta: 0:25:18  iter: 5339  total_loss: 1.547  loss_cls: 0.3831  loss_box_reg: 0.5201  loss_mask: 0.3211  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.2306  time: 0.5770  data_time: 0.3968  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:14:10 d2.utils.events]: \u001b[0m eta: 0:25:11  iter: 5359  total_loss: 1.411  loss_cls: 0.3021  loss_box_reg: 0.5214  loss_mask: 0.301  loss_rpn_cls: 0.06916  loss_rpn_loc: 0.2046  time: 0.5771  data_time: 0.3167  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:14:20 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 5379  total_loss: 1.567  loss_cls: 0.3573  loss_box_reg: 0.5574  loss_mask: 0.2995  loss_rpn_cls: 0.0757  loss_rpn_loc: 0.2017  time: 0.5769  data_time: 0.2133  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:14:36 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 5399  total_loss: 1.525  loss_cls: 0.3425  loss_box_reg: 0.4921  loss_mask: 0.3114  loss_rpn_cls: 0.08653  loss_rpn_loc: 0.1892  time: 0.5777  data_time: 0.4647  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:14:47 d2.utils.events]: \u001b[0m eta: 0:24:56  iter: 5419  total_loss: 1.469  loss_cls: 0.3427  loss_box_reg: 0.5171  loss_mask: 0.2992  loss_rpn_cls: 0.08242  loss_rpn_loc: 0.2032  time: 0.5777  data_time: 0.2657  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:14:58 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 5439  total_loss: 1.422  loss_cls: 0.3321  loss_box_reg: 0.506  loss_mask: 0.306  loss_rpn_cls: 0.09268  loss_rpn_loc: 0.2043  time: 0.5776  data_time: 0.2460  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:15:08 d2.utils.events]: \u001b[0m eta: 0:24:37  iter: 5459  total_loss: 1.438  loss_cls: 0.3324  loss_box_reg: 0.5395  loss_mask: 0.2989  loss_rpn_cls: 0.06931  loss_rpn_loc: 0.1668  time: 0.5773  data_time: 0.1893  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:15:21 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 5479  total_loss: 1.346  loss_cls: 0.305  loss_box_reg: 0.4905  loss_mask: 0.316  loss_rpn_cls: 0.09711  loss_rpn_loc: 0.1905  time: 0.5774  data_time: 0.3085  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:15:31 d2.utils.events]: \u001b[0m eta: 0:24:20  iter: 5499  total_loss: 1.427  loss_cls: 0.3381  loss_box_reg: 0.5228  loss_mask: 0.2986  loss_rpn_cls: 0.09003  loss_rpn_loc: 0.182  time: 0.5771  data_time: 0.1842  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:15:42 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 5519  total_loss: 1.474  loss_cls: 0.3304  loss_box_reg: 0.5219  loss_mask: 0.3202  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.1999  time: 0.5771  data_time: 0.2682  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:15:53 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 5539  total_loss: 1.408  loss_cls: 0.3061  loss_box_reg: 0.4852  loss_mask: 0.3002  loss_rpn_cls: 0.09207  loss_rpn_loc: 0.1968  time: 0.5771  data_time: 0.2478  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:16:04 d2.utils.events]: \u001b[0m eta: 0:24:05  iter: 5559  total_loss: 1.442  loss_cls: 0.341  loss_box_reg: 0.5166  loss_mask: 0.2967  loss_rpn_cls: 0.08507  loss_rpn_loc: 0.1854  time: 0.5770  data_time: 0.2314  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:16:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:16:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:16:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:16:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:16:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:16:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0341 s/iter. Total: 0.1023 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0528 s/iter. Total: 0.1236 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0555 s/iter. Total: 0.1268 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:16:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.607693 (0.125928 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:16:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070270 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:16:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:16:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2578803256357753\n",
      "\u001b[32m[02/02 10:16:32 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 5579  total_loss: 1.403  loss_cls: 0.3212  loss_box_reg: 0.5081  loss_mask: 0.3036  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.1857  time: 0.5770  data_time: 0.2931  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:16:47 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 5599  total_loss: 1.462  loss_cls: 0.3173  loss_box_reg: 0.501  loss_mask: 0.2962  loss_rpn_cls: 0.08057  loss_rpn_loc: 0.1883  time: 0.5776  data_time: 0.4095  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:17:03 d2.utils.events]: \u001b[0m eta: 0:23:46  iter: 5619  total_loss: 1.456  loss_cls: 0.3301  loss_box_reg: 0.5022  loss_mask: 0.3055  loss_rpn_cls: 0.09322  loss_rpn_loc: 0.2041  time: 0.5785  data_time: 0.4885  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:17:17 d2.utils.events]: \u001b[0m eta: 0:23:40  iter: 5639  total_loss: 1.433  loss_cls: 0.3168  loss_box_reg: 0.491  loss_mask: 0.2985  loss_rpn_cls: 0.09454  loss_rpn_loc: 0.2097  time: 0.5789  data_time: 0.3769  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:17:30 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 5659  total_loss: 1.418  loss_cls: 0.3292  loss_box_reg: 0.5108  loss_mask: 0.2918  loss_rpn_cls: 0.06697  loss_rpn_loc: 0.18  time: 0.5791  data_time: 0.3234  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:17:40 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 5679  total_loss: 1.418  loss_cls: 0.3131  loss_box_reg: 0.5226  loss_mask: 0.2963  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1741  time: 0.5788  data_time: 0.1985  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:17:53 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 5699  total_loss: 1.423  loss_cls: 0.3227  loss_box_reg: 0.4719  loss_mask: 0.2996  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.1942  time: 0.5790  data_time: 0.3150  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:18:03 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 5719  total_loss: 1.349  loss_cls: 0.3122  loss_box_reg: 0.4892  loss_mask: 0.2934  loss_rpn_cls: 0.06538  loss_rpn_loc: 0.172  time: 0.5787  data_time: 0.1891  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:18:13 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 5739  total_loss: 1.473  loss_cls: 0.3683  loss_box_reg: 0.5127  loss_mask: 0.3039  loss_rpn_cls: 0.09252  loss_rpn_loc: 0.2133  time: 0.5786  data_time: 0.2268  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:18:24 d2.utils.events]: \u001b[0m eta: 0:23:02  iter: 5759  total_loss: 1.499  loss_cls: 0.3626  loss_box_reg: 0.561  loss_mask: 0.3317  loss_rpn_cls: 0.08345  loss_rpn_loc: 0.2028  time: 0.5784  data_time: 0.2141  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:18:35 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 5779  total_loss: 1.512  loss_cls: 0.3542  loss_box_reg: 0.5374  loss_mask: 0.3152  loss_rpn_cls: 0.08835  loss_rpn_loc: 0.2069  time: 0.5784  data_time: 0.2473  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:18:44 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 5799  total_loss: 1.408  loss_cls: 0.3282  loss_box_reg: 0.5379  loss_mask: 0.3014  loss_rpn_cls: 0.0792  loss_rpn_loc: 0.1813  time: 0.5779  data_time: 0.1590  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:18:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:18:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:18:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:18:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:18:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:18:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:18:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0349 s/iter. Total: 0.1032 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0531 s/iter. Total: 0.1242 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0550 s/iter. Total: 0.1263 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:19:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.514094 (0.125122 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:19:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070359 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:19:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:19:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2569326617494505\n",
      "\u001b[32m[02/02 10:19:09 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 5819  total_loss: 1.472  loss_cls: 0.337  loss_box_reg: 0.5406  loss_mask: 0.292  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.1929  time: 0.5775  data_time: 0.1523  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:19:18 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 5839  total_loss: 1.464  loss_cls: 0.3617  loss_box_reg: 0.5298  loss_mask: 0.3034  loss_rpn_cls: 0.09403  loss_rpn_loc: 0.1743  time: 0.5771  data_time: 0.1400  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:19:27 d2.utils.events]: \u001b[0m eta: 0:22:28  iter: 5859  total_loss: 1.477  loss_cls: 0.2894  loss_box_reg: 0.5023  loss_mask: 0.2948  loss_rpn_cls: 0.09187  loss_rpn_loc: 0.2056  time: 0.5766  data_time: 0.1321  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:19:39 d2.utils.events]: \u001b[0m eta: 0:22:21  iter: 5879  total_loss: 1.542  loss_cls: 0.3318  loss_box_reg: 0.5092  loss_mask: 0.3027  loss_rpn_cls: 0.08796  loss_rpn_loc: 0.2264  time: 0.5766  data_time: 0.2722  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:19:51 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 5899  total_loss: 1.456  loss_cls: 0.3436  loss_box_reg: 0.5369  loss_mask: 0.2981  loss_rpn_cls: 0.0886  loss_rpn_loc: 0.2129  time: 0.5768  data_time: 0.3027  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:20:03 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 5919  total_loss: 1.427  loss_cls: 0.3232  loss_box_reg: 0.5007  loss_mask: 0.2882  loss_rpn_cls: 0.09273  loss_rpn_loc: 0.2114  time: 0.5769  data_time: 0.2974  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:20:20 d2.utils.events]: \u001b[0m eta: 0:22:05  iter: 5939  total_loss: 1.379  loss_cls: 0.303  loss_box_reg: 0.4874  loss_mask: 0.3014  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.2096  time: 0.5777  data_time: 0.4953  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:20:31 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 5959  total_loss: 1.349  loss_cls: 0.2613  loss_box_reg: 0.479  loss_mask: 0.2915  loss_rpn_cls: 0.06639  loss_rpn_loc: 0.1917  time: 0.5777  data_time: 0.2856  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:20:44 d2.utils.events]: \u001b[0m eta: 0:21:49  iter: 5979  total_loss: 1.493  loss_cls: 0.3835  loss_box_reg: 0.5587  loss_mask: 0.2914  loss_rpn_cls: 0.07716  loss_rpn_loc: 0.1899  time: 0.5778  data_time: 0.2882  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:20:55 d2.utils.events]: \u001b[0m eta: 0:21:40  iter: 5999  total_loss: 1.396  loss_cls: 0.3066  loss_box_reg: 0.5251  loss_mask: 0.2979  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.1938  time: 0.5777  data_time: 0.2663  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:21:10 d2.utils.events]: \u001b[0m eta: 0:21:35  iter: 6019  total_loss: 1.543  loss_cls: 0.3329  loss_box_reg: 0.5703  loss_mask: 0.3034  loss_rpn_cls: 0.09862  loss_rpn_loc: 0.2148  time: 0.5783  data_time: 0.4320  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:21:21 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 6039  total_loss: 1.404  loss_cls: 0.3191  loss_box_reg: 0.4994  loss_mask: 0.2942  loss_rpn_cls: 0.07731  loss_rpn_loc: 0.1918  time: 0.5783  data_time: 0.2532  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:21:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:21:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:21:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:21:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:21:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:21:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0340 s/iter. Total: 0.1022 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0526 s/iter. Total: 0.1234 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0555 s/iter. Total: 0.1269 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:21:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.597481 (0.125840 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:21:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070365 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:21:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:21:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2578316112287849\n",
      "\u001b[32m[02/02 10:21:49 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 6059  total_loss: 1.39  loss_cls: 0.3303  loss_box_reg: 0.5168  loss_mask: 0.3015  loss_rpn_cls: 0.09319  loss_rpn_loc: 0.1826  time: 0.5783  data_time: 0.2607  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:22:00 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 6079  total_loss: 1.537  loss_cls: 0.3506  loss_box_reg: 0.5214  loss_mask: 0.3017  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.1982  time: 0.5783  data_time: 0.2818  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:22:11 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 6099  total_loss: 1.372  loss_cls: 0.3224  loss_box_reg: 0.5034  loss_mask: 0.3032  loss_rpn_cls: 0.0734  loss_rpn_loc: 0.19  time: 0.5781  data_time: 0.2122  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:22:22 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 6119  total_loss: 1.438  loss_cls: 0.3172  loss_box_reg: 0.5325  loss_mask: 0.3043  loss_rpn_cls: 0.09288  loss_rpn_loc: 0.2091  time: 0.5780  data_time: 0.2312  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:22:33 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 6139  total_loss: 1.413  loss_cls: 0.3177  loss_box_reg: 0.5221  loss_mask: 0.3153  loss_rpn_cls: 0.06962  loss_rpn_loc: 0.1904  time: 0.5780  data_time: 0.2750  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:22:46 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 6159  total_loss: 1.537  loss_cls: 0.3644  loss_box_reg: 0.52  loss_mask: 0.3171  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.1993  time: 0.5782  data_time: 0.3183  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:22:59 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 6179  total_loss: 1.543  loss_cls: 0.3842  loss_box_reg: 0.5241  loss_mask: 0.3219  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.2159  time: 0.5784  data_time: 0.3186  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:23:10 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 6199  total_loss: 1.361  loss_cls: 0.2896  loss_box_reg: 0.4973  loss_mask: 0.2874  loss_rpn_cls: 0.06985  loss_rpn_loc: 0.206  time: 0.5784  data_time: 0.2807  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:23:19 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 6219  total_loss: 1.385  loss_cls: 0.2891  loss_box_reg: 0.5458  loss_mask: 0.2993  loss_rpn_cls: 0.04331  loss_rpn_loc: 0.1825  time: 0.5779  data_time: 0.1201  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:23:30 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 6239  total_loss: 1.452  loss_cls: 0.3546  loss_box_reg: 0.5414  loss_mask: 0.3018  loss_rpn_cls: 0.08719  loss_rpn_loc: 0.1927  time: 0.5778  data_time: 0.2400  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:23:43 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 6259  total_loss: 1.523  loss_cls: 0.391  loss_box_reg: 0.512  loss_mask: 0.3107  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.2256  time: 0.5780  data_time: 0.3449  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:23:56 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 6279  total_loss: 1.364  loss_cls: 0.3059  loss_box_reg: 0.5136  loss_mask: 0.3132  loss_rpn_cls: 0.08368  loss_rpn_loc: 0.1802  time: 0.5782  data_time: 0.3235  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:24:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:24:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:24:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:24:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:24:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:24:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0374 s/iter. Total: 0.1060 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0528 s/iter. Total: 0.1237 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0551 s/iter. Total: 0.1262 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:24:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.427656 (0.124376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:24:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070149 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:24:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:24:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25680786395713706\n",
      "\u001b[32m[02/02 10:24:21 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 6299  total_loss: 1.462  loss_cls: 0.3335  loss_box_reg: 0.5218  loss_mask: 0.3004  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.1841  time: 0.5779  data_time: 0.1730  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:24:33 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 6319  total_loss: 1.441  loss_cls: 0.3052  loss_box_reg: 0.4784  loss_mask: 0.3003  loss_rpn_cls: 0.05954  loss_rpn_loc: 0.1939  time: 0.5779  data_time: 0.2740  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:24:45 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 6339  total_loss: 1.375  loss_cls: 0.3088  loss_box_reg: 0.5221  loss_mask: 0.3015  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.1965  time: 0.5781  data_time: 0.2977  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:24:57 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 6359  total_loss: 1.507  loss_cls: 0.3535  loss_box_reg: 0.5411  loss_mask: 0.3077  loss_rpn_cls: 0.07781  loss_rpn_loc: 0.2008  time: 0.5780  data_time: 0.2538  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:25:07 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 6379  total_loss: 1.386  loss_cls: 0.3249  loss_box_reg: 0.5291  loss_mask: 0.2931  loss_rpn_cls: 0.07437  loss_rpn_loc: 0.1747  time: 0.5779  data_time: 0.2185  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:25:19 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 6399  total_loss: 1.495  loss_cls: 0.3534  loss_box_reg: 0.5194  loss_mask: 0.3027  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2102  time: 0.5779  data_time: 0.2658  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:25:31 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 6419  total_loss: 1.455  loss_cls: 0.3228  loss_box_reg: 0.511  loss_mask: 0.3025  loss_rpn_cls: 0.08826  loss_rpn_loc: 0.2038  time: 0.5779  data_time: 0.2828  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:25:42 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 6439  total_loss: 1.384  loss_cls: 0.3229  loss_box_reg: 0.4893  loss_mask: 0.2899  loss_rpn_cls: 0.07136  loss_rpn_loc: 0.2154  time: 0.5779  data_time: 0.2674  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:25:51 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 6459  total_loss: 1.412  loss_cls: 0.3237  loss_box_reg: 0.5421  loss_mask: 0.3062  loss_rpn_cls: 0.05767  loss_rpn_loc: 0.1932  time: 0.5774  data_time: 0.1175  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:26:01 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 6479  total_loss: 1.469  loss_cls: 0.3163  loss_box_reg: 0.5605  loss_mask: 0.3131  loss_rpn_cls: 0.07253  loss_rpn_loc: 0.1954  time: 0.5773  data_time: 0.2282  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:26:15 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 6499  total_loss: 1.472  loss_cls: 0.3159  loss_box_reg: 0.5088  loss_mask: 0.3223  loss_rpn_cls: 0.09422  loss_rpn_loc: 0.2003  time: 0.5776  data_time: 0.3650  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:26:26 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 6519  total_loss: 1.46  loss_cls: 0.3157  loss_box_reg: 0.4804  loss_mask: 0.298  loss_rpn_cls: 0.06658  loss_rpn_loc: 0.1974  time: 0.5776  data_time: 0.2646  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:26:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:26:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:26:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:26:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:26:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:26:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0689 s/iter. Eval: 0.0489 s/iter. Total: 0.1185 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 10:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0707 s/iter. Eval: 0.0563 s/iter. Total: 0.1278 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 10:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0587 s/iter. Total: 0.1305 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:26:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.956748 (0.128937 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:26:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070769 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:26:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:26:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2598004461613808\n",
      "\u001b[32m[02/02 10:26:53 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 6539  total_loss: 1.433  loss_cls: 0.3423  loss_box_reg: 0.5111  loss_mask: 0.2974  loss_rpn_cls: 0.08366  loss_rpn_loc: 0.1986  time: 0.5774  data_time: 0.1949  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:27:04 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 6559  total_loss: 1.359  loss_cls: 0.2929  loss_box_reg: 0.5054  loss_mask: 0.2907  loss_rpn_cls: 0.07506  loss_rpn_loc: 0.1828  time: 0.5772  data_time: 0.2169  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:27:16 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 6579  total_loss: 1.441  loss_cls: 0.3499  loss_box_reg: 0.5229  loss_mask: 0.3036  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1985  time: 0.5774  data_time: 0.2938  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:27:29 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 6599  total_loss: 1.46  loss_cls: 0.3106  loss_box_reg: 0.5275  loss_mask: 0.3171  loss_rpn_cls: 0.07961  loss_rpn_loc: 0.2192  time: 0.5775  data_time: 0.3108  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:27:41 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 6619  total_loss: 1.344  loss_cls: 0.2841  loss_box_reg: 0.5035  loss_mask: 0.2958  loss_rpn_cls: 0.0791  loss_rpn_loc: 0.1826  time: 0.5776  data_time: 0.2949  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:27:51 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 6639  total_loss: 1.367  loss_cls: 0.2696  loss_box_reg: 0.5171  loss_mask: 0.2847  loss_rpn_cls: 0.05175  loss_rpn_loc: 0.1813  time: 0.5774  data_time: 0.2021  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:28:03 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 6659  total_loss: 1.499  loss_cls: 0.3529  loss_box_reg: 0.5183  loss_mask: 0.2992  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.215  time: 0.5775  data_time: 0.3188  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:28:17 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 6679  total_loss: 1.36  loss_cls: 0.3473  loss_box_reg: 0.496  loss_mask: 0.2938  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.183  time: 0.5779  data_time: 0.3811  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:28:27 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 6699  total_loss: 1.463  loss_cls: 0.3335  loss_box_reg: 0.5241  loss_mask: 0.3021  loss_rpn_cls: 0.06863  loss_rpn_loc: 0.2163  time: 0.5777  data_time: 0.1929  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:28:36 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 6719  total_loss: 1.406  loss_cls: 0.2908  loss_box_reg: 0.5002  loss_mask: 0.2972  loss_rpn_cls: 0.06413  loss_rpn_loc: 0.1815  time: 0.5773  data_time: 0.1302  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:28:45 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 6739  total_loss: 1.547  loss_cls: 0.3279  loss_box_reg: 0.589  loss_mask: 0.3087  loss_rpn_cls: 0.07481  loss_rpn_loc: 0.2039  time: 0.5769  data_time: 0.1559  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:28:58 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 6759  total_loss: 1.455  loss_cls: 0.3439  loss_box_reg: 0.4982  loss_mask: 0.2882  loss_rpn_cls: 0.08001  loss_rpn_loc: 0.1987  time: 0.5771  data_time: 0.3471  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:29:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:29:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:29:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:29:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:29:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:29:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0335 s/iter. Total: 0.1018 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0527 s/iter. Total: 0.1237 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0553 s/iter. Total: 0.1267 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:29:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.625457 (0.126082 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:29:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070411 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:29:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:29:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2563219963210134\n",
      "\u001b[32m[02/02 10:29:26 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 6779  total_loss: 1.393  loss_cls: 0.3296  loss_box_reg: 0.5237  loss_mask: 0.3022  loss_rpn_cls: 0.09424  loss_rpn_loc: 0.2029  time: 0.5772  data_time: 0.2845  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:29:42 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 6799  total_loss: 1.544  loss_cls: 0.3695  loss_box_reg: 0.5388  loss_mask: 0.2993  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.2206  time: 0.5778  data_time: 0.4686  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:29:54 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 6819  total_loss: 1.439  loss_cls: 0.2874  loss_box_reg: 0.5089  loss_mask: 0.3123  loss_rpn_cls: 0.08269  loss_rpn_loc: 0.2036  time: 0.5778  data_time: 0.2491  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:30:03 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 6839  total_loss: 1.429  loss_cls: 0.3673  loss_box_reg: 0.5213  loss_mask: 0.2999  loss_rpn_cls: 0.07086  loss_rpn_loc: 0.1813  time: 0.5774  data_time: 0.1537  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:30:14 d2.utils.events]: \u001b[0m eta: 0:17:11  iter: 6859  total_loss: 1.417  loss_cls: 0.3024  loss_box_reg: 0.5196  loss_mask: 0.3063  loss_rpn_cls: 0.09953  loss_rpn_loc: 0.2008  time: 0.5774  data_time: 0.2545  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:30:26 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 6879  total_loss: 1.436  loss_cls: 0.3319  loss_box_reg: 0.5032  loss_mask: 0.3097  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.1973  time: 0.5775  data_time: 0.2928  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:30:38 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 6899  total_loss: 1.464  loss_cls: 0.3404  loss_box_reg: 0.5214  loss_mask: 0.3022  loss_rpn_cls: 0.08896  loss_rpn_loc: 0.1955  time: 0.5775  data_time: 0.2688  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:30:47 d2.utils.events]: \u001b[0m eta: 0:16:51  iter: 6919  total_loss: 1.444  loss_cls: 0.3432  loss_box_reg: 0.4877  loss_mask: 0.3085  loss_rpn_cls: 0.08603  loss_rpn_loc: 0.2142  time: 0.5772  data_time: 0.1796  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:31:01 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 6939  total_loss: 1.464  loss_cls: 0.335  loss_box_reg: 0.5473  loss_mask: 0.3111  loss_rpn_cls: 0.09192  loss_rpn_loc: 0.1928  time: 0.5775  data_time: 0.3784  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:31:11 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 6959  total_loss: 1.395  loss_cls: 0.3009  loss_box_reg: 0.533  loss_mask: 0.2957  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1968  time: 0.5773  data_time: 0.1854  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:31:20 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 6979  total_loss: 1.342  loss_cls: 0.3049  loss_box_reg: 0.5113  loss_mask: 0.2919  loss_rpn_cls: 0.08633  loss_rpn_loc: 0.1878  time: 0.5770  data_time: 0.1704  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:31:34 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 6999  total_loss: 1.441  loss_cls: 0.3226  loss_box_reg: 0.508  loss_mask: 0.2993  loss_rpn_cls: 0.08651  loss_rpn_loc: 0.188  time: 0.5772  data_time: 0.3476  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:31:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:31:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:31:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:31:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:31:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:31:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0372 s/iter. Total: 0.1058 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0546 s/iter. Total: 0.1256 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0573 s/iter. Total: 0.1286 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:32:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.808677 (0.127661 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:32:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070456 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:32:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:32:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2607154578167145\n",
      "\u001b[32m[02/02 10:32:01 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 7019  total_loss: 1.42  loss_cls: 0.325  loss_box_reg: 0.5133  loss_mask: 0.2988  loss_rpn_cls: 0.06347  loss_rpn_loc: 0.1896  time: 0.5772  data_time: 0.2527  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:32:11 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 7039  total_loss: 1.385  loss_cls: 0.2918  loss_box_reg: 0.4874  loss_mask: 0.302  loss_rpn_cls: 0.08733  loss_rpn_loc: 0.1891  time: 0.5769  data_time: 0.1826  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:32:21 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 7059  total_loss: 1.407  loss_cls: 0.3037  loss_box_reg: 0.5284  loss_mask: 0.2939  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.1772  time: 0.5766  data_time: 0.1703  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:32:31 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 7079  total_loss: 1.484  loss_cls: 0.3453  loss_box_reg: 0.5218  loss_mask: 0.2999  loss_rpn_cls: 0.08913  loss_rpn_loc: 0.1944  time: 0.5765  data_time: 0.2281  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:32:43 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 7099  total_loss: 1.474  loss_cls: 0.3337  loss_box_reg: 0.5243  loss_mask: 0.3123  loss_rpn_cls: 0.08581  loss_rpn_loc: 0.1983  time: 0.5766  data_time: 0.2809  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:32:57 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 7119  total_loss: 1.45  loss_cls: 0.325  loss_box_reg: 0.4904  loss_mask: 0.3082  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2107  time: 0.5768  data_time: 0.3540  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:33:09 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 7139  total_loss: 1.483  loss_cls: 0.3391  loss_box_reg: 0.5337  loss_mask: 0.3047  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.2024  time: 0.5770  data_time: 0.3363  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:33:22 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 7159  total_loss: 1.452  loss_cls: 0.3277  loss_box_reg: 0.5126  loss_mask: 0.3028  loss_rpn_cls: 0.07508  loss_rpn_loc: 0.2005  time: 0.5772  data_time: 0.3292  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:33:34 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 7179  total_loss: 1.245  loss_cls: 0.274  loss_box_reg: 0.5172  loss_mask: 0.2742  loss_rpn_cls: 0.04927  loss_rpn_loc: 0.1634  time: 0.5772  data_time: 0.2599  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:33:46 d2.utils.events]: \u001b[0m eta: 0:15:16  iter: 7199  total_loss: 1.5  loss_cls: 0.3211  loss_box_reg: 0.5648  loss_mask: 0.3169  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.2112  time: 0.5772  data_time: 0.2774  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:33:57 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 7219  total_loss: 1.376  loss_cls: 0.3038  loss_box_reg: 0.5223  loss_mask: 0.3042  loss_rpn_cls: 0.07941  loss_rpn_loc: 0.185  time: 0.5771  data_time: 0.2459  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:34:07 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 7239  total_loss: 1.309  loss_cls: 0.2627  loss_box_reg: 0.4991  loss_mask: 0.2928  loss_rpn_cls: 0.08366  loss_rpn_loc: 0.1815  time: 0.5770  data_time: 0.1963  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:34:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:34:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:34:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:34:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:34:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:34:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0684 s/iter. Eval: 0.0369 s/iter. Total: 0.1059 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0551 s/iter. Total: 0.1263 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:34:28 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0588 s/iter. Total: 0.1305 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:34:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.989429 (0.129219 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:34:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070647 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:34:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:34:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25896173531186484\n",
      "\u001b[32m[02/02 10:34:32 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 7259  total_loss: 1.452  loss_cls: 0.3821  loss_box_reg: 0.5505  loss_mask: 0.329  loss_rpn_cls: 0.07608  loss_rpn_loc: 0.2003  time: 0.5766  data_time: 0.1496  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:34:47 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 7279  total_loss: 1.403  loss_cls: 0.3181  loss_box_reg: 0.4957  loss_mask: 0.296  loss_rpn_cls: 0.09609  loss_rpn_loc: 0.1876  time: 0.5771  data_time: 0.4080  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:34:59 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 7299  total_loss: 1.377  loss_cls: 0.3119  loss_box_reg: 0.4923  loss_mask: 0.3062  loss_rpn_cls: 0.07553  loss_rpn_loc: 0.2038  time: 0.5772  data_time: 0.2904  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:35:12 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 7319  total_loss: 1.482  loss_cls: 0.3226  loss_box_reg: 0.5175  loss_mask: 0.2883  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.198  time: 0.5773  data_time: 0.3127  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:35:24 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 7339  total_loss: 1.494  loss_cls: 0.3403  loss_box_reg: 0.546  loss_mask: 0.3057  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.2089  time: 0.5774  data_time: 0.2880  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:35:32 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 7359  total_loss: 1.494  loss_cls: 0.361  loss_box_reg: 0.5449  loss_mask: 0.2938  loss_rpn_cls: 0.07005  loss_rpn_loc: 0.1759  time: 0.5769  data_time: 0.1174  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:35:45 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 7379  total_loss: 1.458  loss_cls: 0.3054  loss_box_reg: 0.5324  loss_mask: 0.3119  loss_rpn_cls: 0.07203  loss_rpn_loc: 0.2011  time: 0.5771  data_time: 0.3224  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:35:55 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 7399  total_loss: 1.49  loss_cls: 0.3428  loss_box_reg: 0.5168  loss_mask: 0.2973  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.1998  time: 0.5768  data_time: 0.1942  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:36:04 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 7419  total_loss: 1.508  loss_cls: 0.3632  loss_box_reg: 0.5777  loss_mask: 0.3022  loss_rpn_cls: 0.07949  loss_rpn_loc: 0.1964  time: 0.5766  data_time: 0.1814  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:36:17 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 7439  total_loss: 1.378  loss_cls: 0.3171  loss_box_reg: 0.4872  loss_mask: 0.2924  loss_rpn_cls: 0.06427  loss_rpn_loc: 0.1783  time: 0.5767  data_time: 0.3099  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:36:31 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 7459  total_loss: 1.445  loss_cls: 0.3199  loss_box_reg: 0.5158  loss_mask: 0.309  loss_rpn_cls: 0.08895  loss_rpn_loc: 0.2049  time: 0.5771  data_time: 0.3985  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:36:43 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 7479  total_loss: 1.5  loss_cls: 0.3343  loss_box_reg: 0.5537  loss_mask: 0.3036  loss_rpn_cls: 0.08148  loss_rpn_loc: 0.2068  time: 0.5771  data_time: 0.2966  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:36:56 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 7499  total_loss: 1.344  loss_cls: 0.3087  loss_box_reg: 0.4937  loss_mask: 0.2995  loss_rpn_cls: 0.07532  loss_rpn_loc: 0.1927  time: 0.5773  data_time: 0.3262  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:36:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:36:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:36:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:36:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:36:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:36:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0370 s/iter. Total: 0.1056 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0548 s/iter. Total: 0.1260 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0578 s/iter. Total: 0.1293 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:37:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.850691 (0.128023 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:37:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070539 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:37:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:37:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26092993345209314\n",
      "\u001b[32m[02/02 10:37:22 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 7519  total_loss: 1.369  loss_cls: 0.2802  loss_box_reg: 0.515  loss_mask: 0.2979  loss_rpn_cls: 0.07383  loss_rpn_loc: 0.2184  time: 0.5770  data_time: 0.1733  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:37:32 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 7539  total_loss: 1.407  loss_cls: 0.3299  loss_box_reg: 0.5199  loss_mask: 0.315  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.1663  time: 0.5769  data_time: 0.2278  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:37:44 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 7559  total_loss: 1.473  loss_cls: 0.3484  loss_box_reg: 0.5183  loss_mask: 0.2992  loss_rpn_cls: 0.08893  loss_rpn_loc: 0.2064  time: 0.5770  data_time: 0.2979  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:37:57 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 7579  total_loss: 1.379  loss_cls: 0.3361  loss_box_reg: 0.4882  loss_mask: 0.2842  loss_rpn_cls: 0.06814  loss_rpn_loc: 0.1762  time: 0.5772  data_time: 0.3284  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:38:11 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 7599  total_loss: 1.408  loss_cls: 0.3275  loss_box_reg: 0.484  loss_mask: 0.2879  loss_rpn_cls: 0.09669  loss_rpn_loc: 0.1889  time: 0.5774  data_time: 0.3466  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:38:23 d2.utils.events]: \u001b[0m eta: 0:12:57  iter: 7619  total_loss: 1.437  loss_cls: 0.3014  loss_box_reg: 0.5057  loss_mask: 0.3101  loss_rpn_cls: 0.07143  loss_rpn_loc: 0.2  time: 0.5775  data_time: 0.3221  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:38:34 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 7639  total_loss: 1.399  loss_cls: 0.301  loss_box_reg: 0.5316  loss_mask: 0.3051  loss_rpn_cls: 0.07729  loss_rpn_loc: 0.1787  time: 0.5774  data_time: 0.2320  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:38:46 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 7659  total_loss: 1.453  loss_cls: 0.362  loss_box_reg: 0.5291  loss_mask: 0.3099  loss_rpn_cls: 0.0748  loss_rpn_loc: 0.1996  time: 0.5775  data_time: 0.2976  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:38:56 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 7679  total_loss: 1.348  loss_cls: 0.2988  loss_box_reg: 0.4951  loss_mask: 0.2932  loss_rpn_cls: 0.06398  loss_rpn_loc: 0.179  time: 0.5773  data_time: 0.2157  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:39:06 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 7699  total_loss: 1.492  loss_cls: 0.3703  loss_box_reg: 0.5437  loss_mask: 0.2982  loss_rpn_cls: 0.0588  loss_rpn_loc: 0.1946  time: 0.5771  data_time: 0.1850  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:39:21 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 7719  total_loss: 1.402  loss_cls: 0.3004  loss_box_reg: 0.4743  loss_mask: 0.3048  loss_rpn_cls: 0.09805  loss_rpn_loc: 0.181  time: 0.5775  data_time: 0.4046  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:39:35 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 7739  total_loss: 1.498  loss_cls: 0.351  loss_box_reg: 0.5014  loss_mask: 0.3136  loss_rpn_cls: 0.09567  loss_rpn_loc: 0.2152  time: 0.5778  data_time: 0.3817  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:39:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:39:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:39:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:39:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:39:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:39:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0687 s/iter. Eval: 0.0414 s/iter. Total: 0.1109 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 10:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0535 s/iter. Total: 0.1245 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0557 s/iter. Total: 0.1269 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:39:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.603918 (0.125896 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:39:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070270 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:39:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:39:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25498455753005606\n",
      "\u001b[32m[02/02 10:40:00 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 7759  total_loss: 1.381  loss_cls: 0.3221  loss_box_reg: 0.5201  loss_mask: 0.309  loss_rpn_cls: 0.08032  loss_rpn_loc: 0.1984  time: 0.5775  data_time: 0.1359  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:40:10 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 7779  total_loss: 1.441  loss_cls: 0.3395  loss_box_reg: 0.4898  loss_mask: 0.2991  loss_rpn_cls: 0.0719  loss_rpn_loc: 0.1946  time: 0.5774  data_time: 0.2175  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:40:23 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 7799  total_loss: 1.435  loss_cls: 0.3333  loss_box_reg: 0.5042  loss_mask: 0.2915  loss_rpn_cls: 0.08929  loss_rpn_loc: 0.185  time: 0.5774  data_time: 0.3044  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:40:30 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 7819  total_loss: 1.43  loss_cls: 0.3359  loss_box_reg: 0.5271  loss_mask: 0.2971  loss_rpn_cls: 0.04756  loss_rpn_loc: 0.1648  time: 0.5769  data_time: 0.0771  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:40:42 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 7839  total_loss: 1.401  loss_cls: 0.2837  loss_box_reg: 0.4895  loss_mask: 0.2983  loss_rpn_cls: 0.06836  loss_rpn_loc: 0.1918  time: 0.5769  data_time: 0.2517  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:40:54 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 7859  total_loss: 1.383  loss_cls: 0.3252  loss_box_reg: 0.5055  loss_mask: 0.2937  loss_rpn_cls: 0.08709  loss_rpn_loc: 0.1813  time: 0.5770  data_time: 0.2877  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:41:05 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 7879  total_loss: 1.43  loss_cls: 0.3275  loss_box_reg: 0.5089  loss_mask: 0.3037  loss_rpn_cls: 0.08892  loss_rpn_loc: 0.1926  time: 0.5769  data_time: 0.2480  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:41:18 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 7899  total_loss: 1.397  loss_cls: 0.3048  loss_box_reg: 0.525  loss_mask: 0.3077  loss_rpn_cls: 0.07788  loss_rpn_loc: 0.1951  time: 0.5772  data_time: 0.3605  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:41:29 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 7919  total_loss: 1.417  loss_cls: 0.2815  loss_box_reg: 0.4873  loss_mask: 0.3028  loss_rpn_cls: 0.07746  loss_rpn_loc: 0.1925  time: 0.5771  data_time: 0.2365  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:41:41 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 7939  total_loss: 1.379  loss_cls: 0.3142  loss_box_reg: 0.5029  loss_mask: 0.301  loss_rpn_cls: 0.07318  loss_rpn_loc: 0.1921  time: 0.5772  data_time: 0.2875  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:41:52 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 7959  total_loss: 1.449  loss_cls: 0.306  loss_box_reg: 0.5415  loss_mask: 0.3096  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.1988  time: 0.5771  data_time: 0.2298  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:42:07 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 7979  total_loss: 1.486  loss_cls: 0.3526  loss_box_reg: 0.4938  loss_mask: 0.3234  loss_rpn_cls: 0.09543  loss_rpn_loc: 0.2233  time: 0.5775  data_time: 0.4092  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:42:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:42:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:42:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:42:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:42:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:42:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0345 s/iter. Total: 0.1028 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0699 s/iter. Eval: 0.0520 s/iter. Total: 0.1226 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.0703 s/iter. Eval: 0.0548 s/iter. Total: 0.1258 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:42:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.396664 (0.124109 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:42:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:42:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:42:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2582842754379876\n",
      "\u001b[32m[02/02 10:42:33 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 7999  total_loss: 1.46  loss_cls: 0.3301  loss_box_reg: 0.518  loss_mask: 0.2967  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.2031  time: 0.5773  data_time: 0.2152  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:42:46 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 8019  total_loss: 1.405  loss_cls: 0.312  loss_box_reg: 0.5255  loss_mask: 0.302  loss_rpn_cls: 0.06871  loss_rpn_loc: 0.1908  time: 0.5775  data_time: 0.3445  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:42:55 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 8039  total_loss: 1.398  loss_cls: 0.323  loss_box_reg: 0.5156  loss_mask: 0.2857  loss_rpn_cls: 0.08368  loss_rpn_loc: 0.1806  time: 0.5772  data_time: 0.1499  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:43:03 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 8059  total_loss: 1.347  loss_cls: 0.2867  loss_box_reg: 0.532  loss_mask: 0.285  loss_rpn_cls: 0.06908  loss_rpn_loc: 0.1784  time: 0.5767  data_time: 0.0705  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:43:17 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 8079  total_loss: 1.513  loss_cls: 0.3152  loss_box_reg: 0.4995  loss_mask: 0.3069  loss_rpn_cls: 0.08743  loss_rpn_loc: 0.2053  time: 0.5770  data_time: 0.3991  lr: 0.0001  max_mem: 6493M\n",
      "\u001b[32m[02/02 10:43:29 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 8099  total_loss: 1.406  loss_cls: 0.3084  loss_box_reg: 0.5002  loss_mask: 0.2961  loss_rpn_cls: 0.08012  loss_rpn_loc: 0.1959  time: 0.5771  data_time: 0.2871  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:43:41 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 8119  total_loss: 1.425  loss_cls: 0.3352  loss_box_reg: 0.5166  loss_mask: 0.3129  loss_rpn_cls: 0.07774  loss_rpn_loc: 0.2069  time: 0.5771  data_time: 0.2791  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:43:55 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 8139  total_loss: 1.366  loss_cls: 0.3135  loss_box_reg: 0.5127  loss_mask: 0.2921  loss_rpn_cls: 0.09665  loss_rpn_loc: 0.1829  time: 0.5775  data_time: 0.3980  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:44:08 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 8159  total_loss: 1.454  loss_cls: 0.3588  loss_box_reg: 0.5093  loss_mask: 0.309  loss_rpn_cls: 0.09122  loss_rpn_loc: 0.2162  time: 0.5777  data_time: 0.3269  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:44:17 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 8179  total_loss: 1.391  loss_cls: 0.2965  loss_box_reg: 0.5205  loss_mask: 0.2971  loss_rpn_cls: 0.06672  loss_rpn_loc: 0.1787  time: 0.5774  data_time: 0.1581  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:44:29 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 8199  total_loss: 1.379  loss_cls: 0.3263  loss_box_reg: 0.5124  loss_mask: 0.2935  loss_rpn_cls: 0.06833  loss_rpn_loc: 0.1899  time: 0.5774  data_time: 0.2832  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:44:39 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 8219  total_loss: 1.341  loss_cls: 0.2868  loss_box_reg: 0.4866  loss_mask: 0.2859  loss_rpn_cls: 0.04665  loss_rpn_loc: 0.1714  time: 0.5771  data_time: 0.1660  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:44:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:44:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:44:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:44:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:44:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:44:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0375 s/iter. Total: 0.1063 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0553 s/iter. Total: 0.1267 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0582 s/iter. Total: 0.1301 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:45:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.938026 (0.128776 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:45:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070820 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:45:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:45:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2625619591142382\n",
      "\u001b[32m[02/02 10:45:07 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 8239  total_loss: 1.448  loss_cls: 0.3351  loss_box_reg: 0.4842  loss_mask: 0.3121  loss_rpn_cls: 0.09392  loss_rpn_loc: 0.2098  time: 0.5772  data_time: 0.2936  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:45:18 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 8259  total_loss: 1.385  loss_cls: 0.3248  loss_box_reg: 0.5207  loss_mask: 0.3016  loss_rpn_cls: 0.07102  loss_rpn_loc: 0.1934  time: 0.5771  data_time: 0.2154  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:45:27 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 8279  total_loss: 1.489  loss_cls: 0.3659  loss_box_reg: 0.5222  loss_mask: 0.3073  loss_rpn_cls: 0.09246  loss_rpn_loc: 0.1958  time: 0.5768  data_time: 0.1446  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:45:37 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 8299  total_loss: 1.433  loss_cls: 0.3255  loss_box_reg: 0.5154  loss_mask: 0.2992  loss_rpn_cls: 0.06548  loss_rpn_loc: 0.1769  time: 0.5766  data_time: 0.2003  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:45:47 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 8319  total_loss: 1.447  loss_cls: 0.3175  loss_box_reg: 0.5112  loss_mask: 0.307  loss_rpn_cls: 0.06485  loss_rpn_loc: 0.2098  time: 0.5765  data_time: 0.2146  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:46:05 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 8339  total_loss: 1.487  loss_cls: 0.3312  loss_box_reg: 0.4884  loss_mask: 0.3241  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2331  time: 0.5772  data_time: 0.5352  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:46:19 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 8359  total_loss: 1.486  loss_cls: 0.3575  loss_box_reg: 0.5446  loss_mask: 0.3089  loss_rpn_cls: 0.09303  loss_rpn_loc: 0.2167  time: 0.5774  data_time: 0.3676  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:46:28 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 8379  total_loss: 1.454  loss_cls: 0.3475  loss_box_reg: 0.5435  loss_mask: 0.2864  loss_rpn_cls: 0.06717  loss_rpn_loc: 0.1938  time: 0.5772  data_time: 0.1717  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:46:39 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 8399  total_loss: 1.456  loss_cls: 0.346  loss_box_reg: 0.4957  loss_mask: 0.2905  loss_rpn_cls: 0.06971  loss_rpn_loc: 0.1831  time: 0.5772  data_time: 0.2417  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:46:51 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 8419  total_loss: 1.296  loss_cls: 0.3175  loss_box_reg: 0.4883  loss_mask: 0.2841  loss_rpn_cls: 0.0711  loss_rpn_loc: 0.1773  time: 0.5772  data_time: 0.2552  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:47:02 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 8439  total_loss: 1.428  loss_cls: 0.3227  loss_box_reg: 0.5182  loss_mask: 0.3069  loss_rpn_cls: 0.09556  loss_rpn_loc: 0.1949  time: 0.5771  data_time: 0.2459  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:47:15 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 8459  total_loss: 1.399  loss_cls: 0.3224  loss_box_reg: 0.5165  loss_mask: 0.2828  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.2031  time: 0.5772  data_time: 0.3046  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:47:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:47:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:47:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:47:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:47:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:47:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0374 s/iter. Total: 0.1060 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0541 s/iter. Total: 0.1253 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0562 s/iter. Total: 0.1276 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:47:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.653707 (0.126325 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:47:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070423 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:47:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:47:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2605438731606948\n",
      "\u001b[32m[02/02 10:47:40 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 8479  total_loss: 1.282  loss_cls: 0.3266  loss_box_reg: 0.5019  loss_mask: 0.289  loss_rpn_cls: 0.05247  loss_rpn_loc: 0.1641  time: 0.5769  data_time: 0.1354  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:47:50 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 8499  total_loss: 1.418  loss_cls: 0.31  loss_box_reg: 0.5268  loss_mask: 0.2982  loss_rpn_cls: 0.07377  loss_rpn_loc: 0.184  time: 0.5768  data_time: 0.2296  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:48:01 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 8519  total_loss: 1.425  loss_cls: 0.3463  loss_box_reg: 0.505  loss_mask: 0.3018  loss_rpn_cls: 0.07465  loss_rpn_loc: 0.1936  time: 0.5767  data_time: 0.2105  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:48:11 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 8539  total_loss: 1.465  loss_cls: 0.3216  loss_box_reg: 0.5308  loss_mask: 0.2919  loss_rpn_cls: 0.08089  loss_rpn_loc: 0.2034  time: 0.5765  data_time: 0.2044  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:48:22 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 8559  total_loss: 1.362  loss_cls: 0.3162  loss_box_reg: 0.4775  loss_mask: 0.2894  loss_rpn_cls: 0.07739  loss_rpn_loc: 0.1845  time: 0.5765  data_time: 0.2419  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:48:35 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 8579  total_loss: 1.318  loss_cls: 0.2948  loss_box_reg: 0.4799  loss_mask: 0.287  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.185  time: 0.5766  data_time: 0.3292  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:48:49 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 8599  total_loss: 1.411  loss_cls: 0.3033  loss_box_reg: 0.4966  loss_mask: 0.3057  loss_rpn_cls: 0.08121  loss_rpn_loc: 0.1919  time: 0.5769  data_time: 0.3912  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:49:01 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 8619  total_loss: 1.523  loss_cls: 0.3523  loss_box_reg: 0.5344  loss_mask: 0.2977  loss_rpn_cls: 0.09804  loss_rpn_loc: 0.2071  time: 0.5770  data_time: 0.2894  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:49:13 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 8639  total_loss: 1.456  loss_cls: 0.3158  loss_box_reg: 0.5281  loss_mask: 0.3017  loss_rpn_cls: 0.07566  loss_rpn_loc: 0.2004  time: 0.5770  data_time: 0.2634  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:49:28 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 8659  total_loss: 1.415  loss_cls: 0.3273  loss_box_reg: 0.4863  loss_mask: 0.2961  loss_rpn_cls: 0.08861  loss_rpn_loc: 0.1834  time: 0.5774  data_time: 0.4420  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:49:40 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 8679  total_loss: 1.39  loss_cls: 0.2958  loss_box_reg: 0.5489  loss_mask: 0.3001  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.2014  time: 0.5775  data_time: 0.2956  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:49:50 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 8699  total_loss: 1.443  loss_cls: 0.3296  loss_box_reg: 0.5501  loss_mask: 0.3336  loss_rpn_cls: 0.08381  loss_rpn_loc: 0.2202  time: 0.5773  data_time: 0.1887  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:49:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:49:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:49:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:49:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:49:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:49:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0691 s/iter. Eval: 0.0427 s/iter. Total: 0.1125 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 10:50:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0549 s/iter. Total: 0.1262 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:50:09 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0008 s/iter. Inference: 0.0706 s/iter. Eval: 0.0567 s/iter. Total: 0.1281 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:50:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.741399 (0.127081 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:50:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070344 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:50:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:50:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2585378847932356\n",
      "\u001b[32m[02/02 10:50:18 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 8719  total_loss: 1.472  loss_cls: 0.3367  loss_box_reg: 0.5245  loss_mask: 0.3109  loss_rpn_cls: 0.09803  loss_rpn_loc: 0.1877  time: 0.5773  data_time: 0.2699  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:50:26 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 8739  total_loss: 1.3  loss_cls: 0.257  loss_box_reg: 0.4757  loss_mask: 0.2779  loss_rpn_cls: 0.05416  loss_rpn_loc: 0.1752  time: 0.5770  data_time: 0.1525  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:50:40 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 8759  total_loss: 1.396  loss_cls: 0.3002  loss_box_reg: 0.5217  loss_mask: 0.2956  loss_rpn_cls: 0.0796  loss_rpn_loc: 0.1809  time: 0.5772  data_time: 0.3479  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:50:51 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 8779  total_loss: 1.431  loss_cls: 0.3161  loss_box_reg: 0.5026  loss_mask: 0.3004  loss_rpn_cls: 0.08764  loss_rpn_loc: 0.1952  time: 0.5771  data_time: 0.2279  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:51:03 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 8799  total_loss: 1.531  loss_cls: 0.3512  loss_box_reg: 0.522  loss_mask: 0.3023  loss_rpn_cls: 0.07589  loss_rpn_loc: 0.1855  time: 0.5771  data_time: 0.2758  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:51:16 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 8819  total_loss: 1.424  loss_cls: 0.3343  loss_box_reg: 0.5014  loss_mask: 0.3101  loss_rpn_cls: 0.09135  loss_rpn_loc: 0.1964  time: 0.5774  data_time: 0.3754  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:51:25 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 8839  total_loss: 1.313  loss_cls: 0.2846  loss_box_reg: 0.5062  loss_mask: 0.2749  loss_rpn_cls: 0.05824  loss_rpn_loc: 0.1638  time: 0.5771  data_time: 0.1511  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:51:38 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 8859  total_loss: 1.503  loss_cls: 0.3499  loss_box_reg: 0.5087  loss_mask: 0.3058  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.2158  time: 0.5772  data_time: 0.3085  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:51:50 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 8879  total_loss: 1.412  loss_cls: 0.3348  loss_box_reg: 0.5373  loss_mask: 0.292  loss_rpn_cls: 0.07021  loss_rpn_loc: 0.1865  time: 0.5773  data_time: 0.3055  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:52:00 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 8899  total_loss: 1.399  loss_cls: 0.3378  loss_box_reg: 0.5236  loss_mask: 0.2955  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.1825  time: 0.5771  data_time: 0.1949  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:52:11 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 8919  total_loss: 1.451  loss_cls: 0.334  loss_box_reg: 0.4928  loss_mask: 0.3083  loss_rpn_cls: 0.0879  loss_rpn_loc: 0.2047  time: 0.5770  data_time: 0.2273  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:52:24 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 8939  total_loss: 1.435  loss_cls: 0.3221  loss_box_reg: 0.5107  loss_mask: 0.2976  loss_rpn_cls: 0.07182  loss_rpn_loc: 0.2012  time: 0.5772  data_time: 0.3083  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:52:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:52:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:52:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:52:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:52:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:52:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0685 s/iter. Eval: 0.0384 s/iter. Total: 0.1075 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 10:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0535 s/iter. Total: 0.1245 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0556 s/iter. Total: 0.1269 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 10:52:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.618523 (0.126022 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:52:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070341 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:52:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:52:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2593396891965734\n",
      "\u001b[32m[02/02 10:52:50 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 8959  total_loss: 1.501  loss_cls: 0.3497  loss_box_reg: 0.5292  loss_mask: 0.3139  loss_rpn_cls: 0.07206  loss_rpn_loc: 0.2023  time: 0.5770  data_time: 0.1913  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:53:00 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 8979  total_loss: 1.405  loss_cls: 0.3031  loss_box_reg: 0.5204  loss_mask: 0.306  loss_rpn_cls: 0.08668  loss_rpn_loc: 0.2169  time: 0.5768  data_time: 0.2030  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:53:11 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 8999  total_loss: 1.438  loss_cls: 0.301  loss_box_reg: 0.516  loss_mask: 0.3038  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1955  time: 0.5768  data_time: 0.2355  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:53:24 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 9019  total_loss: 1.312  loss_cls: 0.2979  loss_box_reg: 0.4648  loss_mask: 0.2991  loss_rpn_cls: 0.09655  loss_rpn_loc: 0.2016  time: 0.5770  data_time: 0.3502  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:53:38 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 9039  total_loss: 1.469  loss_cls: 0.3266  loss_box_reg: 0.4856  loss_mask: 0.3  loss_rpn_cls: 0.09488  loss_rpn_loc: 0.2158  time: 0.5772  data_time: 0.3533  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:53:50 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9059  total_loss: 1.355  loss_cls: 0.2995  loss_box_reg: 0.5036  loss_mask: 0.3024  loss_rpn_cls: 0.06731  loss_rpn_loc: 0.1808  time: 0.5773  data_time: 0.2928  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:54:01 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 9079  total_loss: 1.494  loss_cls: 0.3188  loss_box_reg: 0.522  loss_mask: 0.2955  loss_rpn_cls: 0.08165  loss_rpn_loc: 0.2082  time: 0.5771  data_time: 0.2102  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:54:14 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 9099  total_loss: 1.489  loss_cls: 0.3588  loss_box_reg: 0.5329  loss_mask: 0.3089  loss_rpn_cls: 0.08893  loss_rpn_loc: 0.2053  time: 0.5774  data_time: 0.3610  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:54:24 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 9119  total_loss: 1.511  loss_cls: 0.382  loss_box_reg: 0.5449  loss_mask: 0.3174  loss_rpn_cls: 0.08558  loss_rpn_loc: 0.206  time: 0.5772  data_time: 0.1768  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:54:33 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 9139  total_loss: 1.415  loss_cls: 0.3263  loss_box_reg: 0.4923  loss_mask: 0.2842  loss_rpn_cls: 0.08662  loss_rpn_loc: 0.1858  time: 0.5770  data_time: 0.1670  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:54:46 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 9159  total_loss: 1.441  loss_cls: 0.3242  loss_box_reg: 0.5359  loss_mask: 0.3034  loss_rpn_cls: 0.07816  loss_rpn_loc: 0.1887  time: 0.5771  data_time: 0.3228  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:54:57 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 9179  total_loss: 1.385  loss_cls: 0.3089  loss_box_reg: 0.5022  loss_mask: 0.3004  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.1859  time: 0.5770  data_time: 0.2465  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:55:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:55:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:55:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:55:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:55:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:55:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0415 s/iter. Total: 0.1115 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 10:55:11 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0541 s/iter. Total: 0.1253 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:55:16 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0571 s/iter. Total: 0.1285 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:55:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.838932 (0.127922 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:55:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070467 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:55:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:55:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2612286235341855\n",
      "\u001b[32m[02/02 10:55:22 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 9199  total_loss: 1.358  loss_cls: 0.3063  loss_box_reg: 0.5226  loss_mask: 0.2821  loss_rpn_cls: 0.06092  loss_rpn_loc: 0.1906  time: 0.5767  data_time: 0.0961  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:55:34 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 9219  total_loss: 1.361  loss_cls: 0.2821  loss_box_reg: 0.4991  loss_mask: 0.2911  loss_rpn_cls: 0.06359  loss_rpn_loc: 0.1922  time: 0.5768  data_time: 0.3098  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:55:46 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 9239  total_loss: 1.421  loss_cls: 0.3242  loss_box_reg: 0.4828  loss_mask: 0.2905  loss_rpn_cls: 0.09148  loss_rpn_loc: 0.1927  time: 0.5768  data_time: 0.2735  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:55:59 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 9259  total_loss: 1.332  loss_cls: 0.3129  loss_box_reg: 0.4826  loss_mask: 0.3052  loss_rpn_cls: 0.07763  loss_rpn_loc: 0.1863  time: 0.5770  data_time: 0.3384  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:56:11 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 9279  total_loss: 1.399  loss_cls: 0.3067  loss_box_reg: 0.5187  loss_mask: 0.299  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.1993  time: 0.5769  data_time: 0.2625  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:56:22 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 9299  total_loss: 1.399  loss_cls: 0.3448  loss_box_reg: 0.5149  loss_mask: 0.2989  loss_rpn_cls: 0.0893  loss_rpn_loc: 0.1996  time: 0.5769  data_time: 0.2590  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:56:34 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 9319  total_loss: 1.381  loss_cls: 0.2913  loss_box_reg: 0.5263  loss_mask: 0.322  loss_rpn_cls: 0.0579  loss_rpn_loc: 0.1939  time: 0.5770  data_time: 0.2841  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:56:44 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 9339  total_loss: 1.461  loss_cls: 0.3317  loss_box_reg: 0.5025  loss_mask: 0.3002  loss_rpn_cls: 0.08618  loss_rpn_loc: 0.203  time: 0.5768  data_time: 0.2082  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:56:57 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 9359  total_loss: 1.342  loss_cls: 0.2972  loss_box_reg: 0.4985  loss_mask: 0.3025  loss_rpn_cls: 0.06469  loss_rpn_loc: 0.2037  time: 0.5770  data_time: 0.3445  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:57:08 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 9379  total_loss: 1.367  loss_cls: 0.3345  loss_box_reg: 0.493  loss_mask: 0.3011  loss_rpn_cls: 0.07411  loss_rpn_loc: 0.2064  time: 0.5769  data_time: 0.2146  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:57:19 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 9399  total_loss: 1.364  loss_cls: 0.3275  loss_box_reg: 0.481  loss_mask: 0.279  loss_rpn_cls: 0.06791  loss_rpn_loc: 0.1747  time: 0.5768  data_time: 0.2250  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:57:29 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 9419  total_loss: 1.497  loss_cls: 0.3551  loss_box_reg: 0.542  loss_mask: 0.313  loss_rpn_cls: 0.07545  loss_rpn_loc: 0.2031  time: 0.5767  data_time: 0.2296  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:57:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:57:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 10:57:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 10:57:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 10:57:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 10:57:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 10:57:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.0405 s/iter. Total: 0.1110 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 10:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0551 s/iter. Total: 0.1265 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 10:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0576 s/iter. Total: 0.1292 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 10:57:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.875554 (0.128238 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:57:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070622 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 10:57:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 10:57:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2636269625761516\n",
      "\u001b[32m[02/02 10:57:57 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 9439  total_loss: 1.425  loss_cls: 0.3401  loss_box_reg: 0.522  loss_mask: 0.2956  loss_rpn_cls: 0.07136  loss_rpn_loc: 0.1733  time: 0.5767  data_time: 0.2559  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:58:09 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 9459  total_loss: 1.428  loss_cls: 0.3267  loss_box_reg: 0.5258  loss_mask: 0.2909  loss_rpn_cls: 0.08944  loss_rpn_loc: 0.204  time: 0.5768  data_time: 0.2973  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:58:22 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 9479  total_loss: 1.544  loss_cls: 0.3777  loss_box_reg: 0.5124  loss_mask: 0.3201  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.2161  time: 0.5770  data_time: 0.3307  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:58:33 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 9499  total_loss: 1.388  loss_cls: 0.3003  loss_box_reg: 0.5033  loss_mask: 0.2887  loss_rpn_cls: 0.06608  loss_rpn_loc: 0.1964  time: 0.5769  data_time: 0.2473  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:58:44 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 9519  total_loss: 1.41  loss_cls: 0.317  loss_box_reg: 0.4915  loss_mask: 0.2938  loss_rpn_cls: 0.08227  loss_rpn_loc: 0.1958  time: 0.5768  data_time: 0.2254  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:58:57 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 9539  total_loss: 1.466  loss_cls: 0.3273  loss_box_reg: 0.5228  loss_mask: 0.3013  loss_rpn_cls: 0.08344  loss_rpn_loc: 0.203  time: 0.5769  data_time: 0.3237  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:59:10 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9559  total_loss: 1.421  loss_cls: 0.3259  loss_box_reg: 0.5444  loss_mask: 0.2942  loss_rpn_cls: 0.08671  loss_rpn_loc: 0.1958  time: 0.5771  data_time: 0.3567  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:59:22 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 9579  total_loss: 1.354  loss_cls: 0.307  loss_box_reg: 0.4616  loss_mask: 0.2941  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1772  time: 0.5772  data_time: 0.2914  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:59:33 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 9599  total_loss: 1.395  loss_cls: 0.3071  loss_box_reg: 0.5128  loss_mask: 0.2914  loss_rpn_cls: 0.08563  loss_rpn_loc: 0.1847  time: 0.5771  data_time: 0.2118  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 10:59:50 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 9619  total_loss: 1.416  loss_cls: 0.3374  loss_box_reg: 0.4814  loss_mask: 0.2956  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.205  time: 0.5777  data_time: 0.5224  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:00:00 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 9639  total_loss: 1.464  loss_cls: 0.3121  loss_box_reg: 0.5188  loss_mask: 0.294  loss_rpn_cls: 0.0756  loss_rpn_loc: 0.19  time: 0.5775  data_time: 0.2164  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:00:14 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 9659  total_loss: 1.456  loss_cls: 0.3406  loss_box_reg: 0.5061  loss_mask: 0.293  loss_rpn_cls: 0.07254  loss_rpn_loc: 0.186  time: 0.5777  data_time: 0.3422  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:00:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 11:00:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 11:00:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 11:00:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 11:00:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 11:00:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 11:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.0444 s/iter. Total: 0.1133 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 11:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0554 s/iter. Total: 0.1265 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 11:00:33 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0580 s/iter. Total: 0.1295 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 11:00:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.837044 (0.127906 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 11:00:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070491 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 11:00:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 11:00:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2627246059619322\n",
      "\u001b[32m[02/02 11:00:37 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 9679  total_loss: 1.304  loss_cls: 0.2815  loss_box_reg: 0.533  loss_mask: 0.3177  loss_rpn_cls: 0.04542  loss_rpn_loc: 0.1721  time: 0.5773  data_time: 0.0695  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:00:48 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 9699  total_loss: 1.392  loss_cls: 0.2969  loss_box_reg: 0.5228  loss_mask: 0.2961  loss_rpn_cls: 0.08028  loss_rpn_loc: 0.1916  time: 0.5772  data_time: 0.2473  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:01:01 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 9719  total_loss: 1.424  loss_cls: 0.3251  loss_box_reg: 0.525  loss_mask: 0.2991  loss_rpn_cls: 0.08075  loss_rpn_loc: 0.1953  time: 0.5774  data_time: 0.3520  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:01:15 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 9739  total_loss: 1.422  loss_cls: 0.3266  loss_box_reg: 0.505  loss_mask: 0.3089  loss_rpn_cls: 0.07776  loss_rpn_loc: 0.1983  time: 0.5776  data_time: 0.3760  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:01:31 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 9759  total_loss: 1.432  loss_cls: 0.3224  loss_box_reg: 0.5041  loss_mask: 0.3421  loss_rpn_cls: 0.09716  loss_rpn_loc: 0.1923  time: 0.5780  data_time: 0.4526  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:01:40 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 9779  total_loss: 1.461  loss_cls: 0.3255  loss_box_reg: 0.5287  loss_mask: 0.3106  loss_rpn_cls: 0.06993  loss_rpn_loc: 0.1957  time: 0.5778  data_time: 0.1568  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:01:49 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 9799  total_loss: 1.276  loss_cls: 0.2862  loss_box_reg: 0.4909  loss_mask: 0.2761  loss_rpn_cls: 0.05711  loss_rpn_loc: 0.1665  time: 0.5775  data_time: 0.1264  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:01:59 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 9819  total_loss: 1.485  loss_cls: 0.3595  loss_box_reg: 0.5241  loss_mask: 0.2977  loss_rpn_cls: 0.0853  loss_rpn_loc: 0.2107  time: 0.5773  data_time: 0.1912  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:02:11 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 9839  total_loss: 1.391  loss_cls: 0.3253  loss_box_reg: 0.4965  loss_mask: 0.298  loss_rpn_cls: 0.07552  loss_rpn_loc: 0.1923  time: 0.5774  data_time: 0.2812  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:02:23 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 9859  total_loss: 1.388  loss_cls: 0.2928  loss_box_reg: 0.4955  loss_mask: 0.2956  loss_rpn_cls: 0.07956  loss_rpn_loc: 0.1839  time: 0.5774  data_time: 0.2942  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:02:35 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9879  total_loss: 1.347  loss_cls: 0.3153  loss_box_reg: 0.4893  loss_mask: 0.3019  loss_rpn_cls: 0.08441  loss_rpn_loc: 0.2012  time: 0.5775  data_time: 0.3048  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:02:48 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 9899  total_loss: 1.484  loss_cls: 0.3524  loss_box_reg: 0.4819  loss_mask: 0.2934  loss_rpn_cls: 0.08276  loss_rpn_loc: 0.193  time: 0.5776  data_time: 0.3260  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:02:59 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 9919  total_loss: 1.406  loss_cls: 0.327  loss_box_reg: 0.5016  loss_mask: 0.303  loss_rpn_cls: 0.1131  loss_rpn_loc: 0.1968  time: 0.5776  data_time: 0.2346  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:03:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 11:03:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 11:03:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 11:03:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 11:03:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 11:03:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 11:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0688 s/iter. Eval: 0.0430 s/iter. Total: 0.1126 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 11:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0535 s/iter. Total: 0.1245 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 11:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0557 s/iter. Total: 0.1269 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 11:03:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.627904 (0.126103 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 11:03:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070247 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 11:03:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 11:03:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25745614605551853\n",
      "\u001b[32m[02/02 11:03:25 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9939  total_loss: 1.383  loss_cls: 0.3219  loss_box_reg: 0.5253  loss_mask: 0.2931  loss_rpn_cls: 0.07346  loss_rpn_loc: 0.181  time: 0.5774  data_time: 0.1887  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:03:35 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 9959  total_loss: 1.403  loss_cls: 0.2972  loss_box_reg: 0.5089  loss_mask: 0.2918  loss_rpn_cls: 0.06456  loss_rpn_loc: 0.1779  time: 0.5772  data_time: 0.2054  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:03:46 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 9979  total_loss: 1.408  loss_cls: 0.3125  loss_box_reg: 0.496  loss_mask: 0.315  loss_rpn_cls: 0.07511  loss_rpn_loc: 0.1931  time: 0.5772  data_time: 0.2464  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:03:56 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.284  loss_cls: 0.2724  loss_box_reg: 0.4803  loss_mask: 0.3025  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.1819  time: 0.5770  data_time: 0.2113  lr: 0.0001  max_mem: 6565M\n",
      "\u001b[32m[02/02 11:03:56 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:36:09 (0.5770 s / it)\n",
      "\u001b[32m[02/02 11:03:56 d2.engine.hooks]: \u001b[0mTotal training time: 1:46:49 (0:10:40 on hooks)\n",
      "\u001b[32m[02/02 11:03:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 11:03:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 11:03:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 11:03:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 11:03:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 11:03:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 11:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.0391 s/iter. Total: 0.1080 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 11:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0547 s/iter. Total: 0.1259 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 11:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0574 s/iter. Total: 0.1291 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 11:04:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.808993 (0.127664 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 11:04:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070566 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 11:04:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 11:04:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.263889741194944\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.0001\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_8.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f5d69cb-40f6-451a-9915-1c83823442fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 13:16:33 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 13:16:34 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 13:16:35 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/02 13:16:36 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 13:16:36 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/02 13:16:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/02 13:16:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/02 13:16:36 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:16:36 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 13:16:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 13:16:51 d2.utils.events]: \u001b[0m eta: 1:52:52  iter: 19  total_loss: 3.11  loss_cls: 1.369  loss_box_reg: 0.4056  loss_mask: 0.6925  loss_rpn_cls: 0.3542  loss_rpn_loc: 0.2703  time: 0.7189  data_time: 0.4181  lr: 1.3987e-05  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:17:01 d2.utils.events]: \u001b[0m eta: 1:01:12  iter: 39  total_loss: 2.943  loss_cls: 1.279  loss_box_reg: 0.4505  loss_mask: 0.6801  loss_rpn_cls: 0.2729  loss_rpn_loc: 0.2363  time: 0.6147  data_time: 0.2078  lr: 2.7973e-05  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:17:15 d2.utils.events]: \u001b[0m eta: 0:57:42  iter: 59  total_loss: 2.686  loss_cls: 1.083  loss_box_reg: 0.3748  loss_mask: 0.6633  loss_rpn_cls: 0.2923  loss_rpn_loc: 0.2472  time: 0.6449  data_time: 0.3741  lr: 4.1959e-05  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:17:27 d2.utils.events]: \u001b[0m eta: 0:57:15  iter: 79  total_loss: 2.523  loss_cls: 0.8916  loss_box_reg: 0.497  loss_mask: 0.6369  loss_rpn_cls: 0.2177  loss_rpn_loc: 0.249  time: 0.6333  data_time: 0.2838  lr: 5.5945e-05  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:17:39 d2.utils.events]: \u001b[0m eta: 0:57:11  iter: 99  total_loss: 2.41  loss_cls: 0.7897  loss_box_reg: 0.5561  loss_mask: 0.5957  loss_rpn_cls: 0.2145  loss_rpn_loc: 0.2555  time: 0.6202  data_time: 0.2650  lr: 6.9931e-05  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:17:51 d2.utils.events]: \u001b[0m eta: 0:56:47  iter: 119  total_loss: 2.213  loss_cls: 0.7252  loss_box_reg: 0.564  loss_mask: 0.5479  loss_rpn_cls: 0.1847  loss_rpn_loc: 0.2377  time: 0.6210  data_time: 0.3068  lr: 8.3917e-05  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:18:01 d2.utils.events]: \u001b[0m eta: 0:56:14  iter: 139  total_loss: 2.186  loss_cls: 0.7003  loss_box_reg: 0.5925  loss_mask: 0.5154  loss_rpn_cls: 0.1654  loss_rpn_loc: 0.2137  time: 0.6021  data_time: 0.1823  lr: 9.7903e-05  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:18:13 d2.utils.events]: \u001b[0m eta: 0:55:58  iter: 159  total_loss: 2.182  loss_cls: 0.6619  loss_box_reg: 0.6183  loss_mask: 0.5071  loss_rpn_cls: 0.1473  loss_rpn_loc: 0.2464  time: 0.5997  data_time: 0.2737  lr: 0.00011189  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:18:23 d2.utils.events]: \u001b[0m eta: 0:54:36  iter: 179  total_loss: 2.039  loss_cls: 0.6066  loss_box_reg: 0.628  loss_mask: 0.4604  loss_rpn_cls: 0.1342  loss_rpn_loc: 0.2179  time: 0.5885  data_time: 0.2021  lr: 0.00012587  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:18:34 d2.utils.events]: \u001b[0m eta: 0:54:24  iter: 199  total_loss: 1.922  loss_cls: 0.4938  loss_box_reg: 0.6504  loss_mask: 0.425  loss_rpn_cls: 0.1281  loss_rpn_loc: 0.2114  time: 0.5842  data_time: 0.2323  lr: 0.00013986  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:18:44 d2.utils.events]: \u001b[0m eta: 0:53:20  iter: 219  total_loss: 1.756  loss_cls: 0.4146  loss_box_reg: 0.6504  loss_mask: 0.3632  loss_rpn_cls: 0.09182  loss_rpn_loc: 0.2152  time: 0.5772  data_time: 0.2129  lr: 0.00015385  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:18:58 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 239  total_loss: 1.812  loss_cls: 0.508  loss_box_reg: 0.6199  loss_mask: 0.3755  loss_rpn_cls: 0.1397  loss_rpn_loc: 0.2323  time: 0.5877  data_time: 0.3765  lr: 0.00016783  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:18:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:18:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:18:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:18:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:18:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:18:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0671 s/iter. Eval: 0.0195 s/iter. Total: 0.0872 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 13:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0665 s/iter. Eval: 0.0213 s/iter. Total: 0.0885 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:19:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.970690 (0.085954 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:19:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.066567 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:19:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:19:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.12329790583701325\n",
      "\u001b[32m[02/02 13:19:19 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 259  total_loss: 1.77  loss_cls: 0.4729  loss_box_reg: 0.6143  loss_mask: 0.3525  loss_rpn_cls: 0.1307  loss_rpn_loc: 0.2106  time: 0.5801  data_time: 0.1722  lr: 0.00018182  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:19:33 d2.utils.events]: \u001b[0m eta: 0:53:38  iter: 279  total_loss: 1.813  loss_cls: 0.4736  loss_box_reg: 0.5996  loss_mask: 0.3334  loss_rpn_cls: 0.14  loss_rpn_loc: 0.2142  time: 0.5904  data_time: 0.4001  lr: 0.0001958  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:19:44 d2.utils.events]: \u001b[0m eta: 0:53:27  iter: 299  total_loss: 1.799  loss_cls: 0.452  loss_box_reg: 0.6564  loss_mask: 0.3198  loss_rpn_cls: 0.1272  loss_rpn_loc: 0.22  time: 0.5868  data_time: 0.2241  lr: 0.00020979  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:19:54 d2.utils.events]: \u001b[0m eta: 0:53:06  iter: 319  total_loss: 1.726  loss_cls: 0.3943  loss_box_reg: 0.6324  loss_mask: 0.3356  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.2203  time: 0.5824  data_time: 0.2157  lr: 0.00022378  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:20:08 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 339  total_loss: 1.734  loss_cls: 0.4181  loss_box_reg: 0.5792  loss_mask: 0.3399  loss_rpn_cls: 0.1378  loss_rpn_loc: 0.2268  time: 0.5891  data_time: 0.3816  lr: 0.00023776  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:20:17 d2.utils.events]: \u001b[0m eta: 0:52:40  iter: 359  total_loss: 1.774  loss_cls: 0.4128  loss_box_reg: 0.6371  loss_mask: 0.3394  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.2323  time: 0.5804  data_time: 0.1401  lr: 0.00025175  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:20:30 d2.utils.events]: \u001b[0m eta: 0:52:42  iter: 379  total_loss: 1.742  loss_cls: 0.4461  loss_box_reg: 0.61  loss_mask: 0.323  loss_rpn_cls: 0.1154  loss_rpn_loc: 0.2302  time: 0.5835  data_time: 0.3230  lr: 0.00026573  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:20:42 d2.utils.events]: \u001b[0m eta: 0:52:44  iter: 399  total_loss: 1.643  loss_cls: 0.356  loss_box_reg: 0.611  loss_mask: 0.3198  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.2257  time: 0.5838  data_time: 0.2616  lr: 0.00027972  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:20:55 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 419  total_loss: 1.535  loss_cls: 0.3792  loss_box_reg: 0.5802  loss_mask: 0.3029  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2025  time: 0.5873  data_time: 0.3357  lr: 0.00029371  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:21:08 d2.utils.events]: \u001b[0m eta: 0:52:34  iter: 439  total_loss: 1.618  loss_cls: 0.3735  loss_box_reg: 0.5674  loss_mask: 0.3224  loss_rpn_cls: 0.1165  loss_rpn_loc: 0.2066  time: 0.5897  data_time: 0.3179  lr: 0.00030769  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:21:18 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 459  total_loss: 1.628  loss_cls: 0.3586  loss_box_reg: 0.5949  loss_mask: 0.3264  loss_rpn_cls: 0.07502  loss_rpn_loc: 0.2214  time: 0.5860  data_time: 0.2001  lr: 0.00032168  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:21:28 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 479  total_loss: 1.532  loss_cls: 0.3732  loss_box_reg: 0.5651  loss_mask: 0.3063  loss_rpn_cls: 0.09288  loss_rpn_loc: 0.2122  time: 0.5833  data_time: 0.2052  lr: 0.00033566  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:21:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:21:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:21:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:21:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:21:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:21:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0670 s/iter. Eval: 0.0302 s/iter. Total: 0.0978 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 13:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0481 s/iter. Total: 0.1192 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 13:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0523 s/iter. Total: 0.1236 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 13:21:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.085743 (0.121429 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:21:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070122 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:21:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:21:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22001447609834476\n",
      "\u001b[32m[02/02 13:21:57 d2.utils.events]: \u001b[0m eta: 0:52:21  iter: 499  total_loss: 1.648  loss_cls: 0.4155  loss_box_reg: 0.5712  loss_mask: 0.3239  loss_rpn_cls: 0.1419  loss_rpn_loc: 0.2511  time: 0.5863  data_time: 0.3235  lr: 0.00034965  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:22:07 d2.utils.events]: \u001b[0m eta: 0:52:14  iter: 519  total_loss: 1.518  loss_cls: 0.3334  loss_box_reg: 0.5756  loss_mask: 0.307  loss_rpn_cls: 0.08534  loss_rpn_loc: 0.2105  time: 0.5838  data_time: 0.2119  lr: 0.00036364  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:22:16 d2.utils.events]: \u001b[0m eta: 0:52:01  iter: 539  total_loss: 1.598  loss_cls: 0.3552  loss_box_reg: 0.6291  loss_mask: 0.312  loss_rpn_cls: 0.0985  loss_rpn_loc: 0.2136  time: 0.5788  data_time: 0.1442  lr: 0.00037762  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:22:26 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 559  total_loss: 1.681  loss_cls: 0.3897  loss_box_reg: 0.6026  loss_mask: 0.317  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2327  time: 0.5749  data_time: 0.1679  lr: 0.00039161  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:22:39 d2.utils.events]: \u001b[0m eta: 0:51:41  iter: 579  total_loss: 1.542  loss_cls: 0.3782  loss_box_reg: 0.5667  loss_mask: 0.3077  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2166  time: 0.5788  data_time: 0.3692  lr: 0.00040559  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:22:48 d2.utils.events]: \u001b[0m eta: 0:51:32  iter: 599  total_loss: 1.464  loss_cls: 0.3514  loss_box_reg: 0.5466  loss_mask: 0.3011  loss_rpn_cls: 0.08412  loss_rpn_loc: 0.2047  time: 0.5746  data_time: 0.1602  lr: 0.00041958  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:23:04 d2.utils.events]: \u001b[0m eta: 0:51:35  iter: 619  total_loss: 1.55  loss_cls: 0.3815  loss_box_reg: 0.5706  loss_mask: 0.319  loss_rpn_cls: 0.09125  loss_rpn_loc: 0.2157  time: 0.5811  data_time: 0.4480  lr: 0.00043357  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:23:17 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 639  total_loss: 1.527  loss_cls: 0.3562  loss_box_reg: 0.5401  loss_mask: 0.321  loss_rpn_cls: 0.08342  loss_rpn_loc: 0.2226  time: 0.5837  data_time: 0.3345  lr: 0.00044755  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:23:29 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 659  total_loss: 1.59  loss_cls: 0.3825  loss_box_reg: 0.5656  loss_mask: 0.3126  loss_rpn_cls: 0.103  loss_rpn_loc: 0.2219  time: 0.5838  data_time: 0.2614  lr: 0.00046154  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:23:40 d2.utils.events]: \u001b[0m eta: 0:51:25  iter: 679  total_loss: 1.542  loss_cls: 0.3109  loss_box_reg: 0.5567  loss_mask: 0.3235  loss_rpn_cls: 0.08675  loss_rpn_loc: 0.195  time: 0.5827  data_time: 0.2274  lr: 0.00047552  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:23:52 d2.utils.events]: \u001b[0m eta: 0:51:25  iter: 699  total_loss: 1.452  loss_cls: 0.3591  loss_box_reg: 0.5154  loss_mask: 0.3098  loss_rpn_cls: 0.09799  loss_rpn_loc: 0.2108  time: 0.5832  data_time: 0.2836  lr: 0.00048951  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:24:05 d2.utils.events]: \u001b[0m eta: 0:51:27  iter: 719  total_loss: 1.687  loss_cls: 0.4114  loss_box_reg: 0.5993  loss_mask: 0.3182  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.2165  time: 0.5848  data_time: 0.3089  lr: 0.0005035  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:24:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:24:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:24:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:24:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:24:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:24:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0356 s/iter. Total: 0.1037 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 55/121. Dataloading: 0.0007 s/iter. Inference: 0.0690 s/iter. Eval: 0.0429 s/iter. Total: 0.1126 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/02 13:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0007 s/iter. Inference: 0.0691 s/iter. Eval: 0.0448 s/iter. Total: 0.1146 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/02 13:24:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.124841 (0.113145 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:24:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.068875 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:24:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:24:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23034925071906626\n",
      "\u001b[32m[02/02 13:24:34 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 739  total_loss: 1.602  loss_cls: 0.3788  loss_box_reg: 0.5347  loss_mask: 0.3078  loss_rpn_cls: 0.111  loss_rpn_loc: 0.2146  time: 0.5889  data_time: 0.4115  lr: 0.00051748  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:24:46 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 759  total_loss: 1.599  loss_cls: 0.3758  loss_box_reg: 0.5384  loss_mask: 0.3036  loss_rpn_cls: 0.12  loss_rpn_loc: 0.2518  time: 0.5897  data_time: 0.3041  lr: 0.00053147  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:24:59 d2.utils.events]: \u001b[0m eta: 0:51:09  iter: 779  total_loss: 1.487  loss_cls: 0.3606  loss_box_reg: 0.5297  loss_mask: 0.3032  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.232  time: 0.5914  data_time: 0.3377  lr: 0.00054545  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:25:13 d2.utils.events]: \u001b[0m eta: 0:50:57  iter: 799  total_loss: 1.487  loss_cls: 0.3329  loss_box_reg: 0.5065  loss_mask: 0.3199  loss_rpn_cls: 0.09378  loss_rpn_loc: 0.2201  time: 0.5931  data_time: 0.3480  lr: 0.00055944  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:25:23 d2.utils.events]: \u001b[0m eta: 0:50:42  iter: 819  total_loss: 1.422  loss_cls: 0.3129  loss_box_reg: 0.5367  loss_mask: 0.3066  loss_rpn_cls: 0.0764  loss_rpn_loc: 0.1913  time: 0.5909  data_time: 0.1944  lr: 0.00057343  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:25:35 d2.utils.events]: \u001b[0m eta: 0:50:35  iter: 839  total_loss: 1.615  loss_cls: 0.3862  loss_box_reg: 0.5295  loss_mask: 0.2895  loss_rpn_cls: 0.08626  loss_rpn_loc: 0.2015  time: 0.5917  data_time: 0.3105  lr: 0.00058741  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:25:46 d2.utils.events]: \u001b[0m eta: 0:50:32  iter: 859  total_loss: 1.662  loss_cls: 0.4055  loss_box_reg: 0.5766  loss_mask: 0.3241  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.2169  time: 0.5908  data_time: 0.2379  lr: 0.0006014  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:25:56 d2.utils.events]: \u001b[0m eta: 0:50:18  iter: 879  total_loss: 1.466  loss_cls: 0.3143  loss_box_reg: 0.571  loss_mask: 0.2875  loss_rpn_cls: 0.08795  loss_rpn_loc: 0.1997  time: 0.5885  data_time: 0.1914  lr: 0.00061538  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:26:09 d2.utils.events]: \u001b[0m eta: 0:50:11  iter: 899  total_loss: 1.566  loss_cls: 0.3665  loss_box_reg: 0.5426  loss_mask: 0.3074  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.2189  time: 0.5898  data_time: 0.3236  lr: 0.00062937  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:26:19 d2.utils.events]: \u001b[0m eta: 0:50:05  iter: 919  total_loss: 1.597  loss_cls: 0.3914  loss_box_reg: 0.5578  loss_mask: 0.3102  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.2262  time: 0.5875  data_time: 0.1731  lr: 0.00064336  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:26:28 d2.utils.events]: \u001b[0m eta: 0:49:58  iter: 939  total_loss: 1.573  loss_cls: 0.3744  loss_box_reg: 0.5536  loss_mask: 0.2939  loss_rpn_cls: 0.09701  loss_rpn_loc: 0.2043  time: 0.5848  data_time: 0.1465  lr: 0.00065734  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:26:39 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 959  total_loss: 1.433  loss_cls: 0.2978  loss_box_reg: 0.5414  loss_mask: 0.3067  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.2072  time: 0.5838  data_time: 0.2341  lr: 0.00067133  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:26:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:26:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:26:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:26:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:26:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:26:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0672 s/iter. Eval: 0.0306 s/iter. Total: 0.0984 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 13:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0521 s/iter. Total: 0.1232 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 13:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0559 s/iter. Total: 0.1276 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:27:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.769647 (0.127325 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:27:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071467 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:27:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:27:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25261735697628673\n",
      "\u001b[32m[02/02 13:27:06 d2.utils.events]: \u001b[0m eta: 0:49:44  iter: 979  total_loss: 1.543  loss_cls: 0.3488  loss_box_reg: 0.5589  loss_mask: 0.3019  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.208  time: 0.5827  data_time: 0.2197  lr: 0.00068531  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:27:16 d2.utils.events]: \u001b[0m eta: 0:49:38  iter: 999  total_loss: 1.551  loss_cls: 0.3737  loss_box_reg: 0.5494  loss_mask: 0.3158  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.2044  time: 0.5811  data_time: 0.1886  lr: 0.0006993  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:27:24 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 1019  total_loss: 1.492  loss_cls: 0.3758  loss_box_reg: 0.5706  loss_mask: 0.2947  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.1888  time: 0.5782  data_time: 0.1205  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:27:38 d2.utils.events]: \u001b[0m eta: 0:49:19  iter: 1039  total_loss: 1.543  loss_cls: 0.3953  loss_box_reg: 0.5234  loss_mask: 0.3018  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.2028  time: 0.5804  data_time: 0.3635  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:27:51 d2.utils.events]: \u001b[0m eta: 0:49:11  iter: 1059  total_loss: 1.445  loss_cls: 0.3304  loss_box_reg: 0.5004  loss_mask: 0.3047  loss_rpn_cls: 0.08502  loss_rpn_loc: 0.2062  time: 0.5819  data_time: 0.3400  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:28:04 d2.utils.events]: \u001b[0m eta: 0:49:07  iter: 1079  total_loss: 1.567  loss_cls: 0.3749  loss_box_reg: 0.5487  loss_mask: 0.3201  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.2079  time: 0.5826  data_time: 0.2968  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:28:13 d2.utils.events]: \u001b[0m eta: 0:49:00  iter: 1099  total_loss: 1.557  loss_cls: 0.3184  loss_box_reg: 0.5499  loss_mask: 0.3014  loss_rpn_cls: 0.09624  loss_rpn_loc: 0.2157  time: 0.5805  data_time: 0.1634  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:28:24 d2.utils.events]: \u001b[0m eta: 0:48:51  iter: 1119  total_loss: 1.503  loss_cls: 0.3115  loss_box_reg: 0.5422  loss_mask: 0.3039  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.2187  time: 0.5798  data_time: 0.2469  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:28:36 d2.utils.events]: \u001b[0m eta: 0:48:46  iter: 1139  total_loss: 1.565  loss_cls: 0.3565  loss_box_reg: 0.5596  loss_mask: 0.3064  loss_rpn_cls: 0.09938  loss_rpn_loc: 0.1924  time: 0.5800  data_time: 0.2785  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:28:47 d2.utils.events]: \u001b[0m eta: 0:48:40  iter: 1159  total_loss: 1.517  loss_cls: 0.3664  loss_box_reg: 0.5116  loss_mask: 0.3059  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.2152  time: 0.5794  data_time: 0.2420  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:28:54 d2.utils.events]: \u001b[0m eta: 0:48:29  iter: 1179  total_loss: 1.504  loss_cls: 0.3518  loss_box_reg: 0.6043  loss_mask: 0.2912  loss_rpn_cls: 0.05532  loss_rpn_loc: 0.1839  time: 0.5755  data_time: 0.0627  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:29:08 d2.utils.events]: \u001b[0m eta: 0:48:28  iter: 1199  total_loss: 1.522  loss_cls: 0.3316  loss_box_reg: 0.5133  loss_mask: 0.3059  loss_rpn_cls: 0.1267  loss_rpn_loc: 0.2329  time: 0.5776  data_time: 0.3664  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:29:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:29:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:29:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:29:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:29:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:29:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0354 s/iter. Total: 0.1036 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0533 s/iter. Total: 0.1248 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 13:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0714 s/iter. Eval: 0.0561 s/iter. Total: 0.1282 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:29:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.734498 (0.127022 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:29:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071241 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:29:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:29:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24642534712793135\n",
      "\u001b[32m[02/02 13:29:38 d2.utils.events]: \u001b[0m eta: 0:48:29  iter: 1219  total_loss: 1.573  loss_cls: 0.3398  loss_box_reg: 0.5232  loss_mask: 0.3  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2232  time: 0.5799  data_time: 0.3877  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:29:50 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 1239  total_loss: 1.525  loss_cls: 0.3548  loss_box_reg: 0.5607  loss_mask: 0.3051  loss_rpn_cls: 0.08412  loss_rpn_loc: 0.2063  time: 0.5801  data_time: 0.2648  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:30:01 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 1259  total_loss: 1.384  loss_cls: 0.329  loss_box_reg: 0.5116  loss_mask: 0.2863  loss_rpn_cls: 0.09051  loss_rpn_loc: 0.1859  time: 0.5798  data_time: 0.2471  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:30:12 d2.utils.events]: \u001b[0m eta: 0:48:11  iter: 1279  total_loss: 1.517  loss_cls: 0.3665  loss_box_reg: 0.5349  loss_mask: 0.294  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2186  time: 0.5793  data_time: 0.2291  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:30:21 d2.utils.events]: \u001b[0m eta: 0:48:03  iter: 1299  total_loss: 1.44  loss_cls: 0.3083  loss_box_reg: 0.5552  loss_mask: 0.3017  loss_rpn_cls: 0.0917  loss_rpn_loc: 0.1934  time: 0.5771  data_time: 0.1392  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:30:32 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 1319  total_loss: 1.414  loss_cls: 0.317  loss_box_reg: 0.49  loss_mask: 0.2928  loss_rpn_cls: 0.08289  loss_rpn_loc: 0.2144  time: 0.5770  data_time: 0.2603  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:30:45 d2.utils.events]: \u001b[0m eta: 0:47:50  iter: 1339  total_loss: 1.566  loss_cls: 0.3449  loss_box_reg: 0.5396  loss_mask: 0.3244  loss_rpn_cls: 0.07936  loss_rpn_loc: 0.2224  time: 0.5775  data_time: 0.2905  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:30:55 d2.utils.events]: \u001b[0m eta: 0:47:46  iter: 1359  total_loss: 1.466  loss_cls: 0.3211  loss_box_reg: 0.5203  loss_mask: 0.2994  loss_rpn_cls: 0.07104  loss_rpn_loc: 0.1978  time: 0.5764  data_time: 0.1862  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:31:05 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 1379  total_loss: 1.375  loss_cls: 0.3193  loss_box_reg: 0.5221  loss_mask: 0.2867  loss_rpn_cls: 0.0697  loss_rpn_loc: 0.1904  time: 0.5755  data_time: 0.1901  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:31:21 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 1399  total_loss: 1.485  loss_cls: 0.3756  loss_box_reg: 0.5334  loss_mask: 0.3076  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.231  time: 0.5790  data_time: 0.4749  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:31:31 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 1419  total_loss: 1.418  loss_cls: 0.3122  loss_box_reg: 0.535  loss_mask: 0.3197  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.1942  time: 0.5776  data_time: 0.1759  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:31:45 d2.utils.events]: \u001b[0m eta: 0:47:23  iter: 1439  total_loss: 1.614  loss_cls: 0.3631  loss_box_reg: 0.5407  loss_mask: 0.3051  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.2231  time: 0.5791  data_time: 0.3632  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:31:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:31:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:31:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:31:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:31:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:31:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0336 s/iter. Total: 0.1020 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0495 s/iter. Total: 0.1202 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 13:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0533 s/iter. Total: 0.1245 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 13:32:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.093429 (0.121495 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:32:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070036 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:32:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:32:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2374083677487129\n",
      "\u001b[32m[02/02 13:32:13 d2.utils.events]: \u001b[0m eta: 0:47:19  iter: 1459  total_loss: 1.548  loss_cls: 0.3689  loss_box_reg: 0.5339  loss_mask: 0.3  loss_rpn_cls: 0.09824  loss_rpn_loc: 0.2307  time: 0.5797  data_time: 0.3138  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:32:22 d2.utils.events]: \u001b[0m eta: 0:47:07  iter: 1479  total_loss: 1.511  loss_cls: 0.3546  loss_box_reg: 0.5696  loss_mask: 0.3021  loss_rpn_cls: 0.05866  loss_rpn_loc: 0.2147  time: 0.5785  data_time: 0.1835  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:32:37 d2.utils.events]: \u001b[0m eta: 0:47:01  iter: 1499  total_loss: 1.615  loss_cls: 0.4062  loss_box_reg: 0.5343  loss_mask: 0.3188  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.2207  time: 0.5806  data_time: 0.4114  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:32:48 d2.utils.events]: \u001b[0m eta: 0:46:55  iter: 1519  total_loss: 1.39  loss_cls: 0.3011  loss_box_reg: 0.5473  loss_mask: 0.3057  loss_rpn_cls: 0.09656  loss_rpn_loc: 0.1888  time: 0.5800  data_time: 0.2132  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:32:59 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 1539  total_loss: 1.531  loss_cls: 0.3456  loss_box_reg: 0.5503  loss_mask: 0.3117  loss_rpn_cls: 0.07928  loss_rpn_loc: 0.202  time: 0.5798  data_time: 0.2630  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:33:11 d2.utils.events]: \u001b[0m eta: 0:46:49  iter: 1559  total_loss: 1.46  loss_cls: 0.3495  loss_box_reg: 0.5101  loss_mask: 0.2909  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.2134  time: 0.5800  data_time: 0.2782  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:33:22 d2.utils.events]: \u001b[0m eta: 0:46:36  iter: 1579  total_loss: 1.598  loss_cls: 0.3571  loss_box_reg: 0.588  loss_mask: 0.321  loss_rpn_cls: 0.09848  loss_rpn_loc: 0.2118  time: 0.5793  data_time: 0.2231  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:33:29 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 1599  total_loss: 1.434  loss_cls: 0.3244  loss_box_reg: 0.5439  loss_mask: 0.2929  loss_rpn_cls: 0.06889  loss_rpn_loc: 0.1885  time: 0.5769  data_time: 0.0876  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:33:40 d2.utils.events]: \u001b[0m eta: 0:46:18  iter: 1619  total_loss: 1.354  loss_cls: 0.2629  loss_box_reg: 0.5044  loss_mask: 0.2836  loss_rpn_cls: 0.07994  loss_rpn_loc: 0.2153  time: 0.5765  data_time: 0.2299  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:33:54 d2.utils.events]: \u001b[0m eta: 0:46:12  iter: 1639  total_loss: 1.55  loss_cls: 0.398  loss_box_reg: 0.5307  loss_mask: 0.3076  loss_rpn_cls: 0.08967  loss_rpn_loc: 0.2249  time: 0.5777  data_time: 0.3515  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:34:05 d2.utils.events]: \u001b[0m eta: 0:46:05  iter: 1659  total_loss: 1.432  loss_cls: 0.3024  loss_box_reg: 0.5089  loss_mask: 0.2959  loss_rpn_cls: 0.09468  loss_rpn_loc: 0.2191  time: 0.5777  data_time: 0.2727  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:34:20 d2.utils.events]: \u001b[0m eta: 0:45:58  iter: 1679  total_loss: 1.459  loss_cls: 0.3185  loss_box_reg: 0.5247  loss_mask: 0.2866  loss_rpn_cls: 0.08853  loss_rpn_loc: 0.1807  time: 0.5793  data_time: 0.3942  lr: 0.0007  max_mem: 6565M\n",
      "\u001b[32m[02/02 13:34:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:34:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:34:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:34:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:34:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:34:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0686 s/iter. Eval: 0.0347 s/iter. Total: 0.1039 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0513 s/iter. Total: 0.1233 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 13:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0008 s/iter. Inference: 0.0723 s/iter. Eval: 0.0530 s/iter. Total: 0.1261 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 13:34:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.479072 (0.124820 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:34:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071804 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:34:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:34:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2431308364249347\n",
      "\u001b[32m[02/02 13:34:48 d2.utils.events]: \u001b[0m eta: 0:45:49  iter: 1699  total_loss: 1.399  loss_cls: 0.3201  loss_box_reg: 0.4983  loss_mask: 0.3009  loss_rpn_cls: 0.08077  loss_rpn_loc: 0.1954  time: 0.5799  data_time: 0.3110  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:34:58 d2.utils.events]: \u001b[0m eta: 0:45:39  iter: 1719  total_loss: 1.498  loss_cls: 0.3539  loss_box_reg: 0.5523  loss_mask: 0.3116  loss_rpn_cls: 0.07765  loss_rpn_loc: 0.1934  time: 0.5792  data_time: 0.2168  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:35:08 d2.utils.events]: \u001b[0m eta: 0:45:30  iter: 1739  total_loss: 1.423  loss_cls: 0.3065  loss_box_reg: 0.5638  loss_mask: 0.3159  loss_rpn_cls: 0.08784  loss_rpn_loc: 0.2034  time: 0.5778  data_time: 0.1599  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:35:18 d2.utils.events]: \u001b[0m eta: 0:45:25  iter: 1759  total_loss: 1.458  loss_cls: 0.3944  loss_box_reg: 0.5402  loss_mask: 0.2927  loss_rpn_cls: 0.09645  loss_rpn_loc: 0.2111  time: 0.5771  data_time: 0.2050  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:35:28 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 1779  total_loss: 1.527  loss_cls: 0.3828  loss_box_reg: 0.5303  loss_mask: 0.323  loss_rpn_cls: 0.07732  loss_rpn_loc: 0.1895  time: 0.5764  data_time: 0.2042  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:35:40 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 1799  total_loss: 1.42  loss_cls: 0.3069  loss_box_reg: 0.5093  loss_mask: 0.2869  loss_rpn_cls: 0.1165  loss_rpn_loc: 0.1818  time: 0.5767  data_time: 0.2913  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:35:50 d2.utils.events]: \u001b[0m eta: 0:44:55  iter: 1819  total_loss: 1.379  loss_cls: 0.2796  loss_box_reg: 0.525  loss_mask: 0.303  loss_rpn_cls: 0.0475  loss_rpn_loc: 0.1693  time: 0.5757  data_time: 0.1798  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:36:02 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 1839  total_loss: 1.498  loss_cls: 0.3367  loss_box_reg: 0.5514  loss_mask: 0.2934  loss_rpn_cls: 0.09953  loss_rpn_loc: 0.1979  time: 0.5760  data_time: 0.2950  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:36:14 d2.utils.events]: \u001b[0m eta: 0:44:46  iter: 1859  total_loss: 1.366  loss_cls: 0.3154  loss_box_reg: 0.5217  loss_mask: 0.2953  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.198  time: 0.5760  data_time: 0.2628  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:36:33 d2.utils.events]: \u001b[0m eta: 0:44:46  iter: 1879  total_loss: 1.455  loss_cls: 0.3454  loss_box_reg: 0.5043  loss_mask: 0.3138  loss_rpn_cls: 0.1224  loss_rpn_loc: 0.2203  time: 0.5801  data_time: 0.6217  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:36:42 d2.utils.events]: \u001b[0m eta: 0:44:35  iter: 1899  total_loss: 1.502  loss_cls: 0.3081  loss_box_reg: 0.5403  loss_mask: 0.3078  loss_rpn_cls: 0.09653  loss_rpn_loc: 0.1844  time: 0.5788  data_time: 0.1602  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:36:54 d2.utils.events]: \u001b[0m eta: 0:44:29  iter: 1919  total_loss: 1.564  loss_cls: 0.3505  loss_box_reg: 0.5186  loss_mask: 0.3076  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.2166  time: 0.5793  data_time: 0.2986  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:37:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:37:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:37:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:37:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:37:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:37:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0384 s/iter. Total: 0.1071 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0582 s/iter. Total: 0.1298 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 13:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0638 s/iter. Total: 0.1362 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:37:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.608357 (0.134555 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:37:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071472 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:37:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:37:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2593552010595199\n",
      "\u001b[32m[02/02 13:37:24 d2.utils.events]: \u001b[0m eta: 0:44:25  iter: 1939  total_loss: 1.547  loss_cls: 0.3693  loss_box_reg: 0.5108  loss_mask: 0.3139  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2208  time: 0.5797  data_time: 0.2896  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:37:36 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 1959  total_loss: 1.577  loss_cls: 0.3676  loss_box_reg: 0.5247  loss_mask: 0.3172  loss_rpn_cls: 0.09058  loss_rpn_loc: 0.2195  time: 0.5801  data_time: 0.3042  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:37:51 d2.utils.events]: \u001b[0m eta: 0:44:19  iter: 1979  total_loss: 1.602  loss_cls: 0.4032  loss_box_reg: 0.5394  loss_mask: 0.3093  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.2062  time: 0.5818  data_time: 0.4177  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:38:03 d2.utils.events]: \u001b[0m eta: 0:44:08  iter: 1999  total_loss: 1.332  loss_cls: 0.307  loss_box_reg: 0.5135  loss_mask: 0.2826  loss_rpn_cls: 0.07084  loss_rpn_loc: 0.1972  time: 0.5817  data_time: 0.2573  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:38:17 d2.utils.events]: \u001b[0m eta: 0:44:07  iter: 2019  total_loss: 1.507  loss_cls: 0.3757  loss_box_reg: 0.5271  loss_mask: 0.3019  loss_rpn_cls: 0.0862  loss_rpn_loc: 0.2042  time: 0.5830  data_time: 0.3909  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:38:26 d2.utils.events]: \u001b[0m eta: 0:43:55  iter: 2039  total_loss: 1.49  loss_cls: 0.3232  loss_box_reg: 0.5734  loss_mask: 0.3192  loss_rpn_cls: 0.05986  loss_rpn_loc: 0.2007  time: 0.5818  data_time: 0.1634  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:38:40 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 2059  total_loss: 1.448  loss_cls: 0.3204  loss_box_reg: 0.5513  loss_mask: 0.3085  loss_rpn_cls: 0.0819  loss_rpn_loc: 0.1799  time: 0.5830  data_time: 0.3840  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:38:50 d2.utils.events]: \u001b[0m eta: 0:43:37  iter: 2079  total_loss: 1.406  loss_cls: 0.3222  loss_box_reg: 0.5398  loss_mask: 0.3051  loss_rpn_cls: 0.07894  loss_rpn_loc: 0.2215  time: 0.5818  data_time: 0.1603  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:39:02 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 2099  total_loss: 1.436  loss_cls: 0.306  loss_box_reg: 0.4876  loss_mask: 0.291  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2182  time: 0.5823  data_time: 0.3137  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:39:12 d2.utils.events]: \u001b[0m eta: 0:43:26  iter: 2119  total_loss: 1.405  loss_cls: 0.2851  loss_box_reg: 0.5183  loss_mask: 0.2937  loss_rpn_cls: 0.05634  loss_rpn_loc: 0.1887  time: 0.5814  data_time: 0.1834  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:39:22 d2.utils.events]: \u001b[0m eta: 0:43:19  iter: 2139  total_loss: 1.417  loss_cls: 0.3449  loss_box_reg: 0.5143  loss_mask: 0.2835  loss_rpn_cls: 0.09808  loss_rpn_loc: 0.1957  time: 0.5805  data_time: 0.1781  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:39:35 d2.utils.events]: \u001b[0m eta: 0:43:13  iter: 2159  total_loss: 1.563  loss_cls: 0.3762  loss_box_reg: 0.5377  loss_mask: 0.3181  loss_rpn_cls: 0.1175  loss_rpn_loc: 0.2192  time: 0.5815  data_time: 0.3705  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:39:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:39:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:39:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:39:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:39:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:39:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0691 s/iter. Eval: 0.0378 s/iter. Total: 0.1074 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0716 s/iter. Eval: 0.0533 s/iter. Total: 0.1257 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 13:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0554 s/iter. Total: 0.1275 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:40:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.597819 (0.125843 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:40:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070873 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:40:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:40:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2542666690068712\n",
      "\u001b[32m[02/02 13:40:01 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 2179  total_loss: 1.471  loss_cls: 0.3138  loss_box_reg: 0.5448  loss_mask: 0.2905  loss_rpn_cls: 0.09568  loss_rpn_loc: 0.1988  time: 0.5806  data_time: 0.1816  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:40:15 d2.utils.events]: \u001b[0m eta: 0:43:07  iter: 2199  total_loss: 1.454  loss_cls: 0.3494  loss_box_reg: 0.5091  loss_mask: 0.297  loss_rpn_cls: 0.08109  loss_rpn_loc: 0.1971  time: 0.5814  data_time: 0.3385  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:40:26 d2.utils.events]: \u001b[0m eta: 0:42:56  iter: 2219  total_loss: 1.531  loss_cls: 0.3322  loss_box_reg: 0.5424  loss_mask: 0.31  loss_rpn_cls: 0.1203  loss_rpn_loc: 0.2124  time: 0.5811  data_time: 0.2475  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:40:37 d2.utils.events]: \u001b[0m eta: 0:42:47  iter: 2239  total_loss: 1.466  loss_cls: 0.3202  loss_box_reg: 0.5284  loss_mask: 0.3095  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.2077  time: 0.5809  data_time: 0.2517  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:40:48 d2.utils.events]: \u001b[0m eta: 0:42:41  iter: 2259  total_loss: 1.51  loss_cls: 0.351  loss_box_reg: 0.5258  loss_mask: 0.3088  loss_rpn_cls: 0.09698  loss_rpn_loc: 0.2107  time: 0.5808  data_time: 0.2535  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:41:00 d2.utils.events]: \u001b[0m eta: 0:42:32  iter: 2279  total_loss: 1.42  loss_cls: 0.3379  loss_box_reg: 0.5153  loss_mask: 0.2815  loss_rpn_cls: 0.09956  loss_rpn_loc: 0.2183  time: 0.5809  data_time: 0.2846  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:41:11 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 2299  total_loss: 1.44  loss_cls: 0.3452  loss_box_reg: 0.5328  loss_mask: 0.3164  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.1793  time: 0.5807  data_time: 0.2482  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:41:24 d2.utils.events]: \u001b[0m eta: 0:42:21  iter: 2319  total_loss: 1.368  loss_cls: 0.2935  loss_box_reg: 0.5079  loss_mask: 0.2992  loss_rpn_cls: 0.09962  loss_rpn_loc: 0.1933  time: 0.5813  data_time: 0.3321  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:41:36 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 2339  total_loss: 1.39  loss_cls: 0.2965  loss_box_reg: 0.5188  loss_mask: 0.2941  loss_rpn_cls: 0.07314  loss_rpn_loc: 0.2069  time: 0.5815  data_time: 0.2881  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:41:47 d2.utils.events]: \u001b[0m eta: 0:42:09  iter: 2359  total_loss: 1.466  loss_cls: 0.3581  loss_box_reg: 0.4981  loss_mask: 0.2956  loss_rpn_cls: 0.09733  loss_rpn_loc: 0.2111  time: 0.5812  data_time: 0.2458  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:41:56 d2.utils.events]: \u001b[0m eta: 0:41:57  iter: 2379  total_loss: 1.323  loss_cls: 0.2609  loss_box_reg: 0.5064  loss_mask: 0.3085  loss_rpn_cls: 0.05643  loss_rpn_loc: 0.1787  time: 0.5802  data_time: 0.1545  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:42:07 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 2399  total_loss: 1.521  loss_cls: 0.3399  loss_box_reg: 0.535  loss_mask: 0.309  loss_rpn_cls: 0.07331  loss_rpn_loc: 0.2086  time: 0.5796  data_time: 0.1979  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:42:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:42:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:42:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:42:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:42:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:42:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0378 s/iter. Total: 0.1063 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0557 s/iter. Total: 0.1269 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 13:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0585 s/iter. Total: 0.1301 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:42:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.954083 (0.128915 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:42:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070580 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:42:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:42:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2632162482966396\n",
      "\u001b[32m[02/02 13:42:34 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 2419  total_loss: 1.341  loss_cls: 0.296  loss_box_reg: 0.5  loss_mask: 0.2757  loss_rpn_cls: 0.05463  loss_rpn_loc: 0.1842  time: 0.5793  data_time: 0.2367  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:42:45 d2.utils.events]: \u001b[0m eta: 0:41:13  iter: 2439  total_loss: 1.416  loss_cls: 0.3302  loss_box_reg: 0.5076  loss_mask: 0.2882  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.202  time: 0.5789  data_time: 0.2305  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:42:55 d2.utils.events]: \u001b[0m eta: 0:41:06  iter: 2459  total_loss: 1.37  loss_cls: 0.302  loss_box_reg: 0.5507  loss_mask: 0.2893  loss_rpn_cls: 0.06077  loss_rpn_loc: 0.1841  time: 0.5784  data_time: 0.2107  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:43:06 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 2479  total_loss: 1.479  loss_cls: 0.3615  loss_box_reg: 0.5246  loss_mask: 0.2871  loss_rpn_cls: 0.09669  loss_rpn_loc: 0.1951  time: 0.5782  data_time: 0.2521  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:43:17 d2.utils.events]: \u001b[0m eta: 0:40:52  iter: 2499  total_loss: 1.362  loss_cls: 0.3217  loss_box_reg: 0.5312  loss_mask: 0.2862  loss_rpn_cls: 0.06888  loss_rpn_loc: 0.1858  time: 0.5780  data_time: 0.2486  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:43:35 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 2519  total_loss: 1.415  loss_cls: 0.3256  loss_box_reg: 0.5196  loss_mask: 0.3133  loss_rpn_cls: 0.09727  loss_rpn_loc: 0.2022  time: 0.5805  data_time: 0.5535  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:43:47 d2.utils.events]: \u001b[0m eta: 0:40:46  iter: 2539  total_loss: 1.46  loss_cls: 0.3461  loss_box_reg: 0.5196  loss_mask: 0.3042  loss_rpn_cls: 0.07571  loss_rpn_loc: 0.1909  time: 0.5805  data_time: 0.2698  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:43:56 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 2559  total_loss: 1.476  loss_cls: 0.3012  loss_box_reg: 0.514  loss_mask: 0.3067  loss_rpn_cls: 0.07127  loss_rpn_loc: 0.1961  time: 0.5795  data_time: 0.1510  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:44:06 d2.utils.events]: \u001b[0m eta: 0:40:31  iter: 2579  total_loss: 1.521  loss_cls: 0.3614  loss_box_reg: 0.507  loss_mask: 0.2891  loss_rpn_cls: 0.0822  loss_rpn_loc: 0.2151  time: 0.5790  data_time: 0.2108  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:44:19 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 2599  total_loss: 1.437  loss_cls: 0.3264  loss_box_reg: 0.5254  loss_mask: 0.3137  loss_rpn_cls: 0.0602  loss_rpn_loc: 0.2101  time: 0.5796  data_time: 0.3459  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:44:31 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 2619  total_loss: 1.441  loss_cls: 0.3458  loss_box_reg: 0.5161  loss_mask: 0.3129  loss_rpn_cls: 0.08522  loss_rpn_loc: 0.2048  time: 0.5799  data_time: 0.2900  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:44:46 d2.utils.events]: \u001b[0m eta: 0:40:18  iter: 2639  total_loss: 1.437  loss_cls: 0.3466  loss_box_reg: 0.5161  loss_mask: 0.3072  loss_rpn_cls: 0.08997  loss_rpn_loc: 0.2131  time: 0.5812  data_time: 0.4257  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:44:55 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 2659  total_loss: 1.391  loss_cls: 0.3192  loss_box_reg: 0.5032  loss_mask: 0.2938  loss_rpn_cls: 0.0699  loss_rpn_loc: 0.1744  time: 0.5802  data_time: 0.1548  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:44:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:44:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:44:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:44:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:44:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:44:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0351 s/iter. Total: 0.1035 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0539 s/iter. Total: 0.1248 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 13:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0571 s/iter. Total: 0.1289 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:45:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.162138 (0.130708 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:45:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072164 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:45:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:45:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.262527281448105\n",
      "\u001b[32m[02/02 13:45:25 d2.utils.events]: \u001b[0m eta: 0:40:05  iter: 2679  total_loss: 1.437  loss_cls: 0.3002  loss_box_reg: 0.5184  loss_mask: 0.3123  loss_rpn_cls: 0.07633  loss_rpn_loc: 0.2128  time: 0.5806  data_time: 0.3087  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:45:38 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 2699  total_loss: 1.42  loss_cls: 0.3109  loss_box_reg: 0.4979  loss_mask: 0.3164  loss_rpn_cls: 0.08063  loss_rpn_loc: 0.2123  time: 0.5812  data_time: 0.3263  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:45:51 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 2719  total_loss: 1.509  loss_cls: 0.3293  loss_box_reg: 0.5399  loss_mask: 0.3037  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.2179  time: 0.5818  data_time: 0.3379  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:46:03 d2.utils.events]: \u001b[0m eta: 0:39:54  iter: 2739  total_loss: 1.484  loss_cls: 0.3609  loss_box_reg: 0.5498  loss_mask: 0.2955  loss_rpn_cls: 0.0824  loss_rpn_loc: 0.1779  time: 0.5817  data_time: 0.2590  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:46:14 d2.utils.events]: \u001b[0m eta: 0:39:48  iter: 2759  total_loss: 1.397  loss_cls: 0.3119  loss_box_reg: 0.497  loss_mask: 0.2922  loss_rpn_cls: 0.08535  loss_rpn_loc: 0.2067  time: 0.5817  data_time: 0.2667  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:46:27 d2.utils.events]: \u001b[0m eta: 0:39:49  iter: 2779  total_loss: 1.297  loss_cls: 0.3057  loss_box_reg: 0.4817  loss_mask: 0.2911  loss_rpn_cls: 0.08767  loss_rpn_loc: 0.209  time: 0.5821  data_time: 0.3140  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:46:38 d2.utils.events]: \u001b[0m eta: 0:39:48  iter: 2799  total_loss: 1.471  loss_cls: 0.3157  loss_box_reg: 0.5131  loss_mask: 0.3088  loss_rpn_cls: 0.06541  loss_rpn_loc: 0.1884  time: 0.5817  data_time: 0.1938  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:46:47 d2.utils.events]: \u001b[0m eta: 0:39:46  iter: 2819  total_loss: 1.346  loss_cls: 0.3003  loss_box_reg: 0.4993  loss_mask: 0.2897  loss_rpn_cls: 0.05215  loss_rpn_loc: 0.1762  time: 0.5810  data_time: 0.1630  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:47:02 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 2839  total_loss: 1.404  loss_cls: 0.3321  loss_box_reg: 0.5281  loss_mask: 0.3079  loss_rpn_cls: 0.09666  loss_rpn_loc: 0.2294  time: 0.5820  data_time: 0.4023  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:47:12 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 2859  total_loss: 1.469  loss_cls: 0.3261  loss_box_reg: 0.5309  loss_mask: 0.2986  loss_rpn_cls: 0.08343  loss_rpn_loc: 0.2164  time: 0.5815  data_time: 0.2046  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:47:21 d2.utils.events]: \u001b[0m eta: 0:39:17  iter: 2879  total_loss: 1.282  loss_cls: 0.3084  loss_box_reg: 0.517  loss_mask: 0.2833  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.1598  time: 0.5807  data_time: 0.1641  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:47:33 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 2899  total_loss: 1.543  loss_cls: 0.3856  loss_box_reg: 0.5209  loss_mask: 0.3129  loss_rpn_cls: 0.08759  loss_rpn_loc: 0.2231  time: 0.5807  data_time: 0.2686  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:47:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:47:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:47:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:47:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:47:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:47:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.0382 s/iter. Total: 0.1068 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:47:42 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0522 s/iter. Total: 0.1230 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 13:47:47 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0538 s/iter. Total: 0.1248 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 13:47:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.272456 (0.123038 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:47:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070055 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:47:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24704870051523398\n",
      "\u001b[32m[02/02 13:48:04 d2.utils.events]: \u001b[0m eta: 0:39:11  iter: 2919  total_loss: 1.357  loss_cls: 0.2962  loss_box_reg: 0.4783  loss_mask: 0.2931  loss_rpn_cls: 0.08346  loss_rpn_loc: 0.2067  time: 0.5820  data_time: 0.4456  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:48:16 d2.utils.events]: \u001b[0m eta: 0:39:02  iter: 2939  total_loss: 1.464  loss_cls: 0.3618  loss_box_reg: 0.4862  loss_mask: 0.2923  loss_rpn_cls: 0.08556  loss_rpn_loc: 0.2296  time: 0.5822  data_time: 0.2850  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:48:29 d2.utils.events]: \u001b[0m eta: 0:38:53  iter: 2959  total_loss: 1.405  loss_cls: 0.3204  loss_box_reg: 0.5246  loss_mask: 0.2932  loss_rpn_cls: 0.08226  loss_rpn_loc: 0.1852  time: 0.5827  data_time: 0.3310  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:48:42 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 2979  total_loss: 1.459  loss_cls: 0.307  loss_box_reg: 0.5028  loss_mask: 0.3027  loss_rpn_cls: 0.09037  loss_rpn_loc: 0.2128  time: 0.5832  data_time: 0.3480  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:48:51 d2.utils.events]: \u001b[0m eta: 0:38:37  iter: 2999  total_loss: 1.416  loss_cls: 0.3196  loss_box_reg: 0.5315  loss_mask: 0.2957  loss_rpn_cls: 0.06041  loss_rpn_loc: 0.185  time: 0.5821  data_time: 0.1233  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:49:05 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 3019  total_loss: 1.454  loss_cls: 0.3468  loss_box_reg: 0.5244  loss_mask: 0.3139  loss_rpn_cls: 0.08433  loss_rpn_loc: 0.2081  time: 0.5828  data_time: 0.3610  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:49:19 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 3039  total_loss: 1.391  loss_cls: 0.3379  loss_box_reg: 0.4891  loss_mask: 0.2889  loss_rpn_cls: 0.07481  loss_rpn_loc: 0.1865  time: 0.5838  data_time: 0.4045  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:49:29 d2.utils.events]: \u001b[0m eta: 0:38:21  iter: 3059  total_loss: 1.392  loss_cls: 0.3048  loss_box_reg: 0.5134  loss_mask: 0.3088  loss_rpn_cls: 0.06094  loss_rpn_loc: 0.1888  time: 0.5832  data_time: 0.1828  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:49:42 d2.utils.events]: \u001b[0m eta: 0:38:17  iter: 3079  total_loss: 1.484  loss_cls: 0.3772  loss_box_reg: 0.5686  loss_mask: 0.3065  loss_rpn_cls: 0.06582  loss_rpn_loc: 0.2396  time: 0.5836  data_time: 0.3196  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:49:52 d2.utils.events]: \u001b[0m eta: 0:38:05  iter: 3099  total_loss: 1.489  loss_cls: 0.362  loss_box_reg: 0.5375  loss_mask: 0.3002  loss_rpn_cls: 0.07362  loss_rpn_loc: 0.1977  time: 0.5830  data_time: 0.1757  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:50:03 d2.utils.events]: \u001b[0m eta: 0:38:02  iter: 3119  total_loss: 1.304  loss_cls: 0.2498  loss_box_reg: 0.4804  loss_mask: 0.287  loss_rpn_cls: 0.06131  loss_rpn_loc: 0.1685  time: 0.5830  data_time: 0.2621  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:50:15 d2.utils.events]: \u001b[0m eta: 0:38:01  iter: 3139  total_loss: 1.383  loss_cls: 0.2968  loss_box_reg: 0.5088  loss_mask: 0.2938  loss_rpn_cls: 0.08792  loss_rpn_loc: 0.1921  time: 0.5830  data_time: 0.2668  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:50:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:50:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:50:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:50:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:50:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:50:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0391 s/iter. Total: 0.1078 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0576 s/iter. Total: 0.1291 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 13:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0716 s/iter. Eval: 0.0628 s/iter. Total: 0.1352 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:50:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.402247 (0.132778 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:50:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071169 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:50:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:50:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2631725025562033\n",
      "\u001b[32m[02/02 13:50:41 d2.utils.events]: \u001b[0m eta: 0:37:51  iter: 3159  total_loss: 1.38  loss_cls: 0.3277  loss_box_reg: 0.5092  loss_mask: 0.2878  loss_rpn_cls: 0.06622  loss_rpn_loc: 0.1946  time: 0.5820  data_time: 0.1250  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:50:52 d2.utils.events]: \u001b[0m eta: 0:37:46  iter: 3179  total_loss: 1.5  loss_cls: 0.3467  loss_box_reg: 0.5167  loss_mask: 0.3055  loss_rpn_cls: 0.07162  loss_rpn_loc: 0.1914  time: 0.5820  data_time: 0.2530  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:51:03 d2.utils.events]: \u001b[0m eta: 0:37:38  iter: 3199  total_loss: 1.329  loss_cls: 0.2931  loss_box_reg: 0.5112  loss_mask: 0.2882  loss_rpn_cls: 0.06256  loss_rpn_loc: 0.1806  time: 0.5818  data_time: 0.2373  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:51:17 d2.utils.events]: \u001b[0m eta: 0:37:31  iter: 3219  total_loss: 1.403  loss_cls: 0.3197  loss_box_reg: 0.4985  loss_mask: 0.2999  loss_rpn_cls: 0.08714  loss_rpn_loc: 0.1919  time: 0.5823  data_time: 0.3494  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:51:29 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 3239  total_loss: 1.356  loss_cls: 0.3276  loss_box_reg: 0.5096  loss_mask: 0.2951  loss_rpn_cls: 0.07074  loss_rpn_loc: 0.1947  time: 0.5825  data_time: 0.2908  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:51:40 d2.utils.events]: \u001b[0m eta: 0:37:22  iter: 3259  total_loss: 1.338  loss_cls: 0.3054  loss_box_reg: 0.5118  loss_mask: 0.2936  loss_rpn_cls: 0.06112  loss_rpn_loc: 0.2016  time: 0.5824  data_time: 0.2413  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:51:49 d2.utils.events]: \u001b[0m eta: 0:37:11  iter: 3279  total_loss: 1.369  loss_cls: 0.2999  loss_box_reg: 0.5183  loss_mask: 0.3011  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.1889  time: 0.5815  data_time: 0.1332  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:52:01 d2.utils.events]: \u001b[0m eta: 0:37:05  iter: 3299  total_loss: 1.501  loss_cls: 0.3422  loss_box_reg: 0.5167  loss_mask: 0.301  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.194  time: 0.5818  data_time: 0.3196  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:52:12 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 3319  total_loss: 1.387  loss_cls: 0.3348  loss_box_reg: 0.4956  loss_mask: 0.2863  loss_rpn_cls: 0.07262  loss_rpn_loc: 0.1864  time: 0.5816  data_time: 0.2300  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:52:29 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 3339  total_loss: 1.46  loss_cls: 0.3155  loss_box_reg: 0.5076  loss_mask: 0.2986  loss_rpn_cls: 0.08569  loss_rpn_loc: 0.2007  time: 0.5831  data_time: 0.5056  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:52:43 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 3359  total_loss: 1.519  loss_cls: 0.3726  loss_box_reg: 0.4912  loss_mask: 0.3161  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2145  time: 0.5837  data_time: 0.3419  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:52:53 d2.utils.events]: \u001b[0m eta: 0:36:44  iter: 3379  total_loss: 1.441  loss_cls: 0.2986  loss_box_reg: 0.5648  loss_mask: 0.2994  loss_rpn_cls: 0.07532  loss_rpn_loc: 0.1992  time: 0.5833  data_time: 0.2214  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:52:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:52:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:52:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:52:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:52:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:52:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0394 s/iter. Total: 0.1104 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 13:53:05 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0722 s/iter. Eval: 0.0583 s/iter. Total: 0.1313 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 13:53:10 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0737 s/iter. Eval: 0.0628 s/iter. Total: 0.1373 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 13:53:15 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0739 s/iter. Eval: 0.0628 s/iter. Total: 0.1375 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/02 13:53:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.989340 (0.137839 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:53:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073863 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:53:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:53:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2628562022329087\n",
      "\u001b[32m[02/02 13:53:24 d2.utils.events]: \u001b[0m eta: 0:36:45  iter: 3399  total_loss: 1.483  loss_cls: 0.3492  loss_box_reg: 0.5421  loss_mask: 0.3046  loss_rpn_cls: 0.07405  loss_rpn_loc: 0.1907  time: 0.5839  data_time: 0.3696  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:53:37 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 3419  total_loss: 1.471  loss_cls: 0.3432  loss_box_reg: 0.5092  loss_mask: 0.3077  loss_rpn_cls: 0.0821  loss_rpn_loc: 0.1969  time: 0.5841  data_time: 0.2956  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:53:47 d2.utils.events]: \u001b[0m eta: 0:36:38  iter: 3439  total_loss: 1.423  loss_cls: 0.3169  loss_box_reg: 0.5054  loss_mask: 0.2948  loss_rpn_cls: 0.07536  loss_rpn_loc: 0.1815  time: 0.5838  data_time: 0.2235  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:53:58 d2.utils.events]: \u001b[0m eta: 0:36:32  iter: 3459  total_loss: 1.41  loss_cls: 0.2676  loss_box_reg: 0.5484  loss_mask: 0.3218  loss_rpn_cls: 0.06097  loss_rpn_loc: 0.199  time: 0.5835  data_time: 0.2287  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:54:09 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 3479  total_loss: 1.425  loss_cls: 0.343  loss_box_reg: 0.5623  loss_mask: 0.2895  loss_rpn_cls: 0.07671  loss_rpn_loc: 0.1927  time: 0.5833  data_time: 0.2447  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:54:19 d2.utils.events]: \u001b[0m eta: 0:36:15  iter: 3499  total_loss: 1.336  loss_cls: 0.2876  loss_box_reg: 0.5043  loss_mask: 0.2863  loss_rpn_cls: 0.05355  loss_rpn_loc: 0.1666  time: 0.5828  data_time: 0.1737  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:54:31 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 3519  total_loss: 1.416  loss_cls: 0.2997  loss_box_reg: 0.5143  loss_mask: 0.3095  loss_rpn_cls: 0.07686  loss_rpn_loc: 0.1928  time: 0.5830  data_time: 0.3154  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:54:43 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 3539  total_loss: 1.459  loss_cls: 0.3713  loss_box_reg: 0.4944  loss_mask: 0.307  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.1836  time: 0.5830  data_time: 0.2736  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:54:56 d2.utils.events]: \u001b[0m eta: 0:35:59  iter: 3559  total_loss: 1.345  loss_cls: 0.2982  loss_box_reg: 0.5023  loss_mask: 0.3067  loss_rpn_cls: 0.06967  loss_rpn_loc: 0.2091  time: 0.5835  data_time: 0.3456  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:55:11 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 3579  total_loss: 1.392  loss_cls: 0.307  loss_box_reg: 0.4953  loss_mask: 0.3033  loss_rpn_cls: 0.08017  loss_rpn_loc: 0.1991  time: 0.5842  data_time: 0.4013  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:55:22 d2.utils.events]: \u001b[0m eta: 0:35:48  iter: 3599  total_loss: 1.357  loss_cls: 0.3005  loss_box_reg: 0.471  loss_mask: 0.2901  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1979  time: 0.5841  data_time: 0.2436  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:55:31 d2.utils.events]: \u001b[0m eta: 0:35:38  iter: 3619  total_loss: 1.29  loss_cls: 0.2603  loss_box_reg: 0.506  loss_mask: 0.2919  loss_rpn_cls: 0.06093  loss_rpn_loc: 0.1736  time: 0.5834  data_time: 0.1510  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:55:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:55:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:55:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:55:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:55:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:55:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0386 s/iter. Total: 0.1073 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0569 s/iter. Total: 0.1286 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 13:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0718 s/iter. Eval: 0.0617 s/iter. Total: 0.1343 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:55:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.467282 (0.133339 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:55:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071918 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:55:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:55:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26497093297409013\n",
      "\u001b[32m[02/02 13:55:59 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 3639  total_loss: 1.469  loss_cls: 0.3495  loss_box_reg: 0.5092  loss_mask: 0.3092  loss_rpn_cls: 0.09728  loss_rpn_loc: 0.2214  time: 0.5831  data_time: 0.2077  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:56:12 d2.utils.events]: \u001b[0m eta: 0:35:28  iter: 3659  total_loss: 1.466  loss_cls: 0.3466  loss_box_reg: 0.4799  loss_mask: 0.2985  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.1947  time: 0.5836  data_time: 0.3533  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:56:25 d2.utils.events]: \u001b[0m eta: 0:35:21  iter: 3679  total_loss: 1.392  loss_cls: 0.3062  loss_box_reg: 0.514  loss_mask: 0.3085  loss_rpn_cls: 0.08184  loss_rpn_loc: 0.2107  time: 0.5839  data_time: 0.3336  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:56:35 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 3699  total_loss: 1.363  loss_cls: 0.2818  loss_box_reg: 0.4997  loss_mask: 0.3008  loss_rpn_cls: 0.05583  loss_rpn_loc: 0.1919  time: 0.5833  data_time: 0.1728  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:56:44 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 3719  total_loss: 1.483  loss_cls: 0.3368  loss_box_reg: 0.5341  loss_mask: 0.3146  loss_rpn_cls: 0.06781  loss_rpn_loc: 0.2002  time: 0.5828  data_time: 0.1764  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:56:58 d2.utils.events]: \u001b[0m eta: 0:34:53  iter: 3739  total_loss: 1.345  loss_cls: 0.3136  loss_box_reg: 0.4917  loss_mask: 0.2876  loss_rpn_cls: 0.07946  loss_rpn_loc: 0.2039  time: 0.5834  data_time: 0.3657  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:57:11 d2.utils.events]: \u001b[0m eta: 0:34:49  iter: 3759  total_loss: 1.502  loss_cls: 0.3238  loss_box_reg: 0.5541  loss_mask: 0.3132  loss_rpn_cls: 0.08271  loss_rpn_loc: 0.1955  time: 0.5838  data_time: 0.3131  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:57:25 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 3779  total_loss: 1.431  loss_cls: 0.3424  loss_box_reg: 0.49  loss_mask: 0.3073  loss_rpn_cls: 0.084  loss_rpn_loc: 0.1952  time: 0.5842  data_time: 0.3341  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:57:34 d2.utils.events]: \u001b[0m eta: 0:34:32  iter: 3799  total_loss: 1.394  loss_cls: 0.3882  loss_box_reg: 0.524  loss_mask: 0.2934  loss_rpn_cls: 0.08524  loss_rpn_loc: 0.1966  time: 0.5837  data_time: 0.1830  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:57:47 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 3819  total_loss: 1.501  loss_cls: 0.3174  loss_box_reg: 0.5214  loss_mask: 0.3074  loss_rpn_cls: 0.07808  loss_rpn_loc: 0.2083  time: 0.5838  data_time: 0.2948  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:57:56 d2.utils.events]: \u001b[0m eta: 0:34:17  iter: 3839  total_loss: 1.312  loss_cls: 0.2801  loss_box_reg: 0.4999  loss_mask: 0.2981  loss_rpn_cls: 0.05221  loss_rpn_loc: 0.1658  time: 0.5833  data_time: 0.1916  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:58:07 d2.utils.events]: \u001b[0m eta: 0:34:12  iter: 3859  total_loss: 1.487  loss_cls: 0.3484  loss_box_reg: 0.5136  loss_mask: 0.3061  loss_rpn_cls: 0.09391  loss_rpn_loc: 0.2034  time: 0.5830  data_time: 0.2027  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:58:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:58:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 13:58:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 13:58:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 13:58:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 13:58:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 13:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0381 s/iter. Total: 0.1068 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 13:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0569 s/iter. Total: 0.1295 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 13:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0721 s/iter. Eval: 0.0613 s/iter. Total: 0.1342 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 13:58:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.300652 (0.131902 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:58:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071566 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 13:58:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 13:58:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2686500251738474\n",
      "\u001b[32m[02/02 13:58:35 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 3879  total_loss: 1.347  loss_cls: 0.3003  loss_box_reg: 0.5056  loss_mask: 0.3027  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1983  time: 0.5830  data_time: 0.2833  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:58:48 d2.utils.events]: \u001b[0m eta: 0:34:03  iter: 3899  total_loss: 1.492  loss_cls: 0.3497  loss_box_reg: 0.5509  loss_mask: 0.3179  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.2017  time: 0.5833  data_time: 0.2889  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:59:01 d2.utils.events]: \u001b[0m eta: 0:33:57  iter: 3919  total_loss: 1.43  loss_cls: 0.3327  loss_box_reg: 0.5135  loss_mask: 0.2885  loss_rpn_cls: 0.07003  loss_rpn_loc: 0.1894  time: 0.5836  data_time: 0.3181  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:59:14 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 3939  total_loss: 1.394  loss_cls: 0.3391  loss_box_reg: 0.4932  loss_mask: 0.3026  loss_rpn_cls: 0.08381  loss_rpn_loc: 0.1994  time: 0.5840  data_time: 0.3386  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:59:35 d2.utils.events]: \u001b[0m eta: 0:33:51  iter: 3959  total_loss: 1.479  loss_cls: 0.3606  loss_box_reg: 0.4904  loss_mask: 0.3103  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.2191  time: 0.5862  data_time: 0.6672  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:59:45 d2.utils.events]: \u001b[0m eta: 0:33:42  iter: 3979  total_loss: 1.46  loss_cls: 0.3556  loss_box_reg: 0.545  loss_mask: 0.3044  loss_rpn_cls: 0.07306  loss_rpn_loc: 0.1917  time: 0.5859  data_time: 0.1895  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 13:59:59 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 3999  total_loss: 1.386  loss_cls: 0.2906  loss_box_reg: 0.473  loss_mask: 0.2891  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.2097  time: 0.5865  data_time: 0.3619  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:00:09 d2.utils.events]: \u001b[0m eta: 0:33:27  iter: 4019  total_loss: 1.465  loss_cls: 0.3452  loss_box_reg: 0.5416  loss_mask: 0.2871  loss_rpn_cls: 0.07752  loss_rpn_loc: 0.2023  time: 0.5861  data_time: 0.1994  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:00:20 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 4039  total_loss: 1.357  loss_cls: 0.3378  loss_box_reg: 0.4998  loss_mask: 0.2736  loss_rpn_cls: 0.06298  loss_rpn_loc: 0.1917  time: 0.5858  data_time: 0.2197  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:00:29 d2.utils.events]: \u001b[0m eta: 0:33:09  iter: 4059  total_loss: 1.36  loss_cls: 0.3048  loss_box_reg: 0.5205  loss_mask: 0.281  loss_rpn_cls: 0.07581  loss_rpn_loc: 0.1948  time: 0.5851  data_time: 0.1443  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:00:41 d2.utils.events]: \u001b[0m eta: 0:33:05  iter: 4079  total_loss: 1.52  loss_cls: 0.3289  loss_box_reg: 0.5021  loss_mask: 0.3124  loss_rpn_cls: 0.09394  loss_rpn_loc: 0.1999  time: 0.5852  data_time: 0.2884  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:00:50 d2.utils.events]: \u001b[0m eta: 0:32:58  iter: 4099  total_loss: 1.311  loss_cls: 0.2835  loss_box_reg: 0.4924  loss_mask: 0.2791  loss_rpn_cls: 0.0537  loss_rpn_loc: 0.1747  time: 0.5846  data_time: 0.1674  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:00:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:00:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:00:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:00:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:00:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:00:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:00:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0675 s/iter. Eval: 0.0344 s/iter. Total: 0.1025 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:01:05 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0533 s/iter. Total: 0.1241 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:01:10 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0576 s/iter. Total: 0.1292 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:01:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.022160 (0.129501 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:01:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071410 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:01:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:01:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2542676247811114\n",
      "\u001b[32m[02/02 14:01:17 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 4119  total_loss: 1.455  loss_cls: 0.3215  loss_box_reg: 0.5165  loss_mask: 0.316  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.2044  time: 0.5843  data_time: 0.1927  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:01:27 d2.utils.events]: \u001b[0m eta: 0:32:40  iter: 4139  total_loss: 1.455  loss_cls: 0.3325  loss_box_reg: 0.4911  loss_mask: 0.2826  loss_rpn_cls: 0.08296  loss_rpn_loc: 0.2092  time: 0.5839  data_time: 0.1810  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:01:37 d2.utils.events]: \u001b[0m eta: 0:32:33  iter: 4159  total_loss: 1.344  loss_cls: 0.2986  loss_box_reg: 0.5166  loss_mask: 0.2988  loss_rpn_cls: 0.04694  loss_rpn_loc: 0.179  time: 0.5835  data_time: 0.1920  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:01:47 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 4179  total_loss: 1.401  loss_cls: 0.3277  loss_box_reg: 0.5396  loss_mask: 0.2946  loss_rpn_cls: 0.06816  loss_rpn_loc: 0.2009  time: 0.5831  data_time: 0.1825  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:02:01 d2.utils.events]: \u001b[0m eta: 0:32:21  iter: 4199  total_loss: 1.523  loss_cls: 0.3457  loss_box_reg: 0.5151  loss_mask: 0.321  loss_rpn_cls: 0.09215  loss_rpn_loc: 0.2187  time: 0.5837  data_time: 0.4012  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:02:11 d2.utils.events]: \u001b[0m eta: 0:32:13  iter: 4219  total_loss: 1.387  loss_cls: 0.282  loss_box_reg: 0.4955  loss_mask: 0.2911  loss_rpn_cls: 0.07084  loss_rpn_loc: 0.1945  time: 0.5832  data_time: 0.1573  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:02:23 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 4239  total_loss: 1.472  loss_cls: 0.3475  loss_box_reg: 0.5241  loss_mask: 0.3005  loss_rpn_cls: 0.08052  loss_rpn_loc: 0.1991  time: 0.5833  data_time: 0.2997  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:02:32 d2.utils.events]: \u001b[0m eta: 0:31:58  iter: 4259  total_loss: 1.334  loss_cls: 0.3038  loss_box_reg: 0.5188  loss_mask: 0.2928  loss_rpn_cls: 0.04125  loss_rpn_loc: 0.1718  time: 0.5827  data_time: 0.1353  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:02:48 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 4279  total_loss: 1.4  loss_cls: 0.336  loss_box_reg: 0.4897  loss_mask: 0.2919  loss_rpn_cls: 0.07451  loss_rpn_loc: 0.1795  time: 0.5837  data_time: 0.4699  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:03:01 d2.utils.events]: \u001b[0m eta: 0:31:49  iter: 4299  total_loss: 1.329  loss_cls: 0.2861  loss_box_reg: 0.4716  loss_mask: 0.2859  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.2114  time: 0.5841  data_time: 0.3550  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:03:14 d2.utils.events]: \u001b[0m eta: 0:31:42  iter: 4319  total_loss: 1.311  loss_cls: 0.2841  loss_box_reg: 0.4865  loss_mask: 0.2998  loss_rpn_cls: 0.07588  loss_rpn_loc: 0.1963  time: 0.5843  data_time: 0.3002  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:03:25 d2.utils.events]: \u001b[0m eta: 0:31:34  iter: 4339  total_loss: 1.394  loss_cls: 0.3139  loss_box_reg: 0.5009  loss_mask: 0.3069  loss_rpn_cls: 0.0687  loss_rpn_loc: 0.1812  time: 0.5841  data_time: 0.2304  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:03:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:03:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:03:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:03:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:03:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:03:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:03:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0356 s/iter. Total: 0.1073 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0718 s/iter. Eval: 0.0553 s/iter. Total: 0.1279 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0602 s/iter. Total: 0.1330 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:03:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.250888 (0.131473 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:03:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071708 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:03:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:03:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2653001807004951\n",
      "\u001b[32m[02/02 14:03:56 d2.utils.events]: \u001b[0m eta: 0:31:26  iter: 4359  total_loss: 1.496  loss_cls: 0.3565  loss_box_reg: 0.5257  loss_mask: 0.3069  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.2077  time: 0.5846  data_time: 0.3739  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:04:06 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 4379  total_loss: 1.343  loss_cls: 0.2716  loss_box_reg: 0.49  loss_mask: 0.2908  loss_rpn_cls: 0.06754  loss_rpn_loc: 0.1844  time: 0.5844  data_time: 0.2313  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:04:21 d2.utils.events]: \u001b[0m eta: 0:31:14  iter: 4399  total_loss: 1.475  loss_cls: 0.3435  loss_box_reg: 0.4906  loss_mask: 0.2894  loss_rpn_cls: 0.08068  loss_rpn_loc: 0.2094  time: 0.5851  data_time: 0.4056  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:04:30 d2.utils.events]: \u001b[0m eta: 0:31:06  iter: 4419  total_loss: 1.455  loss_cls: 0.3375  loss_box_reg: 0.4976  loss_mask: 0.2965  loss_rpn_cls: 0.0724  loss_rpn_loc: 0.1886  time: 0.5845  data_time: 0.1400  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:04:46 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 4439  total_loss: 1.422  loss_cls: 0.3283  loss_box_reg: 0.48  loss_mask: 0.3119  loss_rpn_cls: 0.08718  loss_rpn_loc: 0.2025  time: 0.5853  data_time: 0.4223  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:04:54 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 4459  total_loss: 1.473  loss_cls: 0.3091  loss_box_reg: 0.5501  loss_mask: 0.3003  loss_rpn_cls: 0.0834  loss_rpn_loc: 0.1936  time: 0.5846  data_time: 0.1362  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:05:06 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 4479  total_loss: 1.327  loss_cls: 0.2787  loss_box_reg: 0.4939  loss_mask: 0.2867  loss_rpn_cls: 0.06729  loss_rpn_loc: 0.1892  time: 0.5847  data_time: 0.2943  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:05:17 d2.utils.events]: \u001b[0m eta: 0:30:45  iter: 4499  total_loss: 1.396  loss_cls: 0.3006  loss_box_reg: 0.5166  loss_mask: 0.3014  loss_rpn_cls: 0.08661  loss_rpn_loc: 0.1945  time: 0.5844  data_time: 0.1963  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:05:29 d2.utils.events]: \u001b[0m eta: 0:30:43  iter: 4519  total_loss: 1.394  loss_cls: 0.3223  loss_box_reg: 0.5088  loss_mask: 0.3018  loss_rpn_cls: 0.07897  loss_rpn_loc: 0.1988  time: 0.5846  data_time: 0.3201  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:05:40 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 4539  total_loss: 1.465  loss_cls: 0.3114  loss_box_reg: 0.555  loss_mask: 0.3084  loss_rpn_cls: 0.07012  loss_rpn_loc: 0.195  time: 0.5843  data_time: 0.2024  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:05:52 d2.utils.events]: \u001b[0m eta: 0:30:24  iter: 4559  total_loss: 1.344  loss_cls: 0.3028  loss_box_reg: 0.508  loss_mask: 0.2843  loss_rpn_cls: 0.04779  loss_rpn_loc: 0.1838  time: 0.5845  data_time: 0.3056  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:06:03 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 4579  total_loss: 1.378  loss_cls: 0.3079  loss_box_reg: 0.4999  loss_mask: 0.2818  loss_rpn_cls: 0.05528  loss_rpn_loc: 0.1922  time: 0.5844  data_time: 0.2537  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:06:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:06:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:06:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:06:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:06:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:06:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0381 s/iter. Total: 0.1068 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0529 s/iter. Total: 0.1240 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0551 s/iter. Total: 0.1266 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 14:06:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.579450 (0.125685 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:06:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070544 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:06:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:06:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26309886543300837\n",
      "\u001b[32m[02/02 14:06:30 d2.utils.events]: \u001b[0m eta: 0:30:05  iter: 4599  total_loss: 1.446  loss_cls: 0.3229  loss_box_reg: 0.4943  loss_mask: 0.3101  loss_rpn_cls: 0.09763  loss_rpn_loc: 0.1982  time: 0.5843  data_time: 0.2394  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:06:41 d2.utils.events]: \u001b[0m eta: 0:30:00  iter: 4619  total_loss: 1.4  loss_cls: 0.3317  loss_box_reg: 0.5117  loss_mask: 0.2922  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.1973  time: 0.5841  data_time: 0.2334  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:06:57 d2.utils.events]: \u001b[0m eta: 0:29:54  iter: 4639  total_loss: 1.429  loss_cls: 0.344  loss_box_reg: 0.4893  loss_mask: 0.3051  loss_rpn_cls: 0.08354  loss_rpn_loc: 0.1976  time: 0.5850  data_time: 0.4626  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:07:09 d2.utils.events]: \u001b[0m eta: 0:29:47  iter: 4659  total_loss: 1.418  loss_cls: 0.3085  loss_box_reg: 0.5159  loss_mask: 0.3121  loss_rpn_cls: 0.07904  loss_rpn_loc: 0.1931  time: 0.5850  data_time: 0.2637  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:07:18 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 4679  total_loss: 1.366  loss_cls: 0.3007  loss_box_reg: 0.4885  loss_mask: 0.2854  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.1855  time: 0.5845  data_time: 0.1811  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:07:30 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 4699  total_loss: 1.397  loss_cls: 0.316  loss_box_reg: 0.5229  loss_mask: 0.2993  loss_rpn_cls: 0.05838  loss_rpn_loc: 0.1873  time: 0.5844  data_time: 0.2444  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:07:39 d2.utils.events]: \u001b[0m eta: 0:29:26  iter: 4719  total_loss: 1.345  loss_cls: 0.2961  loss_box_reg: 0.5194  loss_mask: 0.2894  loss_rpn_cls: 0.06521  loss_rpn_loc: 0.1918  time: 0.5840  data_time: 0.1737  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:07:50 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 4739  total_loss: 1.367  loss_cls: 0.291  loss_box_reg: 0.5106  loss_mask: 0.3092  loss_rpn_cls: 0.06706  loss_rpn_loc: 0.1937  time: 0.5838  data_time: 0.2448  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:08:07 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 4759  total_loss: 1.314  loss_cls: 0.3078  loss_box_reg: 0.4587  loss_mask: 0.2972  loss_rpn_cls: 0.08206  loss_rpn_loc: 0.1872  time: 0.5849  data_time: 0.4916  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:08:14 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 4779  total_loss: 1.34  loss_cls: 0.329  loss_box_reg: 0.5278  loss_mask: 0.2916  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.177  time: 0.5840  data_time: 0.0791  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:08:29 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 4799  total_loss: 1.417  loss_cls: 0.3212  loss_box_reg: 0.4924  loss_mask: 0.2994  loss_rpn_cls: 0.07418  loss_rpn_loc: 0.2219  time: 0.5846  data_time: 0.4155  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:08:41 d2.utils.events]: \u001b[0m eta: 0:28:51  iter: 4819  total_loss: 1.468  loss_cls: 0.3346  loss_box_reg: 0.5405  loss_mask: 0.295  loss_rpn_cls: 0.0788  loss_rpn_loc: 0.1878  time: 0.5847  data_time: 0.2805  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:08:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:08:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:08:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:08:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:08:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:08:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0688 s/iter. Eval: 0.0383 s/iter. Total: 0.1078 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0715 s/iter. Eval: 0.0539 s/iter. Total: 0.1262 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:09:03 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0551 s/iter. Total: 0.1276 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:09:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.625358 (0.126081 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:09:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071258 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:09:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:09:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2616372672442669\n",
      "\u001b[32m[02/02 14:09:07 d2.utils.events]: \u001b[0m eta: 0:28:43  iter: 4839  total_loss: 1.349  loss_cls: 0.2866  loss_box_reg: 0.5124  loss_mask: 0.2906  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.1947  time: 0.5843  data_time: 0.1826  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:09:19 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 4859  total_loss: 1.37  loss_cls: 0.3064  loss_box_reg: 0.5258  loss_mask: 0.2947  loss_rpn_cls: 0.07174  loss_rpn_loc: 0.1837  time: 0.5843  data_time: 0.2795  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:09:27 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 4879  total_loss: 1.347  loss_cls: 0.325  loss_box_reg: 0.4903  loss_mask: 0.272  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.1827  time: 0.5836  data_time: 0.1141  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:09:41 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 4899  total_loss: 1.411  loss_cls: 0.3177  loss_box_reg: 0.4831  loss_mask: 0.3012  loss_rpn_cls: 0.08483  loss_rpn_loc: 0.1953  time: 0.5841  data_time: 0.3885  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:09:51 d2.utils.events]: \u001b[0m eta: 0:28:08  iter: 4919  total_loss: 1.391  loss_cls: 0.3212  loss_box_reg: 0.5144  loss_mask: 0.291  loss_rpn_cls: 0.06196  loss_rpn_loc: 0.1859  time: 0.5837  data_time: 0.1702  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:10:04 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 4939  total_loss: 1.399  loss_cls: 0.2764  loss_box_reg: 0.4908  loss_mask: 0.308  loss_rpn_cls: 0.07281  loss_rpn_loc: 0.1794  time: 0.5840  data_time: 0.3223  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:10:14 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 4959  total_loss: 1.417  loss_cls: 0.2994  loss_box_reg: 0.5042  loss_mask: 0.2948  loss_rpn_cls: 0.07061  loss_rpn_loc: 0.2059  time: 0.5837  data_time: 0.2155  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:10:27 d2.utils.events]: \u001b[0m eta: 0:27:37  iter: 4979  total_loss: 1.447  loss_cls: 0.3317  loss_box_reg: 0.5104  loss_mask: 0.3086  loss_rpn_cls: 0.067  loss_rpn_loc: 0.1838  time: 0.5839  data_time: 0.3059  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:10:39 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 4999  total_loss: 1.356  loss_cls: 0.3112  loss_box_reg: 0.4792  loss_mask: 0.2995  loss_rpn_cls: 0.08238  loss_rpn_loc: 0.1927  time: 0.5839  data_time: 0.2803  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:10:52 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 5019  total_loss: 1.487  loss_cls: 0.3879  loss_box_reg: 0.5305  loss_mask: 0.3104  loss_rpn_cls: 0.08368  loss_rpn_loc: 0.2117  time: 0.5842  data_time: 0.3235  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:11:04 d2.utils.events]: \u001b[0m eta: 0:27:23  iter: 5039  total_loss: 1.465  loss_cls: 0.3135  loss_box_reg: 0.4969  loss_mask: 0.3138  loss_rpn_cls: 0.07442  loss_rpn_loc: 0.1985  time: 0.5843  data_time: 0.2993  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:11:16 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 5059  total_loss: 1.458  loss_cls: 0.3226  loss_box_reg: 0.5279  loss_mask: 0.2944  loss_rpn_cls: 0.101  loss_rpn_loc: 0.1954  time: 0.5844  data_time: 0.2846  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:11:26 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 5079  total_loss: 1.32  loss_cls: 0.3057  loss_box_reg: 0.4843  loss_mask: 0.2893  loss_rpn_cls: 0.07855  loss_rpn_loc: 0.1893  time: 0.5841  data_time: 0.2077  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:11:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:11:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:11:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:11:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:11:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:11:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0372 s/iter. Total: 0.1056 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 53/121. Dataloading: 0.0007 s/iter. Inference: 0.0696 s/iter. Eval: 0.0490 s/iter. Total: 0.1194 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0511 s/iter. Total: 0.1219 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 14:11:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.881534 (0.119668 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:11:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069783 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:11:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:11:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2514831512389032\n",
      "\u001b[32m[02/02 14:11:53 d2.utils.events]: \u001b[0m eta: 0:27:03  iter: 5099  total_loss: 1.34  loss_cls: 0.3027  loss_box_reg: 0.4826  loss_mask: 0.2751  loss_rpn_cls: 0.07418  loss_rpn_loc: 0.2066  time: 0.5840  data_time: 0.2458  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:12:03 d2.utils.events]: \u001b[0m eta: 0:26:51  iter: 5119  total_loss: 1.337  loss_cls: 0.3135  loss_box_reg: 0.5042  loss_mask: 0.2975  loss_rpn_cls: 0.0707  loss_rpn_loc: 0.1789  time: 0.5836  data_time: 0.1743  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:12:15 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 5139  total_loss: 1.414  loss_cls: 0.3397  loss_box_reg: 0.5081  loss_mask: 0.3002  loss_rpn_cls: 0.08384  loss_rpn_loc: 0.2095  time: 0.5838  data_time: 0.3262  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:12:28 d2.utils.events]: \u001b[0m eta: 0:26:40  iter: 5159  total_loss: 1.349  loss_cls: 0.3064  loss_box_reg: 0.4722  loss_mask: 0.2947  loss_rpn_cls: 0.07938  loss_rpn_loc: 0.197  time: 0.5840  data_time: 0.3211  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:12:39 d2.utils.events]: \u001b[0m eta: 0:26:30  iter: 5179  total_loss: 1.425  loss_cls: 0.3389  loss_box_reg: 0.4939  loss_mask: 0.2883  loss_rpn_cls: 0.07102  loss_rpn_loc: 0.1864  time: 0.5838  data_time: 0.2334  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:12:53 d2.utils.events]: \u001b[0m eta: 0:26:24  iter: 5199  total_loss: 1.473  loss_cls: 0.3574  loss_box_reg: 0.5114  loss_mask: 0.3094  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.1998  time: 0.5842  data_time: 0.3473  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:13:07 d2.utils.events]: \u001b[0m eta: 0:26:23  iter: 5219  total_loss: 1.459  loss_cls: 0.3359  loss_box_reg: 0.4922  loss_mask: 0.2932  loss_rpn_cls: 0.08743  loss_rpn_loc: 0.1919  time: 0.5847  data_time: 0.3681  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:13:19 d2.utils.events]: \u001b[0m eta: 0:26:19  iter: 5239  total_loss: 1.401  loss_cls: 0.328  loss_box_reg: 0.539  loss_mask: 0.3056  loss_rpn_cls: 0.07775  loss_rpn_loc: 0.214  time: 0.5847  data_time: 0.2825  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:13:30 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 5259  total_loss: 1.363  loss_cls: 0.3115  loss_box_reg: 0.4836  loss_mask: 0.2842  loss_rpn_cls: 0.07323  loss_rpn_loc: 0.1928  time: 0.5846  data_time: 0.2287  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:13:44 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 5279  total_loss: 1.432  loss_cls: 0.3029  loss_box_reg: 0.5083  loss_mask: 0.2889  loss_rpn_cls: 0.06023  loss_rpn_loc: 0.187  time: 0.5850  data_time: 0.3768  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:13:54 d2.utils.events]: \u001b[0m eta: 0:25:57  iter: 5299  total_loss: 1.416  loss_cls: 0.3139  loss_box_reg: 0.4901  loss_mask: 0.2826  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.1996  time: 0.5848  data_time: 0.2109  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:14:04 d2.utils.events]: \u001b[0m eta: 0:25:50  iter: 5319  total_loss: 1.45  loss_cls: 0.3414  loss_box_reg: 0.5456  loss_mask: 0.2862  loss_rpn_cls: 0.06231  loss_rpn_loc: 0.191  time: 0.5844  data_time: 0.1835  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:14:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:14:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:14:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:14:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:14:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:14:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0394 s/iter. Total: 0.1082 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0560 s/iter. Total: 0.1281 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0715 s/iter. Eval: 0.0587 s/iter. Total: 0.1310 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:14:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.052734 (0.129765 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:14:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071318 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:14:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:14:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25770849237012167\n",
      "\u001b[32m[02/02 14:14:30 d2.utils.events]: \u001b[0m eta: 0:25:40  iter: 5339  total_loss: 1.364  loss_cls: 0.2796  loss_box_reg: 0.5029  loss_mask: 0.2912  loss_rpn_cls: 0.06669  loss_rpn_loc: 0.1849  time: 0.5840  data_time: 0.1714  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:14:42 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 5359  total_loss: 1.356  loss_cls: 0.3035  loss_box_reg: 0.4859  loss_mask: 0.2982  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.1786  time: 0.5841  data_time: 0.2926  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:14:55 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 5379  total_loss: 1.366  loss_cls: 0.3086  loss_box_reg: 0.5059  loss_mask: 0.2971  loss_rpn_cls: 0.08698  loss_rpn_loc: 0.1999  time: 0.5843  data_time: 0.3091  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:15:08 d2.utils.events]: \u001b[0m eta: 0:25:18  iter: 5399  total_loss: 1.455  loss_cls: 0.3466  loss_box_reg: 0.5094  loss_mask: 0.2957  loss_rpn_cls: 0.07783  loss_rpn_loc: 0.2165  time: 0.5845  data_time: 0.3321  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:15:19 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 5419  total_loss: 1.321  loss_cls: 0.2976  loss_box_reg: 0.4984  loss_mask: 0.287  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.1886  time: 0.5844  data_time: 0.2270  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:15:29 d2.utils.events]: \u001b[0m eta: 0:25:04  iter: 5439  total_loss: 1.372  loss_cls: 0.3168  loss_box_reg: 0.5037  loss_mask: 0.3042  loss_rpn_cls: 0.066  loss_rpn_loc: 0.1916  time: 0.5842  data_time: 0.2246  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:15:43 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 5459  total_loss: 1.438  loss_cls: 0.3364  loss_box_reg: 0.5135  loss_mask: 0.2964  loss_rpn_cls: 0.07054  loss_rpn_loc: 0.184  time: 0.5846  data_time: 0.3807  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:15:54 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 5479  total_loss: 1.345  loss_cls: 0.3149  loss_box_reg: 0.4992  loss_mask: 0.2788  loss_rpn_cls: 0.06289  loss_rpn_loc: 0.1771  time: 0.5845  data_time: 0.2387  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:16:06 d2.utils.events]: \u001b[0m eta: 0:24:51  iter: 5499  total_loss: 1.403  loss_cls: 0.316  loss_box_reg: 0.5119  loss_mask: 0.2913  loss_rpn_cls: 0.08006  loss_rpn_loc: 0.1987  time: 0.5845  data_time: 0.2747  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:16:17 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 5519  total_loss: 1.436  loss_cls: 0.3123  loss_box_reg: 0.5002  loss_mask: 0.2945  loss_rpn_cls: 0.0733  loss_rpn_loc: 0.1936  time: 0.5844  data_time: 0.2359  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:16:31 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 5539  total_loss: 1.403  loss_cls: 0.3283  loss_box_reg: 0.536  loss_mask: 0.3024  loss_rpn_cls: 0.07754  loss_rpn_loc: 0.2075  time: 0.5848  data_time: 0.3665  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:16:41 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 5559  total_loss: 1.296  loss_cls: 0.277  loss_box_reg: 0.5131  loss_mask: 0.286  loss_rpn_cls: 0.03791  loss_rpn_loc: 0.1531  time: 0.5844  data_time: 0.1774  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:16:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:16:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:16:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:16:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:16:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:16:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:16:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0396 s/iter. Total: 0.1105 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 14:16:51 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0530 s/iter. Total: 0.1257 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0548 s/iter. Total: 0.1276 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 14:17:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.624204 (0.126071 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:17:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071751 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:17:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:17:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25843541587722924\n",
      "\u001b[32m[02/02 14:17:06 d2.utils.events]: \u001b[0m eta: 0:24:22  iter: 5579  total_loss: 1.358  loss_cls: 0.3387  loss_box_reg: 0.5126  loss_mask: 0.2878  loss_rpn_cls: 0.05772  loss_rpn_loc: 0.1784  time: 0.5840  data_time: 0.1576  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:17:20 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 5599  total_loss: 1.285  loss_cls: 0.2935  loss_box_reg: 0.4779  loss_mask: 0.2885  loss_rpn_cls: 0.05176  loss_rpn_loc: 0.1866  time: 0.5843  data_time: 0.3497  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:17:32 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 5619  total_loss: 1.362  loss_cls: 0.2969  loss_box_reg: 0.4915  loss_mask: 0.304  loss_rpn_cls: 0.07301  loss_rpn_loc: 0.199  time: 0.5845  data_time: 0.2964  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:17:44 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 5639  total_loss: 1.401  loss_cls: 0.2932  loss_box_reg: 0.524  loss_mask: 0.2999  loss_rpn_cls: 0.07207  loss_rpn_loc: 0.1951  time: 0.5845  data_time: 0.2929  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:17:54 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 5659  total_loss: 1.411  loss_cls: 0.3247  loss_box_reg: 0.5062  loss_mask: 0.2877  loss_rpn_cls: 0.06745  loss_rpn_loc: 0.1995  time: 0.5843  data_time: 0.1993  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:18:03 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 5679  total_loss: 1.427  loss_cls: 0.2981  loss_box_reg: 0.5249  loss_mask: 0.3059  loss_rpn_cls: 0.07668  loss_rpn_loc: 0.2168  time: 0.5838  data_time: 0.1420  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:18:15 d2.utils.events]: \u001b[0m eta: 0:23:42  iter: 5699  total_loss: 1.457  loss_cls: 0.3662  loss_box_reg: 0.5374  loss_mask: 0.306  loss_rpn_cls: 0.0718  loss_rpn_loc: 0.2061  time: 0.5838  data_time: 0.2798  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:18:27 d2.utils.events]: \u001b[0m eta: 0:23:38  iter: 5719  total_loss: 1.351  loss_cls: 0.3206  loss_box_reg: 0.477  loss_mask: 0.2848  loss_rpn_cls: 0.07609  loss_rpn_loc: 0.1777  time: 0.5838  data_time: 0.2688  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:18:41 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 5739  total_loss: 1.424  loss_cls: 0.3169  loss_box_reg: 0.4873  loss_mask: 0.3071  loss_rpn_cls: 0.08409  loss_rpn_loc: 0.1892  time: 0.5842  data_time: 0.3564  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:18:53 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 5759  total_loss: 1.388  loss_cls: 0.3072  loss_box_reg: 0.5143  loss_mask: 0.2952  loss_rpn_cls: 0.08456  loss_rpn_loc: 0.1965  time: 0.5843  data_time: 0.2845  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:19:06 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 5779  total_loss: 1.309  loss_cls: 0.2994  loss_box_reg: 0.4665  loss_mask: 0.2901  loss_rpn_cls: 0.07733  loss_rpn_loc: 0.1972  time: 0.5845  data_time: 0.3174  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:19:18 d2.utils.events]: \u001b[0m eta: 0:23:17  iter: 5799  total_loss: 1.493  loss_cls: 0.3587  loss_box_reg: 0.5209  loss_mask: 0.3026  loss_rpn_cls: 0.08076  loss_rpn_loc: 0.2153  time: 0.5845  data_time: 0.2787  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:19:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:19:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:19:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:19:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:19:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:19:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0354 s/iter. Total: 0.1040 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0545 s/iter. Total: 0.1259 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0577 s/iter. Total: 0.1294 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:19:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.865756 (0.128153 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:19:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070873 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:19:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:19:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25883925238260885\n",
      "\u001b[32m[02/02 14:19:43 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 5819  total_loss: 1.456  loss_cls: 0.296  loss_box_reg: 0.5253  loss_mask: 0.2992  loss_rpn_cls: 0.06046  loss_rpn_loc: 0.1797  time: 0.5840  data_time: 0.1439  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:19:52 d2.utils.events]: \u001b[0m eta: 0:23:03  iter: 5839  total_loss: 1.339  loss_cls: 0.3119  loss_box_reg: 0.4868  loss_mask: 0.2891  loss_rpn_cls: 0.06649  loss_rpn_loc: 0.186  time: 0.5836  data_time: 0.1787  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:20:06 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 5859  total_loss: 1.326  loss_cls: 0.3213  loss_box_reg: 0.4787  loss_mask: 0.2825  loss_rpn_cls: 0.0633  loss_rpn_loc: 0.1837  time: 0.5840  data_time: 0.3794  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:20:18 d2.utils.events]: \u001b[0m eta: 0:22:52  iter: 5879  total_loss: 1.523  loss_cls: 0.3395  loss_box_reg: 0.5209  loss_mask: 0.3199  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.203  time: 0.5840  data_time: 0.2701  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:20:29 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 5899  total_loss: 1.383  loss_cls: 0.3497  loss_box_reg: 0.5101  loss_mask: 0.3083  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.1888  time: 0.5839  data_time: 0.2214  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:20:42 d2.utils.events]: \u001b[0m eta: 0:22:37  iter: 5919  total_loss: 1.346  loss_cls: 0.3061  loss_box_reg: 0.4773  loss_mask: 0.2932  loss_rpn_cls: 0.07893  loss_rpn_loc: 0.2039  time: 0.5841  data_time: 0.3356  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:20:53 d2.utils.events]: \u001b[0m eta: 0:22:32  iter: 5939  total_loss: 1.382  loss_cls: 0.2957  loss_box_reg: 0.5027  loss_mask: 0.3044  loss_rpn_cls: 0.07945  loss_rpn_loc: 0.1961  time: 0.5841  data_time: 0.2575  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:21:06 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 5959  total_loss: 1.3  loss_cls: 0.294  loss_box_reg: 0.4802  loss_mask: 0.2864  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.1776  time: 0.5842  data_time: 0.2904  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:21:17 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 5979  total_loss: 1.393  loss_cls: 0.3178  loss_box_reg: 0.5407  loss_mask: 0.2948  loss_rpn_cls: 0.07953  loss_rpn_loc: 0.1949  time: 0.5841  data_time: 0.2463  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:21:29 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 5999  total_loss: 1.484  loss_cls: 0.3391  loss_box_reg: 0.529  loss_mask: 0.3121  loss_rpn_cls: 0.06914  loss_rpn_loc: 0.1809  time: 0.5842  data_time: 0.3069  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:21:42 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 6019  total_loss: 1.428  loss_cls: 0.319  loss_box_reg: 0.492  loss_mask: 0.2957  loss_rpn_cls: 0.08264  loss_rpn_loc: 0.2018  time: 0.5844  data_time: 0.3315  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:21:54 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 6039  total_loss: 1.396  loss_cls: 0.3062  loss_box_reg: 0.5154  loss_mask: 0.2964  loss_rpn_cls: 0.07441  loss_rpn_loc: 0.1904  time: 0.5844  data_time: 0.2477  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:21:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:21:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:21:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:21:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:21:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:21:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0370 s/iter. Total: 0.1055 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0546 s/iter. Total: 0.1257 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0581 s/iter. Total: 0.1296 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:22:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.909381 (0.128529 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:22:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070515 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:22:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:22:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26198782035632096\n",
      "\u001b[32m[02/02 14:22:18 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 6059  total_loss: 1.374  loss_cls: 0.3178  loss_box_reg: 0.5187  loss_mask: 0.2861  loss_rpn_cls: 0.05518  loss_rpn_loc: 0.1665  time: 0.5838  data_time: 0.1063  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:22:30 d2.utils.events]: \u001b[0m eta: 0:21:39  iter: 6079  total_loss: 1.478  loss_cls: 0.3168  loss_box_reg: 0.5069  loss_mask: 0.3045  loss_rpn_cls: 0.0725  loss_rpn_loc: 0.2038  time: 0.5838  data_time: 0.2916  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:22:40 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 6099  total_loss: 1.343  loss_cls: 0.296  loss_box_reg: 0.4963  loss_mask: 0.3013  loss_rpn_cls: 0.07274  loss_rpn_loc: 0.1828  time: 0.5836  data_time: 0.2028  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:22:49 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 6119  total_loss: 1.275  loss_cls: 0.2652  loss_box_reg: 0.5088  loss_mask: 0.2992  loss_rpn_cls: 0.05135  loss_rpn_loc: 0.1697  time: 0.5831  data_time: 0.1361  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:23:01 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 6139  total_loss: 1.331  loss_cls: 0.3128  loss_box_reg: 0.5429  loss_mask: 0.2819  loss_rpn_cls: 0.06036  loss_rpn_loc: 0.1774  time: 0.5832  data_time: 0.2982  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:23:12 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 6159  total_loss: 1.344  loss_cls: 0.3212  loss_box_reg: 0.4923  loss_mask: 0.2894  loss_rpn_cls: 0.08137  loss_rpn_loc: 0.1823  time: 0.5831  data_time: 0.2531  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:23:25 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 6179  total_loss: 1.424  loss_cls: 0.2977  loss_box_reg: 0.4833  loss_mask: 0.3096  loss_rpn_cls: 0.06186  loss_rpn_loc: 0.1919  time: 0.5832  data_time: 0.3026  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:23:39 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 6199  total_loss: 1.33  loss_cls: 0.2661  loss_box_reg: 0.4871  loss_mask: 0.2933  loss_rpn_cls: 0.08505  loss_rpn_loc: 0.1987  time: 0.5836  data_time: 0.3641  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:23:49 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 6219  total_loss: 1.378  loss_cls: 0.3117  loss_box_reg: 0.5029  loss_mask: 0.2902  loss_rpn_cls: 0.06517  loss_rpn_loc: 0.1875  time: 0.5834  data_time: 0.2238  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:24:01 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 6239  total_loss: 1.338  loss_cls: 0.3167  loss_box_reg: 0.5058  loss_mask: 0.2899  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.2003  time: 0.5833  data_time: 0.2658  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:24:11 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 6259  total_loss: 1.425  loss_cls: 0.3485  loss_box_reg: 0.5135  loss_mask: 0.2964  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.2015  time: 0.5832  data_time: 0.2130  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:24:25 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 6279  total_loss: 1.402  loss_cls: 0.36  loss_box_reg: 0.4849  loss_mask: 0.3143  loss_rpn_cls: 0.07776  loss_rpn_loc: 0.2044  time: 0.5836  data_time: 0.3992  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:24:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:24:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:24:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:24:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:24:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:24:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:24:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0356 s/iter. Total: 0.1039 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0540 s/iter. Total: 0.1252 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0568 s/iter. Total: 0.1283 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:24:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.716139 (0.126863 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:24:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070591 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:24:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2645391867012315\n",
      "\u001b[32m[02/02 14:24:54 d2.utils.events]: \u001b[0m eta: 0:20:26  iter: 6299  total_loss: 1.4  loss_cls: 0.3258  loss_box_reg: 0.5022  loss_mask: 0.292  loss_rpn_cls: 0.07204  loss_rpn_loc: 0.1885  time: 0.5837  data_time: 0.3023  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:25:05 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 6319  total_loss: 1.391  loss_cls: 0.2999  loss_box_reg: 0.4958  loss_mask: 0.2991  loss_rpn_cls: 0.05621  loss_rpn_loc: 0.1853  time: 0.5836  data_time: 0.2226  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:25:16 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 6339  total_loss: 1.34  loss_cls: 0.3236  loss_box_reg: 0.4951  loss_mask: 0.2767  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.1745  time: 0.5835  data_time: 0.2460  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:25:27 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 6359  total_loss: 1.291  loss_cls: 0.2617  loss_box_reg: 0.4622  loss_mask: 0.3035  loss_rpn_cls: 0.08507  loss_rpn_loc: 0.1989  time: 0.5834  data_time: 0.2433  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:25:38 d2.utils.events]: \u001b[0m eta: 0:19:58  iter: 6379  total_loss: 1.35  loss_cls: 0.3049  loss_box_reg: 0.5045  loss_mask: 0.2908  loss_rpn_cls: 0.06383  loss_rpn_loc: 0.1856  time: 0.5833  data_time: 0.2093  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:25:48 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 6399  total_loss: 1.354  loss_cls: 0.2927  loss_box_reg: 0.5034  loss_mask: 0.3106  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.1959  time: 0.5830  data_time: 0.2122  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:26:00 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 6419  total_loss: 1.309  loss_cls: 0.3311  loss_box_reg: 0.4977  loss_mask: 0.2984  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1763  time: 0.5831  data_time: 0.2897  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:26:11 d2.utils.events]: \u001b[0m eta: 0:19:37  iter: 6439  total_loss: 1.362  loss_cls: 0.3042  loss_box_reg: 0.5069  loss_mask: 0.3055  loss_rpn_cls: 0.06901  loss_rpn_loc: 0.2129  time: 0.5829  data_time: 0.2068  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:26:24 d2.utils.events]: \u001b[0m eta: 0:19:30  iter: 6459  total_loss: 1.474  loss_cls: 0.3798  loss_box_reg: 0.5165  loss_mask: 0.2941  loss_rpn_cls: 0.08488  loss_rpn_loc: 0.2082  time: 0.5831  data_time: 0.3155  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:26:35 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 6479  total_loss: 1.376  loss_cls: 0.3469  loss_box_reg: 0.4776  loss_mask: 0.2887  loss_rpn_cls: 0.06654  loss_rpn_loc: 0.1957  time: 0.5831  data_time: 0.2627  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:26:46 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 6499  total_loss: 1.324  loss_cls: 0.2448  loss_box_reg: 0.4883  loss_mask: 0.2906  loss_rpn_cls: 0.05937  loss_rpn_loc: 0.1881  time: 0.5829  data_time: 0.2231  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:26:57 d2.utils.events]: \u001b[0m eta: 0:19:06  iter: 6519  total_loss: 1.317  loss_cls: 0.2837  loss_box_reg: 0.4655  loss_mask: 0.2951  loss_rpn_cls: 0.05611  loss_rpn_loc: 0.1925  time: 0.5828  data_time: 0.2301  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:27:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:27:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:27:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:27:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:27:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:27:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0384 s/iter. Total: 0.1071 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0573 s/iter. Total: 0.1289 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0619 s/iter. Total: 0.1340 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:27:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.293039 (0.131837 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:27:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070999 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:27:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:27:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26179184601668815\n",
      "\u001b[32m[02/02 14:27:27 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 6539  total_loss: 1.283  loss_cls: 0.314  loss_box_reg: 0.4951  loss_mask: 0.2913  loss_rpn_cls: 0.0813  loss_rpn_loc: 0.1995  time: 0.5831  data_time: 0.3801  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:27:38 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 6559  total_loss: 1.47  loss_cls: 0.3636  loss_box_reg: 0.4982  loss_mask: 0.3022  loss_rpn_cls: 0.07922  loss_rpn_loc: 0.2036  time: 0.5830  data_time: 0.2284  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:27:54 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 6579  total_loss: 1.3  loss_cls: 0.3063  loss_box_reg: 0.4754  loss_mask: 0.2866  loss_rpn_cls: 0.08896  loss_rpn_loc: 0.1971  time: 0.5836  data_time: 0.4439  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:28:11 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 6599  total_loss: 1.362  loss_cls: 0.3281  loss_box_reg: 0.4437  loss_mask: 0.2802  loss_rpn_cls: 0.08313  loss_rpn_loc: 0.2053  time: 0.5845  data_time: 0.5462  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:28:21 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 6619  total_loss: 1.272  loss_cls: 0.272  loss_box_reg: 0.4761  loss_mask: 0.2798  loss_rpn_cls: 0.04752  loss_rpn_loc: 0.1687  time: 0.5842  data_time: 0.1827  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:28:32 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 6639  total_loss: 1.297  loss_cls: 0.2771  loss_box_reg: 0.4762  loss_mask: 0.2888  loss_rpn_cls: 0.06152  loss_rpn_loc: 0.1862  time: 0.5841  data_time: 0.2336  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:28:41 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 6659  total_loss: 1.449  loss_cls: 0.3206  loss_box_reg: 0.5083  loss_mask: 0.2968  loss_rpn_cls: 0.09618  loss_rpn_loc: 0.1948  time: 0.5837  data_time: 0.1771  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:28:52 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 6679  total_loss: 1.353  loss_cls: 0.3322  loss_box_reg: 0.4876  loss_mask: 0.2789  loss_rpn_cls: 0.0588  loss_rpn_loc: 0.1952  time: 0.5836  data_time: 0.2323  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:29:04 d2.utils.events]: \u001b[0m eta: 0:18:12  iter: 6699  total_loss: 1.455  loss_cls: 0.2912  loss_box_reg: 0.5203  loss_mask: 0.3131  loss_rpn_cls: 0.09433  loss_rpn_loc: 0.2213  time: 0.5836  data_time: 0.2618  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:29:18 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 6719  total_loss: 1.466  loss_cls: 0.3331  loss_box_reg: 0.4968  loss_mask: 0.3074  loss_rpn_cls: 0.09508  loss_rpn_loc: 0.2036  time: 0.5839  data_time: 0.3970  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:29:28 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 6739  total_loss: 1.371  loss_cls: 0.3087  loss_box_reg: 0.5028  loss_mask: 0.2881  loss_rpn_cls: 0.07789  loss_rpn_loc: 0.1806  time: 0.5837  data_time: 0.2024  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:29:36 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 6759  total_loss: 1.325  loss_cls: 0.2875  loss_box_reg: 0.4848  loss_mask: 0.2818  loss_rpn_cls: 0.07475  loss_rpn_loc: 0.2098  time: 0.5832  data_time: 0.1084  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:29:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:29:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:29:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:29:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:29:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:29:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0380 s/iter. Total: 0.1064 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0574 s/iter. Total: 0.1289 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0620 s/iter. Total: 0.1341 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:30:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.294925 (0.131853 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:30:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070974 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:30:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:30:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27170191487013823\n",
      "\u001b[32m[02/02 14:30:04 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 6779  total_loss: 1.287  loss_cls: 0.2654  loss_box_reg: 0.4925  loss_mask: 0.2939  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.1871  time: 0.5832  data_time: 0.2584  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:30:13 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 6799  total_loss: 1.317  loss_cls: 0.2908  loss_box_reg: 0.4866  loss_mask: 0.2888  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.1728  time: 0.5827  data_time: 0.1326  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:30:25 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 6819  total_loss: 1.342  loss_cls: 0.2834  loss_box_reg: 0.513  loss_mask: 0.2862  loss_rpn_cls: 0.06919  loss_rpn_loc: 0.1929  time: 0.5827  data_time: 0.2772  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:30:36 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 6839  total_loss: 1.399  loss_cls: 0.2925  loss_box_reg: 0.4664  loss_mask: 0.3172  loss_rpn_cls: 0.08552  loss_rpn_loc: 0.1948  time: 0.5827  data_time: 0.2499  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:30:48 d2.utils.events]: \u001b[0m eta: 0:17:11  iter: 6859  total_loss: 1.348  loss_cls: 0.3103  loss_box_reg: 0.4857  loss_mask: 0.2689  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.1832  time: 0.5827  data_time: 0.2885  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:30:57 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 6879  total_loss: 1.319  loss_cls: 0.2889  loss_box_reg: 0.4943  loss_mask: 0.2958  loss_rpn_cls: 0.05311  loss_rpn_loc: 0.1742  time: 0.5824  data_time: 0.1546  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:31:10 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 6899  total_loss: 1.399  loss_cls: 0.3374  loss_box_reg: 0.4922  loss_mask: 0.282  loss_rpn_cls: 0.06171  loss_rpn_loc: 0.1781  time: 0.5825  data_time: 0.3011  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:31:22 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 6919  total_loss: 1.28  loss_cls: 0.2766  loss_box_reg: 0.4819  loss_mask: 0.2847  loss_rpn_cls: 0.06028  loss_rpn_loc: 0.1706  time: 0.5825  data_time: 0.2795  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:31:32 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 6939  total_loss: 1.504  loss_cls: 0.3421  loss_box_reg: 0.5312  loss_mask: 0.3127  loss_rpn_cls: 0.08552  loss_rpn_loc: 0.1921  time: 0.5824  data_time: 0.2352  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:31:46 d2.utils.events]: \u001b[0m eta: 0:16:33  iter: 6959  total_loss: 1.367  loss_cls: 0.3075  loss_box_reg: 0.4826  loss_mask: 0.2893  loss_rpn_cls: 0.07435  loss_rpn_loc: 0.1833  time: 0.5826  data_time: 0.3667  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:31:57 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 6979  total_loss: 1.273  loss_cls: 0.289  loss_box_reg: 0.4759  loss_mask: 0.2674  loss_rpn_cls: 0.05775  loss_rpn_loc: 0.173  time: 0.5826  data_time: 0.2509  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:32:07 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 6999  total_loss: 1.413  loss_cls: 0.3146  loss_box_reg: 0.5239  loss_mask: 0.3036  loss_rpn_cls: 0.09337  loss_rpn_loc: 0.1924  time: 0.5824  data_time: 0.2083  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:32:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:32:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:32:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:32:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:32:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:32:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0372 s/iter. Total: 0.1057 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0550 s/iter. Total: 0.1262 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0574 s/iter. Total: 0.1288 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:32:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.811652 (0.127687 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:32:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070462 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:32:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:32:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2657811001747165\n",
      "\u001b[32m[02/02 14:32:35 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 7019  total_loss: 1.373  loss_cls: 0.2916  loss_box_reg: 0.4993  loss_mask: 0.2863  loss_rpn_cls: 0.06578  loss_rpn_loc: 0.1857  time: 0.5823  data_time: 0.2321  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:32:48 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 7039  total_loss: 1.344  loss_cls: 0.3196  loss_box_reg: 0.4765  loss_mask: 0.294  loss_rpn_cls: 0.07624  loss_rpn_loc: 0.1964  time: 0.5825  data_time: 0.3338  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:32:58 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 7059  total_loss: 1.22  loss_cls: 0.2682  loss_box_reg: 0.4532  loss_mask: 0.2848  loss_rpn_cls: 0.0516  loss_rpn_loc: 0.1646  time: 0.5823  data_time: 0.2382  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:33:12 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 7079  total_loss: 1.362  loss_cls: 0.3076  loss_box_reg: 0.5075  loss_mask: 0.3019  loss_rpn_cls: 0.07905  loss_rpn_loc: 0.1853  time: 0.5826  data_time: 0.3481  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:33:22 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 7099  total_loss: 1.307  loss_cls: 0.2895  loss_box_reg: 0.497  loss_mask: 0.2934  loss_rpn_cls: 0.05878  loss_rpn_loc: 0.1832  time: 0.5823  data_time: 0.1834  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:33:32 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 7119  total_loss: 1.259  loss_cls: 0.2828  loss_box_reg: 0.4791  loss_mask: 0.2952  loss_rpn_cls: 0.05461  loss_rpn_loc: 0.1651  time: 0.5821  data_time: 0.2016  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:33:45 d2.utils.events]: \u001b[0m eta: 0:15:39  iter: 7139  total_loss: 1.464  loss_cls: 0.3064  loss_box_reg: 0.5315  loss_mask: 0.3143  loss_rpn_cls: 0.07618  loss_rpn_loc: 0.1992  time: 0.5823  data_time: 0.3315  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:33:54 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 7159  total_loss: 1.414  loss_cls: 0.3342  loss_box_reg: 0.5064  loss_mask: 0.2917  loss_rpn_cls: 0.06581  loss_rpn_loc: 0.1881  time: 0.5820  data_time: 0.1819  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:34:05 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 7179  total_loss: 1.287  loss_cls: 0.2985  loss_box_reg: 0.482  loss_mask: 0.28  loss_rpn_cls: 0.06775  loss_rpn_loc: 0.1796  time: 0.5818  data_time: 0.2091  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:34:18 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 7199  total_loss: 1.422  loss_cls: 0.2957  loss_box_reg: 0.4635  loss_mask: 0.3105  loss_rpn_cls: 0.07253  loss_rpn_loc: 0.2123  time: 0.5821  data_time: 0.3611  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:34:29 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 7219  total_loss: 1.374  loss_cls: 0.3108  loss_box_reg: 0.4796  loss_mask: 0.2871  loss_rpn_cls: 0.07314  loss_rpn_loc: 0.1817  time: 0.5820  data_time: 0.2458  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:34:40 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 7239  total_loss: 1.392  loss_cls: 0.3254  loss_box_reg: 0.5044  loss_mask: 0.2956  loss_rpn_cls: 0.0679  loss_rpn_loc: 0.1778  time: 0.5818  data_time: 0.2071  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:34:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:34:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:34:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:34:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:34:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:34:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:34:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0400 s/iter. Total: 0.1085 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:35:01 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0551 s/iter. Total: 0.1262 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0578 s/iter. Total: 0.1292 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:35:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.967387 (0.129029 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:35:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070436 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:35:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:35:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2553255685889143\n",
      "\u001b[32m[02/02 14:35:10 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 7259  total_loss: 1.341  loss_cls: 0.3109  loss_box_reg: 0.4744  loss_mask: 0.2772  loss_rpn_cls: 0.06755  loss_rpn_loc: 0.1855  time: 0.5821  data_time: 0.3478  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:35:20 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 7279  total_loss: 1.419  loss_cls: 0.3573  loss_box_reg: 0.499  loss_mask: 0.3061  loss_rpn_cls: 0.09461  loss_rpn_loc: 0.1852  time: 0.5819  data_time: 0.1762  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:35:32 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 7299  total_loss: 1.305  loss_cls: 0.3023  loss_box_reg: 0.4604  loss_mask: 0.2985  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.1919  time: 0.5820  data_time: 0.2963  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:35:43 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 7319  total_loss: 1.401  loss_cls: 0.3355  loss_box_reg: 0.4927  loss_mask: 0.2998  loss_rpn_cls: 0.04432  loss_rpn_loc: 0.1707  time: 0.5818  data_time: 0.2311  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:35:56 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 7339  total_loss: 1.357  loss_cls: 0.2785  loss_box_reg: 0.5078  loss_mask: 0.296  loss_rpn_cls: 0.06582  loss_rpn_loc: 0.1787  time: 0.5821  data_time: 0.3425  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:36:11 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 7359  total_loss: 1.356  loss_cls: 0.3171  loss_box_reg: 0.4569  loss_mask: 0.3011  loss_rpn_cls: 0.07703  loss_rpn_loc: 0.1776  time: 0.5824  data_time: 0.3916  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:36:23 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 7379  total_loss: 1.432  loss_cls: 0.3491  loss_box_reg: 0.5152  loss_mask: 0.2981  loss_rpn_cls: 0.09271  loss_rpn_loc: 0.1983  time: 0.5826  data_time: 0.3335  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:36:37 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 7399  total_loss: 1.341  loss_cls: 0.3  loss_box_reg: 0.4686  loss_mask: 0.292  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.2052  time: 0.5829  data_time: 0.3882  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:36:48 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 7419  total_loss: 1.365  loss_cls: 0.3308  loss_box_reg: 0.4649  loss_mask: 0.2871  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.2045  time: 0.5828  data_time: 0.2268  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:36:58 d2.utils.events]: \u001b[0m eta: 0:14:00  iter: 7439  total_loss: 1.354  loss_cls: 0.3035  loss_box_reg: 0.4983  loss_mask: 0.2899  loss_rpn_cls: 0.06981  loss_rpn_loc: 0.1862  time: 0.5826  data_time: 0.1867  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:37:10 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 7459  total_loss: 1.36  loss_cls: 0.3084  loss_box_reg: 0.4977  loss_mask: 0.2901  loss_rpn_cls: 0.07897  loss_rpn_loc: 0.1949  time: 0.5826  data_time: 0.2713  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:37:18 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 7479  total_loss: 1.256  loss_cls: 0.2729  loss_box_reg: 0.4943  loss_mask: 0.277  loss_rpn_cls: 0.05305  loss_rpn_loc: 0.1651  time: 0.5821  data_time: 0.1190  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:37:26 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 7499  total_loss: 1.381  loss_cls: 0.2801  loss_box_reg: 0.4959  loss_mask: 0.3039  loss_rpn_cls: 0.06177  loss_rpn_loc: 0.2165  time: 0.5816  data_time: 0.1109  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:37:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:37:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:37:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:37:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:37:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:37:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:37:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0347 s/iter. Total: 0.1029 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 53/121. Dataloading: 0.0007 s/iter. Inference: 0.0693 s/iter. Eval: 0.0485 s/iter. Total: 0.1186 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0007 s/iter. Inference: 0.0697 s/iter. Eval: 0.0518 s/iter. Total: 0.1223 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 14:37:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.988186 (0.120588 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:37:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069446 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:37:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:37:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.254189280200549\n",
      "\u001b[32m[02/02 14:37:53 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 7519  total_loss: 1.37  loss_cls: 0.3204  loss_box_reg: 0.4887  loss_mask: 0.2929  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.1838  time: 0.5816  data_time: 0.2612  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:38:05 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 7539  total_loss: 1.266  loss_cls: 0.3105  loss_box_reg: 0.494  loss_mask: 0.2948  loss_rpn_cls: 0.06508  loss_rpn_loc: 0.1834  time: 0.5816  data_time: 0.2756  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:38:15 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 7559  total_loss: 1.38  loss_cls: 0.32  loss_box_reg: 0.5015  loss_mask: 0.2903  loss_rpn_cls: 0.0785  loss_rpn_loc: 0.1789  time: 0.5814  data_time: 0.1835  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:38:27 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 7579  total_loss: 1.333  loss_cls: 0.2915  loss_box_reg: 0.4978  loss_mask: 0.2849  loss_rpn_cls: 0.07142  loss_rpn_loc: 0.1878  time: 0.5815  data_time: 0.2822  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:38:35 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 7599  total_loss: 1.363  loss_cls: 0.2889  loss_box_reg: 0.5082  loss_mask: 0.29  loss_rpn_cls: 0.04657  loss_rpn_loc: 0.1814  time: 0.5810  data_time: 0.1201  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:38:47 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 7619  total_loss: 1.357  loss_cls: 0.2957  loss_box_reg: 0.4964  loss_mask: 0.3051  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.1924  time: 0.5810  data_time: 0.2444  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:38:57 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 7639  total_loss: 1.332  loss_cls: 0.2879  loss_box_reg: 0.4617  loss_mask: 0.3001  loss_rpn_cls: 0.08737  loss_rpn_loc: 0.1849  time: 0.5808  data_time: 0.2034  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:39:10 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 7659  total_loss: 1.355  loss_cls: 0.298  loss_box_reg: 0.4914  loss_mask: 0.3037  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.1968  time: 0.5810  data_time: 0.3491  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:39:20 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 7679  total_loss: 1.305  loss_cls: 0.2579  loss_box_reg: 0.4707  loss_mask: 0.3149  loss_rpn_cls: 0.06957  loss_rpn_loc: 0.1939  time: 0.5808  data_time: 0.2000  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:39:32 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 7699  total_loss: 1.437  loss_cls: 0.308  loss_box_reg: 0.513  loss_mask: 0.2915  loss_rpn_cls: 0.07623  loss_rpn_loc: 0.1921  time: 0.5808  data_time: 0.2405  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:39:44 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 7719  total_loss: 1.309  loss_cls: 0.2926  loss_box_reg: 0.4779  loss_mask: 0.2819  loss_rpn_cls: 0.08424  loss_rpn_loc: 0.1924  time: 0.5808  data_time: 0.2902  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:39:57 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 7739  total_loss: 1.336  loss_cls: 0.292  loss_box_reg: 0.4521  loss_mask: 0.2893  loss_rpn_cls: 0.08376  loss_rpn_loc: 0.1924  time: 0.5810  data_time: 0.3351  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:39:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:39:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:39:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:39:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:39:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:39:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0688 s/iter. Eval: 0.0434 s/iter. Total: 0.1128 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 14:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0581 s/iter. Total: 0.1299 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0714 s/iter. Eval: 0.0619 s/iter. Total: 0.1341 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:40:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.311393 (0.131995 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:40:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071225 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:40:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:40:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2676719942973566\n",
      "\u001b[32m[02/02 14:40:23 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 7759  total_loss: 1.415  loss_cls: 0.3219  loss_box_reg: 0.519  loss_mask: 0.2977  loss_rpn_cls: 0.06436  loss_rpn_loc: 0.1876  time: 0.5807  data_time: 0.1484  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:40:33 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 7779  total_loss: 1.375  loss_cls: 0.3161  loss_box_reg: 0.496  loss_mask: 0.3139  loss_rpn_cls: 0.07334  loss_rpn_loc: 0.1857  time: 0.5806  data_time: 0.2271  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:40:44 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 7799  total_loss: 1.299  loss_cls: 0.2959  loss_box_reg: 0.4626  loss_mask: 0.286  loss_rpn_cls: 0.05252  loss_rpn_loc: 0.1795  time: 0.5805  data_time: 0.2418  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:40:58 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 7819  total_loss: 1.374  loss_cls: 0.2998  loss_box_reg: 0.4694  loss_mask: 0.2733  loss_rpn_cls: 0.06783  loss_rpn_loc: 0.1921  time: 0.5807  data_time: 0.3608  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:41:11 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 7839  total_loss: 1.334  loss_cls: 0.2911  loss_box_reg: 0.4746  loss_mask: 0.2848  loss_rpn_cls: 0.06992  loss_rpn_loc: 0.19  time: 0.5810  data_time: 0.3542  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:41:21 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 7859  total_loss: 1.348  loss_cls: 0.3028  loss_box_reg: 0.5017  loss_mask: 0.294  loss_rpn_cls: 0.06355  loss_rpn_loc: 0.186  time: 0.5807  data_time: 0.1841  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:41:31 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 7879  total_loss: 1.272  loss_cls: 0.3063  loss_box_reg: 0.4955  loss_mask: 0.2618  loss_rpn_cls: 0.06131  loss_rpn_loc: 0.1698  time: 0.5805  data_time: 0.1891  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:41:42 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 7899  total_loss: 1.45  loss_cls: 0.3338  loss_box_reg: 0.4968  loss_mask: 0.3055  loss_rpn_cls: 0.09231  loss_rpn_loc: 0.1846  time: 0.5805  data_time: 0.2635  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:41:54 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 7919  total_loss: 1.433  loss_cls: 0.3491  loss_box_reg: 0.4912  loss_mask: 0.2768  loss_rpn_cls: 0.07073  loss_rpn_loc: 0.2004  time: 0.5804  data_time: 0.2510  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:42:07 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 7939  total_loss: 1.487  loss_cls: 0.3346  loss_box_reg: 0.5285  loss_mask: 0.3149  loss_rpn_cls: 0.06517  loss_rpn_loc: 0.2008  time: 0.5806  data_time: 0.3377  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:42:19 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 7959  total_loss: 1.275  loss_cls: 0.272  loss_box_reg: 0.4765  loss_mask: 0.2927  loss_rpn_cls: 0.0475  loss_rpn_loc: 0.1777  time: 0.5808  data_time: 0.3415  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:42:30 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 7979  total_loss: 1.462  loss_cls: 0.3212  loss_box_reg: 0.4937  loss_mask: 0.3013  loss_rpn_cls: 0.09252  loss_rpn_loc: 0.2124  time: 0.5807  data_time: 0.2337  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:42:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:42:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:42:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:42:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:42:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:42:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.0400 s/iter. Total: 0.1089 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 14:42:42 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0558 s/iter. Total: 0.1269 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:42:47 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0713 s/iter. Eval: 0.0605 s/iter. Total: 0.1325 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:42:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.096626 (0.130143 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:42:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070856 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:42:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:42:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2652760807301614\n",
      "\u001b[32m[02/02 14:42:58 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 7999  total_loss: 1.455  loss_cls: 0.3438  loss_box_reg: 0.492  loss_mask: 0.2946  loss_rpn_cls: 0.08097  loss_rpn_loc: 0.2044  time: 0.5806  data_time: 0.2192  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:43:11 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 8019  total_loss: 1.339  loss_cls: 0.3019  loss_box_reg: 0.4901  loss_mask: 0.2917  loss_rpn_cls: 0.08509  loss_rpn_loc: 0.1914  time: 0.5808  data_time: 0.3278  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:43:24 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 8039  total_loss: 1.429  loss_cls: 0.3051  loss_box_reg: 0.5177  loss_mask: 0.3063  loss_rpn_cls: 0.05981  loss_rpn_loc: 0.2096  time: 0.5809  data_time: 0.3020  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:43:37 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 8059  total_loss: 1.323  loss_cls: 0.3168  loss_box_reg: 0.4942  loss_mask: 0.2988  loss_rpn_cls: 0.08334  loss_rpn_loc: 0.1921  time: 0.5811  data_time: 0.3479  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:43:49 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 8079  total_loss: 1.386  loss_cls: 0.3115  loss_box_reg: 0.4866  loss_mask: 0.2976  loss_rpn_cls: 0.06873  loss_rpn_loc: 0.1943  time: 0.5812  data_time: 0.3093  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:44:04 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 8099  total_loss: 1.4  loss_cls: 0.3118  loss_box_reg: 0.4769  loss_mask: 0.2844  loss_rpn_cls: 0.09512  loss_rpn_loc: 0.221  time: 0.5816  data_time: 0.4124  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:44:15 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 8119  total_loss: 1.269  loss_cls: 0.2667  loss_box_reg: 0.4615  loss_mask: 0.288  loss_rpn_cls: 0.05771  loss_rpn_loc: 0.1807  time: 0.5815  data_time: 0.2572  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:44:25 d2.utils.events]: \u001b[0m eta: 0:10:08  iter: 8139  total_loss: 1.277  loss_cls: 0.3002  loss_box_reg: 0.4684  loss_mask: 0.2765  loss_rpn_cls: 0.04523  loss_rpn_loc: 0.1589  time: 0.5813  data_time: 0.1637  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:44:35 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 8159  total_loss: 1.352  loss_cls: 0.3148  loss_box_reg: 0.4751  loss_mask: 0.291  loss_rpn_cls: 0.06495  loss_rpn_loc: 0.1973  time: 0.5811  data_time: 0.1844  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:44:46 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 8179  total_loss: 1.33  loss_cls: 0.317  loss_box_reg: 0.4741  loss_mask: 0.293  loss_rpn_cls: 0.073  loss_rpn_loc: 0.1737  time: 0.5810  data_time: 0.2284  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:44:57 d2.utils.events]: \u001b[0m eta: 0:09:52  iter: 8199  total_loss: 1.321  loss_cls: 0.2996  loss_box_reg: 0.482  loss_mask: 0.281  loss_rpn_cls: 0.0542  loss_rpn_loc: 0.1767  time: 0.5809  data_time: 0.2152  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:45:07 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 8219  total_loss: 1.384  loss_cls: 0.3363  loss_box_reg: 0.5013  loss_mask: 0.2851  loss_rpn_cls: 0.04701  loss_rpn_loc: 0.1765  time: 0.5807  data_time: 0.1876  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:45:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:45:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:45:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:45:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:45:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:45:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:45:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0686 s/iter. Eval: 0.0432 s/iter. Total: 0.1126 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 14:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0716 s/iter. Eval: 0.0579 s/iter. Total: 0.1303 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0722 s/iter. Eval: 0.0615 s/iter. Total: 0.1345 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:45:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.404218 (0.132795 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:45:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:45:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:45:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2667576935480967\n",
      "\u001b[32m[02/02 14:45:36 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 8239  total_loss: 1.426  loss_cls: 0.3241  loss_box_reg: 0.4754  loss_mask: 0.2992  loss_rpn_cls: 0.08609  loss_rpn_loc: 0.2144  time: 0.5808  data_time: 0.2921  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:45:47 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 8259  total_loss: 1.46  loss_cls: 0.3636  loss_box_reg: 0.5263  loss_mask: 0.292  loss_rpn_cls: 0.07772  loss_rpn_loc: 0.1942  time: 0.5807  data_time: 0.2317  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:46:00 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 8279  total_loss: 1.383  loss_cls: 0.3121  loss_box_reg: 0.4849  loss_mask: 0.3004  loss_rpn_cls: 0.07725  loss_rpn_loc: 0.1894  time: 0.5809  data_time: 0.3471  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:46:12 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 8299  total_loss: 1.365  loss_cls: 0.2755  loss_box_reg: 0.5004  loss_mask: 0.2949  loss_rpn_cls: 0.05114  loss_rpn_loc: 0.1886  time: 0.5809  data_time: 0.2565  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:46:22 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 8319  total_loss: 1.332  loss_cls: 0.3117  loss_box_reg: 0.5018  loss_mask: 0.2973  loss_rpn_cls: 0.04883  loss_rpn_loc: 0.1845  time: 0.5807  data_time: 0.1962  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:46:33 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 8339  total_loss: 1.446  loss_cls: 0.314  loss_box_reg: 0.5049  loss_mask: 0.3009  loss_rpn_cls: 0.09342  loss_rpn_loc: 0.1953  time: 0.5806  data_time: 0.2308  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:46:47 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 8359  total_loss: 1.323  loss_cls: 0.2882  loss_box_reg: 0.4797  loss_mask: 0.3016  loss_rpn_cls: 0.06559  loss_rpn_loc: 0.1815  time: 0.5809  data_time: 0.3804  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:46:58 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 8379  total_loss: 1.439  loss_cls: 0.311  loss_box_reg: 0.5072  loss_mask: 0.2914  loss_rpn_cls: 0.08851  loss_rpn_loc: 0.2057  time: 0.5809  data_time: 0.2638  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:47:10 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 8399  total_loss: 1.343  loss_cls: 0.2764  loss_box_reg: 0.4815  loss_mask: 0.3005  loss_rpn_cls: 0.05098  loss_rpn_loc: 0.1793  time: 0.5809  data_time: 0.2794  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:47:26 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 8419  total_loss: 1.291  loss_cls: 0.3014  loss_box_reg: 0.4724  loss_mask: 0.297  loss_rpn_cls: 0.06277  loss_rpn_loc: 0.1896  time: 0.5813  data_time: 0.4338  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:47:36 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 8439  total_loss: 1.321  loss_cls: 0.3199  loss_box_reg: 0.475  loss_mask: 0.2803  loss_rpn_cls: 0.07299  loss_rpn_loc: 0.1856  time: 0.5812  data_time: 0.2173  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:47:46 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 8459  total_loss: 1.419  loss_cls: 0.3245  loss_box_reg: 0.5132  loss_mask: 0.3056  loss_rpn_cls: 0.05678  loss_rpn_loc: 0.1892  time: 0.5810  data_time: 0.1729  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:47:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:47:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:47:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:47:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:47:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:47:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0029 s/iter. Inference: 0.0684 s/iter. Eval: 0.0421 s/iter. Total: 0.1135 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 14:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0010 s/iter. Inference: 0.0704 s/iter. Eval: 0.0551 s/iter. Total: 0.1266 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 14:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0009 s/iter. Inference: 0.0714 s/iter. Eval: 0.0581 s/iter. Total: 0.1305 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:48:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.048374 (0.129727 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:48:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071555 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:48:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:48:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2618845006474131\n",
      "\u001b[32m[02/02 14:48:12 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 8479  total_loss: 1.307  loss_cls: 0.2536  loss_box_reg: 0.4739  loss_mask: 0.2971  loss_rpn_cls: 0.05099  loss_rpn_loc: 0.172  time: 0.5808  data_time: 0.1872  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:48:20 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 8499  total_loss: 1.178  loss_cls: 0.2505  loss_box_reg: 0.4631  loss_mask: 0.2668  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.1696  time: 0.5803  data_time: 0.0926  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:48:29 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 8519  total_loss: 1.295  loss_cls: 0.2779  loss_box_reg: 0.4602  loss_mask: 0.2884  loss_rpn_cls: 0.05721  loss_rpn_loc: 0.1937  time: 0.5800  data_time: 0.1441  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:48:41 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 8539  total_loss: 1.278  loss_cls: 0.291  loss_box_reg: 0.5008  loss_mask: 0.2789  loss_rpn_cls: 0.07305  loss_rpn_loc: 0.179  time: 0.5800  data_time: 0.2603  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:48:53 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 8559  total_loss: 1.444  loss_cls: 0.3391  loss_box_reg: 0.5014  loss_mask: 0.2969  loss_rpn_cls: 0.0927  loss_rpn_loc: 0.1961  time: 0.5801  data_time: 0.3055  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:49:08 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 8579  total_loss: 1.411  loss_cls: 0.3372  loss_box_reg: 0.4876  loss_mask: 0.2835  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.2001  time: 0.5805  data_time: 0.4127  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:49:18 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 8599  total_loss: 1.284  loss_cls: 0.2746  loss_box_reg: 0.4804  loss_mask: 0.2907  loss_rpn_cls: 0.04347  loss_rpn_loc: 0.182  time: 0.5803  data_time: 0.1684  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:49:32 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 8619  total_loss: 1.369  loss_cls: 0.295  loss_box_reg: 0.4779  loss_mask: 0.3009  loss_rpn_cls: 0.09873  loss_rpn_loc: 0.196  time: 0.5806  data_time: 0.4061  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:49:43 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 8639  total_loss: 1.369  loss_cls: 0.3191  loss_box_reg: 0.4933  loss_mask: 0.3031  loss_rpn_cls: 0.07097  loss_rpn_loc: 0.1803  time: 0.5805  data_time: 0.2000  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:49:52 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 8659  total_loss: 1.339  loss_cls: 0.2893  loss_box_reg: 0.4671  loss_mask: 0.2894  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.1887  time: 0.5802  data_time: 0.1816  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:50:08 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 8679  total_loss: 1.39  loss_cls: 0.3036  loss_box_reg: 0.5277  loss_mask: 0.2945  loss_rpn_cls: 0.09366  loss_rpn_loc: 0.2012  time: 0.5807  data_time: 0.4314  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:50:22 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 8699  total_loss: 1.298  loss_cls: 0.2806  loss_box_reg: 0.4711  loss_mask: 0.287  loss_rpn_cls: 0.07817  loss_rpn_loc: 0.1725  time: 0.5810  data_time: 0.3840  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:50:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:50:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:50:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:50:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:50:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:50:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0460 s/iter. Total: 0.1177 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 14:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0586 s/iter. Total: 0.1312 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0722 s/iter. Eval: 0.0634 s/iter. Total: 0.1364 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:50:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.648076 (0.134897 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:50:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072260 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:50:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:50:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2644573421735788\n",
      "\u001b[32m[02/02 14:50:51 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 8719  total_loss: 1.399  loss_cls: 0.3201  loss_box_reg: 0.5002  loss_mask: 0.2971  loss_rpn_cls: 0.05964  loss_rpn_loc: 0.2035  time: 0.5810  data_time: 0.2664  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:51:01 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 8739  total_loss: 1.247  loss_cls: 0.2514  loss_box_reg: 0.488  loss_mask: 0.2894  loss_rpn_cls: 0.05553  loss_rpn_loc: 0.1736  time: 0.5808  data_time: 0.1828  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:51:10 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 8759  total_loss: 1.422  loss_cls: 0.3254  loss_box_reg: 0.5129  loss_mask: 0.2842  loss_rpn_cls: 0.0746  loss_rpn_loc: 0.2031  time: 0.5805  data_time: 0.1405  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:51:23 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 8779  total_loss: 1.391  loss_cls: 0.3212  loss_box_reg: 0.5038  loss_mask: 0.298  loss_rpn_cls: 0.0739  loss_rpn_loc: 0.2096  time: 0.5807  data_time: 0.3586  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:51:34 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 8799  total_loss: 1.364  loss_cls: 0.3158  loss_box_reg: 0.5109  loss_mask: 0.2899  loss_rpn_cls: 0.0521  loss_rpn_loc: 0.1965  time: 0.5807  data_time: 0.2447  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:51:45 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 8819  total_loss: 1.313  loss_cls: 0.3219  loss_box_reg: 0.4931  loss_mask: 0.2779  loss_rpn_cls: 0.05297  loss_rpn_loc: 0.1722  time: 0.5805  data_time: 0.2034  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:52:00 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 8839  total_loss: 1.243  loss_cls: 0.2476  loss_box_reg: 0.4732  loss_mask: 0.2847  loss_rpn_cls: 0.06005  loss_rpn_loc: 0.1713  time: 0.5810  data_time: 0.4567  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:52:11 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 8859  total_loss: 1.288  loss_cls: 0.2622  loss_box_reg: 0.468  loss_mask: 0.2917  loss_rpn_cls: 0.069  loss_rpn_loc: 0.1841  time: 0.5809  data_time: 0.2371  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:52:25 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 8879  total_loss: 1.364  loss_cls: 0.3128  loss_box_reg: 0.4937  loss_mask: 0.294  loss_rpn_cls: 0.07729  loss_rpn_loc: 0.1903  time: 0.5811  data_time: 0.3567  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:52:36 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 8899  total_loss: 1.407  loss_cls: 0.3339  loss_box_reg: 0.4997  loss_mask: 0.3009  loss_rpn_cls: 0.0637  loss_rpn_loc: 0.1907  time: 0.5810  data_time: 0.2398  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:52:45 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 8919  total_loss: 1.237  loss_cls: 0.2655  loss_box_reg: 0.4816  loss_mask: 0.2706  loss_rpn_cls: 0.04718  loss_rpn_loc: 0.1708  time: 0.5807  data_time: 0.1377  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:52:56 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 8939  total_loss: 1.438  loss_cls: 0.3303  loss_box_reg: 0.5295  loss_mask: 0.3025  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.215  time: 0.5807  data_time: 0.2484  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:53:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:53:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:53:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:53:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:53:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:53:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0694 s/iter. Eval: 0.0437 s/iter. Total: 0.1137 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 14:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0726 s/iter. Eval: 0.0594 s/iter. Total: 0.1328 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0729 s/iter. Eval: 0.0637 s/iter. Total: 0.1375 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 14:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0730 s/iter. Eval: 0.0617 s/iter. Total: 0.1356 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/02 14:53:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.767200 (0.135924 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:53:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073020 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:53:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:53:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2661384457130504\n",
      "\u001b[32m[02/02 14:53:25 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 8959  total_loss: 1.291  loss_cls: 0.2845  loss_box_reg: 0.4688  loss_mask: 0.2937  loss_rpn_cls: 0.08363  loss_rpn_loc: 0.1947  time: 0.5806  data_time: 0.2390  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:53:39 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 8979  total_loss: 1.307  loss_cls: 0.2954  loss_box_reg: 0.4671  loss_mask: 0.2941  loss_rpn_cls: 0.0671  loss_rpn_loc: 0.1813  time: 0.5809  data_time: 0.3590  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:53:50 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 8999  total_loss: 1.327  loss_cls: 0.2925  loss_box_reg: 0.5201  loss_mask: 0.3002  loss_rpn_cls: 0.04575  loss_rpn_loc: 0.186  time: 0.5809  data_time: 0.2626  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:54:04 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 9019  total_loss: 1.292  loss_cls: 0.2545  loss_box_reg: 0.4715  loss_mask: 0.2872  loss_rpn_cls: 0.04514  loss_rpn_loc: 0.1656  time: 0.5811  data_time: 0.3616  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:54:14 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 9039  total_loss: 1.312  loss_cls: 0.2992  loss_box_reg: 0.4853  loss_mask: 0.2784  loss_rpn_cls: 0.05734  loss_rpn_loc: 0.1675  time: 0.5810  data_time: 0.1947  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:54:28 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9059  total_loss: 1.381  loss_cls: 0.3341  loss_box_reg: 0.4778  loss_mask: 0.306  loss_rpn_cls: 0.07761  loss_rpn_loc: 0.2016  time: 0.5812  data_time: 0.3649  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:54:37 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 9079  total_loss: 1.382  loss_cls: 0.296  loss_box_reg: 0.5115  loss_mask: 0.2948  loss_rpn_cls: 0.07162  loss_rpn_loc: 0.1986  time: 0.5809  data_time: 0.1419  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:54:51 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 9099  total_loss: 1.37  loss_cls: 0.3142  loss_box_reg: 0.4725  loss_mask: 0.3024  loss_rpn_cls: 0.08365  loss_rpn_loc: 0.196  time: 0.5811  data_time: 0.3730  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:55:00 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 9119  total_loss: 1.371  loss_cls: 0.2886  loss_box_reg: 0.4743  loss_mask: 0.276  loss_rpn_cls: 0.06206  loss_rpn_loc: 0.1731  time: 0.5810  data_time: 0.1839  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:55:13 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 9139  total_loss: 1.377  loss_cls: 0.2932  loss_box_reg: 0.4706  loss_mask: 0.3021  loss_rpn_cls: 0.07402  loss_rpn_loc: 0.1886  time: 0.5811  data_time: 0.3185  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:55:23 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 9159  total_loss: 1.227  loss_cls: 0.2699  loss_box_reg: 0.489  loss_mask: 0.2837  loss_rpn_cls: 0.05758  loss_rpn_loc: 0.1825  time: 0.5808  data_time: 0.1778  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:55:37 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 9179  total_loss: 1.442  loss_cls: 0.3462  loss_box_reg: 0.4798  loss_mask: 0.2889  loss_rpn_cls: 0.07127  loss_rpn_loc: 0.1919  time: 0.5811  data_time: 0.3761  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:55:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:55:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:55:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:55:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:55:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:55:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0496 s/iter. Total: 0.1223 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 14:55:53 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0587 s/iter. Total: 0.1314 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0728 s/iter. Eval: 0.0629 s/iter. Total: 0.1365 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 14:56:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.484972 (0.133491 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:56:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072155 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:56:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:56:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26609249035175975\n",
      "\u001b[32m[02/02 14:56:05 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 9199  total_loss: 1.389  loss_cls: 0.3459  loss_box_reg: 0.4843  loss_mask: 0.292  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.1645  time: 0.5810  data_time: 0.2160  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:56:14 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 9219  total_loss: 1.347  loss_cls: 0.3023  loss_box_reg: 0.4742  loss_mask: 0.2793  loss_rpn_cls: 0.06676  loss_rpn_loc: 0.1902  time: 0.5808  data_time: 0.1747  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:56:29 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 9239  total_loss: 1.395  loss_cls: 0.3209  loss_box_reg: 0.498  loss_mask: 0.3045  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.1921  time: 0.5812  data_time: 0.4198  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:56:44 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 9259  total_loss: 1.425  loss_cls: 0.3325  loss_box_reg: 0.4865  loss_mask: 0.2982  loss_rpn_cls: 0.07793  loss_rpn_loc: 0.2082  time: 0.5814  data_time: 0.3851  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:56:53 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 9279  total_loss: 1.378  loss_cls: 0.2958  loss_box_reg: 0.5126  loss_mask: 0.2984  loss_rpn_cls: 0.0535  loss_rpn_loc: 0.1854  time: 0.5812  data_time: 0.1587  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:57:07 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 9299  total_loss: 1.384  loss_cls: 0.3242  loss_box_reg: 0.4808  loss_mask: 0.2986  loss_rpn_cls: 0.06914  loss_rpn_loc: 0.1938  time: 0.5815  data_time: 0.3972  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:57:17 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 9319  total_loss: 1.342  loss_cls: 0.2964  loss_box_reg: 0.4902  loss_mask: 0.2837  loss_rpn_cls: 0.06921  loss_rpn_loc: 0.1807  time: 0.5813  data_time: 0.1955  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:57:26 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 9339  total_loss: 1.233  loss_cls: 0.276  loss_box_reg: 0.4554  loss_mask: 0.2645  loss_rpn_cls: 0.04656  loss_rpn_loc: 0.1751  time: 0.5810  data_time: 0.1249  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:57:36 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 9359  total_loss: 1.42  loss_cls: 0.3058  loss_box_reg: 0.4941  loss_mask: 0.3098  loss_rpn_cls: 0.05849  loss_rpn_loc: 0.1939  time: 0.5808  data_time: 0.1903  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:57:50 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 9379  total_loss: 1.33  loss_cls: 0.2978  loss_box_reg: 0.4772  loss_mask: 0.2985  loss_rpn_cls: 0.0631  loss_rpn_loc: 0.1777  time: 0.5811  data_time: 0.3856  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:58:01 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 9399  total_loss: 1.299  loss_cls: 0.2909  loss_box_reg: 0.4651  loss_mask: 0.2745  loss_rpn_cls: 0.07337  loss_rpn_loc: 0.1886  time: 0.5810  data_time: 0.2386  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:58:11 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 9419  total_loss: 1.231  loss_cls: 0.2886  loss_box_reg: 0.4549  loss_mask: 0.2705  loss_rpn_cls: 0.04869  loss_rpn_loc: 0.1617  time: 0.5809  data_time: 0.2059  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:58:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:58:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 14:58:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 14:58:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 14:58:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 14:58:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 14:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0705 s/iter. Eval: 0.0558 s/iter. Total: 0.1271 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 14:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0616 s/iter. Total: 0.1344 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 14:58:36 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0733 s/iter. Eval: 0.0666 s/iter. Total: 0.1407 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 14:58:41 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0735 s/iter. Eval: 0.0644 s/iter. Total: 0.1387 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/02 14:58:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.183713 (0.139515 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:58:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073533 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 14:58:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 14:58:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26477901363907735\n",
      "\u001b[32m[02/02 14:58:42 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 9439  total_loss: 1.305  loss_cls: 0.3131  loss_box_reg: 0.4797  loss_mask: 0.3  loss_rpn_cls: 0.07298  loss_rpn_loc: 0.1801  time: 0.5810  data_time: 0.3240  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:58:53 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 9459  total_loss: 1.245  loss_cls: 0.2753  loss_box_reg: 0.5008  loss_mask: 0.2953  loss_rpn_cls: 0.05744  loss_rpn_loc: 0.1692  time: 0.5809  data_time: 0.2225  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:59:05 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 9479  total_loss: 1.383  loss_cls: 0.3229  loss_box_reg: 0.4925  loss_mask: 0.2883  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.1768  time: 0.5810  data_time: 0.3073  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:59:15 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 9499  total_loss: 1.198  loss_cls: 0.2456  loss_box_reg: 0.4738  loss_mask: 0.2778  loss_rpn_cls: 0.0408  loss_rpn_loc: 0.1554  time: 0.5808  data_time: 0.1651  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:59:30 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 9519  total_loss: 1.377  loss_cls: 0.345  loss_box_reg: 0.4692  loss_mask: 0.2914  loss_rpn_cls: 0.07616  loss_rpn_loc: 0.1932  time: 0.5812  data_time: 0.4270  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:59:42 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 9539  total_loss: 1.282  loss_cls: 0.289  loss_box_reg: 0.4846  loss_mask: 0.2831  loss_rpn_cls: 0.05312  loss_rpn_loc: 0.1781  time: 0.5812  data_time: 0.2570  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 14:59:53 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 9559  total_loss: 1.375  loss_cls: 0.3553  loss_box_reg: 0.4721  loss_mask: 0.2804  loss_rpn_cls: 0.06963  loss_rpn_loc: 0.183  time: 0.5811  data_time: 0.2447  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:00:03 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 9579  total_loss: 1.323  loss_cls: 0.3028  loss_box_reg: 0.4779  loss_mask: 0.2936  loss_rpn_cls: 0.06066  loss_rpn_loc: 0.1849  time: 0.5810  data_time: 0.2063  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:00:16 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 9599  total_loss: 1.445  loss_cls: 0.3163  loss_box_reg: 0.5166  loss_mask: 0.2977  loss_rpn_cls: 0.06885  loss_rpn_loc: 0.1942  time: 0.5812  data_time: 0.3332  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:00:29 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 9619  total_loss: 1.358  loss_cls: 0.3092  loss_box_reg: 0.4709  loss_mask: 0.2965  loss_rpn_cls: 0.07611  loss_rpn_loc: 0.1886  time: 0.5812  data_time: 0.3093  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:00:42 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 9639  total_loss: 1.302  loss_cls: 0.2823  loss_box_reg: 0.4708  loss_mask: 0.2856  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.1764  time: 0.5814  data_time: 0.3447  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:00:53 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 9659  total_loss: 1.384  loss_cls: 0.307  loss_box_reg: 0.4795  loss_mask: 0.3108  loss_rpn_cls: 0.07372  loss_rpn_loc: 0.2028  time: 0.5813  data_time: 0.2233  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:01:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:01:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 15:01:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:01:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 15:01:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:01:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 15:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0480 s/iter. Total: 0.1194 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 15:01:13 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0726 s/iter. Eval: 0.0616 s/iter. Total: 0.1350 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 15:01:18 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0728 s/iter. Eval: 0.0629 s/iter. Total: 0.1365 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 15:01:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.633336 (0.134770 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:01:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072466 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:01:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 15:01:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2575509416469835\n",
      "\u001b[32m[02/02 15:01:23 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 9679  total_loss: 1.361  loss_cls: 0.3016  loss_box_reg: 0.4818  loss_mask: 0.3026  loss_rpn_cls: 0.06897  loss_rpn_loc: 0.2039  time: 0.5815  data_time: 0.3241  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:01:32 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 9699  total_loss: 1.384  loss_cls: 0.3173  loss_box_reg: 0.5049  loss_mask: 0.2952  loss_rpn_cls: 0.05965  loss_rpn_loc: 0.1839  time: 0.5812  data_time: 0.1330  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:01:41 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9719  total_loss: 1.318  loss_cls: 0.2731  loss_box_reg: 0.4961  loss_mask: 0.287  loss_rpn_cls: 0.05787  loss_rpn_loc: 0.1685  time: 0.5809  data_time: 0.1464  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:01:51 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 9739  total_loss: 1.294  loss_cls: 0.2936  loss_box_reg: 0.4821  loss_mask: 0.2863  loss_rpn_cls: 0.06662  loss_rpn_loc: 0.1836  time: 0.5807  data_time: 0.1912  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:02:02 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 9759  total_loss: 1.414  loss_cls: 0.317  loss_box_reg: 0.5077  loss_mask: 0.2946  loss_rpn_cls: 0.05803  loss_rpn_loc: 0.1843  time: 0.5806  data_time: 0.2289  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:02:16 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 9779  total_loss: 1.439  loss_cls: 0.3202  loss_box_reg: 0.515  loss_mask: 0.3071  loss_rpn_cls: 0.08611  loss_rpn_loc: 0.2112  time: 0.5809  data_time: 0.3776  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:02:28 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 9799  total_loss: 1.299  loss_cls: 0.2947  loss_box_reg: 0.4712  loss_mask: 0.2807  loss_rpn_cls: 0.0421  loss_rpn_loc: 0.1773  time: 0.5809  data_time: 0.2609  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:02:40 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 9819  total_loss: 1.311  loss_cls: 0.2869  loss_box_reg: 0.4561  loss_mask: 0.2897  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.1716  time: 0.5810  data_time: 0.2995  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:02:54 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 9839  total_loss: 1.43  loss_cls: 0.3074  loss_box_reg: 0.4981  loss_mask: 0.299  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.1858  time: 0.5812  data_time: 0.3573  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:03:05 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 9859  total_loss: 1.263  loss_cls: 0.2678  loss_box_reg: 0.444  loss_mask: 0.2801  loss_rpn_cls: 0.04989  loss_rpn_loc: 0.1855  time: 0.5812  data_time: 0.2794  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:03:18 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9879  total_loss: 1.377  loss_cls: 0.2903  loss_box_reg: 0.5017  loss_mask: 0.2963  loss_rpn_cls: 0.06415  loss_rpn_loc: 0.1793  time: 0.5813  data_time: 0.2984  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:03:31 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 9899  total_loss: 1.305  loss_cls: 0.2708  loss_box_reg: 0.4786  loss_mask: 0.3019  loss_rpn_cls: 0.05673  loss_rpn_loc: 0.1968  time: 0.5815  data_time: 0.3768  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:03:42 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 9919  total_loss: 1.331  loss_cls: 0.2939  loss_box_reg: 0.4913  loss_mask: 0.276  loss_rpn_cls: 0.06001  loss_rpn_loc: 0.1891  time: 0.5814  data_time: 0.2489  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:03:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:03:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 15:03:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:03:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 15:03:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:03:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 15:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0512 s/iter. Total: 0.1212 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 15:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0709 s/iter. Eval: 0.0600 s/iter. Total: 0.1317 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 15:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0711 s/iter. Eval: 0.0616 s/iter. Total: 0.1335 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 15:04:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.322578 (0.132091 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:04:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070933 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:04:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 15:04:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26595181037859744\n",
      "\u001b[32m[02/02 15:04:12 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9939  total_loss: 1.32  loss_cls: 0.2899  loss_box_reg: 0.4647  loss_mask: 0.2947  loss_rpn_cls: 0.08074  loss_rpn_loc: 0.1887  time: 0.5816  data_time: 0.3382  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:04:23 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 9959  total_loss: 1.291  loss_cls: 0.2724  loss_box_reg: 0.4628  loss_mask: 0.2912  loss_rpn_cls: 0.06061  loss_rpn_loc: 0.1785  time: 0.5815  data_time: 0.2208  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:04:35 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 9979  total_loss: 1.347  loss_cls: 0.2824  loss_box_reg: 0.4633  loss_mask: 0.2889  loss_rpn_cls: 0.08107  loss_rpn_loc: 0.1924  time: 0.5815  data_time: 0.2733  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:04:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.469  loss_cls: 0.3459  loss_box_reg: 0.5267  loss_mask: 0.3016  loss_rpn_cls: 0.07936  loss_rpn_loc: 0.1967  time: 0.5817  data_time: 0.3693  lr: 0.0007  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:04:49 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:36:55 (0.5817 s / it)\n",
      "\u001b[32m[02/02 15:04:49 d2.engine.hooks]: \u001b[0mTotal training time: 1:48:10 (0:11:15 on hooks)\n",
      "\u001b[32m[02/02 15:04:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:04:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 15:04:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:04:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 15:04:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:04:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 15:04:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0689 s/iter. Eval: 0.0477 s/iter. Total: 0.1172 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 15:04:56 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0712 s/iter. Eval: 0.0644 s/iter. Total: 0.1365 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 15:05:01 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0713 s/iter. Eval: 0.0641 s/iter. Total: 0.1362 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 15:05:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.461269 (0.133287 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:05:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070941 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:05:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 15:05:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25745033036243475\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.0007\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0007\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_8.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "851f1cd6-7aa0-4d0a-bdd5-15337bc40ed7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 15:45:50 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 15:45:51 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 15:45:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/02 15:45:52 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 15:45:52 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/02 15:45:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/02 15:45:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/02 15:45:53 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:45:53 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 15:45:53 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 15:46:02 d2.utils.events]: \u001b[0m eta: 0:38:54  iter: 19  total_loss: 3.116  loss_cls: 1.411  loss_box_reg: 0.4753  loss_mask: 0.694  loss_rpn_cls: 0.3239  loss_rpn_loc: 0.2377  time: 0.4016  data_time: 0.2358  lr: 9.9905e-06  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:46:13 d2.utils.events]: \u001b[0m eta: 0:39:36  iter: 39  total_loss: 3.003  loss_cls: 1.329  loss_box_reg: 0.4428  loss_mask: 0.6866  loss_rpn_cls: 0.2815  loss_rpn_loc: 0.2584  time: 0.4883  data_time: 0.3380  lr: 1.998e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:46:26 d2.utils.events]: \u001b[0m eta: 0:39:36  iter: 59  total_loss: 2.861  loss_cls: 1.216  loss_box_reg: 0.425  loss_mask: 0.6702  loss_rpn_cls: 0.2852  loss_rpn_loc: 0.2561  time: 0.5371  data_time: 0.3998  lr: 2.997e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:46:40 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 79  total_loss: 2.616  loss_cls: 1.04  loss_box_reg: 0.4201  loss_mask: 0.6448  loss_rpn_cls: 0.2713  loss_rpn_loc: 0.2399  time: 0.5777  data_time: 0.4618  lr: 3.9961e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:46:48 d2.utils.events]: \u001b[0m eta: 0:40:35  iter: 99  total_loss: 2.493  loss_cls: 0.8446  loss_box_reg: 0.471  loss_mask: 0.6113  loss_rpn_cls: 0.2545  loss_rpn_loc: 0.2554  time: 0.5484  data_time: 0.2135  lr: 4.9951e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:47:01 d2.utils.events]: \u001b[0m eta: 0:40:09  iter: 119  total_loss: 2.293  loss_cls: 0.7624  loss_box_reg: 0.4829  loss_mask: 0.5826  loss_rpn_cls: 0.2104  loss_rpn_loc: 0.2298  time: 0.5626  data_time: 0.3996  lr: 5.9941e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:47:11 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 139  total_loss: 2.193  loss_cls: 0.7225  loss_box_reg: 0.5396  loss_mask: 0.5416  loss_rpn_cls: 0.1536  loss_rpn_loc: 0.2272  time: 0.5503  data_time: 0.2510  lr: 6.993e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:47:20 d2.utils.events]: \u001b[0m eta: 0:39:19  iter: 159  total_loss: 2.232  loss_cls: 0.6641  loss_box_reg: 0.5686  loss_mask: 0.5346  loss_rpn_cls: 0.1771  loss_rpn_loc: 0.2221  time: 0.5384  data_time: 0.2379  lr: 7.9921e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:47:30 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 179  total_loss: 2.334  loss_cls: 0.7389  loss_box_reg: 0.6081  loss_mask: 0.5157  loss_rpn_cls: 0.1735  loss_rpn_loc: 0.2485  time: 0.5345  data_time: 0.2851  lr: 8.991e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:47:41 d2.utils.events]: \u001b[0m eta: 0:39:03  iter: 199  total_loss: 2.038  loss_cls: 0.6338  loss_box_reg: 0.5776  loss_mask: 0.4808  loss_rpn_cls: 0.1189  loss_rpn_loc: 0.2292  time: 0.5355  data_time: 0.3251  lr: 9.9901e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:47:55 d2.utils.events]: \u001b[0m eta: 0:40:02  iter: 219  total_loss: 2.018  loss_cls: 0.5896  loss_box_reg: 0.6418  loss_mask: 0.4624  loss_rpn_cls: 0.169  loss_rpn_loc: 0.2354  time: 0.5531  data_time: 0.4996  lr: 0.00010989  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:48:09 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 239  total_loss: 1.986  loss_cls: 0.5237  loss_box_reg: 0.606  loss_mask: 0.4248  loss_rpn_cls: 0.1594  loss_rpn_loc: 0.2462  time: 0.5623  data_time: 0.4212  lr: 0.00011988  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:48:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 15:48:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:48:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 15:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:48:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 15:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0633 s/iter. Eval: 0.0052 s/iter. Total: 0.0691 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/02 15:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0632 s/iter. Eval: 0.0049 s/iter. Total: 0.0688 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/02 15:48:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.949084 (0.068527 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:48:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.063104 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:48:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 15:48:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.039202391694826054\n",
      "\u001b[32m[02/02 15:48:30 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 259  total_loss: 1.912  loss_cls: 0.5317  loss_box_reg: 0.6053  loss_mask: 0.4115  loss_rpn_cls: 0.1492  loss_rpn_loc: 0.2295  time: 0.5646  data_time: 0.3602  lr: 0.00012987  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:48:39 d2.utils.events]: \u001b[0m eta: 0:41:23  iter: 279  total_loss: 1.897  loss_cls: 0.5385  loss_box_reg: 0.6449  loss_mask: 0.3776  loss_rpn_cls: 0.1191  loss_rpn_loc: 0.2081  time: 0.5585  data_time: 0.2467  lr: 0.00013986  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:48:55 d2.utils.events]: \u001b[0m eta: 0:42:15  iter: 299  total_loss: 1.742  loss_cls: 0.4664  loss_box_reg: 0.5893  loss_mask: 0.3488  loss_rpn_cls: 0.1294  loss_rpn_loc: 0.2236  time: 0.5757  data_time: 0.5545  lr: 0.00014985  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:49:04 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 319  total_loss: 1.737  loss_cls: 0.4249  loss_box_reg: 0.6849  loss_mask: 0.3262  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.2078  time: 0.5667  data_time: 0.2181  lr: 0.00015984  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:49:13 d2.utils.events]: \u001b[0m eta: 0:41:07  iter: 339  total_loss: 1.67  loss_cls: 0.3971  loss_box_reg: 0.6309  loss_mask: 0.3294  loss_rpn_cls: 0.11  loss_rpn_loc: 0.2439  time: 0.5599  data_time: 0.2282  lr: 0.00016983  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:49:21 d2.utils.events]: \u001b[0m eta: 0:40:25  iter: 359  total_loss: 1.703  loss_cls: 0.3972  loss_box_reg: 0.6653  loss_mask: 0.3148  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.1947  time: 0.5494  data_time: 0.1607  lr: 0.00017982  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:49:32 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 379  total_loss: 1.727  loss_cls: 0.4323  loss_box_reg: 0.6  loss_mask: 0.3349  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.2479  time: 0.5516  data_time: 0.3568  lr: 0.00018981  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:49:48 d2.utils.events]: \u001b[0m eta: 0:41:14  iter: 399  total_loss: 1.703  loss_cls: 0.4498  loss_box_reg: 0.6072  loss_mask: 0.322  loss_rpn_cls: 0.1474  loss_rpn_loc: 0.2349  time: 0.5618  data_time: 0.4977  lr: 0.0001998  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:49:58 d2.utils.events]: \u001b[0m eta: 0:41:06  iter: 419  total_loss: 1.654  loss_cls: 0.4025  loss_box_reg: 0.5837  loss_mask: 0.3164  loss_rpn_cls: 0.1196  loss_rpn_loc: 0.1931  time: 0.5595  data_time: 0.2778  lr: 0.00020979  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:50:04 d2.utils.events]: \u001b[0m eta: 0:40:10  iter: 439  total_loss: 1.648  loss_cls: 0.3536  loss_box_reg: 0.6412  loss_mask: 0.3061  loss_rpn_cls: 0.09407  loss_rpn_loc: 0.2203  time: 0.5475  data_time: 0.0850  lr: 0.00021978  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:50:12 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 459  total_loss: 1.654  loss_cls: 0.3669  loss_box_reg: 0.6253  loss_mask: 0.3136  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2393  time: 0.5422  data_time: 0.2138  lr: 0.00022977  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:50:22 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 479  total_loss: 1.718  loss_cls: 0.4053  loss_box_reg: 0.6073  loss_mask: 0.3164  loss_rpn_cls: 0.1278  loss_rpn_loc: 0.2116  time: 0.5394  data_time: 0.2542  lr: 0.00023976  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:50:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:50:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 15:50:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:50:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 15:50:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:50:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 15:50:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0678 s/iter. Eval: 0.0389 s/iter. Total: 0.1075 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 15:50:33 d2.evaluation.evaluator]: \u001b[0mInference done 54/121. Dataloading: 0.0008 s/iter. Inference: 0.0694 s/iter. Eval: 0.0463 s/iter. Total: 0.1165 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/02 15:50:38 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0007 s/iter. Inference: 0.0697 s/iter. Eval: 0.0488 s/iter. Total: 0.1193 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/02 15:50:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.482679 (0.116230 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:50:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069283 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:50:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 15:50:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20808634200122644\n",
      "\u001b[32m[02/02 15:50:50 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 499  total_loss: 1.622  loss_cls: 0.3743  loss_box_reg: 0.5697  loss_mask: 0.3194  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.2346  time: 0.5442  data_time: 0.4145  lr: 0.00024975  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:51:02 d2.utils.events]: \u001b[0m eta: 0:40:04  iter: 519  total_loss: 1.632  loss_cls: 0.3521  loss_box_reg: 0.5933  loss_mask: 0.3275  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.2222  time: 0.5474  data_time: 0.4038  lr: 0.00025974  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:51:14 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 539  total_loss: 1.671  loss_cls: 0.4127  loss_box_reg: 0.6024  loss_mask: 0.3022  loss_rpn_cls: 0.1278  loss_rpn_loc: 0.227  time: 0.5493  data_time: 0.3709  lr: 0.00026973  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:51:24 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 559  total_loss: 1.65  loss_cls: 0.4049  loss_box_reg: 0.5936  loss_mask: 0.3017  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.2138  time: 0.5465  data_time: 0.2394  lr: 0.00027972  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:51:37 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 579  total_loss: 1.641  loss_cls: 0.3976  loss_box_reg: 0.5499  loss_mask: 0.32  loss_rpn_cls: 0.1301  loss_rpn_loc: 0.2143  time: 0.5512  data_time: 0.4436  lr: 0.00028971  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:51:44 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 599  total_loss: 1.599  loss_cls: 0.3758  loss_box_reg: 0.5709  loss_mask: 0.32  loss_rpn_cls: 0.07712  loss_rpn_loc: 0.1966  time: 0.5446  data_time: 0.1384  lr: 0.0002997  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:51:52 d2.utils.events]: \u001b[0m eta: 0:39:35  iter: 619  total_loss: 1.538  loss_cls: 0.3104  loss_box_reg: 0.5817  loss_mask: 0.2956  loss_rpn_cls: 0.08795  loss_rpn_loc: 0.1828  time: 0.5391  data_time: 0.1614  lr: 0.00030969  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:52:03 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 639  total_loss: 1.559  loss_cls: 0.3703  loss_box_reg: 0.523  loss_mask: 0.3193  loss_rpn_cls: 0.09802  loss_rpn_loc: 0.2096  time: 0.5392  data_time: 0.3236  lr: 0.00031968  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:52:18 d2.utils.events]: \u001b[0m eta: 0:39:35  iter: 659  total_loss: 1.604  loss_cls: 0.3714  loss_box_reg: 0.5628  loss_mask: 0.321  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.2107  time: 0.5459  data_time: 0.5215  lr: 0.00032967  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:52:30 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 679  total_loss: 1.582  loss_cls: 0.3837  loss_box_reg: 0.558  loss_mask: 0.3172  loss_rpn_cls: 0.08511  loss_rpn_loc: 0.209  time: 0.5481  data_time: 0.3956  lr: 0.00033966  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:52:41 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 699  total_loss: 1.593  loss_cls: 0.3513  loss_box_reg: 0.5783  loss_mask: 0.3121  loss_rpn_cls: 0.1161  loss_rpn_loc: 0.2359  time: 0.5473  data_time: 0.3016  lr: 0.00034965  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:52:51 d2.utils.events]: \u001b[0m eta: 0:39:01  iter: 719  total_loss: 1.591  loss_cls: 0.3967  loss_box_reg: 0.6045  loss_mask: 0.3077  loss_rpn_cls: 0.112  loss_rpn_loc: 0.2157  time: 0.5465  data_time: 0.2919  lr: 0.00035964  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:52:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:52:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 15:52:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:52:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 15:52:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:52:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 15:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0673 s/iter. Eval: 0.0302 s/iter. Total: 0.0980 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 15:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.0489 s/iter. Total: 0.1194 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 15:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0527 s/iter. Total: 0.1237 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 15:53:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.049116 (0.121113 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:53:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069890 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:53:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 15:53:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23551405467714376\n",
      "\u001b[32m[02/02 15:53:17 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 739  total_loss: 1.574  loss_cls: 0.3843  loss_box_reg: 0.5563  loss_mask: 0.3106  loss_rpn_cls: 0.08128  loss_rpn_loc: 0.2228  time: 0.5463  data_time: 0.3026  lr: 0.00036963  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:53:28 d2.utils.events]: \u001b[0m eta: 0:38:55  iter: 759  total_loss: 1.584  loss_cls: 0.3794  loss_box_reg: 0.5477  loss_mask: 0.3168  loss_rpn_cls: 0.1413  loss_rpn_loc: 0.2131  time: 0.5464  data_time: 0.3200  lr: 0.00037962  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:53:38 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 779  total_loss: 1.559  loss_cls: 0.3739  loss_box_reg: 0.5812  loss_mask: 0.3186  loss_rpn_cls: 0.09485  loss_rpn_loc: 0.2124  time: 0.5447  data_time: 0.2477  lr: 0.00038961  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:53:50 d2.utils.events]: \u001b[0m eta: 0:38:41  iter: 799  total_loss: 1.509  loss_cls: 0.3279  loss_box_reg: 0.5351  loss_mask: 0.3028  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.23  time: 0.5466  data_time: 0.3946  lr: 0.0003996  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:53:59 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 819  total_loss: 1.496  loss_cls: 0.376  loss_box_reg: 0.5597  loss_mask: 0.3008  loss_rpn_cls: 0.07505  loss_rpn_loc: 0.2028  time: 0.5435  data_time: 0.1978  lr: 0.00040959  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:54:11 d2.utils.events]: \u001b[0m eta: 0:38:24  iter: 839  total_loss: 1.398  loss_cls: 0.3347  loss_box_reg: 0.5342  loss_mask: 0.2909  loss_rpn_cls: 0.09329  loss_rpn_loc: 0.2104  time: 0.5452  data_time: 0.3869  lr: 0.00041958  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:54:20 d2.utils.events]: \u001b[0m eta: 0:38:17  iter: 859  total_loss: 1.593  loss_cls: 0.365  loss_box_reg: 0.5639  loss_mask: 0.3287  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.2  time: 0.5430  data_time: 0.2211  lr: 0.00042957  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:54:34 d2.utils.events]: \u001b[0m eta: 0:38:11  iter: 879  total_loss: 1.559  loss_cls: 0.3597  loss_box_reg: 0.5435  loss_mask: 0.3132  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.2175  time: 0.5468  data_time: 0.4648  lr: 0.00043956  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:54:46 d2.utils.events]: \u001b[0m eta: 0:38:06  iter: 899  total_loss: 1.582  loss_cls: 0.383  loss_box_reg: 0.561  loss_mask: 0.3012  loss_rpn_cls: 0.09945  loss_rpn_loc: 0.2136  time: 0.5471  data_time: 0.3296  lr: 0.00044955  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:54:55 d2.utils.events]: \u001b[0m eta: 0:38:01  iter: 919  total_loss: 1.464  loss_cls: 0.3306  loss_box_reg: 0.5385  loss_mask: 0.2916  loss_rpn_cls: 0.07728  loss_rpn_loc: 0.2048  time: 0.5456  data_time: 0.2591  lr: 0.00045954  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:55:09 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 939  total_loss: 1.526  loss_cls: 0.3681  loss_box_reg: 0.5492  loss_mask: 0.3127  loss_rpn_cls: 0.08692  loss_rpn_loc: 0.1985  time: 0.5483  data_time: 0.4426  lr: 0.00046953  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:55:22 d2.utils.events]: \u001b[0m eta: 0:37:54  iter: 959  total_loss: 1.522  loss_cls: 0.3558  loss_box_reg: 0.5834  loss_mask: 0.3109  loss_rpn_cls: 0.08161  loss_rpn_loc: 0.1954  time: 0.5503  data_time: 0.4107  lr: 0.00047952  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:55:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:55:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 15:55:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:55:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 15:55:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:55:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 15:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0673 s/iter. Eval: 0.0330 s/iter. Total: 0.1009 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 15:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0518 s/iter. Total: 0.1231 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 15:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0714 s/iter. Eval: 0.0545 s/iter. Total: 0.1267 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 15:55:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.475290 (0.124787 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:55:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071054 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:55:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 15:55:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2468031259696628\n",
      "\u001b[32m[02/02 15:55:48 d2.utils.events]: \u001b[0m eta: 0:37:56  iter: 979  total_loss: 1.496  loss_cls: 0.3756  loss_box_reg: 0.5441  loss_mask: 0.3136  loss_rpn_cls: 0.09897  loss_rpn_loc: 0.1925  time: 0.5500  data_time: 0.3074  lr: 0.00048951  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:56:02 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 999  total_loss: 1.429  loss_cls: 0.3137  loss_box_reg: 0.5238  loss_mask: 0.3038  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.2036  time: 0.5526  data_time: 0.4448  lr: 0.0004995  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:56:15 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 1019  total_loss: 1.625  loss_cls: 0.3892  loss_box_reg: 0.5082  loss_mask: 0.3269  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.2212  time: 0.5545  data_time: 0.4180  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:56:25 d2.utils.events]: \u001b[0m eta: 0:37:49  iter: 1039  total_loss: 1.47  loss_cls: 0.3742  loss_box_reg: 0.5389  loss_mask: 0.2925  loss_rpn_cls: 0.08791  loss_rpn_loc: 0.2008  time: 0.5542  data_time: 0.3091  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:56:35 d2.utils.events]: \u001b[0m eta: 0:37:43  iter: 1059  total_loss: 1.487  loss_cls: 0.3605  loss_box_reg: 0.5613  loss_mask: 0.305  loss_rpn_cls: 0.08696  loss_rpn_loc: 0.2029  time: 0.5523  data_time: 0.2312  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:56:47 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 1079  total_loss: 1.618  loss_cls: 0.368  loss_box_reg: 0.5853  loss_mask: 0.3319  loss_rpn_cls: 0.0952  loss_rpn_loc: 0.2062  time: 0.5540  data_time: 0.4085  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:56:57 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 1099  total_loss: 1.501  loss_cls: 0.3538  loss_box_reg: 0.5574  loss_mask: 0.304  loss_rpn_cls: 0.107  loss_rpn_loc: 0.2003  time: 0.5524  data_time: 0.2404  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:57:07 d2.utils.events]: \u001b[0m eta: 0:37:24  iter: 1119  total_loss: 1.443  loss_cls: 0.3078  loss_box_reg: 0.5556  loss_mask: 0.3026  loss_rpn_cls: 0.07754  loss_rpn_loc: 0.1991  time: 0.5517  data_time: 0.2979  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:57:17 d2.utils.events]: \u001b[0m eta: 0:37:17  iter: 1139  total_loss: 1.394  loss_cls: 0.3183  loss_box_reg: 0.532  loss_mask: 0.2973  loss_rpn_cls: 0.05587  loss_rpn_loc: 0.1752  time: 0.5505  data_time: 0.2608  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:57:30 d2.utils.events]: \u001b[0m eta: 0:37:16  iter: 1159  total_loss: 1.556  loss_cls: 0.3996  loss_box_reg: 0.5155  loss_mask: 0.3032  loss_rpn_cls: 0.1159  loss_rpn_loc: 0.2146  time: 0.5520  data_time: 0.4072  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:57:41 d2.utils.events]: \u001b[0m eta: 0:37:11  iter: 1179  total_loss: 1.487  loss_cls: 0.3763  loss_box_reg: 0.5438  loss_mask: 0.292  loss_rpn_cls: 0.09784  loss_rpn_loc: 0.2169  time: 0.5526  data_time: 0.3559  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:57:53 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 1199  total_loss: 1.477  loss_cls: 0.3143  loss_box_reg: 0.5291  loss_mask: 0.2939  loss_rpn_cls: 0.08524  loss_rpn_loc: 0.2176  time: 0.5531  data_time: 0.3527  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:57:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:57:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 15:57:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 15:57:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 15:57:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 15:57:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 15:58:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0357 s/iter. Total: 0.1038 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 15:58:05 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0529 s/iter. Total: 0.1237 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 15:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0555 s/iter. Total: 0.1266 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 15:58:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.395958 (0.124103 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:58:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069999 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 15:58:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 15:58:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24662883089341356\n",
      "\u001b[32m[02/02 15:58:18 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 1219  total_loss: 1.633  loss_cls: 0.3955  loss_box_reg: 0.5612  loss_mask: 0.3189  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.1996  time: 0.5520  data_time: 0.2678  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:58:32 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 1239  total_loss: 1.495  loss_cls: 0.3581  loss_box_reg: 0.5236  loss_mask: 0.3071  loss_rpn_cls: 0.09419  loss_rpn_loc: 0.2034  time: 0.5537  data_time: 0.4184  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:58:45 d2.utils.events]: \u001b[0m eta: 0:36:55  iter: 1259  total_loss: 1.629  loss_cls: 0.4223  loss_box_reg: 0.5742  loss_mask: 0.3209  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.2191  time: 0.5553  data_time: 0.4122  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:58:54 d2.utils.events]: \u001b[0m eta: 0:36:48  iter: 1279  total_loss: 1.623  loss_cls: 0.3732  loss_box_reg: 0.5459  loss_mask: 0.3132  loss_rpn_cls: 0.0803  loss_rpn_loc: 0.2063  time: 0.5542  data_time: 0.2609  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:59:06 d2.utils.events]: \u001b[0m eta: 0:36:41  iter: 1299  total_loss: 1.366  loss_cls: 0.3037  loss_box_reg: 0.498  loss_mask: 0.3043  loss_rpn_cls: 0.07688  loss_rpn_loc: 0.2093  time: 0.5545  data_time: 0.3390  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:59:19 d2.utils.events]: \u001b[0m eta: 0:36:40  iter: 1319  total_loss: 1.525  loss_cls: 0.3624  loss_box_reg: 0.5168  loss_mask: 0.3021  loss_rpn_cls: 0.09991  loss_rpn_loc: 0.2269  time: 0.5558  data_time: 0.4029  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:59:27 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 1339  total_loss: 1.524  loss_cls: 0.3461  loss_box_reg: 0.5402  loss_mask: 0.3088  loss_rpn_cls: 0.08737  loss_rpn_loc: 0.1896  time: 0.5536  data_time: 0.1922  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:59:39 d2.utils.events]: \u001b[0m eta: 0:36:32  iter: 1359  total_loss: 1.366  loss_cls: 0.323  loss_box_reg: 0.5237  loss_mask: 0.2988  loss_rpn_cls: 0.08597  loss_rpn_loc: 0.2044  time: 0.5540  data_time: 0.3479  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:59:48 d2.utils.events]: \u001b[0m eta: 0:36:22  iter: 1379  total_loss: 1.525  loss_cls: 0.3168  loss_box_reg: 0.5432  loss_mask: 0.2997  loss_rpn_cls: 0.08248  loss_rpn_loc: 0.2033  time: 0.5528  data_time: 0.2562  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 15:59:57 d2.utils.events]: \u001b[0m eta: 0:36:09  iter: 1399  total_loss: 1.463  loss_cls: 0.346  loss_box_reg: 0.5246  loss_mask: 0.2986  loss_rpn_cls: 0.08954  loss_rpn_loc: 0.1913  time: 0.5515  data_time: 0.2351  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:00:08 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 1419  total_loss: 1.469  loss_cls: 0.3411  loss_box_reg: 0.5289  loss_mask: 0.2928  loss_rpn_cls: 0.09229  loss_rpn_loc: 0.1982  time: 0.5513  data_time: 0.3190  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:00:20 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 1439  total_loss: 1.564  loss_cls: 0.3719  loss_box_reg: 0.5443  loss_mask: 0.3287  loss_rpn_cls: 0.0858  loss_rpn_loc: 0.2069  time: 0.5518  data_time: 0.3641  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:00:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:00:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:00:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:00:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:00:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:00:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0669 s/iter. Eval: 0.0304 s/iter. Total: 0.0979 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 16:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0696 s/iter. Eval: 0.0508 s/iter. Total: 0.1211 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0550 s/iter. Total: 0.1260 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 16:00:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.459229 (0.124649 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:00:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069982 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:00:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:00:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24823218500811853\n",
      "\u001b[32m[02/02 16:00:46 d2.utils.events]: \u001b[0m eta: 0:35:56  iter: 1459  total_loss: 1.443  loss_cls: 0.3319  loss_box_reg: 0.495  loss_mask: 0.2743  loss_rpn_cls: 0.07945  loss_rpn_loc: 0.1693  time: 0.5512  data_time: 0.2650  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:00:57 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 1479  total_loss: 1.558  loss_cls: 0.3934  loss_box_reg: 0.5223  loss_mask: 0.3031  loss_rpn_cls: 0.08905  loss_rpn_loc: 0.2063  time: 0.5511  data_time: 0.3155  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:01:09 d2.utils.events]: \u001b[0m eta: 0:35:45  iter: 1499  total_loss: 1.563  loss_cls: 0.3722  loss_box_reg: 0.5582  loss_mask: 0.3156  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.2115  time: 0.5521  data_time: 0.4043  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:01:18 d2.utils.events]: \u001b[0m eta: 0:35:29  iter: 1519  total_loss: 1.49  loss_cls: 0.384  loss_box_reg: 0.5573  loss_mask: 0.3027  loss_rpn_cls: 0.08009  loss_rpn_loc: 0.2015  time: 0.5510  data_time: 0.2457  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:01:32 d2.utils.events]: \u001b[0m eta: 0:35:28  iter: 1539  total_loss: 1.392  loss_cls: 0.2836  loss_box_reg: 0.5003  loss_mask: 0.3093  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2112  time: 0.5526  data_time: 0.4435  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:01:44 d2.utils.events]: \u001b[0m eta: 0:35:19  iter: 1559  total_loss: 1.502  loss_cls: 0.3465  loss_box_reg: 0.5416  loss_mask: 0.292  loss_rpn_cls: 0.08491  loss_rpn_loc: 0.2195  time: 0.5532  data_time: 0.3688  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:01:59 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 1579  total_loss: 1.584  loss_cls: 0.377  loss_box_reg: 0.5347  loss_mask: 0.3031  loss_rpn_cls: 0.1218  loss_rpn_loc: 0.2132  time: 0.5556  data_time: 0.4899  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:02:07 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 1599  total_loss: 1.321  loss_cls: 0.2998  loss_box_reg: 0.5158  loss_mask: 0.3086  loss_rpn_cls: 0.06284  loss_rpn_loc: 0.1856  time: 0.5538  data_time: 0.2068  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:02:19 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 1619  total_loss: 1.578  loss_cls: 0.3669  loss_box_reg: 0.5533  loss_mask: 0.3313  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2062  time: 0.5545  data_time: 0.3707  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:02:27 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 1639  total_loss: 1.459  loss_cls: 0.3618  loss_box_reg: 0.5421  loss_mask: 0.317  loss_rpn_cls: 0.08403  loss_rpn_loc: 0.1981  time: 0.5523  data_time: 0.1584  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:02:36 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 1659  total_loss: 1.419  loss_cls: 0.2909  loss_box_reg: 0.5317  loss_mask: 0.2998  loss_rpn_cls: 0.09479  loss_rpn_loc: 0.2056  time: 0.5513  data_time: 0.2431  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:02:46 d2.utils.events]: \u001b[0m eta: 0:34:36  iter: 1679  total_loss: 1.44  loss_cls: 0.3098  loss_box_reg: 0.5337  loss_mask: 0.299  loss_rpn_cls: 0.09045  loss_rpn_loc: 0.1945  time: 0.5504  data_time: 0.2549  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:02:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:02:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:02:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:02:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:02:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:02:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.0405 s/iter. Total: 0.1093 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 16:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0544 s/iter. Total: 0.1254 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0559 s/iter. Total: 0.1271 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 16:03:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.565908 (0.125568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:03:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070197 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:03:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:03:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25522703355529613\n",
      "\u001b[32m[02/02 16:03:15 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 1699  total_loss: 1.553  loss_cls: 0.3697  loss_box_reg: 0.529  loss_mask: 0.3111  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.2006  time: 0.5515  data_time: 0.4001  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:03:27 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 1719  total_loss: 1.486  loss_cls: 0.3601  loss_box_reg: 0.5172  loss_mask: 0.3021  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2007  time: 0.5524  data_time: 0.3893  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:03:40 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 1739  total_loss: 1.472  loss_cls: 0.3765  loss_box_reg: 0.5214  loss_mask: 0.2973  loss_rpn_cls: 0.09258  loss_rpn_loc: 0.1983  time: 0.5535  data_time: 0.4199  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:03:50 d2.utils.events]: \u001b[0m eta: 0:34:39  iter: 1759  total_loss: 1.415  loss_cls: 0.3223  loss_box_reg: 0.5346  loss_mask: 0.3199  loss_rpn_cls: 0.07686  loss_rpn_loc: 0.1877  time: 0.5528  data_time: 0.2676  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:03:59 d2.utils.events]: \u001b[0m eta: 0:34:36  iter: 1779  total_loss: 1.465  loss_cls: 0.3686  loss_box_reg: 0.5248  loss_mask: 0.3066  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.1926  time: 0.5518  data_time: 0.2377  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:04:09 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 1799  total_loss: 1.474  loss_cls: 0.3296  loss_box_reg: 0.5519  loss_mask: 0.3087  loss_rpn_cls: 0.0956  loss_rpn_loc: 0.2151  time: 0.5508  data_time: 0.2414  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:04:18 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 1819  total_loss: 1.481  loss_cls: 0.3359  loss_box_reg: 0.5314  loss_mask: 0.2935  loss_rpn_cls: 0.05666  loss_rpn_loc: 0.1942  time: 0.5499  data_time: 0.2541  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:04:32 d2.utils.events]: \u001b[0m eta: 0:34:20  iter: 1839  total_loss: 1.477  loss_cls: 0.3458  loss_box_reg: 0.4988  loss_mask: 0.2939  loss_rpn_cls: 0.09988  loss_rpn_loc: 0.2042  time: 0.5518  data_time: 0.4843  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:04:45 d2.utils.events]: \u001b[0m eta: 0:34:21  iter: 1859  total_loss: 1.461  loss_cls: 0.3211  loss_box_reg: 0.5051  loss_mask: 0.2869  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.2099  time: 0.5527  data_time: 0.4032  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:04:54 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 1879  total_loss: 1.518  loss_cls: 0.337  loss_box_reg: 0.5498  loss_mask: 0.3181  loss_rpn_cls: 0.06446  loss_rpn_loc: 0.2233  time: 0.5516  data_time: 0.2266  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:05:07 d2.utils.events]: \u001b[0m eta: 0:34:07  iter: 1899  total_loss: 1.536  loss_cls: 0.3303  loss_box_reg: 0.5204  loss_mask: 0.3193  loss_rpn_cls: 0.0964  loss_rpn_loc: 0.2184  time: 0.5523  data_time: 0.3833  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:05:16 d2.utils.events]: \u001b[0m eta: 0:34:02  iter: 1919  total_loss: 1.389  loss_cls: 0.3281  loss_box_reg: 0.5141  loss_mask: 0.2952  loss_rpn_cls: 0.07331  loss_rpn_loc: 0.1975  time: 0.5515  data_time: 0.2512  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:05:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:05:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:05:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:05:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:05:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:05:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0396 s/iter. Total: 0.1081 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0578 s/iter. Total: 0.1292 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0627 s/iter. Total: 0.1348 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:05:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.387843 (0.132654 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:05:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070962 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:05:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:05:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2571818415018605\n",
      "\u001b[32m[02/02 16:05:44 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 1939  total_loss: 1.547  loss_cls: 0.3647  loss_box_reg: 0.5613  loss_mask: 0.2947  loss_rpn_cls: 0.09631  loss_rpn_loc: 0.217  time: 0.5514  data_time: 0.3111  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:05:52 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 1959  total_loss: 1.423  loss_cls: 0.3127  loss_box_reg: 0.4974  loss_mask: 0.2953  loss_rpn_cls: 0.08368  loss_rpn_loc: 0.1915  time: 0.5502  data_time: 0.2228  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:06:05 d2.utils.events]: \u001b[0m eta: 0:33:39  iter: 1979  total_loss: 1.606  loss_cls: 0.3558  loss_box_reg: 0.5691  loss_mask: 0.3249  loss_rpn_cls: 0.1229  loss_rpn_loc: 0.2271  time: 0.5509  data_time: 0.3953  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:06:15 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 1999  total_loss: 1.46  loss_cls: 0.3317  loss_box_reg: 0.5415  loss_mask: 0.3094  loss_rpn_cls: 0.07661  loss_rpn_loc: 0.1922  time: 0.5503  data_time: 0.2822  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:06:28 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 2019  total_loss: 1.478  loss_cls: 0.3589  loss_box_reg: 0.5115  loss_mask: 0.3094  loss_rpn_cls: 0.08501  loss_rpn_loc: 0.2272  time: 0.5515  data_time: 0.4250  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:06:37 d2.utils.events]: \u001b[0m eta: 0:33:06  iter: 2039  total_loss: 1.365  loss_cls: 0.285  loss_box_reg: 0.5193  loss_mask: 0.2841  loss_rpn_cls: 0.08989  loss_rpn_loc: 0.1975  time: 0.5506  data_time: 0.2362  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:06:48 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 2059  total_loss: 1.508  loss_cls: 0.3272  loss_box_reg: 0.5347  loss_mask: 0.314  loss_rpn_cls: 0.106  loss_rpn_loc: 0.2127  time: 0.5504  data_time: 0.2987  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:06:57 d2.utils.events]: \u001b[0m eta: 0:32:56  iter: 2079  total_loss: 1.403  loss_cls: 0.3068  loss_box_reg: 0.5246  loss_mask: 0.3116  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.2051  time: 0.5494  data_time: 0.2337  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:07:04 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 2099  total_loss: 1.445  loss_cls: 0.3185  loss_box_reg: 0.5526  loss_mask: 0.2967  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.1954  time: 0.5473  data_time: 0.1201  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:07:16 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 2119  total_loss: 1.413  loss_cls: 0.3264  loss_box_reg: 0.496  loss_mask: 0.2821  loss_rpn_cls: 0.08337  loss_rpn_loc: 0.2024  time: 0.5479  data_time: 0.3763  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:07:28 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 2139  total_loss: 1.474  loss_cls: 0.3397  loss_box_reg: 0.5254  loss_mask: 0.3131  loss_rpn_cls: 0.08006  loss_rpn_loc: 0.2053  time: 0.5484  data_time: 0.3702  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:07:40 d2.utils.events]: \u001b[0m eta: 0:32:36  iter: 2159  total_loss: 1.443  loss_cls: 0.3404  loss_box_reg: 0.5534  loss_mask: 0.3103  loss_rpn_cls: 0.09203  loss_rpn_loc: 0.1897  time: 0.5489  data_time: 0.3612  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:07:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:07:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:07:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:07:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:07:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:07:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0382 s/iter. Total: 0.1068 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0598 s/iter. Total: 0.1315 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:08:00 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0621 s/iter. Total: 0.1342 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:08:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.242973 (0.131405 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:08:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070947 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:08:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:08:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2623026723540451\n",
      "\u001b[32m[02/02 16:08:05 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 2179  total_loss: 1.458  loss_cls: 0.3196  loss_box_reg: 0.5411  loss_mask: 0.3056  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.2086  time: 0.5479  data_time: 0.2002  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:08:16 d2.utils.events]: \u001b[0m eta: 0:32:18  iter: 2199  total_loss: 1.401  loss_cls: 0.3125  loss_box_reg: 0.5143  loss_mask: 0.2905  loss_rpn_cls: 0.07073  loss_rpn_loc: 0.2043  time: 0.5478  data_time: 0.3108  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:08:26 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 2219  total_loss: 1.39  loss_cls: 0.3261  loss_box_reg: 0.5506  loss_mask: 0.2982  loss_rpn_cls: 0.06092  loss_rpn_loc: 0.1952  time: 0.5471  data_time: 0.2587  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:08:36 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 2239  total_loss: 1.445  loss_cls: 0.3344  loss_box_reg: 0.551  loss_mask: 0.3016  loss_rpn_cls: 0.08916  loss_rpn_loc: 0.1974  time: 0.5471  data_time: 0.3104  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:08:45 d2.utils.events]: \u001b[0m eta: 0:31:50  iter: 2259  total_loss: 1.467  loss_cls: 0.351  loss_box_reg: 0.5322  loss_mask: 0.2977  loss_rpn_cls: 0.08806  loss_rpn_loc: 0.1954  time: 0.5461  data_time: 0.2211  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:08:56 d2.utils.events]: \u001b[0m eta: 0:31:52  iter: 2279  total_loss: 1.365  loss_cls: 0.3212  loss_box_reg: 0.519  loss_mask: 0.2894  loss_rpn_cls: 0.07505  loss_rpn_loc: 0.2036  time: 0.5462  data_time: 0.3358  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:09:06 d2.utils.events]: \u001b[0m eta: 0:31:45  iter: 2299  total_loss: 1.399  loss_cls: 0.3178  loss_box_reg: 0.5318  loss_mask: 0.2993  loss_rpn_cls: 0.07101  loss_rpn_loc: 0.1796  time: 0.5459  data_time: 0.2814  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:09:19 d2.utils.events]: \u001b[0m eta: 0:31:41  iter: 2319  total_loss: 1.552  loss_cls: 0.4036  loss_box_reg: 0.5328  loss_mask: 0.3104  loss_rpn_cls: 0.08873  loss_rpn_loc: 0.233  time: 0.5466  data_time: 0.3943  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:09:32 d2.utils.events]: \u001b[0m eta: 0:31:39  iter: 2339  total_loss: 1.384  loss_cls: 0.3068  loss_box_reg: 0.5294  loss_mask: 0.3004  loss_rpn_cls: 0.06275  loss_rpn_loc: 0.2029  time: 0.5474  data_time: 0.3966  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:09:42 d2.utils.events]: \u001b[0m eta: 0:31:37  iter: 2359  total_loss: 1.532  loss_cls: 0.3515  loss_box_reg: 0.5143  loss_mask: 0.3108  loss_rpn_cls: 0.08793  loss_rpn_loc: 0.2022  time: 0.5471  data_time: 0.2923  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:09:54 d2.utils.events]: \u001b[0m eta: 0:31:35  iter: 2379  total_loss: 1.429  loss_cls: 0.2865  loss_box_reg: 0.5208  loss_mask: 0.297  loss_rpn_cls: 0.09755  loss_rpn_loc: 0.1986  time: 0.5475  data_time: 0.3653  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:10:06 d2.utils.events]: \u001b[0m eta: 0:31:35  iter: 2399  total_loss: 1.556  loss_cls: 0.3652  loss_box_reg: 0.5798  loss_mask: 0.3116  loss_rpn_cls: 0.09223  loss_rpn_loc: 0.2149  time: 0.5478  data_time: 0.3502  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:10:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:10:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:10:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:10:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:10:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:10:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0671 s/iter. Eval: 0.0356 s/iter. Total: 0.1033 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0699 s/iter. Eval: 0.0535 s/iter. Total: 0.1242 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0563 s/iter. Total: 0.1273 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 16:10:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.642067 (0.126225 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:10:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070135 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:10:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:10:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26189703617459253\n",
      "\u001b[32m[02/02 16:10:36 d2.utils.events]: \u001b[0m eta: 0:31:32  iter: 2419  total_loss: 1.366  loss_cls: 0.3028  loss_box_reg: 0.4815  loss_mask: 0.2917  loss_rpn_cls: 0.09606  loss_rpn_loc: 0.1864  time: 0.5492  data_time: 0.4927  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:10:46 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 2439  total_loss: 1.496  loss_cls: 0.3444  loss_box_reg: 0.5609  loss_mask: 0.3133  loss_rpn_cls: 0.08966  loss_rpn_loc: 0.1949  time: 0.5487  data_time: 0.2594  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:10:58 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 2459  total_loss: 1.557  loss_cls: 0.3714  loss_box_reg: 0.5245  loss_mask: 0.3158  loss_rpn_cls: 0.1  loss_rpn_loc: 0.2204  time: 0.5491  data_time: 0.3628  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:11:08 d2.utils.events]: \u001b[0m eta: 0:31:22  iter: 2479  total_loss: 1.502  loss_cls: 0.3616  loss_box_reg: 0.5513  loss_mask: 0.3133  loss_rpn_cls: 0.06052  loss_rpn_loc: 0.1941  time: 0.5486  data_time: 0.2757  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:11:21 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 2499  total_loss: 1.508  loss_cls: 0.3345  loss_box_reg: 0.5616  loss_mask: 0.3056  loss_rpn_cls: 0.09415  loss_rpn_loc: 0.2055  time: 0.5497  data_time: 0.4441  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:11:29 d2.utils.events]: \u001b[0m eta: 0:31:15  iter: 2519  total_loss: 1.48  loss_cls: 0.3277  loss_box_reg: 0.5369  loss_mask: 0.3096  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1885  time: 0.5484  data_time: 0.1679  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:11:37 d2.utils.events]: \u001b[0m eta: 0:31:00  iter: 2539  total_loss: 1.332  loss_cls: 0.2776  loss_box_reg: 0.538  loss_mask: 0.3016  loss_rpn_cls: 0.05213  loss_rpn_loc: 0.1857  time: 0.5474  data_time: 0.1963  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:11:48 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 2559  total_loss: 1.415  loss_cls: 0.3342  loss_box_reg: 0.4981  loss_mask: 0.2953  loss_rpn_cls: 0.07198  loss_rpn_loc: 0.1938  time: 0.5472  data_time: 0.3033  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:12:00 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 2579  total_loss: 1.513  loss_cls: 0.36  loss_box_reg: 0.5219  loss_mask: 0.3032  loss_rpn_cls: 0.09828  loss_rpn_loc: 0.2203  time: 0.5475  data_time: 0.3530  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:12:11 d2.utils.events]: \u001b[0m eta: 0:30:52  iter: 2599  total_loss: 1.443  loss_cls: 0.3354  loss_box_reg: 0.5271  loss_mask: 0.2882  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.2004  time: 0.5475  data_time: 0.3078  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:12:19 d2.utils.events]: \u001b[0m eta: 0:30:43  iter: 2619  total_loss: 1.295  loss_cls: 0.3009  loss_box_reg: 0.4806  loss_mask: 0.28  loss_rpn_cls: 0.06075  loss_rpn_loc: 0.1707  time: 0.5463  data_time: 0.1755  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:12:35 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 2639  total_loss: 1.377  loss_cls: 0.2932  loss_box_reg: 0.4885  loss_mask: 0.2959  loss_rpn_cls: 0.09332  loss_rpn_loc: 0.197  time: 0.5485  data_time: 0.5834  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:12:45 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 2659  total_loss: 1.423  loss_cls: 0.3192  loss_box_reg: 0.5379  loss_mask: 0.3081  loss_rpn_cls: 0.07817  loss_rpn_loc: 0.2074  time: 0.5479  data_time: 0.2376  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:12:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:12:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:12:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:12:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:12:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:12:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0386 s/iter. Total: 0.1070 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0568 s/iter. Total: 0.1281 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0594 s/iter. Total: 0.1312 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:13:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.081891 (0.130016 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:13:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070854 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:13:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:13:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2578926714528631\n",
      "\u001b[32m[02/02 16:13:13 d2.utils.events]: \u001b[0m eta: 0:30:52  iter: 2679  total_loss: 1.384  loss_cls: 0.286  loss_box_reg: 0.5084  loss_mask: 0.2959  loss_rpn_cls: 0.07408  loss_rpn_loc: 0.1904  time: 0.5481  data_time: 0.3499  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:13:21 d2.utils.events]: \u001b[0m eta: 0:30:34  iter: 2699  total_loss: 1.509  loss_cls: 0.3761  loss_box_reg: 0.5325  loss_mask: 0.31  loss_rpn_cls: 0.06049  loss_rpn_loc: 0.1912  time: 0.5470  data_time: 0.1839  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:13:32 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 2719  total_loss: 1.549  loss_cls: 0.3692  loss_box_reg: 0.5467  loss_mask: 0.3108  loss_rpn_cls: 0.106  loss_rpn_loc: 0.2069  time: 0.5471  data_time: 0.3329  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:13:46 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 2739  total_loss: 1.425  loss_cls: 0.2829  loss_box_reg: 0.493  loss_mask: 0.3017  loss_rpn_cls: 0.08195  loss_rpn_loc: 0.1862  time: 0.5482  data_time: 0.4505  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:13:56 d2.utils.events]: \u001b[0m eta: 0:30:12  iter: 2759  total_loss: 1.416  loss_cls: 0.3055  loss_box_reg: 0.5225  loss_mask: 0.2983  loss_rpn_cls: 0.07275  loss_rpn_loc: 0.1955  time: 0.5480  data_time: 0.3009  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:14:09 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 2779  total_loss: 1.353  loss_cls: 0.296  loss_box_reg: 0.4832  loss_mask: 0.2873  loss_rpn_cls: 0.07633  loss_rpn_loc: 0.1879  time: 0.5485  data_time: 0.4007  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:14:17 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 2799  total_loss: 1.516  loss_cls: 0.3385  loss_box_reg: 0.5329  loss_mask: 0.2912  loss_rpn_cls: 0.09061  loss_rpn_loc: 0.189  time: 0.5477  data_time: 0.2095  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:14:29 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 2819  total_loss: 1.546  loss_cls: 0.3469  loss_box_reg: 0.5549  loss_mask: 0.3072  loss_rpn_cls: 0.08362  loss_rpn_loc: 0.1964  time: 0.5478  data_time: 0.3372  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:14:43 d2.utils.events]: \u001b[0m eta: 0:30:18  iter: 2839  total_loss: 1.395  loss_cls: 0.3324  loss_box_reg: 0.5025  loss_mask: 0.3047  loss_rpn_cls: 0.07772  loss_rpn_loc: 0.2042  time: 0.5491  data_time: 0.4981  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:14:54 d2.utils.events]: \u001b[0m eta: 0:29:54  iter: 2859  total_loss: 1.425  loss_cls: 0.3561  loss_box_reg: 0.5197  loss_mask: 0.3069  loss_rpn_cls: 0.08187  loss_rpn_loc: 0.2  time: 0.5489  data_time: 0.2958  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:15:03 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 2879  total_loss: 1.451  loss_cls: 0.298  loss_box_reg: 0.4991  loss_mask: 0.2981  loss_rpn_cls: 0.07106  loss_rpn_loc: 0.2108  time: 0.5484  data_time: 0.2471  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:15:13 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 2899  total_loss: 1.323  loss_cls: 0.2821  loss_box_reg: 0.504  loss_mask: 0.2979  loss_rpn_cls: 0.05816  loss_rpn_loc: 0.1831  time: 0.5481  data_time: 0.2801  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:15:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:15:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:15:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:15:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:15:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:15:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0674 s/iter. Eval: 0.0348 s/iter. Total: 0.1028 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0548 s/iter. Total: 0.1258 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0588 s/iter. Total: 0.1303 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:15:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.966076 (0.129018 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:15:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070567 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:15:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:15:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25585481006732425\n",
      "\u001b[32m[02/02 16:15:40 d2.utils.events]: \u001b[0m eta: 0:29:55  iter: 2919  total_loss: 1.499  loss_cls: 0.3498  loss_box_reg: 0.5498  loss_mask: 0.3176  loss_rpn_cls: 0.09674  loss_rpn_loc: 0.2247  time: 0.5479  data_time: 0.2960  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:15:55 d2.utils.events]: \u001b[0m eta: 0:29:53  iter: 2939  total_loss: 1.447  loss_cls: 0.3028  loss_box_reg: 0.4961  loss_mask: 0.3134  loss_rpn_cls: 0.09989  loss_rpn_loc: 0.2116  time: 0.5493  data_time: 0.5137  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:16:05 d2.utils.events]: \u001b[0m eta: 0:29:45  iter: 2959  total_loss: 1.377  loss_cls: 0.2873  loss_box_reg: 0.5211  loss_mask: 0.2958  loss_rpn_cls: 0.08438  loss_rpn_loc: 0.1856  time: 0.5488  data_time: 0.2507  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:16:13 d2.utils.events]: \u001b[0m eta: 0:29:26  iter: 2979  total_loss: 1.412  loss_cls: 0.3089  loss_box_reg: 0.525  loss_mask: 0.3018  loss_rpn_cls: 0.07765  loss_rpn_loc: 0.1865  time: 0.5479  data_time: 0.2035  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:16:21 d2.utils.events]: \u001b[0m eta: 0:29:18  iter: 2999  total_loss: 1.415  loss_cls: 0.3119  loss_box_reg: 0.5198  loss_mask: 0.2974  loss_rpn_cls: 0.06138  loss_rpn_loc: 0.1933  time: 0.5468  data_time: 0.1777  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:16:31 d2.utils.events]: \u001b[0m eta: 0:29:07  iter: 3019  total_loss: 1.354  loss_cls: 0.2979  loss_box_reg: 0.4985  loss_mask: 0.2885  loss_rpn_cls: 0.06004  loss_rpn_loc: 0.1956  time: 0.5465  data_time: 0.2768  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:16:44 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 3039  total_loss: 1.423  loss_cls: 0.3187  loss_box_reg: 0.5261  loss_mask: 0.3132  loss_rpn_cls: 0.07956  loss_rpn_loc: 0.1776  time: 0.5472  data_time: 0.4144  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:16:56 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 3059  total_loss: 1.516  loss_cls: 0.3515  loss_box_reg: 0.5419  loss_mask: 0.3203  loss_rpn_cls: 0.08381  loss_rpn_loc: 0.2104  time: 0.5476  data_time: 0.3768  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:17:11 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 3079  total_loss: 1.495  loss_cls: 0.3575  loss_box_reg: 0.5145  loss_mask: 0.3155  loss_rpn_cls: 0.09397  loss_rpn_loc: 0.2098  time: 0.5491  data_time: 0.5245  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:17:22 d2.utils.events]: \u001b[0m eta: 0:29:14  iter: 3099  total_loss: 1.397  loss_cls: 0.3381  loss_box_reg: 0.5126  loss_mask: 0.2925  loss_rpn_cls: 0.08241  loss_rpn_loc: 0.2122  time: 0.5490  data_time: 0.3158  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:17:33 d2.utils.events]: \u001b[0m eta: 0:29:09  iter: 3119  total_loss: 1.355  loss_cls: 0.303  loss_box_reg: 0.5246  loss_mask: 0.2912  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.1858  time: 0.5490  data_time: 0.3273  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:17:47 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 3139  total_loss: 1.469  loss_cls: 0.3373  loss_box_reg: 0.5208  loss_mask: 0.3033  loss_rpn_cls: 0.08319  loss_rpn_loc: 0.1943  time: 0.5499  data_time: 0.4505  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:17:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:17:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:17:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:17:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:17:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:17:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0360 s/iter. Total: 0.1043 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0696 s/iter. Eval: 0.0500 s/iter. Total: 0.1203 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0522 s/iter. Total: 0.1230 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 16:18:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.980139 (0.120518 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:18:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069614 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:18:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:18:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2596265759326053\n",
      "\u001b[32m[02/02 16:18:10 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 3159  total_loss: 1.457  loss_cls: 0.3357  loss_box_reg: 0.5381  loss_mask: 0.3017  loss_rpn_cls: 0.09054  loss_rpn_loc: 0.2073  time: 0.5489  data_time: 0.1712  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:18:23 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 3179  total_loss: 1.464  loss_cls: 0.3249  loss_box_reg: 0.5139  loss_mask: 0.3142  loss_rpn_cls: 0.09186  loss_rpn_loc: 0.2115  time: 0.5493  data_time: 0.3764  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:18:34 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 3199  total_loss: 1.486  loss_cls: 0.3659  loss_box_reg: 0.5291  loss_mask: 0.3212  loss_rpn_cls: 0.09326  loss_rpn_loc: 0.1997  time: 0.5493  data_time: 0.3055  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:18:47 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 3219  total_loss: 1.317  loss_cls: 0.309  loss_box_reg: 0.5042  loss_mask: 0.2841  loss_rpn_cls: 0.07379  loss_rpn_loc: 0.1801  time: 0.5501  data_time: 0.4327  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:18:57 d2.utils.events]: \u001b[0m eta: 0:28:54  iter: 3239  total_loss: 1.585  loss_cls: 0.3569  loss_box_reg: 0.5453  loss_mask: 0.3157  loss_rpn_cls: 0.08682  loss_rpn_loc: 0.2037  time: 0.5498  data_time: 0.2759  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:19:06 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 3259  total_loss: 1.393  loss_cls: 0.3227  loss_box_reg: 0.4903  loss_mask: 0.3079  loss_rpn_cls: 0.07281  loss_rpn_loc: 0.1845  time: 0.5490  data_time: 0.2045  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:19:19 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 3279  total_loss: 1.45  loss_cls: 0.3265  loss_box_reg: 0.5292  loss_mask: 0.3095  loss_rpn_cls: 0.08139  loss_rpn_loc: 0.2004  time: 0.5496  data_time: 0.4068  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:19:29 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 3299  total_loss: 1.413  loss_cls: 0.3179  loss_box_reg: 0.4911  loss_mask: 0.2926  loss_rpn_cls: 0.09478  loss_rpn_loc: 0.1863  time: 0.5495  data_time: 0.3038  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:19:42 d2.utils.events]: \u001b[0m eta: 0:28:20  iter: 3319  total_loss: 1.471  loss_cls: 0.3368  loss_box_reg: 0.5228  loss_mask: 0.2975  loss_rpn_cls: 0.08158  loss_rpn_loc: 0.1883  time: 0.5499  data_time: 0.3905  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:19:54 d2.utils.events]: \u001b[0m eta: 0:28:19  iter: 3339  total_loss: 1.452  loss_cls: 0.3422  loss_box_reg: 0.5116  loss_mask: 0.3022  loss_rpn_cls: 0.06876  loss_rpn_loc: 0.206  time: 0.5504  data_time: 0.3940  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:20:04 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 3359  total_loss: 1.334  loss_cls: 0.2811  loss_box_reg: 0.5056  loss_mask: 0.2903  loss_rpn_cls: 0.07714  loss_rpn_loc: 0.1947  time: 0.5499  data_time: 0.2426  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:20:15 d2.utils.events]: \u001b[0m eta: 0:28:03  iter: 3379  total_loss: 1.452  loss_cls: 0.3222  loss_box_reg: 0.5319  loss_mask: 0.2986  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.2003  time: 0.5500  data_time: 0.3292  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:20:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:20:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:20:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:20:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:20:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:20:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0689 s/iter. Eval: 0.0442 s/iter. Total: 0.1138 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 16:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0588 s/iter. Total: 0.1304 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0630 s/iter. Total: 0.1351 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:20:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.413531 (0.132875 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:20:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071018 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:20:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:20:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26533535483029164\n",
      "\u001b[32m[02/02 16:20:43 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 3399  total_loss: 1.39  loss_cls: 0.3087  loss_box_reg: 0.52  loss_mask: 0.2874  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.1818  time: 0.5501  data_time: 0.3419  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:20:55 d2.utils.events]: \u001b[0m eta: 0:27:54  iter: 3419  total_loss: 1.442  loss_cls: 0.3363  loss_box_reg: 0.5048  loss_mask: 0.3033  loss_rpn_cls: 0.08023  loss_rpn_loc: 0.1956  time: 0.5502  data_time: 0.3356  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:21:07 d2.utils.events]: \u001b[0m eta: 0:27:50  iter: 3439  total_loss: 1.442  loss_cls: 0.3304  loss_box_reg: 0.5072  loss_mask: 0.2942  loss_rpn_cls: 0.06952  loss_rpn_loc: 0.2002  time: 0.5506  data_time: 0.3797  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:21:16 d2.utils.events]: \u001b[0m eta: 0:27:42  iter: 3459  total_loss: 1.435  loss_cls: 0.3385  loss_box_reg: 0.5328  loss_mask: 0.3082  loss_rpn_cls: 0.0872  loss_rpn_loc: 0.1821  time: 0.5499  data_time: 0.2144  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:21:28 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 3479  total_loss: 1.448  loss_cls: 0.3172  loss_box_reg: 0.5171  loss_mask: 0.2954  loss_rpn_cls: 0.08879  loss_rpn_loc: 0.1807  time: 0.5502  data_time: 0.3760  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:21:37 d2.utils.events]: \u001b[0m eta: 0:27:30  iter: 3499  total_loss: 1.427  loss_cls: 0.3658  loss_box_reg: 0.5048  loss_mask: 0.292  loss_rpn_cls: 0.07277  loss_rpn_loc: 0.2098  time: 0.5497  data_time: 0.2239  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:21:51 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 3519  total_loss: 1.4  loss_cls: 0.3208  loss_box_reg: 0.4886  loss_mask: 0.3054  loss_rpn_cls: 0.06334  loss_rpn_loc: 0.1927  time: 0.5506  data_time: 0.4654  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:22:01 d2.utils.events]: \u001b[0m eta: 0:27:25  iter: 3539  total_loss: 1.42  loss_cls: 0.3071  loss_box_reg: 0.5107  loss_mask: 0.307  loss_rpn_cls: 0.06497  loss_rpn_loc: 0.1926  time: 0.5504  data_time: 0.3050  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:22:15 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 3559  total_loss: 1.48  loss_cls: 0.3366  loss_box_reg: 0.5356  loss_mask: 0.3241  loss_rpn_cls: 0.0817  loss_rpn_loc: 0.202  time: 0.5511  data_time: 0.4572  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:22:28 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 3579  total_loss: 1.415  loss_cls: 0.3241  loss_box_reg: 0.5139  loss_mask: 0.2871  loss_rpn_cls: 0.0772  loss_rpn_loc: 0.1928  time: 0.5518  data_time: 0.4433  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:22:41 d2.utils.events]: \u001b[0m eta: 0:27:09  iter: 3599  total_loss: 1.431  loss_cls: 0.3176  loss_box_reg: 0.5256  loss_mask: 0.2976  loss_rpn_cls: 0.08724  loss_rpn_loc: 0.1927  time: 0.5521  data_time: 0.3895  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:22:49 d2.utils.events]: \u001b[0m eta: 0:27:02  iter: 3619  total_loss: 1.422  loss_cls: 0.3355  loss_box_reg: 0.5088  loss_mask: 0.311  loss_rpn_cls: 0.05286  loss_rpn_loc: 0.1912  time: 0.5515  data_time: 0.2179  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:22:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:22:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:22:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:22:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:22:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:22:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0375 s/iter. Total: 0.1057 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0543 s/iter. Total: 0.1252 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0562 s/iter. Total: 0.1273 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 16:23:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.604298 (0.125899 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:23:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070160 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:23:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:23:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2567647422116842\n",
      "\u001b[32m[02/02 16:23:14 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 3639  total_loss: 1.414  loss_cls: 0.3262  loss_box_reg: 0.5144  loss_mask: 0.2956  loss_rpn_cls: 0.06715  loss_rpn_loc: 0.2003  time: 0.5507  data_time: 0.2015  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:23:26 d2.utils.events]: \u001b[0m eta: 0:26:48  iter: 3659  total_loss: 1.414  loss_cls: 0.2895  loss_box_reg: 0.498  loss_mask: 0.292  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.2036  time: 0.5511  data_time: 0.3862  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:23:35 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 3679  total_loss: 1.319  loss_cls: 0.2954  loss_box_reg: 0.5121  loss_mask: 0.295  loss_rpn_cls: 0.04973  loss_rpn_loc: 0.1803  time: 0.5505  data_time: 0.2290  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:23:47 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 3699  total_loss: 1.422  loss_cls: 0.3091  loss_box_reg: 0.5043  loss_mask: 0.3033  loss_rpn_cls: 0.07355  loss_rpn_loc: 0.1918  time: 0.5507  data_time: 0.3573  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:23:58 d2.utils.events]: \u001b[0m eta: 0:26:27  iter: 3719  total_loss: 1.345  loss_cls: 0.2933  loss_box_reg: 0.5082  loss_mask: 0.2941  loss_rpn_cls: 0.07221  loss_rpn_loc: 0.1908  time: 0.5506  data_time: 0.3251  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:24:10 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 3739  total_loss: 1.462  loss_cls: 0.3459  loss_box_reg: 0.5274  loss_mask: 0.3046  loss_rpn_cls: 0.06972  loss_rpn_loc: 0.2022  time: 0.5510  data_time: 0.3729  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:24:20 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 3759  total_loss: 1.47  loss_cls: 0.335  loss_box_reg: 0.5016  loss_mask: 0.2971  loss_rpn_cls: 0.07917  loss_rpn_loc: 0.2153  time: 0.5506  data_time: 0.2699  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:24:31 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 3779  total_loss: 1.487  loss_cls: 0.3663  loss_box_reg: 0.5208  loss_mask: 0.3058  loss_rpn_cls: 0.09293  loss_rpn_loc: 0.2228  time: 0.5506  data_time: 0.3055  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:24:41 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 3799  total_loss: 1.407  loss_cls: 0.3203  loss_box_reg: 0.4976  loss_mask: 0.3053  loss_rpn_cls: 0.07869  loss_rpn_loc: 0.1902  time: 0.5504  data_time: 0.2833  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:24:52 d2.utils.events]: \u001b[0m eta: 0:26:01  iter: 3819  total_loss: 1.488  loss_cls: 0.3423  loss_box_reg: 0.5277  loss_mask: 0.2951  loss_rpn_cls: 0.09485  loss_rpn_loc: 0.2007  time: 0.5505  data_time: 0.3443  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:25:06 d2.utils.events]: \u001b[0m eta: 0:25:55  iter: 3839  total_loss: 1.366  loss_cls: 0.3412  loss_box_reg: 0.4877  loss_mask: 0.286  loss_rpn_cls: 0.07754  loss_rpn_loc: 0.1677  time: 0.5512  data_time: 0.4352  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:25:17 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 3859  total_loss: 1.381  loss_cls: 0.296  loss_box_reg: 0.4978  loss_mask: 0.3006  loss_rpn_cls: 0.09052  loss_rpn_loc: 0.19  time: 0.5513  data_time: 0.3347  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:25:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:25:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:25:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:25:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:25:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:25:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0359 s/iter. Total: 0.1042 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0557 s/iter. Total: 0.1268 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0597 s/iter. Total: 0.1315 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:25:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.110253 (0.130261 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:25:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:25:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:25:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2598016376697769\n",
      "\u001b[32m[02/02 16:25:43 d2.utils.events]: \u001b[0m eta: 0:25:46  iter: 3879  total_loss: 1.492  loss_cls: 0.3109  loss_box_reg: 0.5384  loss_mask: 0.2884  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1896  time: 0.5507  data_time: 0.2286  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:25:55 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 3899  total_loss: 1.377  loss_cls: 0.318  loss_box_reg: 0.4937  loss_mask: 0.2932  loss_rpn_cls: 0.07802  loss_rpn_loc: 0.195  time: 0.5511  data_time: 0.3889  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:26:07 d2.utils.events]: \u001b[0m eta: 0:25:36  iter: 3919  total_loss: 1.433  loss_cls: 0.3178  loss_box_reg: 0.4923  loss_mask: 0.3013  loss_rpn_cls: 0.08649  loss_rpn_loc: 0.1994  time: 0.5512  data_time: 0.3324  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:26:18 d2.utils.events]: \u001b[0m eta: 0:25:31  iter: 3939  total_loss: 1.436  loss_cls: 0.3135  loss_box_reg: 0.4812  loss_mask: 0.2989  loss_rpn_cls: 0.073  loss_rpn_loc: 0.1921  time: 0.5513  data_time: 0.3532  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:26:29 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 3959  total_loss: 1.398  loss_cls: 0.3513  loss_box_reg: 0.5144  loss_mask: 0.3083  loss_rpn_cls: 0.06041  loss_rpn_loc: 0.18  time: 0.5513  data_time: 0.3154  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:26:35 d2.utils.events]: \u001b[0m eta: 0:25:21  iter: 3979  total_loss: 1.406  loss_cls: 0.2845  loss_box_reg: 0.521  loss_mask: 0.3037  loss_rpn_cls: 0.05935  loss_rpn_loc: 0.1823  time: 0.5501  data_time: 0.1145  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:26:45 d2.utils.events]: \u001b[0m eta: 0:25:16  iter: 3999  total_loss: 1.376  loss_cls: 0.3073  loss_box_reg: 0.5022  loss_mask: 0.2922  loss_rpn_cls: 0.05617  loss_rpn_loc: 0.1937  time: 0.5498  data_time: 0.2622  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:27:00 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 4019  total_loss: 1.417  loss_cls: 0.3127  loss_box_reg: 0.4991  loss_mask: 0.3012  loss_rpn_cls: 0.08041  loss_rpn_loc: 0.1911  time: 0.5506  data_time: 0.4702  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:27:09 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 4039  total_loss: 1.478  loss_cls: 0.3738  loss_box_reg: 0.5218  loss_mask: 0.2904  loss_rpn_cls: 0.07292  loss_rpn_loc: 0.201  time: 0.5504  data_time: 0.2672  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:27:21 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 4059  total_loss: 1.48  loss_cls: 0.3541  loss_box_reg: 0.5073  loss_mask: 0.2998  loss_rpn_cls: 0.08231  loss_rpn_loc: 0.2133  time: 0.5506  data_time: 0.3573  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:27:33 d2.utils.events]: \u001b[0m eta: 0:24:59  iter: 4079  total_loss: 1.475  loss_cls: 0.3262  loss_box_reg: 0.5201  loss_mask: 0.3028  loss_rpn_cls: 0.08798  loss_rpn_loc: 0.2126  time: 0.5506  data_time: 0.3214  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:27:43 d2.utils.events]: \u001b[0m eta: 0:24:51  iter: 4099  total_loss: 1.477  loss_cls: 0.3637  loss_box_reg: 0.5179  loss_mask: 0.2948  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.2047  time: 0.5504  data_time: 0.2712  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:27:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:27:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:27:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:27:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:27:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:27:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:27:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0396 s/iter. Total: 0.1082 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0547 s/iter. Total: 0.1257 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0564 s/iter. Total: 0.1276 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:28:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.687749 (0.126619 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:28:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070280 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:28:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:28:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26108883763786866\n",
      "\u001b[32m[02/02 16:28:08 d2.utils.events]: \u001b[0m eta: 0:24:45  iter: 4119  total_loss: 1.362  loss_cls: 0.3152  loss_box_reg: 0.5373  loss_mask: 0.3078  loss_rpn_cls: 0.06958  loss_rpn_loc: 0.1791  time: 0.5499  data_time: 0.2228  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:28:20 d2.utils.events]: \u001b[0m eta: 0:24:40  iter: 4139  total_loss: 1.371  loss_cls: 0.311  loss_box_reg: 0.5063  loss_mask: 0.3023  loss_rpn_cls: 0.08138  loss_rpn_loc: 0.1828  time: 0.5501  data_time: 0.3791  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:28:28 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 4159  total_loss: 1.412  loss_cls: 0.3277  loss_box_reg: 0.5093  loss_mask: 0.2837  loss_rpn_cls: 0.07919  loss_rpn_loc: 0.2016  time: 0.5495  data_time: 0.2003  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:28:41 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 4179  total_loss: 1.403  loss_cls: 0.3064  loss_box_reg: 0.4772  loss_mask: 0.2905  loss_rpn_cls: 0.08518  loss_rpn_loc: 0.2024  time: 0.5499  data_time: 0.3784  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:28:51 d2.utils.events]: \u001b[0m eta: 0:24:24  iter: 4199  total_loss: 1.449  loss_cls: 0.3268  loss_box_reg: 0.5123  loss_mask: 0.292  loss_rpn_cls: 0.08576  loss_rpn_loc: 0.1988  time: 0.5496  data_time: 0.2718  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:29:00 d2.utils.events]: \u001b[0m eta: 0:24:16  iter: 4219  total_loss: 1.367  loss_cls: 0.2961  loss_box_reg: 0.5064  loss_mask: 0.2905  loss_rpn_cls: 0.06885  loss_rpn_loc: 0.1847  time: 0.5493  data_time: 0.2626  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:29:11 d2.utils.events]: \u001b[0m eta: 0:24:15  iter: 4239  total_loss: 1.52  loss_cls: 0.323  loss_box_reg: 0.5557  loss_mask: 0.3141  loss_rpn_cls: 0.09511  loss_rpn_loc: 0.22  time: 0.5491  data_time: 0.2929  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:29:24 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 4259  total_loss: 1.362  loss_cls: 0.2883  loss_box_reg: 0.4737  loss_mask: 0.2851  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.1888  time: 0.5496  data_time: 0.4238  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:29:36 d2.utils.events]: \u001b[0m eta: 0:24:06  iter: 4279  total_loss: 1.472  loss_cls: 0.3649  loss_box_reg: 0.5249  loss_mask: 0.3135  loss_rpn_cls: 0.09156  loss_rpn_loc: 0.2122  time: 0.5499  data_time: 0.3665  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:29:44 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 4299  total_loss: 1.435  loss_cls: 0.328  loss_box_reg: 0.5209  loss_mask: 0.3031  loss_rpn_cls: 0.08083  loss_rpn_loc: 0.1873  time: 0.5493  data_time: 0.2016  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:29:54 d2.utils.events]: \u001b[0m eta: 0:23:54  iter: 4319  total_loss: 1.401  loss_cls: 0.3327  loss_box_reg: 0.532  loss_mask: 0.2925  loss_rpn_cls: 0.09159  loss_rpn_loc: 0.1948  time: 0.5490  data_time: 0.2571  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:30:04 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 4339  total_loss: 1.381  loss_cls: 0.3064  loss_box_reg: 0.4786  loss_mask: 0.272  loss_rpn_cls: 0.07528  loss_rpn_loc: 0.1821  time: 0.5488  data_time: 0.2768  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:30:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:30:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:30:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:30:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:30:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:30:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0674 s/iter. Eval: 0.0353 s/iter. Total: 0.1033 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0697 s/iter. Eval: 0.0514 s/iter. Total: 0.1219 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0549 s/iter. Total: 0.1259 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 16:30:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.402797 (0.124162 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:30:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069949 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:30:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:30:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26086950219799654\n",
      "\u001b[32m[02/02 16:30:29 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 4359  total_loss: 1.483  loss_cls: 0.3415  loss_box_reg: 0.5252  loss_mask: 0.293  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.2142  time: 0.5483  data_time: 0.2364  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:30:40 d2.utils.events]: \u001b[0m eta: 0:23:39  iter: 4379  total_loss: 1.408  loss_cls: 0.3361  loss_box_reg: 0.4947  loss_mask: 0.3063  loss_rpn_cls: 0.07557  loss_rpn_loc: 0.1931  time: 0.5484  data_time: 0.3206  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:30:54 d2.utils.events]: \u001b[0m eta: 0:23:35  iter: 4399  total_loss: 1.402  loss_cls: 0.3087  loss_box_reg: 0.5133  loss_mask: 0.3131  loss_rpn_cls: 0.06966  loss_rpn_loc: 0.2038  time: 0.5491  data_time: 0.4568  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:31:05 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 4419  total_loss: 1.328  loss_cls: 0.3064  loss_box_reg: 0.5085  loss_mask: 0.291  loss_rpn_cls: 0.06012  loss_rpn_loc: 0.1738  time: 0.5489  data_time: 0.2870  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:31:16 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 4439  total_loss: 1.402  loss_cls: 0.3355  loss_box_reg: 0.5027  loss_mask: 0.3096  loss_rpn_cls: 0.07067  loss_rpn_loc: 0.1858  time: 0.5489  data_time: 0.3123  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:31:23 d2.utils.events]: \u001b[0m eta: 0:23:18  iter: 4459  total_loss: 1.503  loss_cls: 0.3408  loss_box_reg: 0.5313  loss_mask: 0.292  loss_rpn_cls: 0.07978  loss_rpn_loc: 0.1997  time: 0.5482  data_time: 0.1874  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:31:37 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 4479  total_loss: 1.47  loss_cls: 0.3591  loss_box_reg: 0.4638  loss_mask: 0.2952  loss_rpn_cls: 0.102  loss_rpn_loc: 0.197  time: 0.5488  data_time: 0.4253  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:31:48 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 4499  total_loss: 1.385  loss_cls: 0.3127  loss_box_reg: 0.4831  loss_mask: 0.2943  loss_rpn_cls: 0.05716  loss_rpn_loc: 0.1878  time: 0.5488  data_time: 0.3253  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:31:55 d2.utils.events]: \u001b[0m eta: 0:23:03  iter: 4519  total_loss: 1.361  loss_cls: 0.293  loss_box_reg: 0.5351  loss_mask: 0.3084  loss_rpn_cls: 0.06286  loss_rpn_loc: 0.1821  time: 0.5480  data_time: 0.1590  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:32:03 d2.utils.events]: \u001b[0m eta: 0:22:58  iter: 4539  total_loss: 1.367  loss_cls: 0.2801  loss_box_reg: 0.5119  loss_mask: 0.2899  loss_rpn_cls: 0.06739  loss_rpn_loc: 0.186  time: 0.5473  data_time: 0.1787  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:32:15 d2.utils.events]: \u001b[0m eta: 0:22:53  iter: 4559  total_loss: 1.459  loss_cls: 0.3075  loss_box_reg: 0.5335  loss_mask: 0.3132  loss_rpn_cls: 0.09161  loss_rpn_loc: 0.1867  time: 0.5476  data_time: 0.3798  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:32:27 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 4579  total_loss: 1.43  loss_cls: 0.3225  loss_box_reg: 0.5198  loss_mask: 0.3088  loss_rpn_cls: 0.08735  loss_rpn_loc: 0.2021  time: 0.5478  data_time: 0.3750  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:32:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:32:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:32:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:32:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:32:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:32:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0379 s/iter. Total: 0.1061 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:32:44 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0577 s/iter. Total: 0.1292 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0618 s/iter. Total: 0.1339 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.277388 (0.131702 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070949 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:32:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26931021671196986\n",
      "\u001b[32m[02/02 16:32:54 d2.utils.events]: \u001b[0m eta: 0:22:38  iter: 4599  total_loss: 1.278  loss_cls: 0.2613  loss_box_reg: 0.4882  loss_mask: 0.2856  loss_rpn_cls: 0.04777  loss_rpn_loc: 0.1653  time: 0.5476  data_time: 0.2778  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:33:07 d2.utils.events]: \u001b[0m eta: 0:22:45  iter: 4619  total_loss: 1.463  loss_cls: 0.3599  loss_box_reg: 0.5085  loss_mask: 0.3029  loss_rpn_cls: 0.09163  loss_rpn_loc: 0.2107  time: 0.5480  data_time: 0.3995  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:33:20 d2.utils.events]: \u001b[0m eta: 0:22:45  iter: 4639  total_loss: 1.379  loss_cls: 0.2714  loss_box_reg: 0.5039  loss_mask: 0.296  loss_rpn_cls: 0.06278  loss_rpn_loc: 0.2006  time: 0.5485  data_time: 0.4230  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:33:30 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 4659  total_loss: 1.422  loss_cls: 0.3096  loss_box_reg: 0.5038  loss_mask: 0.3086  loss_rpn_cls: 0.06839  loss_rpn_loc: 0.2072  time: 0.5483  data_time: 0.2754  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:33:40 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 4679  total_loss: 1.379  loss_cls: 0.3238  loss_box_reg: 0.5094  loss_mask: 0.3021  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.1913  time: 0.5481  data_time: 0.2738  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:33:51 d2.utils.events]: \u001b[0m eta: 0:22:19  iter: 4699  total_loss: 1.414  loss_cls: 0.353  loss_box_reg: 0.5045  loss_mask: 0.2872  loss_rpn_cls: 0.05096  loss_rpn_loc: 0.1699  time: 0.5480  data_time: 0.3104  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:34:04 d2.utils.events]: \u001b[0m eta: 0:22:21  iter: 4719  total_loss: 1.475  loss_cls: 0.3271  loss_box_reg: 0.5015  loss_mask: 0.3145  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.2002  time: 0.5485  data_time: 0.4312  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:34:17 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 4739  total_loss: 1.446  loss_cls: 0.3236  loss_box_reg: 0.5186  loss_mask: 0.2956  loss_rpn_cls: 0.09526  loss_rpn_loc: 0.2071  time: 0.5489  data_time: 0.4063  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:34:27 d2.utils.events]: \u001b[0m eta: 0:22:07  iter: 4759  total_loss: 1.313  loss_cls: 0.2768  loss_box_reg: 0.5075  loss_mask: 0.2974  loss_rpn_cls: 0.05685  loss_rpn_loc: 0.203  time: 0.5487  data_time: 0.2805  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:34:38 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 4779  total_loss: 1.422  loss_cls: 0.3565  loss_box_reg: 0.5099  loss_mask: 0.2891  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.1879  time: 0.5487  data_time: 0.3126  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:34:49 d2.utils.events]: \u001b[0m eta: 0:21:54  iter: 4799  total_loss: 1.396  loss_cls: 0.3328  loss_box_reg: 0.5323  loss_mask: 0.2959  loss_rpn_cls: 0.07127  loss_rpn_loc: 0.1907  time: 0.5487  data_time: 0.3147  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:35:00 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 4819  total_loss: 1.371  loss_cls: 0.2858  loss_box_reg: 0.5044  loss_mask: 0.2902  loss_rpn_cls: 0.06214  loss_rpn_loc: 0.1773  time: 0.5487  data_time: 0.3282  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:35:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:35:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:35:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:35:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:35:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:35:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0681 s/iter. Eval: 0.0413 s/iter. Total: 0.1101 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 16:35:17 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0557 s/iter. Total: 0.1269 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0582 s/iter. Total: 0.1295 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:35:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.827549 (0.127824 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:35:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070370 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:35:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:35:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26379808888311757\n",
      "\u001b[32m[02/02 16:35:26 d2.utils.events]: \u001b[0m eta: 0:21:40  iter: 4839  total_loss: 1.468  loss_cls: 0.3363  loss_box_reg: 0.5752  loss_mask: 0.3172  loss_rpn_cls: 0.0571  loss_rpn_loc: 0.19  time: 0.5485  data_time: 0.2638  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:35:38 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 4859  total_loss: 1.341  loss_cls: 0.3017  loss_box_reg: 0.4731  loss_mask: 0.2795  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.2063  time: 0.5486  data_time: 0.3469  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:35:46 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 4879  total_loss: 1.301  loss_cls: 0.332  loss_box_reg: 0.4863  loss_mask: 0.2875  loss_rpn_cls: 0.05913  loss_rpn_loc: 0.1584  time: 0.5481  data_time: 0.2058  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:35:59 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 4899  total_loss: 1.427  loss_cls: 0.3257  loss_box_reg: 0.5111  loss_mask: 0.3095  loss_rpn_cls: 0.08016  loss_rpn_loc: 0.1892  time: 0.5483  data_time: 0.3729  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:36:10 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 4919  total_loss: 1.51  loss_cls: 0.3397  loss_box_reg: 0.537  loss_mask: 0.3028  loss_rpn_cls: 0.07904  loss_rpn_loc: 0.1969  time: 0.5484  data_time: 0.3471  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:36:23 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 4939  total_loss: 1.523  loss_cls: 0.3551  loss_box_reg: 0.5265  loss_mask: 0.2996  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.2188  time: 0.5488  data_time: 0.4063  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:36:36 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 4959  total_loss: 1.379  loss_cls: 0.2908  loss_box_reg: 0.5119  loss_mask: 0.3114  loss_rpn_cls: 0.06824  loss_rpn_loc: 0.2031  time: 0.5492  data_time: 0.4150  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:36:47 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 4979  total_loss: 1.33  loss_cls: 0.2896  loss_box_reg: 0.5204  loss_mask: 0.2921  loss_rpn_cls: 0.06228  loss_rpn_loc: 0.1898  time: 0.5491  data_time: 0.3252  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:36:59 d2.utils.events]: \u001b[0m eta: 0:21:07  iter: 4999  total_loss: 1.449  loss_cls: 0.322  loss_box_reg: 0.5146  loss_mask: 0.2988  loss_rpn_cls: 0.08234  loss_rpn_loc: 0.2074  time: 0.5494  data_time: 0.3906  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:37:10 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 5019  total_loss: 1.433  loss_cls: 0.3104  loss_box_reg: 0.525  loss_mask: 0.2997  loss_rpn_cls: 0.06626  loss_rpn_loc: 0.1816  time: 0.5494  data_time: 0.3161  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:37:22 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 5039  total_loss: 1.446  loss_cls: 0.3145  loss_box_reg: 0.516  loss_mask: 0.2938  loss_rpn_cls: 0.08356  loss_rpn_loc: 0.1992  time: 0.5496  data_time: 0.3555  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:37:33 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 5059  total_loss: 1.36  loss_cls: 0.2872  loss_box_reg: 0.4709  loss_mask: 0.3022  loss_rpn_cls: 0.0687  loss_rpn_loc: 0.1902  time: 0.5497  data_time: 0.3471  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:37:45 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 5079  total_loss: 1.471  loss_cls: 0.3145  loss_box_reg: 0.5153  loss_mask: 0.293  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.1983  time: 0.5499  data_time: 0.3661  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:37:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:37:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:37:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:37:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:37:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:37:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0684 s/iter. Eval: 0.0433 s/iter. Total: 0.1124 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 16:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0582 s/iter. Total: 0.1297 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0620 s/iter. Total: 0.1339 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:38:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.281924 (0.131741 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:38:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070896 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:38:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:38:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25674707856327206\n",
      "\u001b[32m[02/02 16:38:14 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 5099  total_loss: 1.357  loss_cls: 0.2854  loss_box_reg: 0.4753  loss_mask: 0.2958  loss_rpn_cls: 0.07601  loss_rpn_loc: 0.2028  time: 0.5500  data_time: 0.3320  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:38:25 d2.utils.events]: \u001b[0m eta: 0:20:37  iter: 5119  total_loss: 1.445  loss_cls: 0.3081  loss_box_reg: 0.5062  loss_mask: 0.3033  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.194  time: 0.5501  data_time: 0.3656  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:38:37 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 5139  total_loss: 1.395  loss_cls: 0.3257  loss_box_reg: 0.5011  loss_mask: 0.2997  loss_rpn_cls: 0.0674  loss_rpn_loc: 0.1974  time: 0.5503  data_time: 0.3778  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:38:48 d2.utils.events]: \u001b[0m eta: 0:20:22  iter: 5159  total_loss: 1.483  loss_cls: 0.3677  loss_box_reg: 0.5199  loss_mask: 0.2966  loss_rpn_cls: 0.07578  loss_rpn_loc: 0.2019  time: 0.5503  data_time: 0.3166  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:38:58 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 5179  total_loss: 1.342  loss_cls: 0.3106  loss_box_reg: 0.503  loss_mask: 0.2868  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.1713  time: 0.5500  data_time: 0.2641  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:39:09 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 5199  total_loss: 1.435  loss_cls: 0.3574  loss_box_reg: 0.537  loss_mask: 0.3005  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.1863  time: 0.5501  data_time: 0.3468  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:39:22 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 5219  total_loss: 1.48  loss_cls: 0.3157  loss_box_reg: 0.5094  loss_mask: 0.2944  loss_rpn_cls: 0.08605  loss_rpn_loc: 0.1895  time: 0.5504  data_time: 0.3838  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:39:32 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 5239  total_loss: 1.356  loss_cls: 0.2947  loss_box_reg: 0.5345  loss_mask: 0.305  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1899  time: 0.5502  data_time: 0.2826  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:39:43 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 5259  total_loss: 1.301  loss_cls: 0.2559  loss_box_reg: 0.4703  loss_mask: 0.2979  loss_rpn_cls: 0.05488  loss_rpn_loc: 0.1795  time: 0.5502  data_time: 0.3278  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:39:54 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 5279  total_loss: 1.416  loss_cls: 0.3458  loss_box_reg: 0.4798  loss_mask: 0.2954  loss_rpn_cls: 0.0864  loss_rpn_loc: 0.2007  time: 0.5503  data_time: 0.3370  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:40:05 d2.utils.events]: \u001b[0m eta: 0:19:40  iter: 5299  total_loss: 1.375  loss_cls: 0.3178  loss_box_reg: 0.5079  loss_mask: 0.2927  loss_rpn_cls: 0.05062  loss_rpn_loc: 0.196  time: 0.5502  data_time: 0.3010  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:40:16 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 5319  total_loss: 1.396  loss_cls: 0.332  loss_box_reg: 0.5328  loss_mask: 0.2908  loss_rpn_cls: 0.08206  loss_rpn_loc: 0.1863  time: 0.5502  data_time: 0.3294  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:40:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:40:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:40:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:40:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:40:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:40:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0382 s/iter. Total: 0.1066 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0552 s/iter. Total: 0.1262 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:40:30 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0583 s/iter. Total: 0.1298 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:40:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.907771 (0.128515 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:40:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070506 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:40:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:40:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2612067674263852\n",
      "\u001b[32m[02/02 16:40:42 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 5339  total_loss: 1.354  loss_cls: 0.3104  loss_box_reg: 0.5118  loss_mask: 0.2937  loss_rpn_cls: 0.08282  loss_rpn_loc: 0.2023  time: 0.5499  data_time: 0.2431  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:40:53 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 5359  total_loss: 1.339  loss_cls: 0.294  loss_box_reg: 0.4982  loss_mask: 0.3007  loss_rpn_cls: 0.06804  loss_rpn_loc: 0.1874  time: 0.5500  data_time: 0.3322  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:41:04 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 5379  total_loss: 1.412  loss_cls: 0.3062  loss_box_reg: 0.504  loss_mask: 0.3048  loss_rpn_cls: 0.06767  loss_rpn_loc: 0.1821  time: 0.5498  data_time: 0.2816  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:41:16 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 5399  total_loss: 1.376  loss_cls: 0.3051  loss_box_reg: 0.4772  loss_mask: 0.2941  loss_rpn_cls: 0.0899  loss_rpn_loc: 0.2046  time: 0.5502  data_time: 0.4173  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:41:27 d2.utils.events]: \u001b[0m eta: 0:19:03  iter: 5419  total_loss: 1.369  loss_cls: 0.3358  loss_box_reg: 0.5167  loss_mask: 0.2859  loss_rpn_cls: 0.07392  loss_rpn_loc: 0.1899  time: 0.5501  data_time: 0.2951  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:41:42 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 5439  total_loss: 1.42  loss_cls: 0.3323  loss_box_reg: 0.4658  loss_mask: 0.3101  loss_rpn_cls: 0.09473  loss_rpn_loc: 0.208  time: 0.5508  data_time: 0.5179  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:41:55 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 5459  total_loss: 1.408  loss_cls: 0.3179  loss_box_reg: 0.5177  loss_mask: 0.2898  loss_rpn_cls: 0.07776  loss_rpn_loc: 0.2006  time: 0.5513  data_time: 0.4386  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:42:07 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 5479  total_loss: 1.232  loss_cls: 0.2745  loss_box_reg: 0.4744  loss_mask: 0.2967  loss_rpn_cls: 0.06516  loss_rpn_loc: 0.1766  time: 0.5514  data_time: 0.3592  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:42:18 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 5499  total_loss: 1.441  loss_cls: 0.3554  loss_box_reg: 0.5067  loss_mask: 0.2971  loss_rpn_cls: 0.08315  loss_rpn_loc: 0.1942  time: 0.5513  data_time: 0.2872  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:42:25 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 5519  total_loss: 1.408  loss_cls: 0.3346  loss_box_reg: 0.4768  loss_mask: 0.2857  loss_rpn_cls: 0.0727  loss_rpn_loc: 0.1921  time: 0.5507  data_time: 0.1684  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:42:36 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 5539  total_loss: 1.342  loss_cls: 0.2945  loss_box_reg: 0.4875  loss_mask: 0.2954  loss_rpn_cls: 0.09847  loss_rpn_loc: 0.2009  time: 0.5506  data_time: 0.3129  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:42:43 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 5559  total_loss: 1.395  loss_cls: 0.3134  loss_box_reg: 0.536  loss_mask: 0.3042  loss_rpn_cls: 0.05394  loss_rpn_loc: 0.1803  time: 0.5500  data_time: 0.1427  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:42:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:42:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:42:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:42:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:42:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:42:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0413 s/iter. Total: 0.1099 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 16:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0572 s/iter. Total: 0.1285 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:43:02 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0600 s/iter. Total: 0.1316 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:43:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.146000 (0.130569 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:43:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070655 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:43:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:43:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2617377864012573\n",
      "\u001b[32m[02/02 16:43:11 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 5579  total_loss: 1.351  loss_cls: 0.2744  loss_box_reg: 0.497  loss_mask: 0.2994  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.1999  time: 0.5499  data_time: 0.3124  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:43:22 d2.utils.events]: \u001b[0m eta: 0:18:33  iter: 5599  total_loss: 1.391  loss_cls: 0.2967  loss_box_reg: 0.4845  loss_mask: 0.3056  loss_rpn_cls: 0.07196  loss_rpn_loc: 0.1761  time: 0.5500  data_time: 0.3355  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:43:31 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 5619  total_loss: 1.417  loss_cls: 0.298  loss_box_reg: 0.5666  loss_mask: 0.2972  loss_rpn_cls: 0.0557  loss_rpn_loc: 0.1815  time: 0.5496  data_time: 0.2282  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:43:42 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 5639  total_loss: 1.45  loss_cls: 0.37  loss_box_reg: 0.5219  loss_mask: 0.3013  loss_rpn_cls: 0.08898  loss_rpn_loc: 0.1967  time: 0.5496  data_time: 0.3264  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:43:56 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 5659  total_loss: 1.434  loss_cls: 0.3414  loss_box_reg: 0.4776  loss_mask: 0.3037  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.194  time: 0.5502  data_time: 0.4758  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:44:11 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 5679  total_loss: 1.366  loss_cls: 0.3188  loss_box_reg: 0.4655  loss_mask: 0.2972  loss_rpn_cls: 0.08438  loss_rpn_loc: 0.1857  time: 0.5508  data_time: 0.4851  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:44:19 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 5699  total_loss: 1.262  loss_cls: 0.276  loss_box_reg: 0.5002  loss_mask: 0.2695  loss_rpn_cls: 0.0387  loss_rpn_loc: 0.1693  time: 0.5502  data_time: 0.1735  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:44:29 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 5719  total_loss: 1.421  loss_cls: 0.2956  loss_box_reg: 0.5206  loss_mask: 0.3057  loss_rpn_cls: 0.07895  loss_rpn_loc: 0.2106  time: 0.5500  data_time: 0.2564  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:44:42 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 5739  total_loss: 1.4  loss_cls: 0.3234  loss_box_reg: 0.5057  loss_mask: 0.2956  loss_rpn_cls: 0.07727  loss_rpn_loc: 0.1972  time: 0.5504  data_time: 0.4273  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:44:56 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 5759  total_loss: 1.361  loss_cls: 0.2762  loss_box_reg: 0.4931  loss_mask: 0.3016  loss_rpn_cls: 0.0951  loss_rpn_loc: 0.1929  time: 0.5509  data_time: 0.4676  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:45:07 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 5779  total_loss: 1.405  loss_cls: 0.3274  loss_box_reg: 0.5128  loss_mask: 0.2974  loss_rpn_cls: 0.08551  loss_rpn_loc: 0.2009  time: 0.5510  data_time: 0.3515  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:45:17 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 5799  total_loss: 1.347  loss_cls: 0.2776  loss_box_reg: 0.4863  loss_mask: 0.2963  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.1959  time: 0.5508  data_time: 0.2876  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:45:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:45:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:45:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:45:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:45:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:45:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0393 s/iter. Total: 0.1079 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0579 s/iter. Total: 0.1295 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0618 s/iter. Total: 0.1339 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:45:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.279369 (0.131719 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:45:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071007 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:45:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:45:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26875243720874276\n",
      "\u001b[32m[02/02 16:45:44 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 5819  total_loss: 1.366  loss_cls: 0.3026  loss_box_reg: 0.4933  loss_mask: 0.2824  loss_rpn_cls: 0.06583  loss_rpn_loc: 0.1933  time: 0.5507  data_time: 0.2824  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:45:55 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 5839  total_loss: 1.467  loss_cls: 0.2957  loss_box_reg: 0.5034  loss_mask: 0.3035  loss_rpn_cls: 0.0762  loss_rpn_loc: 0.2083  time: 0.5506  data_time: 0.3073  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:46:03 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 5859  total_loss: 1.284  loss_cls: 0.2855  loss_box_reg: 0.5126  loss_mask: 0.2918  loss_rpn_cls: 0.04535  loss_rpn_loc: 0.172  time: 0.5501  data_time: 0.1826  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:46:16 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 5879  total_loss: 1.482  loss_cls: 0.3707  loss_box_reg: 0.499  loss_mask: 0.3124  loss_rpn_cls: 0.08022  loss_rpn_loc: 0.2063  time: 0.5505  data_time: 0.4314  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:46:28 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 5899  total_loss: 1.381  loss_cls: 0.2717  loss_box_reg: 0.4751  loss_mask: 0.3063  loss_rpn_cls: 0.07768  loss_rpn_loc: 0.2022  time: 0.5507  data_time: 0.3874  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:46:42 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 5919  total_loss: 1.359  loss_cls: 0.3191  loss_box_reg: 0.4763  loss_mask: 0.2821  loss_rpn_cls: 0.08449  loss_rpn_loc: 0.1791  time: 0.5511  data_time: 0.4116  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:46:53 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 5939  total_loss: 1.39  loss_cls: 0.2996  loss_box_reg: 0.4662  loss_mask: 0.294  loss_rpn_cls: 0.06767  loss_rpn_loc: 0.2025  time: 0.5512  data_time: 0.3584  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:47:02 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 5959  total_loss: 1.417  loss_cls: 0.3392  loss_box_reg: 0.5015  loss_mask: 0.282  loss_rpn_cls: 0.05185  loss_rpn_loc: 0.204  time: 0.5509  data_time: 0.2341  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:47:15 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 5979  total_loss: 1.485  loss_cls: 0.3048  loss_box_reg: 0.5395  loss_mask: 0.2979  loss_rpn_cls: 0.08658  loss_rpn_loc: 0.2032  time: 0.5511  data_time: 0.4054  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:47:27 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 5999  total_loss: 1.426  loss_cls: 0.3263  loss_box_reg: 0.5089  loss_mask: 0.3005  loss_rpn_cls: 0.07264  loss_rpn_loc: 0.1807  time: 0.5513  data_time: 0.3644  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:47:37 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 6019  total_loss: 1.409  loss_cls: 0.3159  loss_box_reg: 0.5327  loss_mask: 0.293  loss_rpn_cls: 0.07895  loss_rpn_loc: 0.182  time: 0.5512  data_time: 0.3086  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:47:48 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 6039  total_loss: 1.312  loss_cls: 0.2829  loss_box_reg: 0.4972  loss_mask: 0.2914  loss_rpn_cls: 0.06607  loss_rpn_loc: 0.1796  time: 0.5511  data_time: 0.2981  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:47:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:47:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:47:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:47:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:47:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:47:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0675 s/iter. Eval: 0.0367 s/iter. Total: 0.1048 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 54/121. Dataloading: 0.0007 s/iter. Inference: 0.0690 s/iter. Eval: 0.0459 s/iter. Total: 0.1156 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/02 16:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0007 s/iter. Inference: 0.0691 s/iter. Eval: 0.0470 s/iter. Total: 0.1168 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/02 16:48:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.510467 (0.116470 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:48:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.068979 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:48:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:48:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24647771421509557\n",
      "\u001b[32m[02/02 16:48:15 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 6059  total_loss: 1.42  loss_cls: 0.3284  loss_box_reg: 0.5047  loss_mask: 0.2932  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.1958  time: 0.5514  data_time: 0.3981  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:48:24 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 6079  total_loss: 1.427  loss_cls: 0.3052  loss_box_reg: 0.513  loss_mask: 0.2941  loss_rpn_cls: 0.09121  loss_rpn_loc: 0.1806  time: 0.5510  data_time: 0.2001  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:48:39 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 6099  total_loss: 1.376  loss_cls: 0.3036  loss_box_reg: 0.5023  loss_mask: 0.2886  loss_rpn_cls: 0.08525  loss_rpn_loc: 0.2009  time: 0.5516  data_time: 0.5082  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:48:48 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 6119  total_loss: 1.397  loss_cls: 0.3131  loss_box_reg: 0.4996  loss_mask: 0.3068  loss_rpn_cls: 0.08439  loss_rpn_loc: 0.1891  time: 0.5513  data_time: 0.2519  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:49:00 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 6139  total_loss: 1.408  loss_cls: 0.3367  loss_box_reg: 0.5196  loss_mask: 0.2876  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.2025  time: 0.5514  data_time: 0.3363  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:49:12 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 6159  total_loss: 1.381  loss_cls: 0.2913  loss_box_reg: 0.4893  loss_mask: 0.3082  loss_rpn_cls: 0.09975  loss_rpn_loc: 0.2019  time: 0.5516  data_time: 0.3941  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:49:25 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 6179  total_loss: 1.318  loss_cls: 0.3009  loss_box_reg: 0.5268  loss_mask: 0.2907  loss_rpn_cls: 0.09404  loss_rpn_loc: 0.195  time: 0.5519  data_time: 0.4157  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:49:35 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 6199  total_loss: 1.327  loss_cls: 0.2852  loss_box_reg: 0.4749  loss_mask: 0.2862  loss_rpn_cls: 0.05487  loss_rpn_loc: 0.1768  time: 0.5517  data_time: 0.2863  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:49:46 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 6219  total_loss: 1.417  loss_cls: 0.3322  loss_box_reg: 0.497  loss_mask: 0.293  loss_rpn_cls: 0.08005  loss_rpn_loc: 0.1886  time: 0.5517  data_time: 0.3219  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:49:57 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 6239  total_loss: 1.462  loss_cls: 0.332  loss_box_reg: 0.5203  loss_mask: 0.3148  loss_rpn_cls: 0.08698  loss_rpn_loc: 0.1926  time: 0.5517  data_time: 0.3253  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:50:06 d2.utils.events]: \u001b[0m eta: 0:15:56  iter: 6259  total_loss: 1.319  loss_cls: 0.2922  loss_box_reg: 0.5227  loss_mask: 0.2924  loss_rpn_cls: 0.056  loss_rpn_loc: 0.1748  time: 0.5514  data_time: 0.2195  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:50:13 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 6279  total_loss: 1.346  loss_cls: 0.3181  loss_box_reg: 0.5022  loss_mask: 0.2775  loss_rpn_cls: 0.06001  loss_rpn_loc: 0.1744  time: 0.5507  data_time: 0.1152  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:50:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:50:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:50:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:50:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:50:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:50:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0694 s/iter. Eval: 0.0472 s/iter. Total: 0.1172 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 16:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0614 s/iter. Total: 0.1333 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0714 s/iter. Eval: 0.0639 s/iter. Total: 0.1361 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:50:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.511523 (0.133720 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:50:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071045 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:50:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:50:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2670982154051784\n",
      "\u001b[32m[02/02 16:50:41 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 6299  total_loss: 1.27  loss_cls: 0.2891  loss_box_reg: 0.4773  loss_mask: 0.2951  loss_rpn_cls: 0.06572  loss_rpn_loc: 0.1864  time: 0.5508  data_time: 0.3475  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:50:55 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 6319  total_loss: 1.377  loss_cls: 0.2789  loss_box_reg: 0.4962  loss_mask: 0.2988  loss_rpn_cls: 0.06418  loss_rpn_loc: 0.1883  time: 0.5512  data_time: 0.4563  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:51:07 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 6339  total_loss: 1.392  loss_cls: 0.32  loss_box_reg: 0.4906  loss_mask: 0.2952  loss_rpn_cls: 0.0795  loss_rpn_loc: 0.2007  time: 0.5514  data_time: 0.3696  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:51:17 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 6359  total_loss: 1.403  loss_cls: 0.3199  loss_box_reg: 0.4924  loss_mask: 0.2962  loss_rpn_cls: 0.06328  loss_rpn_loc: 0.1762  time: 0.5513  data_time: 0.2986  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:51:27 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 6379  total_loss: 1.39  loss_cls: 0.3138  loss_box_reg: 0.4922  loss_mask: 0.299  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.184  time: 0.5510  data_time: 0.2441  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:51:35 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 6399  total_loss: 1.226  loss_cls: 0.2829  loss_box_reg: 0.4588  loss_mask: 0.265  loss_rpn_cls: 0.06859  loss_rpn_loc: 0.1747  time: 0.5506  data_time: 0.2141  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:51:46 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 6419  total_loss: 1.408  loss_cls: 0.2877  loss_box_reg: 0.4997  loss_mask: 0.2834  loss_rpn_cls: 0.07407  loss_rpn_loc: 0.1901  time: 0.5505  data_time: 0.3062  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:52:01 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 6439  total_loss: 1.416  loss_cls: 0.3293  loss_box_reg: 0.5308  loss_mask: 0.3034  loss_rpn_cls: 0.08333  loss_rpn_loc: 0.1941  time: 0.5511  data_time: 0.4967  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:52:11 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 6459  total_loss: 1.436  loss_cls: 0.3361  loss_box_reg: 0.5233  loss_mask: 0.2804  loss_rpn_cls: 0.06516  loss_rpn_loc: 0.1912  time: 0.5510  data_time: 0.2956  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:52:23 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 6479  total_loss: 1.409  loss_cls: 0.3053  loss_box_reg: 0.4858  loss_mask: 0.2903  loss_rpn_cls: 0.06064  loss_rpn_loc: 0.1997  time: 0.5511  data_time: 0.3526  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:52:36 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 6499  total_loss: 1.378  loss_cls: 0.3187  loss_box_reg: 0.5065  loss_mask: 0.31  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.1971  time: 0.5514  data_time: 0.4087  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:52:48 d2.utils.events]: \u001b[0m eta: 0:14:45  iter: 6519  total_loss: 1.475  loss_cls: 0.3207  loss_box_reg: 0.5174  loss_mask: 0.3139  loss_rpn_cls: 0.06411  loss_rpn_loc: 0.1967  time: 0.5516  data_time: 0.3634  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:52:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:52:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:52:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:52:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:52:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:52:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:52:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0672 s/iter. Eval: 0.0342 s/iter. Total: 0.1020 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:53:01 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0539 s/iter. Total: 0.1248 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 16:53:06 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0586 s/iter. Total: 0.1302 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:53:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.981630 (0.129152 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:53:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070664 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:53:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:53:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2644088160579417\n",
      "\u001b[32m[02/02 16:53:15 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 6539  total_loss: 1.399  loss_cls: 0.3262  loss_box_reg: 0.4999  loss_mask: 0.2957  loss_rpn_cls: 0.07057  loss_rpn_loc: 0.1897  time: 0.5515  data_time: 0.2943  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:53:30 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 6559  total_loss: 1.465  loss_cls: 0.3405  loss_box_reg: 0.5171  loss_mask: 0.3035  loss_rpn_cls: 0.09223  loss_rpn_loc: 0.2073  time: 0.5521  data_time: 0.5161  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:53:43 d2.utils.events]: \u001b[0m eta: 0:14:34  iter: 6579  total_loss: 1.366  loss_cls: 0.3293  loss_box_reg: 0.5108  loss_mask: 0.3054  loss_rpn_cls: 0.07098  loss_rpn_loc: 0.1865  time: 0.5523  data_time: 0.3829  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:53:55 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 6599  total_loss: 1.433  loss_cls: 0.3304  loss_box_reg: 0.5106  loss_mask: 0.3083  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.2014  time: 0.5525  data_time: 0.3735  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:54:06 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 6619  total_loss: 1.385  loss_cls: 0.3224  loss_box_reg: 0.4753  loss_mask: 0.2995  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.2014  time: 0.5525  data_time: 0.3244  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:54:16 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 6639  total_loss: 1.31  loss_cls: 0.2929  loss_box_reg: 0.4822  loss_mask: 0.2808  loss_rpn_cls: 0.06688  loss_rpn_loc: 0.1843  time: 0.5524  data_time: 0.2999  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:54:25 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 6659  total_loss: 1.349  loss_cls: 0.2931  loss_box_reg: 0.4938  loss_mask: 0.2925  loss_rpn_cls: 0.06729  loss_rpn_loc: 0.1805  time: 0.5521  data_time: 0.2222  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:54:35 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 6679  total_loss: 1.39  loss_cls: 0.3147  loss_box_reg: 0.5017  loss_mask: 0.2833  loss_rpn_cls: 0.07106  loss_rpn_loc: 0.2045  time: 0.5519  data_time: 0.2755  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:54:46 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 6699  total_loss: 1.47  loss_cls: 0.357  loss_box_reg: 0.5518  loss_mask: 0.3187  loss_rpn_cls: 0.08748  loss_rpn_loc: 0.2143  time: 0.5520  data_time: 0.3261  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:54:56 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 6719  total_loss: 1.435  loss_cls: 0.3207  loss_box_reg: 0.5111  loss_mask: 0.3164  loss_rpn_cls: 0.07995  loss_rpn_loc: 0.1924  time: 0.5518  data_time: 0.2830  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:55:09 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 6739  total_loss: 1.382  loss_cls: 0.3031  loss_box_reg: 0.493  loss_mask: 0.3009  loss_rpn_cls: 0.104  loss_rpn_loc: 0.2054  time: 0.5521  data_time: 0.4030  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:55:20 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 6759  total_loss: 1.318  loss_cls: 0.3  loss_box_reg: 0.4801  loss_mask: 0.2802  loss_rpn_cls: 0.06197  loss_rpn_loc: 0.178  time: 0.5520  data_time: 0.3009  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:55:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:55:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:55:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:55:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:55:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:55:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:55:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0415 s/iter. Total: 0.1102 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 16:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0709 s/iter. Eval: 0.0599 s/iter. Total: 0.1317 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0714 s/iter. Eval: 0.0630 s/iter. Total: 0.1352 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 16:55:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.546390 (0.134021 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:55:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071207 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:55:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:55:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26806981929545326\n",
      "\u001b[32m[02/02 16:55:46 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 6779  total_loss: 1.3  loss_cls: 0.2832  loss_box_reg: 0.5074  loss_mask: 0.2985  loss_rpn_cls: 0.04104  loss_rpn_loc: 0.1659  time: 0.5518  data_time: 0.2561  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:55:56 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 6799  total_loss: 1.293  loss_cls: 0.3204  loss_box_reg: 0.4836  loss_mask: 0.2922  loss_rpn_cls: 0.06266  loss_rpn_loc: 0.1705  time: 0.5516  data_time: 0.2821  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:56:06 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 6819  total_loss: 1.288  loss_cls: 0.3041  loss_box_reg: 0.4785  loss_mask: 0.2883  loss_rpn_cls: 0.05285  loss_rpn_loc: 0.1686  time: 0.5513  data_time: 0.2235  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:56:16 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 6839  total_loss: 1.501  loss_cls: 0.3532  loss_box_reg: 0.5181  loss_mask: 0.2914  loss_rpn_cls: 0.06387  loss_rpn_loc: 0.1867  time: 0.5513  data_time: 0.2979  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:56:29 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 6859  total_loss: 1.313  loss_cls: 0.316  loss_box_reg: 0.4786  loss_mask: 0.282  loss_rpn_cls: 0.07663  loss_rpn_loc: 0.1949  time: 0.5515  data_time: 0.4053  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:56:42 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 6879  total_loss: 1.394  loss_cls: 0.2887  loss_box_reg: 0.4829  loss_mask: 0.3023  loss_rpn_cls: 0.0841  loss_rpn_loc: 0.1951  time: 0.5519  data_time: 0.4464  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:56:52 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 6899  total_loss: 1.363  loss_cls: 0.3199  loss_box_reg: 0.5184  loss_mask: 0.3033  loss_rpn_cls: 0.0589  loss_rpn_loc: 0.1852  time: 0.5517  data_time: 0.2495  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:57:04 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 6919  total_loss: 1.389  loss_cls: 0.3236  loss_box_reg: 0.5005  loss_mask: 0.2887  loss_rpn_cls: 0.09104  loss_rpn_loc: 0.1968  time: 0.5518  data_time: 0.3738  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:57:15 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 6939  total_loss: 1.452  loss_cls: 0.3426  loss_box_reg: 0.5129  loss_mask: 0.2998  loss_rpn_cls: 0.08155  loss_rpn_loc: 0.1993  time: 0.5519  data_time: 0.3204  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:57:23 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 6959  total_loss: 1.394  loss_cls: 0.334  loss_box_reg: 0.4849  loss_mask: 0.2883  loss_rpn_cls: 0.06325  loss_rpn_loc: 0.1831  time: 0.5514  data_time: 0.1834  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:57:34 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 6979  total_loss: 1.385  loss_cls: 0.3133  loss_box_reg: 0.4779  loss_mask: 0.2683  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.1919  time: 0.5514  data_time: 0.3233  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:57:46 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 6999  total_loss: 1.383  loss_cls: 0.2941  loss_box_reg: 0.49  loss_mask: 0.2851  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.1845  time: 0.5515  data_time: 0.3340  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:57:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:57:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 16:57:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 16:57:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 16:57:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 16:57:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 16:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0369 s/iter. Total: 0.1053 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 16:58:02 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0568 s/iter. Total: 0.1283 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 16:58:07 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0618 s/iter. Total: 0.1339 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 16:58:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.263924 (0.131586 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:58:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070976 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 16:58:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 16:58:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2712248214270222\n",
      "\u001b[32m[02/02 16:58:12 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 7019  total_loss: 1.379  loss_cls: 0.3014  loss_box_reg: 0.5064  loss_mask: 0.295  loss_rpn_cls: 0.05582  loss_rpn_loc: 0.1898  time: 0.5513  data_time: 0.2569  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:58:22 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 7039  total_loss: 1.42  loss_cls: 0.3285  loss_box_reg: 0.4952  loss_mask: 0.3044  loss_rpn_cls: 0.07645  loss_rpn_loc: 0.1923  time: 0.5511  data_time: 0.2402  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:58:29 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 7059  total_loss: 1.271  loss_cls: 0.2682  loss_box_reg: 0.5089  loss_mask: 0.2947  loss_rpn_cls: 0.04853  loss_rpn_loc: 0.1869  time: 0.5505  data_time: 0.1351  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:58:37 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 7079  total_loss: 1.421  loss_cls: 0.3158  loss_box_reg: 0.5191  loss_mask: 0.299  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.1924  time: 0.5501  data_time: 0.1806  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:58:50 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 7099  total_loss: 1.256  loss_cls: 0.2892  loss_box_reg: 0.4706  loss_mask: 0.2782  loss_rpn_cls: 0.04951  loss_rpn_loc: 0.1714  time: 0.5503  data_time: 0.4026  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:59:01 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 7119  total_loss: 1.366  loss_cls: 0.2953  loss_box_reg: 0.5062  loss_mask: 0.2937  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.1721  time: 0.5503  data_time: 0.3306  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:59:15 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 7139  total_loss: 1.549  loss_cls: 0.3573  loss_box_reg: 0.4933  loss_mask: 0.3026  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.2119  time: 0.5507  data_time: 0.4437  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:59:25 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 7159  total_loss: 1.496  loss_cls: 0.3436  loss_box_reg: 0.5268  loss_mask: 0.3178  loss_rpn_cls: 0.09138  loss_rpn_loc: 0.1989  time: 0.5506  data_time: 0.3011  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:59:37 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 7179  total_loss: 1.34  loss_cls: 0.3467  loss_box_reg: 0.4937  loss_mask: 0.2903  loss_rpn_cls: 0.08866  loss_rpn_loc: 0.179  time: 0.5507  data_time: 0.3490  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 16:59:48 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 7199  total_loss: 1.383  loss_cls: 0.3185  loss_box_reg: 0.4878  loss_mask: 0.3042  loss_rpn_cls: 0.07925  loss_rpn_loc: 0.1923  time: 0.5508  data_time: 0.3464  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:00:02 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 7219  total_loss: 1.449  loss_cls: 0.3261  loss_box_reg: 0.4787  loss_mask: 0.2956  loss_rpn_cls: 0.07582  loss_rpn_loc: 0.2124  time: 0.5511  data_time: 0.4265  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:00:13 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 7239  total_loss: 1.337  loss_cls: 0.2742  loss_box_reg: 0.4681  loss_mask: 0.2894  loss_rpn_cls: 0.08754  loss_rpn_loc: 0.198  time: 0.5512  data_time: 0.3685  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:00:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:00:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:00:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:00:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:00:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:00:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0687 s/iter. Eval: 0.0348 s/iter. Total: 0.1042 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 17:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0520 s/iter. Total: 0.1228 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 17:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0544 s/iter. Total: 0.1255 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 17:00:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.288514 (0.123177 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:00:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069951 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:00:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:00:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.262702390856663\n",
      "\u001b[32m[02/02 17:00:40 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 7259  total_loss: 1.32  loss_cls: 0.2879  loss_box_reg: 0.4858  loss_mask: 0.2979  loss_rpn_cls: 0.05393  loss_rpn_loc: 0.1822  time: 0.5511  data_time: 0.2932  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:00:48 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 7279  total_loss: 1.318  loss_cls: 0.3273  loss_box_reg: 0.4959  loss_mask: 0.2809  loss_rpn_cls: 0.06691  loss_rpn_loc: 0.1708  time: 0.5508  data_time: 0.2031  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:01:02 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 7299  total_loss: 1.288  loss_cls: 0.2851  loss_box_reg: 0.4841  loss_mask: 0.2825  loss_rpn_cls: 0.08414  loss_rpn_loc: 0.1803  time: 0.5512  data_time: 0.4814  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:01:13 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 7319  total_loss: 1.391  loss_cls: 0.2836  loss_box_reg: 0.4861  loss_mask: 0.2939  loss_rpn_cls: 0.05877  loss_rpn_loc: 0.1995  time: 0.5512  data_time: 0.3114  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:01:23 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 7339  total_loss: 1.256  loss_cls: 0.2836  loss_box_reg: 0.4813  loss_mask: 0.2922  loss_rpn_cls: 0.05249  loss_rpn_loc: 0.1818  time: 0.5510  data_time: 0.2525  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:01:33 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 7359  total_loss: 1.475  loss_cls: 0.3228  loss_box_reg: 0.528  loss_mask: 0.3139  loss_rpn_cls: 0.07589  loss_rpn_loc: 0.1983  time: 0.5509  data_time: 0.2773  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:01:42 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 7379  total_loss: 1.332  loss_cls: 0.2657  loss_box_reg: 0.5044  loss_mask: 0.2904  loss_rpn_cls: 0.07631  loss_rpn_loc: 0.1997  time: 0.5506  data_time: 0.2445  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:01:52 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 7399  total_loss: 1.335  loss_cls: 0.3064  loss_box_reg: 0.4852  loss_mask: 0.302  loss_rpn_cls: 0.06719  loss_rpn_loc: 0.1606  time: 0.5505  data_time: 0.2896  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:02:03 d2.utils.events]: \u001b[0m eta: 0:11:09  iter: 7419  total_loss: 1.432  loss_cls: 0.3182  loss_box_reg: 0.4994  loss_mask: 0.3  loss_rpn_cls: 0.0739  loss_rpn_loc: 0.1863  time: 0.5504  data_time: 0.2934  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:02:14 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 7439  total_loss: 1.342  loss_cls: 0.2945  loss_box_reg: 0.4904  loss_mask: 0.2964  loss_rpn_cls: 0.0812  loss_rpn_loc: 0.2004  time: 0.5505  data_time: 0.3572  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:02:26 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 7459  total_loss: 1.372  loss_cls: 0.3039  loss_box_reg: 0.4814  loss_mask: 0.2916  loss_rpn_cls: 0.07714  loss_rpn_loc: 0.2062  time: 0.5507  data_time: 0.3678  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:02:40 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 7479  total_loss: 1.393  loss_cls: 0.3125  loss_box_reg: 0.5264  loss_mask: 0.3006  loss_rpn_cls: 0.08501  loss_rpn_loc: 0.1856  time: 0.5510  data_time: 0.4262  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:02:54 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 7499  total_loss: 1.478  loss_cls: 0.3223  loss_box_reg: 0.5388  loss_mask: 0.3207  loss_rpn_cls: 0.07524  loss_rpn_loc: 0.1964  time: 0.5514  data_time: 0.4670  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:02:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:02:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:02:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:02:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:02:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:02:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0030 s/iter. Inference: 0.0687 s/iter. Eval: 0.0471 s/iter. Total: 0.1188 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 17:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0010 s/iter. Inference: 0.0707 s/iter. Eval: 0.0573 s/iter. Total: 0.1291 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0009 s/iter. Inference: 0.0711 s/iter. Eval: 0.0617 s/iter. Total: 0.1338 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:03:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.313214 (0.132010 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:03:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070902 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:03:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:03:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2672541263914308\n",
      "\u001b[32m[02/02 17:03:22 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 7519  total_loss: 1.423  loss_cls: 0.338  loss_box_reg: 0.478  loss_mask: 0.2893  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.1948  time: 0.5514  data_time: 0.3203  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:03:33 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 7539  total_loss: 1.262  loss_cls: 0.2494  loss_box_reg: 0.4647  loss_mask: 0.2879  loss_rpn_cls: 0.05899  loss_rpn_loc: 0.1926  time: 0.5515  data_time: 0.3687  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:03:44 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 7559  total_loss: 1.364  loss_cls: 0.2873  loss_box_reg: 0.4979  loss_mask: 0.2978  loss_rpn_cls: 0.05875  loss_rpn_loc: 0.1819  time: 0.5514  data_time: 0.3185  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:03:54 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 7579  total_loss: 1.398  loss_cls: 0.3287  loss_box_reg: 0.5203  loss_mask: 0.2875  loss_rpn_cls: 0.0747  loss_rpn_loc: 0.1925  time: 0.5513  data_time: 0.2877  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:04:03 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 7599  total_loss: 1.382  loss_cls: 0.3068  loss_box_reg: 0.4899  loss_mask: 0.2922  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.1818  time: 0.5510  data_time: 0.2188  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:04:11 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 7619  total_loss: 1.333  loss_cls: 0.3051  loss_box_reg: 0.5149  loss_mask: 0.2846  loss_rpn_cls: 0.06358  loss_rpn_loc: 0.1786  time: 0.5507  data_time: 0.1900  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:04:24 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 7639  total_loss: 1.404  loss_cls: 0.31  loss_box_reg: 0.4577  loss_mask: 0.2997  loss_rpn_cls: 0.09977  loss_rpn_loc: 0.2052  time: 0.5509  data_time: 0.4063  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:04:33 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 7659  total_loss: 1.332  loss_cls: 0.3176  loss_box_reg: 0.5166  loss_mask: 0.2843  loss_rpn_cls: 0.05647  loss_rpn_loc: 0.1584  time: 0.5506  data_time: 0.2183  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:04:48 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 7679  total_loss: 1.356  loss_cls: 0.2776  loss_box_reg: 0.5041  loss_mask: 0.2835  loss_rpn_cls: 0.08939  loss_rpn_loc: 0.2031  time: 0.5511  data_time: 0.5019  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:05:03 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 7699  total_loss: 1.264  loss_cls: 0.2603  loss_box_reg: 0.4857  loss_mask: 0.2811  loss_rpn_cls: 0.07793  loss_rpn_loc: 0.1735  time: 0.5516  data_time: 0.5047  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:05:16 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 7719  total_loss: 1.396  loss_cls: 0.3188  loss_box_reg: 0.4776  loss_mask: 0.2939  loss_rpn_cls: 0.05692  loss_rpn_loc: 0.195  time: 0.5518  data_time: 0.4158  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:05:25 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 7739  total_loss: 1.425  loss_cls: 0.2992  loss_box_reg: 0.5094  loss_mask: 0.3243  loss_rpn_cls: 0.08711  loss_rpn_loc: 0.195  time: 0.5516  data_time: 0.2295  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:05:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:05:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:05:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:05:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:05:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:05:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0692 s/iter. Eval: 0.0417 s/iter. Total: 0.1117 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 17:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0706 s/iter. Eval: 0.0564 s/iter. Total: 0.1279 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0711 s/iter. Eval: 0.0609 s/iter. Total: 0.1329 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:05:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.239917 (0.131379 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:05:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070896 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:05:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:05:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.268739131213956\n",
      "\u001b[32m[02/02 17:05:53 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 7759  total_loss: 1.451  loss_cls: 0.3487  loss_box_reg: 0.492  loss_mask: 0.306  loss_rpn_cls: 0.09103  loss_rpn_loc: 0.2101  time: 0.5517  data_time: 0.3394  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:06:01 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 7779  total_loss: 1.276  loss_cls: 0.2691  loss_box_reg: 0.5135  loss_mask: 0.2794  loss_rpn_cls: 0.05489  loss_rpn_loc: 0.1642  time: 0.5513  data_time: 0.1787  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:06:12 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 7799  total_loss: 1.436  loss_cls: 0.3419  loss_box_reg: 0.5309  loss_mask: 0.284  loss_rpn_cls: 0.07108  loss_rpn_loc: 0.1857  time: 0.5513  data_time: 0.3268  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:06:25 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 7819  total_loss: 1.294  loss_cls: 0.2956  loss_box_reg: 0.4712  loss_mask: 0.2967  loss_rpn_cls: 0.08184  loss_rpn_loc: 0.1887  time: 0.5514  data_time: 0.3963  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:06:32 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 7839  total_loss: 1.396  loss_cls: 0.3046  loss_box_reg: 0.5171  loss_mask: 0.3106  loss_rpn_cls: 0.04807  loss_rpn_loc: 0.1993  time: 0.5510  data_time: 0.1509  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:06:43 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 7859  total_loss: 1.295  loss_cls: 0.3022  loss_box_reg: 0.4881  loss_mask: 0.2967  loss_rpn_cls: 0.0647  loss_rpn_loc: 0.1868  time: 0.5509  data_time: 0.3027  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:06:57 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 7879  total_loss: 1.374  loss_cls: 0.3124  loss_box_reg: 0.4886  loss_mask: 0.2877  loss_rpn_cls: 0.08282  loss_rpn_loc: 0.1917  time: 0.5514  data_time: 0.4761  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:07:06 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 7899  total_loss: 1.369  loss_cls: 0.2926  loss_box_reg: 0.5066  loss_mask: 0.2982  loss_rpn_cls: 0.04751  loss_rpn_loc: 0.1662  time: 0.5511  data_time: 0.2078  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:07:17 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 7919  total_loss: 1.409  loss_cls: 0.3065  loss_box_reg: 0.5111  loss_mask: 0.3022  loss_rpn_cls: 0.08144  loss_rpn_loc: 0.1984  time: 0.5510  data_time: 0.3167  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:07:27 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 7939  total_loss: 1.365  loss_cls: 0.3092  loss_box_reg: 0.4896  loss_mask: 0.308  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.1889  time: 0.5510  data_time: 0.3063  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:07:42 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 7959  total_loss: 1.389  loss_cls: 0.3049  loss_box_reg: 0.4605  loss_mask: 0.3018  loss_rpn_cls: 0.08716  loss_rpn_loc: 0.1849  time: 0.5514  data_time: 0.4782  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:07:52 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 7979  total_loss: 1.341  loss_cls: 0.305  loss_box_reg: 0.4905  loss_mask: 0.2948  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.2002  time: 0.5513  data_time: 0.2848  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:07:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:07:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:07:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:07:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:07:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:07:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0704 s/iter. Eval: 0.0439 s/iter. Total: 0.1152 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 17:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0548 s/iter. Total: 0.1261 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 17:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0575 s/iter. Total: 0.1290 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:08:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.840873 (0.127939 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:08:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070523 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:08:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:08:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2683640079272453\n",
      "\u001b[32m[02/02 17:08:17 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 7999  total_loss: 1.412  loss_cls: 0.2979  loss_box_reg: 0.5395  loss_mask: 0.2861  loss_rpn_cls: 0.07402  loss_rpn_loc: 0.1859  time: 0.5511  data_time: 0.2311  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:08:35 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 8019  total_loss: 1.388  loss_cls: 0.3026  loss_box_reg: 0.4702  loss_mask: 0.2991  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.1991  time: 0.5519  data_time: 0.6226  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:08:48 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 8039  total_loss: 1.492  loss_cls: 0.2873  loss_box_reg: 0.505  loss_mask: 0.3064  loss_rpn_cls: 0.07298  loss_rpn_loc: 0.2089  time: 0.5521  data_time: 0.3868  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:08:57 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 8059  total_loss: 1.35  loss_cls: 0.3006  loss_box_reg: 0.5099  loss_mask: 0.2952  loss_rpn_cls: 0.04967  loss_rpn_loc: 0.1811  time: 0.5518  data_time: 0.2309  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:09:07 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 8079  total_loss: 1.336  loss_cls: 0.2706  loss_box_reg: 0.4617  loss_mask: 0.2906  loss_rpn_cls: 0.08224  loss_rpn_loc: 0.1981  time: 0.5518  data_time: 0.3066  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:09:25 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 8099  total_loss: 1.392  loss_cls: 0.3302  loss_box_reg: 0.5005  loss_mask: 0.2935  loss_rpn_cls: 0.09636  loss_rpn_loc: 0.206  time: 0.5525  data_time: 0.6165  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:09:35 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 8119  total_loss: 1.45  loss_cls: 0.3391  loss_box_reg: 0.5124  loss_mask: 0.2868  loss_rpn_cls: 0.07645  loss_rpn_loc: 0.1885  time: 0.5524  data_time: 0.2816  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:09:43 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 8139  total_loss: 1.314  loss_cls: 0.3045  loss_box_reg: 0.4681  loss_mask: 0.2908  loss_rpn_cls: 0.05306  loss_rpn_loc: 0.1749  time: 0.5521  data_time: 0.1698  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:09:50 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 8159  total_loss: 1.276  loss_cls: 0.2719  loss_box_reg: 0.5342  loss_mask: 0.2882  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.1684  time: 0.5516  data_time: 0.1429  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:10:05 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 8179  total_loss: 1.401  loss_cls: 0.3187  loss_box_reg: 0.4611  loss_mask: 0.2912  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1996  time: 0.5521  data_time: 0.5152  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:10:13 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 8199  total_loss: 1.318  loss_cls: 0.2866  loss_box_reg: 0.5283  loss_mask: 0.2903  loss_rpn_cls: 0.05689  loss_rpn_loc: 0.1728  time: 0.5517  data_time: 0.1891  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:10:21 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 8219  total_loss: 1.258  loss_cls: 0.2829  loss_box_reg: 0.4697  loss_mask: 0.2836  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.1717  time: 0.5513  data_time: 0.1502  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:10:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:10:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:10:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:10:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:10:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:10:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:10:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0687 s/iter. Eval: 0.0463 s/iter. Total: 0.1158 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 17:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0706 s/iter. Eval: 0.0582 s/iter. Total: 0.1296 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0711 s/iter. Eval: 0.0626 s/iter. Total: 0.1345 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:10:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.307238 (0.131959 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:10:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070769 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:10:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:10:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26844819125531777\n",
      "\u001b[32m[02/02 17:10:48 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 8239  total_loss: 1.315  loss_cls: 0.3087  loss_box_reg: 0.5111  loss_mask: 0.2912  loss_rpn_cls: 0.07842  loss_rpn_loc: 0.1839  time: 0.5512  data_time: 0.2943  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:10:59 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 8259  total_loss: 1.365  loss_cls: 0.3124  loss_box_reg: 0.4881  loss_mask: 0.2948  loss_rpn_cls: 0.06874  loss_rpn_loc: 0.1898  time: 0.5512  data_time: 0.3111  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:11:09 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 8279  total_loss: 1.278  loss_cls: 0.2772  loss_box_reg: 0.4744  loss_mask: 0.2861  loss_rpn_cls: 0.07103  loss_rpn_loc: 0.184  time: 0.5511  data_time: 0.2897  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:11:20 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 8299  total_loss: 1.348  loss_cls: 0.2865  loss_box_reg: 0.5277  loss_mask: 0.3086  loss_rpn_cls: 0.05984  loss_rpn_loc: 0.1842  time: 0.5511  data_time: 0.3169  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:11:29 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 8319  total_loss: 1.344  loss_cls: 0.311  loss_box_reg: 0.4986  loss_mask: 0.3018  loss_rpn_cls: 0.05557  loss_rpn_loc: 0.1916  time: 0.5508  data_time: 0.2347  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:11:40 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 8339  total_loss: 1.366  loss_cls: 0.3007  loss_box_reg: 0.4749  loss_mask: 0.3016  loss_rpn_cls: 0.06863  loss_rpn_loc: 0.184  time: 0.5508  data_time: 0.3071  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:11:50 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 8359  total_loss: 1.399  loss_cls: 0.3132  loss_box_reg: 0.4839  loss_mask: 0.3147  loss_rpn_cls: 0.07182  loss_rpn_loc: 0.2079  time: 0.5507  data_time: 0.2976  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:12:03 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 8379  total_loss: 1.42  loss_cls: 0.3284  loss_box_reg: 0.466  loss_mask: 0.2889  loss_rpn_cls: 0.08634  loss_rpn_loc: 0.2064  time: 0.5510  data_time: 0.4066  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:12:12 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 8399  total_loss: 1.284  loss_cls: 0.2742  loss_box_reg: 0.5013  loss_mask: 0.2857  loss_rpn_cls: 0.06077  loss_rpn_loc: 0.1774  time: 0.5507  data_time: 0.2103  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:12:26 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 8419  total_loss: 1.357  loss_cls: 0.302  loss_box_reg: 0.4608  loss_mask: 0.3018  loss_rpn_cls: 0.0836  loss_rpn_loc: 0.1965  time: 0.5511  data_time: 0.4744  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:12:36 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 8439  total_loss: 1.314  loss_cls: 0.2834  loss_box_reg: 0.4557  loss_mask: 0.2915  loss_rpn_cls: 0.06923  loss_rpn_loc: 0.1922  time: 0.5510  data_time: 0.2844  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:12:48 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 8459  total_loss: 1.355  loss_cls: 0.2739  loss_box_reg: 0.4872  loss_mask: 0.2912  loss_rpn_cls: 0.08305  loss_rpn_loc: 0.2003  time: 0.5510  data_time: 0.3429  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:12:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:12:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:12:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:12:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:12:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:12:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0731 s/iter. Eval: 0.0592 s/iter. Total: 0.1332 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/02 17:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0716 s/iter. Eval: 0.0594 s/iter. Total: 0.1319 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0629 s/iter. Total: 0.1354 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:13:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.425435 (0.132978 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:13:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071245 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:13:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:13:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26721574368489986\n",
      "\u001b[32m[02/02 17:13:18 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 8479  total_loss: 1.366  loss_cls: 0.3127  loss_box_reg: 0.46  loss_mask: 0.2946  loss_rpn_cls: 0.08004  loss_rpn_loc: 0.2087  time: 0.5512  data_time: 0.4000  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:13:27 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 8499  total_loss: 1.284  loss_cls: 0.2829  loss_box_reg: 0.4967  loss_mask: 0.2841  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.1694  time: 0.5510  data_time: 0.2425  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:13:38 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 8519  total_loss: 1.243  loss_cls: 0.2795  loss_box_reg: 0.4878  loss_mask: 0.2776  loss_rpn_cls: 0.07371  loss_rpn_loc: 0.1811  time: 0.5511  data_time: 0.3331  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:13:48 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 8539  total_loss: 1.26  loss_cls: 0.2869  loss_box_reg: 0.4577  loss_mask: 0.2857  loss_rpn_cls: 0.05857  loss_rpn_loc: 0.1778  time: 0.5509  data_time: 0.2540  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:13:58 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 8559  total_loss: 1.413  loss_cls: 0.3353  loss_box_reg: 0.502  loss_mask: 0.2866  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.1743  time: 0.5508  data_time: 0.2830  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:14:10 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 8579  total_loss: 1.305  loss_cls: 0.2903  loss_box_reg: 0.5089  loss_mask: 0.2943  loss_rpn_cls: 0.05816  loss_rpn_loc: 0.1777  time: 0.5510  data_time: 0.3953  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:14:23 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 8599  total_loss: 1.362  loss_cls: 0.3192  loss_box_reg: 0.4675  loss_mask: 0.3089  loss_rpn_cls: 0.07809  loss_rpn_loc: 0.187  time: 0.5511  data_time: 0.3919  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:14:34 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 8619  total_loss: 1.359  loss_cls: 0.3111  loss_box_reg: 0.482  loss_mask: 0.2982  loss_rpn_cls: 0.07366  loss_rpn_loc: 0.1942  time: 0.5512  data_time: 0.3452  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:14:45 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 8639  total_loss: 1.348  loss_cls: 0.2625  loss_box_reg: 0.5024  loss_mask: 0.2913  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.1987  time: 0.5512  data_time: 0.3248  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:15:04 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 8659  total_loss: 1.393  loss_cls: 0.3492  loss_box_reg: 0.4587  loss_mask: 0.2885  loss_rpn_cls: 0.09048  loss_rpn_loc: 0.2098  time: 0.5520  data_time: 0.6565  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:15:13 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 8679  total_loss: 1.338  loss_cls: 0.2951  loss_box_reg: 0.5046  loss_mask: 0.2915  loss_rpn_cls: 0.06199  loss_rpn_loc: 0.1872  time: 0.5518  data_time: 0.2458  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:15:24 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 8699  total_loss: 1.326  loss_cls: 0.307  loss_box_reg: 0.5081  loss_mask: 0.2888  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.1802  time: 0.5518  data_time: 0.3058  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:15:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:15:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:15:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:15:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:15:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:15:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0701 s/iter. Eval: 0.0473 s/iter. Total: 0.1182 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 17:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0574 s/iter. Total: 0.1292 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0602 s/iter. Total: 0.1320 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:15:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.150708 (0.130610 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:15:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070782 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:15:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:15:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.266371211293495\n",
      "\u001b[32m[02/02 17:15:53 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 8719  total_loss: 1.326  loss_cls: 0.2794  loss_box_reg: 0.4977  loss_mask: 0.3004  loss_rpn_cls: 0.07124  loss_rpn_loc: 0.192  time: 0.5520  data_time: 0.3985  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:16:05 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 8739  total_loss: 1.461  loss_cls: 0.3716  loss_box_reg: 0.4814  loss_mask: 0.2975  loss_rpn_cls: 0.0898  loss_rpn_loc: 0.1956  time: 0.5521  data_time: 0.3770  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:16:13 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 8759  total_loss: 1.124  loss_cls: 0.2302  loss_box_reg: 0.4601  loss_mask: 0.2726  loss_rpn_cls: 0.04189  loss_rpn_loc: 0.1573  time: 0.5517  data_time: 0.1985  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:16:28 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 8779  total_loss: 1.371  loss_cls: 0.3112  loss_box_reg: 0.4839  loss_mask: 0.2946  loss_rpn_cls: 0.07715  loss_rpn_loc: 0.1996  time: 0.5522  data_time: 0.4867  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:16:40 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 8799  total_loss: 1.41  loss_cls: 0.3385  loss_box_reg: 0.4941  loss_mask: 0.3063  loss_rpn_cls: 0.07819  loss_rpn_loc: 0.1924  time: 0.5523  data_time: 0.3869  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:16:49 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 8819  total_loss: 1.337  loss_cls: 0.3123  loss_box_reg: 0.467  loss_mask: 0.2935  loss_rpn_cls: 0.05971  loss_rpn_loc: 0.2007  time: 0.5520  data_time: 0.2307  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:16:58 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 8839  total_loss: 1.284  loss_cls: 0.2791  loss_box_reg: 0.495  loss_mask: 0.2921  loss_rpn_cls: 0.05365  loss_rpn_loc: 0.1868  time: 0.5518  data_time: 0.2161  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:17:09 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 8859  total_loss: 1.377  loss_cls: 0.2782  loss_box_reg: 0.4844  loss_mask: 0.2928  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.1887  time: 0.5518  data_time: 0.3467  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:17:21 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 8879  total_loss: 1.422  loss_cls: 0.3307  loss_box_reg: 0.4987  loss_mask: 0.301  loss_rpn_cls: 0.08169  loss_rpn_loc: 0.1956  time: 0.5519  data_time: 0.3510  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:17:32 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 8899  total_loss: 1.364  loss_cls: 0.3096  loss_box_reg: 0.4888  loss_mask: 0.2938  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.1953  time: 0.5519  data_time: 0.3112  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:17:44 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 8919  total_loss: 1.29  loss_cls: 0.2876  loss_box_reg: 0.4664  loss_mask: 0.2868  loss_rpn_cls: 0.06375  loss_rpn_loc: 0.1868  time: 0.5520  data_time: 0.3525  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:17:53 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 8939  total_loss: 1.373  loss_cls: 0.29  loss_box_reg: 0.5449  loss_mask: 0.2934  loss_rpn_cls: 0.05668  loss_rpn_loc: 0.1665  time: 0.5517  data_time: 0.2160  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:18:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:18:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:18:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:18:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:18:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:18:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:18:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0701 s/iter. Eval: 0.0487 s/iter. Total: 0.1196 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 17:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0010 s/iter. Inference: 0.0705 s/iter. Eval: 0.0543 s/iter. Total: 0.1259 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 17:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0009 s/iter. Inference: 0.0705 s/iter. Eval: 0.0557 s/iter. Total: 0.1271 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 17:18:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.604915 (0.125904 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:18:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070223 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:18:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:18:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26373995843771253\n",
      "\u001b[32m[02/02 17:18:21 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 8959  total_loss: 1.405  loss_cls: 0.3195  loss_box_reg: 0.4962  loss_mask: 0.2974  loss_rpn_cls: 0.07971  loss_rpn_loc: 0.2061  time: 0.5518  data_time: 0.3615  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:18:31 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 8979  total_loss: 1.345  loss_cls: 0.3026  loss_box_reg: 0.4856  loss_mask: 0.289  loss_rpn_cls: 0.06683  loss_rpn_loc: 0.1947  time: 0.5518  data_time: 0.3045  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:18:40 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 8999  total_loss: 1.385  loss_cls: 0.3122  loss_box_reg: 0.4755  loss_mask: 0.3052  loss_rpn_cls: 0.06283  loss_rpn_loc: 0.1968  time: 0.5516  data_time: 0.2284  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:18:52 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 9019  total_loss: 1.422  loss_cls: 0.3352  loss_box_reg: 0.4825  loss_mask: 0.3  loss_rpn_cls: 0.06757  loss_rpn_loc: 0.1969  time: 0.5516  data_time: 0.3326  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:19:02 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 9039  total_loss: 1.381  loss_cls: 0.2961  loss_box_reg: 0.4515  loss_mask: 0.2837  loss_rpn_cls: 0.0622  loss_rpn_loc: 0.195  time: 0.5516  data_time: 0.3011  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:19:11 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 9059  total_loss: 1.377  loss_cls: 0.289  loss_box_reg: 0.5181  loss_mask: 0.3004  loss_rpn_cls: 0.0543  loss_rpn_loc: 0.181  time: 0.5513  data_time: 0.2089  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:19:20 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 9079  total_loss: 1.392  loss_cls: 0.344  loss_box_reg: 0.515  loss_mask: 0.2784  loss_rpn_cls: 0.06093  loss_rpn_loc: 0.1743  time: 0.5510  data_time: 0.2284  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:19:33 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 9099  total_loss: 1.401  loss_cls: 0.3109  loss_box_reg: 0.4872  loss_mask: 0.3014  loss_rpn_cls: 0.08941  loss_rpn_loc: 0.2081  time: 0.5513  data_time: 0.4214  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:19:47 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 9119  total_loss: 1.399  loss_cls: 0.2874  loss_box_reg: 0.4613  loss_mask: 0.2913  loss_rpn_cls: 0.08041  loss_rpn_loc: 0.2065  time: 0.5516  data_time: 0.4698  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:19:55 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 9139  total_loss: 1.235  loss_cls: 0.2527  loss_box_reg: 0.4978  loss_mask: 0.276  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.1547  time: 0.5512  data_time: 0.1539  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:20:08 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 9159  total_loss: 1.408  loss_cls: 0.3182  loss_box_reg: 0.4807  loss_mask: 0.2954  loss_rpn_cls: 0.07785  loss_rpn_loc: 0.2035  time: 0.5514  data_time: 0.4020  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:20:19 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 9179  total_loss: 1.336  loss_cls: 0.2954  loss_box_reg: 0.4888  loss_mask: 0.2772  loss_rpn_cls: 0.07813  loss_rpn_loc: 0.1917  time: 0.5514  data_time: 0.3150  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:20:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:20:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:20:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:20:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:20:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:20:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0695 s/iter. Eval: 0.0525 s/iter. Total: 0.1227 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 17:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0711 s/iter. Eval: 0.0605 s/iter. Total: 0.1324 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0716 s/iter. Eval: 0.0648 s/iter. Total: 0.1373 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:20:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.598812 (0.134473 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:20:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071277 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:20:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26839032355078396\n",
      "\u001b[32m[02/02 17:20:44 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 9199  total_loss: 1.242  loss_cls: 0.261  loss_box_reg: 0.4507  loss_mask: 0.2741  loss_rpn_cls: 0.05815  loss_rpn_loc: 0.1809  time: 0.5511  data_time: 0.1972  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:20:57 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 9219  total_loss: 1.347  loss_cls: 0.2871  loss_box_reg: 0.4922  loss_mask: 0.2919  loss_rpn_cls: 0.05351  loss_rpn_loc: 0.1812  time: 0.5513  data_time: 0.4072  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:21:07 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 9239  total_loss: 1.367  loss_cls: 0.3018  loss_box_reg: 0.5275  loss_mask: 0.2913  loss_rpn_cls: 0.05394  loss_rpn_loc: 0.165  time: 0.5512  data_time: 0.2798  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:21:18 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 9259  total_loss: 1.288  loss_cls: 0.2606  loss_box_reg: 0.4656  loss_mask: 0.2995  loss_rpn_cls: 0.04459  loss_rpn_loc: 0.186  time: 0.5512  data_time: 0.3075  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:21:30 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 9279  total_loss: 1.38  loss_cls: 0.317  loss_box_reg: 0.4753  loss_mask: 0.2904  loss_rpn_cls: 0.07438  loss_rpn_loc: 0.1933  time: 0.5514  data_time: 0.3970  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:21:39 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 9299  total_loss: 1.359  loss_cls: 0.2939  loss_box_reg: 0.5263  loss_mask: 0.2943  loss_rpn_cls: 0.05834  loss_rpn_loc: 0.1916  time: 0.5510  data_time: 0.1948  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:21:48 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 9319  total_loss: 1.363  loss_cls: 0.3121  loss_box_reg: 0.512  loss_mask: 0.295  loss_rpn_cls: 0.05662  loss_rpn_loc: 0.1885  time: 0.5509  data_time: 0.2627  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:21:58 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 9339  total_loss: 1.223  loss_cls: 0.2718  loss_box_reg: 0.4574  loss_mask: 0.2747  loss_rpn_cls: 0.04408  loss_rpn_loc: 0.1652  time: 0.5508  data_time: 0.2552  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:22:07 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 9359  total_loss: 1.338  loss_cls: 0.3104  loss_box_reg: 0.4956  loss_mask: 0.2879  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.1779  time: 0.5505  data_time: 0.2224  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:22:20 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9379  total_loss: 1.403  loss_cls: 0.3403  loss_box_reg: 0.4708  loss_mask: 0.3009  loss_rpn_cls: 0.0927  loss_rpn_loc: 0.1967  time: 0.5507  data_time: 0.4032  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:22:30 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 9399  total_loss: 1.405  loss_cls: 0.3483  loss_box_reg: 0.4878  loss_mask: 0.2961  loss_rpn_cls: 0.0746  loss_rpn_loc: 0.1833  time: 0.5507  data_time: 0.2991  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:22:43 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9419  total_loss: 1.403  loss_cls: 0.3059  loss_box_reg: 0.4806  loss_mask: 0.304  loss_rpn_cls: 0.08411  loss_rpn_loc: 0.2274  time: 0.5508  data_time: 0.4137  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:22:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:22:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:22:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:22:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:22:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:22:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:22:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0691 s/iter. Eval: 0.0503 s/iter. Total: 0.1202 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 17:22:59 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0574 s/iter. Total: 0.1287 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:23:04 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0592 s/iter. Total: 0.1309 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:23:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.026738 (0.129541 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:23:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070681 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:23:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:23:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26421987621060855\n",
      "\u001b[32m[02/02 17:23:08 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 9439  total_loss: 1.383  loss_cls: 0.3077  loss_box_reg: 0.5143  loss_mask: 0.2808  loss_rpn_cls: 0.05452  loss_rpn_loc: 0.1775  time: 0.5506  data_time: 0.2262  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:23:24 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 9459  total_loss: 1.4  loss_cls: 0.2915  loss_box_reg: 0.4875  loss_mask: 0.2872  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.1975  time: 0.5511  data_time: 0.5222  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:23:34 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 9479  total_loss: 1.344  loss_cls: 0.2827  loss_box_reg: 0.5002  loss_mask: 0.2995  loss_rpn_cls: 0.05888  loss_rpn_loc: 0.2036  time: 0.5510  data_time: 0.2959  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:23:46 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 9499  total_loss: 1.342  loss_cls: 0.2752  loss_box_reg: 0.4505  loss_mask: 0.2929  loss_rpn_cls: 0.06226  loss_rpn_loc: 0.1927  time: 0.5511  data_time: 0.3633  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:23:59 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 9519  total_loss: 1.304  loss_cls: 0.3027  loss_box_reg: 0.454  loss_mask: 0.2743  loss_rpn_cls: 0.05901  loss_rpn_loc: 0.177  time: 0.5513  data_time: 0.3965  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:24:08 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 9539  total_loss: 1.318  loss_cls: 0.3128  loss_box_reg: 0.4659  loss_mask: 0.2868  loss_rpn_cls: 0.07322  loss_rpn_loc: 0.1872  time: 0.5511  data_time: 0.2211  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:24:18 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 9559  total_loss: 1.292  loss_cls: 0.2839  loss_box_reg: 0.5032  loss_mask: 0.2826  loss_rpn_cls: 0.0493  loss_rpn_loc: 0.1807  time: 0.5510  data_time: 0.2839  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:24:30 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 9579  total_loss: 1.464  loss_cls: 0.3527  loss_box_reg: 0.5074  loss_mask: 0.301  loss_rpn_cls: 0.07494  loss_rpn_loc: 0.191  time: 0.5511  data_time: 0.3548  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:24:41 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 9599  total_loss: 1.41  loss_cls: 0.3503  loss_box_reg: 0.4894  loss_mask: 0.2845  loss_rpn_cls: 0.08777  loss_rpn_loc: 0.1792  time: 0.5511  data_time: 0.3293  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:24:51 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 9619  total_loss: 1.307  loss_cls: 0.2678  loss_box_reg: 0.4624  loss_mask: 0.2813  loss_rpn_cls: 0.0577  loss_rpn_loc: 0.1744  time: 0.5509  data_time: 0.2564  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:25:01 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 9639  total_loss: 1.343  loss_cls: 0.3198  loss_box_reg: 0.5116  loss_mask: 0.2954  loss_rpn_cls: 0.06132  loss_rpn_loc: 0.1771  time: 0.5509  data_time: 0.3154  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:25:15 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 9659  total_loss: 1.303  loss_cls: 0.2874  loss_box_reg: 0.4591  loss_mask: 0.2978  loss_rpn_cls: 0.08066  loss_rpn_loc: 0.1755  time: 0.5511  data_time: 0.4357  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:25:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:25:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:25:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:25:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:25:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:25:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:25:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0727 s/iter. Eval: 0.0643 s/iter. Total: 0.1379 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/02 17:25:36 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0611 s/iter. Total: 0.1336 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:25:41 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0643 s/iter. Total: 0.1369 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:25:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.597284 (0.134459 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:25:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071386 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:25:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:25:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26747816612195835\n",
      "\u001b[32m[02/02 17:25:45 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 9679  total_loss: 1.361  loss_cls: 0.3365  loss_box_reg: 0.4771  loss_mask: 0.299  loss_rpn_cls: 0.08919  loss_rpn_loc: 0.2115  time: 0.5514  data_time: 0.4352  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:25:53 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 9699  total_loss: 1.289  loss_cls: 0.3109  loss_box_reg: 0.4823  loss_mask: 0.2946  loss_rpn_cls: 0.05503  loss_rpn_loc: 0.1713  time: 0.5511  data_time: 0.1944  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:26:05 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 9719  total_loss: 1.331  loss_cls: 0.2736  loss_box_reg: 0.4935  loss_mask: 0.2993  loss_rpn_cls: 0.0636  loss_rpn_loc: 0.1865  time: 0.5511  data_time: 0.3324  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:26:11 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 9739  total_loss: 1.288  loss_cls: 0.274  loss_box_reg: 0.4857  loss_mask: 0.2764  loss_rpn_cls: 0.04595  loss_rpn_loc: 0.173  time: 0.5507  data_time: 0.1143  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:26:21 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 9759  total_loss: 1.323  loss_cls: 0.2771  loss_box_reg: 0.4904  loss_mask: 0.3033  loss_rpn_cls: 0.04509  loss_rpn_loc: 0.1794  time: 0.5505  data_time: 0.2466  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:26:33 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 9779  total_loss: 1.363  loss_cls: 0.2894  loss_box_reg: 0.448  loss_mask: 0.2986  loss_rpn_cls: 0.08545  loss_rpn_loc: 0.2061  time: 0.5507  data_time: 0.3964  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:26:48 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 9799  total_loss: 1.402  loss_cls: 0.3174  loss_box_reg: 0.4819  loss_mask: 0.2923  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.2007  time: 0.5510  data_time: 0.4827  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:27:01 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 9819  total_loss: 1.326  loss_cls: 0.2841  loss_box_reg: 0.4815  loss_mask: 0.3146  loss_rpn_cls: 0.06701  loss_rpn_loc: 0.1896  time: 0.5512  data_time: 0.4147  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:27:12 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 9839  total_loss: 1.394  loss_cls: 0.314  loss_box_reg: 0.4855  loss_mask: 0.3017  loss_rpn_cls: 0.07412  loss_rpn_loc: 0.1959  time: 0.5513  data_time: 0.3488  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:27:21 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 9859  total_loss: 1.375  loss_cls: 0.2927  loss_box_reg: 0.4879  loss_mask: 0.2878  loss_rpn_cls: 0.0495  loss_rpn_loc: 0.184  time: 0.5510  data_time: 0.2291  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:27:32 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 9879  total_loss: 1.24  loss_cls: 0.2771  loss_box_reg: 0.4584  loss_mask: 0.2899  loss_rpn_cls: 0.05539  loss_rpn_loc: 0.174  time: 0.5510  data_time: 0.3217  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:27:41 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 9899  total_loss: 1.356  loss_cls: 0.3062  loss_box_reg: 0.5215  loss_mask: 0.2917  loss_rpn_cls: 0.05089  loss_rpn_loc: 0.1842  time: 0.5508  data_time: 0.1996  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:27:52 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 9919  total_loss: 1.443  loss_cls: 0.3161  loss_box_reg: 0.5014  loss_mask: 0.2969  loss_rpn_cls: 0.08753  loss_rpn_loc: 0.1893  time: 0.5508  data_time: 0.3174  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:27:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:27:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:27:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:27:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:27:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:27:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0696 s/iter. Eval: 0.0538 s/iter. Total: 0.1242 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 17:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0711 s/iter. Eval: 0.0626 s/iter. Total: 0.1345 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0715 s/iter. Eval: 0.0653 s/iter. Total: 0.1376 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 17:28:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.739121 (0.135682 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:28:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071228 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:28:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:28:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2673164866289569\n",
      "\u001b[32m[02/02 17:28:21 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 9939  total_loss: 1.291  loss_cls: 0.3033  loss_box_reg: 0.4472  loss_mask: 0.2959  loss_rpn_cls: 0.07039  loss_rpn_loc: 0.1703  time: 0.5509  data_time: 0.3723  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:28:35 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 9959  total_loss: 1.307  loss_cls: 0.3019  loss_box_reg: 0.4772  loss_mask: 0.2939  loss_rpn_cls: 0.06258  loss_rpn_loc: 0.1875  time: 0.5511  data_time: 0.4323  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:28:48 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 9979  total_loss: 1.343  loss_cls: 0.3075  loss_box_reg: 0.4492  loss_mask: 0.2859  loss_rpn_cls: 0.0746  loss_rpn_loc: 0.1714  time: 0.5513  data_time: 0.3986  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:28:59 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.352  loss_cls: 0.3096  loss_box_reg: 0.5017  loss_mask: 0.3111  loss_rpn_cls: 0.06061  loss_rpn_loc: 0.1846  time: 0.5514  data_time: 0.3474  lr: 0.0005  max_mem: 6664M\n",
      "\u001b[32m[02/02 17:28:59 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:31:52 (0.5514 s / it)\n",
      "\u001b[32m[02/02 17:28:59 d2.engine.hooks]: \u001b[0mTotal training time: 1:43:04 (0:11:12 on hooks)\n",
      "\u001b[32m[02/02 17:28:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:29:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 17:29:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 17:29:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 17:29:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 17:29:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 17:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0698 s/iter. Eval: 0.0474 s/iter. Total: 0.1178 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 17:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0712 s/iter. Eval: 0.0621 s/iter. Total: 0.1341 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 17:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0715 s/iter. Eval: 0.0639 s/iter. Total: 0.1362 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 17:29:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.514610 (0.133747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:29:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071167 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 17:29:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 17:29:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2665731386160218\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.0005 with AMP enabled (Automatic Mixed Precision)\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.AMP.ENABLED = True\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_8.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea258d3c-05f7-4946-ad18-8c8169f45039",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 19:15:13 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 19:15:14 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 19:15:15 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/02 19:15:16 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/02 19:15:16 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/02 19:15:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/02 19:15:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/02 19:15:16 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:15:16 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 19:15:16 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/02 19:15:29 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 19  total_loss: 3.041  loss_cls: 1.378  loss_box_reg: 0.3663  loss_mask: 0.6953  loss_rpn_cls: 0.3455  loss_rpn_loc: 0.2661  time: 0.5935  data_time: 0.3090  lr: 9.9905e-06  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:15:37 d2.utils.events]: \u001b[0m eta: 0:52:47  iter: 39  total_loss: 3.02  loss_cls: 1.322  loss_box_reg: 0.5111  loss_mask: 0.6873  loss_rpn_cls: 0.2562  loss_rpn_loc: 0.22  time: 0.4970  data_time: 0.1128  lr: 1.998e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:15:46 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 59  total_loss: 2.82  loss_cls: 1.193  loss_box_reg: 0.4594  loss_mask: 0.6696  loss_rpn_cls: 0.2498  loss_rpn_loc: 0.2324  time: 0.4883  data_time: 0.1691  lr: 2.997e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:15:59 d2.utils.events]: \u001b[0m eta: 0:52:54  iter: 79  total_loss: 2.654  loss_cls: 0.9854  loss_box_reg: 0.3739  loss_mask: 0.6468  loss_rpn_cls: 0.2959  loss_rpn_loc: 0.2916  time: 0.5195  data_time: 0.3065  lr: 3.9961e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:16:11 d2.utils.events]: \u001b[0m eta: 0:52:56  iter: 99  total_loss: 2.394  loss_cls: 0.8522  loss_box_reg: 0.5001  loss_mask: 0.6172  loss_rpn_cls: 0.233  loss_rpn_loc: 0.2452  time: 0.5381  data_time: 0.3010  lr: 4.9951e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:16:22 d2.utils.events]: \u001b[0m eta: 0:53:06  iter: 119  total_loss: 2.393  loss_cls: 0.7784  loss_box_reg: 0.484  loss_mask: 0.5984  loss_rpn_cls: 0.218  loss_rpn_loc: 0.2428  time: 0.5457  data_time: 0.2710  lr: 5.9941e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:16:31 d2.utils.events]: \u001b[0m eta: 0:52:44  iter: 139  total_loss: 2.234  loss_cls: 0.7102  loss_box_reg: 0.6103  loss_mask: 0.5358  loss_rpn_cls: 0.1339  loss_rpn_loc: 0.222  time: 0.5283  data_time: 0.1240  lr: 6.993e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:16:45 d2.utils.events]: \u001b[0m eta: 0:53:01  iter: 159  total_loss: 2.174  loss_cls: 0.6805  loss_box_reg: 0.5778  loss_mask: 0.5403  loss_rpn_cls: 0.1899  loss_rpn_loc: 0.2299  time: 0.5510  data_time: 0.3825  lr: 7.9921e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:17:00 d2.utils.events]: \u001b[0m eta: 0:53:08  iter: 179  total_loss: 2.214  loss_cls: 0.6615  loss_box_reg: 0.5778  loss_mask: 0.5003  loss_rpn_cls: 0.1543  loss_rpn_loc: 0.2368  time: 0.5754  data_time: 0.4395  lr: 8.991e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:17:13 d2.utils.events]: \u001b[0m eta: 0:53:16  iter: 199  total_loss: 2.14  loss_cls: 0.619  loss_box_reg: 0.6125  loss_mask: 0.4816  loss_rpn_cls: 0.1358  loss_rpn_loc: 0.2168  time: 0.5811  data_time: 0.3128  lr: 9.9901e-05  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:17:27 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 219  total_loss: 2.001  loss_cls: 0.5826  loss_box_reg: 0.5767  loss_mask: 0.4471  loss_rpn_cls: 0.1515  loss_rpn_loc: 0.2319  time: 0.5932  data_time: 0.3746  lr: 0.00010989  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:17:37 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 239  total_loss: 2.007  loss_cls: 0.5793  loss_box_reg: 0.6403  loss_mask: 0.4238  loss_rpn_cls: 0.1438  loss_rpn_loc: 0.2306  time: 0.5843  data_time: 0.1841  lr: 0.00011988  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:17:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:17:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:17:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:17:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:17:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:17:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0636 s/iter. Eval: 0.0079 s/iter. Total: 0.0721 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/02 19:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0641 s/iter. Eval: 0.0087 s/iter. Total: 0.0736 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 19:17:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.388242 (0.072312 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:17:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.063771 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:17:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:17:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.06688964483804256\n",
      "\u001b[32m[02/02 19:17:56 d2.utils.events]: \u001b[0m eta: 0:53:21  iter: 259  total_loss: 1.984  loss_cls: 0.5426  loss_box_reg: 0.6627  loss_mask: 0.4  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.2148  time: 0.5737  data_time: 0.1410  lr: 0.00012987  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:18:07 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 279  total_loss: 1.854  loss_cls: 0.4983  loss_box_reg: 0.6405  loss_mask: 0.3737  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.2277  time: 0.5749  data_time: 0.2693  lr: 0.00013986  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:18:20 d2.utils.events]: \u001b[0m eta: 0:53:27  iter: 299  total_loss: 1.829  loss_cls: 0.5203  loss_box_reg: 0.6795  loss_mask: 0.3551  loss_rpn_cls: 0.1386  loss_rpn_loc: 0.2216  time: 0.5782  data_time: 0.3072  lr: 0.00014985  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:18:32 d2.utils.events]: \u001b[0m eta: 0:53:23  iter: 319  total_loss: 1.828  loss_cls: 0.4874  loss_box_reg: 0.6335  loss_mask: 0.3624  loss_rpn_cls: 0.1286  loss_rpn_loc: 0.2369  time: 0.5792  data_time: 0.2784  lr: 0.00015984  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:18:43 d2.utils.events]: \u001b[0m eta: 0:53:14  iter: 339  total_loss: 1.742  loss_cls: 0.4272  loss_box_reg: 0.6276  loss_mask: 0.3202  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.2018  time: 0.5774  data_time: 0.2313  lr: 0.00016983  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:18:53 d2.utils.events]: \u001b[0m eta: 0:52:49  iter: 359  total_loss: 1.709  loss_cls: 0.3945  loss_box_reg: 0.6438  loss_mask: 0.3171  loss_rpn_cls: 0.0929  loss_rpn_loc: 0.213  time: 0.5745  data_time: 0.2309  lr: 0.00017982  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:19:07 d2.utils.events]: \u001b[0m eta: 0:52:49  iter: 379  total_loss: 1.748  loss_cls: 0.3664  loss_box_reg: 0.5905  loss_mask: 0.3381  loss_rpn_cls: 0.103  loss_rpn_loc: 0.2421  time: 0.5815  data_time: 0.3944  lr: 0.00018981  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:19:17 d2.utils.events]: \u001b[0m eta: 0:52:19  iter: 399  total_loss: 1.71  loss_cls: 0.3963  loss_box_reg: 0.6371  loss_mask: 0.3201  loss_rpn_cls: 0.1477  loss_rpn_loc: 0.2028  time: 0.5755  data_time: 0.1750  lr: 0.0001998  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:19:26 d2.utils.events]: \u001b[0m eta: 0:52:19  iter: 419  total_loss: 1.814  loss_cls: 0.4583  loss_box_reg: 0.6415  loss_mask: 0.3284  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.2226  time: 0.5712  data_time: 0.1754  lr: 0.00020979  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:19:39 d2.utils.events]: \u001b[0m eta: 0:52:22  iter: 439  total_loss: 1.602  loss_cls: 0.4094  loss_box_reg: 0.5425  loss_mask: 0.2932  loss_rpn_cls: 0.1353  loss_rpn_loc: 0.2072  time: 0.5731  data_time: 0.2933  lr: 0.00021978  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:19:49 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 459  total_loss: 1.636  loss_cls: 0.3664  loss_box_reg: 0.5877  loss_mask: 0.3259  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.2146  time: 0.5697  data_time: 0.1975  lr: 0.00022977  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:20:01 d2.utils.events]: \u001b[0m eta: 0:52:01  iter: 479  total_loss: 1.54  loss_cls: 0.3498  loss_box_reg: 0.5843  loss_mask: 0.3199  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2216  time: 0.5715  data_time: 0.3078  lr: 0.00023976  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:20:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:20:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:20:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:20:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:20:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:20:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0674 s/iter. Eval: 0.0352 s/iter. Total: 0.1034 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 19:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0699 s/iter. Eval: 0.0509 s/iter. Total: 0.1217 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 19:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0553 s/iter. Total: 0.1267 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 19:20:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.412410 (0.124245 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:20:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070328 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:20:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:20:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21607279201739854\n",
      "\u001b[32m[02/02 19:20:30 d2.utils.events]: \u001b[0m eta: 0:51:55  iter: 499  total_loss: 1.635  loss_cls: 0.4238  loss_box_reg: 0.5915  loss_mask: 0.3194  loss_rpn_cls: 0.1197  loss_rpn_loc: 0.2367  time: 0.5762  data_time: 0.3649  lr: 0.00024975  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:20:44 d2.utils.events]: \u001b[0m eta: 0:51:49  iter: 519  total_loss: 1.715  loss_cls: 0.3977  loss_box_reg: 0.6169  loss_mask: 0.3419  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2407  time: 0.5805  data_time: 0.3723  lr: 0.00025974  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:20:55 d2.utils.events]: \u001b[0m eta: 0:51:41  iter: 539  total_loss: 1.562  loss_cls: 0.3605  loss_box_reg: 0.6087  loss_mask: 0.3205  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2375  time: 0.5788  data_time: 0.2289  lr: 0.00026973  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:21:08 d2.utils.events]: \u001b[0m eta: 0:51:40  iter: 559  total_loss: 1.63  loss_cls: 0.3875  loss_box_reg: 0.5611  loss_mask: 0.3092  loss_rpn_cls: 0.1267  loss_rpn_loc: 0.2164  time: 0.5813  data_time: 0.3303  lr: 0.00027972  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:21:17 d2.utils.events]: \u001b[0m eta: 0:51:40  iter: 579  total_loss: 1.61  loss_cls: 0.3332  loss_box_reg: 0.5768  loss_mask: 0.3133  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.22  time: 0.5768  data_time: 0.1504  lr: 0.00028971  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:21:29 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 599  total_loss: 1.608  loss_cls: 0.353  loss_box_reg: 0.5734  loss_mask: 0.3108  loss_rpn_cls: 0.09613  loss_rpn_loc: 0.2254  time: 0.5773  data_time: 0.2818  lr: 0.0002997  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:21:40 d2.utils.events]: \u001b[0m eta: 0:51:20  iter: 619  total_loss: 1.525  loss_cls: 0.3342  loss_box_reg: 0.5615  loss_mask: 0.3082  loss_rpn_cls: 0.07996  loss_rpn_loc: 0.2279  time: 0.5766  data_time: 0.2404  lr: 0.00030969  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:21:51 d2.utils.events]: \u001b[0m eta: 0:51:24  iter: 639  total_loss: 1.603  loss_cls: 0.4093  loss_box_reg: 0.5738  loss_mask: 0.3021  loss_rpn_cls: 0.1235  loss_rpn_loc: 0.2117  time: 0.5765  data_time: 0.2584  lr: 0.00031968  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:22:05 d2.utils.events]: \u001b[0m eta: 0:51:27  iter: 659  total_loss: 1.587  loss_cls: 0.3552  loss_box_reg: 0.5531  loss_mask: 0.3099  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.2115  time: 0.5799  data_time: 0.3722  lr: 0.00032967  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:22:14 d2.utils.events]: \u001b[0m eta: 0:51:20  iter: 679  total_loss: 1.549  loss_cls: 0.3569  loss_box_reg: 0.5827  loss_mask: 0.3042  loss_rpn_cls: 0.07684  loss_rpn_loc: 0.2042  time: 0.5764  data_time: 0.1571  lr: 0.00033966  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:22:28 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 699  total_loss: 1.608  loss_cls: 0.3845  loss_box_reg: 0.5488  loss_mask: 0.3223  loss_rpn_cls: 0.1262  loss_rpn_loc: 0.2416  time: 0.5795  data_time: 0.3747  lr: 0.00034965  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:22:40 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 719  total_loss: 1.479  loss_cls: 0.3341  loss_box_reg: 0.5071  loss_mask: 0.3014  loss_rpn_cls: 0.07567  loss_rpn_loc: 0.204  time: 0.5803  data_time: 0.2869  lr: 0.00035964  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:22:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:22:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:22:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:22:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:22:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:22:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0691 s/iter. Eval: 0.0380 s/iter. Total: 0.1077 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 19:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0516 s/iter. Total: 0.1228 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 19:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0538 s/iter. Total: 0.1255 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 19:22:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.426012 (0.124362 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:22:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:22:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:22:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23767393092107267\n",
      "\u001b[32m[02/02 19:23:06 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 739  total_loss: 1.618  loss_cls: 0.398  loss_box_reg: 0.5969  loss_mask: 0.3133  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2042  time: 0.5786  data_time: 0.2040  lr: 0.00036963  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:23:19 d2.utils.events]: \u001b[0m eta: 0:50:53  iter: 759  total_loss: 1.55  loss_cls: 0.3531  loss_box_reg: 0.5541  loss_mask: 0.3071  loss_rpn_cls: 0.0914  loss_rpn_loc: 0.2107  time: 0.5796  data_time: 0.3005  lr: 0.00037962  max_mem: 6664M\n",
      "\u001b[32m[02/02 19:23:30 d2.utils.events]: \u001b[0m eta: 0:50:43  iter: 779  total_loss: 1.625  loss_cls: 0.394  loss_box_reg: 0.5917  loss_mask: 0.3183  loss_rpn_cls: 0.09939  loss_rpn_loc: 0.2163  time: 0.5796  data_time: 0.2682  lr: 0.00038961  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:23:39 d2.utils.events]: \u001b[0m eta: 0:50:35  iter: 799  total_loss: 1.652  loss_cls: 0.4631  loss_box_reg: 0.5803  loss_mask: 0.2972  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.2007  time: 0.5764  data_time: 0.1540  lr: 0.0003996  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:23:50 d2.utils.events]: \u001b[0m eta: 0:50:14  iter: 819  total_loss: 1.638  loss_cls: 0.4099  loss_box_reg: 0.5904  loss_mask: 0.3075  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.2308  time: 0.5749  data_time: 0.2051  lr: 0.00040959  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:24:02 d2.utils.events]: \u001b[0m eta: 0:50:14  iter: 839  total_loss: 1.463  loss_cls: 0.3  loss_box_reg: 0.5286  loss_mask: 0.2961  loss_rpn_cls: 0.08091  loss_rpn_loc: 0.2065  time: 0.5762  data_time: 0.3020  lr: 0.00041958  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:24:12 d2.utils.events]: \u001b[0m eta: 0:50:11  iter: 859  total_loss: 1.46  loss_cls: 0.3725  loss_box_reg: 0.5437  loss_mask: 0.2782  loss_rpn_cls: 0.08195  loss_rpn_loc: 0.1788  time: 0.5741  data_time: 0.1737  lr: 0.00042957  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:24:26 d2.utils.events]: \u001b[0m eta: 0:50:08  iter: 879  total_loss: 1.482  loss_cls: 0.3293  loss_box_reg: 0.5154  loss_mask: 0.3132  loss_rpn_cls: 0.09205  loss_rpn_loc: 0.2006  time: 0.5770  data_time: 0.3683  lr: 0.00043956  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:24:37 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 899  total_loss: 1.517  loss_cls: 0.3322  loss_box_reg: 0.5387  loss_mask: 0.3016  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2154  time: 0.5759  data_time: 0.2082  lr: 0.00044955  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:24:50 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 919  total_loss: 1.566  loss_cls: 0.3705  loss_box_reg: 0.5588  loss_mask: 0.3224  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2176  time: 0.5777  data_time: 0.3456  lr: 0.00045954  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:25:02 d2.utils.events]: \u001b[0m eta: 0:49:54  iter: 939  total_loss: 1.604  loss_cls: 0.3929  loss_box_reg: 0.5374  loss_mask: 0.3047  loss_rpn_cls: 0.1317  loss_rpn_loc: 0.222  time: 0.5786  data_time: 0.3012  lr: 0.00046953  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:25:12 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 959  total_loss: 1.471  loss_cls: 0.3319  loss_box_reg: 0.5267  loss_mask: 0.3181  loss_rpn_cls: 0.07118  loss_rpn_loc: 0.2119  time: 0.5769  data_time: 0.1920  lr: 0.00047952  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:25:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:25:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:25:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:25:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:25:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:25:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0674 s/iter. Eval: 0.0337 s/iter. Total: 0.1018 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 19:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0484 s/iter. Total: 0.1200 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 19:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0519 s/iter. Total: 0.1247 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 19:25:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.215740 (0.122549 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:25:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071358 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:25:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:25:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2326397500250092\n",
      "\u001b[32m[02/02 19:25:42 d2.utils.events]: \u001b[0m eta: 0:49:41  iter: 979  total_loss: 1.59  loss_cls: 0.3657  loss_box_reg: 0.5349  loss_mask: 0.3135  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2137  time: 0.5796  data_time: 0.3899  lr: 0.00048951  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:25:55 d2.utils.events]: \u001b[0m eta: 0:49:34  iter: 999  total_loss: 1.551  loss_cls: 0.3459  loss_box_reg: 0.549  loss_mask: 0.3214  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.214  time: 0.5814  data_time: 0.3496  lr: 0.0004995  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:26:06 d2.utils.events]: \u001b[0m eta: 0:49:28  iter: 1019  total_loss: 1.497  loss_cls: 0.3351  loss_box_reg: 0.5297  loss_mask: 0.2999  loss_rpn_cls: 0.07886  loss_rpn_loc: 0.1869  time: 0.5806  data_time: 0.2256  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:26:20 d2.utils.events]: \u001b[0m eta: 0:49:29  iter: 1039  total_loss: 1.537  loss_cls: 0.3903  loss_box_reg: 0.5369  loss_mask: 0.3063  loss_rpn_cls: 0.1  loss_rpn_loc: 0.2332  time: 0.5830  data_time: 0.3804  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:26:32 d2.utils.events]: \u001b[0m eta: 0:49:29  iter: 1059  total_loss: 1.481  loss_cls: 0.3338  loss_box_reg: 0.5486  loss_mask: 0.3114  loss_rpn_cls: 0.08291  loss_rpn_loc: 0.2129  time: 0.5831  data_time: 0.2732  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:26:45 d2.utils.events]: \u001b[0m eta: 0:49:28  iter: 1079  total_loss: 1.497  loss_cls: 0.3478  loss_box_reg: 0.5159  loss_mask: 0.2979  loss_rpn_cls: 0.105  loss_rpn_loc: 0.2064  time: 0.5845  data_time: 0.3291  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:26:58 d2.utils.events]: \u001b[0m eta: 0:49:19  iter: 1099  total_loss: 1.545  loss_cls: 0.3848  loss_box_reg: 0.551  loss_mask: 0.3093  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.2202  time: 0.5853  data_time: 0.3208  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:27:06 d2.utils.events]: \u001b[0m eta: 0:49:08  iter: 1119  total_loss: 1.571  loss_cls: 0.4008  loss_box_reg: 0.5822  loss_mask: 0.3041  loss_rpn_cls: 0.08481  loss_rpn_loc: 0.2102  time: 0.5822  data_time: 0.1132  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:27:20 d2.utils.events]: \u001b[0m eta: 0:49:10  iter: 1139  total_loss: 1.438  loss_cls: 0.3144  loss_box_reg: 0.4861  loss_mask: 0.3065  loss_rpn_cls: 0.09827  loss_rpn_loc: 0.2286  time: 0.5839  data_time: 0.3592  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:27:30 d2.utils.events]: \u001b[0m eta: 0:48:59  iter: 1159  total_loss: 1.519  loss_cls: 0.3342  loss_box_reg: 0.5566  loss_mask: 0.3207  loss_rpn_cls: 0.08628  loss_rpn_loc: 0.206  time: 0.5832  data_time: 0.2380  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:27:40 d2.utils.events]: \u001b[0m eta: 0:48:47  iter: 1179  total_loss: 1.433  loss_cls: 0.3316  loss_box_reg: 0.5153  loss_mask: 0.2975  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.1918  time: 0.5815  data_time: 0.1821  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:27:50 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 1199  total_loss: 1.594  loss_cls: 0.4107  loss_box_reg: 0.539  loss_mask: 0.3048  loss_rpn_cls: 0.09529  loss_rpn_loc: 0.2253  time: 0.5804  data_time: 0.2191  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:27:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:27:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:27:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:27:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:27:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:27:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0361 s/iter. Total: 0.1049 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 19:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0494 s/iter. Total: 0.1201 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 19:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0524 s/iter. Total: 0.1240 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 19:28:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.082720 (0.121403 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:28:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070439 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:28:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:28:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2392786897073202\n",
      "\u001b[32m[02/02 19:28:19 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 1219  total_loss: 1.634  loss_cls: 0.3884  loss_box_reg: 0.5711  loss_mask: 0.3148  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.2294  time: 0.5816  data_time: 0.3359  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:28:32 d2.utils.events]: \u001b[0m eta: 0:48:19  iter: 1239  total_loss: 1.519  loss_cls: 0.3707  loss_box_reg: 0.5318  loss_mask: 0.3032  loss_rpn_cls: 0.08244  loss_rpn_loc: 0.2056  time: 0.5826  data_time: 0.3147  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:28:44 d2.utils.events]: \u001b[0m eta: 0:48:18  iter: 1259  total_loss: 1.386  loss_cls: 0.326  loss_box_reg: 0.5449  loss_mask: 0.291  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.2029  time: 0.5834  data_time: 0.2996  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:29:00 d2.utils.events]: \u001b[0m eta: 0:48:14  iter: 1279  total_loss: 1.541  loss_cls: 0.3851  loss_box_reg: 0.5356  loss_mask: 0.3191  loss_rpn_cls: 0.1196  loss_rpn_loc: 0.2058  time: 0.5868  data_time: 0.4633  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:29:15 d2.utils.events]: \u001b[0m eta: 0:48:07  iter: 1299  total_loss: 1.54  loss_cls: 0.3492  loss_box_reg: 0.5109  loss_mask: 0.3069  loss_rpn_cls: 0.09813  loss_rpn_loc: 0.219  time: 0.5888  data_time: 0.3856  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:29:27 d2.utils.events]: \u001b[0m eta: 0:48:00  iter: 1319  total_loss: 1.569  loss_cls: 0.3396  loss_box_reg: 0.5384  loss_mask: 0.3154  loss_rpn_cls: 0.08082  loss_rpn_loc: 0.195  time: 0.5887  data_time: 0.2689  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:29:38 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 1339  total_loss: 1.56  loss_cls: 0.3361  loss_box_reg: 0.5344  loss_mask: 0.3199  loss_rpn_cls: 0.09522  loss_rpn_loc: 0.2113  time: 0.5883  data_time: 0.2396  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:29:47 d2.utils.events]: \u001b[0m eta: 0:47:50  iter: 1359  total_loss: 1.481  loss_cls: 0.3383  loss_box_reg: 0.5345  loss_mask: 0.3141  loss_rpn_cls: 0.09643  loss_rpn_loc: 0.2013  time: 0.5864  data_time: 0.1686  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:29:56 d2.utils.events]: \u001b[0m eta: 0:47:43  iter: 1379  total_loss: 1.615  loss_cls: 0.3801  loss_box_reg: 0.5714  loss_mask: 0.3066  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.2109  time: 0.5846  data_time: 0.1542  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:30:06 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 1399  total_loss: 1.507  loss_cls: 0.3356  loss_box_reg: 0.5363  loss_mask: 0.3057  loss_rpn_cls: 0.0877  loss_rpn_loc: 0.2172  time: 0.5834  data_time: 0.1824  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:30:17 d2.utils.events]: \u001b[0m eta: 0:47:32  iter: 1419  total_loss: 1.418  loss_cls: 0.3119  loss_box_reg: 0.5018  loss_mask: 0.2962  loss_rpn_cls: 0.07611  loss_rpn_loc: 0.1992  time: 0.5825  data_time: 0.2219  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:30:29 d2.utils.events]: \u001b[0m eta: 0:47:22  iter: 1439  total_loss: 1.492  loss_cls: 0.3529  loss_box_reg: 0.5325  loss_mask: 0.3107  loss_rpn_cls: 0.08779  loss_rpn_loc: 0.2173  time: 0.5827  data_time: 0.2749  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:30:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:30:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:30:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:30:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:30:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:30:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0690 s/iter. Eval: 0.0360 s/iter. Total: 0.1055 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 19:30:42 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0480 s/iter. Total: 0.1201 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/02 19:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0490 s/iter. Total: 0.1209 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/02 19:30:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.769657 (0.118704 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:30:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070628 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:30:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:30:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2437945865881262\n",
      "\u001b[32m[02/02 19:30:56 d2.utils.events]: \u001b[0m eta: 0:47:17  iter: 1459  total_loss: 1.506  loss_cls: 0.3447  loss_box_reg: 0.539  loss_mask: 0.2995  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.1996  time: 0.5831  data_time: 0.2866  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:31:04 d2.utils.events]: \u001b[0m eta: 0:47:04  iter: 1479  total_loss: 1.494  loss_cls: 0.3382  loss_box_reg: 0.5497  loss_mask: 0.3053  loss_rpn_cls: 0.07022  loss_rpn_loc: 0.1864  time: 0.5805  data_time: 0.1019  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:31:19 d2.utils.events]: \u001b[0m eta: 0:47:01  iter: 1499  total_loss: 1.481  loss_cls: 0.35  loss_box_reg: 0.5246  loss_mask: 0.3184  loss_rpn_cls: 0.09126  loss_rpn_loc: 0.2194  time: 0.5826  data_time: 0.4116  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:31:29 d2.utils.events]: \u001b[0m eta: 0:46:56  iter: 1519  total_loss: 1.609  loss_cls: 0.3635  loss_box_reg: 0.5969  loss_mask: 0.3294  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.2301  time: 0.5820  data_time: 0.2250  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:31:41 d2.utils.events]: \u001b[0m eta: 0:46:50  iter: 1539  total_loss: 1.489  loss_cls: 0.3446  loss_box_reg: 0.5711  loss_mask: 0.3058  loss_rpn_cls: 0.09861  loss_rpn_loc: 0.2045  time: 0.5822  data_time: 0.2822  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:31:50 d2.utils.events]: \u001b[0m eta: 0:46:41  iter: 1559  total_loss: 1.437  loss_cls: 0.3068  loss_box_reg: 0.5233  loss_mask: 0.3117  loss_rpn_cls: 0.08948  loss_rpn_loc: 0.1918  time: 0.5804  data_time: 0.1397  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:32:03 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 1579  total_loss: 1.455  loss_cls: 0.3359  loss_box_reg: 0.5184  loss_mask: 0.29  loss_rpn_cls: 0.0942  loss_rpn_loc: 0.2054  time: 0.5813  data_time: 0.3424  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:32:18 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 1599  total_loss: 1.509  loss_cls: 0.3532  loss_box_reg: 0.5321  loss_mask: 0.308  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2077  time: 0.5836  data_time: 0.4429  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:32:31 d2.utils.events]: \u001b[0m eta: 0:46:23  iter: 1619  total_loss: 1.444  loss_cls: 0.3347  loss_box_reg: 0.4918  loss_mask: 0.3009  loss_rpn_cls: 0.08907  loss_rpn_loc: 0.1896  time: 0.5842  data_time: 0.3155  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:32:42 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 1639  total_loss: 1.416  loss_cls: 0.3074  loss_box_reg: 0.5176  loss_mask: 0.3035  loss_rpn_cls: 0.07318  loss_rpn_loc: 0.1751  time: 0.5837  data_time: 0.2434  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:32:53 d2.utils.events]: \u001b[0m eta: 0:46:01  iter: 1659  total_loss: 1.5  loss_cls: 0.3308  loss_box_reg: 0.5335  loss_mask: 0.3003  loss_rpn_cls: 0.08658  loss_rpn_loc: 0.2275  time: 0.5832  data_time: 0.2394  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:33:08 d2.utils.events]: \u001b[0m eta: 0:46:00  iter: 1679  total_loss: 1.412  loss_cls: 0.3433  loss_box_reg: 0.5072  loss_mask: 0.294  loss_rpn_cls: 0.08267  loss_rpn_loc: 0.1962  time: 0.5851  data_time: 0.4003  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:33:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:33:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:33:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:33:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:33:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:33:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0749 s/iter. Eval: 0.0397 s/iter. Total: 0.1152 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 19:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0738 s/iter. Eval: 0.0563 s/iter. Total: 0.1310 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0573 s/iter. Total: 0.1307 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 19:33:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.024168 (0.129519 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:33:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072466 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:33:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:33:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2511702556844774\n",
      "\u001b[32m[02/02 19:33:36 d2.utils.events]: \u001b[0m eta: 0:45:55  iter: 1699  total_loss: 1.532  loss_cls: 0.3534  loss_box_reg: 0.5608  loss_mask: 0.308  loss_rpn_cls: 0.09387  loss_rpn_loc: 0.1916  time: 0.5850  data_time: 0.2592  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:33:48 d2.utils.events]: \u001b[0m eta: 0:45:45  iter: 1719  total_loss: 1.557  loss_cls: 0.3521  loss_box_reg: 0.5393  loss_mask: 0.3156  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2191  time: 0.5855  data_time: 0.3157  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:34:02 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 1739  total_loss: 1.437  loss_cls: 0.3499  loss_box_reg: 0.5205  loss_mask: 0.3015  loss_rpn_cls: 0.08298  loss_rpn_loc: 0.2141  time: 0.5868  data_time: 0.3767  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:34:12 d2.utils.events]: \u001b[0m eta: 0:45:37  iter: 1759  total_loss: 1.392  loss_cls: 0.301  loss_box_reg: 0.4804  loss_mask: 0.2957  loss_rpn_cls: 0.06338  loss_rpn_loc: 0.1704  time: 0.5859  data_time: 0.1775  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:34:24 d2.utils.events]: \u001b[0m eta: 0:45:30  iter: 1779  total_loss: 1.493  loss_cls: 0.3517  loss_box_reg: 0.5214  loss_mask: 0.3122  loss_rpn_cls: 0.07678  loss_rpn_loc: 0.2043  time: 0.5857  data_time: 0.2565  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:34:40 d2.utils.events]: \u001b[0m eta: 0:45:32  iter: 1799  total_loss: 1.53  loss_cls: 0.3483  loss_box_reg: 0.5247  loss_mask: 0.3131  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.208  time: 0.5881  data_time: 0.4577  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:34:49 d2.utils.events]: \u001b[0m eta: 0:45:26  iter: 1819  total_loss: 1.461  loss_cls: 0.3343  loss_box_reg: 0.5482  loss_mask: 0.3061  loss_rpn_cls: 0.07326  loss_rpn_loc: 0.1953  time: 0.5865  data_time: 0.1415  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:34:59 d2.utils.events]: \u001b[0m eta: 0:45:20  iter: 1839  total_loss: 1.57  loss_cls: 0.3754  loss_box_reg: 0.5466  loss_mask: 0.3058  loss_rpn_cls: 0.08743  loss_rpn_loc: 0.2099  time: 0.5860  data_time: 0.2238  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:35:10 d2.utils.events]: \u001b[0m eta: 0:45:13  iter: 1859  total_loss: 1.496  loss_cls: 0.3542  loss_box_reg: 0.5651  loss_mask: 0.3101  loss_rpn_cls: 0.08443  loss_rpn_loc: 0.2012  time: 0.5854  data_time: 0.2183  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:35:21 d2.utils.events]: \u001b[0m eta: 0:45:04  iter: 1879  total_loss: 1.479  loss_cls: 0.3135  loss_box_reg: 0.5163  loss_mask: 0.287  loss_rpn_cls: 0.08343  loss_rpn_loc: 0.1989  time: 0.5848  data_time: 0.2239  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:35:38 d2.utils.events]: \u001b[0m eta: 0:45:00  iter: 1899  total_loss: 1.531  loss_cls: 0.3417  loss_box_reg: 0.5037  loss_mask: 0.3031  loss_rpn_cls: 0.09399  loss_rpn_loc: 0.2101  time: 0.5878  data_time: 0.5244  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:35:49 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 1919  total_loss: 1.476  loss_cls: 0.339  loss_box_reg: 0.5352  loss_mask: 0.2796  loss_rpn_cls: 0.07677  loss_rpn_loc: 0.1936  time: 0.5876  data_time: 0.2554  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:35:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:35:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:35:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:35:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:35:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:35:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0731 s/iter. Eval: 0.0533 s/iter. Total: 0.1271 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 19:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0727 s/iter. Eval: 0.0628 s/iter. Total: 0.1363 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0731 s/iter. Eval: 0.0638 s/iter. Total: 0.1376 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 19:36:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.733746 (0.135636 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:36:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073158 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:36:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:36:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2591339182288293\n",
      "\u001b[32m[02/02 19:36:18 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 1939  total_loss: 1.469  loss_cls: 0.3091  loss_box_reg: 0.5021  loss_mask: 0.307  loss_rpn_cls: 0.0779  loss_rpn_loc: 0.1939  time: 0.5873  data_time: 0.2317  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:36:29 d2.utils.events]: \u001b[0m eta: 0:44:41  iter: 1959  total_loss: 1.535  loss_cls: 0.3645  loss_box_reg: 0.5542  loss_mask: 0.3132  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.2083  time: 0.5871  data_time: 0.2640  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:36:39 d2.utils.events]: \u001b[0m eta: 0:44:31  iter: 1979  total_loss: 1.446  loss_cls: 0.3407  loss_box_reg: 0.525  loss_mask: 0.2845  loss_rpn_cls: 0.07238  loss_rpn_loc: 0.1912  time: 0.5858  data_time: 0.1527  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:36:49 d2.utils.events]: \u001b[0m eta: 0:44:23  iter: 1999  total_loss: 1.382  loss_cls: 0.329  loss_box_reg: 0.5344  loss_mask: 0.2938  loss_rpn_cls: 0.08024  loss_rpn_loc: 0.181  time: 0.5852  data_time: 0.2174  lr: 0.0005  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:37:02 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 2019  total_loss: 1.424  loss_cls: 0.319  loss_box_reg: 0.5139  loss_mask: 0.3066  loss_rpn_cls: 0.07993  loss_rpn_loc: 0.2074  time: 0.5859  data_time: 0.3197  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:37:15 d2.utils.events]: \u001b[0m eta: 0:44:11  iter: 2039  total_loss: 1.511  loss_cls: 0.3668  loss_box_reg: 0.5374  loss_mask: 0.3108  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.1961  time: 0.5866  data_time: 0.3290  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:37:28 d2.utils.events]: \u001b[0m eta: 0:44:06  iter: 2059  total_loss: 1.39  loss_cls: 0.3311  loss_box_reg: 0.4724  loss_mask: 0.2914  loss_rpn_cls: 0.08245  loss_rpn_loc: 0.19  time: 0.5869  data_time: 0.2786  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:37:40 d2.utils.events]: \u001b[0m eta: 0:43:57  iter: 2079  total_loss: 1.512  loss_cls: 0.3312  loss_box_reg: 0.5323  loss_mask: 0.3121  loss_rpn_cls: 0.08105  loss_rpn_loc: 0.1996  time: 0.5874  data_time: 0.3120  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:37:54 d2.utils.events]: \u001b[0m eta: 0:43:53  iter: 2099  total_loss: 1.437  loss_cls: 0.3377  loss_box_reg: 0.5379  loss_mask: 0.306  loss_rpn_cls: 0.08416  loss_rpn_loc: 0.1975  time: 0.5880  data_time: 0.3360  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:38:02 d2.utils.events]: \u001b[0m eta: 0:43:51  iter: 2119  total_loss: 1.45  loss_cls: 0.3322  loss_box_reg: 0.5445  loss_mask: 0.3107  loss_rpn_cls: 0.07808  loss_rpn_loc: 0.2083  time: 0.5864  data_time: 0.1077  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:38:15 d2.utils.events]: \u001b[0m eta: 0:43:41  iter: 2139  total_loss: 1.476  loss_cls: 0.3329  loss_box_reg: 0.5305  loss_mask: 0.3055  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.193  time: 0.5870  data_time: 0.3097  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:38:26 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 2159  total_loss: 1.453  loss_cls: 0.3203  loss_box_reg: 0.5415  loss_mask: 0.3188  loss_rpn_cls: 0.0878  loss_rpn_loc: 0.2063  time: 0.5869  data_time: 0.2628  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:38:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:38:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:38:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:38:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:38:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:38:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0693 s/iter. Eval: 0.0399 s/iter. Total: 0.1098 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 19:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0755 s/iter. Eval: 0.0589 s/iter. Total: 0.1353 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 19:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0739 s/iter. Eval: 0.0602 s/iter. Total: 0.1349 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 19:38:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.288615 (0.131798 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:38:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072850 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:38:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:38:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2574899825943214\n",
      "\u001b[32m[02/02 19:38:57 d2.utils.events]: \u001b[0m eta: 0:43:32  iter: 2179  total_loss: 1.314  loss_cls: 0.2828  loss_box_reg: 0.5111  loss_mask: 0.2974  loss_rpn_cls: 0.08531  loss_rpn_loc: 0.1867  time: 0.5877  data_time: 0.3481  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:39:11 d2.utils.events]: \u001b[0m eta: 0:43:24  iter: 2199  total_loss: 1.472  loss_cls: 0.3407  loss_box_reg: 0.4921  loss_mask: 0.3111  loss_rpn_cls: 0.07074  loss_rpn_loc: 0.1852  time: 0.5890  data_time: 0.4055  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:39:24 d2.utils.events]: \u001b[0m eta: 0:43:19  iter: 2219  total_loss: 1.361  loss_cls: 0.2902  loss_box_reg: 0.4894  loss_mask: 0.2882  loss_rpn_cls: 0.07051  loss_rpn_loc: 0.1972  time: 0.5894  data_time: 0.3025  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:39:34 d2.utils.events]: \u001b[0m eta: 0:43:14  iter: 2239  total_loss: 1.601  loss_cls: 0.3752  loss_box_reg: 0.5956  loss_mask: 0.3126  loss_rpn_cls: 0.08705  loss_rpn_loc: 0.2155  time: 0.5885  data_time: 0.1733  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:39:46 d2.utils.events]: \u001b[0m eta: 0:43:10  iter: 2259  total_loss: 1.545  loss_cls: 0.3928  loss_box_reg: 0.5138  loss_mask: 0.3188  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.1969  time: 0.5887  data_time: 0.2694  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:39:57 d2.utils.events]: \u001b[0m eta: 0:42:54  iter: 2279  total_loss: 1.293  loss_cls: 0.2815  loss_box_reg: 0.4949  loss_mask: 0.3068  loss_rpn_cls: 0.046  loss_rpn_loc: 0.1766  time: 0.5885  data_time: 0.2484  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:40:11 d2.utils.events]: \u001b[0m eta: 0:42:48  iter: 2299  total_loss: 1.443  loss_cls: 0.3211  loss_box_reg: 0.5182  loss_mask: 0.3017  loss_rpn_cls: 0.08865  loss_rpn_loc: 0.2036  time: 0.5892  data_time: 0.3382  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:40:25 d2.utils.events]: \u001b[0m eta: 0:42:41  iter: 2319  total_loss: 1.364  loss_cls: 0.3509  loss_box_reg: 0.4773  loss_mask: 0.2942  loss_rpn_cls: 0.08173  loss_rpn_loc: 0.2  time: 0.5900  data_time: 0.3586  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:40:34 d2.utils.events]: \u001b[0m eta: 0:42:33  iter: 2339  total_loss: 1.389  loss_cls: 0.3331  loss_box_reg: 0.5514  loss_mask: 0.2939  loss_rpn_cls: 0.0666  loss_rpn_loc: 0.1799  time: 0.5889  data_time: 0.1521  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:40:45 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 2359  total_loss: 1.498  loss_cls: 0.3631  loss_box_reg: 0.5219  loss_mask: 0.2954  loss_rpn_cls: 0.08185  loss_rpn_loc: 0.199  time: 0.5885  data_time: 0.2193  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:40:57 d2.utils.events]: \u001b[0m eta: 0:42:25  iter: 2379  total_loss: 1.325  loss_cls: 0.2947  loss_box_reg: 0.4664  loss_mask: 0.2919  loss_rpn_cls: 0.08264  loss_rpn_loc: 0.1908  time: 0.5888  data_time: 0.2994  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:41:08 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 2399  total_loss: 1.466  loss_cls: 0.3524  loss_box_reg: 0.5166  loss_mask: 0.2949  loss_rpn_cls: 0.08931  loss_rpn_loc: 0.1927  time: 0.5887  data_time: 0.2312  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:41:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:41:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:41:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:41:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:41:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:41:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0723 s/iter. Eval: 0.0441 s/iter. Total: 0.1171 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 19:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0741 s/iter. Eval: 0.0588 s/iter. Total: 0.1337 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:41:31 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0615 s/iter. Total: 0.1369 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 19:41:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.541334 (0.133977 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:41:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073699 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:41:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:41:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2574322562077873\n",
      "\u001b[32m[02/02 19:41:36 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 2419  total_loss: 1.452  loss_cls: 0.2996  loss_box_reg: 0.5472  loss_mask: 0.315  loss_rpn_cls: 0.07206  loss_rpn_loc: 0.2007  time: 0.5880  data_time: 0.1941  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:41:46 d2.utils.events]: \u001b[0m eta: 0:42:18  iter: 2439  total_loss: 1.48  loss_cls: 0.3599  loss_box_reg: 0.5255  loss_mask: 0.3085  loss_rpn_cls: 0.07923  loss_rpn_loc: 0.21  time: 0.5876  data_time: 0.2045  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:41:59 d2.utils.events]: \u001b[0m eta: 0:42:12  iter: 2459  total_loss: 1.391  loss_cls: 0.3148  loss_box_reg: 0.4679  loss_mask: 0.2915  loss_rpn_cls: 0.08167  loss_rpn_loc: 0.208  time: 0.5881  data_time: 0.3301  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:42:12 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 2479  total_loss: 1.434  loss_cls: 0.3693  loss_box_reg: 0.5065  loss_mask: 0.3081  loss_rpn_cls: 0.07977  loss_rpn_loc: 0.2027  time: 0.5884  data_time: 0.3071  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:42:24 d2.utils.events]: \u001b[0m eta: 0:42:05  iter: 2499  total_loss: 1.399  loss_cls: 0.2814  loss_box_reg: 0.5004  loss_mask: 0.2852  loss_rpn_cls: 0.08636  loss_rpn_loc: 0.1927  time: 0.5886  data_time: 0.3069  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:42:35 d2.utils.events]: \u001b[0m eta: 0:41:59  iter: 2519  total_loss: 1.498  loss_cls: 0.3485  loss_box_reg: 0.4816  loss_mask: 0.2909  loss_rpn_cls: 0.08525  loss_rpn_loc: 0.1909  time: 0.5881  data_time: 0.2099  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:42:44 d2.utils.events]: \u001b[0m eta: 0:41:45  iter: 2539  total_loss: 1.398  loss_cls: 0.2984  loss_box_reg: 0.5337  loss_mask: 0.2848  loss_rpn_cls: 0.07053  loss_rpn_loc: 0.19  time: 0.5869  data_time: 0.1334  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:42:52 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 2559  total_loss: 1.517  loss_cls: 0.3688  loss_box_reg: 0.5219  loss_mask: 0.2927  loss_rpn_cls: 0.07753  loss_rpn_loc: 0.2035  time: 0.5857  data_time: 0.1244  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:43:05 d2.utils.events]: \u001b[0m eta: 0:41:30  iter: 2579  total_loss: 1.328  loss_cls: 0.2873  loss_box_reg: 0.4879  loss_mask: 0.2955  loss_rpn_cls: 0.07134  loss_rpn_loc: 0.1853  time: 0.5860  data_time: 0.3100  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:43:15 d2.utils.events]: \u001b[0m eta: 0:41:16  iter: 2599  total_loss: 1.483  loss_cls: 0.3256  loss_box_reg: 0.5426  loss_mask: 0.313  loss_rpn_cls: 0.07322  loss_rpn_loc: 0.2076  time: 0.5856  data_time: 0.2211  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:43:31 d2.utils.events]: \u001b[0m eta: 0:41:17  iter: 2619  total_loss: 1.449  loss_cls: 0.3302  loss_box_reg: 0.4721  loss_mask: 0.3078  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.2001  time: 0.5871  data_time: 0.4499  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:43:40 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 2639  total_loss: 1.446  loss_cls: 0.3348  loss_box_reg: 0.5498  loss_mask: 0.3319  loss_rpn_cls: 0.07362  loss_rpn_loc: 0.1904  time: 0.5861  data_time: 0.1354  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:43:53 d2.utils.events]: \u001b[0m eta: 0:41:03  iter: 2659  total_loss: 1.4  loss_cls: 0.3445  loss_box_reg: 0.5044  loss_mask: 0.3112  loss_rpn_cls: 0.09548  loss_rpn_loc: 0.2048  time: 0.5865  data_time: 0.3112  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:43:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:43:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:43:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:43:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:43:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:43:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:43:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0687 s/iter. Eval: 0.0422 s/iter. Total: 0.1115 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 19:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0568 s/iter. Total: 0.1288 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0596 s/iter. Total: 0.1322 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 19:44:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.146897 (0.130577 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:44:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071486 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:44:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:44:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26042840758224084\n",
      "\u001b[32m[02/02 19:44:20 d2.utils.events]: \u001b[0m eta: 0:40:48  iter: 2679  total_loss: 1.318  loss_cls: 0.2732  loss_box_reg: 0.4697  loss_mask: 0.2921  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1993  time: 0.5861  data_time: 0.2186  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:44:31 d2.utils.events]: \u001b[0m eta: 0:40:39  iter: 2699  total_loss: 1.294  loss_cls: 0.2402  loss_box_reg: 0.5156  loss_mask: 0.2882  loss_rpn_cls: 0.06638  loss_rpn_loc: 0.1737  time: 0.5856  data_time: 0.2214  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:44:43 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 2719  total_loss: 1.372  loss_cls: 0.3074  loss_box_reg: 0.5234  loss_mask: 0.2992  loss_rpn_cls: 0.07213  loss_rpn_loc: 0.1956  time: 0.5857  data_time: 0.2910  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:44:54 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 2739  total_loss: 1.425  loss_cls: 0.324  loss_box_reg: 0.5115  loss_mask: 0.2958  loss_rpn_cls: 0.07401  loss_rpn_loc: 0.2104  time: 0.5856  data_time: 0.2641  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:45:05 d2.utils.events]: \u001b[0m eta: 0:40:19  iter: 2759  total_loss: 1.475  loss_cls: 0.3456  loss_box_reg: 0.5033  loss_mask: 0.288  loss_rpn_cls: 0.05681  loss_rpn_loc: 0.2005  time: 0.5853  data_time: 0.2186  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:45:16 d2.utils.events]: \u001b[0m eta: 0:40:13  iter: 2779  total_loss: 1.479  loss_cls: 0.3432  loss_box_reg: 0.5181  loss_mask: 0.2967  loss_rpn_cls: 0.07755  loss_rpn_loc: 0.1962  time: 0.5851  data_time: 0.2268  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:45:30 d2.utils.events]: \u001b[0m eta: 0:40:05  iter: 2799  total_loss: 1.448  loss_cls: 0.3085  loss_box_reg: 0.4851  loss_mask: 0.3265  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.2137  time: 0.5858  data_time: 0.3601  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:45:41 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 2819  total_loss: 1.483  loss_cls: 0.3287  loss_box_reg: 0.5249  loss_mask: 0.3064  loss_rpn_cls: 0.07505  loss_rpn_loc: 0.2025  time: 0.5858  data_time: 0.2546  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:45:56 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 2839  total_loss: 1.459  loss_cls: 0.3111  loss_box_reg: 0.5202  loss_mask: 0.2981  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2051  time: 0.5867  data_time: 0.3779  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:46:05 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 2859  total_loss: 1.44  loss_cls: 0.2942  loss_box_reg: 0.5243  loss_mask: 0.3133  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.1949  time: 0.5859  data_time: 0.1622  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:46:18 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 2879  total_loss: 1.497  loss_cls: 0.3506  loss_box_reg: 0.5436  loss_mask: 0.3066  loss_rpn_cls: 0.09454  loss_rpn_loc: 0.2002  time: 0.5862  data_time: 0.2987  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:46:28 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 2899  total_loss: 1.521  loss_cls: 0.3572  loss_box_reg: 0.5899  loss_mask: 0.287  loss_rpn_cls: 0.08203  loss_rpn_loc: 0.1878  time: 0.5857  data_time: 0.2100  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:46:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:46:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:46:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:46:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:46:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:46:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:46:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0729 s/iter. Eval: 0.0409 s/iter. Total: 0.1144 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 19:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0566 s/iter. Total: 0.1300 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0731 s/iter. Eval: 0.0613 s/iter. Total: 0.1352 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 19:46:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.484835 (0.133490 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:46:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073264 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:46:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:46:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2610145478840859\n",
      "\u001b[32m[02/02 19:46:57 d2.utils.events]: \u001b[0m eta: 0:39:31  iter: 2919  total_loss: 1.31  loss_cls: 0.2873  loss_box_reg: 0.504  loss_mask: 0.2971  loss_rpn_cls: 0.0789  loss_rpn_loc: 0.1954  time: 0.5858  data_time: 0.2731  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:47:07 d2.utils.events]: \u001b[0m eta: 0:39:29  iter: 2939  total_loss: 1.386  loss_cls: 0.3142  loss_box_reg: 0.4834  loss_mask: 0.3079  loss_rpn_cls: 0.08268  loss_rpn_loc: 0.2034  time: 0.5853  data_time: 0.1973  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:47:17 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 2959  total_loss: 1.397  loss_cls: 0.3099  loss_box_reg: 0.5154  loss_mask: 0.2821  loss_rpn_cls: 0.08221  loss_rpn_loc: 0.1812  time: 0.5848  data_time: 0.1892  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:47:30 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 2979  total_loss: 1.411  loss_cls: 0.3475  loss_box_reg: 0.4894  loss_mask: 0.293  loss_rpn_cls: 0.07101  loss_rpn_loc: 0.1981  time: 0.5849  data_time: 0.2855  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:47:43 d2.utils.events]: \u001b[0m eta: 0:39:32  iter: 2999  total_loss: 1.436  loss_cls: 0.3547  loss_box_reg: 0.4926  loss_mask: 0.3064  loss_rpn_cls: 0.09544  loss_rpn_loc: 0.2061  time: 0.5856  data_time: 0.3525  lr: 5e-05  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:47:55 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 3019  total_loss: 1.485  loss_cls: 0.3333  loss_box_reg: 0.5721  loss_mask: 0.3224  loss_rpn_cls: 0.07776  loss_rpn_loc: 0.197  time: 0.5855  data_time: 0.2534  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:48:09 d2.utils.events]: \u001b[0m eta: 0:39:27  iter: 3039  total_loss: 1.35  loss_cls: 0.3179  loss_box_reg: 0.4781  loss_mask: 0.2891  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1757  time: 0.5864  data_time: 0.3916  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:48:22 d2.utils.events]: \u001b[0m eta: 0:39:20  iter: 3059  total_loss: 1.428  loss_cls: 0.336  loss_box_reg: 0.4916  loss_mask: 0.2917  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.2112  time: 0.5866  data_time: 0.2957  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:48:32 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 3079  total_loss: 1.461  loss_cls: 0.322  loss_box_reg: 0.4907  loss_mask: 0.2875  loss_rpn_cls: 0.08657  loss_rpn_loc: 0.1955  time: 0.5863  data_time: 0.2201  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:48:42 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 3099  total_loss: 1.368  loss_cls: 0.3103  loss_box_reg: 0.5146  loss_mask: 0.2957  loss_rpn_cls: 0.06265  loss_rpn_loc: 0.1763  time: 0.5856  data_time: 0.1734  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:48:54 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 3119  total_loss: 1.432  loss_cls: 0.3133  loss_box_reg: 0.5297  loss_mask: 0.3154  loss_rpn_cls: 0.08281  loss_rpn_loc: 0.1841  time: 0.5856  data_time: 0.2840  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:49:09 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 3139  total_loss: 1.457  loss_cls: 0.3353  loss_box_reg: 0.5023  loss_mask: 0.3132  loss_rpn_cls: 0.106  loss_rpn_loc: 0.211  time: 0.5869  data_time: 0.4585  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:49:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:49:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:49:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:49:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.0403 s/iter. Total: 0.1093 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 19:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0555 s/iter. Total: 0.1272 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:49:24 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0723 s/iter. Eval: 0.0609 s/iter. Total: 0.1341 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 19:49:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.259252 (0.131545 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:49:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072061 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:49:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:49:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26106408293023403\n",
      "\u001b[32m[02/02 19:49:38 d2.utils.events]: \u001b[0m eta: 0:38:33  iter: 3159  total_loss: 1.417  loss_cls: 0.3249  loss_box_reg: 0.5385  loss_mask: 0.3019  loss_rpn_cls: 0.07157  loss_rpn_loc: 0.1967  time: 0.5868  data_time: 0.2555  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:49:49 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 3179  total_loss: 1.453  loss_cls: 0.3526  loss_box_reg: 0.519  loss_mask: 0.3151  loss_rpn_cls: 0.07826  loss_rpn_loc: 0.1841  time: 0.5867  data_time: 0.2535  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:50:02 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 3199  total_loss: 1.372  loss_cls: 0.3204  loss_box_reg: 0.4767  loss_mask: 0.2901  loss_rpn_cls: 0.08503  loss_rpn_loc: 0.1893  time: 0.5872  data_time: 0.3287  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:50:12 d2.utils.events]: \u001b[0m eta: 0:38:20  iter: 3219  total_loss: 1.364  loss_cls: 0.3241  loss_box_reg: 0.4936  loss_mask: 0.2903  loss_rpn_cls: 0.08117  loss_rpn_loc: 0.1809  time: 0.5865  data_time: 0.1806  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:50:28 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 3239  total_loss: 1.445  loss_cls: 0.3584  loss_box_reg: 0.5218  loss_mask: 0.3061  loss_rpn_cls: 0.09375  loss_rpn_loc: 0.1956  time: 0.5878  data_time: 0.4677  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:50:40 d2.utils.events]: \u001b[0m eta: 0:38:04  iter: 3259  total_loss: 1.416  loss_cls: 0.3447  loss_box_reg: 0.4979  loss_mask: 0.2907  loss_rpn_cls: 0.07411  loss_rpn_loc: 0.208  time: 0.5879  data_time: 0.2919  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:50:52 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 3279  total_loss: 1.418  loss_cls: 0.3343  loss_box_reg: 0.5053  loss_mask: 0.3056  loss_rpn_cls: 0.07373  loss_rpn_loc: 0.1754  time: 0.5878  data_time: 0.2703  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:51:04 d2.utils.events]: \u001b[0m eta: 0:37:51  iter: 3299  total_loss: 1.392  loss_cls: 0.3206  loss_box_reg: 0.4949  loss_mask: 0.315  loss_rpn_cls: 0.07685  loss_rpn_loc: 0.184  time: 0.5879  data_time: 0.2904  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:51:15 d2.utils.events]: \u001b[0m eta: 0:37:42  iter: 3319  total_loss: 1.296  loss_cls: 0.2932  loss_box_reg: 0.4981  loss_mask: 0.305  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.1762  time: 0.5877  data_time: 0.2478  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:51:29 d2.utils.events]: \u001b[0m eta: 0:37:41  iter: 3339  total_loss: 1.508  loss_cls: 0.3658  loss_box_reg: 0.5135  loss_mask: 0.3162  loss_rpn_cls: 0.09528  loss_rpn_loc: 0.2104  time: 0.5884  data_time: 0.3669  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:51:42 d2.utils.events]: \u001b[0m eta: 0:37:39  iter: 3359  total_loss: 1.414  loss_cls: 0.3442  loss_box_reg: 0.5067  loss_mask: 0.312  loss_rpn_cls: 0.09238  loss_rpn_loc: 0.2042  time: 0.5889  data_time: 0.3427  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:51:50 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 3379  total_loss: 1.478  loss_cls: 0.3249  loss_box_reg: 0.5737  loss_mask: 0.2919  loss_rpn_cls: 0.07661  loss_rpn_loc: 0.2008  time: 0.5878  data_time: 0.1143  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:51:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:51:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:51:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:51:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:51:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:51:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0689 s/iter. Eval: 0.0413 s/iter. Total: 0.1108 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 19:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0565 s/iter. Total: 0.1286 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0592 s/iter. Total: 0.1317 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 19:52:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.098205 (0.130157 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:52:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071366 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:52:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:52:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2614605129083461\n",
      "\u001b[32m[02/02 19:52:22 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 3399  total_loss: 1.533  loss_cls: 0.3685  loss_box_reg: 0.5343  loss_mask: 0.304  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.2303  time: 0.5887  data_time: 0.4098  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:52:36 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 3419  total_loss: 1.508  loss_cls: 0.3394  loss_box_reg: 0.503  loss_mask: 0.3097  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2331  time: 0.5894  data_time: 0.4012  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:52:49 d2.utils.events]: \u001b[0m eta: 0:37:12  iter: 3439  total_loss: 1.37  loss_cls: 0.3215  loss_box_reg: 0.4898  loss_mask: 0.3029  loss_rpn_cls: 0.0638  loss_rpn_loc: 0.1864  time: 0.5897  data_time: 0.3150  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:53:02 d2.utils.events]: \u001b[0m eta: 0:37:08  iter: 3459  total_loss: 1.445  loss_cls: 0.3673  loss_box_reg: 0.5232  loss_mask: 0.2887  loss_rpn_cls: 0.0973  loss_rpn_loc: 0.1841  time: 0.5903  data_time: 0.3584  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:53:13 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 3479  total_loss: 1.397  loss_cls: 0.3154  loss_box_reg: 0.4866  loss_mask: 0.2918  loss_rpn_cls: 0.08226  loss_rpn_loc: 0.1837  time: 0.5899  data_time: 0.2207  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:53:22 d2.utils.events]: \u001b[0m eta: 0:36:48  iter: 3499  total_loss: 1.31  loss_cls: 0.3132  loss_box_reg: 0.4862  loss_mask: 0.2785  loss_rpn_cls: 0.06804  loss_rpn_loc: 0.1731  time: 0.5892  data_time: 0.1551  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:53:32 d2.utils.events]: \u001b[0m eta: 0:36:38  iter: 3519  total_loss: 1.437  loss_cls: 0.3013  loss_box_reg: 0.5055  loss_mask: 0.3027  loss_rpn_cls: 0.06906  loss_rpn_loc: 0.1921  time: 0.5886  data_time: 0.1837  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:53:43 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 3539  total_loss: 1.438  loss_cls: 0.3274  loss_box_reg: 0.5342  loss_mask: 0.2978  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.1801  time: 0.5884  data_time: 0.2457  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:53:55 d2.utils.events]: \u001b[0m eta: 0:36:32  iter: 3559  total_loss: 1.494  loss_cls: 0.3584  loss_box_reg: 0.5028  loss_mask: 0.3028  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.202  time: 0.5884  data_time: 0.2752  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:54:08 d2.utils.events]: \u001b[0m eta: 0:36:24  iter: 3579  total_loss: 1.394  loss_cls: 0.3046  loss_box_reg: 0.5173  loss_mask: 0.2997  loss_rpn_cls: 0.05814  loss_rpn_loc: 0.1904  time: 0.5887  data_time: 0.3230  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:54:22 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 3599  total_loss: 1.469  loss_cls: 0.348  loss_box_reg: 0.5025  loss_mask: 0.3093  loss_rpn_cls: 0.09538  loss_rpn_loc: 0.2328  time: 0.5894  data_time: 0.3903  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:54:31 d2.utils.events]: \u001b[0m eta: 0:36:09  iter: 3619  total_loss: 1.44  loss_cls: 0.3429  loss_box_reg: 0.5096  loss_mask: 0.313  loss_rpn_cls: 0.082  loss_rpn_loc: 0.1939  time: 0.5888  data_time: 0.1759  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:54:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:54:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:54:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:54:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:54:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:54:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0684 s/iter. Eval: 0.0398 s/iter. Total: 0.1089 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 19:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0558 s/iter. Total: 0.1279 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0588 s/iter. Total: 0.1313 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 19:54:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.031717 (0.129584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:54:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071397 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:54:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:54:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26072909427348245\n",
      "\u001b[32m[02/02 19:54:59 d2.utils.events]: \u001b[0m eta: 0:36:03  iter: 3639  total_loss: 1.492  loss_cls: 0.3501  loss_box_reg: 0.5293  loss_mask: 0.2984  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.1915  time: 0.5885  data_time: 0.2507  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:55:10 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 3659  total_loss: 1.351  loss_cls: 0.3305  loss_box_reg: 0.5242  loss_mask: 0.297  loss_rpn_cls: 0.08023  loss_rpn_loc: 0.1878  time: 0.5884  data_time: 0.2594  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:55:19 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 3679  total_loss: 1.412  loss_cls: 0.3105  loss_box_reg: 0.5326  loss_mask: 0.3027  loss_rpn_cls: 0.07631  loss_rpn_loc: 0.1801  time: 0.5876  data_time: 0.1304  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:55:29 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 3699  total_loss: 1.467  loss_cls: 0.3143  loss_box_reg: 0.5405  loss_mask: 0.3001  loss_rpn_cls: 0.08654  loss_rpn_loc: 0.1931  time: 0.5872  data_time: 0.2132  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:55:43 d2.utils.events]: \u001b[0m eta: 0:35:33  iter: 3719  total_loss: 1.514  loss_cls: 0.387  loss_box_reg: 0.5044  loss_mask: 0.3169  loss_rpn_cls: 0.082  loss_rpn_loc: 0.2061  time: 0.5878  data_time: 0.3570  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:55:55 d2.utils.events]: \u001b[0m eta: 0:35:30  iter: 3739  total_loss: 1.386  loss_cls: 0.2866  loss_box_reg: 0.4828  loss_mask: 0.3087  loss_rpn_cls: 0.06918  loss_rpn_loc: 0.1757  time: 0.5877  data_time: 0.2671  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:56:08 d2.utils.events]: \u001b[0m eta: 0:35:24  iter: 3759  total_loss: 1.446  loss_cls: 0.3342  loss_box_reg: 0.5158  loss_mask: 0.3127  loss_rpn_cls: 0.0845  loss_rpn_loc: 0.1913  time: 0.5881  data_time: 0.3221  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:56:17 d2.utils.events]: \u001b[0m eta: 0:35:17  iter: 3779  total_loss: 1.464  loss_cls: 0.3381  loss_box_reg: 0.5183  loss_mask: 0.2898  loss_rpn_cls: 0.07216  loss_rpn_loc: 0.1761  time: 0.5874  data_time: 0.1461  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:56:28 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 3799  total_loss: 1.449  loss_cls: 0.3424  loss_box_reg: 0.5107  loss_mask: 0.3074  loss_rpn_cls: 0.08826  loss_rpn_loc: 0.2041  time: 0.5872  data_time: 0.2250  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:56:44 d2.utils.events]: \u001b[0m eta: 0:35:05  iter: 3819  total_loss: 1.498  loss_cls: 0.3297  loss_box_reg: 0.5272  loss_mask: 0.3133  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2047  time: 0.5883  data_time: 0.4663  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:56:52 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 3839  total_loss: 1.278  loss_cls: 0.2621  loss_box_reg: 0.4957  loss_mask: 0.2796  loss_rpn_cls: 0.04655  loss_rpn_loc: 0.1725  time: 0.5874  data_time: 0.1268  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:57:04 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 3859  total_loss: 1.433  loss_cls: 0.351  loss_box_reg: 0.4911  loss_mask: 0.2895  loss_rpn_cls: 0.0914  loss_rpn_loc: 0.1988  time: 0.5874  data_time: 0.2705  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:57:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:57:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:57:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:57:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:57:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:57:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0694 s/iter. Eval: 0.0474 s/iter. Total: 0.1175 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 19:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0574 s/iter. Total: 0.1293 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 19:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0716 s/iter. Eval: 0.0600 s/iter. Total: 0.1324 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 19:57:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.193704 (0.130980 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:57:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071426 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 19:57:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 19:57:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.260545248451004\n",
      "\u001b[32m[02/02 19:57:35 d2.utils.events]: \u001b[0m eta: 0:34:37  iter: 3879  total_loss: 1.406  loss_cls: 0.3174  loss_box_reg: 0.5302  loss_mask: 0.3125  loss_rpn_cls: 0.07147  loss_rpn_loc: 0.1962  time: 0.5880  data_time: 0.3566  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:57:48 d2.utils.events]: \u001b[0m eta: 0:34:36  iter: 3899  total_loss: 1.398  loss_cls: 0.3129  loss_box_reg: 0.489  loss_mask: 0.3097  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.1971  time: 0.5883  data_time: 0.3190  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:58:01 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 3919  total_loss: 1.299  loss_cls: 0.2847  loss_box_reg: 0.4879  loss_mask: 0.2979  loss_rpn_cls: 0.07482  loss_rpn_loc: 0.1801  time: 0.5885  data_time: 0.3285  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:58:11 d2.utils.events]: \u001b[0m eta: 0:34:16  iter: 3939  total_loss: 1.377  loss_cls: 0.3008  loss_box_reg: 0.4792  loss_mask: 0.2949  loss_rpn_cls: 0.07491  loss_rpn_loc: 0.1972  time: 0.5881  data_time: 0.1907  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:58:19 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 3959  total_loss: 1.359  loss_cls: 0.3133  loss_box_reg: 0.5012  loss_mask: 0.29  loss_rpn_cls: 0.07175  loss_rpn_loc: 0.1759  time: 0.5873  data_time: 0.1307  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:58:33 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 3979  total_loss: 1.506  loss_cls: 0.3392  loss_box_reg: 0.5242  loss_mask: 0.2951  loss_rpn_cls: 0.06484  loss_rpn_loc: 0.2035  time: 0.5877  data_time: 0.3292  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:58:47 d2.utils.events]: \u001b[0m eta: 0:33:49  iter: 3999  total_loss: 1.445  loss_cls: 0.3559  loss_box_reg: 0.5274  loss_mask: 0.3211  loss_rpn_cls: 0.09927  loss_rpn_loc: 0.204  time: 0.5883  data_time: 0.3911  lr: 5e-06  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:59:00 d2.utils.events]: \u001b[0m eta: 0:33:36  iter: 4019  total_loss: 1.454  loss_cls: 0.3439  loss_box_reg: 0.5186  loss_mask: 0.2974  loss_rpn_cls: 0.09992  loss_rpn_loc: 0.1878  time: 0.5887  data_time: 0.3521  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:59:11 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 4039  total_loss: 1.367  loss_cls: 0.2979  loss_box_reg: 0.5287  loss_mask: 0.3001  loss_rpn_cls: 0.07339  loss_rpn_loc: 0.1759  time: 0.5884  data_time: 0.2236  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:59:25 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 4059  total_loss: 1.399  loss_cls: 0.3259  loss_box_reg: 0.5013  loss_mask: 0.3021  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.2132  time: 0.5889  data_time: 0.3689  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:59:36 d2.utils.events]: \u001b[0m eta: 0:33:08  iter: 4079  total_loss: 1.446  loss_cls: 0.3654  loss_box_reg: 0.5205  loss_mask: 0.3049  loss_rpn_cls: 0.08811  loss_rpn_loc: 0.1944  time: 0.5888  data_time: 0.2386  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:59:47 d2.utils.events]: \u001b[0m eta: 0:33:01  iter: 4099  total_loss: 1.493  loss_cls: 0.3326  loss_box_reg: 0.5232  loss_mask: 0.3018  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.189  time: 0.5886  data_time: 0.2519  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 19:59:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:59:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 19:59:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 19:59:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 19:59:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 19:59:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 19:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0399 s/iter. Total: 0.1086 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 20:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0563 s/iter. Total: 0.1283 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:00:09 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0589 s/iter. Total: 0.1314 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:00:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.098718 (0.130161 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:00:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071355 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:00:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:00:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26096648807773304\n",
      "\u001b[32m[02/02 20:00:16 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 4119  total_loss: 1.42  loss_cls: 0.3409  loss_box_reg: 0.5025  loss_mask: 0.2989  loss_rpn_cls: 0.08824  loss_rpn_loc: 0.1967  time: 0.5887  data_time: 0.2841  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:00:27 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 4139  total_loss: 1.306  loss_cls: 0.2859  loss_box_reg: 0.5096  loss_mask: 0.2928  loss_rpn_cls: 0.06405  loss_rpn_loc: 0.1691  time: 0.5885  data_time: 0.2421  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:00:40 d2.utils.events]: \u001b[0m eta: 0:32:46  iter: 4159  total_loss: 1.335  loss_cls: 0.3074  loss_box_reg: 0.507  loss_mask: 0.2805  loss_rpn_cls: 0.0766  loss_rpn_loc: 0.1877  time: 0.5888  data_time: 0.3224  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:00:56 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 4179  total_loss: 1.547  loss_cls: 0.3705  loss_box_reg: 0.5303  loss_mask: 0.3023  loss_rpn_cls: 0.1264  loss_rpn_loc: 0.1993  time: 0.5899  data_time: 0.4733  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:01:09 d2.utils.events]: \u001b[0m eta: 0:32:27  iter: 4199  total_loss: 1.517  loss_cls: 0.3507  loss_box_reg: 0.5527  loss_mask: 0.3171  loss_rpn_cls: 0.07264  loss_rpn_loc: 0.2088  time: 0.5901  data_time: 0.3074  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:01:21 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 4219  total_loss: 1.454  loss_cls: 0.3203  loss_box_reg: 0.5257  loss_mask: 0.3231  loss_rpn_cls: 0.08313  loss_rpn_loc: 0.1965  time: 0.5901  data_time: 0.2711  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:01:31 d2.utils.events]: \u001b[0m eta: 0:32:13  iter: 4239  total_loss: 1.411  loss_cls: 0.3126  loss_box_reg: 0.485  loss_mask: 0.2932  loss_rpn_cls: 0.08241  loss_rpn_loc: 0.1925  time: 0.5898  data_time: 0.2064  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:01:44 d2.utils.events]: \u001b[0m eta: 0:32:08  iter: 4259  total_loss: 1.308  loss_cls: 0.3228  loss_box_reg: 0.5061  loss_mask: 0.2934  loss_rpn_cls: 0.05489  loss_rpn_loc: 0.1925  time: 0.5900  data_time: 0.3181  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:01:53 d2.utils.events]: \u001b[0m eta: 0:32:01  iter: 4279  total_loss: 1.4  loss_cls: 0.2838  loss_box_reg: 0.5283  loss_mask: 0.3096  loss_rpn_cls: 0.081  loss_rpn_loc: 0.1833  time: 0.5895  data_time: 0.1844  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:02:04 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 4299  total_loss: 1.384  loss_cls: 0.295  loss_box_reg: 0.5305  loss_mask: 0.2937  loss_rpn_cls: 0.09033  loss_rpn_loc: 0.1973  time: 0.5892  data_time: 0.2080  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:02:15 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 4319  total_loss: 1.407  loss_cls: 0.3367  loss_box_reg: 0.5181  loss_mask: 0.3019  loss_rpn_cls: 0.07003  loss_rpn_loc: 0.1963  time: 0.5890  data_time: 0.2517  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:02:28 d2.utils.events]: \u001b[0m eta: 0:31:39  iter: 4339  total_loss: 1.348  loss_cls: 0.3245  loss_box_reg: 0.5063  loss_mask: 0.2956  loss_rpn_cls: 0.09721  loss_rpn_loc: 0.1872  time: 0.5894  data_time: 0.3460  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:02:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:02:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:02:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:02:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:02:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:02:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:02:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.0403 s/iter. Total: 0.1092 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 20:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0568 s/iter. Total: 0.1285 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0609 s/iter. Total: 0.1336 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:02:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.178313 (0.130848 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:02:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071318 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:02:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:02:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2608987182091829\n",
      "\u001b[32m[02/02 20:02:58 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 4359  total_loss: 1.458  loss_cls: 0.3389  loss_box_reg: 0.5261  loss_mask: 0.3188  loss_rpn_cls: 0.0818  loss_rpn_loc: 0.2165  time: 0.5896  data_time: 0.3214  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:03:10 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 4379  total_loss: 1.216  loss_cls: 0.2397  loss_box_reg: 0.4759  loss_mask: 0.2815  loss_rpn_cls: 0.06877  loss_rpn_loc: 0.165  time: 0.5897  data_time: 0.3077  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:03:22 d2.utils.events]: \u001b[0m eta: 0:31:11  iter: 4399  total_loss: 1.468  loss_cls: 0.3593  loss_box_reg: 0.4991  loss_mask: 0.2895  loss_rpn_cls: 0.07288  loss_rpn_loc: 0.1983  time: 0.5899  data_time: 0.3027  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:03:33 d2.utils.events]: \u001b[0m eta: 0:30:59  iter: 4419  total_loss: 1.333  loss_cls: 0.3024  loss_box_reg: 0.4947  loss_mask: 0.2849  loss_rpn_cls: 0.05693  loss_rpn_loc: 0.1539  time: 0.5895  data_time: 0.2103  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:03:43 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 4439  total_loss: 1.385  loss_cls: 0.2873  loss_box_reg: 0.5246  loss_mask: 0.2876  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.1788  time: 0.5893  data_time: 0.2182  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:03:53 d2.utils.events]: \u001b[0m eta: 0:30:39  iter: 4459  total_loss: 1.443  loss_cls: 0.3135  loss_box_reg: 0.5483  loss_mask: 0.3042  loss_rpn_cls: 0.08372  loss_rpn_loc: 0.1959  time: 0.5888  data_time: 0.1788  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:04:02 d2.utils.events]: \u001b[0m eta: 0:30:32  iter: 4479  total_loss: 1.401  loss_cls: 0.3382  loss_box_reg: 0.5122  loss_mask: 0.3031  loss_rpn_cls: 0.059  loss_rpn_loc: 0.1762  time: 0.5881  data_time: 0.1256  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:04:13 d2.utils.events]: \u001b[0m eta: 0:30:28  iter: 4499  total_loss: 1.457  loss_cls: 0.346  loss_box_reg: 0.5196  loss_mask: 0.3035  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2095  time: 0.5881  data_time: 0.2687  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:04:23 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 4519  total_loss: 1.466  loss_cls: 0.352  loss_box_reg: 0.5488  loss_mask: 0.3104  loss_rpn_cls: 0.07833  loss_rpn_loc: 0.1991  time: 0.5875  data_time: 0.1579  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:04:37 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 4539  total_loss: 1.593  loss_cls: 0.3663  loss_box_reg: 0.5106  loss_mask: 0.2966  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.2163  time: 0.5882  data_time: 0.4157  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:04:54 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 4559  total_loss: 1.484  loss_cls: 0.338  loss_box_reg: 0.5035  loss_mask: 0.3166  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2062  time: 0.5893  data_time: 0.5142  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:05:07 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 4579  total_loss: 1.524  loss_cls: 0.3692  loss_box_reg: 0.5252  loss_mask: 0.3059  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.21  time: 0.5894  data_time: 0.3108  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:05:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:05:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:05:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:05:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:05:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:05:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0684 s/iter. Eval: 0.0396 s/iter. Total: 0.1085 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 20:05:27 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0554 s/iter. Total: 0.1270 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:05:32 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0584 s/iter. Total: 0.1303 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:05:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.946418 (0.128848 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:05:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070969 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:05:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:05:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611024990644525\n",
      "\u001b[32m[02/02 20:05:37 d2.utils.events]: \u001b[0m eta: 0:30:00  iter: 4599  total_loss: 1.354  loss_cls: 0.3208  loss_box_reg: 0.5049  loss_mask: 0.3009  loss_rpn_cls: 0.05594  loss_rpn_loc: 0.1816  time: 0.5898  data_time: 0.3574  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:05:52 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 4619  total_loss: 1.442  loss_cls: 0.3274  loss_box_reg: 0.512  loss_mask: 0.3072  loss_rpn_cls: 0.07135  loss_rpn_loc: 0.1948  time: 0.5905  data_time: 0.4093  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:06:02 d2.utils.events]: \u001b[0m eta: 0:29:53  iter: 4639  total_loss: 1.443  loss_cls: 0.3378  loss_box_reg: 0.5249  loss_mask: 0.316  loss_rpn_cls: 0.08332  loss_rpn_loc: 0.1971  time: 0.5902  data_time: 0.2189  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:06:14 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 4659  total_loss: 1.434  loss_cls: 0.2909  loss_box_reg: 0.5349  loss_mask: 0.3195  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.1884  time: 0.5903  data_time: 0.2913  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:06:24 d2.utils.events]: \u001b[0m eta: 0:29:40  iter: 4679  total_loss: 1.399  loss_cls: 0.3362  loss_box_reg: 0.5096  loss_mask: 0.3045  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.1966  time: 0.5897  data_time: 0.1651  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:06:36 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 4699  total_loss: 1.443  loss_cls: 0.3096  loss_box_reg: 0.5139  loss_mask: 0.3098  loss_rpn_cls: 0.09431  loss_rpn_loc: 0.2066  time: 0.5899  data_time: 0.3226  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:06:49 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 4719  total_loss: 1.387  loss_cls: 0.3526  loss_box_reg: 0.4956  loss_mask: 0.2824  loss_rpn_cls: 0.06965  loss_rpn_loc: 0.1884  time: 0.5900  data_time: 0.3067  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:07:03 d2.utils.events]: \u001b[0m eta: 0:29:24  iter: 4739  total_loss: 1.48  loss_cls: 0.3247  loss_box_reg: 0.5047  loss_mask: 0.3038  loss_rpn_cls: 0.08446  loss_rpn_loc: 0.2122  time: 0.5906  data_time: 0.3862  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:07:14 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 4759  total_loss: 1.499  loss_cls: 0.3108  loss_box_reg: 0.5197  loss_mask: 0.3023  loss_rpn_cls: 0.08725  loss_rpn_loc: 0.2039  time: 0.5905  data_time: 0.2633  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:07:25 d2.utils.events]: \u001b[0m eta: 0:29:10  iter: 4779  total_loss: 1.477  loss_cls: 0.3518  loss_box_reg: 0.5206  loss_mask: 0.2949  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.1989  time: 0.5903  data_time: 0.2414  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:07:39 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 4799  total_loss: 1.46  loss_cls: 0.3196  loss_box_reg: 0.5456  loss_mask: 0.2995  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.2037  time: 0.5907  data_time: 0.3662  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:07:49 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 4819  total_loss: 1.432  loss_cls: 0.3384  loss_box_reg: 0.5229  loss_mask: 0.3102  loss_rpn_cls: 0.0873  loss_rpn_loc: 0.195  time: 0.5904  data_time: 0.2116  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:08:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:08:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:08:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:08:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:08:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:08:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0402 s/iter. Total: 0.1089 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 20:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0563 s/iter. Total: 0.1281 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0585 s/iter. Total: 0.1306 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:08:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.017397 (0.129460 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:08:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071207 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:08:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:08:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26102383501557713\n",
      "\u001b[32m[02/02 20:08:18 d2.utils.events]: \u001b[0m eta: 0:28:44  iter: 4839  total_loss: 1.321  loss_cls: 0.2839  loss_box_reg: 0.5063  loss_mask: 0.2956  loss_rpn_cls: 0.05744  loss_rpn_loc: 0.1881  time: 0.5905  data_time: 0.3103  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:08:30 d2.utils.events]: \u001b[0m eta: 0:28:37  iter: 4859  total_loss: 1.465  loss_cls: 0.3245  loss_box_reg: 0.4922  loss_mask: 0.2925  loss_rpn_cls: 0.08234  loss_rpn_loc: 0.1925  time: 0.5906  data_time: 0.2753  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:08:39 d2.utils.events]: \u001b[0m eta: 0:28:24  iter: 4879  total_loss: 1.421  loss_cls: 0.3219  loss_box_reg: 0.4953  loss_mask: 0.2971  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.1845  time: 0.5900  data_time: 0.1454  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:08:51 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 4899  total_loss: 1.43  loss_cls: 0.3122  loss_box_reg: 0.4989  loss_mask: 0.302  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.206  time: 0.5900  data_time: 0.2585  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:09:02 d2.utils.events]: \u001b[0m eta: 0:28:10  iter: 4919  total_loss: 1.433  loss_cls: 0.3308  loss_box_reg: 0.4977  loss_mask: 0.2921  loss_rpn_cls: 0.07559  loss_rpn_loc: 0.1921  time: 0.5898  data_time: 0.2332  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:09:17 d2.utils.events]: \u001b[0m eta: 0:28:04  iter: 4939  total_loss: 1.4  loss_cls: 0.2975  loss_box_reg: 0.4749  loss_mask: 0.3093  loss_rpn_cls: 0.08625  loss_rpn_loc: 0.2068  time: 0.5905  data_time: 0.4299  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:09:29 d2.utils.events]: \u001b[0m eta: 0:28:00  iter: 4959  total_loss: 1.442  loss_cls: 0.3357  loss_box_reg: 0.526  loss_mask: 0.3062  loss_rpn_cls: 0.07618  loss_rpn_loc: 0.2063  time: 0.5904  data_time: 0.2466  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:09:42 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 4979  total_loss: 1.349  loss_cls: 0.2856  loss_box_reg: 0.5016  loss_mask: 0.294  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.1866  time: 0.5907  data_time: 0.3409  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:09:53 d2.utils.events]: \u001b[0m eta: 0:27:48  iter: 4999  total_loss: 1.382  loss_cls: 0.3121  loss_box_reg: 0.5265  loss_mask: 0.3036  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.1973  time: 0.5905  data_time: 0.2072  lr: 5e-07  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:10:00 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 5019  total_loss: 1.273  loss_cls: 0.2905  loss_box_reg: 0.5383  loss_mask: 0.2815  loss_rpn_cls: 0.04173  loss_rpn_loc: 0.1559  time: 0.5896  data_time: 0.0571  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:10:10 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 5039  total_loss: 1.522  loss_cls: 0.3818  loss_box_reg: 0.5468  loss_mask: 0.3085  loss_rpn_cls: 0.0833  loss_rpn_loc: 0.2011  time: 0.5893  data_time: 0.1625  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:10:25 d2.utils.events]: \u001b[0m eta: 0:27:30  iter: 5059  total_loss: 1.432  loss_cls: 0.3266  loss_box_reg: 0.486  loss_mask: 0.3098  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.2055  time: 0.5898  data_time: 0.3934  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:10:39 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 5079  total_loss: 1.422  loss_cls: 0.3013  loss_box_reg: 0.4779  loss_mask: 0.2928  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.1869  time: 0.5903  data_time: 0.3749  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:10:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:10:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:10:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:10:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:10:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:10:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:10:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0743 s/iter. Eval: 0.0420 s/iter. Total: 0.1170 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 20:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0007 s/iter. Inference: 0.0772 s/iter. Eval: 0.0590 s/iter. Total: 0.1370 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 20:10:52 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0777 s/iter. Eval: 0.0624 s/iter. Total: 0.1409 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 20:10:58 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0774 s/iter. Eval: 0.0597 s/iter. Total: 0.1379 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/02 20:10:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.044893 (0.138318 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:10:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077414 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:10:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:10:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.261124642072329\n",
      "\u001b[32m[02/02 20:11:06 d2.utils.events]: \u001b[0m eta: 0:27:22  iter: 5099  total_loss: 1.411  loss_cls: 0.3277  loss_box_reg: 0.5279  loss_mask: 0.2932  loss_rpn_cls: 0.07255  loss_rpn_loc: 0.1739  time: 0.5897  data_time: 0.1100  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:11:16 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 5119  total_loss: 1.44  loss_cls: 0.3072  loss_box_reg: 0.5279  loss_mask: 0.2969  loss_rpn_cls: 0.09161  loss_rpn_loc: 0.1926  time: 0.5895  data_time: 0.2053  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:11:30 d2.utils.events]: \u001b[0m eta: 0:27:12  iter: 5139  total_loss: 1.456  loss_cls: 0.3375  loss_box_reg: 0.4861  loss_mask: 0.3056  loss_rpn_cls: 0.08901  loss_rpn_loc: 0.2013  time: 0.5899  data_time: 0.3797  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:11:43 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 5159  total_loss: 1.479  loss_cls: 0.334  loss_box_reg: 0.5557  loss_mask: 0.2885  loss_rpn_cls: 0.07734  loss_rpn_loc: 0.1856  time: 0.5901  data_time: 0.3204  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:11:56 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 5179  total_loss: 1.47  loss_cls: 0.3599  loss_box_reg: 0.5402  loss_mask: 0.3034  loss_rpn_cls: 0.07125  loss_rpn_loc: 0.202  time: 0.5904  data_time: 0.3467  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:12:07 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 5199  total_loss: 1.422  loss_cls: 0.3347  loss_box_reg: 0.5102  loss_mask: 0.2966  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.1954  time: 0.5903  data_time: 0.2444  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:12:20 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 5219  total_loss: 1.434  loss_cls: 0.3337  loss_box_reg: 0.5208  loss_mask: 0.2949  loss_rpn_cls: 0.08095  loss_rpn_loc: 0.2  time: 0.5904  data_time: 0.2888  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:12:33 d2.utils.events]: \u001b[0m eta: 0:26:32  iter: 5239  total_loss: 1.452  loss_cls: 0.3268  loss_box_reg: 0.4793  loss_mask: 0.292  loss_rpn_cls: 0.07747  loss_rpn_loc: 0.188  time: 0.5906  data_time: 0.3230  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:12:45 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 5259  total_loss: 1.433  loss_cls: 0.3254  loss_box_reg: 0.493  loss_mask: 0.3194  loss_rpn_cls: 0.08452  loss_rpn_loc: 0.1909  time: 0.5906  data_time: 0.2768  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:12:55 d2.utils.events]: \u001b[0m eta: 0:26:13  iter: 5279  total_loss: 1.344  loss_cls: 0.3132  loss_box_reg: 0.4843  loss_mask: 0.2972  loss_rpn_cls: 0.06542  loss_rpn_loc: 0.1796  time: 0.5904  data_time: 0.2251  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:13:05 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 5299  total_loss: 1.456  loss_cls: 0.3143  loss_box_reg: 0.5297  loss_mask: 0.3127  loss_rpn_cls: 0.07541  loss_rpn_loc: 0.1891  time: 0.5899  data_time: 0.1586  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:13:16 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 5319  total_loss: 1.524  loss_cls: 0.3277  loss_box_reg: 0.502  loss_mask: 0.3187  loss_rpn_cls: 0.09034  loss_rpn_loc: 0.2132  time: 0.5898  data_time: 0.2533  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:13:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:13:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:13:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:13:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:13:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:13:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:13:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0688 s/iter. Eval: 0.0407 s/iter. Total: 0.1101 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 20:13:27 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0567 s/iter. Total: 0.1286 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0715 s/iter. Eval: 0.0593 s/iter. Total: 0.1316 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:13:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.106060 (0.130225 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:13:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071328 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:13:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:13:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.261160750147074\n",
      "\u001b[32m[02/02 20:13:46 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 5339  total_loss: 1.425  loss_cls: 0.3467  loss_box_reg: 0.5295  loss_mask: 0.297  loss_rpn_cls: 0.08559  loss_rpn_loc: 0.1996  time: 0.5901  data_time: 0.3377  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:13:59 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 5359  total_loss: 1.446  loss_cls: 0.2922  loss_box_reg: 0.5263  loss_mask: 0.2942  loss_rpn_cls: 0.08508  loss_rpn_loc: 0.1859  time: 0.5903  data_time: 0.3433  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:14:12 d2.utils.events]: \u001b[0m eta: 0:25:40  iter: 5379  total_loss: 1.35  loss_cls: 0.3057  loss_box_reg: 0.4877  loss_mask: 0.2956  loss_rpn_cls: 0.05872  loss_rpn_loc: 0.1859  time: 0.5905  data_time: 0.3393  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:14:29 d2.utils.events]: \u001b[0m eta: 0:25:35  iter: 5399  total_loss: 1.375  loss_cls: 0.3485  loss_box_reg: 0.4748  loss_mask: 0.3003  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2041  time: 0.5915  data_time: 0.5026  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:14:40 d2.utils.events]: \u001b[0m eta: 0:25:30  iter: 5419  total_loss: 1.432  loss_cls: 0.3337  loss_box_reg: 0.5158  loss_mask: 0.2857  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.1806  time: 0.5914  data_time: 0.2515  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:14:56 d2.utils.events]: \u001b[0m eta: 0:25:30  iter: 5439  total_loss: 1.509  loss_cls: 0.3403  loss_box_reg: 0.5123  loss_mask: 0.3258  loss_rpn_cls: 0.09844  loss_rpn_loc: 0.212  time: 0.5922  data_time: 0.4828  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:15:08 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 5459  total_loss: 1.49  loss_cls: 0.3169  loss_box_reg: 0.5246  loss_mask: 0.3057  loss_rpn_cls: 0.08735  loss_rpn_loc: 0.2103  time: 0.5922  data_time: 0.2812  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:15:19 d2.utils.events]: \u001b[0m eta: 0:25:16  iter: 5479  total_loss: 1.434  loss_cls: 0.3488  loss_box_reg: 0.5067  loss_mask: 0.2951  loss_rpn_cls: 0.06684  loss_rpn_loc: 0.1807  time: 0.5920  data_time: 0.2245  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:15:30 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 5499  total_loss: 1.413  loss_cls: 0.2987  loss_box_reg: 0.51  loss_mask: 0.3002  loss_rpn_cls: 0.09554  loss_rpn_loc: 0.2202  time: 0.5919  data_time: 0.2708  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:15:40 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 5519  total_loss: 1.503  loss_cls: 0.3572  loss_box_reg: 0.5305  loss_mask: 0.3032  loss_rpn_cls: 0.07683  loss_rpn_loc: 0.1926  time: 0.5915  data_time: 0.1745  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:15:49 d2.utils.events]: \u001b[0m eta: 0:24:49  iter: 5539  total_loss: 1.366  loss_cls: 0.3057  loss_box_reg: 0.5099  loss_mask: 0.3076  loss_rpn_cls: 0.06787  loss_rpn_loc: 0.1989  time: 0.5910  data_time: 0.1651  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:16:00 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 5559  total_loss: 1.381  loss_cls: 0.2992  loss_box_reg: 0.512  loss_mask: 0.2918  loss_rpn_cls: 0.069  loss_rpn_loc: 0.1756  time: 0.5908  data_time: 0.2046  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:16:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:16:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:16:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:16:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:16:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:16:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:16:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0397 s/iter. Total: 0.1085 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 20:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0554 s/iter. Total: 0.1271 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0714 s/iter. Eval: 0.0586 s/iter. Total: 0.1308 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:16:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.044843 (0.129697 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:16:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071188 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:16:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:16:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611276719913227\n",
      "\u001b[32m[02/02 20:16:26 d2.utils.events]: \u001b[0m eta: 0:24:32  iter: 5579  total_loss: 1.38  loss_cls: 0.3079  loss_box_reg: 0.515  loss_mask: 0.2929  loss_rpn_cls: 0.06782  loss_rpn_loc: 0.1894  time: 0.5903  data_time: 0.1613  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:16:38 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 5599  total_loss: 1.405  loss_cls: 0.3034  loss_box_reg: 0.5378  loss_mask: 0.3051  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.1907  time: 0.5904  data_time: 0.2948  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:16:53 d2.utils.events]: \u001b[0m eta: 0:24:18  iter: 5619  total_loss: 1.353  loss_cls: 0.2817  loss_box_reg: 0.4799  loss_mask: 0.2978  loss_rpn_cls: 0.07978  loss_rpn_loc: 0.1872  time: 0.5910  data_time: 0.4254  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:17:07 d2.utils.events]: \u001b[0m eta: 0:24:12  iter: 5639  total_loss: 1.54  loss_cls: 0.3318  loss_box_reg: 0.5095  loss_mask: 0.3081  loss_rpn_cls: 0.09181  loss_rpn_loc: 0.2155  time: 0.5913  data_time: 0.3713  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:17:20 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 5659  total_loss: 1.425  loss_cls: 0.3436  loss_box_reg: 0.4822  loss_mask: 0.2936  loss_rpn_cls: 0.1181  loss_rpn_loc: 0.2101  time: 0.5916  data_time: 0.3465  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:17:31 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 5679  total_loss: 1.533  loss_cls: 0.3212  loss_box_reg: 0.5536  loss_mask: 0.3119  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2178  time: 0.5915  data_time: 0.2458  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:17:40 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 5699  total_loss: 1.407  loss_cls: 0.3251  loss_box_reg: 0.5059  loss_mask: 0.2877  loss_rpn_cls: 0.09602  loss_rpn_loc: 0.2045  time: 0.5910  data_time: 0.1548  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:17:53 d2.utils.events]: \u001b[0m eta: 0:23:50  iter: 5719  total_loss: 1.508  loss_cls: 0.3733  loss_box_reg: 0.5223  loss_mask: 0.3212  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.2154  time: 0.5911  data_time: 0.3211  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:18:04 d2.utils.events]: \u001b[0m eta: 0:23:38  iter: 5739  total_loss: 1.43  loss_cls: 0.3199  loss_box_reg: 0.5338  loss_mask: 0.2998  loss_rpn_cls: 0.06676  loss_rpn_loc: 0.202  time: 0.5910  data_time: 0.2533  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:18:17 d2.utils.events]: \u001b[0m eta: 0:23:29  iter: 5759  total_loss: 1.347  loss_cls: 0.2939  loss_box_reg: 0.4987  loss_mask: 0.3116  loss_rpn_cls: 0.07934  loss_rpn_loc: 0.1828  time: 0.5912  data_time: 0.3056  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:18:26 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 5779  total_loss: 1.365  loss_cls: 0.3123  loss_box_reg: 0.5413  loss_mask: 0.3014  loss_rpn_cls: 0.06553  loss_rpn_loc: 0.1708  time: 0.5908  data_time: 0.1747  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:18:37 d2.utils.events]: \u001b[0m eta: 0:23:15  iter: 5799  total_loss: 1.327  loss_cls: 0.295  loss_box_reg: 0.5088  loss_mask: 0.2955  loss_rpn_cls: 0.06341  loss_rpn_loc: 0.1892  time: 0.5907  data_time: 0.2478  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:18:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:18:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:18:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:18:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:18:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:18:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0397 s/iter. Total: 0.1084 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 20:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0714 s/iter. Eval: 0.0570 s/iter. Total: 0.1292 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0715 s/iter. Eval: 0.0597 s/iter. Total: 0.1320 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:18:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.078159 (0.129984 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:18:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071267 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:18:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:18:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26122233512932436\n",
      "\u001b[32m[02/02 20:19:04 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 5819  total_loss: 1.346  loss_cls: 0.3156  loss_box_reg: 0.4869  loss_mask: 0.2964  loss_rpn_cls: 0.06052  loss_rpn_loc: 0.1732  time: 0.5903  data_time: 0.1671  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:19:15 d2.utils.events]: \u001b[0m eta: 0:23:03  iter: 5839  total_loss: 1.452  loss_cls: 0.3657  loss_box_reg: 0.4879  loss_mask: 0.2993  loss_rpn_cls: 0.08276  loss_rpn_loc: 0.1871  time: 0.5901  data_time: 0.2070  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:19:28 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 5859  total_loss: 1.43  loss_cls: 0.3246  loss_box_reg: 0.5303  loss_mask: 0.3173  loss_rpn_cls: 0.08104  loss_rpn_loc: 0.1894  time: 0.5904  data_time: 0.3496  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:19:40 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 5879  total_loss: 1.486  loss_cls: 0.354  loss_box_reg: 0.5237  loss_mask: 0.3072  loss_rpn_cls: 0.102  loss_rpn_loc: 0.1937  time: 0.5904  data_time: 0.2808  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:19:53 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 5899  total_loss: 1.474  loss_cls: 0.3098  loss_box_reg: 0.5188  loss_mask: 0.3072  loss_rpn_cls: 0.09445  loss_rpn_loc: 0.2161  time: 0.5907  data_time: 0.3419  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:20:04 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 5919  total_loss: 1.379  loss_cls: 0.2876  loss_box_reg: 0.5079  loss_mask: 0.2929  loss_rpn_cls: 0.06783  loss_rpn_loc: 0.1853  time: 0.5905  data_time: 0.2341  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:20:15 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 5939  total_loss: 1.369  loss_cls: 0.3254  loss_box_reg: 0.5174  loss_mask: 0.3005  loss_rpn_cls: 0.08015  loss_rpn_loc: 0.1866  time: 0.5904  data_time: 0.2362  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:20:28 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 5959  total_loss: 1.392  loss_cls: 0.3019  loss_box_reg: 0.4862  loss_mask: 0.2936  loss_rpn_cls: 0.06923  loss_rpn_loc: 0.1948  time: 0.5905  data_time: 0.2948  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:20:39 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 5979  total_loss: 1.452  loss_cls: 0.322  loss_box_reg: 0.5169  loss_mask: 0.3061  loss_rpn_cls: 0.08336  loss_rpn_loc: 0.191  time: 0.5904  data_time: 0.2503  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:20:51 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 5999  total_loss: 1.474  loss_cls: 0.3547  loss_box_reg: 0.5105  loss_mask: 0.293  loss_rpn_cls: 0.07201  loss_rpn_loc: 0.1915  time: 0.5904  data_time: 0.2834  lr: 5e-08  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:21:04 d2.utils.events]: \u001b[0m eta: 0:22:03  iter: 6019  total_loss: 1.506  loss_cls: 0.3475  loss_box_reg: 0.5094  loss_mask: 0.3102  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.1978  time: 0.5906  data_time: 0.3351  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:21:15 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 6039  total_loss: 1.413  loss_cls: 0.3193  loss_box_reg: 0.5127  loss_mask: 0.3057  loss_rpn_cls: 0.07845  loss_rpn_loc: 0.1944  time: 0.5906  data_time: 0.2623  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:21:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:21:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:21:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:21:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:21:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:21:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0403 s/iter. Total: 0.1092 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 20:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0576 s/iter. Total: 0.1301 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0603 s/iter. Total: 0.1329 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:21:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.189278 (0.130942 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:21:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071591 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:21:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:21:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2612655034944265\n",
      "\u001b[32m[02/02 20:21:41 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 6059  total_loss: 1.275  loss_cls: 0.254  loss_box_reg: 0.4999  loss_mask: 0.2915  loss_rpn_cls: 0.05982  loss_rpn_loc: 0.1903  time: 0.5901  data_time: 0.1595  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:21:54 d2.utils.events]: \u001b[0m eta: 0:21:39  iter: 6079  total_loss: 1.482  loss_cls: 0.3467  loss_box_reg: 0.5159  loss_mask: 0.2924  loss_rpn_cls: 0.111  loss_rpn_loc: 0.2119  time: 0.5903  data_time: 0.3183  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:22:08 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 6099  total_loss: 1.389  loss_cls: 0.3264  loss_box_reg: 0.5088  loss_mask: 0.2929  loss_rpn_cls: 0.08068  loss_rpn_loc: 0.1849  time: 0.5906  data_time: 0.3735  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:22:20 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 6119  total_loss: 1.511  loss_cls: 0.3576  loss_box_reg: 0.5364  loss_mask: 0.3041  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.2089  time: 0.5906  data_time: 0.2722  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:22:31 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 6139  total_loss: 1.424  loss_cls: 0.3104  loss_box_reg: 0.529  loss_mask: 0.3207  loss_rpn_cls: 0.0784  loss_rpn_loc: 0.2081  time: 0.5905  data_time: 0.2362  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:22:41 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 6159  total_loss: 1.435  loss_cls: 0.3081  loss_box_reg: 0.5103  loss_mask: 0.2963  loss_rpn_cls: 0.05382  loss_rpn_loc: 0.1803  time: 0.5903  data_time: 0.2218  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:22:52 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 6179  total_loss: 1.412  loss_cls: 0.3107  loss_box_reg: 0.5009  loss_mask: 0.2962  loss_rpn_cls: 0.0704  loss_rpn_loc: 0.189  time: 0.5900  data_time: 0.2084  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:23:05 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 6199  total_loss: 1.479  loss_cls: 0.3306  loss_box_reg: 0.5393  loss_mask: 0.3074  loss_rpn_cls: 0.08927  loss_rpn_loc: 0.2029  time: 0.5904  data_time: 0.3589  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:23:19 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 6219  total_loss: 1.419  loss_cls: 0.3359  loss_box_reg: 0.5158  loss_mask: 0.2974  loss_rpn_cls: 0.08304  loss_rpn_loc: 0.1871  time: 0.5906  data_time: 0.3447  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:23:32 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 6239  total_loss: 1.515  loss_cls: 0.3314  loss_box_reg: 0.512  loss_mask: 0.3014  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.2115  time: 0.5908  data_time: 0.3140  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:23:45 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 6259  total_loss: 1.353  loss_cls: 0.3099  loss_box_reg: 0.4944  loss_mask: 0.301  loss_rpn_cls: 0.06903  loss_rpn_loc: 0.1751  time: 0.5910  data_time: 0.3553  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:23:54 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 6279  total_loss: 1.402  loss_cls: 0.3355  loss_box_reg: 0.5201  loss_mask: 0.2903  loss_rpn_cls: 0.06514  loss_rpn_loc: 0.1766  time: 0.5907  data_time: 0.1539  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:24:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:24:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:24:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:24:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:24:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:24:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0681 s/iter. Eval: 0.0401 s/iter. Total: 0.1088 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/02 20:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0562 s/iter. Total: 0.1277 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0721 s/iter. Eval: 0.0599 s/iter. Total: 0.1328 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:24:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.361980 (0.132431 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:24:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072469 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:24:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:24:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2612358475520592\n",
      "\u001b[32m[02/02 20:24:21 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 6299  total_loss: 1.387  loss_cls: 0.304  loss_box_reg: 0.4962  loss_mask: 0.2981  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.1813  time: 0.5903  data_time: 0.1593  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:24:32 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 6319  total_loss: 1.462  loss_cls: 0.3327  loss_box_reg: 0.4985  loss_mask: 0.2944  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.1776  time: 0.5901  data_time: 0.2275  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:24:44 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 6339  total_loss: 1.444  loss_cls: 0.2945  loss_box_reg: 0.5326  loss_mask: 0.3102  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.1939  time: 0.5902  data_time: 0.3030  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:24:55 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 6359  total_loss: 1.452  loss_cls: 0.3152  loss_box_reg: 0.537  loss_mask: 0.3052  loss_rpn_cls: 0.08353  loss_rpn_loc: 0.2062  time: 0.5900  data_time: 0.2256  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:25:06 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 6379  total_loss: 1.44  loss_cls: 0.3418  loss_box_reg: 0.524  loss_mask: 0.293  loss_rpn_cls: 0.07321  loss_rpn_loc: 0.1964  time: 0.5899  data_time: 0.2375  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:25:19 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 6399  total_loss: 1.352  loss_cls: 0.3111  loss_box_reg: 0.5185  loss_mask: 0.3031  loss_rpn_cls: 0.09159  loss_rpn_loc: 0.1913  time: 0.5902  data_time: 0.3520  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:25:32 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 6419  total_loss: 1.538  loss_cls: 0.3309  loss_box_reg: 0.5178  loss_mask: 0.3222  loss_rpn_cls: 0.08196  loss_rpn_loc: 0.2118  time: 0.5903  data_time: 0.3167  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:25:44 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 6439  total_loss: 1.407  loss_cls: 0.3327  loss_box_reg: 0.5218  loss_mask: 0.3157  loss_rpn_cls: 0.09619  loss_rpn_loc: 0.1958  time: 0.5904  data_time: 0.2892  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:25:59 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 6459  total_loss: 1.429  loss_cls: 0.3077  loss_box_reg: 0.5061  loss_mask: 0.3  loss_rpn_cls: 0.0887  loss_rpn_loc: 0.1996  time: 0.5908  data_time: 0.4036  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:26:09 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 6479  total_loss: 1.581  loss_cls: 0.401  loss_box_reg: 0.5185  loss_mask: 0.3024  loss_rpn_cls: 0.09337  loss_rpn_loc: 0.2005  time: 0.5906  data_time: 0.1958  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:26:18 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 6499  total_loss: 1.402  loss_cls: 0.3153  loss_box_reg: 0.5288  loss_mask: 0.3067  loss_rpn_cls: 0.06299  loss_rpn_loc: 0.1882  time: 0.5902  data_time: 0.1629  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:26:31 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 6519  total_loss: 1.435  loss_cls: 0.3147  loss_box_reg: 0.5075  loss_mask: 0.2992  loss_rpn_cls: 0.07733  loss_rpn_loc: 0.1907  time: 0.5903  data_time: 0.3025  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:26:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:26:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:26:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:26:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:26:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:26:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:26:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0425 s/iter. Total: 0.1140 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 20:26:47 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0009 s/iter. Inference: 0.0721 s/iter. Eval: 0.0574 s/iter. Total: 0.1304 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:26:52 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0728 s/iter. Eval: 0.0612 s/iter. Total: 0.1349 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:26:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.285716 (0.131773 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:26:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072044 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:26:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:26:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611765329534312\n",
      "\u001b[32m[02/02 20:26:59 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 6539  total_loss: 1.414  loss_cls: 0.3134  loss_box_reg: 0.5255  loss_mask: 0.307  loss_rpn_cls: 0.0928  loss_rpn_loc: 0.2105  time: 0.5901  data_time: 0.2316  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:27:13 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 6559  total_loss: 1.41  loss_cls: 0.3471  loss_box_reg: 0.4867  loss_mask: 0.2985  loss_rpn_cls: 0.09355  loss_rpn_loc: 0.2062  time: 0.5906  data_time: 0.3899  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:27:25 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 6579  total_loss: 1.337  loss_cls: 0.2922  loss_box_reg: 0.5065  loss_mask: 0.291  loss_rpn_cls: 0.06158  loss_rpn_loc: 0.1864  time: 0.5905  data_time: 0.2470  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:27:35 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 6599  total_loss: 1.447  loss_cls: 0.3526  loss_box_reg: 0.5258  loss_mask: 0.2939  loss_rpn_cls: 0.09111  loss_rpn_loc: 0.1865  time: 0.5902  data_time: 0.1719  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:27:44 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 6619  total_loss: 1.549  loss_cls: 0.3626  loss_box_reg: 0.5505  loss_mask: 0.3138  loss_rpn_cls: 0.06928  loss_rpn_loc: 0.1823  time: 0.5898  data_time: 0.1480  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:27:57 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 6639  total_loss: 1.521  loss_cls: 0.3521  loss_box_reg: 0.5485  loss_mask: 0.302  loss_rpn_cls: 0.08506  loss_rpn_loc: 0.2033  time: 0.5899  data_time: 0.3068  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:28:06 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 6659  total_loss: 1.535  loss_cls: 0.3303  loss_box_reg: 0.5732  loss_mask: 0.3063  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.1989  time: 0.5895  data_time: 0.1576  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:28:20 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 6679  total_loss: 1.323  loss_cls: 0.3025  loss_box_reg: 0.4832  loss_mask: 0.3105  loss_rpn_cls: 0.07606  loss_rpn_loc: 0.1894  time: 0.5900  data_time: 0.4054  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:28:33 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 6699  total_loss: 1.514  loss_cls: 0.3322  loss_box_reg: 0.5175  loss_mask: 0.3127  loss_rpn_cls: 0.08048  loss_rpn_loc: 0.2058  time: 0.5901  data_time: 0.3291  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:28:45 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 6719  total_loss: 1.266  loss_cls: 0.2851  loss_box_reg: 0.4882  loss_mask: 0.2933  loss_rpn_cls: 0.07317  loss_rpn_loc: 0.1697  time: 0.5901  data_time: 0.2770  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:28:56 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 6739  total_loss: 1.495  loss_cls: 0.3831  loss_box_reg: 0.4998  loss_mask: 0.2968  loss_rpn_cls: 0.0795  loss_rpn_loc: 0.2015  time: 0.5901  data_time: 0.2374  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:29:06 d2.utils.events]: \u001b[0m eta: 0:18:04  iter: 6759  total_loss: 1.392  loss_cls: 0.3324  loss_box_reg: 0.5148  loss_mask: 0.3008  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.1836  time: 0.5897  data_time: 0.1799  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:29:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:29:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:29:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:29:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:29:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:29:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0465 s/iter. Total: 0.1173 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 20:29:25 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0724 s/iter. Eval: 0.0577 s/iter. Total: 0.1309 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:29:30 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0727 s/iter. Eval: 0.0612 s/iter. Total: 0.1346 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:29:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.308733 (0.131972 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:29:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072145 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:29:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:29:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26119232457626207\n",
      "\u001b[32m[02/02 20:29:36 d2.utils.events]: \u001b[0m eta: 0:18:01  iter: 6779  total_loss: 1.411  loss_cls: 0.2974  loss_box_reg: 0.5009  loss_mask: 0.3084  loss_rpn_cls: 0.08226  loss_rpn_loc: 0.2115  time: 0.5900  data_time: 0.3267  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:29:49 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 6799  total_loss: 1.405  loss_cls: 0.3238  loss_box_reg: 0.4795  loss_mask: 0.2967  loss_rpn_cls: 0.0713  loss_rpn_loc: 0.1834  time: 0.5901  data_time: 0.3320  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:30:00 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 6819  total_loss: 1.325  loss_cls: 0.2853  loss_box_reg: 0.4882  loss_mask: 0.2961  loss_rpn_cls: 0.06742  loss_rpn_loc: 0.1818  time: 0.5900  data_time: 0.2111  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:30:09 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 6839  total_loss: 1.354  loss_cls: 0.3262  loss_box_reg: 0.526  loss_mask: 0.2881  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.1729  time: 0.5896  data_time: 0.1533  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:30:21 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 6859  total_loss: 1.489  loss_cls: 0.3297  loss_box_reg: 0.4848  loss_mask: 0.3112  loss_rpn_cls: 0.08996  loss_rpn_loc: 0.2285  time: 0.5896  data_time: 0.2838  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:30:31 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 6879  total_loss: 1.349  loss_cls: 0.3157  loss_box_reg: 0.5302  loss_mask: 0.2903  loss_rpn_cls: 0.08044  loss_rpn_loc: 0.1777  time: 0.5894  data_time: 0.1942  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:30:42 d2.utils.events]: \u001b[0m eta: 0:17:21  iter: 6899  total_loss: 1.411  loss_cls: 0.308  loss_box_reg: 0.4917  loss_mask: 0.3078  loss_rpn_cls: 0.08253  loss_rpn_loc: 0.196  time: 0.5892  data_time: 0.2146  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:30:54 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 6919  total_loss: 1.396  loss_cls: 0.3239  loss_box_reg: 0.4793  loss_mask: 0.3029  loss_rpn_cls: 0.08473  loss_rpn_loc: 0.1932  time: 0.5893  data_time: 0.2874  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:31:09 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 6939  total_loss: 1.346  loss_cls: 0.27  loss_box_reg: 0.4801  loss_mask: 0.3024  loss_rpn_cls: 0.08014  loss_rpn_loc: 0.1944  time: 0.5898  data_time: 0.4295  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:31:19 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 6959  total_loss: 1.436  loss_cls: 0.3453  loss_box_reg: 0.5093  loss_mask: 0.2984  loss_rpn_cls: 0.08953  loss_rpn_loc: 0.1974  time: 0.5894  data_time: 0.1607  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:31:31 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 6979  total_loss: 1.386  loss_cls: 0.3358  loss_box_reg: 0.5118  loss_mask: 0.2924  loss_rpn_cls: 0.07634  loss_rpn_loc: 0.1776  time: 0.5895  data_time: 0.3135  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:31:42 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 6999  total_loss: 1.468  loss_cls: 0.3259  loss_box_reg: 0.5144  loss_mask: 0.308  loss_rpn_cls: 0.07515  loss_rpn_loc: 0.1963  time: 0.5895  data_time: 0.2490  lr: 5e-09  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:31:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:31:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:31:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:31:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:31:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:31:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:31:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0688 s/iter. Eval: 0.0435 s/iter. Total: 0.1130 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 20:32:02 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0557 s/iter. Total: 0.1276 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:32:07 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0712 s/iter. Eval: 0.0585 s/iter. Total: 0.1305 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:32:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.967165 (0.129027 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:32:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070923 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:32:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:32:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2610591147454212\n",
      "\u001b[32m[02/02 20:32:12 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 7019  total_loss: 1.456  loss_cls: 0.3348  loss_box_reg: 0.5002  loss_mask: 0.3076  loss_rpn_cls: 0.1197  loss_rpn_loc: 0.1992  time: 0.5897  data_time: 0.3374  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:32:29 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 7039  total_loss: 1.345  loss_cls: 0.3017  loss_box_reg: 0.4881  loss_mask: 0.3146  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.2133  time: 0.5904  data_time: 0.5232  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:32:43 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 7059  total_loss: 1.424  loss_cls: 0.2911  loss_box_reg: 0.464  loss_mask: 0.3115  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.1969  time: 0.5906  data_time: 0.3452  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:32:53 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 7079  total_loss: 1.398  loss_cls: 0.2946  loss_box_reg: 0.4941  loss_mask: 0.304  loss_rpn_cls: 0.07521  loss_rpn_loc: 0.2049  time: 0.5904  data_time: 0.2131  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:33:06 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 7099  total_loss: 1.474  loss_cls: 0.3525  loss_box_reg: 0.5562  loss_mask: 0.305  loss_rpn_cls: 0.07524  loss_rpn_loc: 0.1879  time: 0.5905  data_time: 0.3189  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:33:20 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 7119  total_loss: 1.439  loss_cls: 0.3043  loss_box_reg: 0.5194  loss_mask: 0.3129  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.205  time: 0.5909  data_time: 0.3829  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:33:32 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 7139  total_loss: 1.445  loss_cls: 0.3248  loss_box_reg: 0.4919  loss_mask: 0.2863  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.1908  time: 0.5910  data_time: 0.3121  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:33:43 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 7159  total_loss: 1.42  loss_cls: 0.3316  loss_box_reg: 0.512  loss_mask: 0.3084  loss_rpn_cls: 0.08287  loss_rpn_loc: 0.198  time: 0.5908  data_time: 0.2318  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:33:58 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 7179  total_loss: 1.339  loss_cls: 0.3054  loss_box_reg: 0.4869  loss_mask: 0.3046  loss_rpn_cls: 0.09104  loss_rpn_loc: 0.2063  time: 0.5913  data_time: 0.4314  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:34:10 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 7199  total_loss: 1.425  loss_cls: 0.2864  loss_box_reg: 0.5137  loss_mask: 0.2948  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.1827  time: 0.5912  data_time: 0.2597  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:34:19 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 7219  total_loss: 1.53  loss_cls: 0.392  loss_box_reg: 0.5192  loss_mask: 0.3082  loss_rpn_cls: 0.0975  loss_rpn_loc: 0.206  time: 0.5909  data_time: 0.1647  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:34:26 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 7239  total_loss: 1.349  loss_cls: 0.294  loss_box_reg: 0.515  loss_mask: 0.2971  loss_rpn_cls: 0.06743  loss_rpn_loc: 0.1659  time: 0.5903  data_time: 0.0683  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:34:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:34:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:34:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:34:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:34:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:34:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0692 s/iter. Eval: 0.0487 s/iter. Total: 0.1186 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0567 s/iter. Total: 0.1283 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0587 s/iter. Total: 0.1305 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:34:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.987597 (0.129203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:34:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070826 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:34:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:34:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2612094746685342\n",
      "\u001b[32m[02/02 20:34:55 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 7259  total_loss: 1.427  loss_cls: 0.3379  loss_box_reg: 0.5361  loss_mask: 0.2956  loss_rpn_cls: 0.0829  loss_rpn_loc: 0.1896  time: 0.5903  data_time: 0.3121  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:35:04 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 7279  total_loss: 1.416  loss_cls: 0.3163  loss_box_reg: 0.516  loss_mask: 0.2911  loss_rpn_cls: 0.09029  loss_rpn_loc: 0.2038  time: 0.5899  data_time: 0.1397  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:35:15 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 7299  total_loss: 1.379  loss_cls: 0.307  loss_box_reg: 0.4922  loss_mask: 0.2912  loss_rpn_cls: 0.06614  loss_rpn_loc: 0.1793  time: 0.5898  data_time: 0.2557  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:35:28 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 7319  total_loss: 1.404  loss_cls: 0.3053  loss_box_reg: 0.5079  loss_mask: 0.3009  loss_rpn_cls: 0.07924  loss_rpn_loc: 0.1856  time: 0.5900  data_time: 0.3352  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:35:43 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 7339  total_loss: 1.504  loss_cls: 0.3466  loss_box_reg: 0.5234  loss_mask: 0.3151  loss_rpn_cls: 0.0785  loss_rpn_loc: 0.206  time: 0.5904  data_time: 0.4088  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:35:57 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 7359  total_loss: 1.399  loss_cls: 0.302  loss_box_reg: 0.5062  loss_mask: 0.3089  loss_rpn_cls: 0.08758  loss_rpn_loc: 0.2119  time: 0.5906  data_time: 0.3581  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:36:13 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 7379  total_loss: 1.548  loss_cls: 0.3577  loss_box_reg: 0.5121  loss_mask: 0.3219  loss_rpn_cls: 0.109  loss_rpn_loc: 0.2145  time: 0.5912  data_time: 0.4687  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:36:22 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 7399  total_loss: 1.551  loss_cls: 0.3534  loss_box_reg: 0.5385  loss_mask: 0.2945  loss_rpn_cls: 0.07685  loss_rpn_loc: 0.1866  time: 0.5908  data_time: 0.1506  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:36:31 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 7419  total_loss: 1.507  loss_cls: 0.3724  loss_box_reg: 0.5309  loss_mask: 0.3068  loss_rpn_cls: 0.08058  loss_rpn_loc: 0.202  time: 0.5905  data_time: 0.1497  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:36:41 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 7439  total_loss: 1.379  loss_cls: 0.3088  loss_box_reg: 0.4979  loss_mask: 0.2973  loss_rpn_cls: 0.05861  loss_rpn_loc: 0.1884  time: 0.5902  data_time: 0.2051  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:36:51 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 7459  total_loss: 1.441  loss_cls: 0.3407  loss_box_reg: 0.5447  loss_mask: 0.2965  loss_rpn_cls: 0.07229  loss_rpn_loc: 0.2078  time: 0.5900  data_time: 0.1954  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:37:00 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 7479  total_loss: 1.348  loss_cls: 0.3021  loss_box_reg: 0.5311  loss_mask: 0.3002  loss_rpn_cls: 0.05876  loss_rpn_loc: 0.1797  time: 0.5896  data_time: 0.1433  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:37:13 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 7499  total_loss: 1.362  loss_cls: 0.2947  loss_box_reg: 0.5155  loss_mask: 0.2884  loss_rpn_cls: 0.07182  loss_rpn_loc: 0.1716  time: 0.5898  data_time: 0.3345  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:37:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:37:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:37:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:37:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:37:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:37:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0479 s/iter. Total: 0.1220 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0725 s/iter. Eval: 0.0585 s/iter. Total: 0.1319 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0723 s/iter. Eval: 0.0610 s/iter. Total: 0.1341 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:37:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.364005 (0.132448 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:37:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072185 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:37:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:37:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2612078539832003\n",
      "\u001b[32m[02/02 20:37:42 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 7519  total_loss: 1.419  loss_cls: 0.3277  loss_box_reg: 0.494  loss_mask: 0.318  loss_rpn_cls: 0.09882  loss_rpn_loc: 0.1878  time: 0.5898  data_time: 0.2766  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:37:54 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 7539  total_loss: 1.389  loss_cls: 0.3167  loss_box_reg: 0.5059  loss_mask: 0.2947  loss_rpn_cls: 0.07868  loss_rpn_loc: 0.1783  time: 0.5898  data_time: 0.2438  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:38:05 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 7559  total_loss: 1.423  loss_cls: 0.3197  loss_box_reg: 0.5016  loss_mask: 0.3077  loss_rpn_cls: 0.06022  loss_rpn_loc: 0.1743  time: 0.5897  data_time: 0.2345  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:38:16 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 7579  total_loss: 1.404  loss_cls: 0.326  loss_box_reg: 0.5505  loss_mask: 0.3144  loss_rpn_cls: 0.08756  loss_rpn_loc: 0.1822  time: 0.5896  data_time: 0.2494  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:38:29 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 7599  total_loss: 1.459  loss_cls: 0.3698  loss_box_reg: 0.5428  loss_mask: 0.3016  loss_rpn_cls: 0.08738  loss_rpn_loc: 0.2132  time: 0.5897  data_time: 0.3139  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:38:39 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 7619  total_loss: 1.434  loss_cls: 0.3271  loss_box_reg: 0.5057  loss_mask: 0.2934  loss_rpn_cls: 0.07544  loss_rpn_loc: 0.1965  time: 0.5896  data_time: 0.2275  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:38:51 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 7639  total_loss: 1.33  loss_cls: 0.2957  loss_box_reg: 0.475  loss_mask: 0.2829  loss_rpn_cls: 0.08176  loss_rpn_loc: 0.1987  time: 0.5896  data_time: 0.2838  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:39:03 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 7659  total_loss: 1.501  loss_cls: 0.3732  loss_box_reg: 0.5065  loss_mask: 0.3109  loss_rpn_cls: 0.07745  loss_rpn_loc: 0.2062  time: 0.5896  data_time: 0.2869  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:39:17 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 7679  total_loss: 1.437  loss_cls: 0.3462  loss_box_reg: 0.5282  loss_mask: 0.2992  loss_rpn_cls: 0.08007  loss_rpn_loc: 0.1948  time: 0.5898  data_time: 0.3464  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:39:24 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 7699  total_loss: 1.341  loss_cls: 0.2795  loss_box_reg: 0.5267  loss_mask: 0.2956  loss_rpn_cls: 0.05347  loss_rpn_loc: 0.1934  time: 0.5893  data_time: 0.1033  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:39:38 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 7719  total_loss: 1.476  loss_cls: 0.3132  loss_box_reg: 0.5272  loss_mask: 0.2986  loss_rpn_cls: 0.07362  loss_rpn_loc: 0.2197  time: 0.5895  data_time: 0.3316  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:39:49 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 7739  total_loss: 1.465  loss_cls: 0.3412  loss_box_reg: 0.5429  loss_mask: 0.3135  loss_rpn_cls: 0.06292  loss_rpn_loc: 0.2144  time: 0.5895  data_time: 0.2587  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:39:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:39:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:39:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:39:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:39:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:39:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0743 s/iter. Eval: 0.0461 s/iter. Total: 0.1212 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0010 s/iter. Inference: 0.0739 s/iter. Eval: 0.0598 s/iter. Total: 0.1347 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0009 s/iter. Inference: 0.0744 s/iter. Eval: 0.0621 s/iter. Total: 0.1374 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 20:40:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.727956 (0.135586 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:40:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074264 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:40:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:40:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2612395160686446\n",
      "\u001b[32m[02/02 20:40:22 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 7759  total_loss: 1.43  loss_cls: 0.3547  loss_box_reg: 0.4808  loss_mask: 0.3101  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.1943  time: 0.5900  data_time: 0.4298  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:40:35 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 7779  total_loss: 1.474  loss_cls: 0.3496  loss_box_reg: 0.5445  loss_mask: 0.3129  loss_rpn_cls: 0.09131  loss_rpn_loc: 0.2026  time: 0.5901  data_time: 0.3100  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:40:47 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 7799  total_loss: 1.325  loss_cls: 0.3001  loss_box_reg: 0.4762  loss_mask: 0.2941  loss_rpn_cls: 0.07885  loss_rpn_loc: 0.1788  time: 0.5901  data_time: 0.3070  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:40:59 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 7819  total_loss: 1.564  loss_cls: 0.3905  loss_box_reg: 0.5463  loss_mask: 0.3109  loss_rpn_cls: 0.1126  loss_rpn_loc: 0.2071  time: 0.5901  data_time: 0.2527  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:41:13 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 7839  total_loss: 1.399  loss_cls: 0.3087  loss_box_reg: 0.4803  loss_mask: 0.2926  loss_rpn_cls: 0.08075  loss_rpn_loc: 0.199  time: 0.5905  data_time: 0.4067  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:41:26 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 7859  total_loss: 1.386  loss_cls: 0.3212  loss_box_reg: 0.5021  loss_mask: 0.2978  loss_rpn_cls: 0.09833  loss_rpn_loc: 0.1857  time: 0.5905  data_time: 0.3131  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:41:36 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 7879  total_loss: 1.53  loss_cls: 0.3845  loss_box_reg: 0.5398  loss_mask: 0.2988  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.1953  time: 0.5903  data_time: 0.1980  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:41:48 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 7899  total_loss: 1.405  loss_cls: 0.3042  loss_box_reg: 0.4995  loss_mask: 0.3038  loss_rpn_cls: 0.07515  loss_rpn_loc: 0.1927  time: 0.5903  data_time: 0.2624  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:42:02 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 7919  total_loss: 1.452  loss_cls: 0.3343  loss_box_reg: 0.5277  loss_mask: 0.2963  loss_rpn_cls: 0.08654  loss_rpn_loc: 0.1762  time: 0.5906  data_time: 0.3514  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:42:10 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 7939  total_loss: 1.371  loss_cls: 0.3176  loss_box_reg: 0.5222  loss_mask: 0.2968  loss_rpn_cls: 0.05816  loss_rpn_loc: 0.1849  time: 0.5902  data_time: 0.1480  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:42:22 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 7959  total_loss: 1.305  loss_cls: 0.2892  loss_box_reg: 0.4868  loss_mask: 0.2931  loss_rpn_cls: 0.0681  loss_rpn_loc: 0.1851  time: 0.5902  data_time: 0.2629  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:42:34 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 7979  total_loss: 1.43  loss_cls: 0.312  loss_box_reg: 0.5526  loss_mask: 0.2996  loss_rpn_cls: 0.06354  loss_rpn_loc: 0.1812  time: 0.5901  data_time: 0.2711  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:42:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:42:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:42:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:42:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:42:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:42:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:42:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0464 s/iter. Total: 0.1179 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/02 20:42:47 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0726 s/iter. Eval: 0.0588 s/iter. Total: 0.1322 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0725 s/iter. Eval: 0.0611 s/iter. Total: 0.1345 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:42:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.369003 (0.132491 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:42:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072158 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:42:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:42:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26129300478296313\n",
      "\u001b[32m[02/02 20:43:05 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 7999  total_loss: 1.38  loss_cls: 0.2823  loss_box_reg: 0.4802  loss_mask: 0.3169  loss_rpn_cls: 0.09227  loss_rpn_loc: 0.2065  time: 0.5905  data_time: 0.3969  lr: 5e-10  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:43:14 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 8019  total_loss: 1.358  loss_cls: 0.3046  loss_box_reg: 0.5269  loss_mask: 0.2952  loss_rpn_cls: 0.06328  loss_rpn_loc: 0.1802  time: 0.5901  data_time: 0.1609  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:43:24 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 8039  total_loss: 1.405  loss_cls: 0.3045  loss_box_reg: 0.5218  loss_mask: 0.305  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.1773  time: 0.5899  data_time: 0.1970  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:43:38 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 8059  total_loss: 1.476  loss_cls: 0.311  loss_box_reg: 0.5037  loss_mask: 0.2958  loss_rpn_cls: 0.09497  loss_rpn_loc: 0.2016  time: 0.5901  data_time: 0.3477  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:43:48 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 8079  total_loss: 1.541  loss_cls: 0.3549  loss_box_reg: 0.5574  loss_mask: 0.2979  loss_rpn_cls: 0.08653  loss_rpn_loc: 0.1932  time: 0.5899  data_time: 0.1721  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:44:01 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 8099  total_loss: 1.513  loss_cls: 0.3628  loss_box_reg: 0.5521  loss_mask: 0.2967  loss_rpn_cls: 0.0806  loss_rpn_loc: 0.202  time: 0.5901  data_time: 0.3439  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:44:11 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 8119  total_loss: 1.363  loss_cls: 0.2998  loss_box_reg: 0.5038  loss_mask: 0.2816  loss_rpn_cls: 0.08161  loss_rpn_loc: 0.192  time: 0.5899  data_time: 0.2146  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:44:26 d2.utils.events]: \u001b[0m eta: 0:10:20  iter: 8139  total_loss: 1.43  loss_cls: 0.3445  loss_box_reg: 0.4703  loss_mask: 0.3017  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.2069  time: 0.5902  data_time: 0.3893  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:44:37 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 8159  total_loss: 1.398  loss_cls: 0.314  loss_box_reg: 0.4971  loss_mask: 0.3  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.1908  time: 0.5901  data_time: 0.2414  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:44:50 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 8179  total_loss: 1.417  loss_cls: 0.3348  loss_box_reg: 0.5057  loss_mask: 0.289  loss_rpn_cls: 0.07655  loss_rpn_loc: 0.1864  time: 0.5903  data_time: 0.3128  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:44:59 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 8199  total_loss: 1.438  loss_cls: 0.3121  loss_box_reg: 0.5152  loss_mask: 0.2932  loss_rpn_cls: 0.07378  loss_rpn_loc: 0.1845  time: 0.5900  data_time: 0.1610  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:45:13 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 8219  total_loss: 1.507  loss_cls: 0.3505  loss_box_reg: 0.5358  loss_mask: 0.3112  loss_rpn_cls: 0.09984  loss_rpn_loc: 0.2014  time: 0.5902  data_time: 0.3535  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:45:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:45:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:45:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:45:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:45:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:45:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0033 s/iter. Inference: 0.0694 s/iter. Eval: 0.0469 s/iter. Total: 0.1197 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0011 s/iter. Inference: 0.0723 s/iter. Eval: 0.0590 s/iter. Total: 0.1325 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0012 s/iter. Inference: 0.0722 s/iter. Eval: 0.0611 s/iter. Total: 0.1345 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:45:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.320028 (0.132069 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:45:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071778 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:45:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:45:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n",
      "\u001b[32m[02/02 20:45:41 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 8239  total_loss: 1.443  loss_cls: 0.3354  loss_box_reg: 0.5063  loss_mask: 0.2924  loss_rpn_cls: 0.0957  loss_rpn_loc: 0.2016  time: 0.5902  data_time: 0.2540  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:45:53 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 8259  total_loss: 1.383  loss_cls: 0.3141  loss_box_reg: 0.4792  loss_mask: 0.2927  loss_rpn_cls: 0.06735  loss_rpn_loc: 0.186  time: 0.5902  data_time: 0.2842  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:46:04 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 8279  total_loss: 1.414  loss_cls: 0.311  loss_box_reg: 0.505  loss_mask: 0.2935  loss_rpn_cls: 0.07238  loss_rpn_loc: 0.2047  time: 0.5900  data_time: 0.2267  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:46:15 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 8299  total_loss: 1.478  loss_cls: 0.3282  loss_box_reg: 0.4978  loss_mask: 0.3141  loss_rpn_cls: 0.08602  loss_rpn_loc: 0.2052  time: 0.5899  data_time: 0.2220  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:46:23 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 8319  total_loss: 1.512  loss_cls: 0.3551  loss_box_reg: 0.5336  loss_mask: 0.3006  loss_rpn_cls: 0.07244  loss_rpn_loc: 0.1917  time: 0.5895  data_time: 0.1104  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:46:33 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 8339  total_loss: 1.287  loss_cls: 0.2729  loss_box_reg: 0.5152  loss_mask: 0.3045  loss_rpn_cls: 0.05948  loss_rpn_loc: 0.1835  time: 0.5892  data_time: 0.1632  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:46:48 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 8359  total_loss: 1.368  loss_cls: 0.3079  loss_box_reg: 0.4866  loss_mask: 0.3076  loss_rpn_cls: 0.08331  loss_rpn_loc: 0.1985  time: 0.5896  data_time: 0.4325  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:46:59 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 8379  total_loss: 1.454  loss_cls: 0.3577  loss_box_reg: 0.5009  loss_mask: 0.2958  loss_rpn_cls: 0.07942  loss_rpn_loc: 0.1817  time: 0.5895  data_time: 0.2115  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:47:10 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 8399  total_loss: 1.45  loss_cls: 0.3412  loss_box_reg: 0.5203  loss_mask: 0.2935  loss_rpn_cls: 0.08705  loss_rpn_loc: 0.1893  time: 0.5895  data_time: 0.2671  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:47:26 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 8419  total_loss: 1.465  loss_cls: 0.3274  loss_box_reg: 0.4984  loss_mask: 0.2956  loss_rpn_cls: 0.0912  loss_rpn_loc: 0.2068  time: 0.5899  data_time: 0.4407  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:47:40 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 8439  total_loss: 1.507  loss_cls: 0.3485  loss_box_reg: 0.5374  loss_mask: 0.3105  loss_rpn_cls: 0.08098  loss_rpn_loc: 0.1981  time: 0.5902  data_time: 0.3741  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:47:48 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 8459  total_loss: 1.405  loss_cls: 0.3452  loss_box_reg: 0.5061  loss_mask: 0.3002  loss_rpn_cls: 0.07775  loss_rpn_loc: 0.1787  time: 0.5897  data_time: 0.1001  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:47:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:47:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:47:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:47:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:47:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:47:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:47:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0696 s/iter. Eval: 0.0512 s/iter. Total: 0.1216 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:48:02 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0576 s/iter. Total: 0.1297 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0720 s/iter. Eval: 0.0611 s/iter. Total: 0.1339 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:48:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.377299 (0.132563 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:48:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072119 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:48:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:48:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n",
      "\u001b[32m[02/02 20:48:19 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 8479  total_loss: 1.441  loss_cls: 0.3302  loss_box_reg: 0.4941  loss_mask: 0.3107  loss_rpn_cls: 0.08652  loss_rpn_loc: 0.2054  time: 0.5901  data_time: 0.3858  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:48:32 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 8499  total_loss: 1.383  loss_cls: 0.295  loss_box_reg: 0.4987  loss_mask: 0.3142  loss_rpn_cls: 0.08682  loss_rpn_loc: 0.2063  time: 0.5902  data_time: 0.3071  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:48:41 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 8519  total_loss: 1.447  loss_cls: 0.3363  loss_box_reg: 0.54  loss_mask: 0.3044  loss_rpn_cls: 0.07542  loss_rpn_loc: 0.1817  time: 0.5898  data_time: 0.1301  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:48:54 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 8539  total_loss: 1.417  loss_cls: 0.3383  loss_box_reg: 0.505  loss_mask: 0.301  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.19  time: 0.5900  data_time: 0.3612  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:49:08 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 8559  total_loss: 1.421  loss_cls: 0.342  loss_box_reg: 0.5132  loss_mask: 0.2928  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2019  time: 0.5902  data_time: 0.3472  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:49:19 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 8579  total_loss: 1.545  loss_cls: 0.3494  loss_box_reg: 0.5374  loss_mask: 0.3143  loss_rpn_cls: 0.08715  loss_rpn_loc: 0.2225  time: 0.5901  data_time: 0.2258  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:49:31 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 8599  total_loss: 1.363  loss_cls: 0.294  loss_box_reg: 0.5252  loss_mask: 0.2931  loss_rpn_cls: 0.07797  loss_rpn_loc: 0.1847  time: 0.5901  data_time: 0.2824  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:49:42 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 8619  total_loss: 1.452  loss_cls: 0.3454  loss_box_reg: 0.5139  loss_mask: 0.3169  loss_rpn_cls: 0.05856  loss_rpn_loc: 0.1929  time: 0.5901  data_time: 0.2479  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:49:52 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 8639  total_loss: 1.4  loss_cls: 0.299  loss_box_reg: 0.5355  loss_mask: 0.3122  loss_rpn_cls: 0.07255  loss_rpn_loc: 0.1912  time: 0.5899  data_time: 0.1922  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:50:06 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 8659  total_loss: 1.415  loss_cls: 0.2901  loss_box_reg: 0.513  loss_mask: 0.3107  loss_rpn_cls: 0.06822  loss_rpn_loc: 0.1831  time: 0.5901  data_time: 0.3849  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:50:20 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 8679  total_loss: 1.379  loss_cls: 0.309  loss_box_reg: 0.491  loss_mask: 0.291  loss_rpn_cls: 0.09321  loss_rpn_loc: 0.2043  time: 0.5904  data_time: 0.3802  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:50:29 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 8699  total_loss: 1.333  loss_cls: 0.2846  loss_box_reg: 0.531  loss_mask: 0.294  loss_rpn_cls: 0.05038  loss_rpn_loc: 0.1789  time: 0.5901  data_time: 0.1365  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:50:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:50:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:50:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:50:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:50:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:50:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0544 s/iter. Total: 0.1272 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0587 s/iter. Total: 0.1315 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0615 s/iter. Total: 0.1342 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:50:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.280748 (0.131731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:50:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071527 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:50:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n",
      "\u001b[32m[02/02 20:50:56 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 8719  total_loss: 1.436  loss_cls: 0.3334  loss_box_reg: 0.5362  loss_mask: 0.3017  loss_rpn_cls: 0.0549  loss_rpn_loc: 0.199  time: 0.5898  data_time: 0.1600  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:51:09 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 8739  total_loss: 1.352  loss_cls: 0.2858  loss_box_reg: 0.4772  loss_mask: 0.3047  loss_rpn_cls: 0.06572  loss_rpn_loc: 0.1878  time: 0.5899  data_time: 0.3215  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:51:19 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 8759  total_loss: 1.476  loss_cls: 0.3572  loss_box_reg: 0.5554  loss_mask: 0.2966  loss_rpn_cls: 0.08413  loss_rpn_loc: 0.1822  time: 0.5898  data_time: 0.2007  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:51:31 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 8779  total_loss: 1.317  loss_cls: 0.2826  loss_box_reg: 0.471  loss_mask: 0.3061  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.187  time: 0.5897  data_time: 0.2659  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:51:44 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 8799  total_loss: 1.45  loss_cls: 0.341  loss_box_reg: 0.5219  loss_mask: 0.3007  loss_rpn_cls: 0.07086  loss_rpn_loc: 0.1956  time: 0.5899  data_time: 0.3277  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:51:55 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 8819  total_loss: 1.509  loss_cls: 0.3647  loss_box_reg: 0.5285  loss_mask: 0.3103  loss_rpn_cls: 0.09952  loss_rpn_loc: 0.213  time: 0.5898  data_time: 0.2537  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:52:08 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 8839  total_loss: 1.419  loss_cls: 0.3304  loss_box_reg: 0.5042  loss_mask: 0.3139  loss_rpn_cls: 0.07482  loss_rpn_loc: 0.1986  time: 0.5899  data_time: 0.3226  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:52:22 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 8859  total_loss: 1.412  loss_cls: 0.3475  loss_box_reg: 0.5085  loss_mask: 0.3015  loss_rpn_cls: 0.06783  loss_rpn_loc: 0.2057  time: 0.5902  data_time: 0.3740  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:52:34 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 8879  total_loss: 1.452  loss_cls: 0.3113  loss_box_reg: 0.4987  loss_mask: 0.2966  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.2072  time: 0.5902  data_time: 0.2844  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:52:47 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 8899  total_loss: 1.443  loss_cls: 0.3261  loss_box_reg: 0.4941  loss_mask: 0.3082  loss_rpn_cls: 0.07852  loss_rpn_loc: 0.1831  time: 0.5904  data_time: 0.3461  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:53:00 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 8919  total_loss: 1.435  loss_cls: 0.3399  loss_box_reg: 0.4935  loss_mask: 0.3138  loss_rpn_cls: 0.08798  loss_rpn_loc: 0.202  time: 0.5905  data_time: 0.3045  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:53:12 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 8939  total_loss: 1.483  loss_cls: 0.3741  loss_box_reg: 0.5386  loss_mask: 0.296  loss_rpn_cls: 0.07023  loss_rpn_loc: 0.1964  time: 0.5905  data_time: 0.2737  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:53:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:53:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:53:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:53:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:53:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:53:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:53:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0024 s/iter. Inference: 0.0730 s/iter. Eval: 0.0493 s/iter. Total: 0.1247 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:53:26 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0010 s/iter. Inference: 0.0736 s/iter. Eval: 0.0610 s/iter. Total: 0.1356 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:53:31 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0009 s/iter. Inference: 0.0731 s/iter. Eval: 0.0625 s/iter. Total: 0.1366 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:53:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.424976 (0.132974 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:53:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072211 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:53:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:53:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n",
      "\u001b[32m[02/02 20:53:39 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 8959  total_loss: 1.399  loss_cls: 0.3258  loss_box_reg: 0.513  loss_mask: 0.2833  loss_rpn_cls: 0.07754  loss_rpn_loc: 0.1891  time: 0.5903  data_time: 0.1592  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:53:50 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 8979  total_loss: 1.431  loss_cls: 0.3153  loss_box_reg: 0.5133  loss_mask: 0.2909  loss_rpn_cls: 0.08428  loss_rpn_loc: 0.1964  time: 0.5902  data_time: 0.2555  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:54:03 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 8999  total_loss: 1.391  loss_cls: 0.2994  loss_box_reg: 0.4987  loss_mask: 0.3236  loss_rpn_cls: 0.08534  loss_rpn_loc: 0.19  time: 0.5903  data_time: 0.3184  lr: 5e-11  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:54:19 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 9019  total_loss: 1.469  loss_cls: 0.357  loss_box_reg: 0.5211  loss_mask: 0.3062  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.2144  time: 0.5908  data_time: 0.4569  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:54:29 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 9039  total_loss: 1.44  loss_cls: 0.3141  loss_box_reg: 0.5403  loss_mask: 0.294  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1821  time: 0.5906  data_time: 0.2016  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:54:41 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 9059  total_loss: 1.461  loss_cls: 0.334  loss_box_reg: 0.4707  loss_mask: 0.3145  loss_rpn_cls: 0.085  loss_rpn_loc: 0.1875  time: 0.5906  data_time: 0.2751  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:54:52 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9079  total_loss: 1.383  loss_cls: 0.3173  loss_box_reg: 0.5319  loss_mask: 0.2979  loss_rpn_cls: 0.07725  loss_rpn_loc: 0.1941  time: 0.5905  data_time: 0.2457  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:55:03 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 9099  total_loss: 1.426  loss_cls: 0.3502  loss_box_reg: 0.4836  loss_mask: 0.2962  loss_rpn_cls: 0.0827  loss_rpn_loc: 0.1872  time: 0.5905  data_time: 0.2690  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:55:13 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 9119  total_loss: 1.367  loss_cls: 0.3089  loss_box_reg: 0.5439  loss_mask: 0.3073  loss_rpn_cls: 0.06842  loss_rpn_loc: 0.1937  time: 0.5902  data_time: 0.1689  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:55:25 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 9139  total_loss: 1.387  loss_cls: 0.3098  loss_box_reg: 0.4808  loss_mask: 0.2998  loss_rpn_cls: 0.08921  loss_rpn_loc: 0.1971  time: 0.5903  data_time: 0.2982  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:55:33 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 9159  total_loss: 1.592  loss_cls: 0.3868  loss_box_reg: 0.5715  loss_mask: 0.3027  loss_rpn_cls: 0.08421  loss_rpn_loc: 0.2007  time: 0.5899  data_time: 0.1204  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:55:45 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 9179  total_loss: 1.388  loss_cls: 0.321  loss_box_reg: 0.4926  loss_mask: 0.2976  loss_rpn_cls: 0.07951  loss_rpn_loc: 0.1989  time: 0.5899  data_time: 0.2670  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:55:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:55:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:55:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:55:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:55:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:55:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0708 s/iter. Eval: 0.0510 s/iter. Total: 0.1226 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0600 s/iter. Total: 0.1325 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0723 s/iter. Eval: 0.0629 s/iter. Total: 0.1360 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:56:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.431913 (0.133034 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:56:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071836 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:56:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:56:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n",
      "\u001b[32m[02/02 20:56:11 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 9199  total_loss: 1.276  loss_cls: 0.275  loss_box_reg: 0.4918  loss_mask: 0.284  loss_rpn_cls: 0.05859  loss_rpn_loc: 0.1674  time: 0.5896  data_time: 0.1306  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:56:23 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 9219  total_loss: 1.374  loss_cls: 0.312  loss_box_reg: 0.5235  loss_mask: 0.3042  loss_rpn_cls: 0.08347  loss_rpn_loc: 0.2077  time: 0.5896  data_time: 0.3174  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:56:35 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9239  total_loss: 1.395  loss_cls: 0.3106  loss_box_reg: 0.5097  loss_mask: 0.2919  loss_rpn_cls: 0.06739  loss_rpn_loc: 0.1908  time: 0.5896  data_time: 0.2548  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:56:47 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 9259  total_loss: 1.521  loss_cls: 0.346  loss_box_reg: 0.5251  loss_mask: 0.3022  loss_rpn_cls: 0.08726  loss_rpn_loc: 0.2147  time: 0.5896  data_time: 0.2949  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:57:03 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 9279  total_loss: 1.408  loss_cls: 0.313  loss_box_reg: 0.4916  loss_mask: 0.3116  loss_rpn_cls: 0.09369  loss_rpn_loc: 0.1931  time: 0.5901  data_time: 0.4634  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:57:14 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 9299  total_loss: 1.383  loss_cls: 0.3147  loss_box_reg: 0.5335  loss_mask: 0.2987  loss_rpn_cls: 0.07142  loss_rpn_loc: 0.178  time: 0.5900  data_time: 0.2268  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:57:26 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 9319  total_loss: 1.458  loss_cls: 0.336  loss_box_reg: 0.4884  loss_mask: 0.3022  loss_rpn_cls: 0.07469  loss_rpn_loc: 0.1956  time: 0.5900  data_time: 0.3047  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:57:39 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 9339  total_loss: 1.363  loss_cls: 0.3049  loss_box_reg: 0.4839  loss_mask: 0.3033  loss_rpn_cls: 0.07627  loss_rpn_loc: 0.196  time: 0.5901  data_time: 0.3173  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:57:49 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 9359  total_loss: 1.423  loss_cls: 0.3263  loss_box_reg: 0.5237  loss_mask: 0.2975  loss_rpn_cls: 0.08222  loss_rpn_loc: 0.1848  time: 0.5900  data_time: 0.2087  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:58:03 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 9379  total_loss: 1.418  loss_cls: 0.3345  loss_box_reg: 0.4899  loss_mask: 0.2966  loss_rpn_cls: 0.0855  loss_rpn_loc: 0.1966  time: 0.5902  data_time: 0.3575  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:58:16 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9399  total_loss: 1.402  loss_cls: 0.3117  loss_box_reg: 0.5067  loss_mask: 0.3037  loss_rpn_cls: 0.07309  loss_rpn_loc: 0.2127  time: 0.5903  data_time: 0.3444  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:58:24 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9419  total_loss: 1.358  loss_cls: 0.3325  loss_box_reg: 0.5143  loss_mask: 0.2934  loss_rpn_cls: 0.05584  loss_rpn_loc: 0.1689  time: 0.5899  data_time: 0.0791  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:58:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:58:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 20:58:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 20:58:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 20:58:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 20:58:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 20:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0713 s/iter. Eval: 0.0518 s/iter. Total: 0.1239 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 20:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0726 s/iter. Eval: 0.0598 s/iter. Total: 0.1332 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 20:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0727 s/iter. Eval: 0.0628 s/iter. Total: 0.1364 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 20:58:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.494180 (0.133571 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:58:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072317 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 20:58:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 20:58:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n",
      "\u001b[32m[02/02 20:58:50 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9439  total_loss: 1.453  loss_cls: 0.3183  loss_box_reg: 0.5439  loss_mask: 0.3018  loss_rpn_cls: 0.08891  loss_rpn_loc: 0.1859  time: 0.5896  data_time: 0.1555  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:59:02 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 9459  total_loss: 1.389  loss_cls: 0.3146  loss_box_reg: 0.4907  loss_mask: 0.2995  loss_rpn_cls: 0.07297  loss_rpn_loc: 0.1955  time: 0.5897  data_time: 0.2774  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:59:12 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 9479  total_loss: 1.51  loss_cls: 0.3371  loss_box_reg: 0.535  loss_mask: 0.3122  loss_rpn_cls: 0.08162  loss_rpn_loc: 0.1821  time: 0.5895  data_time: 0.1892  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:59:24 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 9499  total_loss: 1.354  loss_cls: 0.3048  loss_box_reg: 0.5125  loss_mask: 0.2985  loss_rpn_cls: 0.08837  loss_rpn_loc: 0.1826  time: 0.5894  data_time: 0.2536  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:59:32 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 9519  total_loss: 1.481  loss_cls: 0.3095  loss_box_reg: 0.5602  loss_mask: 0.3061  loss_rpn_cls: 0.05785  loss_rpn_loc: 0.1835  time: 0.5890  data_time: 0.0964  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:59:41 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 9539  total_loss: 1.441  loss_cls: 0.3357  loss_box_reg: 0.515  loss_mask: 0.305  loss_rpn_cls: 0.08687  loss_rpn_loc: 0.1906  time: 0.5888  data_time: 0.1611  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 20:59:51 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9559  total_loss: 1.477  loss_cls: 0.3744  loss_box_reg: 0.5432  loss_mask: 0.3005  loss_rpn_cls: 0.0892  loss_rpn_loc: 0.2092  time: 0.5886  data_time: 0.1870  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:00:05 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 9579  total_loss: 1.446  loss_cls: 0.3267  loss_box_reg: 0.4866  loss_mask: 0.3081  loss_rpn_cls: 0.08558  loss_rpn_loc: 0.2059  time: 0.5888  data_time: 0.3761  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:00:15 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 9599  total_loss: 1.394  loss_cls: 0.2948  loss_box_reg: 0.4932  loss_mask: 0.3054  loss_rpn_cls: 0.07402  loss_rpn_loc: 0.2024  time: 0.5887  data_time: 0.2096  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:00:27 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 9619  total_loss: 1.411  loss_cls: 0.3172  loss_box_reg: 0.5076  loss_mask: 0.3032  loss_rpn_cls: 0.08122  loss_rpn_loc: 0.2021  time: 0.5887  data_time: 0.2899  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:00:38 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 9639  total_loss: 1.388  loss_cls: 0.3052  loss_box_reg: 0.5157  loss_mask: 0.3029  loss_rpn_cls: 0.07971  loss_rpn_loc: 0.1952  time: 0.5886  data_time: 0.2077  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:00:54 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 9659  total_loss: 1.395  loss_cls: 0.3348  loss_box_reg: 0.4963  loss_mask: 0.3013  loss_rpn_cls: 0.08571  loss_rpn_loc: 0.2061  time: 0.5889  data_time: 0.4358  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:01:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 21:01:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 21:01:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 21:01:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 21:01:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 21:01:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 21:01:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0731 s/iter. Eval: 0.0522 s/iter. Total: 0.1261 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 21:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0737 s/iter. Eval: 0.0603 s/iter. Total: 0.1349 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/02 21:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0734 s/iter. Eval: 0.0628 s/iter. Total: 0.1370 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 21:01:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.607574 (0.134548 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 21:01:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072998 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 21:01:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 21:01:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n",
      "\u001b[32m[02/02 21:01:22 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 9679  total_loss: 1.344  loss_cls: 0.3157  loss_box_reg: 0.4951  loss_mask: 0.2873  loss_rpn_cls: 0.07569  loss_rpn_loc: 0.1889  time: 0.5889  data_time: 0.2427  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:01:34 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 9699  total_loss: 1.35  loss_cls: 0.3429  loss_box_reg: 0.4792  loss_mask: 0.2873  loss_rpn_cls: 0.09351  loss_rpn_loc: 0.2043  time: 0.5889  data_time: 0.2785  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:01:45 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9719  total_loss: 1.442  loss_cls: 0.367  loss_box_reg: 0.51  loss_mask: 0.2938  loss_rpn_cls: 0.09782  loss_rpn_loc: 0.1936  time: 0.5888  data_time: 0.2303  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:02:00 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 9739  total_loss: 1.45  loss_cls: 0.3364  loss_box_reg: 0.4862  loss_mask: 0.3182  loss_rpn_cls: 0.09798  loss_rpn_loc: 0.2172  time: 0.5891  data_time: 0.4162  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:02:13 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 9759  total_loss: 1.359  loss_cls: 0.3043  loss_box_reg: 0.4894  loss_mask: 0.2874  loss_rpn_cls: 0.09413  loss_rpn_loc: 0.1934  time: 0.5893  data_time: 0.3519  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:02:24 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 9779  total_loss: 1.457  loss_cls: 0.3759  loss_box_reg: 0.5088  loss_mask: 0.3068  loss_rpn_cls: 0.08299  loss_rpn_loc: 0.1883  time: 0.5892  data_time: 0.2112  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:02:34 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 9799  total_loss: 1.435  loss_cls: 0.3411  loss_box_reg: 0.5293  loss_mask: 0.3104  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.1923  time: 0.5891  data_time: 0.2174  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:02:44 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 9819  total_loss: 1.459  loss_cls: 0.3552  loss_box_reg: 0.5159  loss_mask: 0.2926  loss_rpn_cls: 0.07432  loss_rpn_loc: 0.1966  time: 0.5889  data_time: 0.1968  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:02:58 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 9839  total_loss: 1.37  loss_cls: 0.2851  loss_box_reg: 0.528  loss_mask: 0.3106  loss_rpn_cls: 0.08928  loss_rpn_loc: 0.1998  time: 0.5890  data_time: 0.3338  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:03:07 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 9859  total_loss: 1.263  loss_cls: 0.3029  loss_box_reg: 0.4726  loss_mask: 0.2867  loss_rpn_cls: 0.07195  loss_rpn_loc: 0.1851  time: 0.5888  data_time: 0.1625  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:03:19 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9879  total_loss: 1.535  loss_cls: 0.3575  loss_box_reg: 0.5497  loss_mask: 0.323  loss_rpn_cls: 0.08522  loss_rpn_loc: 0.1975  time: 0.5888  data_time: 0.3003  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:03:31 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 9899  total_loss: 1.453  loss_cls: 0.3355  loss_box_reg: 0.4919  loss_mask: 0.293  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.1937  time: 0.5888  data_time: 0.2796  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:03:45 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 9919  total_loss: 1.327  loss_cls: 0.3157  loss_box_reg: 0.5032  loss_mask: 0.293  loss_rpn_cls: 0.05483  loss_rpn_loc: 0.1851  time: 0.5890  data_time: 0.3414  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:03:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 21:03:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 21:03:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 21:03:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 21:03:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 21:03:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 21:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0696 s/iter. Eval: 0.0508 s/iter. Total: 0.1213 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 21:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0010 s/iter. Inference: 0.0739 s/iter. Eval: 0.0637 s/iter. Total: 0.1386 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 21:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0009 s/iter. Inference: 0.0729 s/iter. Eval: 0.0633 s/iter. Total: 0.1371 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/02 21:04:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.545290 (0.134011 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 21:04:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072136 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 21:04:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 21:04:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n",
      "\u001b[32m[02/02 21:04:12 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9939  total_loss: 1.467  loss_cls: 0.3192  loss_box_reg: 0.5228  loss_mask: 0.2992  loss_rpn_cls: 0.06094  loss_rpn_loc: 0.1977  time: 0.5889  data_time: 0.2175  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:04:22 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 9959  total_loss: 1.419  loss_cls: 0.2947  loss_box_reg: 0.5049  loss_mask: 0.304  loss_rpn_cls: 0.07952  loss_rpn_loc: 0.1862  time: 0.5887  data_time: 0.1913  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:04:32 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 9979  total_loss: 1.398  loss_cls: 0.3411  loss_box_reg: 0.528  loss_mask: 0.3075  loss_rpn_cls: 0.07614  loss_rpn_loc: 0.183  time: 0.5885  data_time: 0.1974  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:04:43 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.471  loss_cls: 0.3499  loss_box_reg: 0.5092  loss_mask: 0.303  loss_rpn_cls: 0.09862  loss_rpn_loc: 0.1891  time: 0.5884  data_time: 0.1917  lr: 5e-12  max_mem: 6684M\n",
      "\u001b[32m[02/02 21:04:43 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:38:02 (0.5884 s / it)\n",
      "\u001b[32m[02/02 21:04:43 d2.engine.hooks]: \u001b[0mTotal training time: 1:49:24 (0:11:22 on hooks)\n",
      "\u001b[32m[02/02 21:04:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 21:04:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/02 21:04:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/02 21:04:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/02 21:04:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/02 21:04:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/02 21:04:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.0705 s/iter. Eval: 0.0539 s/iter. Total: 0.1260 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/02 21:04:50 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0009 s/iter. Inference: 0.0717 s/iter. Eval: 0.0651 s/iter. Total: 0.1377 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/02 21:04:55 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0641 s/iter. Total: 0.1367 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/02 21:05:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.448136 (0.133174 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 21:05:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071298 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/02 21:05:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/02 21:05:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2611939516473268\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.0005 with gamma=0.1 and lr reduction every 1000 iterations starting from iteration 2000\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.1\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_8.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af362349-94f2-4b45-9f1a-4f0d352139d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/03 14:38:56 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/03 14:38:57 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/03 14:38:58 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/03 14:38:58 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/03 14:38:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/03 14:38:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/03 14:38:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/03 14:38:59 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:38:59 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/03 14:38:59 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/03 14:39:11 d2.utils.events]: \u001b[0m eta: 0:55:52  iter: 19  total_loss: 3.033  loss_cls: 1.345  loss_box_reg: 0.4651  loss_mask: 0.6917  loss_rpn_cls: 0.3185  loss_rpn_loc: 0.2383  time: 0.5531  data_time: 0.2877  lr: 9.9905e-06  max_mem: 6514M\n",
      "\u001b[32m[02/03 14:39:23 d2.utils.events]: \u001b[0m eta: 0:55:15  iter: 39  total_loss: 2.989  loss_cls: 1.275  loss_box_reg: 0.3904  loss_mask: 0.6853  loss_rpn_cls: 0.322  loss_rpn_loc: 0.2452  time: 0.5804  data_time: 0.2821  lr: 1.998e-05  max_mem: 6514M\n",
      "\u001b[32m[02/03 14:39:36 d2.utils.events]: \u001b[0m eta: 0:54:45  iter: 59  total_loss: 2.794  loss_cls: 1.16  loss_box_reg: 0.4584  loss_mask: 0.6686  loss_rpn_cls: 0.2149  loss_rpn_loc: 0.2261  time: 0.5976  data_time: 0.3071  lr: 2.997e-05  max_mem: 6909M\n",
      "\u001b[32m[02/03 14:39:48 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 79  total_loss: 2.596  loss_cls: 0.9762  loss_box_reg: 0.4754  loss_mask: 0.6427  loss_rpn_cls: 0.2733  loss_rpn_loc: 0.2543  time: 0.5984  data_time: 0.2946  lr: 3.9961e-05  max_mem: 6909M\n",
      "\u001b[32m[02/03 14:40:02 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 99  total_loss: 2.328  loss_cls: 0.8268  loss_box_reg: 0.4483  loss_mask: 0.6108  loss_rpn_cls: 0.224  loss_rpn_loc: 0.2231  time: 0.6196  data_time: 0.3815  lr: 4.9951e-05  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:40:16 d2.utils.events]: \u001b[0m eta: 0:54:37  iter: 119  total_loss: 2.346  loss_cls: 0.7628  loss_box_reg: 0.4405  loss_mask: 0.5857  loss_rpn_cls: 0.2226  loss_rpn_loc: 0.2533  time: 0.6335  data_time: 0.3724  lr: 5.9941e-05  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:40:28 d2.utils.events]: \u001b[0m eta: 0:54:45  iter: 139  total_loss: 2.206  loss_cls: 0.7201  loss_box_reg: 0.5723  loss_mask: 0.5596  loss_rpn_cls: 0.1696  loss_rpn_loc: 0.234  time: 0.6289  data_time: 0.2786  lr: 6.993e-05  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:40:38 d2.utils.events]: \u001b[0m eta: 0:54:29  iter: 159  total_loss: 2.298  loss_cls: 0.7244  loss_box_reg: 0.5918  loss_mask: 0.524  loss_rpn_cls: 0.1872  loss_rpn_loc: 0.2359  time: 0.6144  data_time: 0.2153  lr: 7.9921e-05  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:40:50 d2.utils.events]: \u001b[0m eta: 0:54:11  iter: 179  total_loss: 2.146  loss_cls: 0.6704  loss_box_reg: 0.6274  loss_mask: 0.4887  loss_rpn_cls: 0.1583  loss_rpn_loc: 0.223  time: 0.6116  data_time: 0.2827  lr: 8.991e-05  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:41:03 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 199  total_loss: 2.129  loss_cls: 0.6686  loss_box_reg: 0.6159  loss_mask: 0.489  loss_rpn_cls: 0.1468  loss_rpn_loc: 0.2473  time: 0.6138  data_time: 0.3071  lr: 9.9901e-05  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:41:12 d2.utils.events]: \u001b[0m eta: 0:54:18  iter: 219  total_loss: 2.113  loss_cls: 0.636  loss_box_reg: 0.6926  loss_mask: 0.4441  loss_rpn_cls: 0.123  loss_rpn_loc: 0.2133  time: 0.6017  data_time: 0.1602  lr: 0.00010989  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:41:24 d2.utils.events]: \u001b[0m eta: 0:54:11  iter: 239  total_loss: 1.976  loss_cls: 0.5633  loss_box_reg: 0.6026  loss_mask: 0.4283  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2248  time: 0.6002  data_time: 0.2664  lr: 0.00011988  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:41:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:41:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 14:41:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:41:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 14:41:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:41:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 14:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0624 s/iter. Eval: 0.0010 s/iter. Total: 0.0639 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/03 14:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0644 s/iter. Eval: 0.0007 s/iter. Total: 0.0658 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/03 14:41:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.611367 (0.065615 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:41:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.063865 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:41:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 14:41:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.005152608643683925\n",
      "\u001b[32m[02/03 14:41:47 d2.utils.events]: \u001b[0m eta: 0:54:19  iter: 259  total_loss: 1.957  loss_cls: 0.5747  loss_box_reg: 0.6598  loss_mask: 0.3911  loss_rpn_cls: 0.1417  loss_rpn_loc: 0.2233  time: 0.6107  data_time: 0.4051  lr: 0.00012987  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:42:00 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 279  total_loss: 1.832  loss_cls: 0.4773  loss_box_reg: 0.6085  loss_mask: 0.3849  loss_rpn_cls: 0.1358  loss_rpn_loc: 0.235  time: 0.6124  data_time: 0.3218  lr: 0.00013986  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:42:11 d2.utils.events]: \u001b[0m eta: 0:53:57  iter: 299  total_loss: 1.811  loss_cls: 0.4808  loss_box_reg: 0.6566  loss_mask: 0.3544  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.2237  time: 0.6073  data_time: 0.2315  lr: 0.00014985  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:42:22 d2.utils.events]: \u001b[0m eta: 0:53:51  iter: 319  total_loss: 1.78  loss_cls: 0.4646  loss_box_reg: 0.6875  loss_mask: 0.3404  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.2015  time: 0.6047  data_time: 0.2500  lr: 0.00015984  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:42:34 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 339  total_loss: 1.748  loss_cls: 0.4359  loss_box_reg: 0.6403  loss_mask: 0.3451  loss_rpn_cls: 0.124  loss_rpn_loc: 0.2245  time: 0.6031  data_time: 0.2597  lr: 0.00016983  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:42:45 d2.utils.events]: \u001b[0m eta: 0:53:23  iter: 359  total_loss: 1.758  loss_cls: 0.4502  loss_box_reg: 0.6355  loss_mask: 0.3416  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.2228  time: 0.6007  data_time: 0.2470  lr: 0.00017982  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:42:53 d2.utils.events]: \u001b[0m eta: 0:53:15  iter: 379  total_loss: 1.613  loss_cls: 0.3556  loss_box_reg: 0.652  loss_mask: 0.3218  loss_rpn_cls: 0.08708  loss_rpn_loc: 0.2093  time: 0.5911  data_time: 0.1172  lr: 0.00018981  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:43:07 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 399  total_loss: 1.676  loss_cls: 0.3999  loss_box_reg: 0.6096  loss_mask: 0.3244  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.2098  time: 0.5950  data_time: 0.3499  lr: 0.0001998  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:43:21 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 419  total_loss: 1.666  loss_cls: 0.4042  loss_box_reg: 0.5607  loss_mask: 0.3238  loss_rpn_cls: 0.1198  loss_rpn_loc: 0.2535  time: 0.6017  data_time: 0.4150  lr: 0.00020979  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:43:33 d2.utils.events]: \u001b[0m eta: 0:52:56  iter: 439  total_loss: 1.747  loss_cls: 0.4186  loss_box_reg: 0.6491  loss_mask: 0.3109  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.2139  time: 0.6003  data_time: 0.2653  lr: 0.00021978  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:43:44 d2.utils.events]: \u001b[0m eta: 0:52:51  iter: 459  total_loss: 1.766  loss_cls: 0.4708  loss_box_reg: 0.6098  loss_mask: 0.3432  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.2439  time: 0.5972  data_time: 0.2101  lr: 0.00022977  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:43:56 d2.utils.events]: \u001b[0m eta: 0:52:49  iter: 479  total_loss: 1.548  loss_cls: 0.3521  loss_box_reg: 0.6024  loss_mask: 0.3067  loss_rpn_cls: 0.09945  loss_rpn_loc: 0.2214  time: 0.5978  data_time: 0.2840  lr: 0.00023976  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:43:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:43:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 14:43:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:43:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 14:43:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:43:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 14:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0717 s/iter. Eval: 0.0349 s/iter. Total: 0.1072 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 14:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 53/121. Dataloading: 0.0007 s/iter. Inference: 0.0699 s/iter. Eval: 0.0470 s/iter. Total: 0.1177 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 14:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0503 s/iter. Total: 0.1213 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 14:44:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.835829 (0.119274 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:44:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069942 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:44:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 14:44:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21108000262455023\n",
      "\u001b[32m[02/03 14:44:18 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 499  total_loss: 1.709  loss_cls: 0.4032  loss_box_reg: 0.6488  loss_mask: 0.3206  loss_rpn_cls: 0.08473  loss_rpn_loc: 0.2131  time: 0.5873  data_time: 0.0314  lr: 0.00024975  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:44:30 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 519  total_loss: 1.635  loss_cls: 0.4047  loss_box_reg: 0.5735  loss_mask: 0.3125  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.211  time: 0.5883  data_time: 0.2967  lr: 0.00025974  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:44:41 d2.utils.events]: \u001b[0m eta: 0:52:22  iter: 539  total_loss: 1.546  loss_cls: 0.3679  loss_box_reg: 0.5598  loss_mask: 0.3243  loss_rpn_cls: 0.08134  loss_rpn_loc: 0.2053  time: 0.5873  data_time: 0.2542  lr: 0.00026973  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:44:52 d2.utils.events]: \u001b[0m eta: 0:52:15  iter: 559  total_loss: 1.581  loss_cls: 0.409  loss_box_reg: 0.5826  loss_mask: 0.3117  loss_rpn_cls: 0.09159  loss_rpn_loc: 0.201  time: 0.5857  data_time: 0.2286  lr: 0.00027972  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:45:06 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 579  total_loss: 1.524  loss_cls: 0.3493  loss_box_reg: 0.5687  loss_mask: 0.3204  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.216  time: 0.5892  data_time: 0.3630  lr: 0.00028971  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:45:17 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 599  total_loss: 1.677  loss_cls: 0.4462  loss_box_reg: 0.584  loss_mask: 0.3201  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2185  time: 0.5888  data_time: 0.2638  lr: 0.0002997  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:45:30 d2.utils.events]: \u001b[0m eta: 0:52:00  iter: 619  total_loss: 1.672  loss_cls: 0.3852  loss_box_reg: 0.5939  loss_mask: 0.3167  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.2213  time: 0.5899  data_time: 0.3050  lr: 0.00030969  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:45:43 d2.utils.events]: \u001b[0m eta: 0:51:55  iter: 639  total_loss: 1.529  loss_cls: 0.388  loss_box_reg: 0.5654  loss_mask: 0.3129  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.1999  time: 0.5922  data_time: 0.3340  lr: 0.00031968  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:45:55 d2.utils.events]: \u001b[0m eta: 0:51:48  iter: 659  total_loss: 1.553  loss_cls: 0.361  loss_box_reg: 0.5517  loss_mask: 0.3083  loss_rpn_cls: 0.08972  loss_rpn_loc: 0.2049  time: 0.5918  data_time: 0.2602  lr: 0.00032967  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:46:06 d2.utils.events]: \u001b[0m eta: 0:51:42  iter: 679  total_loss: 1.529  loss_cls: 0.3708  loss_box_reg: 0.587  loss_mask: 0.3023  loss_rpn_cls: 0.09972  loss_rpn_loc: 0.2089  time: 0.5912  data_time: 0.2663  lr: 0.00033966  max_mem: 7501M\n",
      "\u001b[32m[02/03 14:46:21 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 699  total_loss: 1.66  loss_cls: 0.4007  loss_box_reg: 0.5704  loss_mask: 0.3166  loss_rpn_cls: 0.118  loss_rpn_loc: 0.2228  time: 0.5958  data_time: 0.4149  lr: 0.00034965  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:46:32 d2.utils.events]: \u001b[0m eta: 0:51:28  iter: 719  total_loss: 1.485  loss_cls: 0.2909  loss_box_reg: 0.5484  loss_mask: 0.3153  loss_rpn_cls: 0.08487  loss_rpn_loc: 0.1982  time: 0.5941  data_time: 0.2288  lr: 0.00035964  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:46:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:46:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 14:46:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:46:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 14:46:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:46:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 14:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0675 s/iter. Eval: 0.0324 s/iter. Total: 0.1006 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 14:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0514 s/iter. Total: 0.1231 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 14:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0718 s/iter. Eval: 0.0549 s/iter. Total: 0.1275 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 14:46:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.575231 (0.125649 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:46:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071222 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:46:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 14:46:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23516086095092326\n",
      "\u001b[32m[02/03 14:47:04 d2.utils.events]: \u001b[0m eta: 0:51:25  iter: 739  total_loss: 1.653  loss_cls: 0.3781  loss_box_reg: 0.54  loss_mask: 0.3284  loss_rpn_cls: 0.1458  loss_rpn_loc: 0.2218  time: 0.6001  data_time: 0.4721  lr: 0.00036963  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:47:17 d2.utils.events]: \u001b[0m eta: 0:51:17  iter: 759  total_loss: 1.572  loss_cls: 0.395  loss_box_reg: 0.5776  loss_mask: 0.306  loss_rpn_cls: 0.09006  loss_rpn_loc: 0.2102  time: 0.6010  data_time: 0.3146  lr: 0.00037962  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:47:28 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 779  total_loss: 1.468  loss_cls: 0.3773  loss_box_reg: 0.5195  loss_mask: 0.2841  loss_rpn_cls: 0.07998  loss_rpn_loc: 0.1858  time: 0.5993  data_time: 0.2310  lr: 0.00038961  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:47:39 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 799  total_loss: 1.499  loss_cls: 0.3614  loss_box_reg: 0.5485  loss_mask: 0.3063  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.1991  time: 0.5984  data_time: 0.2386  lr: 0.0003996  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:47:52 d2.utils.events]: \u001b[0m eta: 0:50:57  iter: 819  total_loss: 1.484  loss_cls: 0.3364  loss_box_reg: 0.5217  loss_mask: 0.3159  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.2297  time: 0.6001  data_time: 0.3550  lr: 0.00040959  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:48:04 d2.utils.events]: \u001b[0m eta: 0:50:52  iter: 839  total_loss: 1.572  loss_cls: 0.3931  loss_box_reg: 0.5691  loss_mask: 0.3108  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.2186  time: 0.5997  data_time: 0.2740  lr: 0.00041958  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:48:16 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 859  total_loss: 1.59  loss_cls: 0.3615  loss_box_reg: 0.5649  loss_mask: 0.3102  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.2206  time: 0.5994  data_time: 0.2724  lr: 0.00042957  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:48:26 d2.utils.events]: \u001b[0m eta: 0:50:37  iter: 879  total_loss: 1.559  loss_cls: 0.3833  loss_box_reg: 0.5492  loss_mask: 0.2995  loss_rpn_cls: 0.1219  loss_rpn_loc: 0.2135  time: 0.5976  data_time: 0.2153  lr: 0.00043956  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:48:36 d2.utils.events]: \u001b[0m eta: 0:50:28  iter: 899  total_loss: 1.417  loss_cls: 0.3414  loss_box_reg: 0.5302  loss_mask: 0.2991  loss_rpn_cls: 0.08821  loss_rpn_loc: 0.1981  time: 0.5954  data_time: 0.1942  lr: 0.00044955  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:48:45 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 919  total_loss: 1.651  loss_cls: 0.3936  loss_box_reg: 0.6119  loss_mask: 0.3176  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.2016  time: 0.5925  data_time: 0.1582  lr: 0.00045954  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:48:59 d2.utils.events]: \u001b[0m eta: 0:50:15  iter: 939  total_loss: 1.565  loss_cls: 0.3768  loss_box_reg: 0.5629  loss_mask: 0.3034  loss_rpn_cls: 0.08557  loss_rpn_loc: 0.2172  time: 0.5945  data_time: 0.3575  lr: 0.00046953  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:49:07 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 959  total_loss: 1.618  loss_cls: 0.3305  loss_box_reg: 0.5426  loss_mask: 0.3001  loss_rpn_cls: 0.08339  loss_rpn_loc: 0.1967  time: 0.5909  data_time: 0.1115  lr: 0.00047952  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:49:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 14:49:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:49:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 14:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:49:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 14:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0674 s/iter. Eval: 0.0296 s/iter. Total: 0.0977 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 14:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 53/121. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.0479 s/iter. Total: 0.1185 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 14:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0538 s/iter. Total: 0.1265 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 14:49:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.520500 (0.125177 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:49:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071872 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:49:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 14:49:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23901245522223522\n",
      "\u001b[32m[02/03 14:49:39 d2.utils.events]: \u001b[0m eta: 0:50:01  iter: 979  total_loss: 1.576  loss_cls: 0.371  loss_box_reg: 0.5484  loss_mask: 0.3326  loss_rpn_cls: 0.0906  loss_rpn_loc: 0.2095  time: 0.5950  data_time: 0.4600  lr: 0.00048951  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:49:51 d2.utils.events]: \u001b[0m eta: 0:49:59  iter: 999  total_loss: 1.581  loss_cls: 0.3753  loss_box_reg: 0.5596  loss_mask: 0.3172  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.2116  time: 0.5947  data_time: 0.2448  lr: 0.0004995  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:50:02 d2.utils.events]: \u001b[0m eta: 0:49:53  iter: 1019  total_loss: 1.601  loss_cls: 0.3705  loss_box_reg: 0.5767  loss_mask: 0.3071  loss_rpn_cls: 0.08777  loss_rpn_loc: 0.2154  time: 0.5936  data_time: 0.2236  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:50:14 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 1039  total_loss: 1.403  loss_cls: 0.347  loss_box_reg: 0.5387  loss_mask: 0.2965  loss_rpn_cls: 0.09493  loss_rpn_loc: 0.2092  time: 0.5943  data_time: 0.3036  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:50:23 d2.utils.events]: \u001b[0m eta: 0:49:40  iter: 1059  total_loss: 1.396  loss_cls: 0.2979  loss_box_reg: 0.5162  loss_mask: 0.298  loss_rpn_cls: 0.08409  loss_rpn_loc: 0.1635  time: 0.5918  data_time: 0.1685  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:50:36 d2.utils.events]: \u001b[0m eta: 0:49:41  iter: 1079  total_loss: 1.541  loss_cls: 0.3574  loss_box_reg: 0.5834  loss_mask: 0.2989  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.2035  time: 0.5926  data_time: 0.3087  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:50:48 d2.utils.events]: \u001b[0m eta: 0:49:31  iter: 1099  total_loss: 1.552  loss_cls: 0.3506  loss_box_reg: 0.5562  loss_mask: 0.3155  loss_rpn_cls: 0.06816  loss_rpn_loc: 0.2038  time: 0.5924  data_time: 0.2656  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:51:02 d2.utils.events]: \u001b[0m eta: 0:49:25  iter: 1119  total_loss: 1.511  loss_cls: 0.3222  loss_box_reg: 0.5685  loss_mask: 0.3028  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.2319  time: 0.5942  data_time: 0.3678  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:51:15 d2.utils.events]: \u001b[0m eta: 0:49:18  iter: 1139  total_loss: 1.591  loss_cls: 0.365  loss_box_reg: 0.5487  loss_mask: 0.3187  loss_rpn_cls: 0.1264  loss_rpn_loc: 0.226  time: 0.5957  data_time: 0.3500  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:51:27 d2.utils.events]: \u001b[0m eta: 0:49:16  iter: 1159  total_loss: 1.524  loss_cls: 0.3302  loss_box_reg: 0.5612  loss_mask: 0.3157  loss_rpn_cls: 0.07474  loss_rpn_loc: 0.1738  time: 0.5956  data_time: 0.2714  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:51:35 d2.utils.events]: \u001b[0m eta: 0:49:05  iter: 1179  total_loss: 1.53  loss_cls: 0.3524  loss_box_reg: 0.5326  loss_mask: 0.3012  loss_rpn_cls: 0.08568  loss_rpn_loc: 0.1895  time: 0.5924  data_time: 0.1034  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:51:48 d2.utils.events]: \u001b[0m eta: 0:49:01  iter: 1199  total_loss: 1.523  loss_cls: 0.3642  loss_box_reg: 0.5461  loss_mask: 0.2985  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2103  time: 0.5929  data_time: 0.2866  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:51:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:51:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 14:51:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:51:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 14:51:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:51:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 14:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0689 s/iter. Eval: 0.0346 s/iter. Total: 0.1041 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 14:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0727 s/iter. Eval: 0.0553 s/iter. Total: 0.1289 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 14:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0732 s/iter. Eval: 0.0583 s/iter. Total: 0.1323 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 14:52:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.007868 (0.129378 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:52:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072426 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:52:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 14:52:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24698189823820718\n",
      "\u001b[32m[02/03 14:52:16 d2.utils.events]: \u001b[0m eta: 0:48:54  iter: 1219  total_loss: 1.572  loss_cls: 0.3396  loss_box_reg: 0.5425  loss_mask: 0.3077  loss_rpn_cls: 0.09641  loss_rpn_loc: 0.2105  time: 0.5927  data_time: 0.2581  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:52:27 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 1239  total_loss: 1.532  loss_cls: 0.363  loss_box_reg: 0.5405  loss_mask: 0.3066  loss_rpn_cls: 0.07429  loss_rpn_loc: 0.2024  time: 0.5922  data_time: 0.2439  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:52:38 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 1259  total_loss: 1.538  loss_cls: 0.3631  loss_box_reg: 0.5755  loss_mask: 0.3249  loss_rpn_cls: 0.09517  loss_rpn_loc: 0.2033  time: 0.5912  data_time: 0.2052  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:52:49 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 1279  total_loss: 1.482  loss_cls: 0.36  loss_box_reg: 0.552  loss_mask: 0.3052  loss_rpn_cls: 0.0909  loss_rpn_loc: 0.2104  time: 0.5906  data_time: 0.2474  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:52:59 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 1299  total_loss: 1.592  loss_cls: 0.3927  loss_box_reg: 0.5569  loss_mask: 0.3224  loss_rpn_cls: 0.09511  loss_rpn_loc: 0.218  time: 0.5893  data_time: 0.1907  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:53:10 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 1319  total_loss: 1.537  loss_cls: 0.4013  loss_box_reg: 0.5486  loss_mask: 0.3063  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.2027  time: 0.5890  data_time: 0.2532  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:53:21 d2.utils.events]: \u001b[0m eta: 0:48:10  iter: 1339  total_loss: 1.531  loss_cls: 0.3754  loss_box_reg: 0.5348  loss_mask: 0.3117  loss_rpn_cls: 0.09955  loss_rpn_loc: 0.2198  time: 0.5883  data_time: 0.2133  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:53:36 d2.utils.events]: \u001b[0m eta: 0:48:09  iter: 1359  total_loss: 1.645  loss_cls: 0.3757  loss_box_reg: 0.5783  loss_mask: 0.321  loss_rpn_cls: 0.1379  loss_rpn_loc: 0.2268  time: 0.5904  data_time: 0.3974  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:53:48 d2.utils.events]: \u001b[0m eta: 0:48:05  iter: 1379  total_loss: 1.506  loss_cls: 0.3582  loss_box_reg: 0.5457  loss_mask: 0.305  loss_rpn_cls: 0.09245  loss_rpn_loc: 0.2007  time: 0.5910  data_time: 0.3194  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:53:57 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 1399  total_loss: 1.428  loss_cls: 0.3149  loss_box_reg: 0.5552  loss_mask: 0.305  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.1846  time: 0.5889  data_time: 0.1506  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:54:14 d2.utils.events]: \u001b[0m eta: 0:47:43  iter: 1419  total_loss: 1.407  loss_cls: 0.3264  loss_box_reg: 0.5209  loss_mask: 0.295  loss_rpn_cls: 0.09524  loss_rpn_loc: 0.2071  time: 0.5921  data_time: 0.4846  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:54:25 d2.utils.events]: \u001b[0m eta: 0:47:38  iter: 1439  total_loss: 1.375  loss_cls: 0.3002  loss_box_reg: 0.4954  loss_mask: 0.2974  loss_rpn_cls: 0.07666  loss_rpn_loc: 0.1976  time: 0.5916  data_time: 0.2473  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:54:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:54:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 14:54:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:54:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 14:54:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:54:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 14:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0688 s/iter. Eval: 0.0362 s/iter. Total: 0.1056 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 14:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0718 s/iter. Eval: 0.0566 s/iter. Total: 0.1291 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 14:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0595 s/iter. Total: 0.1322 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 14:54:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.148191 (0.130588 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:54:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071529 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:54:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 14:54:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2544114903311005\n",
      "\u001b[32m[02/03 14:54:54 d2.utils.events]: \u001b[0m eta: 0:47:35  iter: 1459  total_loss: 1.54  loss_cls: 0.3748  loss_box_reg: 0.5453  loss_mask: 0.311  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1917  time: 0.5922  data_time: 0.3028  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:55:09 d2.utils.events]: \u001b[0m eta: 0:47:25  iter: 1479  total_loss: 1.437  loss_cls: 0.3257  loss_box_reg: 0.5157  loss_mask: 0.2922  loss_rpn_cls: 0.09346  loss_rpn_loc: 0.2051  time: 0.5945  data_time: 0.4460  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:55:22 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 1499  total_loss: 1.561  loss_cls: 0.3812  loss_box_reg: 0.5653  loss_mask: 0.2974  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.2056  time: 0.5949  data_time: 0.3002  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:55:32 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 1519  total_loss: 1.357  loss_cls: 0.3401  loss_box_reg: 0.5115  loss_mask: 0.2986  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.1835  time: 0.5939  data_time: 0.1998  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:55:45 d2.utils.events]: \u001b[0m eta: 0:47:15  iter: 1539  total_loss: 1.466  loss_cls: 0.3406  loss_box_reg: 0.5431  loss_mask: 0.2907  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.2013  time: 0.5942  data_time: 0.2989  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:55:57 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 1559  total_loss: 1.463  loss_cls: 0.3328  loss_box_reg: 0.5065  loss_mask: 0.3102  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2319  time: 0.5947  data_time: 0.3112  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:56:09 d2.utils.events]: \u001b[0m eta: 0:47:05  iter: 1579  total_loss: 1.472  loss_cls: 0.3092  loss_box_reg: 0.5366  loss_mask: 0.3065  loss_rpn_cls: 0.09402  loss_rpn_loc: 0.2063  time: 0.5948  data_time: 0.2864  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:56:21 d2.utils.events]: \u001b[0m eta: 0:46:59  iter: 1599  total_loss: 1.514  loss_cls: 0.3543  loss_box_reg: 0.5226  loss_mask: 0.3198  loss_rpn_cls: 0.07806  loss_rpn_loc: 0.1941  time: 0.5949  data_time: 0.2792  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:56:33 d2.utils.events]: \u001b[0m eta: 0:46:52  iter: 1619  total_loss: 1.379  loss_cls: 0.3204  loss_box_reg: 0.5256  loss_mask: 0.3006  loss_rpn_cls: 0.08225  loss_rpn_loc: 0.1858  time: 0.5947  data_time: 0.2655  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:56:43 d2.utils.events]: \u001b[0m eta: 0:46:43  iter: 1639  total_loss: 1.513  loss_cls: 0.3215  loss_box_reg: 0.5468  loss_mask: 0.3059  loss_rpn_cls: 0.07961  loss_rpn_loc: 0.2097  time: 0.5934  data_time: 0.1725  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:56:53 d2.utils.events]: \u001b[0m eta: 0:46:36  iter: 1659  total_loss: 1.52  loss_cls: 0.3093  loss_box_reg: 0.5451  loss_mask: 0.2954  loss_rpn_cls: 0.08026  loss_rpn_loc: 0.2028  time: 0.5922  data_time: 0.1888  lr: 0.0005  max_mem: 7954M\n",
      "\u001b[32m[02/03 14:57:06 d2.utils.events]: \u001b[0m eta: 0:46:28  iter: 1679  total_loss: 1.451  loss_cls: 0.3174  loss_box_reg: 0.5567  loss_mask: 0.3236  loss_rpn_cls: 0.07625  loss_rpn_loc: 0.2019  time: 0.5929  data_time: 0.3263  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:57:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:57:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 14:57:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:57:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 14:57:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:57:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 14:57:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0690 s/iter. Eval: 0.0383 s/iter. Total: 0.1079 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 14:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0714 s/iter. Eval: 0.0569 s/iter. Total: 0.1291 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 14:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0722 s/iter. Eval: 0.0617 s/iter. Total: 0.1347 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 14:57:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.445911 (0.133154 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:57:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072155 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 14:57:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 14:57:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2570617184435344\n",
      "\u001b[32m[02/03 14:57:32 d2.utils.events]: \u001b[0m eta: 0:46:15  iter: 1699  total_loss: 1.492  loss_cls: 0.3541  loss_box_reg: 0.5332  loss_mask: 0.3063  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.2028  time: 0.5914  data_time: 0.1509  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:57:43 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 1719  total_loss: 1.492  loss_cls: 0.3296  loss_box_reg: 0.5234  loss_mask: 0.2998  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.2009  time: 0.5914  data_time: 0.2686  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:57:55 d2.utils.events]: \u001b[0m eta: 0:45:57  iter: 1739  total_loss: 1.553  loss_cls: 0.3722  loss_box_reg: 0.5244  loss_mask: 0.3018  loss_rpn_cls: 0.09552  loss_rpn_loc: 0.2019  time: 0.5910  data_time: 0.2558  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:58:02 d2.utils.events]: \u001b[0m eta: 0:45:49  iter: 1759  total_loss: 1.479  loss_cls: 0.334  loss_box_reg: 0.553  loss_mask: 0.2974  loss_rpn_cls: 0.06841  loss_rpn_loc: 0.1951  time: 0.5884  data_time: 0.0606  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:58:15 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 1779  total_loss: 1.445  loss_cls: 0.3544  loss_box_reg: 0.5256  loss_mask: 0.3091  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.1919  time: 0.5892  data_time: 0.3482  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:58:27 d2.utils.events]: \u001b[0m eta: 0:45:38  iter: 1799  total_loss: 1.443  loss_cls: 0.318  loss_box_reg: 0.552  loss_mask: 0.2951  loss_rpn_cls: 0.08029  loss_rpn_loc: 0.1982  time: 0.5893  data_time: 0.2771  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:58:38 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 1819  total_loss: 1.395  loss_cls: 0.2975  loss_box_reg: 0.5489  loss_mask: 0.3146  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.2039  time: 0.5889  data_time: 0.2317  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:58:48 d2.utils.events]: \u001b[0m eta: 0:45:21  iter: 1839  total_loss: 1.345  loss_cls: 0.3121  loss_box_reg: 0.4971  loss_mask: 0.3052  loss_rpn_cls: 0.07159  loss_rpn_loc: 0.2055  time: 0.5878  data_time: 0.1800  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:59:00 d2.utils.events]: \u001b[0m eta: 0:45:12  iter: 1859  total_loss: 1.539  loss_cls: 0.3541  loss_box_reg: 0.5409  loss_mask: 0.3176  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.2154  time: 0.5882  data_time: 0.3021  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:59:13 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 1879  total_loss: 1.462  loss_cls: 0.3276  loss_box_reg: 0.5262  loss_mask: 0.3012  loss_rpn_cls: 0.07065  loss_rpn_loc: 0.1938  time: 0.5886  data_time: 0.3146  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:59:24 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 1899  total_loss: 1.467  loss_cls: 0.342  loss_box_reg: 0.5264  loss_mask: 0.3072  loss_rpn_cls: 0.0838  loss_rpn_loc: 0.2179  time: 0.5881  data_time: 0.2249  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:59:40 d2.utils.events]: \u001b[0m eta: 0:45:06  iter: 1919  total_loss: 1.484  loss_cls: 0.3586  loss_box_reg: 0.5275  loss_mask: 0.3093  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.2061  time: 0.5905  data_time: 0.4831  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 14:59:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:59:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 14:59:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 14:59:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 14:59:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 14:59:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 14:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0365 s/iter. Total: 0.1053 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 14:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0543 s/iter. Total: 0.1257 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 15:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0593 s/iter. Total: 0.1318 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:00:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.067208 (0.129890 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:00:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071383 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:00:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:00:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2507135785528519\n",
      "\u001b[32m[02/03 15:00:08 d2.utils.events]: \u001b[0m eta: 0:44:50  iter: 1939  total_loss: 1.491  loss_cls: 0.3529  loss_box_reg: 0.537  loss_mask: 0.3123  loss_rpn_cls: 0.07669  loss_rpn_loc: 0.2129  time: 0.5901  data_time: 0.2387  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:00:23 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 1959  total_loss: 1.541  loss_cls: 0.3668  loss_box_reg: 0.5652  loss_mask: 0.3112  loss_rpn_cls: 0.1153  loss_rpn_loc: 0.2144  time: 0.5920  data_time: 0.4563  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:00:36 d2.utils.events]: \u001b[0m eta: 0:44:42  iter: 1979  total_loss: 1.384  loss_cls: 0.3027  loss_box_reg: 0.5108  loss_mask: 0.3071  loss_rpn_cls: 0.0912  loss_rpn_loc: 0.2077  time: 0.5926  data_time: 0.3268  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:00:48 d2.utils.events]: \u001b[0m eta: 0:44:35  iter: 1999  total_loss: 1.383  loss_cls: 0.3339  loss_box_reg: 0.4883  loss_mask: 0.2833  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.1752  time: 0.5926  data_time: 0.2724  lr: 0.0005  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:00:59 d2.utils.events]: \u001b[0m eta: 0:44:28  iter: 2019  total_loss: 1.479  loss_cls: 0.3599  loss_box_reg: 0.5238  loss_mask: 0.3108  loss_rpn_cls: 0.08887  loss_rpn_loc: 0.1853  time: 0.5922  data_time: 0.2334  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:01:11 d2.utils.events]: \u001b[0m eta: 0:44:17  iter: 2039  total_loss: 1.462  loss_cls: 0.3326  loss_box_reg: 0.5371  loss_mask: 0.3015  loss_rpn_cls: 0.07339  loss_rpn_loc: 0.1924  time: 0.5923  data_time: 0.2890  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:01:21 d2.utils.events]: \u001b[0m eta: 0:44:15  iter: 2059  total_loss: 1.465  loss_cls: 0.3263  loss_box_reg: 0.5203  loss_mask: 0.3054  loss_rpn_cls: 0.09528  loss_rpn_loc: 0.2026  time: 0.5915  data_time: 0.2098  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:01:32 d2.utils.events]: \u001b[0m eta: 0:44:04  iter: 2079  total_loss: 1.508  loss_cls: 0.3465  loss_box_reg: 0.5342  loss_mask: 0.3001  loss_rpn_cls: 0.08562  loss_rpn_loc: 0.2071  time: 0.5907  data_time: 0.2047  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:01:43 d2.utils.events]: \u001b[0m eta: 0:43:57  iter: 2099  total_loss: 1.482  loss_cls: 0.3321  loss_box_reg: 0.5354  loss_mask: 0.3049  loss_rpn_cls: 0.06985  loss_rpn_loc: 0.1983  time: 0.5903  data_time: 0.2386  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:01:54 d2.utils.events]: \u001b[0m eta: 0:43:48  iter: 2119  total_loss: 1.507  loss_cls: 0.3347  loss_box_reg: 0.566  loss_mask: 0.3119  loss_rpn_cls: 0.08759  loss_rpn_loc: 0.1961  time: 0.5899  data_time: 0.2365  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:02:06 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 2139  total_loss: 1.564  loss_cls: 0.369  loss_box_reg: 0.5284  loss_mask: 0.3062  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2091  time: 0.5901  data_time: 0.2859  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:02:18 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 2159  total_loss: 1.48  loss_cls: 0.3376  loss_box_reg: 0.516  loss_mask: 0.2782  loss_rpn_cls: 0.09923  loss_rpn_loc: 0.1985  time: 0.5901  data_time: 0.2727  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:02:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:02:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:02:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:02:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:02:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:02:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0686 s/iter. Eval: 0.0430 s/iter. Total: 0.1123 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 15:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0539 s/iter. Total: 0.1255 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 15:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0584 s/iter. Total: 0.1330 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:02:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.241781 (0.131395 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:02:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073210 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:02:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:02:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2544573314153111\n",
      "\u001b[32m[02/03 15:02:49 d2.utils.events]: \u001b[0m eta: 0:43:32  iter: 2179  total_loss: 1.535  loss_cls: 0.3386  loss_box_reg: 0.5433  loss_mask: 0.3186  loss_rpn_cls: 0.0923  loss_rpn_loc: 0.2067  time: 0.5912  data_time: 0.3922  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:03:03 d2.utils.events]: \u001b[0m eta: 0:43:25  iter: 2199  total_loss: 1.473  loss_cls: 0.3268  loss_box_reg: 0.518  loss_mask: 0.3203  loss_rpn_cls: 0.09119  loss_rpn_loc: 0.2112  time: 0.5922  data_time: 0.3729  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:03:13 d2.utils.events]: \u001b[0m eta: 0:43:14  iter: 2219  total_loss: 1.5  loss_cls: 0.3554  loss_box_reg: 0.5754  loss_mask: 0.3087  loss_rpn_cls: 0.09648  loss_rpn_loc: 0.2093  time: 0.5917  data_time: 0.2344  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:03:26 d2.utils.events]: \u001b[0m eta: 0:43:08  iter: 2239  total_loss: 1.443  loss_cls: 0.3141  loss_box_reg: 0.5359  loss_mask: 0.2957  loss_rpn_cls: 0.09151  loss_rpn_loc: 0.2135  time: 0.5920  data_time: 0.3093  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:03:37 d2.utils.events]: \u001b[0m eta: 0:43:01  iter: 2259  total_loss: 1.317  loss_cls: 0.2776  loss_box_reg: 0.4981  loss_mask: 0.2939  loss_rpn_cls: 0.05852  loss_rpn_loc: 0.1771  time: 0.5918  data_time: 0.2752  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:03:46 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 2279  total_loss: 1.452  loss_cls: 0.3199  loss_box_reg: 0.5336  loss_mask: 0.2861  loss_rpn_cls: 0.08697  loss_rpn_loc: 0.1903  time: 0.5905  data_time: 0.1347  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:04:01 d2.utils.events]: \u001b[0m eta: 0:42:50  iter: 2299  total_loss: 1.402  loss_cls: 0.3186  loss_box_reg: 0.4944  loss_mask: 0.309  loss_rpn_cls: 0.07708  loss_rpn_loc: 0.2057  time: 0.5918  data_time: 0.4081  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:04:12 d2.utils.events]: \u001b[0m eta: 0:42:46  iter: 2319  total_loss: 1.52  loss_cls: 0.3478  loss_box_reg: 0.5251  loss_mask: 0.3184  loss_rpn_cls: 0.07572  loss_rpn_loc: 0.1891  time: 0.5914  data_time: 0.2245  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:04:23 d2.utils.events]: \u001b[0m eta: 0:42:41  iter: 2339  total_loss: 1.413  loss_cls: 0.3162  loss_box_reg: 0.5205  loss_mask: 0.2918  loss_rpn_cls: 0.09562  loss_rpn_loc: 0.1921  time: 0.5912  data_time: 0.2646  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:04:32 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 2359  total_loss: 1.425  loss_cls: 0.3203  loss_box_reg: 0.515  loss_mask: 0.2843  loss_rpn_cls: 0.06663  loss_rpn_loc: 0.185  time: 0.5900  data_time: 0.1404  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:04:45 d2.utils.events]: \u001b[0m eta: 0:42:25  iter: 2379  total_loss: 1.397  loss_cls: 0.3342  loss_box_reg: 0.5113  loss_mask: 0.2828  loss_rpn_cls: 0.08995  loss_rpn_loc: 0.1868  time: 0.5903  data_time: 0.2894  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:04:58 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 2399  total_loss: 1.466  loss_cls: 0.342  loss_box_reg: 0.5302  loss_mask: 0.3212  loss_rpn_cls: 0.09138  loss_rpn_loc: 0.1831  time: 0.5911  data_time: 0.3549  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:05:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:05:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:05:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:05:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:05:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:05:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0374 s/iter. Total: 0.1062 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0543 s/iter. Total: 0.1258 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 15:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0563 s/iter. Total: 0.1283 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:05:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.787046 (0.127475 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:05:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071236 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:05:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:05:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25588201742033684\n",
      "\u001b[32m[02/03 15:05:24 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 2419  total_loss: 1.522  loss_cls: 0.3692  loss_box_reg: 0.5506  loss_mask: 0.2957  loss_rpn_cls: 0.08022  loss_rpn_loc: 0.2063  time: 0.5900  data_time: 0.1632  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:05:34 d2.utils.events]: \u001b[0m eta: 0:42:08  iter: 2439  total_loss: 1.419  loss_cls: 0.3646  loss_box_reg: 0.5274  loss_mask: 0.298  loss_rpn_cls: 0.08877  loss_rpn_loc: 0.1895  time: 0.5892  data_time: 0.1835  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:05:43 d2.utils.events]: \u001b[0m eta: 0:41:56  iter: 2459  total_loss: 1.527  loss_cls: 0.3306  loss_box_reg: 0.5413  loss_mask: 0.3228  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.2041  time: 0.5882  data_time: 0.1595  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:05:58 d2.utils.events]: \u001b[0m eta: 0:41:53  iter: 2479  total_loss: 1.454  loss_cls: 0.3553  loss_box_reg: 0.5079  loss_mask: 0.3149  loss_rpn_cls: 0.09036  loss_rpn_loc: 0.2174  time: 0.5896  data_time: 0.4294  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:06:12 d2.utils.events]: \u001b[0m eta: 0:41:43  iter: 2499  total_loss: 1.376  loss_cls: 0.2968  loss_box_reg: 0.4855  loss_mask: 0.2802  loss_rpn_cls: 0.07872  loss_rpn_loc: 0.1928  time: 0.5905  data_time: 0.3826  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:06:25 d2.utils.events]: \u001b[0m eta: 0:41:40  iter: 2519  total_loss: 1.407  loss_cls: 0.321  loss_box_reg: 0.504  loss_mask: 0.3034  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2136  time: 0.5908  data_time: 0.3069  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:06:34 d2.utils.events]: \u001b[0m eta: 0:41:29  iter: 2539  total_loss: 1.436  loss_cls: 0.3187  loss_box_reg: 0.5514  loss_mask: 0.2992  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1862  time: 0.5896  data_time: 0.1476  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:06:44 d2.utils.events]: \u001b[0m eta: 0:41:20  iter: 2559  total_loss: 1.446  loss_cls: 0.3364  loss_box_reg: 0.5116  loss_mask: 0.2977  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.1992  time: 0.5892  data_time: 0.2286  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:06:53 d2.utils.events]: \u001b[0m eta: 0:41:06  iter: 2579  total_loss: 1.385  loss_cls: 0.3254  loss_box_reg: 0.5472  loss_mask: 0.298  loss_rpn_cls: 0.05707  loss_rpn_loc: 0.1924  time: 0.5881  data_time: 0.1450  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:07:06 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 2599  total_loss: 1.492  loss_cls: 0.3211  loss_box_reg: 0.5086  loss_mask: 0.318  loss_rpn_cls: 0.09422  loss_rpn_loc: 0.2065  time: 0.5886  data_time: 0.3265  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:07:20 d2.utils.events]: \u001b[0m eta: 0:40:55  iter: 2619  total_loss: 1.459  loss_cls: 0.3136  loss_box_reg: 0.521  loss_mask: 0.3132  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.2058  time: 0.5894  data_time: 0.3499  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:07:32 d2.utils.events]: \u001b[0m eta: 0:40:48  iter: 2639  total_loss: 1.441  loss_cls: 0.3177  loss_box_reg: 0.5241  loss_mask: 0.2953  loss_rpn_cls: 0.07002  loss_rpn_loc: 0.1822  time: 0.5894  data_time: 0.2721  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:07:43 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 2659  total_loss: 1.433  loss_cls: 0.3038  loss_box_reg: 0.5357  loss_mask: 0.3119  loss_rpn_cls: 0.07248  loss_rpn_loc: 0.2144  time: 0.5890  data_time: 0.2240  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:07:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:07:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:07:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:07:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:07:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:07:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0685 s/iter. Eval: 0.0374 s/iter. Total: 0.1065 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0576 s/iter. Total: 0.1300 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0731 s/iter. Eval: 0.0622 s/iter. Total: 0.1361 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 15:08:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.597544 (0.134462 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:08:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:08:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:08:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26335642550162663\n",
      "\u001b[32m[02/03 15:08:13 d2.utils.events]: \u001b[0m eta: 0:40:50  iter: 2679  total_loss: 1.418  loss_cls: 0.332  loss_box_reg: 0.4673  loss_mask: 0.293  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.2076  time: 0.5893  data_time: 0.2884  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:08:25 d2.utils.events]: \u001b[0m eta: 0:40:45  iter: 2699  total_loss: 1.455  loss_cls: 0.3277  loss_box_reg: 0.5317  loss_mask: 0.3135  loss_rpn_cls: 0.05625  loss_rpn_loc: 0.1942  time: 0.5894  data_time: 0.2910  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:08:40 d2.utils.events]: \u001b[0m eta: 0:40:41  iter: 2719  total_loss: 1.454  loss_cls: 0.3437  loss_box_reg: 0.5046  loss_mask: 0.2976  loss_rpn_cls: 0.08041  loss_rpn_loc: 0.2028  time: 0.5906  data_time: 0.4009  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:08:51 d2.utils.events]: \u001b[0m eta: 0:40:34  iter: 2739  total_loss: 1.447  loss_cls: 0.362  loss_box_reg: 0.5065  loss_mask: 0.297  loss_rpn_cls: 0.06372  loss_rpn_loc: 0.1827  time: 0.5904  data_time: 0.2425  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:09:03 d2.utils.events]: \u001b[0m eta: 0:40:30  iter: 2759  total_loss: 1.527  loss_cls: 0.3519  loss_box_reg: 0.5382  loss_mask: 0.3119  loss_rpn_cls: 0.09674  loss_rpn_loc: 0.2303  time: 0.5903  data_time: 0.2704  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:09:13 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 2779  total_loss: 1.365  loss_cls: 0.294  loss_box_reg: 0.5087  loss_mask: 0.2897  loss_rpn_cls: 0.06014  loss_rpn_loc: 0.2019  time: 0.5900  data_time: 0.2466  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:09:23 d2.utils.events]: \u001b[0m eta: 0:40:11  iter: 2799  total_loss: 1.467  loss_cls: 0.3423  loss_box_reg: 0.5119  loss_mask: 0.3012  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.2049  time: 0.5892  data_time: 0.1833  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:09:33 d2.utils.events]: \u001b[0m eta: 0:40:02  iter: 2819  total_loss: 1.444  loss_cls: 0.3495  loss_box_reg: 0.5362  loss_mask: 0.289  loss_rpn_cls: 0.07633  loss_rpn_loc: 0.182  time: 0.5886  data_time: 0.1988  lr: 0.0004  max_mem: 7955M\n",
      "\u001b[32m[02/03 15:09:46 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 2839  total_loss: 1.488  loss_cls: 0.327  loss_box_reg: 0.5366  loss_mask: 0.3082  loss_rpn_cls: 0.08292  loss_rpn_loc: 0.2007  time: 0.5890  data_time: 0.3291  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:09:57 d2.utils.events]: \u001b[0m eta: 0:39:50  iter: 2859  total_loss: 1.423  loss_cls: 0.3403  loss_box_reg: 0.5206  loss_mask: 0.2825  loss_rpn_cls: 0.0934  loss_rpn_loc: 0.1824  time: 0.5888  data_time: 0.2525  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:10:08 d2.utils.events]: \u001b[0m eta: 0:39:40  iter: 2879  total_loss: 1.505  loss_cls: 0.3578  loss_box_reg: 0.5229  loss_mask: 0.3081  loss_rpn_cls: 0.08312  loss_rpn_loc: 0.2038  time: 0.5885  data_time: 0.2396  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:10:22 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 2899  total_loss: 1.446  loss_cls: 0.341  loss_box_reg: 0.5454  loss_mask: 0.3093  loss_rpn_cls: 0.08186  loss_rpn_loc: 0.2  time: 0.5893  data_time: 0.3592  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:10:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:10:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:10:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:10:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:10:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:10:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0739 s/iter. Eval: 0.0353 s/iter. Total: 0.1098 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 15:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0730 s/iter. Eval: 0.0532 s/iter. Total: 0.1270 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:10:37 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0727 s/iter. Eval: 0.0567 s/iter. Total: 0.1302 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:10:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.988694 (0.129213 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:10:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072466 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:10:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:10:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2557088708113584\n",
      "\u001b[32m[02/03 15:10:48 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 2919  total_loss: 1.456  loss_cls: 0.3502  loss_box_reg: 0.5485  loss_mask: 0.3084  loss_rpn_cls: 0.07232  loss_rpn_loc: 0.2069  time: 0.5885  data_time: 0.1694  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:11:01 d2.utils.events]: \u001b[0m eta: 0:39:22  iter: 2939  total_loss: 1.504  loss_cls: 0.3371  loss_box_reg: 0.5122  loss_mask: 0.3043  loss_rpn_cls: 0.08326  loss_rpn_loc: 0.2001  time: 0.5888  data_time: 0.3206  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:11:11 d2.utils.events]: \u001b[0m eta: 0:39:09  iter: 2959  total_loss: 1.365  loss_cls: 0.3396  loss_box_reg: 0.4816  loss_mask: 0.273  loss_rpn_cls: 0.06169  loss_rpn_loc: 0.1919  time: 0.5883  data_time: 0.1985  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:11:25 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 2979  total_loss: 1.572  loss_cls: 0.3764  loss_box_reg: 0.5485  loss_mask: 0.3245  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.224  time: 0.5890  data_time: 0.3626  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:11:38 d2.utils.events]: \u001b[0m eta: 0:39:01  iter: 2999  total_loss: 1.411  loss_cls: 0.3115  loss_box_reg: 0.5113  loss_mask: 0.2959  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.2228  time: 0.5893  data_time: 0.3128  lr: 0.0004  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:11:46 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 3019  total_loss: 1.382  loss_cls: 0.3186  loss_box_reg: 0.535  loss_mask: 0.2914  loss_rpn_cls: 0.0616  loss_rpn_loc: 0.1936  time: 0.5882  data_time: 0.1175  lr: 0.00032  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:11:57 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 3039  total_loss: 1.463  loss_cls: 0.3162  loss_box_reg: 0.5184  loss_mask: 0.2972  loss_rpn_cls: 0.08146  loss_rpn_loc: 0.2025  time: 0.5877  data_time: 0.1991  lr: 0.00032  max_mem: 7992M\n",
      "\u001b[32m[02/03 15:12:13 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 3059  total_loss: 1.41  loss_cls: 0.331  loss_box_reg: 0.4872  loss_mask: 0.3024  loss_rpn_cls: 0.07879  loss_rpn_loc: 0.1865  time: 0.5891  data_time: 0.4661  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:12:22 d2.utils.events]: \u001b[0m eta: 0:38:33  iter: 3079  total_loss: 1.504  loss_cls: 0.3189  loss_box_reg: 0.5143  loss_mask: 0.3086  loss_rpn_cls: 0.096  loss_rpn_loc: 0.2006  time: 0.5884  data_time: 0.1711  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:12:35 d2.utils.events]: \u001b[0m eta: 0:38:33  iter: 3099  total_loss: 1.426  loss_cls: 0.326  loss_box_reg: 0.4906  loss_mask: 0.2968  loss_rpn_cls: 0.09986  loss_rpn_loc: 0.1973  time: 0.5889  data_time: 0.3208  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:12:46 d2.utils.events]: \u001b[0m eta: 0:38:24  iter: 3119  total_loss: 1.505  loss_cls: 0.3042  loss_box_reg: 0.5478  loss_mask: 0.3119  loss_rpn_cls: 0.09909  loss_rpn_loc: 0.2098  time: 0.5884  data_time: 0.2007  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:12:58 d2.utils.events]: \u001b[0m eta: 0:38:16  iter: 3139  total_loss: 1.39  loss_cls: 0.3029  loss_box_reg: 0.5189  loss_mask: 0.3036  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.1785  time: 0.5885  data_time: 0.2893  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:13:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:13:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:13:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:13:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:13:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:13:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:13:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0684 s/iter. Eval: 0.0383 s/iter. Total: 0.1073 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:13:07 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0714 s/iter. Eval: 0.0538 s/iter. Total: 0.1260 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 15:13:12 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0725 s/iter. Eval: 0.0568 s/iter. Total: 0.1301 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:13:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.995176 (0.129269 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:13:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072730 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:13:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:13:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25800615009354694\n",
      "\u001b[32m[02/03 15:13:22 d2.utils.events]: \u001b[0m eta: 0:38:03  iter: 3159  total_loss: 1.334  loss_cls: 0.3261  loss_box_reg: 0.4957  loss_mask: 0.2817  loss_rpn_cls: 0.06044  loss_rpn_loc: 0.1692  time: 0.5873  data_time: 0.0891  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:13:34 d2.utils.events]: \u001b[0m eta: 0:37:55  iter: 3179  total_loss: 1.391  loss_cls: 0.2989  loss_box_reg: 0.5167  loss_mask: 0.2984  loss_rpn_cls: 0.08067  loss_rpn_loc: 0.2022  time: 0.5874  data_time: 0.2933  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:13:47 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 3199  total_loss: 1.372  loss_cls: 0.3356  loss_box_reg: 0.4993  loss_mask: 0.2919  loss_rpn_cls: 0.08394  loss_rpn_loc: 0.2017  time: 0.5876  data_time: 0.3032  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:13:58 d2.utils.events]: \u001b[0m eta: 0:37:41  iter: 3219  total_loss: 1.437  loss_cls: 0.352  loss_box_reg: 0.492  loss_mask: 0.3111  loss_rpn_cls: 0.09544  loss_rpn_loc: 0.1965  time: 0.5874  data_time: 0.2277  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:14:09 d2.utils.events]: \u001b[0m eta: 0:37:36  iter: 3239  total_loss: 1.361  loss_cls: 0.3298  loss_box_reg: 0.4773  loss_mask: 0.3006  loss_rpn_cls: 0.08495  loss_rpn_loc: 0.214  time: 0.5872  data_time: 0.2340  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:14:20 d2.utils.events]: \u001b[0m eta: 0:37:28  iter: 3259  total_loss: 1.504  loss_cls: 0.3453  loss_box_reg: 0.5165  loss_mask: 0.302  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.207  time: 0.5871  data_time: 0.2639  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:14:30 d2.utils.events]: \u001b[0m eta: 0:37:21  iter: 3279  total_loss: 1.412  loss_cls: 0.2978  loss_box_reg: 0.5558  loss_mask: 0.3061  loss_rpn_cls: 0.07009  loss_rpn_loc: 0.1869  time: 0.5865  data_time: 0.1759  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:14:42 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 3299  total_loss: 1.414  loss_cls: 0.3261  loss_box_reg: 0.5003  loss_mask: 0.2884  loss_rpn_cls: 0.0623  loss_rpn_loc: 0.1982  time: 0.5866  data_time: 0.2928  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:14:54 d2.utils.events]: \u001b[0m eta: 0:37:00  iter: 3319  total_loss: 1.434  loss_cls: 0.352  loss_box_reg: 0.5194  loss_mask: 0.2981  loss_rpn_cls: 0.08851  loss_rpn_loc: 0.1866  time: 0.5866  data_time: 0.2688  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:15:07 d2.utils.events]: \u001b[0m eta: 0:36:54  iter: 3339  total_loss: 1.429  loss_cls: 0.3396  loss_box_reg: 0.4913  loss_mask: 0.2906  loss_rpn_cls: 0.07595  loss_rpn_loc: 0.2071  time: 0.5871  data_time: 0.3496  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:15:18 d2.utils.events]: \u001b[0m eta: 0:36:51  iter: 3359  total_loss: 1.353  loss_cls: 0.2855  loss_box_reg: 0.5466  loss_mask: 0.3016  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.1853  time: 0.5867  data_time: 0.1970  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:15:34 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 3379  total_loss: 1.384  loss_cls: 0.3143  loss_box_reg: 0.5101  loss_mask: 0.2843  loss_rpn_cls: 0.08024  loss_rpn_loc: 0.1976  time: 0.5881  data_time: 0.5101  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:15:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:15:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:15:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:15:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:15:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:15:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0694 s/iter. Eval: 0.0368 s/iter. Total: 0.1068 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0732 s/iter. Eval: 0.0533 s/iter. Total: 0.1273 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0724 s/iter. Eval: 0.0547 s/iter. Total: 0.1279 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:15:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.604088 (0.125897 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:15:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071722 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:15:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:15:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25875840622493895\n",
      "\u001b[32m[02/03 15:16:03 d2.utils.events]: \u001b[0m eta: 0:36:36  iter: 3399  total_loss: 1.369  loss_cls: 0.3001  loss_box_reg: 0.4822  loss_mask: 0.2837  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.1835  time: 0.5885  data_time: 0.3230  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:16:15 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 3419  total_loss: 1.445  loss_cls: 0.2793  loss_box_reg: 0.5171  loss_mask: 0.3153  loss_rpn_cls: 0.07398  loss_rpn_loc: 0.1962  time: 0.5884  data_time: 0.2645  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:16:28 d2.utils.events]: \u001b[0m eta: 0:36:28  iter: 3439  total_loss: 1.417  loss_cls: 0.3217  loss_box_reg: 0.4855  loss_mask: 0.287  loss_rpn_cls: 0.07072  loss_rpn_loc: 0.1993  time: 0.5890  data_time: 0.3564  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:16:39 d2.utils.events]: \u001b[0m eta: 0:36:23  iter: 3459  total_loss: 1.414  loss_cls: 0.3041  loss_box_reg: 0.5267  loss_mask: 0.3019  loss_rpn_cls: 0.07043  loss_rpn_loc: 0.187  time: 0.5885  data_time: 0.2069  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:16:50 d2.utils.events]: \u001b[0m eta: 0:36:13  iter: 3479  total_loss: 1.411  loss_cls: 0.3119  loss_box_reg: 0.526  loss_mask: 0.312  loss_rpn_cls: 0.0903  loss_rpn_loc: 0.204  time: 0.5885  data_time: 0.2724  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:17:01 d2.utils.events]: \u001b[0m eta: 0:36:03  iter: 3499  total_loss: 1.315  loss_cls: 0.3225  loss_box_reg: 0.5066  loss_mask: 0.2901  loss_rpn_cls: 0.03994  loss_rpn_loc: 0.1891  time: 0.5882  data_time: 0.2251  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:17:12 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 3519  total_loss: 1.428  loss_cls: 0.3406  loss_box_reg: 0.5071  loss_mask: 0.3147  loss_rpn_cls: 0.09207  loss_rpn_loc: 0.1969  time: 0.5878  data_time: 0.1992  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:17:24 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 3539  total_loss: 1.36  loss_cls: 0.3021  loss_box_reg: 0.5061  loss_mask: 0.2911  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1913  time: 0.5879  data_time: 0.2865  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:17:34 d2.utils.events]: \u001b[0m eta: 0:35:45  iter: 3559  total_loss: 1.436  loss_cls: 0.3272  loss_box_reg: 0.5492  loss_mask: 0.294  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1957  time: 0.5876  data_time: 0.2286  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:17:49 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 3579  total_loss: 1.506  loss_cls: 0.376  loss_box_reg: 0.5159  loss_mask: 0.3161  loss_rpn_cls: 0.09138  loss_rpn_loc: 0.2166  time: 0.5884  data_time: 0.4065  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:18:01 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 3599  total_loss: 1.46  loss_cls: 0.3111  loss_box_reg: 0.5292  loss_mask: 0.2993  loss_rpn_cls: 0.06911  loss_rpn_loc: 0.2009  time: 0.5886  data_time: 0.3129  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:18:13 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 3619  total_loss: 1.388  loss_cls: 0.3036  loss_box_reg: 0.4863  loss_mask: 0.2912  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.192  time: 0.5885  data_time: 0.2622  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:18:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:18:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:18:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:18:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:18:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:18:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0678 s/iter. Eval: 0.0369 s/iter. Total: 0.1052 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0542 s/iter. Total: 0.1255 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 15:18:32 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0008 s/iter. Inference: 0.0708 s/iter. Eval: 0.0564 s/iter. Total: 0.1280 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 15:18:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.750917 (0.127163 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:18:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070688 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:18:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:18:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.263568415607324\n",
      "\u001b[32m[02/03 15:18:42 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 3639  total_loss: 1.429  loss_cls: 0.3209  loss_box_reg: 0.4763  loss_mask: 0.2838  loss_rpn_cls: 0.0951  loss_rpn_loc: 0.1933  time: 0.5887  data_time: 0.2921  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:18:53 d2.utils.events]: \u001b[0m eta: 0:35:15  iter: 3659  total_loss: 1.392  loss_cls: 0.3105  loss_box_reg: 0.5051  loss_mask: 0.2941  loss_rpn_cls: 0.08062  loss_rpn_loc: 0.1819  time: 0.5885  data_time: 0.2292  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:19:04 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 3679  total_loss: 1.373  loss_cls: 0.3019  loss_box_reg: 0.5047  loss_mask: 0.2977  loss_rpn_cls: 0.05852  loss_rpn_loc: 0.1907  time: 0.5884  data_time: 0.2629  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:19:16 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 3699  total_loss: 1.399  loss_cls: 0.3187  loss_box_reg: 0.4841  loss_mask: 0.2884  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.194  time: 0.5884  data_time: 0.2700  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:19:28 d2.utils.events]: \u001b[0m eta: 0:34:50  iter: 3719  total_loss: 1.343  loss_cls: 0.2952  loss_box_reg: 0.4934  loss_mask: 0.2863  loss_rpn_cls: 0.0711  loss_rpn_loc: 0.2024  time: 0.5884  data_time: 0.2583  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:19:40 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 3739  total_loss: 1.441  loss_cls: 0.342  loss_box_reg: 0.4845  loss_mask: 0.3208  loss_rpn_cls: 0.08061  loss_rpn_loc: 0.2097  time: 0.5886  data_time: 0.3165  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:19:52 d2.utils.events]: \u001b[0m eta: 0:34:38  iter: 3759  total_loss: 1.335  loss_cls: 0.297  loss_box_reg: 0.492  loss_mask: 0.2969  loss_rpn_cls: 0.07997  loss_rpn_loc: 0.2014  time: 0.5886  data_time: 0.2617  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:20:06 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 3779  total_loss: 1.499  loss_cls: 0.3563  loss_box_reg: 0.5445  loss_mask: 0.3041  loss_rpn_cls: 0.09669  loss_rpn_loc: 0.2117  time: 0.5891  data_time: 0.3632  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:20:17 d2.utils.events]: \u001b[0m eta: 0:34:32  iter: 3799  total_loss: 1.383  loss_cls: 0.3152  loss_box_reg: 0.5003  loss_mask: 0.3056  loss_rpn_cls: 0.07095  loss_rpn_loc: 0.1776  time: 0.5889  data_time: 0.2456  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:20:30 d2.utils.events]: \u001b[0m eta: 0:34:31  iter: 3819  total_loss: 1.392  loss_cls: 0.3211  loss_box_reg: 0.4878  loss_mask: 0.3048  loss_rpn_cls: 0.07857  loss_rpn_loc: 0.1975  time: 0.5893  data_time: 0.3415  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:20:42 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 3839  total_loss: 1.444  loss_cls: 0.3196  loss_box_reg: 0.5435  loss_mask: 0.2974  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.1995  time: 0.5893  data_time: 0.2607  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:20:52 d2.utils.events]: \u001b[0m eta: 0:34:18  iter: 3859  total_loss: 1.428  loss_cls: 0.3327  loss_box_reg: 0.5134  loss_mask: 0.2859  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.2025  time: 0.5889  data_time: 0.2252  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:21:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:21:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:21:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:21:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:21:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:21:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:21:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0372 s/iter. Total: 0.1057 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:21:08 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0535 s/iter. Total: 0.1248 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 15:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0008 s/iter. Inference: 0.0708 s/iter. Eval: 0.0558 s/iter. Total: 0.1275 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 15:21:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.680623 (0.126557 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:21:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070606 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:21:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:21:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26096643330269437\n",
      "\u001b[32m[02/03 15:21:21 d2.utils.events]: \u001b[0m eta: 0:34:12  iter: 3879  total_loss: 1.434  loss_cls: 0.3027  loss_box_reg: 0.5407  loss_mask: 0.2982  loss_rpn_cls: 0.07116  loss_rpn_loc: 0.1978  time: 0.5891  data_time: 0.3141  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:21:32 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 3899  total_loss: 1.424  loss_cls: 0.2837  loss_box_reg: 0.4859  loss_mask: 0.2961  loss_rpn_cls: 0.07793  loss_rpn_loc: 0.2012  time: 0.5890  data_time: 0.2525  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:21:42 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 3919  total_loss: 1.272  loss_cls: 0.2559  loss_box_reg: 0.5164  loss_mask: 0.2827  loss_rpn_cls: 0.04886  loss_rpn_loc: 0.1743  time: 0.5886  data_time: 0.2098  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:21:54 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 3939  total_loss: 1.534  loss_cls: 0.3633  loss_box_reg: 0.5394  loss_mask: 0.3036  loss_rpn_cls: 0.09961  loss_rpn_loc: 0.2034  time: 0.5886  data_time: 0.2748  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:22:07 d2.utils.events]: \u001b[0m eta: 0:33:43  iter: 3959  total_loss: 1.48  loss_cls: 0.3113  loss_box_reg: 0.5237  loss_mask: 0.3112  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.1828  time: 0.5889  data_time: 0.3168  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:22:20 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 3979  total_loss: 1.453  loss_cls: 0.3195  loss_box_reg: 0.5204  loss_mask: 0.314  loss_rpn_cls: 0.09373  loss_rpn_loc: 0.1773  time: 0.5891  data_time: 0.3121  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:22:29 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 3999  total_loss: 1.389  loss_cls: 0.3132  loss_box_reg: 0.5559  loss_mask: 0.2913  loss_rpn_cls: 0.08284  loss_rpn_loc: 0.1812  time: 0.5885  data_time: 0.1539  lr: 0.00032  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:22:38 d2.utils.events]: \u001b[0m eta: 0:33:10  iter: 4019  total_loss: 1.324  loss_cls: 0.28  loss_box_reg: 0.4803  loss_mask: 0.2957  loss_rpn_cls: 0.06295  loss_rpn_loc: 0.1978  time: 0.5879  data_time: 0.1736  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:22:52 d2.utils.events]: \u001b[0m eta: 0:33:05  iter: 4039  total_loss: 1.448  loss_cls: 0.3497  loss_box_reg: 0.5091  loss_mask: 0.295  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.1927  time: 0.5884  data_time: 0.3608  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:23:04 d2.utils.events]: \u001b[0m eta: 0:32:59  iter: 4059  total_loss: 1.365  loss_cls: 0.2968  loss_box_reg: 0.5038  loss_mask: 0.3015  loss_rpn_cls: 0.06608  loss_rpn_loc: 0.1793  time: 0.5883  data_time: 0.2366  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:23:17 d2.utils.events]: \u001b[0m eta: 0:32:55  iter: 4079  total_loss: 1.437  loss_cls: 0.3341  loss_box_reg: 0.512  loss_mask: 0.2989  loss_rpn_cls: 0.0938  loss_rpn_loc: 0.1898  time: 0.5886  data_time: 0.3150  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:23:25 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 4099  total_loss: 1.429  loss_cls: 0.3114  loss_box_reg: 0.5405  loss_mask: 0.2772  loss_rpn_cls: 0.06321  loss_rpn_loc: 0.1811  time: 0.5878  data_time: 0.1084  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:23:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:23:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:23:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:23:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:23:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:23:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:23:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0683 s/iter. Eval: 0.0406 s/iter. Total: 0.1096 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 15:23:46 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0716 s/iter. Eval: 0.0583 s/iter. Total: 0.1306 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0721 s/iter. Eval: 0.0619 s/iter. Total: 0.1348 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:23:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.453395 (0.133219 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:23:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071933 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:23:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:23:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26673133288134676\n",
      "\u001b[32m[02/03 15:24:01 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 4119  total_loss: 1.457  loss_cls: 0.3316  loss_box_reg: 0.4991  loss_mask: 0.3111  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.228  time: 0.5895  data_time: 0.5936  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:24:10 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 4139  total_loss: 1.357  loss_cls: 0.312  loss_box_reg: 0.5266  loss_mask: 0.2957  loss_rpn_cls: 0.05202  loss_rpn_loc: 0.1761  time: 0.5888  data_time: 0.1434  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:24:20 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 4159  total_loss: 1.39  loss_cls: 0.2996  loss_box_reg: 0.5344  loss_mask: 0.3082  loss_rpn_cls: 0.06595  loss_rpn_loc: 0.1896  time: 0.5885  data_time: 0.2044  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:24:34 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 4179  total_loss: 1.368  loss_cls: 0.2927  loss_box_reg: 0.4823  loss_mask: 0.3143  loss_rpn_cls: 0.05898  loss_rpn_loc: 0.1932  time: 0.5889  data_time: 0.3478  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:24:43 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 4199  total_loss: 1.435  loss_cls: 0.3203  loss_box_reg: 0.5499  loss_mask: 0.3063  loss_rpn_cls: 0.08112  loss_rpn_loc: 0.1862  time: 0.5884  data_time: 0.1747  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:24:54 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 4219  total_loss: 1.5  loss_cls: 0.3695  loss_box_reg: 0.535  loss_mask: 0.2894  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.1821  time: 0.5880  data_time: 0.2005  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:25:09 d2.utils.events]: \u001b[0m eta: 0:32:04  iter: 4239  total_loss: 1.475  loss_cls: 0.3365  loss_box_reg: 0.5202  loss_mask: 0.3024  loss_rpn_cls: 0.0773  loss_rpn_loc: 0.1988  time: 0.5889  data_time: 0.4425  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:25:20 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 4259  total_loss: 1.387  loss_cls: 0.3256  loss_box_reg: 0.4905  loss_mask: 0.2924  loss_rpn_cls: 0.06103  loss_rpn_loc: 0.1824  time: 0.5886  data_time: 0.2040  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:25:33 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 4279  total_loss: 1.419  loss_cls: 0.3262  loss_box_reg: 0.5177  loss_mask: 0.3014  loss_rpn_cls: 0.09204  loss_rpn_loc: 0.2098  time: 0.5889  data_time: 0.3150  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:25:44 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 4299  total_loss: 1.393  loss_cls: 0.3186  loss_box_reg: 0.515  loss_mask: 0.2915  loss_rpn_cls: 0.08572  loss_rpn_loc: 0.18  time: 0.5889  data_time: 0.2643  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:25:58 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 4319  total_loss: 1.375  loss_cls: 0.3263  loss_box_reg: 0.504  loss_mask: 0.2983  loss_rpn_cls: 0.09131  loss_rpn_loc: 0.1995  time: 0.5893  data_time: 0.3645  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:26:12 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 4339  total_loss: 1.502  loss_cls: 0.3225  loss_box_reg: 0.492  loss_mask: 0.2991  loss_rpn_cls: 0.0935  loss_rpn_loc: 0.2104  time: 0.5897  data_time: 0.3556  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:26:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:26:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:26:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:26:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:26:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:26:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0696 s/iter. Eval: 0.0433 s/iter. Total: 0.1135 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 15:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0739 s/iter. Eval: 0.0593 s/iter. Total: 0.1340 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0747 s/iter. Eval: 0.0630 s/iter. Total: 0.1385 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 15:26:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.800307 (0.136210 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:26:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074281 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:26:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:26:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2619872703850991\n",
      "\u001b[32m[02/03 15:26:42 d2.utils.events]: \u001b[0m eta: 0:31:36  iter: 4359  total_loss: 1.467  loss_cls: 0.3302  loss_box_reg: 0.5286  loss_mask: 0.2884  loss_rpn_cls: 0.09136  loss_rpn_loc: 0.1831  time: 0.5899  data_time: 0.3079  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:26:54 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 4379  total_loss: 1.418  loss_cls: 0.319  loss_box_reg: 0.5314  loss_mask: 0.29  loss_rpn_cls: 0.06873  loss_rpn_loc: 0.2087  time: 0.5901  data_time: 0.2952  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:27:07 d2.utils.events]: \u001b[0m eta: 0:31:25  iter: 4399  total_loss: 1.529  loss_cls: 0.3689  loss_box_reg: 0.5314  loss_mask: 0.288  loss_rpn_cls: 0.09849  loss_rpn_loc: 0.2039  time: 0.5903  data_time: 0.3135  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:27:17 d2.utils.events]: \u001b[0m eta: 0:31:14  iter: 4419  total_loss: 1.389  loss_cls: 0.3043  loss_box_reg: 0.5133  loss_mask: 0.2999  loss_rpn_cls: 0.06755  loss_rpn_loc: 0.1744  time: 0.5898  data_time: 0.1834  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:27:27 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 4439  total_loss: 1.365  loss_cls: 0.3041  loss_box_reg: 0.5053  loss_mask: 0.3027  loss_rpn_cls: 0.08062  loss_rpn_loc: 0.2049  time: 0.5895  data_time: 0.2081  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:27:38 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 4459  total_loss: 1.366  loss_cls: 0.3075  loss_box_reg: 0.4951  loss_mask: 0.3006  loss_rpn_cls: 0.06482  loss_rpn_loc: 0.1872  time: 0.5893  data_time: 0.2325  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:27:50 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 4479  total_loss: 1.429  loss_cls: 0.3152  loss_box_reg: 0.5017  loss_mask: 0.3095  loss_rpn_cls: 0.08675  loss_rpn_loc: 0.1996  time: 0.5894  data_time: 0.2932  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:28:01 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 4499  total_loss: 1.339  loss_cls: 0.2893  loss_box_reg: 0.513  loss_mask: 0.304  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.1919  time: 0.5891  data_time: 0.2146  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:28:10 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 4519  total_loss: 1.313  loss_cls: 0.2782  loss_box_reg: 0.4919  loss_mask: 0.2843  loss_rpn_cls: 0.0528  loss_rpn_loc: 0.1735  time: 0.5887  data_time: 0.1733  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:28:26 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 4539  total_loss: 1.473  loss_cls: 0.3318  loss_box_reg: 0.5172  loss_mask: 0.3099  loss_rpn_cls: 0.09373  loss_rpn_loc: 0.2022  time: 0.5895  data_time: 0.4269  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:28:38 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 4559  total_loss: 1.322  loss_cls: 0.3005  loss_box_reg: 0.4964  loss_mask: 0.2914  loss_rpn_cls: 0.06888  loss_rpn_loc: 0.1837  time: 0.5895  data_time: 0.2658  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:28:50 d2.utils.events]: \u001b[0m eta: 0:30:27  iter: 4579  total_loss: 1.367  loss_cls: 0.2934  loss_box_reg: 0.4759  loss_mask: 0.2984  loss_rpn_cls: 0.08787  loss_rpn_loc: 0.173  time: 0.5896  data_time: 0.3004  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:29:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:29:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:29:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:29:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:29:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:29:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0691 s/iter. Eval: 0.0352 s/iter. Total: 0.1049 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:29:09 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0720 s/iter. Eval: 0.0547 s/iter. Total: 0.1275 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0577 s/iter. Total: 0.1311 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.097370 (0.130150 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072099 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:29:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:29:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2632468880645666\n",
      "\u001b[32m[02/03 15:29:19 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 4599  total_loss: 1.321  loss_cls: 0.3002  loss_box_reg: 0.4778  loss_mask: 0.2869  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.1743  time: 0.5897  data_time: 0.2790  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:29:28 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 4619  total_loss: 1.386  loss_cls: 0.3075  loss_box_reg: 0.5231  loss_mask: 0.2987  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.1903  time: 0.5891  data_time: 0.1412  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:29:39 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 4639  total_loss: 1.483  loss_cls: 0.3356  loss_box_reg: 0.5454  loss_mask: 0.2922  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.2227  time: 0.5890  data_time: 0.2359  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:29:51 d2.utils.events]: \u001b[0m eta: 0:29:52  iter: 4659  total_loss: 1.459  loss_cls: 0.3658  loss_box_reg: 0.5402  loss_mask: 0.3022  loss_rpn_cls: 0.05483  loss_rpn_loc: 0.1999  time: 0.5889  data_time: 0.2565  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:30:01 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 4679  total_loss: 1.298  loss_cls: 0.3066  loss_box_reg: 0.4981  loss_mask: 0.2806  loss_rpn_cls: 0.05171  loss_rpn_loc: 0.1633  time: 0.5885  data_time: 0.1763  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:30:10 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 4699  total_loss: 1.454  loss_cls: 0.3166  loss_box_reg: 0.5341  loss_mask: 0.2996  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.1796  time: 0.5880  data_time: 0.1705  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:30:22 d2.utils.events]: \u001b[0m eta: 0:29:21  iter: 4719  total_loss: 1.375  loss_cls: 0.3114  loss_box_reg: 0.4751  loss_mask: 0.3022  loss_rpn_cls: 0.07252  loss_rpn_loc: 0.1737  time: 0.5881  data_time: 0.2903  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:30:31 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 4739  total_loss: 1.284  loss_cls: 0.2819  loss_box_reg: 0.4916  loss_mask: 0.2803  loss_rpn_cls: 0.05766  loss_rpn_loc: 0.1876  time: 0.5875  data_time: 0.1530  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:30:46 d2.utils.events]: \u001b[0m eta: 0:29:08  iter: 4759  total_loss: 1.326  loss_cls: 0.3033  loss_box_reg: 0.4589  loss_mask: 0.293  loss_rpn_cls: 0.06976  loss_rpn_loc: 0.1845  time: 0.5882  data_time: 0.4115  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:30:58 d2.utils.events]: \u001b[0m eta: 0:29:00  iter: 4779  total_loss: 1.403  loss_cls: 0.3722  loss_box_reg: 0.4967  loss_mask: 0.2829  loss_rpn_cls: 0.0949  loss_rpn_loc: 0.1993  time: 0.5881  data_time: 0.2719  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:31:10 d2.utils.events]: \u001b[0m eta: 0:28:54  iter: 4799  total_loss: 1.413  loss_cls: 0.2979  loss_box_reg: 0.5087  loss_mask: 0.3029  loss_rpn_cls: 0.08371  loss_rpn_loc: 0.2006  time: 0.5883  data_time: 0.3107  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:31:26 d2.utils.events]: \u001b[0m eta: 0:28:47  iter: 4819  total_loss: 1.363  loss_cls: 0.2722  loss_box_reg: 0.5048  loss_mask: 0.3057  loss_rpn_cls: 0.08147  loss_rpn_loc: 0.2001  time: 0.5891  data_time: 0.4583  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:31:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:31:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:31:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:31:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:31:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:31:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0713 s/iter. Eval: 0.0392 s/iter. Total: 0.1111 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 15:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0009 s/iter. Inference: 0.0724 s/iter. Eval: 0.0566 s/iter. Total: 0.1299 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0728 s/iter. Eval: 0.0607 s/iter. Total: 0.1343 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:31:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.226211 (0.131260 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:31:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071938 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:31:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:31:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2670641111784403\n",
      "\u001b[32m[02/03 15:31:56 d2.utils.events]: \u001b[0m eta: 0:28:48  iter: 4839  total_loss: 1.379  loss_cls: 0.3129  loss_box_reg: 0.5116  loss_mask: 0.3103  loss_rpn_cls: 0.08801  loss_rpn_loc: 0.1928  time: 0.5894  data_time: 0.3274  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:32:04 d2.utils.events]: \u001b[0m eta: 0:28:35  iter: 4859  total_loss: 1.337  loss_cls: 0.2867  loss_box_reg: 0.5333  loss_mask: 0.2963  loss_rpn_cls: 0.05518  loss_rpn_loc: 0.1795  time: 0.5886  data_time: 0.0945  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:32:17 d2.utils.events]: \u001b[0m eta: 0:28:28  iter: 4879  total_loss: 1.388  loss_cls: 0.3206  loss_box_reg: 0.5198  loss_mask: 0.298  loss_rpn_cls: 0.07727  loss_rpn_loc: 0.1797  time: 0.5888  data_time: 0.3037  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:32:27 d2.utils.events]: \u001b[0m eta: 0:28:21  iter: 4899  total_loss: 1.394  loss_cls: 0.3202  loss_box_reg: 0.5156  loss_mask: 0.2911  loss_rpn_cls: 0.06637  loss_rpn_loc: 0.1919  time: 0.5885  data_time: 0.2121  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:32:40 d2.utils.events]: \u001b[0m eta: 0:28:23  iter: 4919  total_loss: 1.4  loss_cls: 0.3028  loss_box_reg: 0.4843  loss_mask: 0.2989  loss_rpn_cls: 0.08673  loss_rpn_loc: 0.1945  time: 0.5887  data_time: 0.2922  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:32:55 d2.utils.events]: \u001b[0m eta: 0:28:17  iter: 4939  total_loss: 1.441  loss_cls: 0.3083  loss_box_reg: 0.4986  loss_mask: 0.2985  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.2162  time: 0.5894  data_time: 0.4475  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:33:07 d2.utils.events]: \u001b[0m eta: 0:28:10  iter: 4959  total_loss: 1.322  loss_cls: 0.2927  loss_box_reg: 0.5208  loss_mask: 0.3082  loss_rpn_cls: 0.0648  loss_rpn_loc: 0.1904  time: 0.5895  data_time: 0.3096  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:33:16 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 4979  total_loss: 1.267  loss_cls: 0.289  loss_box_reg: 0.4953  loss_mask: 0.2866  loss_rpn_cls: 0.05157  loss_rpn_loc: 0.1674  time: 0.5888  data_time: 0.1104  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:33:29 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 4999  total_loss: 1.459  loss_cls: 0.3512  loss_box_reg: 0.5362  loss_mask: 0.3055  loss_rpn_cls: 0.07885  loss_rpn_loc: 0.2056  time: 0.5891  data_time: 0.3477  lr: 0.000256  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:33:39 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 5019  total_loss: 1.366  loss_cls: 0.3069  loss_box_reg: 0.515  loss_mask: 0.2987  loss_rpn_cls: 0.06152  loss_rpn_loc: 0.1996  time: 0.5888  data_time: 0.1915  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:33:51 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 5039  total_loss: 1.397  loss_cls: 0.3341  loss_box_reg: 0.5129  loss_mask: 0.287  loss_rpn_cls: 0.09496  loss_rpn_loc: 0.2133  time: 0.5889  data_time: 0.2847  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:34:09 d2.utils.events]: \u001b[0m eta: 0:27:42  iter: 5059  total_loss: 1.406  loss_cls: 0.3556  loss_box_reg: 0.4981  loss_mask: 0.3008  loss_rpn_cls: 0.09805  loss_rpn_loc: 0.1995  time: 0.5900  data_time: 0.5422  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:34:20 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 5079  total_loss: 1.37  loss_cls: 0.3203  loss_box_reg: 0.5073  loss_mask: 0.3041  loss_rpn_cls: 0.06216  loss_rpn_loc: 0.1751  time: 0.5899  data_time: 0.2406  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:34:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:34:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:34:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:34:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:34:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:34:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0689 s/iter. Eval: 0.0359 s/iter. Total: 0.1055 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0523 s/iter. Total: 0.1237 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 15:34:35 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0728 s/iter. Eval: 0.0532 s/iter. Total: 0.1268 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 15:34:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.462103 (0.124673 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:34:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071989 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:34:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:34:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2575334976190718\n",
      "\u001b[32m[02/03 15:34:46 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 5099  total_loss: 1.46  loss_cls: 0.3507  loss_box_reg: 0.5243  loss_mask: 0.2918  loss_rpn_cls: 0.07033  loss_rpn_loc: 0.1872  time: 0.5896  data_time: 0.1980  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:34:59 d2.utils.events]: \u001b[0m eta: 0:27:18  iter: 5119  total_loss: 1.366  loss_cls: 0.3185  loss_box_reg: 0.4919  loss_mask: 0.2807  loss_rpn_cls: 0.06617  loss_rpn_loc: 0.1887  time: 0.5897  data_time: 0.3080  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:35:09 d2.utils.events]: \u001b[0m eta: 0:27:16  iter: 5139  total_loss: 1.401  loss_cls: 0.3286  loss_box_reg: 0.5197  loss_mask: 0.2943  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.2002  time: 0.5895  data_time: 0.2127  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:35:23 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 5159  total_loss: 1.41  loss_cls: 0.3233  loss_box_reg: 0.5061  loss_mask: 0.2976  loss_rpn_cls: 0.08102  loss_rpn_loc: 0.1924  time: 0.5899  data_time: 0.3694  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:35:38 d2.utils.events]: \u001b[0m eta: 0:27:07  iter: 5179  total_loss: 1.408  loss_cls: 0.3707  loss_box_reg: 0.4797  loss_mask: 0.2946  loss_rpn_cls: 0.08582  loss_rpn_loc: 0.2026  time: 0.5905  data_time: 0.4145  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:35:51 d2.utils.events]: \u001b[0m eta: 0:27:05  iter: 5199  total_loss: 1.299  loss_cls: 0.2794  loss_box_reg: 0.4645  loss_mask: 0.2758  loss_rpn_cls: 0.07777  loss_rpn_loc: 0.1864  time: 0.5906  data_time: 0.2980  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:36:01 d2.utils.events]: \u001b[0m eta: 0:26:54  iter: 5219  total_loss: 1.45  loss_cls: 0.349  loss_box_reg: 0.5114  loss_mask: 0.2932  loss_rpn_cls: 0.08239  loss_rpn_loc: 0.2085  time: 0.5903  data_time: 0.2036  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:36:11 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 5239  total_loss: 1.31  loss_cls: 0.267  loss_box_reg: 0.5131  loss_mask: 0.2839  loss_rpn_cls: 0.0597  loss_rpn_loc: 0.1689  time: 0.5900  data_time: 0.2157  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:36:24 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 5259  total_loss: 1.394  loss_cls: 0.3169  loss_box_reg: 0.4769  loss_mask: 0.3147  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.1842  time: 0.5901  data_time: 0.3057  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:36:37 d2.utils.events]: \u001b[0m eta: 0:26:28  iter: 5279  total_loss: 1.515  loss_cls: 0.335  loss_box_reg: 0.5074  loss_mask: 0.2962  loss_rpn_cls: 0.08912  loss_rpn_loc: 0.2142  time: 0.5905  data_time: 0.3573  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:36:48 d2.utils.events]: \u001b[0m eta: 0:26:21  iter: 5299  total_loss: 1.359  loss_cls: 0.294  loss_box_reg: 0.4998  loss_mask: 0.2932  loss_rpn_cls: 0.06892  loss_rpn_loc: 0.1925  time: 0.5902  data_time: 0.2120  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:36:58 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 5319  total_loss: 1.41  loss_cls: 0.3293  loss_box_reg: 0.5047  loss_mask: 0.2933  loss_rpn_cls: 0.0582  loss_rpn_loc: 0.1827  time: 0.5899  data_time: 0.2016  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:37:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:37:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:37:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:37:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:37:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:37:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0374 s/iter. Total: 0.1063 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0556 s/iter. Total: 0.1272 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0596 s/iter. Total: 0.1317 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:37:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.192102 (0.130966 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:37:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071136 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:37:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:37:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26658840978998805\n",
      "\u001b[32m[02/03 15:37:26 d2.utils.events]: \u001b[0m eta: 0:26:01  iter: 5339  total_loss: 1.283  loss_cls: 0.2886  loss_box_reg: 0.5231  loss_mask: 0.2874  loss_rpn_cls: 0.07309  loss_rpn_loc: 0.1834  time: 0.5898  data_time: 0.2332  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:37:38 d2.utils.events]: \u001b[0m eta: 0:25:57  iter: 5359  total_loss: 1.457  loss_cls: 0.3456  loss_box_reg: 0.4952  loss_mask: 0.3088  loss_rpn_cls: 0.09201  loss_rpn_loc: 0.1909  time: 0.5899  data_time: 0.3173  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:37:49 d2.utils.events]: \u001b[0m eta: 0:25:50  iter: 5379  total_loss: 1.336  loss_cls: 0.2999  loss_box_reg: 0.4829  loss_mask: 0.2918  loss_rpn_cls: 0.06777  loss_rpn_loc: 0.1733  time: 0.5898  data_time: 0.2281  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:38:02 d2.utils.events]: \u001b[0m eta: 0:25:39  iter: 5399  total_loss: 1.448  loss_cls: 0.3494  loss_box_reg: 0.513  loss_mask: 0.3067  loss_rpn_cls: 0.08817  loss_rpn_loc: 0.1809  time: 0.5899  data_time: 0.3105  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:38:15 d2.utils.events]: \u001b[0m eta: 0:25:39  iter: 5419  total_loss: 1.359  loss_cls: 0.2994  loss_box_reg: 0.5009  loss_mask: 0.2988  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.1815  time: 0.5902  data_time: 0.3366  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:38:26 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 5439  total_loss: 1.445  loss_cls: 0.342  loss_box_reg: 0.5217  loss_mask: 0.3027  loss_rpn_cls: 0.07309  loss_rpn_loc: 0.1881  time: 0.5901  data_time: 0.2557  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:38:36 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 5459  total_loss: 1.235  loss_cls: 0.235  loss_box_reg: 0.5079  loss_mask: 0.2874  loss_rpn_cls: 0.03227  loss_rpn_loc: 0.1733  time: 0.5897  data_time: 0.1848  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:38:50 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 5479  total_loss: 1.462  loss_cls: 0.3371  loss_box_reg: 0.5433  loss_mask: 0.3119  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.2073  time: 0.5902  data_time: 0.3896  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:38:59 d2.utils.events]: \u001b[0m eta: 0:25:10  iter: 5499  total_loss: 1.31  loss_cls: 0.2558  loss_box_reg: 0.5292  loss_mask: 0.3147  loss_rpn_cls: 0.05284  loss_rpn_loc: 0.1769  time: 0.5897  data_time: 0.1465  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:39:11 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 5519  total_loss: 1.379  loss_cls: 0.3207  loss_box_reg: 0.4716  loss_mask: 0.3072  loss_rpn_cls: 0.07769  loss_rpn_loc: 0.1908  time: 0.5897  data_time: 0.2878  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:39:23 d2.utils.events]: \u001b[0m eta: 0:24:54  iter: 5539  total_loss: 1.455  loss_cls: 0.3404  loss_box_reg: 0.5057  loss_mask: 0.3203  loss_rpn_cls: 0.09024  loss_rpn_loc: 0.2069  time: 0.5897  data_time: 0.2624  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:39:30 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 5559  total_loss: 1.439  loss_cls: 0.3239  loss_box_reg: 0.5552  loss_mask: 0.2959  loss_rpn_cls: 0.06669  loss_rpn_loc: 0.1887  time: 0.5888  data_time: 0.0605  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:39:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:39:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:39:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:39:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:39:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:39:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.0366 s/iter. Total: 0.1051 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:39:42 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0709 s/iter. Eval: 0.0547 s/iter. Total: 0.1264 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 15:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0711 s/iter. Eval: 0.0582 s/iter. Total: 0.1301 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:39:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.992897 (0.129249 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:39:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070968 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:39:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:39:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26266139408734906\n",
      "\u001b[32m[02/03 15:39:59 d2.utils.events]: \u001b[0m eta: 0:24:34  iter: 5579  total_loss: 1.418  loss_cls: 0.3203  loss_box_reg: 0.5062  loss_mask: 0.3036  loss_rpn_cls: 0.08706  loss_rpn_loc: 0.1885  time: 0.5890  data_time: 0.3069  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:40:10 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 5599  total_loss: 1.407  loss_cls: 0.3417  loss_box_reg: 0.4805  loss_mask: 0.2926  loss_rpn_cls: 0.08652  loss_rpn_loc: 0.1963  time: 0.5887  data_time: 0.2115  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:40:21 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 5619  total_loss: 1.355  loss_cls: 0.3249  loss_box_reg: 0.5092  loss_mask: 0.2896  loss_rpn_cls: 0.05835  loss_rpn_loc: 0.1853  time: 0.5887  data_time: 0.2561  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:40:30 d2.utils.events]: \u001b[0m eta: 0:24:06  iter: 5639  total_loss: 1.378  loss_cls: 0.2904  loss_box_reg: 0.4935  loss_mask: 0.2859  loss_rpn_cls: 0.04466  loss_rpn_loc: 0.2002  time: 0.5881  data_time: 0.1429  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:40:43 d2.utils.events]: \u001b[0m eta: 0:24:03  iter: 5659  total_loss: 1.501  loss_cls: 0.3558  loss_box_reg: 0.5476  loss_mask: 0.3157  loss_rpn_cls: 0.08829  loss_rpn_loc: 0.195  time: 0.5884  data_time: 0.3287  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:40:55 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 5679  total_loss: 1.375  loss_cls: 0.317  loss_box_reg: 0.5188  loss_mask: 0.2983  loss_rpn_cls: 0.05129  loss_rpn_loc: 0.1618  time: 0.5884  data_time: 0.2821  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:41:07 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 5699  total_loss: 1.371  loss_cls: 0.3029  loss_box_reg: 0.4938  loss_mask: 0.287  loss_rpn_cls: 0.09139  loss_rpn_loc: 0.1929  time: 0.5884  data_time: 0.2831  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:41:21 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 5719  total_loss: 1.449  loss_cls: 0.3421  loss_box_reg: 0.5085  loss_mask: 0.3184  loss_rpn_cls: 0.09442  loss_rpn_loc: 0.209  time: 0.5888  data_time: 0.3643  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:41:31 d2.utils.events]: \u001b[0m eta: 0:23:42  iter: 5739  total_loss: 1.369  loss_cls: 0.3134  loss_box_reg: 0.5055  loss_mask: 0.2943  loss_rpn_cls: 0.06878  loss_rpn_loc: 0.174  time: 0.5885  data_time: 0.1950  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:41:42 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 5759  total_loss: 1.318  loss_cls: 0.2888  loss_box_reg: 0.4832  loss_mask: 0.3003  loss_rpn_cls: 0.07428  loss_rpn_loc: 0.1997  time: 0.5884  data_time: 0.2679  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:41:54 d2.utils.events]: \u001b[0m eta: 0:23:27  iter: 5779  total_loss: 1.307  loss_cls: 0.2715  loss_box_reg: 0.4884  loss_mask: 0.2988  loss_rpn_cls: 0.07901  loss_rpn_loc: 0.204  time: 0.5885  data_time: 0.2994  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:42:05 d2.utils.events]: \u001b[0m eta: 0:23:18  iter: 5799  total_loss: 1.387  loss_cls: 0.2811  loss_box_reg: 0.5172  loss_mask: 0.3074  loss_rpn_cls: 0.0523  loss_rpn_loc: 0.1967  time: 0.5884  data_time: 0.2396  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:42:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:42:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:42:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:42:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:42:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:42:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0376 s/iter. Total: 0.1061 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:42:21 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0562 s/iter. Total: 0.1276 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0593 s/iter. Total: 0.1311 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:42:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.110138 (0.130260 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:42:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070874 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:42:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:42:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26315710696489614\n",
      "\u001b[32m[02/03 15:42:38 d2.utils.events]: \u001b[0m eta: 0:23:10  iter: 5819  total_loss: 1.469  loss_cls: 0.3315  loss_box_reg: 0.4897  loss_mask: 0.2985  loss_rpn_cls: 0.08614  loss_rpn_loc: 0.2106  time: 0.5890  data_time: 0.4532  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:42:53 d2.utils.events]: \u001b[0m eta: 0:23:00  iter: 5839  total_loss: 1.282  loss_cls: 0.2604  loss_box_reg: 0.4535  loss_mask: 0.2823  loss_rpn_cls: 0.07689  loss_rpn_loc: 0.1831  time: 0.5895  data_time: 0.4306  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:43:03 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 5859  total_loss: 1.305  loss_cls: 0.2949  loss_box_reg: 0.4994  loss_mask: 0.3096  loss_rpn_cls: 0.05791  loss_rpn_loc: 0.1682  time: 0.5892  data_time: 0.1941  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:43:16 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 5879  total_loss: 1.455  loss_cls: 0.3294  loss_box_reg: 0.4922  loss_mask: 0.3084  loss_rpn_cls: 0.1154  loss_rpn_loc: 0.1931  time: 0.5895  data_time: 0.3558  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:43:30 d2.utils.events]: \u001b[0m eta: 0:22:46  iter: 5899  total_loss: 1.408  loss_cls: 0.3037  loss_box_reg: 0.5129  loss_mask: 0.3008  loss_rpn_cls: 0.06765  loss_rpn_loc: 0.1887  time: 0.5899  data_time: 0.3974  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:43:43 d2.utils.events]: \u001b[0m eta: 0:22:38  iter: 5919  total_loss: 1.37  loss_cls: 0.2856  loss_box_reg: 0.5027  loss_mask: 0.3018  loss_rpn_cls: 0.08744  loss_rpn_loc: 0.1977  time: 0.5901  data_time: 0.3274  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:43:56 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 5939  total_loss: 1.412  loss_cls: 0.3026  loss_box_reg: 0.5116  loss_mask: 0.2897  loss_rpn_cls: 0.07994  loss_rpn_loc: 0.1966  time: 0.5903  data_time: 0.3521  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:44:08 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 5959  total_loss: 1.409  loss_cls: 0.3242  loss_box_reg: 0.4922  loss_mask: 0.2978  loss_rpn_cls: 0.07993  loss_rpn_loc: 0.1998  time: 0.5904  data_time: 0.2842  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:44:19 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 5979  total_loss: 1.421  loss_cls: 0.3156  loss_box_reg: 0.5112  loss_mask: 0.2984  loss_rpn_cls: 0.06777  loss_rpn_loc: 0.1768  time: 0.5903  data_time: 0.2440  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:44:31 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 5999  total_loss: 1.534  loss_cls: 0.3772  loss_box_reg: 0.5385  loss_mask: 0.3053  loss_rpn_cls: 0.09258  loss_rpn_loc: 0.2104  time: 0.5903  data_time: 0.2834  lr: 0.0002048  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:44:41 d2.utils.events]: \u001b[0m eta: 0:22:00  iter: 6019  total_loss: 1.375  loss_cls: 0.2822  loss_box_reg: 0.4996  loss_mask: 0.2936  loss_rpn_cls: 0.06551  loss_rpn_loc: 0.1938  time: 0.5899  data_time: 0.1853  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:44:50 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 6039  total_loss: 1.395  loss_cls: 0.311  loss_box_reg: 0.5126  loss_mask: 0.3062  loss_rpn_cls: 0.06273  loss_rpn_loc: 0.1684  time: 0.5895  data_time: 0.1582  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:44:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:44:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:44:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:44:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:44:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:44:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0372 s/iter. Total: 0.1061 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0555 s/iter. Total: 0.1269 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0589 s/iter. Total: 0.1307 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:45:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.049742 (0.129739 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:45:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070792 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:45:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:45:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26731268793057233\n",
      "\u001b[32m[02/03 15:45:19 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 6059  total_loss: 1.478  loss_cls: 0.3359  loss_box_reg: 0.511  loss_mask: 0.3001  loss_rpn_cls: 0.07924  loss_rpn_loc: 0.185  time: 0.5896  data_time: 0.2832  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:45:30 d2.utils.events]: \u001b[0m eta: 0:21:35  iter: 6079  total_loss: 1.349  loss_cls: 0.2738  loss_box_reg: 0.5158  loss_mask: 0.2993  loss_rpn_cls: 0.05934  loss_rpn_loc: 0.2012  time: 0.5893  data_time: 0.2132  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:45:42 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 6099  total_loss: 1.335  loss_cls: 0.2681  loss_box_reg: 0.4753  loss_mask: 0.2857  loss_rpn_cls: 0.07703  loss_rpn_loc: 0.1867  time: 0.5895  data_time: 0.3297  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:45:55 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 6119  total_loss: 1.412  loss_cls: 0.3322  loss_box_reg: 0.4848  loss_mask: 0.3002  loss_rpn_cls: 0.09237  loss_rpn_loc: 0.2079  time: 0.5897  data_time: 0.3296  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:46:05 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 6139  total_loss: 1.393  loss_cls: 0.3236  loss_box_reg: 0.5146  loss_mask: 0.3045  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1901  time: 0.5893  data_time: 0.1785  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:46:16 d2.utils.events]: \u001b[0m eta: 0:21:05  iter: 6159  total_loss: 1.336  loss_cls: 0.2934  loss_box_reg: 0.5229  loss_mask: 0.2856  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.1796  time: 0.5892  data_time: 0.2421  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:46:28 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 6179  total_loss: 1.354  loss_cls: 0.3117  loss_box_reg: 0.4922  loss_mask: 0.2971  loss_rpn_cls: 0.08146  loss_rpn_loc: 0.1947  time: 0.5893  data_time: 0.3198  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:46:38 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 6199  total_loss: 1.377  loss_cls: 0.318  loss_box_reg: 0.5288  loss_mask: 0.3062  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.1916  time: 0.5890  data_time: 0.1805  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:46:52 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 6219  total_loss: 1.418  loss_cls: 0.3195  loss_box_reg: 0.4865  loss_mask: 0.3095  loss_rpn_cls: 0.09886  loss_rpn_loc: 0.204  time: 0.5893  data_time: 0.3468  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:47:04 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 6239  total_loss: 1.329  loss_cls: 0.3004  loss_box_reg: 0.4942  loss_mask: 0.2882  loss_rpn_cls: 0.04837  loss_rpn_loc: 0.1972  time: 0.5893  data_time: 0.2739  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:47:17 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 6259  total_loss: 1.357  loss_cls: 0.2754  loss_box_reg: 0.485  loss_mask: 0.285  loss_rpn_cls: 0.08512  loss_rpn_loc: 0.1867  time: 0.5895  data_time: 0.3396  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:47:30 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 6279  total_loss: 1.435  loss_cls: 0.3241  loss_box_reg: 0.474  loss_mask: 0.3065  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.2032  time: 0.5897  data_time: 0.3550  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:47:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:47:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:47:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:47:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:47:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:47:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0681 s/iter. Eval: 0.0382 s/iter. Total: 0.1069 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0577 s/iter. Total: 0.1292 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0621 s/iter. Total: 0.1341 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:47:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.271431 (0.131650 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:47:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070951 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:47:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:47:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.267838277762992\n",
      "\u001b[32m[02/03 15:47:56 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 6299  total_loss: 1.387  loss_cls: 0.3233  loss_box_reg: 0.5027  loss_mask: 0.2992  loss_rpn_cls: 0.08008  loss_rpn_loc: 0.1802  time: 0.5893  data_time: 0.1380  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:48:06 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 6319  total_loss: 1.346  loss_cls: 0.3188  loss_box_reg: 0.5309  loss_mask: 0.2886  loss_rpn_cls: 0.06318  loss_rpn_loc: 0.1859  time: 0.5891  data_time: 0.2317  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:48:22 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 6339  total_loss: 1.38  loss_cls: 0.3158  loss_box_reg: 0.4956  loss_mask: 0.2986  loss_rpn_cls: 0.06762  loss_rpn_loc: 0.2079  time: 0.5897  data_time: 0.4622  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:48:34 d2.utils.events]: \u001b[0m eta: 0:19:58  iter: 6359  total_loss: 1.405  loss_cls: 0.3015  loss_box_reg: 0.5019  loss_mask: 0.3105  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.1664  time: 0.5898  data_time: 0.3059  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:48:45 d2.utils.events]: \u001b[0m eta: 0:19:52  iter: 6379  total_loss: 1.305  loss_cls: 0.2918  loss_box_reg: 0.4573  loss_mask: 0.3003  loss_rpn_cls: 0.04691  loss_rpn_loc: 0.1928  time: 0.5896  data_time: 0.2146  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:48:57 d2.utils.events]: \u001b[0m eta: 0:19:44  iter: 6399  total_loss: 1.272  loss_cls: 0.2836  loss_box_reg: 0.4801  loss_mask: 0.2945  loss_rpn_cls: 0.05006  loss_rpn_loc: 0.1751  time: 0.5896  data_time: 0.2796  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:49:08 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 6419  total_loss: 1.383  loss_cls: 0.3544  loss_box_reg: 0.5074  loss_mask: 0.2884  loss_rpn_cls: 0.0664  loss_rpn_loc: 0.1979  time: 0.5895  data_time: 0.2304  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:49:18 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 6439  total_loss: 1.308  loss_cls: 0.284  loss_box_reg: 0.518  loss_mask: 0.2961  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.1874  time: 0.5892  data_time: 0.2083  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:49:28 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 6459  total_loss: 1.346  loss_cls: 0.31  loss_box_reg: 0.506  loss_mask: 0.2769  loss_rpn_cls: 0.06686  loss_rpn_loc: 0.167  time: 0.5890  data_time: 0.2103  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:49:38 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 6479  total_loss: 1.394  loss_cls: 0.3124  loss_box_reg: 0.5363  loss_mask: 0.3044  loss_rpn_cls: 0.06126  loss_rpn_loc: 0.1761  time: 0.5887  data_time: 0.1927  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:49:50 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 6499  total_loss: 1.396  loss_cls: 0.2997  loss_box_reg: 0.5046  loss_mask: 0.2906  loss_rpn_cls: 0.07947  loss_rpn_loc: 0.1825  time: 0.5887  data_time: 0.2695  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:50:01 d2.utils.events]: \u001b[0m eta: 0:19:03  iter: 6519  total_loss: 1.405  loss_cls: 0.3183  loss_box_reg: 0.4933  loss_mask: 0.3045  loss_rpn_cls: 0.07771  loss_rpn_loc: 0.1963  time: 0.5887  data_time: 0.2579  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:50:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:50:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:50:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:50:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:50:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:50:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0684 s/iter. Eval: 0.0394 s/iter. Total: 0.1086 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0555 s/iter. Total: 0.1273 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0713 s/iter. Eval: 0.0592 s/iter. Total: 0.1312 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:50:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.107306 (0.130235 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:50:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070983 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:50:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:50:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2613866786168606\n",
      "\u001b[32m[02/03 15:50:29 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 6539  total_loss: 1.408  loss_cls: 0.3073  loss_box_reg: 0.5029  loss_mask: 0.3025  loss_rpn_cls: 0.07788  loss_rpn_loc: 0.1982  time: 0.5885  data_time: 0.2347  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:50:40 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 6559  total_loss: 1.443  loss_cls: 0.3459  loss_box_reg: 0.5051  loss_mask: 0.2962  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.2017  time: 0.5884  data_time: 0.2232  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:50:50 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 6579  total_loss: 1.402  loss_cls: 0.3442  loss_box_reg: 0.5303  loss_mask: 0.2977  loss_rpn_cls: 0.06256  loss_rpn_loc: 0.171  time: 0.5882  data_time: 0.2122  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:51:06 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 6599  total_loss: 1.363  loss_cls: 0.3109  loss_box_reg: 0.4858  loss_mask: 0.2979  loss_rpn_cls: 0.0886  loss_rpn_loc: 0.1909  time: 0.5887  data_time: 0.4322  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:51:14 d2.utils.events]: \u001b[0m eta: 0:18:31  iter: 6619  total_loss: 1.281  loss_cls: 0.2785  loss_box_reg: 0.5  loss_mask: 0.2693  loss_rpn_cls: 0.06389  loss_rpn_loc: 0.1677  time: 0.5882  data_time: 0.1332  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:51:27 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 6639  total_loss: 1.42  loss_cls: 0.2759  loss_box_reg: 0.5084  loss_mask: 0.2948  loss_rpn_cls: 0.07383  loss_rpn_loc: 0.2212  time: 0.5884  data_time: 0.3126  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:51:36 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 6659  total_loss: 1.443  loss_cls: 0.3289  loss_box_reg: 0.5231  loss_mask: 0.2851  loss_rpn_cls: 0.07991  loss_rpn_loc: 0.1827  time: 0.5880  data_time: 0.1409  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:51:47 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 6679  total_loss: 1.408  loss_cls: 0.3109  loss_box_reg: 0.5249  loss_mask: 0.2994  loss_rpn_cls: 0.08217  loss_rpn_loc: 0.2045  time: 0.5879  data_time: 0.2567  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:52:01 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 6699  total_loss: 1.333  loss_cls: 0.302  loss_box_reg: 0.4789  loss_mask: 0.2964  loss_rpn_cls: 0.06  loss_rpn_loc: 0.1779  time: 0.5881  data_time: 0.3430  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:52:12 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 6719  total_loss: 1.266  loss_cls: 0.2792  loss_box_reg: 0.5145  loss_mask: 0.2831  loss_rpn_cls: 0.06951  loss_rpn_loc: 0.172  time: 0.5880  data_time: 0.2541  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:52:23 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 6739  total_loss: 1.442  loss_cls: 0.3116  loss_box_reg: 0.4994  loss_mask: 0.2783  loss_rpn_cls: 0.07695  loss_rpn_loc: 0.187  time: 0.5879  data_time: 0.2375  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:52:36 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 6759  total_loss: 1.353  loss_cls: 0.3035  loss_box_reg: 0.4657  loss_mask: 0.3035  loss_rpn_cls: 0.06301  loss_rpn_loc: 0.1955  time: 0.5881  data_time: 0.3307  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:52:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:52:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:52:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:52:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:52:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:52:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:52:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0380 s/iter. Total: 0.1066 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:52:52 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0557 s/iter. Total: 0.1271 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:52:57 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0709 s/iter. Eval: 0.0590 s/iter. Total: 0.1308 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:53:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.102432 (0.130193 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:53:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070798 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:53:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:53:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2674451498497015\n",
      "\u001b[32m[02/03 15:53:04 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 6779  total_loss: 1.48  loss_cls: 0.3425  loss_box_reg: 0.5098  loss_mask: 0.3133  loss_rpn_cls: 0.08154  loss_rpn_loc: 0.1902  time: 0.5880  data_time: 0.2447  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:53:18 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 6799  total_loss: 1.453  loss_cls: 0.3274  loss_box_reg: 0.4926  loss_mask: 0.3069  loss_rpn_cls: 0.09936  loss_rpn_loc: 0.2222  time: 0.5883  data_time: 0.3730  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:53:26 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 6819  total_loss: 1.289  loss_cls: 0.2596  loss_box_reg: 0.4685  loss_mask: 0.2859  loss_rpn_cls: 0.05245  loss_rpn_loc: 0.1646  time: 0.5878  data_time: 0.1045  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:53:37 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 6839  total_loss: 1.381  loss_cls: 0.3034  loss_box_reg: 0.4819  loss_mask: 0.2969  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.1889  time: 0.5878  data_time: 0.2893  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:53:51 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 6859  total_loss: 1.425  loss_cls: 0.2991  loss_box_reg: 0.536  loss_mask: 0.3162  loss_rpn_cls: 0.07895  loss_rpn_loc: 0.2054  time: 0.5880  data_time: 0.3472  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:54:04 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 6879  total_loss: 1.34  loss_cls: 0.3317  loss_box_reg: 0.4643  loss_mask: 0.2915  loss_rpn_cls: 0.07438  loss_rpn_loc: 0.2022  time: 0.5882  data_time: 0.3507  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:54:18 d2.utils.events]: \u001b[0m eta: 0:17:00  iter: 6899  total_loss: 1.431  loss_cls: 0.3095  loss_box_reg: 0.5047  loss_mask: 0.309  loss_rpn_cls: 0.07574  loss_rpn_loc: 0.2271  time: 0.5886  data_time: 0.3909  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:54:34 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 6919  total_loss: 1.36  loss_cls: 0.2996  loss_box_reg: 0.4858  loss_mask: 0.298  loss_rpn_cls: 0.09149  loss_rpn_loc: 0.1782  time: 0.5891  data_time: 0.4384  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:54:43 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 6939  total_loss: 1.307  loss_cls: 0.2662  loss_box_reg: 0.4899  loss_mask: 0.3005  loss_rpn_cls: 0.05747  loss_rpn_loc: 0.1752  time: 0.5888  data_time: 0.1926  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:54:55 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 6959  total_loss: 1.502  loss_cls: 0.3425  loss_box_reg: 0.5458  loss_mask: 0.299  loss_rpn_cls: 0.07442  loss_rpn_loc: 0.201  time: 0.5887  data_time: 0.2526  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:55:06 d2.utils.events]: \u001b[0m eta: 0:16:33  iter: 6979  total_loss: 1.397  loss_cls: 0.2992  loss_box_reg: 0.5001  loss_mask: 0.2976  loss_rpn_cls: 0.05003  loss_rpn_loc: 0.17  time: 0.5887  data_time: 0.2694  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:55:18 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 6999  total_loss: 1.395  loss_cls: 0.3462  loss_box_reg: 0.5  loss_mask: 0.2793  loss_rpn_cls: 0.0761  loss_rpn_loc: 0.1954  time: 0.5887  data_time: 0.2782  lr: 0.00016384  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:55:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:55:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:55:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:55:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:55:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:55:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0375 s/iter. Total: 0.1060 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 15:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0557 s/iter. Total: 0.1272 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0710 s/iter. Eval: 0.0589 s/iter. Total: 0.1308 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:55:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.090485 (0.130090 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:55:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070876 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:55:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:55:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2679357773798259\n",
      "\u001b[32m[02/03 15:55:44 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 7019  total_loss: 1.286  loss_cls: 0.2691  loss_box_reg: 0.4843  loss_mask: 0.2916  loss_rpn_cls: 0.06592  loss_rpn_loc: 0.1845  time: 0.5883  data_time: 0.1467  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:55:54 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 7039  total_loss: 1.314  loss_cls: 0.3106  loss_box_reg: 0.4847  loss_mask: 0.2812  loss_rpn_cls: 0.0692  loss_rpn_loc: 0.1768  time: 0.5881  data_time: 0.1875  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:56:09 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 7059  total_loss: 1.427  loss_cls: 0.3058  loss_box_reg: 0.5015  loss_mask: 0.2954  loss_rpn_cls: 0.08381  loss_rpn_loc: 0.1992  time: 0.5885  data_time: 0.4282  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:56:21 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 7079  total_loss: 1.422  loss_cls: 0.3112  loss_box_reg: 0.5626  loss_mask: 0.2886  loss_rpn_cls: 0.08481  loss_rpn_loc: 0.1997  time: 0.5886  data_time: 0.2970  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:56:32 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 7099  total_loss: 1.302  loss_cls: 0.2978  loss_box_reg: 0.4851  loss_mask: 0.2863  loss_rpn_cls: 0.06578  loss_rpn_loc: 0.1823  time: 0.5884  data_time: 0.2262  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:56:49 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 7119  total_loss: 1.455  loss_cls: 0.3356  loss_box_reg: 0.4796  loss_mask: 0.3047  loss_rpn_cls: 0.08914  loss_rpn_loc: 0.1958  time: 0.5892  data_time: 0.5260  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:56:59 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 7139  total_loss: 1.366  loss_cls: 0.2968  loss_box_reg: 0.4961  loss_mask: 0.2866  loss_rpn_cls: 0.07335  loss_rpn_loc: 0.1739  time: 0.5889  data_time: 0.1877  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:57:09 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 7159  total_loss: 1.373  loss_cls: 0.2934  loss_box_reg: 0.4855  loss_mask: 0.2809  loss_rpn_cls: 0.05984  loss_rpn_loc: 0.182  time: 0.5887  data_time: 0.1882  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:57:19 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 7179  total_loss: 1.415  loss_cls: 0.3283  loss_box_reg: 0.5121  loss_mask: 0.292  loss_rpn_cls: 0.07268  loss_rpn_loc: 0.1975  time: 0.5885  data_time: 0.1958  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:57:32 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 7199  total_loss: 1.354  loss_cls: 0.3022  loss_box_reg: 0.4887  loss_mask: 0.299  loss_rpn_cls: 0.0735  loss_rpn_loc: 0.1747  time: 0.5887  data_time: 0.3327  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:57:43 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 7219  total_loss: 1.318  loss_cls: 0.2899  loss_box_reg: 0.493  loss_mask: 0.2968  loss_rpn_cls: 0.06952  loss_rpn_loc: 0.1703  time: 0.5886  data_time: 0.2453  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:57:54 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 7239  total_loss: 1.322  loss_cls: 0.2937  loss_box_reg: 0.5139  loss_mask: 0.2906  loss_rpn_cls: 0.07294  loss_rpn_loc: 0.1826  time: 0.5884  data_time: 0.2011  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:58:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:58:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 15:58:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 15:58:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 15:58:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 15:58:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 15:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0683 s/iter. Eval: 0.0442 s/iter. Total: 0.1132 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 15:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0558 s/iter. Total: 0.1274 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 15:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0592 s/iter. Total: 0.1312 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 15:58:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.102427 (0.130193 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:58:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070983 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 15:58:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 15:58:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.264673923727985\n",
      "\u001b[32m[02/03 15:58:21 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 7259  total_loss: 1.414  loss_cls: 0.3325  loss_box_reg: 0.4782  loss_mask: 0.287  loss_rpn_cls: 0.08556  loss_rpn_loc: 0.1918  time: 0.5882  data_time: 0.2102  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:58:32 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 7279  total_loss: 1.416  loss_cls: 0.3351  loss_box_reg: 0.5181  loss_mask: 0.3109  loss_rpn_cls: 0.09119  loss_rpn_loc: 0.2174  time: 0.5880  data_time: 0.2269  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:58:43 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 7299  total_loss: 1.406  loss_cls: 0.3149  loss_box_reg: 0.5076  loss_mask: 0.298  loss_rpn_cls: 0.0603  loss_rpn_loc: 0.1818  time: 0.5880  data_time: 0.2469  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:58:54 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 7319  total_loss: 1.307  loss_cls: 0.2826  loss_box_reg: 0.4673  loss_mask: 0.2888  loss_rpn_cls: 0.07084  loss_rpn_loc: 0.1807  time: 0.5878  data_time: 0.2357  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:59:04 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 7339  total_loss: 1.369  loss_cls: 0.3292  loss_box_reg: 0.4818  loss_mask: 0.3004  loss_rpn_cls: 0.07743  loss_rpn_loc: 0.1983  time: 0.5876  data_time: 0.1854  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:59:17 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 7359  total_loss: 1.443  loss_cls: 0.3515  loss_box_reg: 0.5059  loss_mask: 0.2961  loss_rpn_cls: 0.0863  loss_rpn_loc: 0.1934  time: 0.5877  data_time: 0.3276  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:59:26 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 7379  total_loss: 1.398  loss_cls: 0.2968  loss_box_reg: 0.5056  loss_mask: 0.2987  loss_rpn_cls: 0.04846  loss_rpn_loc: 0.1865  time: 0.5874  data_time: 0.1529  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:59:37 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 7399  total_loss: 1.415  loss_cls: 0.2869  loss_box_reg: 0.5107  loss_mask: 0.2988  loss_rpn_cls: 0.07819  loss_rpn_loc: 0.18  time: 0.5873  data_time: 0.2573  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 15:59:50 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 7419  total_loss: 1.369  loss_cls: 0.3093  loss_box_reg: 0.5047  loss_mask: 0.3017  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.1799  time: 0.5875  data_time: 0.3417  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:00:03 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 7439  total_loss: 1.286  loss_cls: 0.2753  loss_box_reg: 0.4846  loss_mask: 0.2917  loss_rpn_cls: 0.07188  loss_rpn_loc: 0.1975  time: 0.5876  data_time: 0.3103  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:00:18 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 7459  total_loss: 1.333  loss_cls: 0.2837  loss_box_reg: 0.4737  loss_mask: 0.3026  loss_rpn_cls: 0.095  loss_rpn_loc: 0.2193  time: 0.5882  data_time: 0.4607  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:00:30 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 7479  total_loss: 1.317  loss_cls: 0.3086  loss_box_reg: 0.4718  loss_mask: 0.289  loss_rpn_cls: 0.05669  loss_rpn_loc: 0.1803  time: 0.5882  data_time: 0.2777  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:00:44 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 7499  total_loss: 1.423  loss_cls: 0.32  loss_box_reg: 0.5029  loss_mask: 0.3026  loss_rpn_cls: 0.0581  loss_rpn_loc: 0.1841  time: 0.5885  data_time: 0.3940  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:00:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:00:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:00:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:00:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:00:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:00:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0687 s/iter. Eval: 0.0387 s/iter. Total: 0.1080 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 16:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0562 s/iter. Total: 0.1282 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 16:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0715 s/iter. Eval: 0.0600 s/iter. Total: 0.1323 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 16:01:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.269665 (0.131635 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:01:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071318 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:01:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:01:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2686520871214179\n",
      "\u001b[32m[02/03 16:01:13 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 7519  total_loss: 1.363  loss_cls: 0.2995  loss_box_reg: 0.5032  loss_mask: 0.2837  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.1563  time: 0.5884  data_time: 0.2626  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:01:27 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 7539  total_loss: 1.387  loss_cls: 0.3108  loss_box_reg: 0.5054  loss_mask: 0.2856  loss_rpn_cls: 0.08413  loss_rpn_loc: 0.194  time: 0.5888  data_time: 0.3950  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:01:37 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 7559  total_loss: 1.39  loss_cls: 0.3204  loss_box_reg: 0.5288  loss_mask: 0.3013  loss_rpn_cls: 0.06568  loss_rpn_loc: 0.1766  time: 0.5885  data_time: 0.1780  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:01:48 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 7579  total_loss: 1.289  loss_cls: 0.2901  loss_box_reg: 0.4971  loss_mask: 0.2846  loss_rpn_cls: 0.07548  loss_rpn_loc: 0.1725  time: 0.5884  data_time: 0.2354  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:02:00 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 7599  total_loss: 1.252  loss_cls: 0.2824  loss_box_reg: 0.4765  loss_mask: 0.2913  loss_rpn_cls: 0.05741  loss_rpn_loc: 0.153  time: 0.5884  data_time: 0.2716  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:02:12 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 7619  total_loss: 1.38  loss_cls: 0.318  loss_box_reg: 0.4965  loss_mask: 0.2827  loss_rpn_cls: 0.06787  loss_rpn_loc: 0.1855  time: 0.5885  data_time: 0.2966  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:02:22 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 7639  total_loss: 1.288  loss_cls: 0.291  loss_box_reg: 0.4866  loss_mask: 0.2908  loss_rpn_cls: 0.05092  loss_rpn_loc: 0.1611  time: 0.5883  data_time: 0.1931  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:02:32 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 7659  total_loss: 1.422  loss_cls: 0.3273  loss_box_reg: 0.4975  loss_mask: 0.3123  loss_rpn_cls: 0.08211  loss_rpn_loc: 0.2033  time: 0.5880  data_time: 0.1778  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:02:42 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 7679  total_loss: 1.269  loss_cls: 0.285  loss_box_reg: 0.4575  loss_mask: 0.279  loss_rpn_cls: 0.05559  loss_rpn_loc: 0.175  time: 0.5878  data_time: 0.2175  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:02:58 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 7699  total_loss: 1.46  loss_cls: 0.3034  loss_box_reg: 0.5051  loss_mask: 0.3178  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.2027  time: 0.5884  data_time: 0.4591  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:03:12 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 7719  total_loss: 1.411  loss_cls: 0.3037  loss_box_reg: 0.4857  loss_mask: 0.2844  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.1937  time: 0.5886  data_time: 0.3389  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:03:21 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 7739  total_loss: 1.445  loss_cls: 0.3138  loss_box_reg: 0.5088  loss_mask: 0.3039  loss_rpn_cls: 0.08679  loss_rpn_loc: 0.2055  time: 0.5882  data_time: 0.1564  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:03:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:03:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:03:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:03:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:03:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:03:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0725 s/iter. Eval: 0.0423 s/iter. Total: 0.1155 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 16:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0736 s/iter. Eval: 0.0573 s/iter. Total: 0.1318 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 16:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0731 s/iter. Eval: 0.0600 s/iter. Total: 0.1339 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 16:03:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.569596 (0.134221 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:03:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073550 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:03:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:03:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2629861493080141\n",
      "\u001b[32m[02/03 16:03:53 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 7759  total_loss: 1.395  loss_cls: 0.2888  loss_box_reg: 0.4956  loss_mask: 0.3132  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.1978  time: 0.5886  data_time: 0.3994  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:04:03 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 7779  total_loss: 1.326  loss_cls: 0.2868  loss_box_reg: 0.5075  loss_mask: 0.2875  loss_rpn_cls: 0.04305  loss_rpn_loc: 0.1857  time: 0.5884  data_time: 0.1625  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:04:13 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 7799  total_loss: 1.47  loss_cls: 0.3323  loss_box_reg: 0.5369  loss_mask: 0.3074  loss_rpn_cls: 0.07428  loss_rpn_loc: 0.1818  time: 0.5882  data_time: 0.2138  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:04:24 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 7819  total_loss: 1.328  loss_cls: 0.3121  loss_box_reg: 0.4858  loss_mask: 0.2919  loss_rpn_cls: 0.07035  loss_rpn_loc: 0.1737  time: 0.5881  data_time: 0.2039  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:04:34 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 7839  total_loss: 1.327  loss_cls: 0.3103  loss_box_reg: 0.4722  loss_mask: 0.2875  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.1918  time: 0.5879  data_time: 0.1742  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:04:47 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 7859  total_loss: 1.395  loss_cls: 0.3188  loss_box_reg: 0.4833  loss_mask: 0.2995  loss_rpn_cls: 0.07321  loss_rpn_loc: 0.1938  time: 0.5880  data_time: 0.3269  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:04:58 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 7879  total_loss: 1.505  loss_cls: 0.3301  loss_box_reg: 0.5378  loss_mask: 0.313  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.1956  time: 0.5879  data_time: 0.2390  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:05:10 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 7899  total_loss: 1.419  loss_cls: 0.3057  loss_box_reg: 0.4714  loss_mask: 0.3051  loss_rpn_cls: 0.08884  loss_rpn_loc: 0.1934  time: 0.5880  data_time: 0.2905  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:05:25 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 7919  total_loss: 1.399  loss_cls: 0.3482  loss_box_reg: 0.4866  loss_mask: 0.2952  loss_rpn_cls: 0.09666  loss_rpn_loc: 0.2093  time: 0.5883  data_time: 0.4089  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:05:41 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 7939  total_loss: 1.361  loss_cls: 0.3098  loss_box_reg: 0.46  loss_mask: 0.3034  loss_rpn_cls: 0.08579  loss_rpn_loc: 0.1907  time: 0.5889  data_time: 0.4600  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:05:53 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 7959  total_loss: 1.392  loss_cls: 0.3166  loss_box_reg: 0.4929  loss_mask: 0.3053  loss_rpn_cls: 0.05891  loss_rpn_loc: 0.1972  time: 0.5890  data_time: 0.2761  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:06:05 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 7979  total_loss: 1.315  loss_cls: 0.2753  loss_box_reg: 0.5007  loss_mask: 0.3025  loss_rpn_cls: 0.06321  loss_rpn_loc: 0.1846  time: 0.5890  data_time: 0.2546  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:06:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:06:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:06:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:06:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:06:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:06:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0478 s/iter. Total: 0.1236 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 16:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.0763 s/iter. Eval: 0.0638 s/iter. Total: 0.1409 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 16:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.0766 s/iter. Eval: 0.0654 s/iter. Total: 0.1429 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 16:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0627 s/iter. Total: 0.1396 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/03 16:06:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.334703 (0.140816 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:06:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076108 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:06:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:06:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2666418375952592\n",
      "\u001b[32m[02/03 16:06:35 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 7999  total_loss: 1.421  loss_cls: 0.3069  loss_box_reg: 0.5111  loss_mask: 0.2932  loss_rpn_cls: 0.05822  loss_rpn_loc: 0.1796  time: 0.5889  data_time: 0.2406  lr: 0.00013107  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:06:48 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 8019  total_loss: 1.405  loss_cls: 0.3059  loss_box_reg: 0.4686  loss_mask: 0.2885  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.188  time: 0.5891  data_time: 0.3482  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:07:03 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 8039  total_loss: 1.461  loss_cls: 0.3567  loss_box_reg: 0.5214  loss_mask: 0.3027  loss_rpn_cls: 0.08872  loss_rpn_loc: 0.191  time: 0.5895  data_time: 0.3784  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:07:16 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 8059  total_loss: 1.241  loss_cls: 0.2474  loss_box_reg: 0.449  loss_mask: 0.2838  loss_rpn_cls: 0.05088  loss_rpn_loc: 0.1671  time: 0.5897  data_time: 0.3378  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:07:27 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 8079  total_loss: 1.396  loss_cls: 0.3374  loss_box_reg: 0.5117  loss_mask: 0.2994  loss_rpn_cls: 0.06415  loss_rpn_loc: 0.1756  time: 0.5896  data_time: 0.2165  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:07:45 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 8099  total_loss: 1.34  loss_cls: 0.2702  loss_box_reg: 0.5152  loss_mask: 0.2993  loss_rpn_cls: 0.08852  loss_rpn_loc: 0.1945  time: 0.5903  data_time: 0.5155  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:07:56 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 8119  total_loss: 1.339  loss_cls: 0.2863  loss_box_reg: 0.4824  loss_mask: 0.2888  loss_rpn_cls: 0.06958  loss_rpn_loc: 0.1874  time: 0.5902  data_time: 0.2435  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:08:08 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 8139  total_loss: 1.368  loss_cls: 0.321  loss_box_reg: 0.5127  loss_mask: 0.2807  loss_rpn_cls: 0.06983  loss_rpn_loc: 0.1707  time: 0.5902  data_time: 0.2594  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:08:19 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 8159  total_loss: 1.342  loss_cls: 0.3016  loss_box_reg: 0.4885  loss_mask: 0.2937  loss_rpn_cls: 0.06689  loss_rpn_loc: 0.1709  time: 0.5901  data_time: 0.2280  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:08:31 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 8179  total_loss: 1.438  loss_cls: 0.3209  loss_box_reg: 0.5188  loss_mask: 0.3043  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.1967  time: 0.5902  data_time: 0.2722  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:08:43 d2.utils.events]: \u001b[0m eta: 0:10:17  iter: 8199  total_loss: 1.351  loss_cls: 0.2789  loss_box_reg: 0.4752  loss_mask: 0.3059  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.1908  time: 0.5902  data_time: 0.2524  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:08:53 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 8219  total_loss: 1.464  loss_cls: 0.3368  loss_box_reg: 0.5073  loss_mask: 0.3072  loss_rpn_cls: 0.06637  loss_rpn_loc: 0.203  time: 0.5900  data_time: 0.2145  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:08:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:08:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:08:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:08:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:08:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:08:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0454 s/iter. Total: 0.1199 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 16:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0754 s/iter. Eval: 0.0618 s/iter. Total: 0.1380 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 16:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0755 s/iter. Eval: 0.0646 s/iter. Total: 0.1409 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 16:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0620 s/iter. Total: 0.1379 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/03 16:09:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.060425 (0.138452 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:09:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074973 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:09:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:09:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2680637971046112\n",
      "\u001b[32m[02/03 16:09:20 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 8239  total_loss: 1.243  loss_cls: 0.3123  loss_box_reg: 0.479  loss_mask: 0.2895  loss_rpn_cls: 0.07556  loss_rpn_loc: 0.1808  time: 0.5896  data_time: 0.0834  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:09:31 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 8259  total_loss: 1.299  loss_cls: 0.2958  loss_box_reg: 0.4921  loss_mask: 0.2796  loss_rpn_cls: 0.0495  loss_rpn_loc: 0.1745  time: 0.5896  data_time: 0.2605  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:09:41 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 8279  total_loss: 1.291  loss_cls: 0.3041  loss_box_reg: 0.4984  loss_mask: 0.2826  loss_rpn_cls: 0.06067  loss_rpn_loc: 0.1649  time: 0.5894  data_time: 0.1952  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:09:54 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 8299  total_loss: 1.323  loss_cls: 0.2847  loss_box_reg: 0.5151  loss_mask: 0.3013  loss_rpn_cls: 0.06101  loss_rpn_loc: 0.1853  time: 0.5895  data_time: 0.3194  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:10:05 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 8319  total_loss: 1.386  loss_cls: 0.291  loss_box_reg: 0.4844  loss_mask: 0.301  loss_rpn_cls: 0.08799  loss_rpn_loc: 0.1975  time: 0.5894  data_time: 0.2100  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:10:17 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 8339  total_loss: 1.332  loss_cls: 0.2947  loss_box_reg: 0.516  loss_mask: 0.2824  loss_rpn_cls: 0.06482  loss_rpn_loc: 0.1707  time: 0.5894  data_time: 0.2776  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:10:31 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 8359  total_loss: 1.413  loss_cls: 0.3498  loss_box_reg: 0.4883  loss_mask: 0.3006  loss_rpn_cls: 0.08442  loss_rpn_loc: 0.1973  time: 0.5897  data_time: 0.3347  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:10:44 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 8379  total_loss: 1.315  loss_cls: 0.2814  loss_box_reg: 0.4985  loss_mask: 0.3195  loss_rpn_cls: 0.06021  loss_rpn_loc: 0.1729  time: 0.5899  data_time: 0.3363  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:10:56 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 8399  total_loss: 1.336  loss_cls: 0.3323  loss_box_reg: 0.4813  loss_mask: 0.2777  loss_rpn_cls: 0.06791  loss_rpn_loc: 0.185  time: 0.5899  data_time: 0.2628  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:11:09 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 8419  total_loss: 1.377  loss_cls: 0.3239  loss_box_reg: 0.485  loss_mask: 0.2911  loss_rpn_cls: 0.09479  loss_rpn_loc: 0.1991  time: 0.5900  data_time: 0.2970  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:11:20 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 8439  total_loss: 1.447  loss_cls: 0.3553  loss_box_reg: 0.4842  loss_mask: 0.2959  loss_rpn_cls: 0.0688  loss_rpn_loc: 0.1931  time: 0.5898  data_time: 0.2182  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:11:35 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 8459  total_loss: 1.336  loss_cls: 0.2825  loss_box_reg: 0.493  loss_mask: 0.2978  loss_rpn_cls: 0.09455  loss_rpn_loc: 0.2114  time: 0.5903  data_time: 0.4378  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:11:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:11:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:11:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:11:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:11:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:11:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:11:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0727 s/iter. Eval: 0.0477 s/iter. Total: 0.1212 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 16:11:47 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0587 s/iter. Total: 0.1341 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 16:11:52 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0616 s/iter. Total: 0.1373 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 16:11:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.774372 (0.135986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:11:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074636 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:11:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:11:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26588315875821794\n",
      "\u001b[32m[02/03 16:12:02 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 8479  total_loss: 1.314  loss_cls: 0.2916  loss_box_reg: 0.5243  loss_mask: 0.2949  loss_rpn_cls: 0.06822  loss_rpn_loc: 0.187  time: 0.5900  data_time: 0.1557  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:12:16 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 8499  total_loss: 1.376  loss_cls: 0.268  loss_box_reg: 0.4755  loss_mask: 0.302  loss_rpn_cls: 0.0866  loss_rpn_loc: 0.198  time: 0.5903  data_time: 0.3449  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:12:31 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 8519  total_loss: 1.329  loss_cls: 0.2871  loss_box_reg: 0.4803  loss_mask: 0.2975  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.2038  time: 0.5906  data_time: 0.4194  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:12:43 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 8539  total_loss: 1.366  loss_cls: 0.3063  loss_box_reg: 0.4884  loss_mask: 0.3097  loss_rpn_cls: 0.06321  loss_rpn_loc: 0.1948  time: 0.5907  data_time: 0.2685  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:12:52 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 8559  total_loss: 1.47  loss_cls: 0.3107  loss_box_reg: 0.5481  loss_mask: 0.3121  loss_rpn_cls: 0.06891  loss_rpn_loc: 0.1856  time: 0.5903  data_time: 0.1071  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:13:04 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 8579  total_loss: 1.506  loss_cls: 0.3375  loss_box_reg: 0.5117  loss_mask: 0.3137  loss_rpn_cls: 0.07435  loss_rpn_loc: 0.218  time: 0.5903  data_time: 0.2681  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:13:20 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 8599  total_loss: 1.479  loss_cls: 0.3455  loss_box_reg: 0.4879  loss_mask: 0.2895  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2059  time: 0.5908  data_time: 0.4532  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:13:31 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 8619  total_loss: 1.473  loss_cls: 0.307  loss_box_reg: 0.4996  loss_mask: 0.3127  loss_rpn_cls: 0.07412  loss_rpn_loc: 0.2124  time: 0.5908  data_time: 0.2514  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:13:44 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 8639  total_loss: 1.358  loss_cls: 0.2887  loss_box_reg: 0.4514  loss_mask: 0.283  loss_rpn_cls: 0.05886  loss_rpn_loc: 0.19  time: 0.5909  data_time: 0.3180  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:13:55 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 8659  total_loss: 1.41  loss_cls: 0.2864  loss_box_reg: 0.5158  loss_mask: 0.3032  loss_rpn_cls: 0.08264  loss_rpn_loc: 0.1822  time: 0.5907  data_time: 0.1934  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:14:07 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 8679  total_loss: 1.349  loss_cls: 0.2989  loss_box_reg: 0.4857  loss_mask: 0.2821  loss_rpn_cls: 0.07141  loss_rpn_loc: 0.1844  time: 0.5907  data_time: 0.2705  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:14:15 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 8699  total_loss: 1.313  loss_cls: 0.2827  loss_box_reg: 0.4721  loss_mask: 0.2852  loss_rpn_cls: 0.06914  loss_rpn_loc: 0.1822  time: 0.5904  data_time: 0.1384  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:14:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:14:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:14:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:14:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:14:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:14:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0732 s/iter. Eval: 0.0441 s/iter. Total: 0.1181 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 16:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0747 s/iter. Eval: 0.0590 s/iter. Total: 0.1345 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 16:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0751 s/iter. Eval: 0.0624 s/iter. Total: 0.1383 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 16:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0748 s/iter. Eval: 0.0606 s/iter. Total: 0.1363 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/03 16:14:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.870293 (0.136813 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:14:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074793 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:14:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:14:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2668925172075349\n",
      "\u001b[32m[02/03 16:14:47 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 8719  total_loss: 1.381  loss_cls: 0.3162  loss_box_reg: 0.4871  loss_mask: 0.2938  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.1882  time: 0.5906  data_time: 0.3423  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:14:59 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 8739  total_loss: 1.274  loss_cls: 0.3258  loss_box_reg: 0.483  loss_mask: 0.2904  loss_rpn_cls: 0.04941  loss_rpn_loc: 0.1784  time: 0.5906  data_time: 0.2737  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:15:13 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 8759  total_loss: 1.379  loss_cls: 0.3166  loss_box_reg: 0.4884  loss_mask: 0.2875  loss_rpn_cls: 0.07336  loss_rpn_loc: 0.1815  time: 0.5909  data_time: 0.3601  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:15:27 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 8779  total_loss: 1.384  loss_cls: 0.3266  loss_box_reg: 0.5263  loss_mask: 0.314  loss_rpn_cls: 0.06114  loss_rpn_loc: 0.189  time: 0.5911  data_time: 0.3507  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:15:36 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 8799  total_loss: 1.374  loss_cls: 0.3212  loss_box_reg: 0.4911  loss_mask: 0.2866  loss_rpn_cls: 0.06185  loss_rpn_loc: 0.1866  time: 0.5909  data_time: 0.1677  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:15:48 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 8819  total_loss: 1.302  loss_cls: 0.2805  loss_box_reg: 0.4993  loss_mask: 0.2964  loss_rpn_cls: 0.06042  loss_rpn_loc: 0.189  time: 0.5909  data_time: 0.2737  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:16:01 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 8839  total_loss: 1.471  loss_cls: 0.3519  loss_box_reg: 0.4948  loss_mask: 0.3051  loss_rpn_cls: 0.07961  loss_rpn_loc: 0.211  time: 0.5910  data_time: 0.3094  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:16:16 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 8859  total_loss: 1.321  loss_cls: 0.2726  loss_box_reg: 0.4598  loss_mask: 0.2821  loss_rpn_cls: 0.07999  loss_rpn_loc: 0.2015  time: 0.5913  data_time: 0.3668  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:16:29 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 8879  total_loss: 1.38  loss_cls: 0.3068  loss_box_reg: 0.4875  loss_mask: 0.2978  loss_rpn_cls: 0.09604  loss_rpn_loc: 0.2047  time: 0.5915  data_time: 0.3213  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:16:37 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 8899  total_loss: 1.246  loss_cls: 0.2502  loss_box_reg: 0.5269  loss_mask: 0.2844  loss_rpn_cls: 0.05284  loss_rpn_loc: 0.1571  time: 0.5911  data_time: 0.1133  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:16:50 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 8919  total_loss: 1.319  loss_cls: 0.2698  loss_box_reg: 0.4689  loss_mask: 0.2918  loss_rpn_cls: 0.07459  loss_rpn_loc: 0.1853  time: 0.5911  data_time: 0.2874  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:17:05 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 8939  total_loss: 1.428  loss_cls: 0.3225  loss_box_reg: 0.51  loss_mask: 0.3195  loss_rpn_cls: 0.07115  loss_rpn_loc: 0.2007  time: 0.5916  data_time: 0.4561  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:17:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:17:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:17:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:17:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:17:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:17:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:17:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0499 s/iter. Total: 0.1257 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 16:17:21 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0751 s/iter. Eval: 0.0617 s/iter. Total: 0.1376 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 16:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0752 s/iter. Eval: 0.0635 s/iter. Total: 0.1395 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 16:17:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.927036 (0.137302 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:17:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074953 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:17:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:17:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2662638190179695\n",
      "\u001b[32m[02/03 16:17:33 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 8959  total_loss: 1.35  loss_cls: 0.2922  loss_box_reg: 0.4974  loss_mask: 0.2971  loss_rpn_cls: 0.07103  loss_rpn_loc: 0.185  time: 0.5914  data_time: 0.1944  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:17:45 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 8979  total_loss: 1.352  loss_cls: 0.3037  loss_box_reg: 0.5042  loss_mask: 0.2882  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.185  time: 0.5914  data_time: 0.2537  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:17:56 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 8999  total_loss: 1.305  loss_cls: 0.3061  loss_box_reg: 0.4852  loss_mask: 0.2771  loss_rpn_cls: 0.05761  loss_rpn_loc: 0.1886  time: 0.5913  data_time: 0.2410  lr: 0.00010486  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:18:09 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 9019  total_loss: 1.263  loss_cls: 0.2713  loss_box_reg: 0.455  loss_mask: 0.2953  loss_rpn_cls: 0.05074  loss_rpn_loc: 0.1726  time: 0.5915  data_time: 0.3166  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:18:23 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 9039  total_loss: 1.407  loss_cls: 0.3578  loss_box_reg: 0.5005  loss_mask: 0.3077  loss_rpn_cls: 0.08296  loss_rpn_loc: 0.1824  time: 0.5917  data_time: 0.3551  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:18:37 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 9059  total_loss: 1.387  loss_cls: 0.3146  loss_box_reg: 0.4988  loss_mask: 0.2938  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.1838  time: 0.5919  data_time: 0.3661  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:18:48 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 9079  total_loss: 1.385  loss_cls: 0.2849  loss_box_reg: 0.492  loss_mask: 0.3032  loss_rpn_cls: 0.07894  loss_rpn_loc: 0.1738  time: 0.5918  data_time: 0.1886  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:19:01 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 9099  total_loss: 1.326  loss_cls: 0.3245  loss_box_reg: 0.4902  loss_mask: 0.2839  loss_rpn_cls: 0.07102  loss_rpn_loc: 0.1743  time: 0.5919  data_time: 0.3286  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:19:11 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 9119  total_loss: 1.386  loss_cls: 0.3083  loss_box_reg: 0.5148  loss_mask: 0.292  loss_rpn_cls: 0.07393  loss_rpn_loc: 0.1929  time: 0.5918  data_time: 0.1968  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:19:21 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 9139  total_loss: 1.408  loss_cls: 0.3427  loss_box_reg: 0.5034  loss_mask: 0.305  loss_rpn_cls: 0.06921  loss_rpn_loc: 0.1859  time: 0.5916  data_time: 0.1749  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:19:33 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 9159  total_loss: 1.322  loss_cls: 0.2714  loss_box_reg: 0.5086  loss_mask: 0.3018  loss_rpn_cls: 0.05614  loss_rpn_loc: 0.1929  time: 0.5916  data_time: 0.2537  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:19:41 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 9179  total_loss: 1.392  loss_cls: 0.3082  loss_box_reg: 0.4979  loss_mask: 0.2865  loss_rpn_cls: 0.05923  loss_rpn_loc: 0.1707  time: 0.5912  data_time: 0.0896  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:19:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:19:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:19:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:19:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:19:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:19:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0753 s/iter. Eval: 0.0529 s/iter. Total: 0.1289 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/03 16:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0618 s/iter. Total: 0.1376 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 16:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0753 s/iter. Eval: 0.0639 s/iter. Total: 0.1401 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 16:20:08 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0615 s/iter. Total: 0.1373 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/03 16:20:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.042971 (0.138301 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:20:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075000 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:20:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:20:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26747378415467177\n",
      "\u001b[32m[02/03 16:20:10 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 9199  total_loss: 1.392  loss_cls: 0.2652  loss_box_reg: 0.5  loss_mask: 0.2946  loss_rpn_cls: 0.06108  loss_rpn_loc: 0.1939  time: 0.5910  data_time: 0.2115  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:20:23 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 9219  total_loss: 1.447  loss_cls: 0.3759  loss_box_reg: 0.4723  loss_mask: 0.3014  loss_rpn_cls: 0.08162  loss_rpn_loc: 0.18  time: 0.5912  data_time: 0.3443  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:20:32 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 9239  total_loss: 1.29  loss_cls: 0.309  loss_box_reg: 0.4965  loss_mask: 0.2829  loss_rpn_cls: 0.05584  loss_rpn_loc: 0.1692  time: 0.5909  data_time: 0.1446  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:20:43 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 9259  total_loss: 1.436  loss_cls: 0.3159  loss_box_reg: 0.4938  loss_mask: 0.3004  loss_rpn_cls: 0.07139  loss_rpn_loc: 0.2005  time: 0.5909  data_time: 0.2593  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:20:56 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 9279  total_loss: 1.287  loss_cls: 0.3354  loss_box_reg: 0.4715  loss_mask: 0.2927  loss_rpn_cls: 0.07495  loss_rpn_loc: 0.1755  time: 0.5910  data_time: 0.2968  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:21:09 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 9299  total_loss: 1.331  loss_cls: 0.2876  loss_box_reg: 0.4818  loss_mask: 0.2892  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.1942  time: 0.5911  data_time: 0.3434  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:21:22 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 9319  total_loss: 1.357  loss_cls: 0.3223  loss_box_reg: 0.4733  loss_mask: 0.2917  loss_rpn_cls: 0.07889  loss_rpn_loc: 0.1964  time: 0.5912  data_time: 0.3146  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:21:32 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 9339  total_loss: 1.29  loss_cls: 0.2693  loss_box_reg: 0.4567  loss_mask: 0.2757  loss_rpn_cls: 0.05119  loss_rpn_loc: 0.1689  time: 0.5910  data_time: 0.1722  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:21:47 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 9359  total_loss: 1.412  loss_cls: 0.3043  loss_box_reg: 0.5035  loss_mask: 0.3158  loss_rpn_cls: 0.08201  loss_rpn_loc: 0.1965  time: 0.5914  data_time: 0.4144  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:22:01 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 9379  total_loss: 1.419  loss_cls: 0.3089  loss_box_reg: 0.4726  loss_mask: 0.3154  loss_rpn_cls: 0.07015  loss_rpn_loc: 0.1885  time: 0.5915  data_time: 0.3371  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:22:13 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 9399  total_loss: 1.349  loss_cls: 0.3047  loss_box_reg: 0.4981  loss_mask: 0.303  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1864  time: 0.5916  data_time: 0.2872  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:22:24 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 9419  total_loss: 1.356  loss_cls: 0.3043  loss_box_reg: 0.4903  loss_mask: 0.2813  loss_rpn_cls: 0.0616  loss_rpn_loc: 0.2005  time: 0.5915  data_time: 0.2670  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:22:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:22:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:22:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:22:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:22:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:22:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:22:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0696 s/iter. Eval: 0.0498 s/iter. Total: 0.1202 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 16:22:42 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0710 s/iter. Eval: 0.0599 s/iter. Total: 0.1317 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 16:22:47 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0712 s/iter. Eval: 0.0618 s/iter. Total: 0.1339 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 16:22:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.325888 (0.132120 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:22:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071084 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:22:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:22:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2650746441599783\n",
      "\u001b[32m[02/03 16:22:52 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9439  total_loss: 1.372  loss_cls: 0.3225  loss_box_reg: 0.4678  loss_mask: 0.2891  loss_rpn_cls: 0.07274  loss_rpn_loc: 0.1758  time: 0.5914  data_time: 0.2300  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:23:02 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9459  total_loss: 1.366  loss_cls: 0.3177  loss_box_reg: 0.4975  loss_mask: 0.2854  loss_rpn_cls: 0.07311  loss_rpn_loc: 0.1842  time: 0.5912  data_time: 0.1852  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:23:15 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 9479  total_loss: 1.361  loss_cls: 0.3175  loss_box_reg: 0.483  loss_mask: 0.2931  loss_rpn_cls: 0.07944  loss_rpn_loc: 0.1909  time: 0.5913  data_time: 0.3097  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:23:27 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 9499  total_loss: 1.301  loss_cls: 0.2455  loss_box_reg: 0.4762  loss_mask: 0.2913  loss_rpn_cls: 0.06125  loss_rpn_loc: 0.1725  time: 0.5914  data_time: 0.2907  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:23:42 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 9519  total_loss: 1.297  loss_cls: 0.3139  loss_box_reg: 0.4804  loss_mask: 0.2809  loss_rpn_cls: 0.07738  loss_rpn_loc: 0.1821  time: 0.5916  data_time: 0.3965  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:23:52 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 9539  total_loss: 1.347  loss_cls: 0.304  loss_box_reg: 0.4966  loss_mask: 0.293  loss_rpn_cls: 0.07617  loss_rpn_loc: 0.1789  time: 0.5915  data_time: 0.2213  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:24:08 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 9559  total_loss: 1.431  loss_cls: 0.3299  loss_box_reg: 0.4814  loss_mask: 0.3142  loss_rpn_cls: 0.08992  loss_rpn_loc: 0.1888  time: 0.5920  data_time: 0.4758  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:24:18 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 9579  total_loss: 1.369  loss_cls: 0.3039  loss_box_reg: 0.5216  loss_mask: 0.2936  loss_rpn_cls: 0.07615  loss_rpn_loc: 0.1781  time: 0.5917  data_time: 0.1564  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:24:27 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 9599  total_loss: 1.337  loss_cls: 0.3046  loss_box_reg: 0.4927  loss_mask: 0.2823  loss_rpn_cls: 0.0621  loss_rpn_loc: 0.1772  time: 0.5915  data_time: 0.1884  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:24:40 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 9619  total_loss: 1.392  loss_cls: 0.349  loss_box_reg: 0.486  loss_mask: 0.3034  loss_rpn_cls: 0.08785  loss_rpn_loc: 0.1982  time: 0.5916  data_time: 0.3241  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:24:52 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 9639  total_loss: 1.372  loss_cls: 0.3186  loss_box_reg: 0.4958  loss_mask: 0.2909  loss_rpn_cls: 0.083  loss_rpn_loc: 0.2023  time: 0.5915  data_time: 0.2680  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:25:03 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9659  total_loss: 1.312  loss_cls: 0.2915  loss_box_reg: 0.4744  loss_mask: 0.2853  loss_rpn_cls: 0.06404  loss_rpn_loc: 0.1648  time: 0.5915  data_time: 0.2727  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:25:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:25:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:25:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:25:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:25:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:25:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0696 s/iter. Eval: 0.0458 s/iter. Total: 0.1163 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 16:25:23 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0708 s/iter. Eval: 0.0569 s/iter. Total: 0.1285 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 16:25:28 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0608 s/iter. Total: 0.1335 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 16:25:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.426768 (0.132989 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:25:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072562 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:25:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:25:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2656216319256656\n",
      "\u001b[32m[02/03 16:25:32 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 9679  total_loss: 1.362  loss_cls: 0.3164  loss_box_reg: 0.4668  loss_mask: 0.2928  loss_rpn_cls: 0.06998  loss_rpn_loc: 0.1894  time: 0.5915  data_time: 0.2689  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:25:44 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 9699  total_loss: 1.355  loss_cls: 0.3058  loss_box_reg: 0.4798  loss_mask: 0.3063  loss_rpn_cls: 0.07512  loss_rpn_loc: 0.1913  time: 0.5916  data_time: 0.2781  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:25:55 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 9719  total_loss: 1.372  loss_cls: 0.3288  loss_box_reg: 0.4914  loss_mask: 0.3072  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.1901  time: 0.5914  data_time: 0.2164  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:26:06 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 9739  total_loss: 1.394  loss_cls: 0.2955  loss_box_reg: 0.5584  loss_mask: 0.3182  loss_rpn_cls: 0.06786  loss_rpn_loc: 0.1926  time: 0.5913  data_time: 0.2104  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:26:17 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 9759  total_loss: 1.423  loss_cls: 0.3366  loss_box_reg: 0.5034  loss_mask: 0.2911  loss_rpn_cls: 0.05835  loss_rpn_loc: 0.2044  time: 0.5912  data_time: 0.2249  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:26:27 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 9779  total_loss: 1.239  loss_cls: 0.2795  loss_box_reg: 0.4995  loss_mask: 0.2973  loss_rpn_cls: 0.07394  loss_rpn_loc: 0.1701  time: 0.5910  data_time: 0.1757  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:26:37 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 9799  total_loss: 1.319  loss_cls: 0.3096  loss_box_reg: 0.4629  loss_mask: 0.2853  loss_rpn_cls: 0.06572  loss_rpn_loc: 0.1735  time: 0.5909  data_time: 0.2147  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:26:53 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 9819  total_loss: 1.473  loss_cls: 0.3279  loss_box_reg: 0.5026  loss_mask: 0.3091  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.2246  time: 0.5913  data_time: 0.4474  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:27:06 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 9839  total_loss: 1.422  loss_cls: 0.3503  loss_box_reg: 0.4924  loss_mask: 0.2909  loss_rpn_cls: 0.08406  loss_rpn_loc: 0.1932  time: 0.5914  data_time: 0.3397  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:27:17 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 9859  total_loss: 1.33  loss_cls: 0.3072  loss_box_reg: 0.4835  loss_mask: 0.27  loss_rpn_cls: 0.07168  loss_rpn_loc: 0.1859  time: 0.5914  data_time: 0.2349  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:27:29 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 9879  total_loss: 1.264  loss_cls: 0.2663  loss_box_reg: 0.4827  loss_mask: 0.2845  loss_rpn_cls: 0.05518  loss_rpn_loc: 0.1794  time: 0.5914  data_time: 0.2573  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:27:40 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 9899  total_loss: 1.357  loss_cls: 0.2854  loss_box_reg: 0.5101  loss_mask: 0.2996  loss_rpn_cls: 0.06423  loss_rpn_loc: 0.1722  time: 0.5913  data_time: 0.2533  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:27:51 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 9919  total_loss: 1.316  loss_cls: 0.2953  loss_box_reg: 0.4715  loss_mask: 0.279  loss_rpn_cls: 0.06594  loss_rpn_loc: 0.1632  time: 0.5912  data_time: 0.2403  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:27:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:27:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:27:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:27:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:27:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:27:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:27:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0030 s/iter. Inference: 0.0699 s/iter. Eval: 0.0513 s/iter. Total: 0.1242 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 16:28:00 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0011 s/iter. Inference: 0.0723 s/iter. Eval: 0.0610 s/iter. Total: 0.1345 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 16:28:05 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0010 s/iter. Inference: 0.0730 s/iter. Eval: 0.0629 s/iter. Total: 0.1369 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 16:28:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.685464 (0.135220 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:28:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072642 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:28:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:28:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2687301286944816\n",
      "\u001b[32m[02/03 16:28:25 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 9939  total_loss: 1.361  loss_cls: 0.305  loss_box_reg: 0.4809  loss_mask: 0.2951  loss_rpn_cls: 0.07562  loss_rpn_loc: 0.1879  time: 0.5917  data_time: 0.4464  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:28:39 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 9959  total_loss: 1.353  loss_cls: 0.3201  loss_box_reg: 0.5025  loss_mask: 0.3038  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.1906  time: 0.5918  data_time: 0.3325  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:28:50 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 9979  total_loss: 1.491  loss_cls: 0.3293  loss_box_reg: 0.5235  loss_mask: 0.3019  loss_rpn_cls: 0.08994  loss_rpn_loc: 0.2111  time: 0.5918  data_time: 0.2316  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:29:02 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.339  loss_cls: 0.321  loss_box_reg: 0.4875  loss_mask: 0.2877  loss_rpn_cls: 0.06839  loss_rpn_loc: 0.1994  time: 0.5918  data_time: 0.2733  lr: 8.3886e-05  max_mem: 8200M\n",
      "\u001b[32m[02/03 16:29:02 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:38:37 (0.5918 s / it)\n",
      "\u001b[32m[02/03 16:29:02 d2.engine.hooks]: \u001b[0mTotal training time: 1:50:01 (0:11:24 on hooks)\n",
      "\u001b[32m[02/03 16:29:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:29:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:29:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:29:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:29:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:29:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0754 s/iter. Eval: 0.0558 s/iter. Total: 0.1322 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/03 16:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.0773 s/iter. Eval: 0.0696 s/iter. Total: 0.1479 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 16:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.0774 s/iter. Eval: 0.0698 s/iter. Total: 0.1481 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/03 16:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0770 s/iter. Eval: 0.0671 s/iter. Total: 0.1450 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/03 16:29:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.903675 (0.145721 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:29:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077013 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:29:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:29:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2679478374697448\n"
     ]
    }
   ],
   "source": [
    "# learning rate = 0.0005 with gamma=0.8 and lr reduction every 1000 iterations starting from iteration 2000\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_8.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee646177-610b-41ae-9054-1a044f112230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  1\n",
      "mAP : 0.26041674840123386\n",
      "False negatives : 0.1091769381932369\n",
      "False positives : 0.15870824222011362\n",
      "Experiment  2\n",
      "mAP : 0.26435589723958464\n",
      "False negatives : 0.11097223966023297\n",
      "False positives : 0.15866990742949222\n",
      "Experiment  3\n",
      "mAP : 0.26081937610254613\n",
      "False negatives : 0.11307294932245454\n",
      "False positives : 0.1617883726075458\n",
      "Experiment  4\n",
      "mAP : 0.2636338649191153\n",
      "False negatives : 0.10976414966407033\n",
      "False positives : 0.1585849269005686\n",
      "Experiment  5\n",
      "mAP : 0.2668117103727\n",
      "False negatives : 0.10974907050829233\n",
      "False positives : 0.1589980911079324\n",
      "Experiment  6\n",
      "mAP : 0.26120385696089043\n",
      "False negatives : 0.11449647063904518\n",
      "False positives : 0.16376188109298417\n",
      "Experiment  7\n",
      "mAP : 0.2668593156088135\n",
      "False negatives : 0.11234782869593239\n",
      "False positives : 0.16108722956894572\n",
      "Experiment  8\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def print_metrics(output):\n",
    "    with open(f\"output_{output}/metrics.json\",'r') as f:\n",
    "        metrics = [json.loads(line) for line in f]\n",
    "    print(\"mAP :\", np.mean([metrics[i][\"mAP IoU\"] for i in range(len(metrics)) if 'mAP IoU' in metrics[i]][-10:])) # Average mAP in the last 10 epochs\n",
    "    print(\"False negatives :\", np.mean([metrics[i][\"mask_rcnn/false_negative\"] for i in range(len(metrics)) if 'mask_rcnn/false_negative' in metrics[i]][-100:]))\n",
    "    print(\"False positives :\", np.mean([metrics[i][\"mask_rcnn/false_positive\"] for i in range(len(metrics)) if 'mask_rcnn/false_positive' in metrics[i]][-100:]))\n",
    "i=1\n",
    "while True:\n",
    "    try:\n",
    "        print(\"Experiment \",i)\n",
    "        print_metrics(\"8.\"+str(i))\n",
    "        i+=1\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89eedac0-1c54-43e2-9295-d2609249749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9d55a2-3e5f-4165-a951-b75e2246725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6de93820e04ee610\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6de93820e04ee610\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a594cfb-7f0d-45c2-b9fd-fb93dc4da478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fe1a9ae4089e278c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fe1a9ae4089e278c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdccb80-cfda-4fd3-bb5c-d4126145c0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9989862dce779e08\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9989862dce779e08\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a353893a-f055-4a1c-8b1f-2aac94786a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3fd958b6c0276fb4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3fd958b6c0276fb4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6012;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe590b68-d2b2-449e-8912-fc1528564547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7f6d770316df5a73\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7f6d770316df5a73\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c0085b-0ef7-4873-bfcb-ff37a923c544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d0c1e973919957f7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d0c1e973919957f7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6011;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_8.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a751fad-f76b-48b4-9f90-85753414672b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3dc0612a1dc10466\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3dc0612a1dc10466\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_8.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
