{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d67fe08-e488-417d-84f0-deba44591870",
   "metadata": {},
   "source": [
    "### Notebook 5: No pretraining on LIVECell (transfer learning experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c366087-a5de-4cae-a5c8-c5d0aaba1c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b511db5-1fc3-4dcd-970f-2744e2a9aa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/10 15:23:30 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n"
     ]
    }
   ],
   "source": [
    "dataDir=Path('../')\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "register_coco_instances('sartorius_train',{}, '../sartorius-annotations-coco-format/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_val',{},'../sartorius-annotations-coco-format/annotations_val.json', dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2214b1-93f0-4af7-beae-1d5b30131b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1\n",
    "    false_positives = np.sum(matches, axis=0) == 0\n",
    "    false_negatives = np.sum(matches, axis=1) == 0\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"MaP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1eb2f4d-a035-4003-a602-a2933f1aaaa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/10 15:24:00 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/10 15:24:01 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/10 15:24:03 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/10 15:24:04 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/10 15:24:05 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[01/10 15:24:05 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/10 15:24:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/10 15:24:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/10 15:24:05 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:24:05 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/10 15:24:05 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/10 15:24:19 d2.utils.events]: \u001b[0m eta: 1:13:30  iter: 19  total_loss: 6.204  loss_cls: 1.255  loss_box_reg: 0.3608  loss_mask: 0.6915  loss_rpn_cls: 3.503  loss_rpn_loc: 0.3257  time: 0.7184  data_time: 0.3434  lr: 9.9905e-06  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:24:33 d2.utils.events]: \u001b[0m eta: 1:00:30  iter: 39  total_loss: 3.259  loss_cls: 1.172  loss_box_reg: 0.3538  loss_mask: 0.6896  loss_rpn_cls: 0.6401  loss_rpn_loc: 0.3474  time: 0.7010  data_time: 0.3649  lr: 1.998e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:24:44 d2.utils.events]: \u001b[0m eta: 0:58:34  iter: 59  total_loss: 2.711  loss_cls: 0.9616  loss_box_reg: 0.3962  loss_mask: 0.6838  loss_rpn_cls: 0.3463  loss_rpn_loc: 0.2898  time: 0.6559  data_time: 0.2492  lr: 2.997e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:24:55 d2.utils.events]: \u001b[0m eta: 0:58:01  iter: 79  total_loss: 2.545  loss_cls: 0.8139  loss_box_reg: 0.4267  loss_mask: 0.6762  loss_rpn_cls: 0.3147  loss_rpn_loc: 0.3112  time: 0.6217  data_time: 0.1932  lr: 3.9961e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:25:06 d2.utils.events]: \u001b[0m eta: 0:57:25  iter: 99  total_loss: 2.557  loss_cls: 0.7883  loss_box_reg: 0.5399  loss_mask: 0.6633  loss_rpn_cls: 0.2891  loss_rpn_loc: 0.2845  time: 0.6101  data_time: 0.2475  lr: 4.9951e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:25:17 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 119  total_loss: 2.584  loss_cls: 0.7839  loss_box_reg: 0.5822  loss_mask: 0.653  loss_rpn_cls: 0.2696  loss_rpn_loc: 0.3129  time: 0.6003  data_time: 0.2286  lr: 5.9941e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:25:30 d2.utils.events]: \u001b[0m eta: 0:57:11  iter: 139  total_loss: 2.537  loss_cls: 0.7748  loss_box_reg: 0.5854  loss_mask: 0.6426  loss_rpn_cls: 0.2543  loss_rpn_loc: 0.2895  time: 0.6101  data_time: 0.3437  lr: 6.993e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:25:41 d2.utils.events]: \u001b[0m eta: 0:55:56  iter: 159  total_loss: 2.54  loss_cls: 0.7607  loss_box_reg: 0.6836  loss_mask: 0.615  loss_rpn_cls: 0.2345  loss_rpn_loc: 0.2695  time: 0.5990  data_time: 0.2206  lr: 7.9921e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:25:50 d2.utils.events]: \u001b[0m eta: 0:55:45  iter: 179  total_loss: 2.495  loss_cls: 0.7523  loss_box_reg: 0.6968  loss_mask: 0.5887  loss_rpn_cls: 0.1854  loss_rpn_loc: 0.2632  time: 0.5843  data_time: 0.1537  lr: 8.991e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:26:01 d2.utils.events]: \u001b[0m eta: 0:55:24  iter: 199  total_loss: 2.484  loss_cls: 0.7632  loss_box_reg: 0.6529  loss_mask: 0.5816  loss_rpn_cls: 0.2342  loss_rpn_loc: 0.278  time: 0.5817  data_time: 0.2400  lr: 9.9901e-05  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:26:10 d2.utils.events]: \u001b[0m eta: 0:54:52  iter: 219  total_loss: 2.334  loss_cls: 0.7109  loss_box_reg: 0.6295  loss_mask: 0.541  loss_rpn_cls: 0.2107  loss_rpn_loc: 0.2596  time: 0.5698  data_time: 0.1401  lr: 0.00010989  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:26:23 d2.utils.events]: \u001b[0m eta: 0:54:59  iter: 239  total_loss: 2.297  loss_cls: 0.7136  loss_box_reg: 0.6288  loss_mask: 0.5448  loss_rpn_cls: 0.1868  loss_rpn_loc: 0.2727  time: 0.5751  data_time: 0.3032  lr: 0.00011988  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:26:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:26:25 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/10 15:26:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:26:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:26:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:26:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:26:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0637 s/iter. Eval: 0.0000 s/iter. Total: 0.0643 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/10 15:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0006 s/iter. Inference: 0.0638 s/iter. Eval: 0.0000 s/iter. Total: 0.0645 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/10 15:26:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.537270 (0.064976 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:26:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.063734 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:26:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:26:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=6.524575902566333e-05\n",
      "\u001b[32m[01/10 15:26:42 d2.utils.events]: \u001b[0m eta: 0:55:17  iter: 259  total_loss: 2.284  loss_cls: 0.6898  loss_box_reg: 0.6524  loss_mask: 0.4905  loss_rpn_cls: 0.1654  loss_rpn_loc: 0.2674  time: 0.5693  data_time: 0.1720  lr: 0.00012987  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:26:50 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 279  total_loss: 2.311  loss_cls: 0.6895  loss_box_reg: 0.7454  loss_mask: 0.4504  loss_rpn_cls: 0.1593  loss_rpn_loc: 0.2493  time: 0.5596  data_time: 0.1279  lr: 0.00013986  max_mem: 5148M\n",
      "\u001b[32m[01/10 15:27:03 d2.utils.events]: \u001b[0m eta: 0:54:57  iter: 299  total_loss: 2.18  loss_cls: 0.6926  loss_box_reg: 0.6567  loss_mask: 0.4345  loss_rpn_cls: 0.1708  loss_rpn_loc: 0.2488  time: 0.5657  data_time: 0.3049  lr: 0.00014985  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:27:16 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 319  total_loss: 2.137  loss_cls: 0.6715  loss_box_reg: 0.6828  loss_mask: 0.4212  loss_rpn_cls: 0.1713  loss_rpn_loc: 0.2458  time: 0.5702  data_time: 0.3051  lr: 0.00015984  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:27:27 d2.utils.events]: \u001b[0m eta: 0:54:25  iter: 339  total_loss: 2.059  loss_cls: 0.5943  loss_box_reg: 0.6819  loss_mask: 0.3999  loss_rpn_cls: 0.1707  loss_rpn_loc: 0.2456  time: 0.5694  data_time: 0.2318  lr: 0.00016983  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:27:37 d2.utils.events]: \u001b[0m eta: 0:54:11  iter: 359  total_loss: 2.016  loss_cls: 0.5438  loss_box_reg: 0.658  loss_mask: 0.4035  loss_rpn_cls: 0.1555  loss_rpn_loc: 0.2634  time: 0.5639  data_time: 0.1606  lr: 0.00017982  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:27:50 d2.utils.events]: \u001b[0m eta: 0:54:14  iter: 379  total_loss: 2.13  loss_cls: 0.6317  loss_box_reg: 0.5706  loss_mask: 0.4078  loss_rpn_cls: 0.1957  loss_rpn_loc: 0.2615  time: 0.5695  data_time: 0.3291  lr: 0.00018981  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:28:03 d2.utils.events]: \u001b[0m eta: 0:54:26  iter: 399  total_loss: 1.896  loss_cls: 0.5306  loss_box_reg: 0.6362  loss_mask: 0.3876  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.238  time: 0.5721  data_time: 0.2854  lr: 0.0001998  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:28:15 d2.utils.events]: \u001b[0m eta: 0:54:17  iter: 419  total_loss: 2.052  loss_cls: 0.5677  loss_box_reg: 0.6551  loss_mask: 0.3905  loss_rpn_cls: 0.1771  loss_rpn_loc: 0.2787  time: 0.5739  data_time: 0.2922  lr: 0.00020979  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:28:28 d2.utils.events]: \u001b[0m eta: 0:54:13  iter: 439  total_loss: 1.955  loss_cls: 0.5401  loss_box_reg: 0.5874  loss_mask: 0.3719  loss_rpn_cls: 0.1679  loss_rpn_loc: 0.2612  time: 0.5778  data_time: 0.3358  lr: 0.00021978  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:28:39 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 459  total_loss: 1.844  loss_cls: 0.4634  loss_box_reg: 0.6297  loss_mask: 0.3747  loss_rpn_cls: 0.1211  loss_rpn_loc: 0.2486  time: 0.5768  data_time: 0.2468  lr: 0.00022977  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:28:51 d2.utils.events]: \u001b[0m eta: 0:53:58  iter: 479  total_loss: 2.016  loss_cls: 0.5451  loss_box_reg: 0.6135  loss_mask: 0.3831  loss_rpn_cls: 0.1682  loss_rpn_loc: 0.2574  time: 0.5771  data_time: 0.2664  lr: 0.00023976  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:28:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:28:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:28:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:28:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:28:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:28:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:28:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0682 s/iter. Eval: 0.0066 s/iter. Total: 0.0754 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 15:28:59 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.0104 s/iter. Total: 0.0810 s/iter. ETA=0:00:03\n",
      "\u001b[32m[01/10 15:29:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.474927 (0.081680 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:29:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069811 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:29:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:29:03 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.17892839102652747\n",
      "\u001b[32m[01/10 15:29:11 d2.utils.events]: \u001b[0m eta: 0:53:42  iter: 499  total_loss: 1.779  loss_cls: 0.465  loss_box_reg: 0.6143  loss_mask: 0.3529  loss_rpn_cls: 0.1396  loss_rpn_loc: 0.2484  time: 0.5735  data_time: 0.1750  lr: 0.00024975  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:29:20 d2.utils.events]: \u001b[0m eta: 0:53:29  iter: 519  total_loss: 1.857  loss_cls: 0.4575  loss_box_reg: 0.6473  loss_mask: 0.3728  loss_rpn_cls: 0.1418  loss_rpn_loc: 0.2528  time: 0.5691  data_time: 0.1529  lr: 0.00025974  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:29:31 d2.utils.events]: \u001b[0m eta: 0:53:18  iter: 539  total_loss: 1.735  loss_cls: 0.4633  loss_box_reg: 0.6193  loss_mask: 0.3426  loss_rpn_cls: 0.09369  loss_rpn_loc: 0.2196  time: 0.5671  data_time: 0.2029  lr: 0.00026973  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:29:39 d2.utils.events]: \u001b[0m eta: 0:52:59  iter: 559  total_loss: 1.839  loss_cls: 0.4993  loss_box_reg: 0.6234  loss_mask: 0.3424  loss_rpn_cls: 0.1229  loss_rpn_loc: 0.2342  time: 0.5624  data_time: 0.1284  lr: 0.00027972  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:29:50 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 579  total_loss: 1.76  loss_cls: 0.452  loss_box_reg: 0.6079  loss_mask: 0.3619  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.2412  time: 0.5604  data_time: 0.1900  lr: 0.00028971  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:30:00 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 599  total_loss: 1.77  loss_cls: 0.4621  loss_box_reg: 0.6183  loss_mask: 0.3501  loss_rpn_cls: 0.1301  loss_rpn_loc: 0.2269  time: 0.5597  data_time: 0.2240  lr: 0.0002997  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:30:13 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 619  total_loss: 1.72  loss_cls: 0.4355  loss_box_reg: 0.5705  loss_mask: 0.3477  loss_rpn_cls: 0.1432  loss_rpn_loc: 0.2516  time: 0.5622  data_time: 0.3228  lr: 0.00030969  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:30:26 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 639  total_loss: 1.811  loss_cls: 0.4687  loss_box_reg: 0.5653  loss_mask: 0.3526  loss_rpn_cls: 0.1853  loss_rpn_loc: 0.2457  time: 0.5650  data_time: 0.3243  lr: 0.00031968  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:30:35 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 659  total_loss: 1.666  loss_cls: 0.3717  loss_box_reg: 0.5652  loss_mask: 0.3422  loss_rpn_cls: 0.1305  loss_rpn_loc: 0.2083  time: 0.5616  data_time: 0.1442  lr: 0.00032967  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:30:49 d2.utils.events]: \u001b[0m eta: 0:52:12  iter: 679  total_loss: 1.747  loss_cls: 0.4414  loss_box_reg: 0.5578  loss_mask: 0.3309  loss_rpn_cls: 0.1466  loss_rpn_loc: 0.2535  time: 0.5649  data_time: 0.3542  lr: 0.00033966  max_mem: 5903M\n",
      "\u001b[32m[01/10 15:31:05 d2.utils.events]: \u001b[0m eta: 0:52:11  iter: 699  total_loss: 1.708  loss_cls: 0.4134  loss_box_reg: 0.5683  loss_mask: 0.362  loss_rpn_cls: 0.1427  loss_rpn_loc: 0.2324  time: 0.5723  data_time: 0.4760  lr: 0.00034965  max_mem: 6106M\n",
      "\u001b[32m[01/10 15:31:18 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 719  total_loss: 1.766  loss_cls: 0.4435  loss_box_reg: 0.5727  loss_mask: 0.355  loss_rpn_cls: 0.1402  loss_rpn_loc: 0.2462  time: 0.5749  data_time: 0.3408  lr: 0.00035964  max_mem: 6106M\n",
      "\u001b[32m[01/10 15:31:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:31:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:31:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:31:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:31:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:31:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:31:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0689 s/iter. Eval: 0.0087 s/iter. Total: 0.0782 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 15:31:29 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.0102 s/iter. Total: 0.0809 s/iter. ETA=0:00:03\n",
      "\u001b[32m[01/10 15:31:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.391706 (0.080963 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:31:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.069699 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:31:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:31:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.18245389853936073\n",
      "\u001b[32m[01/10 15:31:40 d2.utils.events]: \u001b[0m eta: 0:51:59  iter: 739  total_loss: 1.773  loss_cls: 0.4868  loss_box_reg: 0.602  loss_mask: 0.326  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.234  time: 0.5740  data_time: 0.2237  lr: 0.00036963  max_mem: 6106M\n",
      "\u001b[32m[01/10 15:31:53 d2.utils.events]: \u001b[0m eta: 0:51:52  iter: 759  total_loss: 1.705  loss_cls: 0.4345  loss_box_reg: 0.5741  loss_mask: 0.3529  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.2284  time: 0.5762  data_time: 0.3297  lr: 0.00037962  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:32:04 d2.utils.events]: \u001b[0m eta: 0:51:44  iter: 779  total_loss: 1.608  loss_cls: 0.3767  loss_box_reg: 0.564  loss_mask: 0.3237  loss_rpn_cls: 0.1299  loss_rpn_loc: 0.2131  time: 0.5757  data_time: 0.2429  lr: 0.00038961  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:32:18 d2.utils.events]: \u001b[0m eta: 0:51:39  iter: 799  total_loss: 1.794  loss_cls: 0.4595  loss_box_reg: 0.578  loss_mask: 0.3455  loss_rpn_cls: 0.1532  loss_rpn_loc: 0.251  time: 0.5790  data_time: 0.3830  lr: 0.0003996  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:32:30 d2.utils.events]: \u001b[0m eta: 0:51:35  iter: 819  total_loss: 1.824  loss_cls: 0.4967  loss_box_reg: 0.5962  loss_mask: 0.3592  loss_rpn_cls: 0.1455  loss_rpn_loc: 0.2581  time: 0.5791  data_time: 0.2587  lr: 0.00040959  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:32:40 d2.utils.events]: \u001b[0m eta: 0:51:25  iter: 839  total_loss: 1.579  loss_cls: 0.3578  loss_box_reg: 0.5678  loss_mask: 0.3315  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.2375  time: 0.5776  data_time: 0.2104  lr: 0.00041958  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:32:52 d2.utils.events]: \u001b[0m eta: 0:51:17  iter: 859  total_loss: 1.689  loss_cls: 0.434  loss_box_reg: 0.5717  loss_mask: 0.3334  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.2082  time: 0.5779  data_time: 0.2756  lr: 0.00042957  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:33:02 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 879  total_loss: 1.686  loss_cls: 0.3927  loss_box_reg: 0.5881  loss_mask: 0.3414  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.2213  time: 0.5759  data_time: 0.1748  lr: 0.00043956  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:33:14 d2.utils.events]: \u001b[0m eta: 0:51:04  iter: 899  total_loss: 1.684  loss_cls: 0.4222  loss_box_reg: 0.5897  loss_mask: 0.3176  loss_rpn_cls: 0.1445  loss_rpn_loc: 0.2506  time: 0.5762  data_time: 0.2647  lr: 0.00044955  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:33:27 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 919  total_loss: 1.766  loss_cls: 0.4558  loss_box_reg: 0.5507  loss_mask: 0.3418  loss_rpn_cls: 0.1431  loss_rpn_loc: 0.2525  time: 0.5785  data_time: 0.3548  lr: 0.00045954  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:33:39 d2.utils.events]: \u001b[0m eta: 0:50:52  iter: 939  total_loss: 1.72  loss_cls: 0.4037  loss_box_reg: 0.5675  loss_mask: 0.3458  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.2292  time: 0.5782  data_time: 0.2467  lr: 0.00046953  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:33:51 d2.utils.events]: \u001b[0m eta: 0:50:47  iter: 959  total_loss: 1.726  loss_cls: 0.436  loss_box_reg: 0.5951  loss_mask: 0.3457  loss_rpn_cls: 0.1224  loss_rpn_loc: 0.2429  time: 0.5794  data_time: 0.3155  lr: 0.00047952  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:33:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:33:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:33:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:33:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:33:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:33:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:33:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0005 s/iter. Inference: 0.0698 s/iter. Eval: 0.0093 s/iter. Total: 0.0797 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 15:34:02 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0722 s/iter. Eval: 0.0133 s/iter. Total: 0.0862 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 15:34:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.164188 (0.087622 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:34:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072464 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:34:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:34:07 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.205495982593382\n",
      "\u001b[32m[01/10 15:34:13 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 979  total_loss: 1.629  loss_cls: 0.378  loss_box_reg: 0.6128  loss_mask: 0.3138  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.2148  time: 0.5775  data_time: 0.1687  lr: 0.00048951  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:34:27 d2.utils.events]: \u001b[0m eta: 0:50:34  iter: 999  total_loss: 1.746  loss_cls: 0.412  loss_box_reg: 0.5787  loss_mask: 0.3368  loss_rpn_cls: 0.1269  loss_rpn_loc: 0.2334  time: 0.5805  data_time: 0.3778  lr: 0.0004995  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:34:40 d2.utils.events]: \u001b[0m eta: 0:50:27  iter: 1019  total_loss: 1.682  loss_cls: 0.3728  loss_box_reg: 0.5349  loss_mask: 0.3327  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.2432  time: 0.5819  data_time: 0.3238  lr: 0.0005  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:34:55 d2.utils.events]: \u001b[0m eta: 0:50:21  iter: 1039  total_loss: 1.72  loss_cls: 0.4075  loss_box_reg: 0.588  loss_mask: 0.3471  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.2469  time: 0.5850  data_time: 0.3991  lr: 0.0005  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:35:05 d2.utils.events]: \u001b[0m eta: 0:50:15  iter: 1059  total_loss: 1.625  loss_cls: 0.3828  loss_box_reg: 0.5717  loss_mask: 0.3322  loss_rpn_cls: 0.0974  loss_rpn_loc: 0.2225  time: 0.5836  data_time: 0.1863  lr: 0.0005  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:35:16 d2.utils.events]: \u001b[0m eta: 0:50:07  iter: 1079  total_loss: 1.599  loss_cls: 0.3719  loss_box_reg: 0.5485  loss_mask: 0.3269  loss_rpn_cls: 0.1131  loss_rpn_loc: 0.211  time: 0.5829  data_time: 0.2208  lr: 0.0005  max_mem: 6277M\n",
      "\u001b[32m[01/10 15:35:30 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 1099  total_loss: 1.624  loss_cls: 0.3888  loss_box_reg: 0.5563  loss_mask: 0.3249  loss_rpn_cls: 0.1196  loss_rpn_loc: 0.2329  time: 0.5852  data_time: 0.3544  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:35:41 d2.utils.events]: \u001b[0m eta: 0:50:01  iter: 1119  total_loss: 1.628  loss_cls: 0.3963  loss_box_reg: 0.6009  loss_mask: 0.3199  loss_rpn_cls: 0.08535  loss_rpn_loc: 0.2164  time: 0.5841  data_time: 0.1929  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:35:53 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 1139  total_loss: 1.787  loss_cls: 0.4553  loss_box_reg: 0.594  loss_mask: 0.3505  loss_rpn_cls: 0.1191  loss_rpn_loc: 0.2398  time: 0.5844  data_time: 0.2660  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:36:05 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 1159  total_loss: 1.633  loss_cls: 0.3994  loss_box_reg: 0.5697  loss_mask: 0.3333  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.2237  time: 0.5847  data_time: 0.2728  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:36:16 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 1179  total_loss: 1.797  loss_cls: 0.447  loss_box_reg: 0.5641  loss_mask: 0.3135  loss_rpn_cls: 0.1284  loss_rpn_loc: 0.2558  time: 0.5844  data_time: 0.2327  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:36:26 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 1199  total_loss: 1.66  loss_cls: 0.3945  loss_box_reg: 0.5648  loss_mask: 0.3364  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.2245  time: 0.5826  data_time: 0.1550  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:36:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:36:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:36:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:36:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:36:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:36:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0693 s/iter. Eval: 0.0085 s/iter. Total: 0.0784 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 15:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.0107 s/iter. Total: 0.0817 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 15:36:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.490405 (0.081814 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:36:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070262 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:36:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:36:41 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21749550632028067\n",
      "\u001b[32m[01/10 15:36:48 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 1219  total_loss: 1.562  loss_cls: 0.3427  loss_box_reg: 0.5813  loss_mask: 0.3135  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.2033  time: 0.5823  data_time: 0.2393  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:36:58 d2.utils.events]: \u001b[0m eta: 0:49:33  iter: 1239  total_loss: 1.579  loss_cls: 0.3915  loss_box_reg: 0.5543  loss_mask: 0.308  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.213  time: 0.5812  data_time: 0.2048  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:37:12 d2.utils.events]: \u001b[0m eta: 0:49:28  iter: 1259  total_loss: 1.721  loss_cls: 0.4305  loss_box_reg: 0.5676  loss_mask: 0.3301  loss_rpn_cls: 0.1306  loss_rpn_loc: 0.2389  time: 0.5833  data_time: 0.3751  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:37:22 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 1279  total_loss: 1.626  loss_cls: 0.3853  loss_box_reg: 0.5611  loss_mask: 0.3164  loss_rpn_cls: 0.09729  loss_rpn_loc: 0.2241  time: 0.5817  data_time: 0.1648  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:37:34 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 1299  total_loss: 1.663  loss_cls: 0.373  loss_box_reg: 0.5577  loss_mask: 0.3233  loss_rpn_cls: 0.1333  loss_rpn_loc: 0.2484  time: 0.5820  data_time: 0.2756  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:37:46 d2.utils.events]: \u001b[0m eta: 0:49:08  iter: 1319  total_loss: 1.656  loss_cls: 0.4347  loss_box_reg: 0.5804  loss_mask: 0.3083  loss_rpn_cls: 0.1186  loss_rpn_loc: 0.2291  time: 0.5823  data_time: 0.2781  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:37:59 d2.utils.events]: \u001b[0m eta: 0:49:06  iter: 1339  total_loss: 1.58  loss_cls: 0.3546  loss_box_reg: 0.536  loss_mask: 0.3146  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.2309  time: 0.5836  data_time: 0.3443  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:38:11 d2.utils.events]: \u001b[0m eta: 0:49:01  iter: 1359  total_loss: 1.686  loss_cls: 0.4156  loss_box_reg: 0.5809  loss_mask: 0.3291  loss_rpn_cls: 0.146  loss_rpn_loc: 0.2436  time: 0.5833  data_time: 0.2348  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:38:26 d2.utils.events]: \u001b[0m eta: 0:48:55  iter: 1379  total_loss: 1.626  loss_cls: 0.3747  loss_box_reg: 0.5616  loss_mask: 0.3344  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2297  time: 0.5859  data_time: 0.4236  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:38:37 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 1399  total_loss: 1.548  loss_cls: 0.3626  loss_box_reg: 0.5544  loss_mask: 0.311  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.2117  time: 0.5854  data_time: 0.2328  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:38:47 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 1419  total_loss: 1.474  loss_cls: 0.3257  loss_box_reg: 0.5583  loss_mask: 0.3143  loss_rpn_cls: 0.08236  loss_rpn_loc: 0.213  time: 0.5840  data_time: 0.1719  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:38:57 d2.utils.events]: \u001b[0m eta: 0:48:22  iter: 1439  total_loss: 1.557  loss_cls: 0.3298  loss_box_reg: 0.5582  loss_mask: 0.3366  loss_rpn_cls: 0.08773  loss_rpn_loc: 0.1956  time: 0.5828  data_time: 0.1909  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:39:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:39:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:39:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:39:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:39:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:39:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0107 s/iter. Total: 0.0817 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 15:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0153 s/iter. Total: 0.0895 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 15:39:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.501410 (0.090529 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:39:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073435 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:39:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:39:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22482208677085003\n",
      "\u001b[32m[01/10 15:39:22 d2.utils.events]: \u001b[0m eta: 0:48:18  iter: 1459  total_loss: 1.562  loss_cls: 0.3893  loss_box_reg: 0.5635  loss_mask: 0.3155  loss_rpn_cls: 0.09886  loss_rpn_loc: 0.2186  time: 0.5839  data_time: 0.3137  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:39:37 d2.utils.events]: \u001b[0m eta: 0:48:14  iter: 1479  total_loss: 1.642  loss_cls: 0.3728  loss_box_reg: 0.564  loss_mask: 0.3217  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.2326  time: 0.5864  data_time: 0.4342  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:39:46 d2.utils.events]: \u001b[0m eta: 0:48:07  iter: 1499  total_loss: 1.536  loss_cls: 0.314  loss_box_reg: 0.5726  loss_mask: 0.3264  loss_rpn_cls: 0.08969  loss_rpn_loc: 0.2098  time: 0.5848  data_time: 0.1603  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:39:56 d2.utils.events]: \u001b[0m eta: 0:47:59  iter: 1519  total_loss: 1.571  loss_cls: 0.3834  loss_box_reg: 0.5892  loss_mask: 0.3324  loss_rpn_cls: 0.09485  loss_rpn_loc: 0.2365  time: 0.5834  data_time: 0.1721  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:40:06 d2.utils.events]: \u001b[0m eta: 0:47:54  iter: 1539  total_loss: 1.579  loss_cls: 0.3878  loss_box_reg: 0.593  loss_mask: 0.3221  loss_rpn_cls: 0.08924  loss_rpn_loc: 0.2106  time: 0.5820  data_time: 0.1530  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:40:19 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 1559  total_loss: 1.641  loss_cls: 0.4232  loss_box_reg: 0.5277  loss_mask: 0.3197  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2218  time: 0.5830  data_time: 0.3375  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:40:30 d2.utils.events]: \u001b[0m eta: 0:47:54  iter: 1579  total_loss: 1.631  loss_cls: 0.3663  loss_box_reg: 0.5126  loss_mask: 0.3263  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.2181  time: 0.5831  data_time: 0.2613  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:40:46 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 1599  total_loss: 1.67  loss_cls: 0.4174  loss_box_reg: 0.5767  loss_mask: 0.3415  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.2431  time: 0.5855  data_time: 0.4351  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:40:57 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 1619  total_loss: 1.48  loss_cls: 0.3182  loss_box_reg: 0.5579  loss_mask: 0.2999  loss_rpn_cls: 0.07186  loss_rpn_loc: 0.1959  time: 0.5852  data_time: 0.2281  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:41:11 d2.utils.events]: \u001b[0m eta: 0:47:44  iter: 1639  total_loss: 1.57  loss_cls: 0.3454  loss_box_reg: 0.5534  loss_mask: 0.3298  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.2088  time: 0.5862  data_time: 0.3417  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:41:23 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 1659  total_loss: 1.571  loss_cls: 0.3483  loss_box_reg: 0.5607  loss_mask: 0.323  loss_rpn_cls: 0.1182  loss_rpn_loc: 0.2184  time: 0.5865  data_time: 0.2848  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:41:34 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 1679  total_loss: 1.656  loss_cls: 0.4172  loss_box_reg: 0.5841  loss_mask: 0.3116  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.2278  time: 0.5861  data_time: 0.2247  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:41:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:41:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:41:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:41:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:41:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:41:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0754 s/iter. Eval: 0.0095 s/iter. Total: 0.0855 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 15:41:51 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0749 s/iter. Eval: 0.0150 s/iter. Total: 0.0907 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 15:41:56 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0155 s/iter. Total: 0.0916 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 15:41:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.673365 (0.092012 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:41:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075288 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:41:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:41:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23782556221918144\n",
      "\u001b[32m[01/10 15:42:00 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 1699  total_loss: 1.523  loss_cls: 0.3539  loss_box_reg: 0.5491  loss_mask: 0.3248  loss_rpn_cls: 0.1263  loss_rpn_loc: 0.2228  time: 0.5877  data_time: 0.3883  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:42:15 d2.utils.events]: \u001b[0m eta: 0:47:22  iter: 1719  total_loss: 1.492  loss_cls: 0.3531  loss_box_reg: 0.5416  loss_mask: 0.3198  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.2203  time: 0.5897  data_time: 0.4153  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:42:27 d2.utils.events]: \u001b[0m eta: 0:47:15  iter: 1739  total_loss: 1.527  loss_cls: 0.3251  loss_box_reg: 0.555  loss_mask: 0.31  loss_rpn_cls: 0.08329  loss_rpn_loc: 0.2149  time: 0.5895  data_time: 0.2609  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:42:36 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 1759  total_loss: 1.481  loss_cls: 0.2966  loss_box_reg: 0.532  loss_mask: 0.3127  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.2152  time: 0.5882  data_time: 0.1552  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:42:49 d2.utils.events]: \u001b[0m eta: 0:47:13  iter: 1779  total_loss: 1.639  loss_cls: 0.3795  loss_box_reg: 0.5856  loss_mask: 0.3166  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.2261  time: 0.5887  data_time: 0.2936  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:43:01 d2.utils.events]: \u001b[0m eta: 0:46:58  iter: 1799  total_loss: 1.529  loss_cls: 0.3519  loss_box_reg: 0.5425  loss_mask: 0.3184  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.2145  time: 0.5887  data_time: 0.2739  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:43:10 d2.utils.events]: \u001b[0m eta: 0:46:51  iter: 1819  total_loss: 1.602  loss_cls: 0.3793  loss_box_reg: 0.5734  loss_mask: 0.3288  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.2125  time: 0.5872  data_time: 0.1270  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:43:20 d2.utils.events]: \u001b[0m eta: 0:46:52  iter: 1839  total_loss: 1.63  loss_cls: 0.404  loss_box_reg: 0.5523  loss_mask: 0.31  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.2242  time: 0.5865  data_time: 0.2013  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:43:32 d2.utils.events]: \u001b[0m eta: 0:46:46  iter: 1859  total_loss: 1.637  loss_cls: 0.3746  loss_box_reg: 0.579  loss_mask: 0.3209  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.2404  time: 0.5867  data_time: 0.2707  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:43:45 d2.utils.events]: \u001b[0m eta: 0:46:44  iter: 1879  total_loss: 1.535  loss_cls: 0.3658  loss_box_reg: 0.5477  loss_mask: 0.3179  loss_rpn_cls: 0.09373  loss_rpn_loc: 0.2343  time: 0.5869  data_time: 0.2659  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:43:55 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 1899  total_loss: 1.61  loss_cls: 0.3796  loss_box_reg: 0.5897  loss_mask: 0.3148  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2128  time: 0.5862  data_time: 0.1920  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:44:07 d2.utils.events]: \u001b[0m eta: 0:46:24  iter: 1919  total_loss: 1.534  loss_cls: 0.3589  loss_box_reg: 0.5622  loss_mask: 0.3085  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.2081  time: 0.5865  data_time: 0.2976  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:44:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:44:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:44:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:44:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:44:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:44:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0114 s/iter. Total: 0.0827 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 15:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0133 s/iter. Total: 0.0857 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 15:44:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.016164 (0.086346 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:44:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071757 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:44:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:44:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.22430929287944498\n",
      "\u001b[32m[01/10 15:44:31 d2.utils.events]: \u001b[0m eta: 0:46:21  iter: 1939  total_loss: 1.66  loss_cls: 0.3673  loss_box_reg: 0.5783  loss_mask: 0.327  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.2267  time: 0.5868  data_time: 0.2772  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:44:40 d2.utils.events]: \u001b[0m eta: 0:46:11  iter: 1959  total_loss: 1.553  loss_cls: 0.3765  loss_box_reg: 0.5397  loss_mask: 0.3107  loss_rpn_cls: 0.07937  loss_rpn_loc: 0.2086  time: 0.5855  data_time: 0.1527  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:44:49 d2.utils.events]: \u001b[0m eta: 0:46:04  iter: 1979  total_loss: 1.498  loss_cls: 0.3456  loss_box_reg: 0.5662  loss_mask: 0.2942  loss_rpn_cls: 0.104  loss_rpn_loc: 0.2004  time: 0.5841  data_time: 0.1378  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:44:59 d2.utils.events]: \u001b[0m eta: 0:45:57  iter: 1999  total_loss: 1.598  loss_cls: 0.3648  loss_box_reg: 0.547  loss_mask: 0.3494  loss_rpn_cls: 0.08549  loss_rpn_loc: 0.226  time: 0.5835  data_time: 0.1836  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:45:15 d2.utils.events]: \u001b[0m eta: 0:45:51  iter: 2019  total_loss: 1.455  loss_cls: 0.3637  loss_box_reg: 0.5203  loss_mask: 0.3072  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.2411  time: 0.5855  data_time: 0.4480  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:45:25 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 2039  total_loss: 1.492  loss_cls: 0.3532  loss_box_reg: 0.5344  loss_mask: 0.3083  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.2216  time: 0.5845  data_time: 0.1577  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:45:42 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 2059  total_loss: 1.602  loss_cls: 0.3667  loss_box_reg: 0.5471  loss_mask: 0.3231  loss_rpn_cls: 0.1177  loss_rpn_loc: 0.2408  time: 0.5870  data_time: 0.5004  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:45:52 d2.utils.events]: \u001b[0m eta: 0:45:35  iter: 2079  total_loss: 1.514  loss_cls: 0.3455  loss_box_reg: 0.5356  loss_mask: 0.3212  loss_rpn_cls: 0.08901  loss_rpn_loc: 0.2099  time: 0.5864  data_time: 0.2134  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:46:05 d2.utils.events]: \u001b[0m eta: 0:45:24  iter: 2099  total_loss: 1.588  loss_cls: 0.389  loss_box_reg: 0.5689  loss_mask: 0.3003  loss_rpn_cls: 0.1196  loss_rpn_loc: 0.2237  time: 0.5868  data_time: 0.2959  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:46:16 d2.utils.events]: \u001b[0m eta: 0:45:17  iter: 2119  total_loss: 1.565  loss_cls: 0.3694  loss_box_reg: 0.5894  loss_mask: 0.3197  loss_rpn_cls: 0.1263  loss_rpn_loc: 0.2171  time: 0.5863  data_time: 0.2176  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:46:29 d2.utils.events]: \u001b[0m eta: 0:45:08  iter: 2139  total_loss: 1.704  loss_cls: 0.4225  loss_box_reg: 0.5765  loss_mask: 0.3283  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.2218  time: 0.5871  data_time: 0.3457  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:46:41 d2.utils.events]: \u001b[0m eta: 0:45:00  iter: 2159  total_loss: 1.567  loss_cls: 0.3978  loss_box_reg: 0.5475  loss_mask: 0.3026  loss_rpn_cls: 0.09991  loss_rpn_loc: 0.2115  time: 0.5871  data_time: 0.2654  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:46:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:46:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:46:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:46:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:46:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:46:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0740 s/iter. Eval: 0.0107 s/iter. Total: 0.0853 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 15:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0776 s/iter. Eval: 0.0162 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 15:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0165 s/iter. Total: 0.0943 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 15:47:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.010812 (0.094921 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:47:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077127 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:47:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:47:07 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23303414823935892\n",
      "\u001b[32m[01/10 15:47:08 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 2179  total_loss: 1.47  loss_cls: 0.3269  loss_box_reg: 0.4937  loss_mask: 0.3365  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.2322  time: 0.5885  data_time: 0.3895  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:47:19 d2.utils.events]: \u001b[0m eta: 0:44:39  iter: 2199  total_loss: 1.553  loss_cls: 0.3796  loss_box_reg: 0.5752  loss_mask: 0.3057  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2167  time: 0.5883  data_time: 0.2397  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:47:31 d2.utils.events]: \u001b[0m eta: 0:44:37  iter: 2219  total_loss: 1.471  loss_cls: 0.3387  loss_box_reg: 0.5455  loss_mask: 0.3092  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.213  time: 0.5884  data_time: 0.2775  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:47:43 d2.utils.events]: \u001b[0m eta: 0:44:34  iter: 2239  total_loss: 1.462  loss_cls: 0.3407  loss_box_reg: 0.5297  loss_mask: 0.3191  loss_rpn_cls: 0.08653  loss_rpn_loc: 0.2132  time: 0.5885  data_time: 0.2668  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:47:54 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 2259  total_loss: 1.568  loss_cls: 0.3823  loss_box_reg: 0.5461  loss_mask: 0.3195  loss_rpn_cls: 0.08572  loss_rpn_loc: 0.217  time: 0.5882  data_time: 0.2361  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:48:07 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 2279  total_loss: 1.543  loss_cls: 0.3064  loss_box_reg: 0.5442  loss_mask: 0.3269  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.229  time: 0.5885  data_time: 0.2931  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:48:22 d2.utils.events]: \u001b[0m eta: 0:44:15  iter: 2299  total_loss: 1.528  loss_cls: 0.3459  loss_box_reg: 0.5291  loss_mask: 0.3234  loss_rpn_cls: 0.09054  loss_rpn_loc: 0.2162  time: 0.5900  data_time: 0.4477  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:48:32 d2.utils.events]: \u001b[0m eta: 0:44:06  iter: 2319  total_loss: 1.543  loss_cls: 0.366  loss_box_reg: 0.5443  loss_mask: 0.3306  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.2004  time: 0.5894  data_time: 0.1986  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:48:43 d2.utils.events]: \u001b[0m eta: 0:44:00  iter: 2339  total_loss: 1.649  loss_cls: 0.3471  loss_box_reg: 0.5173  loss_mask: 0.3201  loss_rpn_cls: 0.1359  loss_rpn_loc: 0.2193  time: 0.5890  data_time: 0.2273  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:48:57 d2.utils.events]: \u001b[0m eta: 0:44:00  iter: 2359  total_loss: 1.614  loss_cls: 0.3805  loss_box_reg: 0.5234  loss_mask: 0.3143  loss_rpn_cls: 0.1113  loss_rpn_loc: 0.2089  time: 0.5900  data_time: 0.3500  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:49:08 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 2379  total_loss: 1.546  loss_cls: 0.3365  loss_box_reg: 0.5533  loss_mask: 0.3152  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.196  time: 0.5894  data_time: 0.1954  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:49:21 d2.utils.events]: \u001b[0m eta: 0:43:44  iter: 2399  total_loss: 1.554  loss_cls: 0.3543  loss_box_reg: 0.5578  loss_mask: 0.3052  loss_rpn_cls: 0.08997  loss_rpn_loc: 0.206  time: 0.5898  data_time: 0.3254  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:49:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:49:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:49:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:49:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:49:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:49:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0101 s/iter. Total: 0.0818 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 15:49:36 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0735 s/iter. Eval: 0.0160 s/iter. Total: 0.0903 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 15:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0168 s/iter. Total: 0.0914 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 15:49:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.683533 (0.092099 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:49:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073918 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:49:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:49:41 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2453820704243752\n",
      "\u001b[32m[01/10 15:49:41 d2.utils.events]: \u001b[0m eta: 0:43:37  iter: 2419  total_loss: 1.581  loss_cls: 0.3482  loss_box_reg: 0.5917  loss_mask: 0.3084  loss_rpn_cls: 0.07747  loss_rpn_loc: 0.2168  time: 0.5886  data_time: 0.1340  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:49:51 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 2439  total_loss: 1.501  loss_cls: 0.3327  loss_box_reg: 0.55  loss_mask: 0.3129  loss_rpn_cls: 0.0833  loss_rpn_loc: 0.2187  time: 0.5876  data_time: 0.1460  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:50:03 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 2459  total_loss: 1.487  loss_cls: 0.3399  loss_box_reg: 0.5187  loss_mask: 0.3042  loss_rpn_cls: 0.0937  loss_rpn_loc: 0.1982  time: 0.5880  data_time: 0.3123  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:50:15 d2.utils.events]: \u001b[0m eta: 0:43:11  iter: 2479  total_loss: 1.526  loss_cls: 0.3717  loss_box_reg: 0.5555  loss_mask: 0.3121  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2087  time: 0.5879  data_time: 0.2533  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:50:24 d2.utils.events]: \u001b[0m eta: 0:43:04  iter: 2499  total_loss: 1.552  loss_cls: 0.2994  loss_box_reg: 0.5697  loss_mask: 0.2971  loss_rpn_cls: 0.07648  loss_rpn_loc: 0.1812  time: 0.5867  data_time: 0.1409  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:50:34 d2.utils.events]: \u001b[0m eta: 0:42:57  iter: 2519  total_loss: 1.559  loss_cls: 0.3728  loss_box_reg: 0.5446  loss_mask: 0.3145  loss_rpn_cls: 0.09937  loss_rpn_loc: 0.2131  time: 0.5861  data_time: 0.1959  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:50:45 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 2539  total_loss: 1.521  loss_cls: 0.3083  loss_box_reg: 0.5435  loss_mask: 0.3141  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.2169  time: 0.5859  data_time: 0.2463  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:50:59 d2.utils.events]: \u001b[0m eta: 0:42:46  iter: 2559  total_loss: 1.495  loss_cls: 0.3374  loss_box_reg: 0.5372  loss_mask: 0.3127  loss_rpn_cls: 0.0857  loss_rpn_loc: 0.2106  time: 0.5866  data_time: 0.3478  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:51:13 d2.utils.events]: \u001b[0m eta: 0:42:49  iter: 2579  total_loss: 1.596  loss_cls: 0.4033  loss_box_reg: 0.5569  loss_mask: 0.2947  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.235  time: 0.5875  data_time: 0.3639  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:51:28 d2.utils.events]: \u001b[0m eta: 0:42:42  iter: 2599  total_loss: 1.534  loss_cls: 0.3638  loss_box_reg: 0.5149  loss_mask: 0.3196  loss_rpn_cls: 0.09537  loss_rpn_loc: 0.2165  time: 0.5889  data_time: 0.4378  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:51:41 d2.utils.events]: \u001b[0m eta: 0:42:37  iter: 2619  total_loss: 1.627  loss_cls: 0.382  loss_box_reg: 0.5445  loss_mask: 0.3393  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.2331  time: 0.5892  data_time: 0.2931  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:51:52 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 2639  total_loss: 1.463  loss_cls: 0.3414  loss_box_reg: 0.5465  loss_mask: 0.3038  loss_rpn_cls: 0.09466  loss_rpn_loc: 0.2036  time: 0.5891  data_time: 0.2534  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:52:02 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 2659  total_loss: 1.484  loss_cls: 0.3444  loss_box_reg: 0.55  loss_mask: 0.3075  loss_rpn_cls: 0.07867  loss_rpn_loc: 0.2065  time: 0.5885  data_time: 0.2021  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:52:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:52:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:52:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:52:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:52:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:52:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0099 s/iter. Total: 0.0815 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 15:52:10 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0150 s/iter. Total: 0.0892 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 15:52:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.483647 (0.090376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:52:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073670 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:52:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:52:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24519312433955726\n",
      "\u001b[32m[01/10 15:52:23 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 2679  total_loss: 1.413  loss_cls: 0.3112  loss_box_reg: 0.5264  loss_mask: 0.3049  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.1936  time: 0.5876  data_time: 0.1494  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:52:35 d2.utils.events]: \u001b[0m eta: 0:41:55  iter: 2699  total_loss: 1.605  loss_cls: 0.3883  loss_box_reg: 0.5406  loss_mask: 0.3131  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2057  time: 0.5873  data_time: 0.2216  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:52:48 d2.utils.events]: \u001b[0m eta: 0:41:39  iter: 2719  total_loss: 1.536  loss_cls: 0.348  loss_box_reg: 0.5296  loss_mask: 0.3198  loss_rpn_cls: 0.09521  loss_rpn_loc: 0.2106  time: 0.5878  data_time: 0.3289  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:53:00 d2.utils.events]: \u001b[0m eta: 0:41:41  iter: 2739  total_loss: 1.462  loss_cls: 0.3577  loss_box_reg: 0.5253  loss_mask: 0.3182  loss_rpn_cls: 0.09384  loss_rpn_loc: 0.1935  time: 0.5880  data_time: 0.2881  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:53:12 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 2759  total_loss: 1.604  loss_cls: 0.3881  loss_box_reg: 0.5325  loss_mask: 0.3211  loss_rpn_cls: 0.07257  loss_rpn_loc: 0.235  time: 0.5882  data_time: 0.2926  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:53:22 d2.utils.events]: \u001b[0m eta: 0:41:19  iter: 2779  total_loss: 1.535  loss_cls: 0.3692  loss_box_reg: 0.5298  loss_mask: 0.3137  loss_rpn_cls: 0.09864  loss_rpn_loc: 0.2064  time: 0.5876  data_time: 0.1775  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:53:34 d2.utils.events]: \u001b[0m eta: 0:41:15  iter: 2799  total_loss: 1.54  loss_cls: 0.3392  loss_box_reg: 0.5575  loss_mask: 0.3008  loss_rpn_cls: 0.09842  loss_rpn_loc: 0.2182  time: 0.5877  data_time: 0.2835  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:53:47 d2.utils.events]: \u001b[0m eta: 0:41:14  iter: 2819  total_loss: 1.662  loss_cls: 0.4033  loss_box_reg: 0.5649  loss_mask: 0.3124  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2406  time: 0.5879  data_time: 0.2813  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:54:03 d2.utils.events]: \u001b[0m eta: 0:41:14  iter: 2839  total_loss: 1.548  loss_cls: 0.3533  loss_box_reg: 0.5297  loss_mask: 0.3172  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.2156  time: 0.5894  data_time: 0.4597  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:54:16 d2.utils.events]: \u001b[0m eta: 0:41:09  iter: 2859  total_loss: 1.466  loss_cls: 0.3394  loss_box_reg: 0.5193  loss_mask: 0.3069  loss_rpn_cls: 0.08628  loss_rpn_loc: 0.2277  time: 0.5898  data_time: 0.3296  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:54:27 d2.utils.events]: \u001b[0m eta: 0:40:55  iter: 2879  total_loss: 1.446  loss_cls: 0.3178  loss_box_reg: 0.5472  loss_mask: 0.3137  loss_rpn_cls: 0.0873  loss_rpn_loc: 0.2067  time: 0.5896  data_time: 0.2299  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:54:37 d2.utils.events]: \u001b[0m eta: 0:40:51  iter: 2899  total_loss: 1.369  loss_cls: 0.2915  loss_box_reg: 0.5025  loss_mask: 0.3051  loss_rpn_cls: 0.0631  loss_rpn_loc: 0.1798  time: 0.5889  data_time: 0.1696  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:54:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:54:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:54:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:54:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:54:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:54:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0761 s/iter. Eval: 0.0105 s/iter. Total: 0.0872 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 15:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0780 s/iter. Eval: 0.0168 s/iter. Total: 0.0956 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 15:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0762 s/iter. Eval: 0.0167 s/iter. Total: 0.0937 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 15:54:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.939023 (0.094302 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:54:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076197 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:54:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:54:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24185390566661444\n",
      "\u001b[32m[01/10 15:55:01 d2.utils.events]: \u001b[0m eta: 0:40:48  iter: 2919  total_loss: 1.579  loss_cls: 0.3177  loss_box_reg: 0.5107  loss_mask: 0.3198  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2342  time: 0.5890  data_time: 0.2703  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:55:16 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 2939  total_loss: 1.583  loss_cls: 0.3923  loss_box_reg: 0.5746  loss_mask: 0.322  loss_rpn_cls: 0.135  loss_rpn_loc: 0.23  time: 0.5900  data_time: 0.4126  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:55:29 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 2959  total_loss: 1.518  loss_cls: 0.3117  loss_box_reg: 0.556  loss_mask: 0.3193  loss_rpn_cls: 0.09129  loss_rpn_loc: 0.205  time: 0.5904  data_time: 0.3300  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:55:39 d2.utils.events]: \u001b[0m eta: 0:40:24  iter: 2979  total_loss: 1.487  loss_cls: 0.3482  loss_box_reg: 0.5351  loss_mask: 0.3017  loss_rpn_cls: 0.08675  loss_rpn_loc: 0.2038  time: 0.5900  data_time: 0.2246  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:55:51 d2.utils.events]: \u001b[0m eta: 0:40:13  iter: 2999  total_loss: 1.54  loss_cls: 0.3776  loss_box_reg: 0.5482  loss_mask: 0.3085  loss_rpn_cls: 0.09442  loss_rpn_loc: 0.2106  time: 0.5901  data_time: 0.2767  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:56:04 d2.utils.events]: \u001b[0m eta: 0:40:02  iter: 3019  total_loss: 1.509  loss_cls: 0.35  loss_box_reg: 0.5582  loss_mask: 0.311  loss_rpn_cls: 0.08792  loss_rpn_loc: 0.2171  time: 0.5903  data_time: 0.2966  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:56:15 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 3039  total_loss: 1.513  loss_cls: 0.3532  loss_box_reg: 0.5358  loss_mask: 0.3233  loss_rpn_cls: 0.08258  loss_rpn_loc: 0.2033  time: 0.5902  data_time: 0.2436  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:56:27 d2.utils.events]: \u001b[0m eta: 0:39:42  iter: 3059  total_loss: 1.349  loss_cls: 0.2904  loss_box_reg: 0.5265  loss_mask: 0.3013  loss_rpn_cls: 0.07582  loss_rpn_loc: 0.2101  time: 0.5902  data_time: 0.2655  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:56:40 d2.utils.events]: \u001b[0m eta: 0:39:36  iter: 3079  total_loss: 1.437  loss_cls: 0.3264  loss_box_reg: 0.5105  loss_mask: 0.3055  loss_rpn_cls: 0.09513  loss_rpn_loc: 0.2082  time: 0.5904  data_time: 0.3117  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:56:52 d2.utils.events]: \u001b[0m eta: 0:39:28  iter: 3099  total_loss: 1.436  loss_cls: 0.3107  loss_box_reg: 0.4938  loss_mask: 0.3081  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.1833  time: 0.5905  data_time: 0.2780  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:57:03 d2.utils.events]: \u001b[0m eta: 0:39:21  iter: 3119  total_loss: 1.557  loss_cls: 0.3694  loss_box_reg: 0.5368  loss_mask: 0.3098  loss_rpn_cls: 0.09801  loss_rpn_loc: 0.2094  time: 0.5903  data_time: 0.2295  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:57:11 d2.utils.events]: \u001b[0m eta: 0:39:08  iter: 3139  total_loss: 1.573  loss_cls: 0.3361  loss_box_reg: 0.5741  loss_mask: 0.3215  loss_rpn_cls: 0.0759  loss_rpn_loc: 0.2051  time: 0.5892  data_time: 0.1192  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:57:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:57:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:57:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:57:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:57:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:57:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0108 s/iter. Total: 0.0823 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 15:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0149 s/iter. Total: 0.0890 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 15:57:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.431632 (0.089928 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:57:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073578 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 15:57:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 15:57:25 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24237636803970927\n",
      "\u001b[32m[01/10 15:57:34 d2.utils.events]: \u001b[0m eta: 0:39:05  iter: 3159  total_loss: 1.572  loss_cls: 0.3239  loss_box_reg: 0.5526  loss_mask: 0.3109  loss_rpn_cls: 0.08559  loss_rpn_loc: 0.2093  time: 0.5890  data_time: 0.2279  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:57:44 d2.utils.events]: \u001b[0m eta: 0:38:53  iter: 3179  total_loss: 1.418  loss_cls: 0.2932  loss_box_reg: 0.5364  loss_mask: 0.3058  loss_rpn_cls: 0.05475  loss_rpn_loc: 0.1944  time: 0.5885  data_time: 0.1986  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:57:56 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 3199  total_loss: 1.524  loss_cls: 0.3613  loss_box_reg: 0.5552  loss_mask: 0.3315  loss_rpn_cls: 0.1132  loss_rpn_loc: 0.2157  time: 0.5885  data_time: 0.2655  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:58:06 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 3219  total_loss: 1.493  loss_cls: 0.3457  loss_box_reg: 0.5089  loss_mask: 0.3018  loss_rpn_cls: 0.09472  loss_rpn_loc: 0.2082  time: 0.5880  data_time: 0.2091  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:58:20 d2.utils.events]: \u001b[0m eta: 0:38:33  iter: 3239  total_loss: 1.543  loss_cls: 0.3712  loss_box_reg: 0.5132  loss_mask: 0.3106  loss_rpn_cls: 0.0901  loss_rpn_loc: 0.2041  time: 0.5885  data_time: 0.3412  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:58:35 d2.utils.events]: \u001b[0m eta: 0:38:27  iter: 3259  total_loss: 1.639  loss_cls: 0.4104  loss_box_reg: 0.5827  loss_mask: 0.3261  loss_rpn_cls: 0.1222  loss_rpn_loc: 0.2297  time: 0.5895  data_time: 0.4121  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:58:44 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 3279  total_loss: 1.517  loss_cls: 0.3497  loss_box_reg: 0.519  loss_mask: 0.2977  loss_rpn_cls: 0.09993  loss_rpn_loc: 0.1926  time: 0.5888  data_time: 0.1669  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:58:57 d2.utils.events]: \u001b[0m eta: 0:38:07  iter: 3299  total_loss: 1.43  loss_cls: 0.3224  loss_box_reg: 0.496  loss_mask: 0.304  loss_rpn_cls: 0.0527  loss_rpn_loc: 0.2015  time: 0.5891  data_time: 0.3253  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:59:10 d2.utils.events]: \u001b[0m eta: 0:38:06  iter: 3319  total_loss: 1.566  loss_cls: 0.3394  loss_box_reg: 0.5626  loss_mask: 0.3209  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.2122  time: 0.5896  data_time: 0.3413  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:59:22 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 3339  total_loss: 1.464  loss_cls: 0.3335  loss_box_reg: 0.544  loss_mask: 0.3081  loss_rpn_cls: 0.09553  loss_rpn_loc: 0.2274  time: 0.5896  data_time: 0.2665  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:59:37 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 3359  total_loss: 1.631  loss_cls: 0.4106  loss_box_reg: 0.5483  loss_mask: 0.3216  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2213  time: 0.5905  data_time: 0.4075  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:59:47 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 3379  total_loss: 1.434  loss_cls: 0.3253  loss_box_reg: 0.5386  loss_mask: 0.3012  loss_rpn_cls: 0.07723  loss_rpn_loc: 0.2121  time: 0.5900  data_time: 0.1811  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 15:59:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:59:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 15:59:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 15:59:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 15:59:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 15:59:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 15:59:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0702 s/iter. Eval: 0.0101 s/iter. Total: 0.0809 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 15:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0159 s/iter. Total: 0.0901 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0164 s/iter. Total: 0.0908 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 16:00:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.615693 (0.091515 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:00:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073630 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:00:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:00:04 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2487265927535293\n",
      "\u001b[32m[01/10 16:00:08 d2.utils.events]: \u001b[0m eta: 0:37:28  iter: 3399  total_loss: 1.462  loss_cls: 0.3356  loss_box_reg: 0.5545  loss_mask: 0.3052  loss_rpn_cls: 0.08673  loss_rpn_loc: 0.1901  time: 0.5892  data_time: 0.1447  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:00:19 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 3419  total_loss: 1.429  loss_cls: 0.3065  loss_box_reg: 0.5513  loss_mask: 0.3211  loss_rpn_cls: 0.07292  loss_rpn_loc: 0.1961  time: 0.5889  data_time: 0.2276  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:00:30 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 3439  total_loss: 1.436  loss_cls: 0.3149  loss_box_reg: 0.5171  loss_mask: 0.3  loss_rpn_cls: 0.08248  loss_rpn_loc: 0.2108  time: 0.5888  data_time: 0.2328  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:00:41 d2.utils.events]: \u001b[0m eta: 0:37:06  iter: 3459  total_loss: 1.441  loss_cls: 0.3141  loss_box_reg: 0.5544  loss_mask: 0.3042  loss_rpn_cls: 0.05932  loss_rpn_loc: 0.2047  time: 0.5886  data_time: 0.2470  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:00:54 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 3479  total_loss: 1.44  loss_cls: 0.3194  loss_box_reg: 0.5365  loss_mask: 0.3148  loss_rpn_cls: 0.08502  loss_rpn_loc: 0.196  time: 0.5889  data_time: 0.3218  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:01:08 d2.utils.events]: \u001b[0m eta: 0:37:04  iter: 3499  total_loss: 1.513  loss_cls: 0.3482  loss_box_reg: 0.5403  loss_mask: 0.3002  loss_rpn_cls: 0.09942  loss_rpn_loc: 0.2108  time: 0.5894  data_time: 0.3343  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:01:20 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 3519  total_loss: 1.532  loss_cls: 0.3427  loss_box_reg: 0.524  loss_mask: 0.3197  loss_rpn_cls: 0.09286  loss_rpn_loc: 0.2265  time: 0.5895  data_time: 0.3038  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:01:32 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 3539  total_loss: 1.454  loss_cls: 0.3495  loss_box_reg: 0.5306  loss_mask: 0.3023  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.199  time: 0.5897  data_time: 0.2912  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:01:44 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 3559  total_loss: 1.591  loss_cls: 0.3791  loss_box_reg: 0.5167  loss_mask: 0.2963  loss_rpn_cls: 0.09187  loss_rpn_loc: 0.2041  time: 0.5898  data_time: 0.2782  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:01:55 d2.utils.events]: \u001b[0m eta: 0:36:32  iter: 3579  total_loss: 1.475  loss_cls: 0.3412  loss_box_reg: 0.5474  loss_mask: 0.3093  loss_rpn_cls: 0.07853  loss_rpn_loc: 0.2012  time: 0.5894  data_time: 0.2000  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:02:05 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 3599  total_loss: 1.496  loss_cls: 0.3259  loss_box_reg: 0.5357  loss_mask: 0.3044  loss_rpn_cls: 0.06518  loss_rpn_loc: 0.2025  time: 0.5889  data_time: 0.1851  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:02:18 d2.utils.events]: \u001b[0m eta: 0:36:09  iter: 3619  total_loss: 1.577  loss_cls: 0.3789  loss_box_reg: 0.5219  loss_mask: 0.3057  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.2192  time: 0.5893  data_time: 0.3298  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:02:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:02:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:02:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:02:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:02:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:02:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:02:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0769 s/iter. Eval: 0.0101 s/iter. Total: 0.0876 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:02:29 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0737 s/iter. Eval: 0.0152 s/iter. Total: 0.0896 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:02:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.576239 (0.091174 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:02:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074078 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:02:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:02:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2425206819464747\n",
      "\u001b[32m[01/10 16:02:41 d2.utils.events]: \u001b[0m eta: 0:35:59  iter: 3639  total_loss: 1.458  loss_cls: 0.3321  loss_box_reg: 0.5282  loss_mask: 0.3233  loss_rpn_cls: 0.09955  loss_rpn_loc: 0.2125  time: 0.5892  data_time: 0.2540  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:02:51 d2.utils.events]: \u001b[0m eta: 0:35:55  iter: 3659  total_loss: 1.472  loss_cls: 0.3295  loss_box_reg: 0.4881  loss_mask: 0.3222  loss_rpn_cls: 0.08202  loss_rpn_loc: 0.2137  time: 0.5886  data_time: 0.1648  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:03:03 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 3679  total_loss: 1.531  loss_cls: 0.3819  loss_box_reg: 0.5432  loss_mask: 0.3069  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.219  time: 0.5886  data_time: 0.2608  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:03:14 d2.utils.events]: \u001b[0m eta: 0:35:42  iter: 3699  total_loss: 1.378  loss_cls: 0.3328  loss_box_reg: 0.5006  loss_mask: 0.2865  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.197  time: 0.5884  data_time: 0.2310  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:03:30 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 3719  total_loss: 1.513  loss_cls: 0.3752  loss_box_reg: 0.4875  loss_mask: 0.3128  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.2125  time: 0.5895  data_time: 0.4560  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:03:40 d2.utils.events]: \u001b[0m eta: 0:35:35  iter: 3739  total_loss: 1.639  loss_cls: 0.3472  loss_box_reg: 0.5566  loss_mask: 0.3152  loss_rpn_cls: 0.06561  loss_rpn_loc: 0.2099  time: 0.5890  data_time: 0.1717  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:03:54 d2.utils.events]: \u001b[0m eta: 0:35:30  iter: 3759  total_loss: 1.53  loss_cls: 0.3475  loss_box_reg: 0.4972  loss_mask: 0.3153  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.2419  time: 0.5896  data_time: 0.3735  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:04:05 d2.utils.events]: \u001b[0m eta: 0:35:20  iter: 3779  total_loss: 1.603  loss_cls: 0.345  loss_box_reg: 0.533  loss_mask: 0.3091  loss_rpn_cls: 0.09382  loss_rpn_loc: 0.1836  time: 0.5894  data_time: 0.2366  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:04:17 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 3799  total_loss: 1.452  loss_cls: 0.3184  loss_box_reg: 0.4978  loss_mask: 0.3028  loss_rpn_cls: 0.1101  loss_rpn_loc: 0.2059  time: 0.5895  data_time: 0.2880  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:04:29 d2.utils.events]: \u001b[0m eta: 0:35:08  iter: 3819  total_loss: 1.495  loss_cls: 0.3417  loss_box_reg: 0.5011  loss_mask: 0.3111  loss_rpn_cls: 0.07897  loss_rpn_loc: 0.1952  time: 0.5897  data_time: 0.2790  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:04:41 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 3839  total_loss: 1.418  loss_cls: 0.3101  loss_box_reg: 0.515  loss_mask: 0.3082  loss_rpn_cls: 0.07998  loss_rpn_loc: 0.2056  time: 0.5896  data_time: 0.2534  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:04:51 d2.utils.events]: \u001b[0m eta: 0:34:47  iter: 3859  total_loss: 1.494  loss_cls: 0.3307  loss_box_reg: 0.5418  loss_mask: 0.2935  loss_rpn_cls: 0.07309  loss_rpn_loc: 0.2026  time: 0.5893  data_time: 0.2301  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:04:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:04:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:04:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:04:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:04:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:04:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:05:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0714 s/iter. Eval: 0.0106 s/iter. Total: 0.0826 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:05:06 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0162 s/iter. Total: 0.0906 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:05:11 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0007 s/iter. Inference: 0.0745 s/iter. Eval: 0.0169 s/iter. Total: 0.0921 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 16:05:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.770697 (0.092851 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:05:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074503 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:05:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:05:11 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24624827664974092\n",
      "\u001b[32m[01/10 16:05:13 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 3879  total_loss: 1.553  loss_cls: 0.3591  loss_box_reg: 0.5817  loss_mask: 0.3121  loss_rpn_cls: 0.08297  loss_rpn_loc: 0.1977  time: 0.5888  data_time: 0.1727  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:05:25 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 3899  total_loss: 1.465  loss_cls: 0.3313  loss_box_reg: 0.5645  loss_mask: 0.2978  loss_rpn_cls: 0.09922  loss_rpn_loc: 0.2193  time: 0.5888  data_time: 0.2673  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:05:36 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 3919  total_loss: 1.504  loss_cls: 0.3228  loss_box_reg: 0.5701  loss_mask: 0.3198  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.2088  time: 0.5885  data_time: 0.2126  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:05:49 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 3939  total_loss: 1.4  loss_cls: 0.3058  loss_box_reg: 0.517  loss_mask: 0.319  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.2053  time: 0.5889  data_time: 0.3323  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:06:00 d2.utils.events]: \u001b[0m eta: 0:34:09  iter: 3959  total_loss: 1.496  loss_cls: 0.3393  loss_box_reg: 0.5052  loss_mask: 0.3094  loss_rpn_cls: 0.09348  loss_rpn_loc: 0.2033  time: 0.5886  data_time: 0.2190  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:06:13 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 3979  total_loss: 1.458  loss_cls: 0.3162  loss_box_reg: 0.5287  loss_mask: 0.3073  loss_rpn_cls: 0.09297  loss_rpn_loc: 0.2062  time: 0.5889  data_time: 0.3317  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:06:23 d2.utils.events]: \u001b[0m eta: 0:33:51  iter: 3999  total_loss: 1.522  loss_cls: 0.361  loss_box_reg: 0.5549  loss_mask: 0.2977  loss_rpn_cls: 0.08603  loss_rpn_loc: 0.193  time: 0.5885  data_time: 0.1952  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:06:36 d2.utils.events]: \u001b[0m eta: 0:33:43  iter: 4019  total_loss: 1.538  loss_cls: 0.3467  loss_box_reg: 0.5373  loss_mask: 0.2945  loss_rpn_cls: 0.09165  loss_rpn_loc: 0.2179  time: 0.5887  data_time: 0.3047  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:06:47 d2.utils.events]: \u001b[0m eta: 0:33:37  iter: 4039  total_loss: 1.422  loss_cls: 0.3221  loss_box_reg: 0.5465  loss_mask: 0.3096  loss_rpn_cls: 0.09748  loss_rpn_loc: 0.2139  time: 0.5887  data_time: 0.2431  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:06:58 d2.utils.events]: \u001b[0m eta: 0:33:34  iter: 4059  total_loss: 1.434  loss_cls: 0.327  loss_box_reg: 0.5497  loss_mask: 0.3041  loss_rpn_cls: 0.05803  loss_rpn_loc: 0.199  time: 0.5885  data_time: 0.2375  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:07:10 d2.utils.events]: \u001b[0m eta: 0:33:31  iter: 4079  total_loss: 1.406  loss_cls: 0.2884  loss_box_reg: 0.5306  loss_mask: 0.299  loss_rpn_cls: 0.09325  loss_rpn_loc: 0.2101  time: 0.5884  data_time: 0.2358  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:07:22 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 4099  total_loss: 1.607  loss_cls: 0.3676  loss_box_reg: 0.5522  loss_mask: 0.3184  loss_rpn_cls: 0.09822  loss_rpn_loc: 0.2051  time: 0.5886  data_time: 0.2801  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:07:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:07:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:07:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:07:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:07:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:07:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0116 s/iter. Total: 0.0859 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0783 s/iter. Eval: 0.0158 s/iter. Total: 0.0949 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 16:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0755 s/iter. Eval: 0.0152 s/iter. Total: 0.0915 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 16:07:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.668873 (0.091973 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:07:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075457 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:07:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:07:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24228183195298947\n",
      "\u001b[32m[01/10 16:07:46 d2.utils.events]: \u001b[0m eta: 0:33:24  iter: 4119  total_loss: 1.558  loss_cls: 0.3444  loss_box_reg: 0.5317  loss_mask: 0.3014  loss_rpn_cls: 0.08976  loss_rpn_loc: 0.2046  time: 0.5887  data_time: 0.2664  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:07:56 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 4139  total_loss: 1.506  loss_cls: 0.3465  loss_box_reg: 0.5252  loss_mask: 0.2977  loss_rpn_cls: 0.08588  loss_rpn_loc: 0.1986  time: 0.5881  data_time: 0.1455  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:08:10 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 4159  total_loss: 1.511  loss_cls: 0.3631  loss_box_reg: 0.5058  loss_mask: 0.328  loss_rpn_cls: 0.1118  loss_rpn_loc: 0.2226  time: 0.5887  data_time: 0.3715  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:08:21 d2.utils.events]: \u001b[0m eta: 0:33:10  iter: 4179  total_loss: 1.528  loss_cls: 0.3758  loss_box_reg: 0.4977  loss_mask: 0.3046  loss_rpn_cls: 0.08321  loss_rpn_loc: 0.2131  time: 0.5885  data_time: 0.2325  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:08:31 d2.utils.events]: \u001b[0m eta: 0:33:04  iter: 4199  total_loss: 1.407  loss_cls: 0.2966  loss_box_reg: 0.5031  loss_mask: 0.288  loss_rpn_cls: 0.0679  loss_rpn_loc: 0.1916  time: 0.5880  data_time: 0.1639  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:08:43 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 4219  total_loss: 1.574  loss_cls: 0.3817  loss_box_reg: 0.5497  loss_mask: 0.313  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.2292  time: 0.5881  data_time: 0.2646  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:08:52 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 4239  total_loss: 1.53  loss_cls: 0.3554  loss_box_reg: 0.541  loss_mask: 0.2948  loss_rpn_cls: 0.09641  loss_rpn_loc: 0.2027  time: 0.5875  data_time: 0.1457  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:09:07 d2.utils.events]: \u001b[0m eta: 0:32:42  iter: 4259  total_loss: 1.486  loss_cls: 0.3544  loss_box_reg: 0.4885  loss_mask: 0.2989  loss_rpn_cls: 0.08881  loss_rpn_loc: 0.203  time: 0.5883  data_time: 0.4237  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:09:20 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 4279  total_loss: 1.481  loss_cls: 0.3614  loss_box_reg: 0.5296  loss_mask: 0.3037  loss_rpn_cls: 0.07953  loss_rpn_loc: 0.2013  time: 0.5885  data_time: 0.2952  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:09:35 d2.utils.events]: \u001b[0m eta: 0:32:36  iter: 4299  total_loss: 1.587  loss_cls: 0.3981  loss_box_reg: 0.5191  loss_mask: 0.3079  loss_rpn_cls: 0.09884  loss_rpn_loc: 0.2094  time: 0.5894  data_time: 0.4451  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:09:47 d2.utils.events]: \u001b[0m eta: 0:32:26  iter: 4319  total_loss: 1.438  loss_cls: 0.308  loss_box_reg: 0.519  loss_mask: 0.2979  loss_rpn_cls: 0.08139  loss_rpn_loc: 0.1925  time: 0.5893  data_time: 0.2533  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:09:57 d2.utils.events]: \u001b[0m eta: 0:32:18  iter: 4339  total_loss: 1.418  loss_cls: 0.3349  loss_box_reg: 0.524  loss_mask: 0.304  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.1973  time: 0.5890  data_time: 0.2139  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:10:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:10:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:10:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:10:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:10:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:10:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:10:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0698 s/iter. Eval: 0.0101 s/iter. Total: 0.0805 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0728 s/iter. Eval: 0.0155 s/iter. Total: 0.0891 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:10:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.567569 (0.091100 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:10:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073553 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:10:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:10:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25001505315153333\n",
      "\u001b[32m[01/10 16:10:18 d2.utils.events]: \u001b[0m eta: 0:32:06  iter: 4359  total_loss: 1.43  loss_cls: 0.3283  loss_box_reg: 0.5526  loss_mask: 0.307  loss_rpn_cls: 0.07808  loss_rpn_loc: 0.1894  time: 0.5883  data_time: 0.1387  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:10:29 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 4379  total_loss: 1.483  loss_cls: 0.3238  loss_box_reg: 0.5549  loss_mask: 0.3044  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.2069  time: 0.5881  data_time: 0.2233  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:10:39 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 4399  total_loss: 1.411  loss_cls: 0.301  loss_box_reg: 0.5126  loss_mask: 0.304  loss_rpn_cls: 0.05639  loss_rpn_loc: 0.1948  time: 0.5877  data_time: 0.1711  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:10:51 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 4419  total_loss: 1.492  loss_cls: 0.3186  loss_box_reg: 0.4921  loss_mask: 0.3084  loss_rpn_cls: 0.08392  loss_rpn_loc: 0.1939  time: 0.5877  data_time: 0.2803  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:11:03 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 4439  total_loss: 1.572  loss_cls: 0.37  loss_box_reg: 0.5404  loss_mask: 0.3179  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.2307  time: 0.5879  data_time: 0.2852  lr: 0.0005  max_mem: 6333M\n",
      "\u001b[32m[01/10 16:11:18 d2.utils.events]: \u001b[0m eta: 0:31:37  iter: 4459  total_loss: 1.477  loss_cls: 0.3348  loss_box_reg: 0.4964  loss_mask: 0.3092  loss_rpn_cls: 0.09268  loss_rpn_loc: 0.2147  time: 0.5885  data_time: 0.4079  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:11:29 d2.utils.events]: \u001b[0m eta: 0:31:30  iter: 4479  total_loss: 1.436  loss_cls: 0.3381  loss_box_reg: 0.5486  loss_mask: 0.2941  loss_rpn_cls: 0.07766  loss_rpn_loc: 0.1941  time: 0.5884  data_time: 0.2412  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:11:41 d2.utils.events]: \u001b[0m eta: 0:31:19  iter: 4499  total_loss: 1.511  loss_cls: 0.3471  loss_box_reg: 0.5522  loss_mask: 0.3037  loss_rpn_cls: 0.0977  loss_rpn_loc: 0.204  time: 0.5884  data_time: 0.2703  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:11:53 d2.utils.events]: \u001b[0m eta: 0:31:14  iter: 4519  total_loss: 1.42  loss_cls: 0.3039  loss_box_reg: 0.5472  loss_mask: 0.2972  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.2011  time: 0.5885  data_time: 0.2939  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:12:04 d2.utils.events]: \u001b[0m eta: 0:31:07  iter: 4539  total_loss: 1.565  loss_cls: 0.3243  loss_box_reg: 0.5483  loss_mask: 0.3162  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2332  time: 0.5884  data_time: 0.2472  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:12:17 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 4559  total_loss: 1.53  loss_cls: 0.3247  loss_box_reg: 0.513  loss_mask: 0.3159  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.2209  time: 0.5886  data_time: 0.2923  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:12:29 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 4579  total_loss: 1.423  loss_cls: 0.3323  loss_box_reg: 0.4941  loss_mask: 0.2898  loss_rpn_cls: 0.08076  loss_rpn_loc: 0.1921  time: 0.5887  data_time: 0.2952  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:12:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:12:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:12:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:12:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:12:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:12:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:12:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0697 s/iter. Eval: 0.0103 s/iter. Total: 0.0806 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:12:50 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0722 s/iter. Eval: 0.0149 s/iter. Total: 0.0878 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:12:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.342164 (0.089157 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:12:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072447 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:12:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:12:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.244929682939611\n",
      "\u001b[32m[01/10 16:12:55 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 4599  total_loss: 1.514  loss_cls: 0.3464  loss_box_reg: 0.5487  loss_mask: 0.3108  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.2066  time: 0.5893  data_time: 0.3825  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:13:06 d2.utils.events]: \u001b[0m eta: 0:30:42  iter: 4619  total_loss: 1.439  loss_cls: 0.361  loss_box_reg: 0.5388  loss_mask: 0.3085  loss_rpn_cls: 0.07201  loss_rpn_loc: 0.199  time: 0.5890  data_time: 0.1981  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:13:16 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 4639  total_loss: 1.414  loss_cls: 0.3116  loss_box_reg: 0.522  loss_mask: 0.3081  loss_rpn_cls: 0.07214  loss_rpn_loc: 0.1846  time: 0.5888  data_time: 0.2221  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:13:29 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 4659  total_loss: 1.572  loss_cls: 0.3842  loss_box_reg: 0.5323  loss_mask: 0.328  loss_rpn_cls: 0.08012  loss_rpn_loc: 0.2088  time: 0.5888  data_time: 0.2931  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:13:41 d2.utils.events]: \u001b[0m eta: 0:30:26  iter: 4679  total_loss: 1.409  loss_cls: 0.3345  loss_box_reg: 0.4785  loss_mask: 0.3158  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.2169  time: 0.5890  data_time: 0.3168  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:13:52 d2.utils.events]: \u001b[0m eta: 0:30:20  iter: 4699  total_loss: 1.361  loss_cls: 0.3146  loss_box_reg: 0.5177  loss_mask: 0.2899  loss_rpn_cls: 0.07025  loss_rpn_loc: 0.1785  time: 0.5889  data_time: 0.2523  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:14:06 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 4719  total_loss: 1.623  loss_cls: 0.3954  loss_box_reg: 0.5129  loss_mask: 0.3183  loss_rpn_cls: 0.1357  loss_rpn_loc: 0.2307  time: 0.5894  data_time: 0.3845  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:14:19 d2.utils.events]: \u001b[0m eta: 0:30:04  iter: 4739  total_loss: 1.512  loss_cls: 0.3635  loss_box_reg: 0.5444  loss_mask: 0.3125  loss_rpn_cls: 0.0833  loss_rpn_loc: 0.2019  time: 0.5896  data_time: 0.3202  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:14:28 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 4759  total_loss: 1.433  loss_cls: 0.3121  loss_box_reg: 0.5459  loss_mask: 0.3031  loss_rpn_cls: 0.0704  loss_rpn_loc: 0.1883  time: 0.5889  data_time: 0.1178  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:14:40 d2.utils.events]: \u001b[0m eta: 0:29:49  iter: 4779  total_loss: 1.43  loss_cls: 0.3352  loss_box_reg: 0.5594  loss_mask: 0.3068  loss_rpn_cls: 0.0647  loss_rpn_loc: 0.1873  time: 0.5890  data_time: 0.2807  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:14:53 d2.utils.events]: \u001b[0m eta: 0:29:42  iter: 4799  total_loss: 1.452  loss_cls: 0.2997  loss_box_reg: 0.5116  loss_mask: 0.321  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.2248  time: 0.5893  data_time: 0.3544  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:15:07 d2.utils.events]: \u001b[0m eta: 0:29:35  iter: 4819  total_loss: 1.525  loss_cls: 0.3622  loss_box_reg: 0.5344  loss_mask: 0.311  loss_rpn_cls: 0.09053  loss_rpn_loc: 0.2249  time: 0.5896  data_time: 0.3509  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:15:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:15:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:15:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:15:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:15:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:15:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0693 s/iter. Eval: 0.0093 s/iter. Total: 0.0792 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0141 s/iter. Total: 0.0865 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:15:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.178129 (0.087742 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:15:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071913 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:15:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:15:30 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24680528835234491\n",
      "\u001b[32m[01/10 16:15:30 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 4839  total_loss: 1.485  loss_cls: 0.3351  loss_box_reg: 0.516  loss_mask: 0.3052  loss_rpn_cls: 0.08885  loss_rpn_loc: 0.2058  time: 0.5896  data_time: 0.2701  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:15:42 d2.utils.events]: \u001b[0m eta: 0:29:22  iter: 4859  total_loss: 1.413  loss_cls: 0.2966  loss_box_reg: 0.5014  loss_mask: 0.2928  loss_rpn_cls: 0.07298  loss_rpn_loc: 0.2034  time: 0.5896  data_time: 0.2768  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:15:52 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 4879  total_loss: 1.586  loss_cls: 0.3744  loss_box_reg: 0.5314  loss_mask: 0.3035  loss_rpn_cls: 0.08763  loss_rpn_loc: 0.2124  time: 0.5894  data_time: 0.2130  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:16:08 d2.utils.events]: \u001b[0m eta: 0:29:09  iter: 4899  total_loss: 1.499  loss_cls: 0.3487  loss_box_reg: 0.4928  loss_mask: 0.3073  loss_rpn_cls: 0.09905  loss_rpn_loc: 0.2104  time: 0.5901  data_time: 0.4413  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:16:19 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 4919  total_loss: 1.489  loss_cls: 0.3243  loss_box_reg: 0.5236  loss_mask: 0.2953  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.2077  time: 0.5900  data_time: 0.2339  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:16:31 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 4939  total_loss: 1.556  loss_cls: 0.3524  loss_box_reg: 0.5612  loss_mask: 0.3483  loss_rpn_cls: 0.101  loss_rpn_loc: 0.2142  time: 0.5900  data_time: 0.2654  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:16:41 d2.utils.events]: \u001b[0m eta: 0:28:49  iter: 4959  total_loss: 1.478  loss_cls: 0.3283  loss_box_reg: 0.5664  loss_mask: 0.3091  loss_rpn_cls: 0.06459  loss_rpn_loc: 0.1838  time: 0.5897  data_time: 0.2055  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:16:50 d2.utils.events]: \u001b[0m eta: 0:28:43  iter: 4979  total_loss: 1.502  loss_cls: 0.3426  loss_box_reg: 0.5252  loss_mask: 0.2928  loss_rpn_cls: 0.06376  loss_rpn_loc: 0.1927  time: 0.5892  data_time: 0.1488  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:17:01 d2.utils.events]: \u001b[0m eta: 0:28:37  iter: 4999  total_loss: 1.358  loss_cls: 0.2853  loss_box_reg: 0.5016  loss_mask: 0.2998  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.2008  time: 0.5891  data_time: 0.2359  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:17:11 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 5019  total_loss: 1.436  loss_cls: 0.3232  loss_box_reg: 0.522  loss_mask: 0.3106  loss_rpn_cls: 0.07804  loss_rpn_loc: 0.1989  time: 0.5886  data_time: 0.1494  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:17:26 d2.utils.events]: \u001b[0m eta: 0:28:23  iter: 5039  total_loss: 1.535  loss_cls: 0.3659  loss_box_reg: 0.4975  loss_mask: 0.3171  loss_rpn_cls: 0.1232  loss_rpn_loc: 0.2134  time: 0.5894  data_time: 0.4408  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:17:37 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 5059  total_loss: 1.367  loss_cls: 0.3093  loss_box_reg: 0.5196  loss_mask: 0.3027  loss_rpn_cls: 0.06003  loss_rpn_loc: 0.1896  time: 0.5891  data_time: 0.2112  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:17:52 d2.utils.events]: \u001b[0m eta: 0:28:07  iter: 5079  total_loss: 1.464  loss_cls: 0.3379  loss_box_reg: 0.5091  loss_mask: 0.3026  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.2149  time: 0.5897  data_time: 0.4117  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:17:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:17:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:17:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:17:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:17:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:17:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0110 s/iter. Total: 0.0819 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0727 s/iter. Eval: 0.0154 s/iter. Total: 0.0888 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:18:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.410145 (0.089743 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:18:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072800 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:18:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:18:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2499022410832936\n",
      "\u001b[32m[01/10 16:18:17 d2.utils.events]: \u001b[0m eta: 0:28:00  iter: 5099  total_loss: 1.428  loss_cls: 0.3119  loss_box_reg: 0.5054  loss_mask: 0.3087  loss_rpn_cls: 0.07959  loss_rpn_loc: 0.1988  time: 0.5900  data_time: 0.3383  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:18:30 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 5119  total_loss: 1.411  loss_cls: 0.29  loss_box_reg: 0.4917  loss_mask: 0.306  loss_rpn_cls: 0.07099  loss_rpn_loc: 0.1962  time: 0.5902  data_time: 0.3292  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:18:41 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 5139  total_loss: 1.389  loss_cls: 0.288  loss_box_reg: 0.5185  loss_mask: 0.2975  loss_rpn_cls: 0.08837  loss_rpn_loc: 0.2027  time: 0.5901  data_time: 0.2524  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:18:50 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 5159  total_loss: 1.442  loss_cls: 0.352  loss_box_reg: 0.5445  loss_mask: 0.3145  loss_rpn_cls: 0.07269  loss_rpn_loc: 0.2032  time: 0.5896  data_time: 0.1643  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:19:00 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 5179  total_loss: 1.478  loss_cls: 0.3456  loss_box_reg: 0.5089  loss_mask: 0.3187  loss_rpn_cls: 0.0812  loss_rpn_loc: 0.2015  time: 0.5892  data_time: 0.1800  lr: 0.0005  max_mem: 6357M\n",
      "\u001b[32m[01/10 16:19:14 d2.utils.events]: \u001b[0m eta: 0:27:16  iter: 5199  total_loss: 1.554  loss_cls: 0.336  loss_box_reg: 0.5306  loss_mask: 0.3017  loss_rpn_cls: 0.116  loss_rpn_loc: 0.2103  time: 0.5896  data_time: 0.3556  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:19:23 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 5219  total_loss: 1.277  loss_cls: 0.2693  loss_box_reg: 0.4973  loss_mask: 0.287  loss_rpn_cls: 0.05988  loss_rpn_loc: 0.1957  time: 0.5891  data_time: 0.1635  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:19:35 d2.utils.events]: \u001b[0m eta: 0:26:54  iter: 5239  total_loss: 1.377  loss_cls: 0.2862  loss_box_reg: 0.5015  loss_mask: 0.2989  loss_rpn_cls: 0.06838  loss_rpn_loc: 0.1767  time: 0.5892  data_time: 0.3098  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:19:44 d2.utils.events]: \u001b[0m eta: 0:26:41  iter: 5259  total_loss: 1.559  loss_cls: 0.3765  loss_box_reg: 0.5351  loss_mask: 0.3086  loss_rpn_cls: 0.08872  loss_rpn_loc: 0.2117  time: 0.5887  data_time: 0.1477  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:19:55 d2.utils.events]: \u001b[0m eta: 0:26:30  iter: 5279  total_loss: 1.439  loss_cls: 0.3156  loss_box_reg: 0.5303  loss_mask: 0.3062  loss_rpn_cls: 0.09437  loss_rpn_loc: 0.202  time: 0.5885  data_time: 0.2145  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:20:11 d2.utils.events]: \u001b[0m eta: 0:26:22  iter: 5299  total_loss: 1.546  loss_cls: 0.3859  loss_box_reg: 0.5322  loss_mask: 0.3072  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.2218  time: 0.5893  data_time: 0.5012  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:20:29 d2.utils.events]: \u001b[0m eta: 0:26:22  iter: 5319  total_loss: 1.553  loss_cls: 0.3584  loss_box_reg: 0.5344  loss_mask: 0.3268  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.2248  time: 0.5904  data_time: 0.5221  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:20:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:20:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:20:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:20:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:20:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:20:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0110 s/iter. Total: 0.0822 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0727 s/iter. Eval: 0.0158 s/iter. Total: 0.0892 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:20:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.469458 (0.090254 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:20:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072853 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:20:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25307961406508706\n",
      "\u001b[32m[01/10 16:20:50 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 5339  total_loss: 1.377  loss_cls: 0.2977  loss_box_reg: 0.4966  loss_mask: 0.2881  loss_rpn_cls: 0.04879  loss_rpn_loc: 0.179  time: 0.5900  data_time: 0.1744  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:21:04 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 5359  total_loss: 1.509  loss_cls: 0.3182  loss_box_reg: 0.5273  loss_mask: 0.3232  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.2264  time: 0.5903  data_time: 0.3607  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:21:18 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 5379  total_loss: 1.503  loss_cls: 0.3544  loss_box_reg: 0.508  loss_mask: 0.3072  loss_rpn_cls: 0.08936  loss_rpn_loc: 0.2155  time: 0.5907  data_time: 0.3659  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:21:28 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 5399  total_loss: 1.381  loss_cls: 0.2983  loss_box_reg: 0.538  loss_mask: 0.3065  loss_rpn_cls: 0.06722  loss_rpn_loc: 0.1755  time: 0.5904  data_time: 0.2061  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:21:40 d2.utils.events]: \u001b[0m eta: 0:25:49  iter: 5419  total_loss: 1.493  loss_cls: 0.3449  loss_box_reg: 0.5496  loss_mask: 0.301  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.2058  time: 0.5904  data_time: 0.2594  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:21:52 d2.utils.events]: \u001b[0m eta: 0:25:43  iter: 5439  total_loss: 1.526  loss_cls: 0.3543  loss_box_reg: 0.5509  loss_mask: 0.3097  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.2007  time: 0.5906  data_time: 0.3100  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:22:05 d2.utils.events]: \u001b[0m eta: 0:25:35  iter: 5459  total_loss: 1.357  loss_cls: 0.3003  loss_box_reg: 0.5026  loss_mask: 0.2964  loss_rpn_cls: 0.07714  loss_rpn_loc: 0.2007  time: 0.5907  data_time: 0.3314  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:22:18 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 5479  total_loss: 1.622  loss_cls: 0.3687  loss_box_reg: 0.5325  loss_mask: 0.3243  loss_rpn_cls: 0.1176  loss_rpn_loc: 0.2267  time: 0.5909  data_time: 0.3192  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:22:28 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 5499  total_loss: 1.39  loss_cls: 0.2771  loss_box_reg: 0.5109  loss_mask: 0.2995  loss_rpn_cls: 0.07323  loss_rpn_loc: 0.186  time: 0.5906  data_time: 0.1933  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:22:40 d2.utils.events]: \u001b[0m eta: 0:25:16  iter: 5519  total_loss: 1.414  loss_cls: 0.3015  loss_box_reg: 0.4944  loss_mask: 0.301  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.2004  time: 0.5906  data_time: 0.2809  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:22:50 d2.utils.events]: \u001b[0m eta: 0:25:07  iter: 5539  total_loss: 1.477  loss_cls: 0.329  loss_box_reg: 0.5477  loss_mask: 0.322  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1865  time: 0.5904  data_time: 0.2173  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:23:02 d2.utils.events]: \u001b[0m eta: 0:24:58  iter: 5559  total_loss: 1.523  loss_cls: 0.3666  loss_box_reg: 0.5608  loss_mask: 0.308  loss_rpn_cls: 0.07752  loss_rpn_loc: 0.2177  time: 0.5905  data_time: 0.3002  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:23:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:23:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:23:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:23:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:23:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:23:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0698 s/iter. Eval: 0.0094 s/iter. Total: 0.0797 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0722 s/iter. Eval: 0.0150 s/iter. Total: 0.0880 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:23:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.471136 (0.090268 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:23:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072693 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:23:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:23:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25468571106784277\n",
      "\u001b[32m[01/10 16:23:25 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 5579  total_loss: 1.362  loss_cls: 0.28  loss_box_reg: 0.491  loss_mask: 0.298  loss_rpn_cls: 0.06265  loss_rpn_loc: 0.1859  time: 0.5902  data_time: 0.2065  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:23:34 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 5599  total_loss: 1.551  loss_cls: 0.3731  loss_box_reg: 0.5069  loss_mask: 0.3043  loss_rpn_cls: 0.08404  loss_rpn_loc: 0.2156  time: 0.5898  data_time: 0.1659  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:23:46 d2.utils.events]: \u001b[0m eta: 0:24:34  iter: 5619  total_loss: 1.515  loss_cls: 0.353  loss_box_reg: 0.5159  loss_mask: 0.3201  loss_rpn_cls: 0.07941  loss_rpn_loc: 0.2037  time: 0.5897  data_time: 0.2315  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:23:59 d2.utils.events]: \u001b[0m eta: 0:24:27  iter: 5639  total_loss: 1.447  loss_cls: 0.3265  loss_box_reg: 0.4907  loss_mask: 0.322  loss_rpn_cls: 0.07888  loss_rpn_loc: 0.1835  time: 0.5900  data_time: 0.3465  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:24:15 d2.utils.events]: \u001b[0m eta: 0:24:21  iter: 5659  total_loss: 1.472  loss_cls: 0.3259  loss_box_reg: 0.5106  loss_mask: 0.3024  loss_rpn_cls: 0.09879  loss_rpn_loc: 0.2225  time: 0.5907  data_time: 0.4588  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:24:26 d2.utils.events]: \u001b[0m eta: 0:24:13  iter: 5679  total_loss: 1.462  loss_cls: 0.3394  loss_box_reg: 0.5309  loss_mask: 0.2927  loss_rpn_cls: 0.08055  loss_rpn_loc: 0.2064  time: 0.5906  data_time: 0.2327  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:24:35 d2.utils.events]: \u001b[0m eta: 0:24:05  iter: 5699  total_loss: 1.379  loss_cls: 0.2848  loss_box_reg: 0.5533  loss_mask: 0.2882  loss_rpn_cls: 0.0755  loss_rpn_loc: 0.1897  time: 0.5901  data_time: 0.1447  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:24:47 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 5719  total_loss: 1.418  loss_cls: 0.3378  loss_box_reg: 0.5025  loss_mask: 0.3012  loss_rpn_cls: 0.0639  loss_rpn_loc: 0.206  time: 0.5902  data_time: 0.3113  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:25:00 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 5739  total_loss: 1.461  loss_cls: 0.3865  loss_box_reg: 0.5109  loss_mask: 0.3043  loss_rpn_cls: 0.08139  loss_rpn_loc: 0.1948  time: 0.5904  data_time: 0.3300  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:25:10 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 5759  total_loss: 1.509  loss_cls: 0.3536  loss_box_reg: 0.5406  loss_mask: 0.311  loss_rpn_cls: 0.09173  loss_rpn_loc: 0.2171  time: 0.5901  data_time: 0.1923  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:25:20 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 5779  total_loss: 1.399  loss_cls: 0.356  loss_box_reg: 0.4949  loss_mask: 0.2978  loss_rpn_cls: 0.08026  loss_rpn_loc: 0.1994  time: 0.5897  data_time: 0.1768  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:25:33 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 5799  total_loss: 1.471  loss_cls: 0.347  loss_box_reg: 0.5113  loss_mask: 0.3068  loss_rpn_cls: 0.07712  loss_rpn_loc: 0.1829  time: 0.5899  data_time: 0.2991  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:25:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:25:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:25:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:25:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:25:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:25:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0701 s/iter. Eval: 0.0112 s/iter. Total: 0.0819 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0142 s/iter. Total: 0.0867 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:25:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.183489 (0.087789 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:25:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071913 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:25:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:25:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23920795509871332\n",
      "\u001b[32m[01/10 16:25:56 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 5819  total_loss: 1.472  loss_cls: 0.351  loss_box_reg: 0.5013  loss_mask: 0.3154  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.2252  time: 0.5898  data_time: 0.2661  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:26:10 d2.utils.events]: \u001b[0m eta: 0:23:17  iter: 5839  total_loss: 1.544  loss_cls: 0.3431  loss_box_reg: 0.5072  loss_mask: 0.308  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.2152  time: 0.5903  data_time: 0.4007  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:26:25 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 5859  total_loss: 1.457  loss_cls: 0.3396  loss_box_reg: 0.5062  loss_mask: 0.3064  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.2182  time: 0.5908  data_time: 0.4081  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:26:35 d2.utils.events]: \u001b[0m eta: 0:23:06  iter: 5879  total_loss: 1.393  loss_cls: 0.3064  loss_box_reg: 0.5454  loss_mask: 0.3054  loss_rpn_cls: 0.07819  loss_rpn_loc: 0.1935  time: 0.5905  data_time: 0.1810  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:26:48 d2.utils.events]: \u001b[0m eta: 0:22:58  iter: 5899  total_loss: 1.408  loss_cls: 0.3043  loss_box_reg: 0.4887  loss_mask: 0.2928  loss_rpn_cls: 0.08461  loss_rpn_loc: 0.1923  time: 0.5906  data_time: 0.3325  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:27:00 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 5919  total_loss: 1.473  loss_cls: 0.3106  loss_box_reg: 0.5033  loss_mask: 0.3044  loss_rpn_cls: 0.08529  loss_rpn_loc: 0.1836  time: 0.5907  data_time: 0.2791  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:27:11 d2.utils.events]: \u001b[0m eta: 0:22:45  iter: 5939  total_loss: 1.489  loss_cls: 0.3119  loss_box_reg: 0.4899  loss_mask: 0.3165  loss_rpn_cls: 0.09166  loss_rpn_loc: 0.2107  time: 0.5907  data_time: 0.2672  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:27:24 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 5959  total_loss: 1.478  loss_cls: 0.3428  loss_box_reg: 0.5239  loss_mask: 0.2922  loss_rpn_cls: 0.07667  loss_rpn_loc: 0.2071  time: 0.5909  data_time: 0.3277  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:27:37 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 5979  total_loss: 1.537  loss_cls: 0.3668  loss_box_reg: 0.5282  loss_mask: 0.3077  loss_rpn_cls: 0.1176  loss_rpn_loc: 0.2287  time: 0.5910  data_time: 0.2998  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:27:48 d2.utils.events]: \u001b[0m eta: 0:22:28  iter: 5999  total_loss: 1.456  loss_cls: 0.3561  loss_box_reg: 0.5151  loss_mask: 0.291  loss_rpn_cls: 0.07599  loss_rpn_loc: 0.2042  time: 0.5909  data_time: 0.2515  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:27:59 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 6019  total_loss: 1.498  loss_cls: 0.3734  loss_box_reg: 0.5483  loss_mask: 0.3083  loss_rpn_cls: 0.08269  loss_rpn_loc: 0.1902  time: 0.5908  data_time: 0.2367  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:28:08 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 6039  total_loss: 1.46  loss_cls: 0.338  loss_box_reg: 0.5365  loss_mask: 0.3151  loss_rpn_cls: 0.06182  loss_rpn_loc: 0.1861  time: 0.5903  data_time: 0.1382  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:28:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:28:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:28:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:28:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:28:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:28:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0693 s/iter. Eval: 0.0096 s/iter. Total: 0.0795 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:28:20 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0007 s/iter. Inference: 0.0718 s/iter. Eval: 0.0142 s/iter. Total: 0.0867 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:28:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.196126 (0.087898 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:28:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:28:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:28:24 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2536940409201285\n",
      "\u001b[32m[01/10 16:28:28 d2.utils.events]: \u001b[0m eta: 0:22:03  iter: 6059  total_loss: 1.36  loss_cls: 0.3251  loss_box_reg: 0.5188  loss_mask: 0.2888  loss_rpn_cls: 0.05694  loss_rpn_loc: 0.1703  time: 0.5898  data_time: 0.1369  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:28:41 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 6079  total_loss: 1.408  loss_cls: 0.3282  loss_box_reg: 0.4862  loss_mask: 0.3006  loss_rpn_cls: 0.07301  loss_rpn_loc: 0.1975  time: 0.5899  data_time: 0.3180  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:28:54 d2.utils.events]: \u001b[0m eta: 0:21:45  iter: 6099  total_loss: 1.438  loss_cls: 0.3185  loss_box_reg: 0.4941  loss_mask: 0.2899  loss_rpn_cls: 0.08273  loss_rpn_loc: 0.1851  time: 0.5900  data_time: 0.2992  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:29:07 d2.utils.events]: \u001b[0m eta: 0:21:39  iter: 6119  total_loss: 1.468  loss_cls: 0.3309  loss_box_reg: 0.5199  loss_mask: 0.2983  loss_rpn_cls: 0.09647  loss_rpn_loc: 0.2021  time: 0.5903  data_time: 0.3307  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:29:18 d2.utils.events]: \u001b[0m eta: 0:21:31  iter: 6139  total_loss: 1.358  loss_cls: 0.303  loss_box_reg: 0.5163  loss_mask: 0.3007  loss_rpn_cls: 0.06906  loss_rpn_loc: 0.1959  time: 0.5902  data_time: 0.2540  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:29:32 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 6159  total_loss: 1.527  loss_cls: 0.3618  loss_box_reg: 0.5022  loss_mask: 0.3096  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.197  time: 0.5905  data_time: 0.3812  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:29:45 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 6179  total_loss: 1.419  loss_cls: 0.3267  loss_box_reg: 0.4809  loss_mask: 0.3087  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2019  time: 0.5907  data_time: 0.3279  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:29:56 d2.utils.events]: \u001b[0m eta: 0:21:17  iter: 6199  total_loss: 1.526  loss_cls: 0.3529  loss_box_reg: 0.5296  loss_mask: 0.3066  loss_rpn_cls: 0.08448  loss_rpn_loc: 0.2087  time: 0.5905  data_time: 0.2210  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:30:03 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 6219  total_loss: 1.441  loss_cls: 0.3483  loss_box_reg: 0.5305  loss_mask: 0.2876  loss_rpn_cls: 0.06964  loss_rpn_loc: 0.1957  time: 0.5898  data_time: 0.0781  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:30:16 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 6239  total_loss: 1.54  loss_cls: 0.3758  loss_box_reg: 0.5099  loss_mask: 0.3079  loss_rpn_cls: 0.09336  loss_rpn_loc: 0.2172  time: 0.5900  data_time: 0.3180  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:30:29 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 6259  total_loss: 1.416  loss_cls: 0.3049  loss_box_reg: 0.5161  loss_mask: 0.2922  loss_rpn_cls: 0.08085  loss_rpn_loc: 0.1946  time: 0.5901  data_time: 0.3131  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:30:43 d2.utils.events]: \u001b[0m eta: 0:20:54  iter: 6279  total_loss: 1.377  loss_cls: 0.2944  loss_box_reg: 0.4864  loss_mask: 0.3  loss_rpn_cls: 0.07407  loss_rpn_loc: 0.2012  time: 0.5905  data_time: 0.3755  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:30:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:30:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:30:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:30:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:30:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:30:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:30:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0701 s/iter. Eval: 0.0104 s/iter. Total: 0.0810 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:30:58 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0145 s/iter. Total: 0.0872 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:31:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.243162 (0.088303 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:31:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072101 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:31:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:31:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2503940534022265\n",
      "\u001b[32m[01/10 16:31:05 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 6299  total_loss: 1.424  loss_cls: 0.3172  loss_box_reg: 0.5113  loss_mask: 0.3047  loss_rpn_cls: 0.06781  loss_rpn_loc: 0.1966  time: 0.5904  data_time: 0.2414  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:31:19 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 6319  total_loss: 1.489  loss_cls: 0.3529  loss_box_reg: 0.5095  loss_mask: 0.3194  loss_rpn_cls: 0.08682  loss_rpn_loc: 0.2004  time: 0.5907  data_time: 0.3761  lr: 0.0005  max_mem: 6519M\n",
      "\u001b[32m[01/10 16:31:35 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 6339  total_loss: 1.468  loss_cls: 0.3054  loss_box_reg: 0.5139  loss_mask: 0.2988  loss_rpn_cls: 0.09317  loss_rpn_loc: 0.2055  time: 0.5913  data_time: 0.4271  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:31:45 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 6359  total_loss: 1.454  loss_cls: 0.3411  loss_box_reg: 0.535  loss_mask: 0.2968  loss_rpn_cls: 0.07648  loss_rpn_loc: 0.1978  time: 0.5911  data_time: 0.2270  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:31:59 d2.utils.events]: \u001b[0m eta: 0:20:20  iter: 6379  total_loss: 1.349  loss_cls: 0.287  loss_box_reg: 0.5045  loss_mask: 0.2798  loss_rpn_cls: 0.08754  loss_rpn_loc: 0.1857  time: 0.5914  data_time: 0.3603  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:32:09 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 6399  total_loss: 1.549  loss_cls: 0.3075  loss_box_reg: 0.554  loss_mask: 0.3205  loss_rpn_cls: 0.0803  loss_rpn_loc: 0.2069  time: 0.5911  data_time: 0.2074  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:32:20 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 6419  total_loss: 1.419  loss_cls: 0.3269  loss_box_reg: 0.5194  loss_mask: 0.3071  loss_rpn_cls: 0.06621  loss_rpn_loc: 0.1869  time: 0.5909  data_time: 0.2005  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:32:33 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 6439  total_loss: 1.392  loss_cls: 0.2971  loss_box_reg: 0.5187  loss_mask: 0.3101  loss_rpn_cls: 0.09383  loss_rpn_loc: 0.2094  time: 0.5911  data_time: 0.3437  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:32:48 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 6459  total_loss: 1.479  loss_cls: 0.3154  loss_box_reg: 0.5359  loss_mask: 0.3017  loss_rpn_cls: 0.09974  loss_rpn_loc: 0.1993  time: 0.5917  data_time: 0.4353  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:32:58 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 6479  total_loss: 1.415  loss_cls: 0.2875  loss_box_reg: 0.5294  loss_mask: 0.2976  loss_rpn_cls: 0.07654  loss_rpn_loc: 0.1949  time: 0.5914  data_time: 0.1841  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:33:09 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 6499  total_loss: 1.414  loss_cls: 0.3276  loss_box_reg: 0.5151  loss_mask: 0.2935  loss_rpn_cls: 0.08463  loss_rpn_loc: 0.2038  time: 0.5912  data_time: 0.2330  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:33:19 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 6519  total_loss: 1.509  loss_cls: 0.3857  loss_box_reg: 0.5463  loss_mask: 0.3004  loss_rpn_cls: 0.04912  loss_rpn_loc: 0.1882  time: 0.5910  data_time: 0.1888  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:33:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:33:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:33:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:33:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:33:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:33:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:33:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0698 s/iter. Eval: 0.0105 s/iter. Total: 0.0809 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0146 s/iter. Total: 0.0873 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:33:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.238791 (0.088265 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:33:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072048 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:33:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:33:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2416046560174159\n",
      "\u001b[32m[01/10 16:33:39 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 6539  total_loss: 1.485  loss_cls: 0.3503  loss_box_reg: 0.5603  loss_mask: 0.3013  loss_rpn_cls: 0.07903  loss_rpn_loc: 0.2065  time: 0.5905  data_time: 0.1373  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:33:52 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 6559  total_loss: 1.449  loss_cls: 0.3535  loss_box_reg: 0.5234  loss_mask: 0.3103  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.2118  time: 0.5906  data_time: 0.3239  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:34:03 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 6579  total_loss: 1.489  loss_cls: 0.332  loss_box_reg: 0.5244  loss_mask: 0.3049  loss_rpn_cls: 0.09201  loss_rpn_loc: 0.2058  time: 0.5905  data_time: 0.2367  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:34:16 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 6599  total_loss: 1.435  loss_cls: 0.3115  loss_box_reg: 0.4994  loss_mask: 0.2909  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.1915  time: 0.5907  data_time: 0.3452  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:34:27 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 6619  total_loss: 1.358  loss_cls: 0.2994  loss_box_reg: 0.5054  loss_mask: 0.2921  loss_rpn_cls: 0.06015  loss_rpn_loc: 0.1684  time: 0.5905  data_time: 0.2143  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:34:38 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 6639  total_loss: 1.638  loss_cls: 0.3677  loss_box_reg: 0.57  loss_mask: 0.3158  loss_rpn_cls: 0.08771  loss_rpn_loc: 0.2053  time: 0.5904  data_time: 0.2491  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:34:54 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 6659  total_loss: 1.498  loss_cls: 0.3222  loss_box_reg: 0.4875  loss_mask: 0.3155  loss_rpn_cls: 0.06435  loss_rpn_loc: 0.2121  time: 0.5910  data_time: 0.4621  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:35:07 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 6679  total_loss: 1.557  loss_cls: 0.3536  loss_box_reg: 0.5057  loss_mask: 0.3161  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.2165  time: 0.5912  data_time: 0.3165  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:35:18 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 6699  total_loss: 1.423  loss_cls: 0.352  loss_box_reg: 0.5096  loss_mask: 0.3011  loss_rpn_cls: 0.06641  loss_rpn_loc: 0.1962  time: 0.5911  data_time: 0.2475  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:35:29 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 6719  total_loss: 1.344  loss_cls: 0.3095  loss_box_reg: 0.5031  loss_mask: 0.3008  loss_rpn_cls: 0.07695  loss_rpn_loc: 0.1962  time: 0.5909  data_time: 0.2195  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:35:42 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 6739  total_loss: 1.449  loss_cls: 0.3127  loss_box_reg: 0.5244  loss_mask: 0.2873  loss_rpn_cls: 0.07661  loss_rpn_loc: 0.2066  time: 0.5911  data_time: 0.3277  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:35:52 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 6759  total_loss: 1.423  loss_cls: 0.311  loss_box_reg: 0.5435  loss_mask: 0.2964  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.1947  time: 0.5908  data_time: 0.1933  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:36:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:36:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:36:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:36:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:36:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:36:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0696 s/iter. Eval: 0.0100 s/iter. Total: 0.0802 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0721 s/iter. Eval: 0.0154 s/iter. Total: 0.0883 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:36:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.473730 (0.090291 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:36:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072685 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:36:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:36:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24977043451524245\n",
      "\u001b[32m[01/10 16:36:15 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 6779  total_loss: 1.444  loss_cls: 0.311  loss_box_reg: 0.515  loss_mask: 0.3004  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.1912  time: 0.5908  data_time: 0.2850  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:36:26 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 6799  total_loss: 1.351  loss_cls: 0.274  loss_box_reg: 0.5147  loss_mask: 0.295  loss_rpn_cls: 0.04919  loss_rpn_loc: 0.1837  time: 0.5906  data_time: 0.2024  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:36:38 d2.utils.events]: \u001b[0m eta: 0:17:52  iter: 6819  total_loss: 1.386  loss_cls: 0.3256  loss_box_reg: 0.489  loss_mask: 0.2854  loss_rpn_cls: 0.07551  loss_rpn_loc: 0.2034  time: 0.5906  data_time: 0.2823  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:36:48 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 6839  total_loss: 1.443  loss_cls: 0.3332  loss_box_reg: 0.5131  loss_mask: 0.3123  loss_rpn_cls: 0.07987  loss_rpn_loc: 0.1894  time: 0.5904  data_time: 0.2121  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:37:02 d2.utils.events]: \u001b[0m eta: 0:17:33  iter: 6859  total_loss: 1.464  loss_cls: 0.3395  loss_box_reg: 0.4873  loss_mask: 0.3029  loss_rpn_cls: 0.08282  loss_rpn_loc: 0.2087  time: 0.5907  data_time: 0.3479  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:37:15 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 6879  total_loss: 1.434  loss_cls: 0.3198  loss_box_reg: 0.5082  loss_mask: 0.3141  loss_rpn_cls: 0.09078  loss_rpn_loc: 0.211  time: 0.5909  data_time: 0.3552  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:37:26 d2.utils.events]: \u001b[0m eta: 0:17:24  iter: 6899  total_loss: 1.388  loss_cls: 0.2818  loss_box_reg: 0.5083  loss_mask: 0.2972  loss_rpn_cls: 0.09133  loss_rpn_loc: 0.1868  time: 0.5908  data_time: 0.2400  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:37:38 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 6919  total_loss: 1.346  loss_cls: 0.3138  loss_box_reg: 0.5284  loss_mask: 0.3041  loss_rpn_cls: 0.06544  loss_rpn_loc: 0.1982  time: 0.5908  data_time: 0.2603  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:37:50 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 6939  total_loss: 1.399  loss_cls: 0.3305  loss_box_reg: 0.5124  loss_mask: 0.2921  loss_rpn_cls: 0.08085  loss_rpn_loc: 0.198  time: 0.5909  data_time: 0.3200  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:38:00 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 6959  total_loss: 1.456  loss_cls: 0.3376  loss_box_reg: 0.5527  loss_mask: 0.3089  loss_rpn_cls: 0.07437  loss_rpn_loc: 0.1959  time: 0.5906  data_time: 0.1687  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:38:10 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 6979  total_loss: 1.393  loss_cls: 0.3186  loss_box_reg: 0.4893  loss_mask: 0.3  loss_rpn_cls: 0.06257  loss_rpn_loc: 0.1837  time: 0.5903  data_time: 0.1760  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:38:21 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 6999  total_loss: 1.546  loss_cls: 0.3415  loss_box_reg: 0.5259  loss_mask: 0.3128  loss_rpn_cls: 0.08698  loss_rpn_loc: 0.2077  time: 0.5903  data_time: 0.2758  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:38:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:38:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:38:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:38:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:38:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:38:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:38:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0700 s/iter. Eval: 0.0106 s/iter. Total: 0.0811 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:38:38 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0725 s/iter. Eval: 0.0157 s/iter. Total: 0.0889 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:38:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.536688 (0.090834 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:38:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072992 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:38:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:38:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2575798355084428\n",
      "\u001b[32m[01/10 16:38:44 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 7019  total_loss: 1.42  loss_cls: 0.3078  loss_box_reg: 0.5292  loss_mask: 0.3044  loss_rpn_cls: 0.07103  loss_rpn_loc: 0.1987  time: 0.5901  data_time: 0.2219  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:38:55 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 7039  total_loss: 1.4  loss_cls: 0.3148  loss_box_reg: 0.5092  loss_mask: 0.2948  loss_rpn_cls: 0.07636  loss_rpn_loc: 0.2119  time: 0.5901  data_time: 0.2434  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:39:08 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 7059  total_loss: 1.449  loss_cls: 0.3448  loss_box_reg: 0.5075  loss_mask: 0.3065  loss_rpn_cls: 0.08147  loss_rpn_loc: 0.2168  time: 0.5901  data_time: 0.2898  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:39:20 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 7079  total_loss: 1.408  loss_cls: 0.3261  loss_box_reg: 0.5011  loss_mask: 0.2877  loss_rpn_cls: 0.08545  loss_rpn_loc: 0.191  time: 0.5902  data_time: 0.2854  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:39:31 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 7099  total_loss: 1.386  loss_cls: 0.3227  loss_box_reg: 0.5224  loss_mask: 0.2955  loss_rpn_cls: 0.08778  loss_rpn_loc: 0.1969  time: 0.5901  data_time: 0.2365  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:39:41 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 7119  total_loss: 1.422  loss_cls: 0.3082  loss_box_reg: 0.514  loss_mask: 0.2871  loss_rpn_cls: 0.05026  loss_rpn_loc: 0.1883  time: 0.5898  data_time: 0.1967  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:39:54 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 7139  total_loss: 1.534  loss_cls: 0.395  loss_box_reg: 0.5108  loss_mask: 0.2997  loss_rpn_cls: 0.08949  loss_rpn_loc: 0.2012  time: 0.5900  data_time: 0.3211  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:40:08 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 7159  total_loss: 1.512  loss_cls: 0.3383  loss_box_reg: 0.4983  loss_mask: 0.3163  loss_rpn_cls: 0.09988  loss_rpn_loc: 0.221  time: 0.5903  data_time: 0.3631  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:40:22 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 7179  total_loss: 1.477  loss_cls: 0.3161  loss_box_reg: 0.4869  loss_mask: 0.3092  loss_rpn_cls: 0.09069  loss_rpn_loc: 0.2096  time: 0.5906  data_time: 0.3667  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:40:32 d2.utils.events]: \u001b[0m eta: 0:15:39  iter: 7199  total_loss: 1.371  loss_cls: 0.3089  loss_box_reg: 0.5334  loss_mask: 0.3075  loss_rpn_cls: 0.05312  loss_rpn_loc: 0.1892  time: 0.5904  data_time: 0.1845  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:40:41 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 7219  total_loss: 1.352  loss_cls: 0.2804  loss_box_reg: 0.5239  loss_mask: 0.3027  loss_rpn_cls: 0.07383  loss_rpn_loc: 0.1844  time: 0.5900  data_time: 0.1641  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:40:53 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 7239  total_loss: 1.461  loss_cls: 0.34  loss_box_reg: 0.5282  loss_mask: 0.3063  loss_rpn_cls: 0.07965  loss_rpn_loc: 0.1905  time: 0.5900  data_time: 0.2475  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:41:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:41:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:41:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:41:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:41:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:41:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0752 s/iter. Eval: 0.0106 s/iter. Total: 0.0864 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:41:11 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0749 s/iter. Eval: 0.0156 s/iter. Total: 0.0913 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 16:41:16 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0746 s/iter. Eval: 0.0159 s/iter. Total: 0.0913 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 16:41:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.659683 (0.091894 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:41:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074589 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:41:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:41:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25589041163480686\n",
      "\u001b[32m[01/10 16:41:16 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 7259  total_loss: 1.392  loss_cls: 0.3087  loss_box_reg: 0.5167  loss_mask: 0.2991  loss_rpn_cls: 0.07865  loss_rpn_loc: 0.1925  time: 0.5899  data_time: 0.2372  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:41:26 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 7279  total_loss: 1.492  loss_cls: 0.3518  loss_box_reg: 0.5315  loss_mask: 0.3072  loss_rpn_cls: 0.0596  loss_rpn_loc: 0.2099  time: 0.5896  data_time: 0.1521  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:41:38 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 7299  total_loss: 1.552  loss_cls: 0.3686  loss_box_reg: 0.544  loss_mask: 0.3213  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.2281  time: 0.5897  data_time: 0.2959  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:41:49 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 7319  total_loss: 1.39  loss_cls: 0.3251  loss_box_reg: 0.5081  loss_mask: 0.3026  loss_rpn_cls: 0.07677  loss_rpn_loc: 0.1957  time: 0.5896  data_time: 0.2283  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:41:59 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 7339  total_loss: 1.468  loss_cls: 0.3496  loss_box_reg: 0.5418  loss_mask: 0.31  loss_rpn_cls: 0.07989  loss_rpn_loc: 0.197  time: 0.5892  data_time: 0.1388  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:42:09 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 7359  total_loss: 1.401  loss_cls: 0.2973  loss_box_reg: 0.4999  loss_mask: 0.306  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.1898  time: 0.5891  data_time: 0.2279  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:42:23 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 7379  total_loss: 1.438  loss_cls: 0.3187  loss_box_reg: 0.4844  loss_mask: 0.3097  loss_rpn_cls: 0.04158  loss_rpn_loc: 0.1994  time: 0.5894  data_time: 0.3578  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:42:38 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 7399  total_loss: 1.501  loss_cls: 0.3137  loss_box_reg: 0.5185  loss_mask: 0.2989  loss_rpn_cls: 0.07647  loss_rpn_loc: 0.206  time: 0.5899  data_time: 0.4185  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:42:50 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 7419  total_loss: 1.534  loss_cls: 0.3339  loss_box_reg: 0.5215  loss_mask: 0.3321  loss_rpn_cls: 0.09664  loss_rpn_loc: 0.2126  time: 0.5899  data_time: 0.2912  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:43:02 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 7439  total_loss: 1.406  loss_cls: 0.3445  loss_box_reg: 0.5548  loss_mask: 0.305  loss_rpn_cls: 0.07299  loss_rpn_loc: 0.2022  time: 0.5899  data_time: 0.2590  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:43:13 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 7459  total_loss: 1.296  loss_cls: 0.2768  loss_box_reg: 0.4905  loss_mask: 0.2841  loss_rpn_cls: 0.05988  loss_rpn_loc: 0.1785  time: 0.5897  data_time: 0.2202  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:43:23 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 7479  total_loss: 1.399  loss_cls: 0.2999  loss_box_reg: 0.4956  loss_mask: 0.302  loss_rpn_cls: 0.08096  loss_rpn_loc: 0.2126  time: 0.5895  data_time: 0.2157  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:43:35 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 7499  total_loss: 1.438  loss_cls: 0.3462  loss_box_reg: 0.5351  loss_mask: 0.3101  loss_rpn_cls: 0.08993  loss_rpn_loc: 0.2046  time: 0.5896  data_time: 0.2956  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:43:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:43:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:43:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:43:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:43:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:43:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0101 s/iter. Total: 0.0809 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/10 16:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0732 s/iter. Eval: 0.0143 s/iter. Total: 0.0883 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:43:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.439230 (0.089993 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:43:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073832 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:43:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:43:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2414552894592201\n",
      "\u001b[32m[01/10 16:44:00 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 7519  total_loss: 1.514  loss_cls: 0.3269  loss_box_reg: 0.5146  loss_mask: 0.3096  loss_rpn_cls: 0.08679  loss_rpn_loc: 0.2008  time: 0.5898  data_time: 0.3270  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:44:11 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 7539  total_loss: 1.433  loss_cls: 0.3119  loss_box_reg: 0.5549  loss_mask: 0.3106  loss_rpn_cls: 0.06663  loss_rpn_loc: 0.1959  time: 0.5896  data_time: 0.1989  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:44:24 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 7559  total_loss: 1.398  loss_cls: 0.3254  loss_box_reg: 0.4887  loss_mask: 0.3031  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.1944  time: 0.5899  data_time: 0.3438  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:44:38 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 7579  total_loss: 1.347  loss_cls: 0.2834  loss_box_reg: 0.5001  loss_mask: 0.3061  loss_rpn_cls: 0.05458  loss_rpn_loc: 0.1783  time: 0.5900  data_time: 0.3424  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:44:46 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 7599  total_loss: 1.467  loss_cls: 0.3565  loss_box_reg: 0.5383  loss_mask: 0.3076  loss_rpn_cls: 0.08378  loss_rpn_loc: 0.2108  time: 0.5896  data_time: 0.1050  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:44:57 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 7619  total_loss: 1.343  loss_cls: 0.2611  loss_box_reg: 0.4965  loss_mask: 0.2987  loss_rpn_cls: 0.07567  loss_rpn_loc: 0.1845  time: 0.5894  data_time: 0.2178  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:45:06 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 7639  total_loss: 1.331  loss_cls: 0.3317  loss_box_reg: 0.5112  loss_mask: 0.3009  loss_rpn_cls: 0.05527  loss_rpn_loc: 0.184  time: 0.5890  data_time: 0.1402  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:45:18 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 7659  total_loss: 1.394  loss_cls: 0.3278  loss_box_reg: 0.5124  loss_mask: 0.3036  loss_rpn_cls: 0.08704  loss_rpn_loc: 0.2032  time: 0.5892  data_time: 0.3018  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:45:30 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 7679  total_loss: 1.363  loss_cls: 0.2947  loss_box_reg: 0.5246  loss_mask: 0.2975  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.1941  time: 0.5892  data_time: 0.2806  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:45:45 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 7699  total_loss: 1.449  loss_cls: 0.3282  loss_box_reg: 0.4975  loss_mask: 0.3142  loss_rpn_cls: 0.07813  loss_rpn_loc: 0.2039  time: 0.5896  data_time: 0.3968  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:45:55 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 7719  total_loss: 1.468  loss_cls: 0.3196  loss_box_reg: 0.5117  loss_mask: 0.2986  loss_rpn_cls: 0.06334  loss_rpn_loc: 0.2047  time: 0.5893  data_time: 0.1650  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:46:09 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 7739  total_loss: 1.509  loss_cls: 0.3117  loss_box_reg: 0.5181  loss_mask: 0.3159  loss_rpn_cls: 0.09519  loss_rpn_loc: 0.2151  time: 0.5897  data_time: 0.3931  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:46:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:46:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:46:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:46:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:46:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:46:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0719 s/iter. Eval: 0.0114 s/iter. Total: 0.0839 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0161 s/iter. Total: 0.0905 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0007 s/iter. Inference: 0.0747 s/iter. Eval: 0.0165 s/iter. Total: 0.0920 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 16:46:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.754681 (0.092713 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:46:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074705 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:46:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:46:22 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2527621915908485\n",
      "\u001b[32m[01/10 16:46:31 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 7759  total_loss: 1.357  loss_cls: 0.2895  loss_box_reg: 0.5041  loss_mask: 0.295  loss_rpn_cls: 0.04758  loss_rpn_loc: 0.1733  time: 0.5894  data_time: 0.1512  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:46:44 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 7779  total_loss: 1.434  loss_cls: 0.3436  loss_box_reg: 0.4889  loss_mask: 0.3136  loss_rpn_cls: 0.07482  loss_rpn_loc: 0.2023  time: 0.5896  data_time: 0.3544  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:46:54 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 7799  total_loss: 1.369  loss_cls: 0.3258  loss_box_reg: 0.5272  loss_mask: 0.2904  loss_rpn_cls: 0.07039  loss_rpn_loc: 0.1874  time: 0.5893  data_time: 0.1652  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:47:08 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 7819  total_loss: 1.495  loss_cls: 0.3623  loss_box_reg: 0.5066  loss_mask: 0.3013  loss_rpn_cls: 0.07672  loss_rpn_loc: 0.2293  time: 0.5896  data_time: 0.3799  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:47:20 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 7839  total_loss: 1.374  loss_cls: 0.3229  loss_box_reg: 0.5144  loss_mask: 0.3089  loss_rpn_cls: 0.08012  loss_rpn_loc: 0.2004  time: 0.5897  data_time: 0.2826  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:47:31 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 7859  total_loss: 1.366  loss_cls: 0.3124  loss_box_reg: 0.4879  loss_mask: 0.281  loss_rpn_cls: 0.07819  loss_rpn_loc: 0.1926  time: 0.5895  data_time: 0.1984  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:47:42 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 7879  total_loss: 1.553  loss_cls: 0.3689  loss_box_reg: 0.5438  loss_mask: 0.31  loss_rpn_cls: 0.08742  loss_rpn_loc: 0.1972  time: 0.5895  data_time: 0.2680  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:47:54 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 7899  total_loss: 1.437  loss_cls: 0.3289  loss_box_reg: 0.5035  loss_mask: 0.3069  loss_rpn_cls: 0.08783  loss_rpn_loc: 0.2022  time: 0.5895  data_time: 0.2714  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:48:05 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 7919  total_loss: 1.432  loss_cls: 0.3104  loss_box_reg: 0.4881  loss_mask: 0.3017  loss_rpn_cls: 0.06325  loss_rpn_loc: 0.1869  time: 0.5894  data_time: 0.2401  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:48:15 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 7939  total_loss: 1.344  loss_cls: 0.3237  loss_box_reg: 0.4969  loss_mask: 0.2829  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.1736  time: 0.5891  data_time: 0.1581  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:48:28 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 7959  total_loss: 1.322  loss_cls: 0.2787  loss_box_reg: 0.4975  loss_mask: 0.2928  loss_rpn_cls: 0.07272  loss_rpn_loc: 0.178  time: 0.5893  data_time: 0.3287  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:48:41 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 7979  total_loss: 1.409  loss_cls: 0.3296  loss_box_reg: 0.4787  loss_mask: 0.3064  loss_rpn_cls: 0.08337  loss_rpn_loc: 0.1904  time: 0.5895  data_time: 0.3509  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:48:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:48:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:48:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:48:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:48:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:48:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0701 s/iter. Eval: 0.0110 s/iter. Total: 0.0819 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:48:52 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0153 s/iter. Total: 0.0887 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:48:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.423365 (0.089857 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:48:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072870 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:48:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:48:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2483854032797831\n",
      "\u001b[32m[01/10 16:49:03 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 7999  total_loss: 1.38  loss_cls: 0.2862  loss_box_reg: 0.4913  loss_mask: 0.2984  loss_rpn_cls: 0.06436  loss_rpn_loc: 0.2007  time: 0.5892  data_time: 0.1510  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:49:16 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 8019  total_loss: 1.4  loss_cls: 0.3099  loss_box_reg: 0.5077  loss_mask: 0.3063  loss_rpn_cls: 0.06965  loss_rpn_loc: 0.1874  time: 0.5894  data_time: 0.3575  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:49:30 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 8039  total_loss: 1.536  loss_cls: 0.3592  loss_box_reg: 0.5184  loss_mask: 0.3121  loss_rpn_cls: 0.08973  loss_rpn_loc: 0.2107  time: 0.5896  data_time: 0.3515  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:49:41 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 8059  total_loss: 1.376  loss_cls: 0.2811  loss_box_reg: 0.501  loss_mask: 0.3166  loss_rpn_cls: 0.07532  loss_rpn_loc: 0.1961  time: 0.5896  data_time: 0.2617  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:49:50 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 8079  total_loss: 1.383  loss_cls: 0.346  loss_box_reg: 0.4816  loss_mask: 0.2984  loss_rpn_cls: 0.06788  loss_rpn_loc: 0.1761  time: 0.5892  data_time: 0.0954  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:50:04 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 8099  total_loss: 1.315  loss_cls: 0.2616  loss_box_reg: 0.4762  loss_mask: 0.2993  loss_rpn_cls: 0.06867  loss_rpn_loc: 0.1936  time: 0.5894  data_time: 0.3758  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:50:14 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 8119  total_loss: 1.4  loss_cls: 0.2948  loss_box_reg: 0.536  loss_mask: 0.2866  loss_rpn_cls: 0.06609  loss_rpn_loc: 0.1889  time: 0.5892  data_time: 0.2054  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:50:30 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 8139  total_loss: 1.435  loss_cls: 0.3319  loss_box_reg: 0.503  loss_mask: 0.2969  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.2069  time: 0.5897  data_time: 0.4435  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:50:40 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 8159  total_loss: 1.505  loss_cls: 0.3398  loss_box_reg: 0.5029  loss_mask: 0.2992  loss_rpn_cls: 0.08692  loss_rpn_loc: 0.2065  time: 0.5895  data_time: 0.1769  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:50:55 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 8179  total_loss: 1.435  loss_cls: 0.2849  loss_box_reg: 0.503  loss_mask: 0.3012  loss_rpn_cls: 0.09995  loss_rpn_loc: 0.1886  time: 0.5900  data_time: 0.4371  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:51:06 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 8199  total_loss: 1.375  loss_cls: 0.3425  loss_box_reg: 0.5178  loss_mask: 0.3079  loss_rpn_cls: 0.0702  loss_rpn_loc: 0.1856  time: 0.5898  data_time: 0.2081  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:51:16 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 8219  total_loss: 1.496  loss_cls: 0.3447  loss_box_reg: 0.5408  loss_mask: 0.3051  loss_rpn_cls: 0.07947  loss_rpn_loc: 0.1934  time: 0.5897  data_time: 0.2020  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:51:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:51:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:51:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:51:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:51:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:51:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:51:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0710 s/iter. Eval: 0.0126 s/iter. Total: 0.0845 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0723 s/iter. Eval: 0.0145 s/iter. Total: 0.0875 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:51:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.313977 (0.088914 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:51:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072629 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:51:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:51:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24716700341782114\n",
      "\u001b[32m[01/10 16:51:38 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 8239  total_loss: 1.486  loss_cls: 0.3566  loss_box_reg: 0.5384  loss_mask: 0.3107  loss_rpn_cls: 0.08909  loss_rpn_loc: 0.1918  time: 0.5895  data_time: 0.1971  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:51:50 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 8259  total_loss: 1.443  loss_cls: 0.3461  loss_box_reg: 0.5314  loss_mask: 0.2945  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.1966  time: 0.5895  data_time: 0.2716  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:52:05 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 8279  total_loss: 1.45  loss_cls: 0.3412  loss_box_reg: 0.4989  loss_mask: 0.3116  loss_rpn_cls: 0.09388  loss_rpn_loc: 0.2196  time: 0.5899  data_time: 0.4206  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:52:18 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 8299  total_loss: 1.431  loss_cls: 0.2864  loss_box_reg: 0.5283  loss_mask: 0.3066  loss_rpn_cls: 0.0693  loss_rpn_loc: 0.1985  time: 0.5901  data_time: 0.3289  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:52:31 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 8319  total_loss: 1.394  loss_cls: 0.2984  loss_box_reg: 0.485  loss_mask: 0.3008  loss_rpn_cls: 0.06913  loss_rpn_loc: 0.2036  time: 0.5902  data_time: 0.3382  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:52:42 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 8339  total_loss: 1.428  loss_cls: 0.3254  loss_box_reg: 0.5245  loss_mask: 0.2824  loss_rpn_cls: 0.07468  loss_rpn_loc: 0.1895  time: 0.5900  data_time: 0.1988  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:52:52 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 8359  total_loss: 1.483  loss_cls: 0.3602  loss_box_reg: 0.5342  loss_mask: 0.302  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.2115  time: 0.5899  data_time: 0.2121  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:53:04 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 8379  total_loss: 1.367  loss_cls: 0.3066  loss_box_reg: 0.4811  loss_mask: 0.3091  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.207  time: 0.5899  data_time: 0.2568  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:53:15 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 8399  total_loss: 1.364  loss_cls: 0.3169  loss_box_reg: 0.5084  loss_mask: 0.2884  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.1795  time: 0.5898  data_time: 0.2569  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:53:28 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 8419  total_loss: 1.579  loss_cls: 0.3345  loss_box_reg: 0.5671  loss_mask: 0.3274  loss_rpn_cls: 0.0744  loss_rpn_loc: 0.2114  time: 0.5900  data_time: 0.3120  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:53:41 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 8439  total_loss: 1.46  loss_cls: 0.3213  loss_box_reg: 0.5076  loss_mask: 0.2844  loss_rpn_cls: 0.07734  loss_rpn_loc: 0.2034  time: 0.5901  data_time: 0.3029  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:53:52 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 8459  total_loss: 1.387  loss_cls: 0.3263  loss_box_reg: 0.4775  loss_mask: 0.3108  loss_rpn_cls: 0.08137  loss_rpn_loc: 0.178  time: 0.5900  data_time: 0.2308  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:53:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:53:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:53:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:53:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:53:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:53:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:53:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0708 s/iter. Eval: 0.0122 s/iter. Total: 0.0838 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:54:03 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0008 s/iter. Inference: 0.0730 s/iter. Eval: 0.0154 s/iter. Total: 0.0892 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:54:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.495896 (0.090482 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:54:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073294 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:54:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:54:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2564021089101537\n",
      "\u001b[32m[01/10 16:54:12 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 8479  total_loss: 1.419  loss_cls: 0.2941  loss_box_reg: 0.5536  loss_mask: 0.2939  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.1861  time: 0.5895  data_time: 0.1168  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:54:22 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 8499  total_loss: 1.328  loss_cls: 0.3118  loss_box_reg: 0.5023  loss_mask: 0.3008  loss_rpn_cls: 0.07037  loss_rpn_loc: 0.1708  time: 0.5893  data_time: 0.1830  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:54:34 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 8519  total_loss: 1.281  loss_cls: 0.2913  loss_box_reg: 0.4782  loss_mask: 0.2852  loss_rpn_cls: 0.08047  loss_rpn_loc: 0.1875  time: 0.5893  data_time: 0.2646  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:54:42 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 8539  total_loss: 1.365  loss_cls: 0.3237  loss_box_reg: 0.5137  loss_mask: 0.2832  loss_rpn_cls: 0.06134  loss_rpn_loc: 0.1713  time: 0.5890  data_time: 0.1215  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:54:55 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 8559  total_loss: 1.461  loss_cls: 0.3344  loss_box_reg: 0.516  loss_mask: 0.3025  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.2041  time: 0.5890  data_time: 0.2743  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:55:06 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 8579  total_loss: 1.343  loss_cls: 0.29  loss_box_reg: 0.5155  loss_mask: 0.285  loss_rpn_cls: 0.06646  loss_rpn_loc: 0.1864  time: 0.5890  data_time: 0.2814  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:55:18 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 8599  total_loss: 1.415  loss_cls: 0.303  loss_box_reg: 0.5189  loss_mask: 0.3018  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.1977  time: 0.5890  data_time: 0.2440  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:55:27 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 8619  total_loss: 1.398  loss_cls: 0.3039  loss_box_reg: 0.526  loss_mask: 0.3078  loss_rpn_cls: 0.0661  loss_rpn_loc: 0.1874  time: 0.5887  data_time: 0.1649  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:55:37 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 8639  total_loss: 1.404  loss_cls: 0.2917  loss_box_reg: 0.5225  loss_mask: 0.3002  loss_rpn_cls: 0.06062  loss_rpn_loc: 0.1946  time: 0.5885  data_time: 0.1882  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:55:49 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 8659  total_loss: 1.392  loss_cls: 0.3015  loss_box_reg: 0.515  loss_mask: 0.3017  loss_rpn_cls: 0.06967  loss_rpn_loc: 0.1814  time: 0.5885  data_time: 0.2701  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:56:02 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 8679  total_loss: 1.412  loss_cls: 0.328  loss_box_reg: 0.5223  loss_mask: 0.3147  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.2175  time: 0.5886  data_time: 0.2900  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:56:13 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 8699  total_loss: 1.456  loss_cls: 0.3187  loss_box_reg: 0.5286  loss_mask: 0.3053  loss_rpn_cls: 0.04788  loss_rpn_loc: 0.1999  time: 0.5886  data_time: 0.2423  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:56:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:56:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:56:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:56:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:56:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:56:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0705 s/iter. Eval: 0.0118 s/iter. Total: 0.0830 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0154 s/iter. Total: 0.0887 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 16:56:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.524517 (0.090729 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:56:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073279 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:56:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:56:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2591903713471597\n",
      "\u001b[32m[01/10 16:56:43 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 8719  total_loss: 1.379  loss_cls: 0.3214  loss_box_reg: 0.508  loss_mask: 0.3025  loss_rpn_cls: 0.09303  loss_rpn_loc: 0.2112  time: 0.5893  data_time: 0.5582  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:56:56 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 8739  total_loss: 1.551  loss_cls: 0.3572  loss_box_reg: 0.5299  loss_mask: 0.2921  loss_rpn_cls: 0.09378  loss_rpn_loc: 0.2121  time: 0.5894  data_time: 0.2995  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:57:07 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 8759  total_loss: 1.523  loss_cls: 0.3445  loss_box_reg: 0.5555  loss_mask: 0.3221  loss_rpn_cls: 0.07807  loss_rpn_loc: 0.2036  time: 0.5893  data_time: 0.2509  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:57:19 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 8779  total_loss: 1.396  loss_cls: 0.3219  loss_box_reg: 0.525  loss_mask: 0.283  loss_rpn_cls: 0.07209  loss_rpn_loc: 0.1915  time: 0.5894  data_time: 0.2892  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:57:33 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 8799  total_loss: 1.344  loss_cls: 0.2878  loss_box_reg: 0.4975  loss_mask: 0.293  loss_rpn_cls: 0.05764  loss_rpn_loc: 0.1981  time: 0.5896  data_time: 0.3872  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:57:43 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 8819  total_loss: 1.261  loss_cls: 0.279  loss_box_reg: 0.4835  loss_mask: 0.2766  loss_rpn_cls: 0.06381  loss_rpn_loc: 0.1979  time: 0.5894  data_time: 0.1748  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:57:55 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 8839  total_loss: 1.388  loss_cls: 0.2904  loss_box_reg: 0.4755  loss_mask: 0.3017  loss_rpn_cls: 0.08712  loss_rpn_loc: 0.1949  time: 0.5894  data_time: 0.2664  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:58:05 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 8859  total_loss: 1.461  loss_cls: 0.3294  loss_box_reg: 0.5194  loss_mask: 0.3074  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.2072  time: 0.5892  data_time: 0.1952  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:58:16 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 8879  total_loss: 1.416  loss_cls: 0.3287  loss_box_reg: 0.5199  loss_mask: 0.3163  loss_rpn_cls: 0.06613  loss_rpn_loc: 0.1869  time: 0.5892  data_time: 0.2671  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:58:27 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 8899  total_loss: 1.358  loss_cls: 0.2901  loss_box_reg: 0.5083  loss_mask: 0.2762  loss_rpn_cls: 0.05869  loss_rpn_loc: 0.1846  time: 0.5891  data_time: 0.2223  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:58:39 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 8919  total_loss: 1.354  loss_cls: 0.3152  loss_box_reg: 0.4729  loss_mask: 0.2804  loss_rpn_cls: 0.0754  loss_rpn_loc: 0.1823  time: 0.5891  data_time: 0.2846  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:58:50 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 8939  total_loss: 1.368  loss_cls: 0.3074  loss_box_reg: 0.492  loss_mask: 0.3147  loss_rpn_cls: 0.08823  loss_rpn_loc: 0.1951  time: 0.5889  data_time: 0.1815  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:58:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:58:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 16:58:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 16:58:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 16:58:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 16:58:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 16:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0756 s/iter. Eval: 0.0133 s/iter. Total: 0.0896 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 16:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0180 s/iter. Total: 0.0968 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 16:59:11 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0788 s/iter. Eval: 0.0181 s/iter. Total: 0.0978 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 16:59:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.411486 (0.098375 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:59:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078898 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 16:59:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 16:59:12 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2544396616159681\n",
      "\u001b[32m[01/10 16:59:15 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 8959  total_loss: 1.435  loss_cls: 0.3047  loss_box_reg: 0.5196  loss_mask: 0.3023  loss_rpn_cls: 0.09432  loss_rpn_loc: 0.1908  time: 0.5890  data_time: 0.2690  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:59:26 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 8979  total_loss: 1.286  loss_cls: 0.2847  loss_box_reg: 0.4756  loss_mask: 0.2814  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.1746  time: 0.5890  data_time: 0.2500  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:59:42 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 8999  total_loss: 1.382  loss_cls: 0.3058  loss_box_reg: 0.4835  loss_mask: 0.301  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2057  time: 0.5894  data_time: 0.4318  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 16:59:52 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 9019  total_loss: 1.377  loss_cls: 0.3371  loss_box_reg: 0.5167  loss_mask: 0.2996  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.1698  time: 0.5893  data_time: 0.1856  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:00:06 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 9039  total_loss: 1.434  loss_cls: 0.3219  loss_box_reg: 0.5069  loss_mask: 0.3136  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.1964  time: 0.5894  data_time: 0.3294  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:00:14 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 9059  total_loss: 1.42  loss_cls: 0.324  loss_box_reg: 0.531  loss_mask: 0.2978  loss_rpn_cls: 0.0617  loss_rpn_loc: 0.203  time: 0.5890  data_time: 0.1039  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:00:29 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 9079  total_loss: 1.337  loss_cls: 0.2908  loss_box_reg: 0.4745  loss_mask: 0.3071  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.198  time: 0.5894  data_time: 0.4166  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:00:43 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 9099  total_loss: 1.336  loss_cls: 0.291  loss_box_reg: 0.4722  loss_mask: 0.2919  loss_rpn_cls: 0.07443  loss_rpn_loc: 0.1854  time: 0.5897  data_time: 0.4029  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:00:57 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 9119  total_loss: 1.415  loss_cls: 0.3197  loss_box_reg: 0.4964  loss_mask: 0.2957  loss_rpn_cls: 0.06399  loss_rpn_loc: 0.196  time: 0.5899  data_time: 0.3493  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:01:11 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 9139  total_loss: 1.456  loss_cls: 0.3446  loss_box_reg: 0.5083  loss_mask: 0.3054  loss_rpn_cls: 0.07925  loss_rpn_loc: 0.1979  time: 0.5901  data_time: 0.3555  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:01:25 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 9159  total_loss: 1.43  loss_cls: 0.3138  loss_box_reg: 0.5082  loss_mask: 0.298  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.2012  time: 0.5903  data_time: 0.3561  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:01:36 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 9179  total_loss: 1.26  loss_cls: 0.2772  loss_box_reg: 0.5152  loss_mask: 0.2885  loss_rpn_cls: 0.04069  loss_rpn_loc: 0.178  time: 0.5902  data_time: 0.2416  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:01:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:01:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:01:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:01:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:01:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:01:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:01:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0750 s/iter. Eval: 0.0119 s/iter. Total: 0.0876 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:01:53 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0770 s/iter. Eval: 0.0181 s/iter. Total: 0.0960 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0765 s/iter. Eval: 0.0180 s/iter. Total: 0.0954 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:01:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.117500 (0.095841 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:01:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076466 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:01:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:01:58 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2603586455342648\n",
      "\u001b[32m[01/10 17:02:00 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 9199  total_loss: 1.38  loss_cls: 0.3291  loss_box_reg: 0.5242  loss_mask: 0.3027  loss_rpn_cls: 0.06718  loss_rpn_loc: 0.1868  time: 0.5902  data_time: 0.2491  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:02:11 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 9219  total_loss: 1.437  loss_cls: 0.2978  loss_box_reg: 0.5358  loss_mask: 0.305  loss_rpn_cls: 0.07518  loss_rpn_loc: 0.2069  time: 0.5902  data_time: 0.2580  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:02:22 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 9239  total_loss: 1.331  loss_cls: 0.3002  loss_box_reg: 0.4793  loss_mask: 0.2848  loss_rpn_cls: 0.06224  loss_rpn_loc: 0.1879  time: 0.5901  data_time: 0.2294  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:02:37 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 9259  total_loss: 1.436  loss_cls: 0.3237  loss_box_reg: 0.4827  loss_mask: 0.2903  loss_rpn_cls: 0.08073  loss_rpn_loc: 0.2009  time: 0.5904  data_time: 0.4222  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:02:54 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 9279  total_loss: 1.365  loss_cls: 0.3093  loss_box_reg: 0.4896  loss_mask: 0.2933  loss_rpn_cls: 0.09227  loss_rpn_loc: 0.2009  time: 0.5909  data_time: 0.4649  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:03:05 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 9299  total_loss: 1.365  loss_cls: 0.3288  loss_box_reg: 0.4798  loss_mask: 0.2871  loss_rpn_cls: 0.07332  loss_rpn_loc: 0.1922  time: 0.5909  data_time: 0.2404  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:03:15 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 9319  total_loss: 1.433  loss_cls: 0.3099  loss_box_reg: 0.5031  loss_mask: 0.311  loss_rpn_cls: 0.0584  loss_rpn_loc: 0.189  time: 0.5907  data_time: 0.1858  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:03:29 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 9339  total_loss: 1.438  loss_cls: 0.3355  loss_box_reg: 0.5102  loss_mask: 0.3104  loss_rpn_cls: 0.08866  loss_rpn_loc: 0.1995  time: 0.5909  data_time: 0.3704  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:03:44 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 9359  total_loss: 1.424  loss_cls: 0.3295  loss_box_reg: 0.5296  loss_mask: 0.3024  loss_rpn_cls: 0.07421  loss_rpn_loc: 0.1986  time: 0.5912  data_time: 0.4054  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:03:56 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 9379  total_loss: 1.411  loss_cls: 0.2885  loss_box_reg: 0.5053  loss_mask: 0.307  loss_rpn_cls: 0.04447  loss_rpn_loc: 0.1898  time: 0.5913  data_time: 0.2939  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:04:13 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 9399  total_loss: 1.417  loss_cls: 0.3338  loss_box_reg: 0.5088  loss_mask: 0.3187  loss_rpn_cls: 0.09006  loss_rpn_loc: 0.2065  time: 0.5918  data_time: 0.5143  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:04:26 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9419  total_loss: 1.404  loss_cls: 0.3094  loss_box_reg: 0.5022  loss_mask: 0.2912  loss_rpn_cls: 0.07619  loss_rpn_loc: 0.2  time: 0.5919  data_time: 0.3155  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:04:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:04:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:04:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:04:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:04:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:04:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0729 s/iter. Eval: 0.0124 s/iter. Total: 0.0860 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0008 s/iter. Inference: 0.0736 s/iter. Eval: 0.0155 s/iter. Total: 0.0899 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 17:04:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.557964 (0.091017 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:04:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073712 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:04:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:04:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2525323867886177\n",
      "\u001b[32m[01/10 17:04:48 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9439  total_loss: 1.313  loss_cls: 0.2889  loss_box_reg: 0.5152  loss_mask: 0.2883  loss_rpn_cls: 0.04938  loss_rpn_loc: 0.1691  time: 0.5917  data_time: 0.1671  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:05:01 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 9459  total_loss: 1.428  loss_cls: 0.3217  loss_box_reg: 0.482  loss_mask: 0.3089  loss_rpn_cls: 0.08146  loss_rpn_loc: 0.1956  time: 0.5918  data_time: 0.3354  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:05:12 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 9479  total_loss: 1.366  loss_cls: 0.2918  loss_box_reg: 0.5159  loss_mask: 0.2924  loss_rpn_cls: 0.05895  loss_rpn_loc: 0.1896  time: 0.5918  data_time: 0.2330  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:05:26 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 9499  total_loss: 1.33  loss_cls: 0.3071  loss_box_reg: 0.4734  loss_mask: 0.2802  loss_rpn_cls: 0.0859  loss_rpn_loc: 0.1793  time: 0.5920  data_time: 0.3661  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:05:43 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 9519  total_loss: 1.503  loss_cls: 0.3568  loss_box_reg: 0.5051  loss_mask: 0.319  loss_rpn_cls: 0.09956  loss_rpn_loc: 0.2279  time: 0.5925  data_time: 0.4918  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:05:55 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 9539  total_loss: 1.353  loss_cls: 0.3148  loss_box_reg: 0.492  loss_mask: 0.2927  loss_rpn_cls: 0.07474  loss_rpn_loc: 0.1727  time: 0.5925  data_time: 0.2758  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:06:06 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 9559  total_loss: 1.491  loss_cls: 0.3377  loss_box_reg: 0.542  loss_mask: 0.3034  loss_rpn_cls: 0.0806  loss_rpn_loc: 0.2077  time: 0.5925  data_time: 0.2533  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:06:19 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 9579  total_loss: 1.391  loss_cls: 0.3047  loss_box_reg: 0.4911  loss_mask: 0.3094  loss_rpn_cls: 0.07769  loss_rpn_loc: 0.2051  time: 0.5926  data_time: 0.3388  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:06:35 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 9599  total_loss: 1.338  loss_cls: 0.2772  loss_box_reg: 0.5087  loss_mask: 0.306  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.1896  time: 0.5930  data_time: 0.4491  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:06:48 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 9619  total_loss: 1.493  loss_cls: 0.3243  loss_box_reg: 0.5176  loss_mask: 0.316  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.2223  time: 0.5932  data_time: 0.3436  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:07:00 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 9639  total_loss: 1.346  loss_cls: 0.3024  loss_box_reg: 0.4711  loss_mask: 0.2789  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.1827  time: 0.5931  data_time: 0.2442  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:07:10 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 9659  total_loss: 1.329  loss_cls: 0.2699  loss_box_reg: 0.4909  loss_mask: 0.3058  loss_rpn_cls: 0.08025  loss_rpn_loc: 0.1855  time: 0.5930  data_time: 0.1938  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:07:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:07:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:07:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:07:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:07:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:07:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0754 s/iter. Eval: 0.0128 s/iter. Total: 0.0890 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0776 s/iter. Eval: 0.0174 s/iter. Total: 0.0959 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0768 s/iter. Eval: 0.0173 s/iter. Total: 0.0950 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:07:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.101431 (0.095702 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:07:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076886 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:07:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:07:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25717202259727817\n",
      "\u001b[32m[01/10 17:07:32 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 9679  total_loss: 1.436  loss_cls: 0.3233  loss_box_reg: 0.5283  loss_mask: 0.2971  loss_rpn_cls: 0.05548  loss_rpn_loc: 0.1987  time: 0.5928  data_time: 0.1670  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:07:44 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 9699  total_loss: 1.323  loss_cls: 0.3188  loss_box_reg: 0.4823  loss_mask: 0.2819  loss_rpn_cls: 0.05583  loss_rpn_loc: 0.1834  time: 0.5927  data_time: 0.2404  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:07:55 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 9719  total_loss: 1.271  loss_cls: 0.264  loss_box_reg: 0.4735  loss_mask: 0.2732  loss_rpn_cls: 0.04421  loss_rpn_loc: 0.1528  time: 0.5927  data_time: 0.2623  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:08:05 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 9739  total_loss: 1.263  loss_cls: 0.2686  loss_box_reg: 0.5058  loss_mask: 0.293  loss_rpn_cls: 0.05112  loss_rpn_loc: 0.1763  time: 0.5924  data_time: 0.1677  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:08:17 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 9759  total_loss: 1.404  loss_cls: 0.2897  loss_box_reg: 0.4941  loss_mask: 0.3149  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.2085  time: 0.5924  data_time: 0.2643  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:08:28 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 9779  total_loss: 1.536  loss_cls: 0.3794  loss_box_reg: 0.488  loss_mask: 0.3017  loss_rpn_cls: 0.0638  loss_rpn_loc: 0.1859  time: 0.5924  data_time: 0.2451  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:08:42 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 9799  total_loss: 1.456  loss_cls: 0.3062  loss_box_reg: 0.4972  loss_mask: 0.3034  loss_rpn_cls: 0.08011  loss_rpn_loc: 0.207  time: 0.5925  data_time: 0.3299  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:08:58 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 9819  total_loss: 1.463  loss_cls: 0.3549  loss_box_reg: 0.5109  loss_mask: 0.3052  loss_rpn_cls: 0.09986  loss_rpn_loc: 0.2146  time: 0.5931  data_time: 0.5104  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:09:09 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 9839  total_loss: 1.318  loss_cls: 0.2757  loss_box_reg: 0.5087  loss_mask: 0.297  loss_rpn_cls: 0.06728  loss_rpn_loc: 0.1776  time: 0.5929  data_time: 0.2072  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:09:23 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 9859  total_loss: 1.456  loss_cls: 0.3649  loss_box_reg: 0.5422  loss_mask: 0.3017  loss_rpn_cls: 0.09625  loss_rpn_loc: 0.2184  time: 0.5931  data_time: 0.3575  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:09:36 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 9879  total_loss: 1.392  loss_cls: 0.3184  loss_box_reg: 0.4812  loss_mask: 0.2986  loss_rpn_cls: 0.07295  loss_rpn_loc: 0.201  time: 0.5933  data_time: 0.3415  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:09:50 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 9899  total_loss: 1.427  loss_cls: 0.3206  loss_box_reg: 0.4979  loss_mask: 0.3091  loss_rpn_cls: 0.07051  loss_rpn_loc: 0.206  time: 0.5935  data_time: 0.3698  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:10:05 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 9919  total_loss: 1.404  loss_cls: 0.3024  loss_box_reg: 0.5132  loss_mask: 0.2905  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.1933  time: 0.5938  data_time: 0.4042  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:10:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:10:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:10:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:10:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:10:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:10:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0740 s/iter. Eval: 0.0139 s/iter. Total: 0.0886 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0748 s/iter. Eval: 0.0172 s/iter. Total: 0.0929 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:10:18 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0170 s/iter. Total: 0.0924 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:10:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.810525 (0.093194 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:10:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074517 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:10:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:10:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25108789354132194\n",
      "\u001b[32m[01/10 17:10:27 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 9939  total_loss: 1.34  loss_cls: 0.2742  loss_box_reg: 0.5032  loss_mask: 0.2971  loss_rpn_cls: 0.0574  loss_rpn_loc: 0.1781  time: 0.5935  data_time: 0.1434  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:10:40 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 9959  total_loss: 1.374  loss_cls: 0.3147  loss_box_reg: 0.4749  loss_mask: 0.3062  loss_rpn_cls: 0.07451  loss_rpn_loc: 0.2107  time: 0.5937  data_time: 0.3162  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:10:55 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 9979  total_loss: 1.43  loss_cls: 0.3027  loss_box_reg: 0.5064  loss_mask: 0.3079  loss_rpn_cls: 0.08921  loss_rpn_loc: 0.2038  time: 0.5940  data_time: 0.4205  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:11:07 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.39  loss_cls: 0.2872  loss_box_reg: 0.4708  loss_mask: 0.2967  loss_rpn_cls: 0.08186  loss_rpn_loc: 0.2006  time: 0.5940  data_time: 0.2650  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:11:07 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:38:58 (0.5940 s / it)\n",
      "\u001b[32m[01/10 17:11:07 d2.engine.hooks]: \u001b[0mTotal training time: 1:47:00 (0:08:02 on hooks)\n",
      "\u001b[32m[01/10 17:11:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:11:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:11:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:11:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:11:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:11:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:11:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0728 s/iter. Eval: 0.0125 s/iter. Total: 0.0860 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0759 s/iter. Eval: 0.0185 s/iter. Total: 0.0952 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0756 s/iter. Eval: 0.0178 s/iter. Total: 0.0943 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:11:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.011900 (0.094930 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:11:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:11:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:11:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2515005784631531\n"
     ]
    }
   ],
   "source": [
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e50e30c-531e-49c1-bed9-8bf643133f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/10 17:13:04 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/10 17:13:05 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[01/10 17:13:06 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[01/10 17:13:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/10 17:13:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/10 17:13:06 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:13:06 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[01/10 17:13:06 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n",
      "\u001b[32m[01/10 17:13:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 10000\n",
      "\u001b[32m[01/10 17:13:20 d2.utils.events]: \u001b[0m eta: 1:25:10  iter: 10019  total_loss: 1.402  loss_cls: 0.3113  loss_box_reg: 0.4604  loss_mask: 0.2995  loss_rpn_cls: 0.09901  loss_rpn_loc: 0.2184  time: 0.7075  data_time: 0.3967  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:13:35 d2.utils.events]: \u001b[0m eta: 1:03:44  iter: 10039  total_loss: 1.395  loss_cls: 0.2898  loss_box_reg: 0.4452  loss_mask: 0.3091  loss_rpn_cls: 0.09071  loss_rpn_loc: 0.2109  time: 0.7304  data_time: 0.4043  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:13:51 d2.utils.events]: \u001b[0m eta: 1:02:23  iter: 10059  total_loss: 1.372  loss_cls: 0.2828  loss_box_reg: 0.5335  loss_mask: 0.2995  loss_rpn_cls: 0.06593  loss_rpn_loc: 0.195  time: 0.7523  data_time: 0.4573  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:14:02 d2.utils.events]: \u001b[0m eta: 0:59:59  iter: 10079  total_loss: 1.326  loss_cls: 0.2885  loss_box_reg: 0.4864  loss_mask: 0.315  loss_rpn_cls: 0.06128  loss_rpn_loc: 0.1937  time: 0.6974  data_time: 0.2236  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:14:12 d2.utils.events]: \u001b[0m eta: 0:57:36  iter: 10099  total_loss: 1.495  loss_cls: 0.3664  loss_box_reg: 0.5145  loss_mask: 0.3077  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.1885  time: 0.6596  data_time: 0.1957  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:14:29 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 10119  total_loss: 1.444  loss_cls: 0.3354  loss_box_reg: 0.5225  loss_mask: 0.3075  loss_rpn_cls: 0.09881  loss_rpn_loc: 0.2004  time: 0.6895  data_time: 0.5009  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:14:40 d2.utils.events]: \u001b[0m eta: 0:59:04  iter: 10139  total_loss: 1.474  loss_cls: 0.3626  loss_box_reg: 0.5189  loss_mask: 0.3167  loss_rpn_cls: 0.06535  loss_rpn_loc: 0.1908  time: 0.6679  data_time: 0.2195  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:14:51 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 10159  total_loss: 1.331  loss_cls: 0.298  loss_box_reg: 0.4902  loss_mask: 0.2866  loss_rpn_cls: 0.07116  loss_rpn_loc: 0.1935  time: 0.6561  data_time: 0.2605  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:14:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:14:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:14:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:14:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:14:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:14:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:14:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0721 s/iter. Eval: 0.0142 s/iter. Total: 0.0870 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0747 s/iter. Eval: 0.0175 s/iter. Total: 0.0930 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:15:06 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0744 s/iter. Eval: 0.0174 s/iter. Total: 0.0927 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:15:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.842368 (0.093469 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:15:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074486 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:15:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:15:06 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2583163827062144\n",
      "\u001b[32m[01/10 17:15:14 d2.utils.events]: \u001b[0m eta: 0:57:08  iter: 10179  total_loss: 1.434  loss_cls: 0.3024  loss_box_reg: 0.5186  loss_mask: 0.2987  loss_rpn_cls: 0.06058  loss_rpn_loc: 0.1881  time: 0.6418  data_time: 0.2045  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:15:27 d2.utils.events]: \u001b[0m eta: 0:56:39  iter: 10199  total_loss: 1.404  loss_cls: 0.3191  loss_box_reg: 0.5283  loss_mask: 0.3083  loss_rpn_cls: 0.07075  loss_rpn_loc: 0.1816  time: 0.6405  data_time: 0.3078  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:15:37 d2.utils.events]: \u001b[0m eta: 0:56:26  iter: 10219  total_loss: 1.41  loss_cls: 0.3323  loss_box_reg: 0.5104  loss_mask: 0.292  loss_rpn_cls: 0.06815  loss_rpn_loc: 0.187  time: 0.6283  data_time: 0.1926  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:15:49 d2.utils.events]: \u001b[0m eta: 0:56:13  iter: 10239  total_loss: 1.369  loss_cls: 0.3072  loss_box_reg: 0.4976  loss_mask: 0.2828  loss_rpn_cls: 0.05756  loss_rpn_loc: 0.1714  time: 0.6279  data_time: 0.2955  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:16:01 d2.utils.events]: \u001b[0m eta: 0:55:56  iter: 10259  total_loss: 1.347  loss_cls: 0.2934  loss_box_reg: 0.4748  loss_mask: 0.282  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.178  time: 0.6255  data_time: 0.2735  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:16:17 d2.utils.events]: \u001b[0m eta: 0:55:59  iter: 10279  total_loss: 1.33  loss_cls: 0.3073  loss_box_reg: 0.4729  loss_mask: 0.3265  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.2023  time: 0.6392  data_time: 0.4874  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:16:28 d2.utils.events]: \u001b[0m eta: 0:55:46  iter: 10299  total_loss: 1.432  loss_cls: 0.2985  loss_box_reg: 0.5032  loss_mask: 0.307  loss_rpn_cls: 0.05827  loss_rpn_loc: 0.1948  time: 0.6312  data_time: 0.2016  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:16:41 d2.utils.events]: \u001b[0m eta: 0:55:35  iter: 10319  total_loss: 1.405  loss_cls: 0.3394  loss_box_reg: 0.4758  loss_mask: 0.2859  loss_rpn_cls: 0.07197  loss_rpn_loc: 0.2034  time: 0.6314  data_time: 0.3027  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:16:50 d2.utils.events]: \u001b[0m eta: 0:55:28  iter: 10339  total_loss: 1.427  loss_cls: 0.3253  loss_box_reg: 0.49  loss_mask: 0.2977  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.1919  time: 0.6225  data_time: 0.1609  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:17:03 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 10359  total_loss: 1.429  loss_cls: 0.3578  loss_box_reg: 0.4855  loss_mask: 0.2979  loss_rpn_cls: 0.06787  loss_rpn_loc: 0.194  time: 0.6233  data_time: 0.3050  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:17:19 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 10379  total_loss: 1.421  loss_cls: 0.3161  loss_box_reg: 0.453  loss_mask: 0.2978  loss_rpn_cls: 0.09261  loss_rpn_loc: 0.1985  time: 0.6334  data_time: 0.4728  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:17:30 d2.utils.events]: \u001b[0m eta: 0:55:12  iter: 10399  total_loss: 1.425  loss_cls: 0.3031  loss_box_reg: 0.4961  loss_mask: 0.3049  loss_rpn_cls: 0.07861  loss_rpn_loc: 0.2039  time: 0.6298  data_time: 0.2420  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:17:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:17:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:17:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:17:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:17:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:17:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:17:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0728 s/iter. Eval: 0.0125 s/iter. Total: 0.0859 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:17:41 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0745 s/iter. Eval: 0.0166 s/iter. Total: 0.0919 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:17:46 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0746 s/iter. Eval: 0.0171 s/iter. Total: 0.0924 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:17:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.802985 (0.093129 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:17:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074650 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:17:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:17:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2565540110184344\n",
      "\u001b[32m[01/10 17:17:54 d2.utils.events]: \u001b[0m eta: 0:55:01  iter: 10419  total_loss: 1.414  loss_cls: 0.2876  loss_box_reg: 0.4965  loss_mask: 0.2914  loss_rpn_cls: 0.07953  loss_rpn_loc: 0.1851  time: 0.6269  data_time: 0.2569  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:18:06 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 10439  total_loss: 1.451  loss_cls: 0.2835  loss_box_reg: 0.5199  loss_mask: 0.3085  loss_rpn_cls: 0.06515  loss_rpn_loc: 0.1871  time: 0.6245  data_time: 0.2565  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:18:18 d2.utils.events]: \u001b[0m eta: 0:54:37  iter: 10459  total_loss: 1.425  loss_cls: 0.3439  loss_box_reg: 0.5187  loss_mask: 0.3022  loss_rpn_cls: 0.07395  loss_rpn_loc: 0.1846  time: 0.6242  data_time: 0.2899  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:18:31 d2.utils.events]: \u001b[0m eta: 0:54:40  iter: 10479  total_loss: 1.369  loss_cls: 0.2898  loss_box_reg: 0.5002  loss_mask: 0.3094  loss_rpn_cls: 0.07512  loss_rpn_loc: 0.2011  time: 0.6263  data_time: 0.3406  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:18:46 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 10499  total_loss: 1.349  loss_cls: 0.2979  loss_box_reg: 0.4854  loss_mask: 0.293  loss_rpn_cls: 0.08658  loss_rpn_loc: 0.1919  time: 0.6297  data_time: 0.3707  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:18:58 d2.utils.events]: \u001b[0m eta: 0:54:42  iter: 10519  total_loss: 1.347  loss_cls: 0.2966  loss_box_reg: 0.4927  loss_mask: 0.2883  loss_rpn_cls: 0.08229  loss_rpn_loc: 0.1939  time: 0.6300  data_time: 0.3128  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:19:15 d2.utils.events]: \u001b[0m eta: 0:54:41  iter: 10539  total_loss: 1.396  loss_cls: 0.292  loss_box_reg: 0.4559  loss_mask: 0.3054  loss_rpn_cls: 0.06549  loss_rpn_loc: 0.194  time: 0.6370  data_time: 0.4750  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:19:30 d2.utils.events]: \u001b[0m eta: 0:54:40  iter: 10559  total_loss: 1.533  loss_cls: 0.3744  loss_box_reg: 0.542  loss_mask: 0.308  loss_rpn_cls: 0.09041  loss_rpn_loc: 0.1944  time: 0.6412  data_time: 0.4225  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:19:42 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 10579  total_loss: 1.3  loss_cls: 0.2648  loss_box_reg: 0.4885  loss_mask: 0.2783  loss_rpn_cls: 0.0384  loss_rpn_loc: 0.1756  time: 0.6393  data_time: 0.2678  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:19:52 d2.utils.events]: \u001b[0m eta: 0:54:00  iter: 10599  total_loss: 1.304  loss_cls: 0.2678  loss_box_reg: 0.4996  loss_mask: 0.2952  loss_rpn_cls: 0.04862  loss_rpn_loc: 0.1665  time: 0.6347  data_time: 0.1918  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:20:07 d2.utils.events]: \u001b[0m eta: 0:53:56  iter: 10619  total_loss: 1.471  loss_cls: 0.3274  loss_box_reg: 0.4937  loss_mask: 0.3218  loss_rpn_cls: 0.06649  loss_rpn_loc: 0.2067  time: 0.6394  data_time: 0.4402  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:20:22 d2.utils.events]: \u001b[0m eta: 0:53:51  iter: 10639  total_loss: 1.333  loss_cls: 0.2933  loss_box_reg: 0.4827  loss_mask: 0.2806  loss_rpn_cls: 0.06848  loss_rpn_loc: 0.1865  time: 0.6419  data_time: 0.3881  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:20:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:20:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:20:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:20:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:20:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:20:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0723 s/iter. Eval: 0.0120 s/iter. Total: 0.0850 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0766 s/iter. Eval: 0.0183 s/iter. Total: 0.0958 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0008 s/iter. Inference: 0.0766 s/iter. Eval: 0.0186 s/iter. Total: 0.0961 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:20:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.227172 (0.096786 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:20:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076589 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:20:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:20:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25584342084206607\n",
      "\u001b[32m[01/10 17:20:47 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 10659  total_loss: 1.459  loss_cls: 0.3282  loss_box_reg: 0.5128  loss_mask: 0.3106  loss_rpn_cls: 0.088  loss_rpn_loc: 0.2071  time: 0.6427  data_time: 0.3358  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:20:58 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 10679  total_loss: 1.291  loss_cls: 0.2811  loss_box_reg: 0.4593  loss_mask: 0.2885  loss_rpn_cls: 0.06231  loss_rpn_loc: 0.1774  time: 0.6390  data_time: 0.2044  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:21:09 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 10699  total_loss: 1.336  loss_cls: 0.3003  loss_box_reg: 0.5081  loss_mask: 0.2941  loss_rpn_cls: 0.05771  loss_rpn_loc: 0.1753  time: 0.6371  data_time: 0.2477  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:21:19 d2.utils.events]: \u001b[0m eta: 0:53:33  iter: 10719  total_loss: 1.446  loss_cls: 0.3421  loss_box_reg: 0.5171  loss_mask: 0.3061  loss_rpn_cls: 0.06511  loss_rpn_loc: 0.1846  time: 0.6333  data_time: 0.1664  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:21:33 d2.utils.events]: \u001b[0m eta: 0:53:28  iter: 10739  total_loss: 1.436  loss_cls: 0.3216  loss_box_reg: 0.5095  loss_mask: 0.3135  loss_rpn_cls: 0.07036  loss_rpn_loc: 0.2  time: 0.6346  data_time: 0.3377  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:21:44 d2.utils.events]: \u001b[0m eta: 0:53:14  iter: 10759  total_loss: 1.353  loss_cls: 0.3206  loss_box_reg: 0.5236  loss_mask: 0.297  loss_rpn_cls: 0.05202  loss_rpn_loc: 0.1869  time: 0.6326  data_time: 0.2302  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:21:55 d2.utils.events]: \u001b[0m eta: 0:52:58  iter: 10779  total_loss: 1.309  loss_cls: 0.3197  loss_box_reg: 0.509  loss_mask: 0.2763  loss_rpn_cls: 0.05697  loss_rpn_loc: 0.1743  time: 0.6297  data_time: 0.2014  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:22:08 d2.utils.events]: \u001b[0m eta: 0:52:56  iter: 10799  total_loss: 1.413  loss_cls: 0.3138  loss_box_reg: 0.5012  loss_mask: 0.3219  loss_rpn_cls: 0.08843  loss_rpn_loc: 0.2096  time: 0.6310  data_time: 0.3437  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:22:20 d2.utils.events]: \u001b[0m eta: 0:53:01  iter: 10819  total_loss: 1.358  loss_cls: 0.2905  loss_box_reg: 0.5091  loss_mask: 0.2953  loss_rpn_cls: 0.0666  loss_rpn_loc: 0.1869  time: 0.6303  data_time: 0.2708  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:22:33 d2.utils.events]: \u001b[0m eta: 0:52:58  iter: 10839  total_loss: 1.265  loss_cls: 0.2694  loss_box_reg: 0.4554  loss_mask: 0.2814  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.1857  time: 0.6306  data_time: 0.3051  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:22:48 d2.utils.events]: \u001b[0m eta: 0:52:58  iter: 10859  total_loss: 1.312  loss_cls: 0.3  loss_box_reg: 0.4672  loss_mask: 0.2895  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.1938  time: 0.6332  data_time: 0.4011  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:23:00 d2.utils.events]: \u001b[0m eta: 0:52:53  iter: 10879  total_loss: 1.44  loss_cls: 0.3479  loss_box_reg: 0.5191  loss_mask: 0.3016  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.2059  time: 0.6327  data_time: 0.2883  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:23:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:23:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:23:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:23:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:23:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:23:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0118 s/iter. Total: 0.0844 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0767 s/iter. Eval: 0.0175 s/iter. Total: 0.0951 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0757 s/iter. Eval: 0.0169 s/iter. Total: 0.0935 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:23:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.941247 (0.094321 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:23:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075863 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:23:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:23:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25032738462340215\n",
      "\u001b[32m[01/10 17:23:24 d2.utils.events]: \u001b[0m eta: 0:52:42  iter: 10899  total_loss: 1.315  loss_cls: 0.288  loss_box_reg: 0.4777  loss_mask: 0.2905  loss_rpn_cls: 0.0633  loss_rpn_loc: 0.1714  time: 0.6318  data_time: 0.2736  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:23:39 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 10919  total_loss: 1.354  loss_cls: 0.3127  loss_box_reg: 0.4826  loss_mask: 0.2992  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.1924  time: 0.6344  data_time: 0.4050  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:23:51 d2.utils.events]: \u001b[0m eta: 0:52:30  iter: 10939  total_loss: 1.383  loss_cls: 0.2878  loss_box_reg: 0.494  loss_mask: 0.2908  loss_rpn_cls: 0.07585  loss_rpn_loc: 0.1875  time: 0.6336  data_time: 0.2781  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:24:04 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 10959  total_loss: 1.308  loss_cls: 0.2859  loss_box_reg: 0.5025  loss_mask: 0.3075  loss_rpn_cls: 0.06163  loss_rpn_loc: 0.1761  time: 0.6334  data_time: 0.2926  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:24:19 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 10979  total_loss: 1.37  loss_cls: 0.332  loss_box_reg: 0.466  loss_mask: 0.298  loss_rpn_cls: 0.09473  loss_rpn_loc: 0.1976  time: 0.6358  data_time: 0.4064  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:24:36 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 10999  total_loss: 1.429  loss_cls: 0.3124  loss_box_reg: 0.4927  loss_mask: 0.2822  loss_rpn_cls: 0.08812  loss_rpn_loc: 0.1928  time: 0.6401  data_time: 0.5046  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:24:46 d2.utils.events]: \u001b[0m eta: 0:52:09  iter: 11019  total_loss: 1.348  loss_cls: 0.3243  loss_box_reg: 0.5191  loss_mask: 0.2954  loss_rpn_cls: 0.06169  loss_rpn_loc: 0.1874  time: 0.6380  data_time: 0.2052  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:25:00 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 11039  total_loss: 1.498  loss_cls: 0.3496  loss_box_reg: 0.5036  loss_mask: 0.2889  loss_rpn_cls: 0.08158  loss_rpn_loc: 0.2021  time: 0.6392  data_time: 0.3626  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:25:11 d2.utils.events]: \u001b[0m eta: 0:51:35  iter: 11059  total_loss: 1.263  loss_cls: 0.2769  loss_box_reg: 0.4849  loss_mask: 0.2734  loss_rpn_cls: 0.05518  loss_rpn_loc: 0.182  time: 0.6370  data_time: 0.2154  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:25:21 d2.utils.events]: \u001b[0m eta: 0:51:28  iter: 11079  total_loss: 1.422  loss_cls: 0.3328  loss_box_reg: 0.503  loss_mask: 0.3012  loss_rpn_cls: 0.05645  loss_rpn_loc: 0.1772  time: 0.6346  data_time: 0.1845  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:25:32 d2.utils.events]: \u001b[0m eta: 0:51:24  iter: 11099  total_loss: 1.343  loss_cls: 0.2926  loss_box_reg: 0.5072  loss_mask: 0.2831  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.1782  time: 0.6333  data_time: 0.2453  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:25:46 d2.utils.events]: \u001b[0m eta: 0:51:04  iter: 11119  total_loss: 1.365  loss_cls: 0.293  loss_box_reg: 0.4868  loss_mask: 0.3041  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.1976  time: 0.6344  data_time: 0.3597  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:25:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:25:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:25:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:25:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:25:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:25:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:25:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0126 s/iter. Total: 0.0886 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0009 s/iter. Inference: 0.0787 s/iter. Eval: 0.0203 s/iter. Total: 0.0999 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0009 s/iter. Inference: 0.0790 s/iter. Eval: 0.0203 s/iter. Total: 0.1002 s/iter. ETA=0:00:01\n",
      "\u001b[32m[01/10 17:26:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.613327 (0.100115 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:26:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.078595 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:26:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:26:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25709031567812746\n",
      "\u001b[32m[01/10 17:26:12 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 11139  total_loss: 1.394  loss_cls: 0.3006  loss_box_reg: 0.4938  loss_mask: 0.3017  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.1931  time: 0.6343  data_time: 0.2918  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:26:21 d2.utils.events]: \u001b[0m eta: 0:50:50  iter: 11159  total_loss: 1.295  loss_cls: 0.2678  loss_box_reg: 0.4966  loss_mask: 0.2909  loss_rpn_cls: 0.0441  loss_rpn_loc: 0.1729  time: 0.6315  data_time: 0.1570  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:26:38 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 11179  total_loss: 1.484  loss_cls: 0.341  loss_box_reg: 0.4844  loss_mask: 0.3075  loss_rpn_cls: 0.08482  loss_rpn_loc: 0.1976  time: 0.6351  data_time: 0.5140  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:26:50 d2.utils.events]: \u001b[0m eta: 0:51:06  iter: 11199  total_loss: 1.48  loss_cls: 0.3313  loss_box_reg: 0.52  loss_mask: 0.2992  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.213  time: 0.6344  data_time: 0.2598  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:27:01 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 11219  total_loss: 1.337  loss_cls: 0.2989  loss_box_reg: 0.4811  loss_mask: 0.2825  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1894  time: 0.6334  data_time: 0.2476  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:27:15 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 11239  total_loss: 1.344  loss_cls: 0.2883  loss_box_reg: 0.4744  loss_mask: 0.3003  loss_rpn_cls: 0.08561  loss_rpn_loc: 0.1987  time: 0.6344  data_time: 0.3622  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:27:30 d2.utils.events]: \u001b[0m eta: 0:51:09  iter: 11259  total_loss: 1.404  loss_cls: 0.3018  loss_box_reg: 0.4999  loss_mask: 0.3159  loss_rpn_cls: 0.08192  loss_rpn_loc: 0.1956  time: 0.6355  data_time: 0.3656  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:27:41 d2.utils.events]: \u001b[0m eta: 0:50:48  iter: 11279  total_loss: 1.345  loss_cls: 0.3101  loss_box_reg: 0.5085  loss_mask: 0.3043  loss_rpn_cls: 0.05835  loss_rpn_loc: 0.1808  time: 0.6348  data_time: 0.2689  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:27:51 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 11299  total_loss: 1.335  loss_cls: 0.3031  loss_box_reg: 0.5241  loss_mask: 0.2959  loss_rpn_cls: 0.04794  loss_rpn_loc: 0.1853  time: 0.6323  data_time: 0.1521  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:28:02 d2.utils.events]: \u001b[0m eta: 0:50:34  iter: 11319  total_loss: 1.49  loss_cls: 0.3313  loss_box_reg: 0.5002  loss_mask: 0.3102  loss_rpn_cls: 0.07489  loss_rpn_loc: 0.197  time: 0.6314  data_time: 0.2422  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:28:16 d2.utils.events]: \u001b[0m eta: 0:50:36  iter: 11339  total_loss: 1.331  loss_cls: 0.3017  loss_box_reg: 0.4683  loss_mask: 0.3035  loss_rpn_cls: 0.06545  loss_rpn_loc: 0.1846  time: 0.6321  data_time: 0.3391  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:28:25 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 11359  total_loss: 1.35  loss_cls: 0.2646  loss_box_reg: 0.5029  loss_mask: 0.2846  loss_rpn_cls: 0.0477  loss_rpn_loc: 0.1799  time: 0.6295  data_time: 0.1337  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:28:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:28:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:28:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:28:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:28:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:28:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0729 s/iter. Eval: 0.0123 s/iter. Total: 0.0857 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0008 s/iter. Inference: 0.0772 s/iter. Eval: 0.0187 s/iter. Total: 0.0967 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0772 s/iter. Eval: 0.0190 s/iter. Total: 0.0971 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:28:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.384442 (0.098142 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:28:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077423 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:28:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:28:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26220337363460333\n",
      "\u001b[32m[01/10 17:28:52 d2.utils.events]: \u001b[0m eta: 0:50:19  iter: 11379  total_loss: 1.429  loss_cls: 0.324  loss_box_reg: 0.5302  loss_mask: 0.3049  loss_rpn_cls: 0.09063  loss_rpn_loc: 0.2101  time: 0.6307  data_time: 0.3712  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:29:04 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 11399  total_loss: 1.422  loss_cls: 0.3364  loss_box_reg: 0.5221  loss_mask: 0.3046  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.2038  time: 0.6300  data_time: 0.2549  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:29:16 d2.utils.events]: \u001b[0m eta: 0:50:12  iter: 11419  total_loss: 1.34  loss_cls: 0.3101  loss_box_reg: 0.5033  loss_mask: 0.2928  loss_rpn_cls: 0.06312  loss_rpn_loc: 0.1735  time: 0.6297  data_time: 0.2851  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:29:29 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 11439  total_loss: 1.33  loss_cls: 0.2864  loss_box_reg: 0.4785  loss_mask: 0.3045  loss_rpn_cls: 0.07126  loss_rpn_loc: 0.1649  time: 0.6301  data_time: 0.3297  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:29:41 d2.utils.events]: \u001b[0m eta: 0:50:17  iter: 11459  total_loss: 1.415  loss_cls: 0.292  loss_box_reg: 0.5102  loss_mask: 0.3052  loss_rpn_cls: 0.08143  loss_rpn_loc: 0.2107  time: 0.6296  data_time: 0.2704  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:29:53 d2.utils.events]: \u001b[0m eta: 0:50:11  iter: 11479  total_loss: 1.406  loss_cls: 0.3232  loss_box_reg: 0.5252  loss_mask: 0.2954  loss_rpn_cls: 0.07958  loss_rpn_loc: 0.2144  time: 0.6292  data_time: 0.2660  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:30:05 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 11499  total_loss: 1.369  loss_cls: 0.33  loss_box_reg: 0.506  loss_mask: 0.2898  loss_rpn_cls: 0.05895  loss_rpn_loc: 0.1936  time: 0.6287  data_time: 0.2612  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:30:21 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 11519  total_loss: 1.28  loss_cls: 0.2856  loss_box_reg: 0.4465  loss_mask: 0.29  loss_rpn_cls: 0.07826  loss_rpn_loc: 0.1951  time: 0.6314  data_time: 0.4922  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:30:38 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 11539  total_loss: 1.394  loss_cls: 0.3051  loss_box_reg: 0.4898  loss_mask: 0.2872  loss_rpn_cls: 0.07788  loss_rpn_loc: 0.1983  time: 0.6337  data_time: 0.4714  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:30:54 d2.utils.events]: \u001b[0m eta: 0:49:42  iter: 11559  total_loss: 1.303  loss_cls: 0.2827  loss_box_reg: 0.5042  loss_mask: 0.297  loss_rpn_cls: 0.07124  loss_rpn_loc: 0.1962  time: 0.6362  data_time: 0.4874  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:31:05 d2.utils.events]: \u001b[0m eta: 0:49:44  iter: 11579  total_loss: 1.362  loss_cls: 0.2999  loss_box_reg: 0.4849  loss_mask: 0.3041  loss_rpn_cls: 0.05238  loss_rpn_loc: 0.1821  time: 0.6353  data_time: 0.2212  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:31:16 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 11599  total_loss: 1.419  loss_cls: 0.3377  loss_box_reg: 0.5028  loss_mask: 0.2886  loss_rpn_cls: 0.05841  loss_rpn_loc: 0.1742  time: 0.6340  data_time: 0.2080  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:31:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:31:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:31:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:31:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:31:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:31:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0120 s/iter. Total: 0.0863 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0777 s/iter. Eval: 0.0179 s/iter. Total: 0.0964 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0771 s/iter. Eval: 0.0181 s/iter. Total: 0.0960 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:31:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.212196 (0.096657 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:31:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077025 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:31:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2604185527964436\n",
      "\u001b[32m[01/10 17:31:40 d2.utils.events]: \u001b[0m eta: 0:49:21  iter: 11619  total_loss: 1.414  loss_cls: 0.3409  loss_box_reg: 0.5264  loss_mask: 0.3076  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.1879  time: 0.6329  data_time: 0.2223  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:31:52 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 11639  total_loss: 1.37  loss_cls: 0.3079  loss_box_reg: 0.4853  loss_mask: 0.2819  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.185  time: 0.6327  data_time: 0.2903  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:32:03 d2.utils.events]: \u001b[0m eta: 0:49:01  iter: 11659  total_loss: 1.452  loss_cls: 0.3511  loss_box_reg: 0.5327  loss_mask: 0.3103  loss_rpn_cls: 0.08389  loss_rpn_loc: 0.2019  time: 0.6316  data_time: 0.2178  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:32:14 d2.utils.events]: \u001b[0m eta: 0:48:58  iter: 11679  total_loss: 1.305  loss_cls: 0.2943  loss_box_reg: 0.4647  loss_mask: 0.2821  loss_rpn_cls: 0.06951  loss_rpn_loc: 0.176  time: 0.6309  data_time: 0.2525  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:32:24 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 11699  total_loss: 1.316  loss_cls: 0.2583  loss_box_reg: 0.4961  loss_mask: 0.2934  loss_rpn_cls: 0.06106  loss_rpn_loc: 0.196  time: 0.6294  data_time: 0.1986  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:32:34 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 11719  total_loss: 1.317  loss_cls: 0.3036  loss_box_reg: 0.4803  loss_mask: 0.2819  loss_rpn_cls: 0.06744  loss_rpn_loc: 0.1825  time: 0.6279  data_time: 0.1761  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:32:43 d2.utils.events]: \u001b[0m eta: 0:48:10  iter: 11739  total_loss: 1.329  loss_cls: 0.276  loss_box_reg: 0.5146  loss_mask: 0.285  loss_rpn_cls: 0.04411  loss_rpn_loc: 0.1654  time: 0.6257  data_time: 0.1227  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:32:54 d2.utils.events]: \u001b[0m eta: 0:48:03  iter: 11759  total_loss: 1.405  loss_cls: 0.3151  loss_box_reg: 0.5098  loss_mask: 0.3117  loss_rpn_cls: 0.0568  loss_rpn_loc: 0.1973  time: 0.6246  data_time: 0.2121  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:33:06 d2.utils.events]: \u001b[0m eta: 0:47:57  iter: 11779  total_loss: 1.38  loss_cls: 0.2972  loss_box_reg: 0.5213  loss_mask: 0.2994  loss_rpn_cls: 0.07338  loss_rpn_loc: 0.203  time: 0.6244  data_time: 0.2810  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:33:20 d2.utils.events]: \u001b[0m eta: 0:47:50  iter: 11799  total_loss: 1.444  loss_cls: 0.3264  loss_box_reg: 0.4878  loss_mask: 0.3102  loss_rpn_cls: 0.07705  loss_rpn_loc: 0.2143  time: 0.6251  data_time: 0.3540  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:33:33 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 11819  total_loss: 1.382  loss_cls: 0.2721  loss_box_reg: 0.4939  loss_mask: 0.2946  loss_rpn_cls: 0.07164  loss_rpn_loc: 0.1867  time: 0.6254  data_time: 0.3205  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:33:46 d2.utils.events]: \u001b[0m eta: 0:47:31  iter: 11839  total_loss: 1.361  loss_cls: 0.307  loss_box_reg: 0.489  loss_mask: 0.289  loss_rpn_cls: 0.06097  loss_rpn_loc: 0.1806  time: 0.6258  data_time: 0.3344  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:33:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:33:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:33:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:33:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:33:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:33:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0754 s/iter. Eval: 0.0130 s/iter. Total: 0.0891 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0763 s/iter. Eval: 0.0179 s/iter. Total: 0.0950 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0759 s/iter. Eval: 0.0183 s/iter. Total: 0.0951 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:34:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.110475 (0.095780 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:34:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075920 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:34:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:34:09 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2552656972709009\n",
      "\u001b[32m[01/10 17:34:09 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 11859  total_loss: 1.386  loss_cls: 0.2893  loss_box_reg: 0.5207  loss_mask: 0.3061  loss_rpn_cls: 0.05521  loss_rpn_loc: 0.1914  time: 0.6249  data_time: 0.2204  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:34:25 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 11879  total_loss: 1.504  loss_cls: 0.3664  loss_box_reg: 0.5158  loss_mask: 0.3178  loss_rpn_cls: 0.0879  loss_rpn_loc: 0.2177  time: 0.6266  data_time: 0.4179  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:34:38 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 11899  total_loss: 1.45  loss_cls: 0.3416  loss_box_reg: 0.5165  loss_mask: 0.2998  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.2081  time: 0.6268  data_time: 0.3227  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:34:48 d2.utils.events]: \u001b[0m eta: 0:47:02  iter: 11919  total_loss: 1.365  loss_cls: 0.3096  loss_box_reg: 0.4809  loss_mask: 0.2995  loss_rpn_cls: 0.0771  loss_rpn_loc: 0.204  time: 0.6256  data_time: 0.1875  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:35:01 d2.utils.events]: \u001b[0m eta: 0:46:58  iter: 11939  total_loss: 1.337  loss_cls: 0.3228  loss_box_reg: 0.4889  loss_mask: 0.3001  loss_rpn_cls: 0.05555  loss_rpn_loc: 0.1707  time: 0.6260  data_time: 0.3242  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:35:14 d2.utils.events]: \u001b[0m eta: 0:46:52  iter: 11959  total_loss: 1.35  loss_cls: 0.3082  loss_box_reg: 0.4672  loss_mask: 0.3095  loss_rpn_cls: 0.06156  loss_rpn_loc: 0.1904  time: 0.6261  data_time: 0.3029  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:35:28 d2.utils.events]: \u001b[0m eta: 0:46:43  iter: 11979  total_loss: 1.525  loss_cls: 0.3472  loss_box_reg: 0.5217  loss_mask: 0.3068  loss_rpn_cls: 0.07114  loss_rpn_loc: 0.2171  time: 0.6270  data_time: 0.3740  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:35:41 d2.utils.events]: \u001b[0m eta: 0:46:34  iter: 11999  total_loss: 1.39  loss_cls: 0.302  loss_box_reg: 0.4906  loss_mask: 0.2962  loss_rpn_cls: 0.06884  loss_rpn_loc: 0.1725  time: 0.6271  data_time: 0.3227  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:35:53 d2.utils.events]: \u001b[0m eta: 0:46:28  iter: 12019  total_loss: 1.385  loss_cls: 0.3226  loss_box_reg: 0.4844  loss_mask: 0.3086  loss_rpn_cls: 0.06546  loss_rpn_loc: 0.2019  time: 0.6269  data_time: 0.2787  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:36:08 d2.utils.events]: \u001b[0m eta: 0:46:21  iter: 12039  total_loss: 1.298  loss_cls: 0.2933  loss_box_reg: 0.4784  loss_mask: 0.3002  loss_rpn_cls: 0.08502  loss_rpn_loc: 0.1907  time: 0.6278  data_time: 0.3803  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:36:20 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 12059  total_loss: 1.343  loss_cls: 0.3063  loss_box_reg: 0.4933  loss_mask: 0.2934  loss_rpn_cls: 0.05415  loss_rpn_loc: 0.1828  time: 0.6279  data_time: 0.3085  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:36:36 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 12079  total_loss: 1.499  loss_cls: 0.3276  loss_box_reg: 0.483  loss_mask: 0.3085  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.2063  time: 0.6296  data_time: 0.4550  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:36:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:36:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:36:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:36:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:36:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:36:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0726 s/iter. Eval: 0.0127 s/iter. Total: 0.0859 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0744 s/iter. Eval: 0.0165 s/iter. Total: 0.0916 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0169 s/iter. Total: 0.0927 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:36:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.846257 (0.093502 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:36:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075010 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:36:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:36:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2556488285772987\n",
      "\u001b[32m[01/10 17:36:59 d2.utils.events]: \u001b[0m eta: 0:46:08  iter: 12099  total_loss: 1.412  loss_cls: 0.334  loss_box_reg: 0.5145  loss_mask: 0.3024  loss_rpn_cls: 0.08839  loss_rpn_loc: 0.1859  time: 0.6285  data_time: 0.2010  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:37:09 d2.utils.events]: \u001b[0m eta: 0:46:02  iter: 12119  total_loss: 1.215  loss_cls: 0.2425  loss_box_reg: 0.4995  loss_mask: 0.2945  loss_rpn_cls: 0.05675  loss_rpn_loc: 0.1697  time: 0.6273  data_time: 0.1706  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:37:20 d2.utils.events]: \u001b[0m eta: 0:45:49  iter: 12139  total_loss: 1.326  loss_cls: 0.2788  loss_box_reg: 0.4689  loss_mask: 0.2762  loss_rpn_cls: 0.05157  loss_rpn_loc: 0.1831  time: 0.6264  data_time: 0.2208  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:37:29 d2.utils.events]: \u001b[0m eta: 0:45:41  iter: 12159  total_loss: 1.19  loss_cls: 0.2296  loss_box_reg: 0.481  loss_mask: 0.284  loss_rpn_cls: 0.04125  loss_rpn_loc: 0.1627  time: 0.6250  data_time: 0.1514  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:37:40 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 12179  total_loss: 1.312  loss_cls: 0.2847  loss_box_reg: 0.4897  loss_mask: 0.2819  loss_rpn_cls: 0.05838  loss_rpn_loc: 0.1847  time: 0.6242  data_time: 0.2132  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:37:49 d2.utils.events]: \u001b[0m eta: 0:45:19  iter: 12199  total_loss: 1.411  loss_cls: 0.3102  loss_box_reg: 0.5324  loss_mask: 0.3025  loss_rpn_cls: 0.06281  loss_rpn_loc: 0.1855  time: 0.6227  data_time: 0.1595  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:38:05 d2.utils.events]: \u001b[0m eta: 0:45:13  iter: 12219  total_loss: 1.413  loss_cls: 0.3279  loss_box_reg: 0.4855  loss_mask: 0.3139  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1805  time: 0.6240  data_time: 0.4292  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:38:16 d2.utils.events]: \u001b[0m eta: 0:45:05  iter: 12239  total_loss: 1.34  loss_cls: 0.2962  loss_box_reg: 0.4689  loss_mask: 0.2875  loss_rpn_cls: 0.07455  loss_rpn_loc: 0.1922  time: 0.6238  data_time: 0.2720  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:38:28 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 12259  total_loss: 1.422  loss_cls: 0.3266  loss_box_reg: 0.5092  loss_mask: 0.2946  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.1932  time: 0.6235  data_time: 0.2794  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:38:39 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 12279  total_loss: 1.362  loss_cls: 0.2859  loss_box_reg: 0.5075  loss_mask: 0.2961  loss_rpn_cls: 0.06737  loss_rpn_loc: 0.1997  time: 0.6225  data_time: 0.1853  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:38:52 d2.utils.events]: \u001b[0m eta: 0:44:41  iter: 12299  total_loss: 1.362  loss_cls: 0.3001  loss_box_reg: 0.4823  loss_mask: 0.2936  loss_rpn_cls: 0.0828  loss_rpn_loc: 0.2074  time: 0.6228  data_time: 0.3290  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:39:05 d2.utils.events]: \u001b[0m eta: 0:44:30  iter: 12319  total_loss: 1.39  loss_cls: 0.3376  loss_box_reg: 0.4661  loss_mask: 0.2994  loss_rpn_cls: 0.05313  loss_rpn_loc: 0.174  time: 0.6232  data_time: 0.3466  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:39:18 d2.utils.events]: \u001b[0m eta: 0:44:16  iter: 12339  total_loss: 1.303  loss_cls: 0.3019  loss_box_reg: 0.4597  loss_mask: 0.2914  loss_rpn_cls: 0.05848  loss_rpn_loc: 0.1846  time: 0.6235  data_time: 0.3339  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:39:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:39:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:39:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:39:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:39:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:39:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:39:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0723 s/iter. Eval: 0.0130 s/iter. Total: 0.0860 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:39:26 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0175 s/iter. Total: 0.0932 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:39:31 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0754 s/iter. Eval: 0.0180 s/iter. Total: 0.0942 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:39:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.999108 (0.094820 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:39:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075401 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:39:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:39:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2600023179490603\n",
      "\u001b[32m[01/10 17:39:41 d2.utils.events]: \u001b[0m eta: 0:44:09  iter: 12359  total_loss: 1.315  loss_cls: 0.251  loss_box_reg: 0.4929  loss_mask: 0.2874  loss_rpn_cls: 0.0383  loss_rpn_loc: 0.1764  time: 0.6228  data_time: 0.2288  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:39:55 d2.utils.events]: \u001b[0m eta: 0:43:59  iter: 12379  total_loss: 1.335  loss_cls: 0.2861  loss_box_reg: 0.4786  loss_mask: 0.2937  loss_rpn_cls: 0.08358  loss_rpn_loc: 0.1919  time: 0.6233  data_time: 0.3483  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:40:10 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 12399  total_loss: 1.413  loss_cls: 0.3475  loss_box_reg: 0.5012  loss_mask: 0.2991  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1966  time: 0.6243  data_time: 0.3935  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:40:19 d2.utils.events]: \u001b[0m eta: 0:43:41  iter: 12419  total_loss: 1.283  loss_cls: 0.2762  loss_box_reg: 0.4964  loss_mask: 0.2852  loss_rpn_cls: 0.05859  loss_rpn_loc: 0.1908  time: 0.6229  data_time: 0.1458  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:40:32 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 12439  total_loss: 1.353  loss_cls: 0.2775  loss_box_reg: 0.4909  loss_mask: 0.3064  loss_rpn_cls: 0.06143  loss_rpn_loc: 0.1959  time: 0.6232  data_time: 0.3171  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:40:52 d2.utils.events]: \u001b[0m eta: 0:43:29  iter: 12459  total_loss: 1.36  loss_cls: 0.3146  loss_box_reg: 0.4631  loss_mask: 0.3023  loss_rpn_cls: 0.08218  loss_rpn_loc: 0.2024  time: 0.6262  data_time: 0.6261  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:41:04 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 12479  total_loss: 1.32  loss_cls: 0.2747  loss_box_reg: 0.4931  loss_mask: 0.318  loss_rpn_cls: 0.0383  loss_rpn_loc: 0.1762  time: 0.6260  data_time: 0.2798  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:41:15 d2.utils.events]: \u001b[0m eta: 0:43:08  iter: 12499  total_loss: 1.409  loss_cls: 0.2903  loss_box_reg: 0.4913  loss_mask: 0.2974  loss_rpn_cls: 0.05033  loss_rpn_loc: 0.1748  time: 0.6254  data_time: 0.2187  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:41:28 d2.utils.events]: \u001b[0m eta: 0:43:00  iter: 12519  total_loss: 1.373  loss_cls: 0.3122  loss_box_reg: 0.4827  loss_mask: 0.3213  loss_rpn_cls: 0.07507  loss_rpn_loc: 0.1873  time: 0.6255  data_time: 0.3161  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:41:40 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 12539  total_loss: 1.322  loss_cls: 0.3229  loss_box_reg: 0.477  loss_mask: 0.286  loss_rpn_cls: 0.07029  loss_rpn_loc: 0.1748  time: 0.6255  data_time: 0.2888  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:41:53 d2.utils.events]: \u001b[0m eta: 0:42:43  iter: 12559  total_loss: 1.291  loss_cls: 0.2891  loss_box_reg: 0.4677  loss_mask: 0.2746  loss_rpn_cls: 0.04771  loss_rpn_loc: 0.1809  time: 0.6255  data_time: 0.3067  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:42:04 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 12579  total_loss: 1.311  loss_cls: 0.2768  loss_box_reg: 0.4753  loss_mask: 0.2857  loss_rpn_cls: 0.06304  loss_rpn_loc: 0.1736  time: 0.6251  data_time: 0.2569  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:42:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:42:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:42:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:42:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:42:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:42:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0716 s/iter. Eval: 0.0120 s/iter. Total: 0.0842 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0749 s/iter. Eval: 0.0169 s/iter. Total: 0.0926 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0748 s/iter. Eval: 0.0172 s/iter. Total: 0.0928 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:42:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.863267 (0.093649 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:42:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074915 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:42:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:42:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2583720882778558\n",
      "\u001b[32m[01/10 17:42:26 d2.utils.events]: \u001b[0m eta: 0:42:22  iter: 12599  total_loss: 1.429  loss_cls: 0.3303  loss_box_reg: 0.4618  loss_mask: 0.2862  loss_rpn_cls: 0.07857  loss_rpn_loc: 0.1984  time: 0.6239  data_time: 0.1487  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:42:38 d2.utils.events]: \u001b[0m eta: 0:42:21  iter: 12619  total_loss: 1.281  loss_cls: 0.2617  loss_box_reg: 0.4907  loss_mask: 0.2945  loss_rpn_cls: 0.07694  loss_rpn_loc: 0.1916  time: 0.6235  data_time: 0.2417  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:42:50 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 12639  total_loss: 1.464  loss_cls: 0.33  loss_box_reg: 0.5158  loss_mask: 0.3152  loss_rpn_cls: 0.08656  loss_rpn_loc: 0.2072  time: 0.6236  data_time: 0.3073  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:42:59 d2.utils.events]: \u001b[0m eta: 0:42:09  iter: 12659  total_loss: 1.473  loss_cls: 0.3522  loss_box_reg: 0.5176  loss_mask: 0.3016  loss_rpn_cls: 0.06631  loss_rpn_loc: 0.1896  time: 0.6223  data_time: 0.1280  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:43:09 d2.utils.events]: \u001b[0m eta: 0:41:58  iter: 12679  total_loss: 1.321  loss_cls: 0.296  loss_box_reg: 0.4752  loss_mask: 0.3011  loss_rpn_cls: 0.06287  loss_rpn_loc: 0.1814  time: 0.6215  data_time: 0.1981  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:43:22 d2.utils.events]: \u001b[0m eta: 0:41:55  iter: 12699  total_loss: 1.351  loss_cls: 0.2924  loss_box_reg: 0.4779  loss_mask: 0.3014  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.1846  time: 0.6214  data_time: 0.2930  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:43:34 d2.utils.events]: \u001b[0m eta: 0:41:48  iter: 12719  total_loss: 1.31  loss_cls: 0.2703  loss_box_reg: 0.4894  loss_mask: 0.3036  loss_rpn_cls: 0.06157  loss_rpn_loc: 0.1771  time: 0.6212  data_time: 0.2641  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:43:47 d2.utils.events]: \u001b[0m eta: 0:41:45  iter: 12739  total_loss: 1.368  loss_cls: 0.2985  loss_box_reg: 0.476  loss_mask: 0.2938  loss_rpn_cls: 0.05168  loss_rpn_loc: 0.1875  time: 0.6217  data_time: 0.3573  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:44:02 d2.utils.events]: \u001b[0m eta: 0:41:40  iter: 12759  total_loss: 1.344  loss_cls: 0.336  loss_box_reg: 0.4806  loss_mask: 0.2819  loss_rpn_cls: 0.06654  loss_rpn_loc: 0.1864  time: 0.6223  data_time: 0.3861  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:44:14 d2.utils.events]: \u001b[0m eta: 0:41:35  iter: 12779  total_loss: 1.23  loss_cls: 0.253  loss_box_reg: 0.4821  loss_mask: 0.2918  loss_rpn_cls: 0.04663  loss_rpn_loc: 0.1632  time: 0.6224  data_time: 0.3094  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:44:26 d2.utils.events]: \u001b[0m eta: 0:41:26  iter: 12799  total_loss: 1.439  loss_cls: 0.3344  loss_box_reg: 0.5067  loss_mask: 0.3006  loss_rpn_cls: 0.08692  loss_rpn_loc: 0.1863  time: 0.6222  data_time: 0.2742  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:44:37 d2.utils.events]: \u001b[0m eta: 0:41:22  iter: 12819  total_loss: 1.414  loss_cls: 0.3551  loss_box_reg: 0.5035  loss_mask: 0.2819  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.1866  time: 0.6217  data_time: 0.2154  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:44:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:44:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:44:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:44:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:44:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:44:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0729 s/iter. Eval: 0.0144 s/iter. Total: 0.0881 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0764 s/iter. Eval: 0.0180 s/iter. Total: 0.0952 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0179 s/iter. Total: 0.0948 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:44:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.078539 (0.095505 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:44:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076009 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:44:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:44:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2577701078335806\n",
      "\u001b[32m[01/10 17:45:01 d2.utils.events]: \u001b[0m eta: 0:41:15  iter: 12839  total_loss: 1.418  loss_cls: 0.3172  loss_box_reg: 0.5262  loss_mask: 0.3181  loss_rpn_cls: 0.07471  loss_rpn_loc: 0.2054  time: 0.6215  data_time: 0.2546  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:45:10 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 12859  total_loss: 1.417  loss_cls: 0.313  loss_box_reg: 0.5189  loss_mask: 0.3151  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.1852  time: 0.6201  data_time: 0.1192  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:45:24 d2.utils.events]: \u001b[0m eta: 0:40:58  iter: 12879  total_loss: 1.232  loss_cls: 0.2805  loss_box_reg: 0.4703  loss_mask: 0.2879  loss_rpn_cls: 0.06993  loss_rpn_loc: 0.1761  time: 0.6207  data_time: 0.3739  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:45:39 d2.utils.events]: \u001b[0m eta: 0:40:51  iter: 12899  total_loss: 1.378  loss_cls: 0.3086  loss_box_reg: 0.4899  loss_mask: 0.3162  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.1846  time: 0.6217  data_time: 0.4231  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:45:50 d2.utils.events]: \u001b[0m eta: 0:40:43  iter: 12919  total_loss: 1.344  loss_cls: 0.2945  loss_box_reg: 0.499  loss_mask: 0.2889  loss_rpn_cls: 0.05446  loss_rpn_loc: 0.1849  time: 0.6212  data_time: 0.2393  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:46:04 d2.utils.events]: \u001b[0m eta: 0:40:28  iter: 12939  total_loss: 1.352  loss_cls: 0.2973  loss_box_reg: 0.4803  loss_mask: 0.2832  loss_rpn_cls: 0.08202  loss_rpn_loc: 0.2047  time: 0.6216  data_time: 0.3515  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:46:16 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 12959  total_loss: 1.335  loss_cls: 0.3357  loss_box_reg: 0.5033  loss_mask: 0.3113  loss_rpn_cls: 0.05706  loss_rpn_loc: 0.1814  time: 0.6214  data_time: 0.2701  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:46:30 d2.utils.events]: \u001b[0m eta: 0:40:14  iter: 12979  total_loss: 1.378  loss_cls: 0.2991  loss_box_reg: 0.484  loss_mask: 0.3065  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.1874  time: 0.6219  data_time: 0.3667  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:46:42 d2.utils.events]: \u001b[0m eta: 0:40:12  iter: 12999  total_loss: 1.327  loss_cls: 0.2898  loss_box_reg: 0.4776  loss_mask: 0.2841  loss_rpn_cls: 0.05105  loss_rpn_loc: 0.1943  time: 0.6218  data_time: 0.2749  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:46:53 d2.utils.events]: \u001b[0m eta: 0:40:07  iter: 13019  total_loss: 1.348  loss_cls: 0.3111  loss_box_reg: 0.486  loss_mask: 0.2859  loss_rpn_cls: 0.08381  loss_rpn_loc: 0.1937  time: 0.6213  data_time: 0.2305  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:47:06 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 13039  total_loss: 1.429  loss_cls: 0.3241  loss_box_reg: 0.4874  loss_mask: 0.2997  loss_rpn_cls: 0.107  loss_rpn_loc: 0.1916  time: 0.6214  data_time: 0.2993  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:47:17 d2.utils.events]: \u001b[0m eta: 0:39:53  iter: 13059  total_loss: 1.308  loss_cls: 0.2767  loss_box_reg: 0.4836  loss_mask: 0.2878  loss_rpn_cls: 0.04544  loss_rpn_loc: 0.164  time: 0.6209  data_time: 0.2270  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:47:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:47:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:47:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:47:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:47:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:47:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0728 s/iter. Eval: 0.0141 s/iter. Total: 0.0876 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0761 s/iter. Eval: 0.0177 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0759 s/iter. Eval: 0.0179 s/iter. Total: 0.0946 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:47:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.064175 (0.095381 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:47:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075905 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:47:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:47:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25854541460789504\n",
      "\u001b[32m[01/10 17:47:44 d2.utils.events]: \u001b[0m eta: 0:39:45  iter: 13079  total_loss: 1.323  loss_cls: 0.2808  loss_box_reg: 0.4617  loss_mask: 0.2913  loss_rpn_cls: 0.08682  loss_rpn_loc: 0.2014  time: 0.6216  data_time: 0.3836  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:47:52 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 13099  total_loss: 1.395  loss_cls: 0.3143  loss_box_reg: 0.5241  loss_mask: 0.2958  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.1844  time: 0.6204  data_time: 0.1256  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:48:05 d2.utils.events]: \u001b[0m eta: 0:39:26  iter: 13119  total_loss: 1.342  loss_cls: 0.2703  loss_box_reg: 0.4719  loss_mask: 0.2948  loss_rpn_cls: 0.05321  loss_rpn_loc: 0.1735  time: 0.6205  data_time: 0.3089  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:48:14 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 13139  total_loss: 1.234  loss_cls: 0.2465  loss_box_reg: 0.4773  loss_mask: 0.292  loss_rpn_cls: 0.04237  loss_rpn_loc: 0.1611  time: 0.6193  data_time: 0.1247  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:48:29 d2.utils.events]: \u001b[0m eta: 0:39:14  iter: 13159  total_loss: 1.449  loss_cls: 0.3413  loss_box_reg: 0.4918  loss_mask: 0.3212  loss_rpn_cls: 0.07035  loss_rpn_loc: 0.2111  time: 0.6201  data_time: 0.4066  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:48:39 d2.utils.events]: \u001b[0m eta: 0:39:10  iter: 13179  total_loss: 1.216  loss_cls: 0.2211  loss_box_reg: 0.4629  loss_mask: 0.2888  loss_rpn_cls: 0.0491  loss_rpn_loc: 0.1672  time: 0.6193  data_time: 0.1734  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:48:49 d2.utils.events]: \u001b[0m eta: 0:39:03  iter: 13199  total_loss: 1.372  loss_cls: 0.3272  loss_box_reg: 0.4677  loss_mask: 0.2843  loss_rpn_cls: 0.04117  loss_rpn_loc: 0.1787  time: 0.6188  data_time: 0.2133  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:49:02 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 13219  total_loss: 1.375  loss_cls: 0.3029  loss_box_reg: 0.4964  loss_mask: 0.2968  loss_rpn_cls: 0.06278  loss_rpn_loc: 0.1816  time: 0.6190  data_time: 0.3114  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:49:18 d2.utils.events]: \u001b[0m eta: 0:38:49  iter: 13239  total_loss: 1.372  loss_cls: 0.3023  loss_box_reg: 0.4737  loss_mask: 0.3117  loss_rpn_cls: 0.07878  loss_rpn_loc: 0.1823  time: 0.6202  data_time: 0.4756  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:49:31 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 13259  total_loss: 1.44  loss_cls: 0.3262  loss_box_reg: 0.5168  loss_mask: 0.2958  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.2139  time: 0.6202  data_time: 0.2938  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:49:42 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 13279  total_loss: 1.294  loss_cls: 0.2903  loss_box_reg: 0.4794  loss_mask: 0.2835  loss_rpn_cls: 0.05206  loss_rpn_loc: 0.178  time: 0.6197  data_time: 0.2146  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:49:51 d2.utils.events]: \u001b[0m eta: 0:38:32  iter: 13299  total_loss: 1.347  loss_cls: 0.3036  loss_box_reg: 0.5003  loss_mask: 0.2879  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.1865  time: 0.6189  data_time: 0.1661  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:49:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:49:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:49:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:49:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:49:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:49:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0725 s/iter. Eval: 0.0120 s/iter. Total: 0.0852 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:50:04 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0752 s/iter. Eval: 0.0180 s/iter. Total: 0.0941 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:50:09 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0175 s/iter. Total: 0.0932 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:50:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.914232 (0.094088 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:50:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074923 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:50:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:50:10 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2565571812790193\n",
      "\u001b[32m[01/10 17:50:17 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 13319  total_loss: 1.428  loss_cls: 0.3187  loss_box_reg: 0.4749  loss_mask: 0.3094  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.198  time: 0.6193  data_time: 0.3455  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:50:28 d2.utils.events]: \u001b[0m eta: 0:38:21  iter: 13339  total_loss: 1.292  loss_cls: 0.295  loss_box_reg: 0.4907  loss_mask: 0.2952  loss_rpn_cls: 0.06735  loss_rpn_loc: 0.1796  time: 0.6189  data_time: 0.2241  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:50:45 d2.utils.events]: \u001b[0m eta: 0:38:18  iter: 13359  total_loss: 1.426  loss_cls: 0.3079  loss_box_reg: 0.4849  loss_mask: 0.32  loss_rpn_cls: 0.06986  loss_rpn_loc: 0.2093  time: 0.6201  data_time: 0.4834  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:50:54 d2.utils.events]: \u001b[0m eta: 0:38:07  iter: 13379  total_loss: 1.152  loss_cls: 0.2265  loss_box_reg: 0.4704  loss_mask: 0.2781  loss_rpn_cls: 0.0409  loss_rpn_loc: 0.1549  time: 0.6193  data_time: 0.1599  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:51:08 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 13399  total_loss: 1.35  loss_cls: 0.282  loss_box_reg: 0.5085  loss_mask: 0.2977  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.2021  time: 0.6196  data_time: 0.3400  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:51:21 d2.utils.events]: \u001b[0m eta: 0:37:53  iter: 13419  total_loss: 1.357  loss_cls: 0.3077  loss_box_reg: 0.4894  loss_mask: 0.2982  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.1921  time: 0.6196  data_time: 0.2849  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:51:35 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 13439  total_loss: 1.444  loss_cls: 0.3296  loss_box_reg: 0.4943  loss_mask: 0.282  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.195  time: 0.6203  data_time: 0.3874  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:51:47 d2.utils.events]: \u001b[0m eta: 0:37:39  iter: 13459  total_loss: 1.354  loss_cls: 0.2905  loss_box_reg: 0.4568  loss_mask: 0.2965  loss_rpn_cls: 0.08784  loss_rpn_loc: 0.1902  time: 0.6200  data_time: 0.2527  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:51:56 d2.utils.events]: \u001b[0m eta: 0:37:31  iter: 13479  total_loss: 1.344  loss_cls: 0.2967  loss_box_reg: 0.5098  loss_mask: 0.2841  loss_rpn_cls: 0.05878  loss_rpn_loc: 0.1773  time: 0.6190  data_time: 0.1446  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:52:08 d2.utils.events]: \u001b[0m eta: 0:37:26  iter: 13499  total_loss: 1.245  loss_cls: 0.2485  loss_box_reg: 0.4785  loss_mask: 0.2794  loss_rpn_cls: 0.05375  loss_rpn_loc: 0.18  time: 0.6189  data_time: 0.2864  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:52:18 d2.utils.events]: \u001b[0m eta: 0:37:18  iter: 13519  total_loss: 1.469  loss_cls: 0.3346  loss_box_reg: 0.5306  loss_mask: 0.3007  loss_rpn_cls: 0.08247  loss_rpn_loc: 0.1892  time: 0.6184  data_time: 0.2052  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:52:30 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 13539  total_loss: 1.347  loss_cls: 0.2766  loss_box_reg: 0.4983  loss_mask: 0.3042  loss_rpn_cls: 0.04934  loss_rpn_loc: 0.2005  time: 0.6181  data_time: 0.2470  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:52:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:52:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:52:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:52:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:52:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:52:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0727 s/iter. Eval: 0.0121 s/iter. Total: 0.0855 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0754 s/iter. Eval: 0.0183 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0175 s/iter. Total: 0.0933 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:52:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.885654 (0.093842 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:52:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074937 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:52:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25671710611118254\n",
      "\u001b[32m[01/10 17:52:52 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 13559  total_loss: 1.309  loss_cls: 0.2999  loss_box_reg: 0.4886  loss_mask: 0.2894  loss_rpn_cls: 0.05771  loss_rpn_loc: 0.188  time: 0.6176  data_time: 0.2090  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:53:06 d2.utils.events]: \u001b[0m eta: 0:36:56  iter: 13579  total_loss: 1.32  loss_cls: 0.2958  loss_box_reg: 0.4757  loss_mask: 0.2995  loss_rpn_cls: 0.066  loss_rpn_loc: 0.1867  time: 0.6181  data_time: 0.3728  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:53:21 d2.utils.events]: \u001b[0m eta: 0:36:51  iter: 13599  total_loss: 1.32  loss_cls: 0.2809  loss_box_reg: 0.4902  loss_mask: 0.2856  loss_rpn_cls: 0.07187  loss_rpn_loc: 0.1963  time: 0.6187  data_time: 0.3938  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:53:33 d2.utils.events]: \u001b[0m eta: 0:36:44  iter: 13619  total_loss: 1.328  loss_cls: 0.2984  loss_box_reg: 0.4571  loss_mask: 0.2777  loss_rpn_cls: 0.07117  loss_rpn_loc: 0.1685  time: 0.6186  data_time: 0.2884  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:53:46 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 13639  total_loss: 1.386  loss_cls: 0.27  loss_box_reg: 0.495  loss_mask: 0.3  loss_rpn_cls: 0.07352  loss_rpn_loc: 0.1986  time: 0.6187  data_time: 0.3080  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:54:03 d2.utils.events]: \u001b[0m eta: 0:36:28  iter: 13659  total_loss: 1.295  loss_cls: 0.2893  loss_box_reg: 0.4624  loss_mask: 0.2881  loss_rpn_cls: 0.07261  loss_rpn_loc: 0.1836  time: 0.6200  data_time: 0.5070  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:54:14 d2.utils.events]: \u001b[0m eta: 0:36:24  iter: 13679  total_loss: 1.252  loss_cls: 0.2828  loss_box_reg: 0.4639  loss_mask: 0.2911  loss_rpn_cls: 0.0584  loss_rpn_loc: 0.1774  time: 0.6196  data_time: 0.2265  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:54:28 d2.utils.events]: \u001b[0m eta: 0:36:24  iter: 13699  total_loss: 1.269  loss_cls: 0.2556  loss_box_reg: 0.4952  loss_mask: 0.2905  loss_rpn_cls: 0.07087  loss_rpn_loc: 0.1876  time: 0.6200  data_time: 0.3455  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:54:41 d2.utils.events]: \u001b[0m eta: 0:36:22  iter: 13719  total_loss: 1.385  loss_cls: 0.2979  loss_box_reg: 0.4954  loss_mask: 0.3057  loss_rpn_cls: 0.06139  loss_rpn_loc: 0.1865  time: 0.6203  data_time: 0.3422  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:54:49 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 13739  total_loss: 1.237  loss_cls: 0.2605  loss_box_reg: 0.4603  loss_mask: 0.2802  loss_rpn_cls: 0.04331  loss_rpn_loc: 0.1633  time: 0.6190  data_time: 0.0722  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:54:59 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 13759  total_loss: 1.369  loss_cls: 0.3102  loss_box_reg: 0.4894  loss_mask: 0.3046  loss_rpn_cls: 0.05324  loss_rpn_loc: 0.174  time: 0.6183  data_time: 0.1663  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:55:15 d2.utils.events]: \u001b[0m eta: 0:35:56  iter: 13779  total_loss: 1.33  loss_cls: 0.2966  loss_box_reg: 0.4471  loss_mask: 0.3036  loss_rpn_cls: 0.07747  loss_rpn_loc: 0.2071  time: 0.6193  data_time: 0.4639  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:55:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:55:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:55:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:55:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:55:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:55:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0721 s/iter. Eval: 0.0124 s/iter. Total: 0.0851 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0746 s/iter. Eval: 0.0170 s/iter. Total: 0.0923 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0175 s/iter. Total: 0.0928 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:55:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.841061 (0.093457 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:55:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074547 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:55:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:55:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25669906943045856\n",
      "\u001b[32m[01/10 17:55:39 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 13799  total_loss: 1.422  loss_cls: 0.314  loss_box_reg: 0.4801  loss_mask: 0.2888  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.203  time: 0.6191  data_time: 0.2623  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:55:49 d2.utils.events]: \u001b[0m eta: 0:35:34  iter: 13819  total_loss: 1.294  loss_cls: 0.2721  loss_box_reg: 0.4759  loss_mask: 0.2869  loss_rpn_cls: 0.05946  loss_rpn_loc: 0.173  time: 0.6187  data_time: 0.2228  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:56:01 d2.utils.events]: \u001b[0m eta: 0:35:29  iter: 13839  total_loss: 1.379  loss_cls: 0.2798  loss_box_reg: 0.4927  loss_mask: 0.2968  loss_rpn_cls: 0.07714  loss_rpn_loc: 0.1976  time: 0.6186  data_time: 0.2698  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:56:14 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 13859  total_loss: 1.244  loss_cls: 0.2898  loss_box_reg: 0.4778  loss_mask: 0.3024  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.191  time: 0.6187  data_time: 0.3152  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:56:29 d2.utils.events]: \u001b[0m eta: 0:35:19  iter: 13879  total_loss: 1.35  loss_cls: 0.3104  loss_box_reg: 0.4863  loss_mask: 0.2881  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.202  time: 0.6193  data_time: 0.3905  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:56:37 d2.utils.events]: \u001b[0m eta: 0:35:08  iter: 13899  total_loss: 1.252  loss_cls: 0.2758  loss_box_reg: 0.466  loss_mask: 0.2855  loss_rpn_cls: 0.05054  loss_rpn_loc: 0.177  time: 0.6183  data_time: 0.1038  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:56:51 d2.utils.events]: \u001b[0m eta: 0:35:01  iter: 13919  total_loss: 1.322  loss_cls: 0.3171  loss_box_reg: 0.4607  loss_mask: 0.2913  loss_rpn_cls: 0.05989  loss_rpn_loc: 0.188  time: 0.6186  data_time: 0.3573  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:57:06 d2.utils.events]: \u001b[0m eta: 0:35:02  iter: 13939  total_loss: 1.317  loss_cls: 0.2887  loss_box_reg: 0.4505  loss_mask: 0.2831  loss_rpn_cls: 0.062  loss_rpn_loc: 0.1873  time: 0.6192  data_time: 0.4115  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:57:21 d2.utils.events]: \u001b[0m eta: 0:35:02  iter: 13959  total_loss: 1.423  loss_cls: 0.3145  loss_box_reg: 0.4715  loss_mask: 0.3084  loss_rpn_cls: 0.09812  loss_rpn_loc: 0.204  time: 0.6200  data_time: 0.4315  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:57:32 d2.utils.events]: \u001b[0m eta: 0:34:49  iter: 13979  total_loss: 1.266  loss_cls: 0.2802  loss_box_reg: 0.502  loss_mask: 0.2893  loss_rpn_cls: 0.04874  loss_rpn_loc: 0.1636  time: 0.6196  data_time: 0.2179  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:57:46 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 13999  total_loss: 1.403  loss_cls: 0.3196  loss_box_reg: 0.5029  loss_mask: 0.2805  loss_rpn_cls: 0.07215  loss_rpn_loc: 0.1954  time: 0.6199  data_time: 0.3360  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:57:57 d2.utils.events]: \u001b[0m eta: 0:34:36  iter: 14019  total_loss: 1.304  loss_cls: 0.2766  loss_box_reg: 0.4794  loss_mask: 0.299  loss_rpn_cls: 0.0646  loss_rpn_loc: 0.1911  time: 0.6196  data_time: 0.2408  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:58:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:58:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 17:58:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 17:58:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 17:58:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 17:58:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 17:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0729 s/iter. Eval: 0.0119 s/iter. Total: 0.0854 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 17:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0012 s/iter. Inference: 0.0759 s/iter. Eval: 0.0173 s/iter. Total: 0.0944 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 17:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0010 s/iter. Inference: 0.0753 s/iter. Eval: 0.0168 s/iter. Total: 0.0931 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 17:58:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.874184 (0.093743 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:58:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075333 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 17:58:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 17:58:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2544119399420935\n",
      "\u001b[32m[01/10 17:58:21 d2.utils.events]: \u001b[0m eta: 0:34:30  iter: 14039  total_loss: 1.329  loss_cls: 0.2748  loss_box_reg: 0.4998  loss_mask: 0.3127  loss_rpn_cls: 0.07726  loss_rpn_loc: 0.1923  time: 0.6194  data_time: 0.2560  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:58:36 d2.utils.events]: \u001b[0m eta: 0:34:26  iter: 14059  total_loss: 1.398  loss_cls: 0.3064  loss_box_reg: 0.4688  loss_mask: 0.3053  loss_rpn_cls: 0.07079  loss_rpn_loc: 0.2087  time: 0.6200  data_time: 0.4022  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:58:47 d2.utils.events]: \u001b[0m eta: 0:34:13  iter: 14079  total_loss: 1.264  loss_cls: 0.2628  loss_box_reg: 0.5023  loss_mask: 0.2785  loss_rpn_cls: 0.04197  loss_rpn_loc: 0.1822  time: 0.6197  data_time: 0.2405  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:58:55 d2.utils.events]: \u001b[0m eta: 0:34:05  iter: 14099  total_loss: 1.378  loss_cls: 0.2859  loss_box_reg: 0.4953  loss_mask: 0.3119  loss_rpn_cls: 0.05901  loss_rpn_loc: 0.1739  time: 0.6187  data_time: 0.1083  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:59:09 d2.utils.events]: \u001b[0m eta: 0:34:05  iter: 14119  total_loss: 1.404  loss_cls: 0.3044  loss_box_reg: 0.4809  loss_mask: 0.296  loss_rpn_cls: 0.0855  loss_rpn_loc: 0.2094  time: 0.6190  data_time: 0.3312  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:59:22 d2.utils.events]: \u001b[0m eta: 0:34:00  iter: 14139  total_loss: 1.226  loss_cls: 0.2307  loss_box_reg: 0.4476  loss_mask: 0.2737  loss_rpn_cls: 0.05945  loss_rpn_loc: 0.176  time: 0.6192  data_time: 0.3259  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:59:36 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 14159  total_loss: 1.378  loss_cls: 0.3024  loss_box_reg: 0.4739  loss_mask: 0.2946  loss_rpn_cls: 0.07721  loss_rpn_loc: 0.1891  time: 0.6197  data_time: 0.3939  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 17:59:50 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 14179  total_loss: 1.372  loss_cls: 0.2878  loss_box_reg: 0.4623  loss_mask: 0.3044  loss_rpn_cls: 0.06717  loss_rpn_loc: 0.177  time: 0.6199  data_time: 0.3505  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:00:03 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 14199  total_loss: 1.481  loss_cls: 0.3551  loss_box_reg: 0.5114  loss_mask: 0.298  loss_rpn_cls: 0.08126  loss_rpn_loc: 0.2011  time: 0.6201  data_time: 0.3331  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:00:14 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 14219  total_loss: 1.414  loss_cls: 0.3111  loss_box_reg: 0.5319  loss_mask: 0.3158  loss_rpn_cls: 0.06642  loss_rpn_loc: 0.1904  time: 0.6199  data_time: 0.2419  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:00:29 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 14239  total_loss: 1.384  loss_cls: 0.2985  loss_box_reg: 0.4979  loss_mask: 0.3119  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.1869  time: 0.6205  data_time: 0.3917  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:00:41 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 14259  total_loss: 1.525  loss_cls: 0.3327  loss_box_reg: 0.4944  loss_mask: 0.3031  loss_rpn_cls: 0.08063  loss_rpn_loc: 0.2228  time: 0.6202  data_time: 0.2389  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:00:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:00:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:00:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:00:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:00:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:00:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0721 s/iter. Eval: 0.0118 s/iter. Total: 0.0846 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0758 s/iter. Eval: 0.0178 s/iter. Total: 0.0945 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:01:02 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0760 s/iter. Eval: 0.0179 s/iter. Total: 0.0947 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:01:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.075638 (0.095480 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:01:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076022 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:01:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:01:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25733773906229046\n",
      "\u001b[32m[01/10 18:01:03 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 14279  total_loss: 1.274  loss_cls: 0.2947  loss_box_reg: 0.4519  loss_mask: 0.2745  loss_rpn_cls: 0.0401  loss_rpn_loc: 0.1758  time: 0.6196  data_time: 0.1776  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:01:12 d2.utils.events]: \u001b[0m eta: 0:33:04  iter: 14299  total_loss: 1.316  loss_cls: 0.3023  loss_box_reg: 0.5074  loss_mask: 0.2835  loss_rpn_cls: 0.04894  loss_rpn_loc: 0.1625  time: 0.6188  data_time: 0.1307  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:01:22 d2.utils.events]: \u001b[0m eta: 0:32:54  iter: 14319  total_loss: 1.26  loss_cls: 0.2558  loss_box_reg: 0.4796  loss_mask: 0.2921  loss_rpn_cls: 0.06729  loss_rpn_loc: 0.1785  time: 0.6183  data_time: 0.2060  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:01:33 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 14339  total_loss: 1.374  loss_cls: 0.2794  loss_box_reg: 0.4952  loss_mask: 0.2953  loss_rpn_cls: 0.03641  loss_rpn_loc: 0.1671  time: 0.6179  data_time: 0.1990  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:01:49 d2.utils.events]: \u001b[0m eta: 0:32:36  iter: 14359  total_loss: 1.348  loss_cls: 0.2857  loss_box_reg: 0.4582  loss_mask: 0.2935  loss_rpn_cls: 0.08917  loss_rpn_loc: 0.1884  time: 0.6187  data_time: 0.4698  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:01:59 d2.utils.events]: \u001b[0m eta: 0:32:31  iter: 14379  total_loss: 1.304  loss_cls: 0.3058  loss_box_reg: 0.4845  loss_mask: 0.2955  loss_rpn_cls: 0.05802  loss_rpn_loc: 0.1759  time: 0.6182  data_time: 0.1725  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:02:11 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 14399  total_loss: 1.397  loss_cls: 0.3393  loss_box_reg: 0.4834  loss_mask: 0.2975  loss_rpn_cls: 0.07506  loss_rpn_loc: 0.1984  time: 0.6182  data_time: 0.2883  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:02:22 d2.utils.events]: \u001b[0m eta: 0:32:15  iter: 14419  total_loss: 1.271  loss_cls: 0.2663  loss_box_reg: 0.4677  loss_mask: 0.2749  loss_rpn_cls: 0.04418  loss_rpn_loc: 0.168  time: 0.6178  data_time: 0.2292  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:02:34 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 14439  total_loss: 1.253  loss_cls: 0.2621  loss_box_reg: 0.4607  loss_mask: 0.2897  loss_rpn_cls: 0.05893  loss_rpn_loc: 0.1715  time: 0.6178  data_time: 0.2864  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:02:46 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 14459  total_loss: 1.267  loss_cls: 0.2782  loss_box_reg: 0.5079  loss_mask: 0.2905  loss_rpn_cls: 0.0347  loss_rpn_loc: 0.1683  time: 0.6177  data_time: 0.2626  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:02:59 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 14479  total_loss: 1.389  loss_cls: 0.2872  loss_box_reg: 0.4932  loss_mask: 0.3113  loss_rpn_cls: 0.06806  loss_rpn_loc: 0.1925  time: 0.6178  data_time: 0.3056  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:03:09 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 14499  total_loss: 1.283  loss_cls: 0.2782  loss_box_reg: 0.48  loss_mask: 0.2912  loss_rpn_cls: 0.06204  loss_rpn_loc: 0.1821  time: 0.6174  data_time: 0.2034  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:03:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:03:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:03:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:03:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:03:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:03:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0750 s/iter. Eval: 0.0130 s/iter. Total: 0.0887 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0757 s/iter. Eval: 0.0172 s/iter. Total: 0.0938 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0752 s/iter. Eval: 0.0175 s/iter. Total: 0.0935 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:03:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.944757 (0.094351 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:03:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075262 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:03:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25719940252096196\n",
      "\u001b[32m[01/10 18:03:33 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 14519  total_loss: 1.286  loss_cls: 0.2869  loss_box_reg: 0.4564  loss_mask: 0.2825  loss_rpn_cls: 0.06038  loss_rpn_loc: 0.1738  time: 0.6172  data_time: 0.2555  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:03:44 d2.utils.events]: \u001b[0m eta: 0:31:35  iter: 14539  total_loss: 1.39  loss_cls: 0.2975  loss_box_reg: 0.4992  loss_mask: 0.3039  loss_rpn_cls: 0.06097  loss_rpn_loc: 0.1839  time: 0.6169  data_time: 0.2362  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:04:00 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 14559  total_loss: 1.441  loss_cls: 0.3082  loss_box_reg: 0.481  loss_mask: 0.3095  loss_rpn_cls: 0.09675  loss_rpn_loc: 0.2177  time: 0.6177  data_time: 0.4423  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:04:13 d2.utils.events]: \u001b[0m eta: 0:31:26  iter: 14579  total_loss: 1.266  loss_cls: 0.3011  loss_box_reg: 0.4691  loss_mask: 0.2694  loss_rpn_cls: 0.05073  loss_rpn_loc: 0.1778  time: 0.6179  data_time: 0.3372  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:04:31 d2.utils.events]: \u001b[0m eta: 0:31:19  iter: 14599  total_loss: 1.361  loss_cls: 0.327  loss_box_reg: 0.5001  loss_mask: 0.3087  loss_rpn_cls: 0.101  loss_rpn_loc: 0.199  time: 0.6191  data_time: 0.5503  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:04:43 d2.utils.events]: \u001b[0m eta: 0:31:15  iter: 14619  total_loss: 1.356  loss_cls: 0.3059  loss_box_reg: 0.498  loss_mask: 0.284  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.1915  time: 0.6190  data_time: 0.2790  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:04:54 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 14639  total_loss: 1.439  loss_cls: 0.323  loss_box_reg: 0.5151  loss_mask: 0.2988  loss_rpn_cls: 0.08073  loss_rpn_loc: 0.2068  time: 0.6187  data_time: 0.2140  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:05:05 d2.utils.events]: \u001b[0m eta: 0:31:00  iter: 14659  total_loss: 1.236  loss_cls: 0.2688  loss_box_reg: 0.4559  loss_mask: 0.2708  loss_rpn_cls: 0.0574  loss_rpn_loc: 0.1624  time: 0.6183  data_time: 0.1949  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:05:17 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 14679  total_loss: 1.282  loss_cls: 0.2557  loss_box_reg: 0.472  loss_mask: 0.2853  loss_rpn_cls: 0.04618  loss_rpn_loc: 0.182  time: 0.6184  data_time: 0.3121  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:05:32 d2.utils.events]: \u001b[0m eta: 0:30:45  iter: 14699  total_loss: 1.472  loss_cls: 0.3607  loss_box_reg: 0.4936  loss_mask: 0.3058  loss_rpn_cls: 0.07972  loss_rpn_loc: 0.2025  time: 0.6189  data_time: 0.3965  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:05:41 d2.utils.events]: \u001b[0m eta: 0:30:34  iter: 14719  total_loss: 1.246  loss_cls: 0.2526  loss_box_reg: 0.4555  loss_mask: 0.2859  loss_rpn_cls: 0.04519  loss_rpn_loc: 0.1694  time: 0.6181  data_time: 0.1315  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:05:56 d2.utils.events]: \u001b[0m eta: 0:30:30  iter: 14739  total_loss: 1.32  loss_cls: 0.3112  loss_box_reg: 0.461  loss_mask: 0.2969  loss_rpn_cls: 0.08424  loss_rpn_loc: 0.1887  time: 0.6186  data_time: 0.3967  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:06:08 d2.utils.events]: \u001b[0m eta: 0:30:26  iter: 14759  total_loss: 1.401  loss_cls: 0.3239  loss_box_reg: 0.4754  loss_mask: 0.3034  loss_rpn_cls: 0.06097  loss_rpn_loc: 0.1856  time: 0.6186  data_time: 0.3011  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:06:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:06:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:06:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:06:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:06:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:06:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0722 s/iter. Eval: 0.0126 s/iter. Total: 0.0854 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0764 s/iter. Eval: 0.0196 s/iter. Total: 0.0969 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0758 s/iter. Eval: 0.0191 s/iter. Total: 0.0958 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:06:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.170831 (0.096300 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:06:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075808 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:06:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:06:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25545423210898754\n",
      "\u001b[32m[01/10 18:06:33 d2.utils.events]: \u001b[0m eta: 0:30:16  iter: 14779  total_loss: 1.435  loss_cls: 0.3148  loss_box_reg: 0.4993  loss_mask: 0.3018  loss_rpn_cls: 0.06939  loss_rpn_loc: 0.2104  time: 0.6186  data_time: 0.2712  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:06:48 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 14799  total_loss: 1.21  loss_cls: 0.2837  loss_box_reg: 0.4576  loss_mask: 0.2762  loss_rpn_cls: 0.07142  loss_rpn_loc: 0.1672  time: 0.6192  data_time: 0.4264  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:06:58 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 14819  total_loss: 1.274  loss_cls: 0.2739  loss_box_reg: 0.4937  loss_mask: 0.2879  loss_rpn_cls: 0.05687  loss_rpn_loc: 0.1818  time: 0.6187  data_time: 0.1864  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:07:12 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 14839  total_loss: 1.264  loss_cls: 0.2754  loss_box_reg: 0.4506  loss_mask: 0.2854  loss_rpn_cls: 0.05034  loss_rpn_loc: 0.1841  time: 0.6189  data_time: 0.3528  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:07:25 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 14859  total_loss: 1.334  loss_cls: 0.3092  loss_box_reg: 0.4703  loss_mask: 0.2835  loss_rpn_cls: 0.08402  loss_rpn_loc: 0.1965  time: 0.6190  data_time: 0.3137  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:07:38 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 14879  total_loss: 1.343  loss_cls: 0.3109  loss_box_reg: 0.5  loss_mask: 0.2997  loss_rpn_cls: 0.05942  loss_rpn_loc: 0.1806  time: 0.6192  data_time: 0.3215  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:07:49 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 14899  total_loss: 1.367  loss_cls: 0.2914  loss_box_reg: 0.5026  loss_mask: 0.3062  loss_rpn_cls: 0.05289  loss_rpn_loc: 0.1782  time: 0.6189  data_time: 0.2340  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:08:01 d2.utils.events]: \u001b[0m eta: 0:29:32  iter: 14919  total_loss: 1.307  loss_cls: 0.2934  loss_box_reg: 0.4839  loss_mask: 0.2889  loss_rpn_cls: 0.06595  loss_rpn_loc: 0.1716  time: 0.6189  data_time: 0.2918  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:08:11 d2.utils.events]: \u001b[0m eta: 0:29:22  iter: 14939  total_loss: 1.348  loss_cls: 0.2708  loss_box_reg: 0.4761  loss_mask: 0.2869  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.1902  time: 0.6185  data_time: 0.1925  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:08:22 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 14959  total_loss: 1.234  loss_cls: 0.2502  loss_box_reg: 0.4527  loss_mask: 0.2894  loss_rpn_cls: 0.05407  loss_rpn_loc: 0.1784  time: 0.6181  data_time: 0.2016  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:08:38 d2.utils.events]: \u001b[0m eta: 0:29:06  iter: 14979  total_loss: 1.339  loss_cls: 0.2742  loss_box_reg: 0.4579  loss_mask: 0.3124  loss_rpn_cls: 0.06215  loss_rpn_loc: 0.1862  time: 0.6188  data_time: 0.4629  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:08:51 d2.utils.events]: \u001b[0m eta: 0:28:59  iter: 14999  total_loss: 1.422  loss_cls: 0.3339  loss_box_reg: 0.5201  loss_mask: 0.3069  loss_rpn_cls: 0.06559  loss_rpn_loc: 0.1954  time: 0.6189  data_time: 0.3112  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:08:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:08:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:08:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:08:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:08:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:08:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0717 s/iter. Eval: 0.0115 s/iter. Total: 0.0838 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0744 s/iter. Eval: 0.0166 s/iter. Total: 0.0917 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0009 s/iter. Inference: 0.0748 s/iter. Eval: 0.0173 s/iter. Total: 0.0931 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:09:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.877444 (0.093771 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:09:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074934 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:09:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:09:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2577098443732723\n",
      "\u001b[32m[01/10 18:09:15 d2.utils.events]: \u001b[0m eta: 0:28:52  iter: 15019  total_loss: 1.293  loss_cls: 0.2875  loss_box_reg: 0.4925  loss_mask: 0.2852  loss_rpn_cls: 0.05619  loss_rpn_loc: 0.174  time: 0.6189  data_time: 0.2753  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:09:27 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 15039  total_loss: 1.307  loss_cls: 0.3058  loss_box_reg: 0.4868  loss_mask: 0.2935  loss_rpn_cls: 0.04233  loss_rpn_loc: 0.1829  time: 0.6187  data_time: 0.2291  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:09:42 d2.utils.events]: \u001b[0m eta: 0:28:38  iter: 15059  total_loss: 1.368  loss_cls: 0.3012  loss_box_reg: 0.4428  loss_mask: 0.2919  loss_rpn_cls: 0.09668  loss_rpn_loc: 0.207  time: 0.6192  data_time: 0.4252  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:09:53 d2.utils.events]: \u001b[0m eta: 0:28:31  iter: 15079  total_loss: 1.328  loss_cls: 0.2742  loss_box_reg: 0.5061  loss_mask: 0.3  loss_rpn_cls: 0.0541  loss_rpn_loc: 0.1718  time: 0.6191  data_time: 0.2603  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:10:05 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 15099  total_loss: 1.323  loss_cls: 0.2951  loss_box_reg: 0.4926  loss_mask: 0.2868  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.1818  time: 0.6189  data_time: 0.2374  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:10:20 d2.utils.events]: \u001b[0m eta: 0:28:18  iter: 15119  total_loss: 1.4  loss_cls: 0.3122  loss_box_reg: 0.4982  loss_mask: 0.3262  loss_rpn_cls: 0.07372  loss_rpn_loc: 0.2091  time: 0.6193  data_time: 0.3857  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:10:29 d2.utils.events]: \u001b[0m eta: 0:28:10  iter: 15139  total_loss: 1.362  loss_cls: 0.322  loss_box_reg: 0.4951  loss_mask: 0.2916  loss_rpn_cls: 0.06273  loss_rpn_loc: 0.1687  time: 0.6188  data_time: 0.1688  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:10:39 d2.utils.events]: \u001b[0m eta: 0:28:00  iter: 15159  total_loss: 1.307  loss_cls: 0.2713  loss_box_reg: 0.4822  loss_mask: 0.2886  loss_rpn_cls: 0.05098  loss_rpn_loc: 0.1696  time: 0.6183  data_time: 0.1679  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:10:53 d2.utils.events]: \u001b[0m eta: 0:27:54  iter: 15179  total_loss: 1.432  loss_cls: 0.3389  loss_box_reg: 0.514  loss_mask: 0.2958  loss_rpn_cls: 0.08715  loss_rpn_loc: 0.1953  time: 0.6186  data_time: 0.3762  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:11:05 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 15199  total_loss: 1.368  loss_cls: 0.3151  loss_box_reg: 0.4762  loss_mask: 0.2954  loss_rpn_cls: 0.07354  loss_rpn_loc: 0.1806  time: 0.6185  data_time: 0.2608  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:11:20 d2.utils.events]: \u001b[0m eta: 0:27:41  iter: 15219  total_loss: 1.287  loss_cls: 0.2584  loss_box_reg: 0.4558  loss_mask: 0.2904  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.1777  time: 0.6191  data_time: 0.4337  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:11:34 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 15239  total_loss: 1.27  loss_cls: 0.2686  loss_box_reg: 0.4809  loss_mask: 0.2859  loss_rpn_cls: 0.06891  loss_rpn_loc: 0.1864  time: 0.6193  data_time: 0.3340  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:11:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:11:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:11:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:11:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:11:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:11:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:11:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0132 s/iter. Total: 0.0859 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0168 s/iter. Total: 0.0921 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0749 s/iter. Eval: 0.0170 s/iter. Total: 0.0928 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:11:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.866114 (0.093673 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:11:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074996 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:11:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:11:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25970604674921566\n",
      "\u001b[32m[01/10 18:12:00 d2.utils.events]: \u001b[0m eta: 0:27:25  iter: 15259  total_loss: 1.331  loss_cls: 0.3002  loss_box_reg: 0.4548  loss_mask: 0.2919  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.1783  time: 0.6196  data_time: 0.3709  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:12:12 d2.utils.events]: \u001b[0m eta: 0:27:21  iter: 15279  total_loss: 1.303  loss_cls: 0.2997  loss_box_reg: 0.4636  loss_mask: 0.2832  loss_rpn_cls: 0.06351  loss_rpn_loc: 0.1867  time: 0.6195  data_time: 0.2879  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:12:23 d2.utils.events]: \u001b[0m eta: 0:27:15  iter: 15299  total_loss: 1.278  loss_cls: 0.2725  loss_box_reg: 0.4696  loss_mask: 0.2792  loss_rpn_cls: 0.05071  loss_rpn_loc: 0.1694  time: 0.6193  data_time: 0.2302  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:12:34 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 15319  total_loss: 1.295  loss_cls: 0.2695  loss_box_reg: 0.4795  loss_mask: 0.2862  loss_rpn_cls: 0.0446  loss_rpn_loc: 0.1784  time: 0.6190  data_time: 0.2143  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:12:47 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 15339  total_loss: 1.331  loss_cls: 0.294  loss_box_reg: 0.4758  loss_mask: 0.2938  loss_rpn_cls: 0.08734  loss_rpn_loc: 0.1815  time: 0.6191  data_time: 0.3164  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:13:00 d2.utils.events]: \u001b[0m eta: 0:26:54  iter: 15359  total_loss: 1.226  loss_cls: 0.2787  loss_box_reg: 0.4802  loss_mask: 0.2901  loss_rpn_cls: 0.04991  loss_rpn_loc: 0.1782  time: 0.6192  data_time: 0.3195  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:13:09 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 15379  total_loss: 1.361  loss_cls: 0.3011  loss_box_reg: 0.4764  loss_mask: 0.2874  loss_rpn_cls: 0.05634  loss_rpn_loc: 0.1742  time: 0.6187  data_time: 0.1806  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:13:20 d2.utils.events]: \u001b[0m eta: 0:26:38  iter: 15399  total_loss: 1.281  loss_cls: 0.2861  loss_box_reg: 0.4781  loss_mask: 0.2915  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.1657  time: 0.6184  data_time: 0.2373  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:13:35 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 15419  total_loss: 1.328  loss_cls: 0.265  loss_box_reg: 0.4778  loss_mask: 0.2974  loss_rpn_cls: 0.06695  loss_rpn_loc: 0.1776  time: 0.6188  data_time: 0.4047  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:13:48 d2.utils.events]: \u001b[0m eta: 0:26:24  iter: 15439  total_loss: 1.282  loss_cls: 0.2803  loss_box_reg: 0.4537  loss_mask: 0.2879  loss_rpn_cls: 0.07565  loss_rpn_loc: 0.1819  time: 0.6189  data_time: 0.3078  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:14:01 d2.utils.events]: \u001b[0m eta: 0:26:17  iter: 15459  total_loss: 1.278  loss_cls: 0.2843  loss_box_reg: 0.4399  loss_mask: 0.2989  loss_rpn_cls: 0.0564  loss_rpn_loc: 0.1975  time: 0.6190  data_time: 0.3432  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:14:14 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 15479  total_loss: 1.303  loss_cls: 0.3012  loss_box_reg: 0.4753  loss_mask: 0.2876  loss_rpn_cls: 0.061  loss_rpn_loc: 0.1737  time: 0.6193  data_time: 0.3537  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:14:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:14:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:14:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:14:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:14:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:14:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:14:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0728 s/iter. Eval: 0.0121 s/iter. Total: 0.0855 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:14:27 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0752 s/iter. Eval: 0.0180 s/iter. Total: 0.0940 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0751 s/iter. Eval: 0.0183 s/iter. Total: 0.0941 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:14:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.044251 (0.095209 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:14:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075300 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:14:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:14:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2584461493467797\n",
      "\u001b[32m[01/10 18:14:38 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 15499  total_loss: 1.317  loss_cls: 0.2715  loss_box_reg: 0.5111  loss_mask: 0.3042  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.1904  time: 0.6191  data_time: 0.2306  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:14:49 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 15519  total_loss: 1.363  loss_cls: 0.3118  loss_box_reg: 0.5051  loss_mask: 0.3059  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.1827  time: 0.6187  data_time: 0.1988  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:15:03 d2.utils.events]: \u001b[0m eta: 0:25:48  iter: 15539  total_loss: 1.325  loss_cls: 0.2713  loss_box_reg: 0.4404  loss_mask: 0.2897  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.1967  time: 0.6190  data_time: 0.3797  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:15:14 d2.utils.events]: \u001b[0m eta: 0:25:37  iter: 15559  total_loss: 1.393  loss_cls: 0.2902  loss_box_reg: 0.5031  loss_mask: 0.2942  loss_rpn_cls: 0.06885  loss_rpn_loc: 0.2034  time: 0.6189  data_time: 0.2507  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:15:29 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 15579  total_loss: 1.481  loss_cls: 0.3395  loss_box_reg: 0.5396  loss_mask: 0.3046  loss_rpn_cls: 0.07947  loss_rpn_loc: 0.2065  time: 0.6192  data_time: 0.3652  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:15:42 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 15599  total_loss: 1.267  loss_cls: 0.2972  loss_box_reg: 0.482  loss_mask: 0.2994  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.1842  time: 0.6193  data_time: 0.3151  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:15:56 d2.utils.events]: \u001b[0m eta: 0:25:17  iter: 15619  total_loss: 1.282  loss_cls: 0.2733  loss_box_reg: 0.4588  loss_mask: 0.2863  loss_rpn_cls: 0.05753  loss_rpn_loc: 0.1874  time: 0.6196  data_time: 0.3633  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:16:06 d2.utils.events]: \u001b[0m eta: 0:25:09  iter: 15639  total_loss: 1.29  loss_cls: 0.3048  loss_box_reg: 0.5017  loss_mask: 0.2678  loss_rpn_cls: 0.06185  loss_rpn_loc: 0.1749  time: 0.6192  data_time: 0.1857  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:16:21 d2.utils.events]: \u001b[0m eta: 0:25:07  iter: 15659  total_loss: 1.392  loss_cls: 0.2938  loss_box_reg: 0.4981  loss_mask: 0.3022  loss_rpn_cls: 0.08327  loss_rpn_loc: 0.199  time: 0.6196  data_time: 0.3975  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:16:33 d2.utils.events]: \u001b[0m eta: 0:25:00  iter: 15679  total_loss: 1.375  loss_cls: 0.2843  loss_box_reg: 0.4935  loss_mask: 0.2989  loss_rpn_cls: 0.09198  loss_rpn_loc: 0.1923  time: 0.6197  data_time: 0.3082  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:16:45 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 15699  total_loss: 1.303  loss_cls: 0.2862  loss_box_reg: 0.4841  loss_mask: 0.2881  loss_rpn_cls: 0.04345  loss_rpn_loc: 0.1626  time: 0.6195  data_time: 0.2421  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:16:56 d2.utils.events]: \u001b[0m eta: 0:24:47  iter: 15719  total_loss: 1.299  loss_cls: 0.2794  loss_box_reg: 0.4761  loss_mask: 0.2809  loss_rpn_cls: 0.04912  loss_rpn_loc: 0.1773  time: 0.6194  data_time: 0.2568  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:17:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:17:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:17:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:17:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:17:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:17:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0723 s/iter. Eval: 0.0121 s/iter. Total: 0.0850 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0752 s/iter. Eval: 0.0177 s/iter. Total: 0.0938 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0755 s/iter. Eval: 0.0184 s/iter. Total: 0.0947 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:17:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.078906 (0.095508 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:17:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075571 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:17:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:17:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25892633065916665\n",
      "\u001b[32m[01/10 18:17:18 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 15739  total_loss: 1.453  loss_cls: 0.3328  loss_box_reg: 0.5325  loss_mask: 0.3057  loss_rpn_cls: 0.07074  loss_rpn_loc: 0.2023  time: 0.6189  data_time: 0.1722  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:17:30 d2.utils.events]: \u001b[0m eta: 0:24:31  iter: 15759  total_loss: 1.375  loss_cls: 0.3334  loss_box_reg: 0.4896  loss_mask: 0.2837  loss_rpn_cls: 0.07757  loss_rpn_loc: 0.1853  time: 0.6187  data_time: 0.2502  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:17:41 d2.utils.events]: \u001b[0m eta: 0:24:21  iter: 15779  total_loss: 1.215  loss_cls: 0.2892  loss_box_reg: 0.4702  loss_mask: 0.2751  loss_rpn_cls: 0.06147  loss_rpn_loc: 0.1709  time: 0.6185  data_time: 0.2210  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:17:52 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 15799  total_loss: 1.343  loss_cls: 0.309  loss_box_reg: 0.4433  loss_mask: 0.2902  loss_rpn_cls: 0.07252  loss_rpn_loc: 0.1899  time: 0.6182  data_time: 0.2328  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:18:06 d2.utils.events]: \u001b[0m eta: 0:24:04  iter: 15819  total_loss: 1.367  loss_cls: 0.3346  loss_box_reg: 0.449  loss_mask: 0.2921  loss_rpn_cls: 0.07258  loss_rpn_loc: 0.194  time: 0.6186  data_time: 0.3714  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:18:19 d2.utils.events]: \u001b[0m eta: 0:23:55  iter: 15839  total_loss: 1.289  loss_cls: 0.2984  loss_box_reg: 0.473  loss_mask: 0.2887  loss_rpn_cls: 0.0424  loss_rpn_loc: 0.1678  time: 0.6187  data_time: 0.3335  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:18:30 d2.utils.events]: \u001b[0m eta: 0:23:47  iter: 15859  total_loss: 1.412  loss_cls: 0.3266  loss_box_reg: 0.5187  loss_mask: 0.3036  loss_rpn_cls: 0.08256  loss_rpn_loc: 0.1878  time: 0.6184  data_time: 0.2158  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:18:43 d2.utils.events]: \u001b[0m eta: 0:23:40  iter: 15879  total_loss: 1.294  loss_cls: 0.3092  loss_box_reg: 0.439  loss_mask: 0.2696  loss_rpn_cls: 0.05438  loss_rpn_loc: 0.1839  time: 0.6186  data_time: 0.3282  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:18:56 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 15899  total_loss: 1.315  loss_cls: 0.27  loss_box_reg: 0.4792  loss_mask: 0.2954  loss_rpn_cls: 0.06232  loss_rpn_loc: 0.1787  time: 0.6186  data_time: 0.3120  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:19:08 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 15919  total_loss: 1.276  loss_cls: 0.2793  loss_box_reg: 0.473  loss_mask: 0.2885  loss_rpn_cls: 0.06372  loss_rpn_loc: 0.1618  time: 0.6185  data_time: 0.2607  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:19:22 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 15939  total_loss: 1.313  loss_cls: 0.2885  loss_box_reg: 0.4571  loss_mask: 0.3093  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.1934  time: 0.6189  data_time: 0.3712  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:19:35 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 15959  total_loss: 1.285  loss_cls: 0.2744  loss_box_reg: 0.4832  loss_mask: 0.3004  loss_rpn_cls: 0.04721  loss_rpn_loc: 0.1727  time: 0.6189  data_time: 0.2902  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:19:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:19:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:19:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:19:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:19:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:19:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0138 s/iter. Total: 0.0898 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0765 s/iter. Eval: 0.0181 s/iter. Total: 0.0954 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.0767 s/iter. Eval: 0.0188 s/iter. Total: 0.0963 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:19:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.257028 (0.097043 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:19:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076602 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:19:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:19:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2612429854054345\n",
      "\u001b[32m[01/10 18:19:59 d2.utils.events]: \u001b[0m eta: 0:23:06  iter: 15979  total_loss: 1.323  loss_cls: 0.3045  loss_box_reg: 0.4678  loss_mask: 0.2981  loss_rpn_cls: 0.06799  loss_rpn_loc: 0.1832  time: 0.6188  data_time: 0.2820  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:20:10 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 15999  total_loss: 1.349  loss_cls: 0.276  loss_box_reg: 0.5087  loss_mask: 0.2891  loss_rpn_cls: 0.05925  loss_rpn_loc: 0.1817  time: 0.6185  data_time: 0.2142  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:20:22 d2.utils.events]: \u001b[0m eta: 0:22:50  iter: 16019  total_loss: 1.369  loss_cls: 0.2843  loss_box_reg: 0.4832  loss_mask: 0.2892  loss_rpn_cls: 0.04709  loss_rpn_loc: 0.1895  time: 0.6185  data_time: 0.2931  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:20:34 d2.utils.events]: \u001b[0m eta: 0:22:42  iter: 16039  total_loss: 1.283  loss_cls: 0.2696  loss_box_reg: 0.4848  loss_mask: 0.2873  loss_rpn_cls: 0.0526  loss_rpn_loc: 0.1798  time: 0.6183  data_time: 0.2404  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:20:48 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 16059  total_loss: 1.402  loss_cls: 0.3095  loss_box_reg: 0.4786  loss_mask: 0.3024  loss_rpn_cls: 0.07217  loss_rpn_loc: 0.1964  time: 0.6186  data_time: 0.3705  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:21:05 d2.utils.events]: \u001b[0m eta: 0:22:30  iter: 16079  total_loss: 1.267  loss_cls: 0.2478  loss_box_reg: 0.4469  loss_mask: 0.2926  loss_rpn_cls: 0.06143  loss_rpn_loc: 0.1655  time: 0.6194  data_time: 0.5226  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:21:17 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 16099  total_loss: 1.207  loss_cls: 0.2688  loss_box_reg: 0.4787  loss_mask: 0.2898  loss_rpn_cls: 0.03531  loss_rpn_loc: 0.1605  time: 0.6193  data_time: 0.2725  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:21:32 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 16119  total_loss: 1.315  loss_cls: 0.2941  loss_box_reg: 0.4649  loss_mask: 0.2858  loss_rpn_cls: 0.06928  loss_rpn_loc: 0.1956  time: 0.6198  data_time: 0.4132  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:21:43 d2.utils.events]: \u001b[0m eta: 0:22:10  iter: 16139  total_loss: 1.304  loss_cls: 0.3037  loss_box_reg: 0.4822  loss_mask: 0.3094  loss_rpn_cls: 0.06881  loss_rpn_loc: 0.2009  time: 0.6195  data_time: 0.2181  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:21:54 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 16159  total_loss: 1.211  loss_cls: 0.2497  loss_box_reg: 0.4372  loss_mask: 0.2739  loss_rpn_cls: 0.06035  loss_rpn_loc: 0.1686  time: 0.6194  data_time: 0.2392  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:22:07 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 16179  total_loss: 1.355  loss_cls: 0.2878  loss_box_reg: 0.5149  loss_mask: 0.2939  loss_rpn_cls: 0.05538  loss_rpn_loc: 0.1829  time: 0.6195  data_time: 0.3131  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:22:15 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 16199  total_loss: 1.197  loss_cls: 0.2771  loss_box_reg: 0.4917  loss_mask: 0.2859  loss_rpn_cls: 0.04856  loss_rpn_loc: 0.1712  time: 0.6187  data_time: 0.0841  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:22:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:22:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:22:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:22:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:22:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:22:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:22:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0727 s/iter. Eval: 0.0156 s/iter. Total: 0.0891 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:22:32 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0175 s/iter. Total: 0.0933 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:22:37 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0754 s/iter. Eval: 0.0178 s/iter. Total: 0.0940 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:22:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.985979 (0.094707 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:22:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075444 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:22:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:22:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2502205250866308\n",
      "\u001b[32m[01/10 18:22:39 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 16219  total_loss: 1.258  loss_cls: 0.2934  loss_box_reg: 0.4891  loss_mask: 0.3049  loss_rpn_cls: 0.04692  loss_rpn_loc: 0.1752  time: 0.6187  data_time: 0.2707  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:22:51 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 16239  total_loss: 1.324  loss_cls: 0.2789  loss_box_reg: 0.4728  loss_mask: 0.3154  loss_rpn_cls: 0.07863  loss_rpn_loc: 0.185  time: 0.6185  data_time: 0.2456  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:23:05 d2.utils.events]: \u001b[0m eta: 0:21:31  iter: 16259  total_loss: 1.374  loss_cls: 0.3031  loss_box_reg: 0.5014  loss_mask: 0.3022  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.2132  time: 0.6188  data_time: 0.3873  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:23:20 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 16279  total_loss: 1.284  loss_cls: 0.2857  loss_box_reg: 0.4737  loss_mask: 0.2886  loss_rpn_cls: 0.06221  loss_rpn_loc: 0.1718  time: 0.6192  data_time: 0.3974  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:23:32 d2.utils.events]: \u001b[0m eta: 0:21:17  iter: 16299  total_loss: 1.264  loss_cls: 0.3091  loss_box_reg: 0.461  loss_mask: 0.2836  loss_rpn_cls: 0.06662  loss_rpn_loc: 0.1694  time: 0.6191  data_time: 0.2757  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:23:47 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 16319  total_loss: 1.34  loss_cls: 0.3027  loss_box_reg: 0.4674  loss_mask: 0.2959  loss_rpn_cls: 0.06639  loss_rpn_loc: 0.187  time: 0.6195  data_time: 0.4102  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:24:03 d2.utils.events]: \u001b[0m eta: 0:21:06  iter: 16339  total_loss: 1.314  loss_cls: 0.2832  loss_box_reg: 0.4753  loss_mask: 0.2912  loss_rpn_cls: 0.05826  loss_rpn_loc: 0.182  time: 0.6202  data_time: 0.4833  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:24:15 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 16359  total_loss: 1.33  loss_cls: 0.3152  loss_box_reg: 0.4743  loss_mask: 0.2878  loss_rpn_cls: 0.05685  loss_rpn_loc: 0.2019  time: 0.6201  data_time: 0.2584  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:24:28 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 16379  total_loss: 1.359  loss_cls: 0.2634  loss_box_reg: 0.5054  loss_mask: 0.3042  loss_rpn_cls: 0.05376  loss_rpn_loc: 0.2012  time: 0.6201  data_time: 0.3165  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:24:38 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 16399  total_loss: 1.259  loss_cls: 0.2346  loss_box_reg: 0.4662  loss_mask: 0.296  loss_rpn_cls: 0.04602  loss_rpn_loc: 0.166  time: 0.6198  data_time: 0.1962  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:24:47 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 16419  total_loss: 1.348  loss_cls: 0.3096  loss_box_reg: 0.5073  loss_mask: 0.286  loss_rpn_cls: 0.04967  loss_rpn_loc: 0.1827  time: 0.6193  data_time: 0.1406  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:25:01 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 16439  total_loss: 1.34  loss_cls: 0.3012  loss_box_reg: 0.4651  loss_mask: 0.2883  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.2037  time: 0.6195  data_time: 0.3830  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:25:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:25:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:25:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:25:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:25:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:25:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0719 s/iter. Eval: 0.0122 s/iter. Total: 0.0847 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0177 s/iter. Total: 0.0936 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.0752 s/iter. Eval: 0.0184 s/iter. Total: 0.0944 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:25:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.040948 (0.095181 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:25:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075265 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:25:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:25:22 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26204013887823757\n",
      "\u001b[32m[01/10 18:25:23 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 16459  total_loss: 1.292  loss_cls: 0.2959  loss_box_reg: 0.4677  loss_mask: 0.2916  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.1859  time: 0.6192  data_time: 0.1817  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:25:34 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 16479  total_loss: 1.265  loss_cls: 0.2671  loss_box_reg: 0.4762  loss_mask: 0.293  loss_rpn_cls: 0.04665  loss_rpn_loc: 0.1651  time: 0.6189  data_time: 0.2142  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:25:49 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 16499  total_loss: 1.401  loss_cls: 0.2903  loss_box_reg: 0.4532  loss_mask: 0.2963  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.2042  time: 0.6192  data_time: 0.3973  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:26:04 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 16519  total_loss: 1.368  loss_cls: 0.3066  loss_box_reg: 0.4592  loss_mask: 0.2965  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.1989  time: 0.6196  data_time: 0.4059  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:26:16 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 16539  total_loss: 1.259  loss_cls: 0.2442  loss_box_reg: 0.4549  loss_mask: 0.2864  loss_rpn_cls: 0.06595  loss_rpn_loc: 0.1689  time: 0.6196  data_time: 0.2697  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:26:27 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 16559  total_loss: 1.338  loss_cls: 0.3298  loss_box_reg: 0.5044  loss_mask: 0.2926  loss_rpn_cls: 0.06341  loss_rpn_loc: 0.1708  time: 0.6195  data_time: 0.2440  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:26:42 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 16579  total_loss: 1.25  loss_cls: 0.2418  loss_box_reg: 0.4501  loss_mask: 0.295  loss_rpn_cls: 0.06996  loss_rpn_loc: 0.178  time: 0.6198  data_time: 0.3894  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:26:53 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 16599  total_loss: 1.222  loss_cls: 0.2609  loss_box_reg: 0.4558  loss_mask: 0.2852  loss_rpn_cls: 0.05642  loss_rpn_loc: 0.1959  time: 0.6196  data_time: 0.2571  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:27:09 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 16619  total_loss: 1.365  loss_cls: 0.3038  loss_box_reg: 0.4519  loss_mask: 0.2896  loss_rpn_cls: 0.08238  loss_rpn_loc: 0.1776  time: 0.6201  data_time: 0.4412  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:27:16 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 16639  total_loss: 1.314  loss_cls: 0.2802  loss_box_reg: 0.4884  loss_mask: 0.2846  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.1615  time: 0.6194  data_time: 0.0828  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:27:27 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 16659  total_loss: 1.283  loss_cls: 0.2758  loss_box_reg: 0.5004  loss_mask: 0.2918  loss_rpn_cls: 0.05979  loss_rpn_loc: 0.1801  time: 0.6191  data_time: 0.1923  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:27:40 d2.utils.events]: \u001b[0m eta: 0:19:04  iter: 16679  total_loss: 1.441  loss_cls: 0.2928  loss_box_reg: 0.4968  loss_mask: 0.3006  loss_rpn_cls: 0.08615  loss_rpn_loc: 0.1914  time: 0.6192  data_time: 0.3524  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:27:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:27:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:27:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:27:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:27:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:27:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0771 s/iter. Eval: 0.0131 s/iter. Total: 0.0908 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0759 s/iter. Eval: 0.0173 s/iter. Total: 0.0940 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0753 s/iter. Eval: 0.0172 s/iter. Total: 0.0932 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:28:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.923961 (0.094172 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:28:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075325 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:28:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:28:06 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25226959326158904\n",
      "\u001b[32m[01/10 18:28:07 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 16699  total_loss: 1.312  loss_cls: 0.2774  loss_box_reg: 0.4626  loss_mask: 0.2839  loss_rpn_cls: 0.06197  loss_rpn_loc: 0.19  time: 0.6196  data_time: 0.3866  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:28:16 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 16719  total_loss: 1.275  loss_cls: 0.2777  loss_box_reg: 0.4683  loss_mask: 0.3013  loss_rpn_cls: 0.04768  loss_rpn_loc: 0.1776  time: 0.6190  data_time: 0.1097  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:28:27 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 16739  total_loss: 1.283  loss_cls: 0.2642  loss_box_reg: 0.4697  loss_mask: 0.2839  loss_rpn_cls: 0.05522  loss_rpn_loc: 0.1805  time: 0.6188  data_time: 0.2342  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:28:41 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 16759  total_loss: 1.318  loss_cls: 0.2948  loss_box_reg: 0.496  loss_mask: 0.3039  loss_rpn_cls: 0.05504  loss_rpn_loc: 0.192  time: 0.6191  data_time: 0.3867  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:28:53 d2.utils.events]: \u001b[0m eta: 0:18:32  iter: 16779  total_loss: 1.419  loss_cls: 0.3094  loss_box_reg: 0.4934  loss_mask: 0.2988  loss_rpn_cls: 0.05727  loss_rpn_loc: 0.1986  time: 0.6190  data_time: 0.2773  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:29:05 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 16799  total_loss: 1.325  loss_cls: 0.2873  loss_box_reg: 0.4855  loss_mask: 0.3072  loss_rpn_cls: 0.05691  loss_rpn_loc: 0.1812  time: 0.6189  data_time: 0.2566  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:29:15 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 16819  total_loss: 1.298  loss_cls: 0.2966  loss_box_reg: 0.4681  loss_mask: 0.2884  loss_rpn_cls: 0.0403  loss_rpn_loc: 0.1656  time: 0.6185  data_time: 0.1815  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:29:27 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 16839  total_loss: 1.324  loss_cls: 0.2795  loss_box_reg: 0.4803  loss_mask: 0.3099  loss_rpn_cls: 0.06736  loss_rpn_loc: 0.1768  time: 0.6185  data_time: 0.2888  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:29:35 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 16859  total_loss: 1.365  loss_cls: 0.3126  loss_box_reg: 0.4931  loss_mask: 0.3037  loss_rpn_cls: 0.04893  loss_rpn_loc: 0.1828  time: 0.6180  data_time: 0.1145  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:29:51 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 16879  total_loss: 1.283  loss_cls: 0.2934  loss_box_reg: 0.4474  loss_mask: 0.2882  loss_rpn_cls: 0.06651  loss_rpn_loc: 0.1806  time: 0.6184  data_time: 0.4304  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:30:00 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 16899  total_loss: 1.283  loss_cls: 0.2652  loss_box_reg: 0.4757  loss_mask: 0.2912  loss_rpn_cls: 0.0554  loss_rpn_loc: 0.1822  time: 0.6180  data_time: 0.1812  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:30:12 d2.utils.events]: \u001b[0m eta: 0:17:42  iter: 16919  total_loss: 1.203  loss_cls: 0.2557  loss_box_reg: 0.4215  loss_mask: 0.2659  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.1927  time: 0.6179  data_time: 0.2401  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:30:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:30:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:30:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:30:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:30:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:30:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:30:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0722 s/iter. Eval: 0.0130 s/iter. Total: 0.0859 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0741 s/iter. Eval: 0.0175 s/iter. Total: 0.0923 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0007 s/iter. Inference: 0.0747 s/iter. Eval: 0.0179 s/iter. Total: 0.0934 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:30:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.947561 (0.094376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:30:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074848 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:30:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2596584313713426\n",
      "\u001b[32m[01/10 18:30:36 d2.utils.events]: \u001b[0m eta: 0:17:33  iter: 16939  total_loss: 1.315  loss_cls: 0.257  loss_box_reg: 0.4695  loss_mask: 0.3036  loss_rpn_cls: 0.04986  loss_rpn_loc: 0.178  time: 0.6178  data_time: 0.2833  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:30:45 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 16959  total_loss: 1.211  loss_cls: 0.2646  loss_box_reg: 0.4794  loss_mask: 0.2787  loss_rpn_cls: 0.04609  loss_rpn_loc: 0.176  time: 0.6173  data_time: 0.1543  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:31:03 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 16979  total_loss: 1.34  loss_cls: 0.2864  loss_box_reg: 0.4679  loss_mask: 0.2934  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.1979  time: 0.6181  data_time: 0.5377  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:31:15 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 16999  total_loss: 1.359  loss_cls: 0.289  loss_box_reg: 0.4883  loss_mask: 0.2879  loss_rpn_cls: 0.07964  loss_rpn_loc: 0.1935  time: 0.6181  data_time: 0.2932  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:31:30 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 17019  total_loss: 1.388  loss_cls: 0.3094  loss_box_reg: 0.4853  loss_mask: 0.2918  loss_rpn_cls: 0.09962  loss_rpn_loc: 0.1887  time: 0.6184  data_time: 0.3648  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:31:39 d2.utils.events]: \u001b[0m eta: 0:17:03  iter: 17039  total_loss: 1.347  loss_cls: 0.2983  loss_box_reg: 0.4895  loss_mask: 0.2995  loss_rpn_cls: 0.04526  loss_rpn_loc: 0.199  time: 0.6179  data_time: 0.1185  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:31:50 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 17059  total_loss: 1.274  loss_cls: 0.3003  loss_box_reg: 0.4562  loss_mask: 0.28  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.1757  time: 0.6178  data_time: 0.2376  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:32:02 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 17079  total_loss: 1.316  loss_cls: 0.2736  loss_box_reg: 0.4732  loss_mask: 0.2881  loss_rpn_cls: 0.05881  loss_rpn_loc: 0.1742  time: 0.6177  data_time: 0.2544  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:32:13 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 17099  total_loss: 1.277  loss_cls: 0.2822  loss_box_reg: 0.4803  loss_mask: 0.2975  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.1812  time: 0.6175  data_time: 0.2421  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:32:25 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 17119  total_loss: 1.322  loss_cls: 0.2982  loss_box_reg: 0.5298  loss_mask: 0.279  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1852  time: 0.6175  data_time: 0.2932  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:32:34 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 17139  total_loss: 1.324  loss_cls: 0.2855  loss_box_reg: 0.4761  loss_mask: 0.2777  loss_rpn_cls: 0.05229  loss_rpn_loc: 0.1709  time: 0.6170  data_time: 0.1276  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:32:46 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 17159  total_loss: 1.296  loss_cls: 0.297  loss_box_reg: 0.4492  loss_mask: 0.3022  loss_rpn_cls: 0.0638  loss_rpn_loc: 0.1948  time: 0.6170  data_time: 0.2782  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:33:01 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 17179  total_loss: 1.317  loss_cls: 0.2544  loss_box_reg: 0.4477  loss_mask: 0.2974  loss_rpn_cls: 0.07134  loss_rpn_loc: 0.1724  time: 0.6173  data_time: 0.3927  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:33:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:33:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:33:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:33:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:33:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:33:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:33:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0705 s/iter. Eval: 0.0116 s/iter. Total: 0.0826 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:33:10 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0728 s/iter. Eval: 0.0157 s/iter. Total: 0.0893 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 18:33:15 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0165 s/iter. Total: 0.0909 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:33:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.615386 (0.091512 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:33:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073647 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:33:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:33:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24891826139105436\n",
      "\u001b[32m[01/10 18:33:23 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 17199  total_loss: 1.259  loss_cls: 0.2615  loss_box_reg: 0.4507  loss_mask: 0.2842  loss_rpn_cls: 0.05328  loss_rpn_loc: 0.1863  time: 0.6171  data_time: 0.2191  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:33:38 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 17219  total_loss: 1.452  loss_cls: 0.3294  loss_box_reg: 0.4905  loss_mask: 0.3162  loss_rpn_cls: 0.08876  loss_rpn_loc: 0.2143  time: 0.6174  data_time: 0.4089  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:33:47 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 17239  total_loss: 1.247  loss_cls: 0.2424  loss_box_reg: 0.4819  loss_mask: 0.2755  loss_rpn_cls: 0.04196  loss_rpn_loc: 0.1717  time: 0.6169  data_time: 0.0862  lr: 0.0005  max_mem: 6652M\n",
      "\u001b[32m[01/10 18:34:02 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 17259  total_loss: 1.306  loss_cls: 0.2909  loss_box_reg: 0.4124  loss_mask: 0.2955  loss_rpn_cls: 0.0848  loss_rpn_loc: 0.2039  time: 0.6174  data_time: 0.4464  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:34:10 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 17279  total_loss: 1.251  loss_cls: 0.2733  loss_box_reg: 0.515  loss_mask: 0.2754  loss_rpn_cls: 0.04526  loss_rpn_loc: 0.1583  time: 0.6167  data_time: 0.0788  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:34:21 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 17299  total_loss: 1.276  loss_cls: 0.2583  loss_box_reg: 0.4633  loss_mask: 0.304  loss_rpn_cls: 0.06786  loss_rpn_loc: 0.1815  time: 0.6166  data_time: 0.2147  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:34:33 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 17319  total_loss: 1.299  loss_cls: 0.2876  loss_box_reg: 0.4403  loss_mask: 0.2952  loss_rpn_cls: 0.06768  loss_rpn_loc: 0.1846  time: 0.6165  data_time: 0.2284  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:34:46 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 17339  total_loss: 1.257  loss_cls: 0.2548  loss_box_reg: 0.4863  loss_mask: 0.2952  loss_rpn_cls: 0.04188  loss_rpn_loc: 0.1725  time: 0.6165  data_time: 0.2826  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:34:55 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 17359  total_loss: 1.322  loss_cls: 0.283  loss_box_reg: 0.5082  loss_mask: 0.2889  loss_rpn_cls: 0.0568  loss_rpn_loc: 0.1729  time: 0.6161  data_time: 0.1255  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:35:05 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 17379  total_loss: 1.361  loss_cls: 0.2876  loss_box_reg: 0.5149  loss_mask: 0.2997  loss_rpn_cls: 0.0511  loss_rpn_loc: 0.1847  time: 0.6158  data_time: 0.1869  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:35:15 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 17399  total_loss: 1.211  loss_cls: 0.2677  loss_box_reg: 0.4589  loss_mask: 0.2789  loss_rpn_cls: 0.05105  loss_rpn_loc: 0.176  time: 0.6155  data_time: 0.1453  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:35:28 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 17419  total_loss: 1.408  loss_cls: 0.3206  loss_box_reg: 0.4836  loss_mask: 0.3034  loss_rpn_cls: 0.0857  loss_rpn_loc: 0.1895  time: 0.6156  data_time: 0.2973  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:35:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:35:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:35:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:35:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:35:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:35:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0737 s/iter. Eval: 0.0127 s/iter. Total: 0.0871 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0762 s/iter. Eval: 0.0172 s/iter. Total: 0.0942 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:35:44 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0749 s/iter. Eval: 0.0170 s/iter. Total: 0.0927 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:35:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.821074 (0.093285 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:35:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074886 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:35:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:35:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2543488806950142\n",
      "\u001b[32m[01/10 18:35:53 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 17439  total_loss: 1.304  loss_cls: 0.291  loss_box_reg: 0.4886  loss_mask: 0.2844  loss_rpn_cls: 0.07651  loss_rpn_loc: 0.1862  time: 0.6157  data_time: 0.3155  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:36:05 d2.utils.events]: \u001b[0m eta: 0:14:45  iter: 17459  total_loss: 1.297  loss_cls: 0.2955  loss_box_reg: 0.4821  loss_mask: 0.2975  loss_rpn_cls: 0.03928  loss_rpn_loc: 0.179  time: 0.6156  data_time: 0.2545  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:36:17 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 17479  total_loss: 1.31  loss_cls: 0.291  loss_box_reg: 0.443  loss_mask: 0.278  loss_rpn_cls: 0.06679  loss_rpn_loc: 0.1749  time: 0.6156  data_time: 0.2963  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:36:35 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 17499  total_loss: 1.224  loss_cls: 0.2827  loss_box_reg: 0.4374  loss_mask: 0.2828  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.1864  time: 0.6163  data_time: 0.5444  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:36:46 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 17519  total_loss: 1.292  loss_cls: 0.2778  loss_box_reg: 0.4593  loss_mask: 0.2986  loss_rpn_cls: 0.0653  loss_rpn_loc: 0.1919  time: 0.6161  data_time: 0.2431  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:37:00 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 17539  total_loss: 1.347  loss_cls: 0.2627  loss_box_reg: 0.4515  loss_mask: 0.2751  loss_rpn_cls: 0.08144  loss_rpn_loc: 0.1979  time: 0.6164  data_time: 0.3793  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:37:10 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 17559  total_loss: 1.342  loss_cls: 0.274  loss_box_reg: 0.4735  loss_mask: 0.2949  loss_rpn_cls: 0.05441  loss_rpn_loc: 0.1885  time: 0.6161  data_time: 0.1904  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:37:21 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 17579  total_loss: 1.269  loss_cls: 0.2844  loss_box_reg: 0.4763  loss_mask: 0.289  loss_rpn_cls: 0.05794  loss_rpn_loc: 0.1748  time: 0.6159  data_time: 0.2035  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:37:35 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 17599  total_loss: 1.342  loss_cls: 0.2944  loss_box_reg: 0.4494  loss_mask: 0.2957  loss_rpn_cls: 0.0881  loss_rpn_loc: 0.1979  time: 0.6161  data_time: 0.3863  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:37:45 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 17619  total_loss: 1.279  loss_cls: 0.2681  loss_box_reg: 0.4605  loss_mask: 0.2756  loss_rpn_cls: 0.05547  loss_rpn_loc: 0.1697  time: 0.6158  data_time: 0.1658  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:37:58 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 17639  total_loss: 1.352  loss_cls: 0.2803  loss_box_reg: 0.461  loss_mask: 0.3042  loss_rpn_cls: 0.07861  loss_rpn_loc: 0.1864  time: 0.6159  data_time: 0.3361  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:38:10 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 17659  total_loss: 1.401  loss_cls: 0.3428  loss_box_reg: 0.4835  loss_mask: 0.2925  loss_rpn_cls: 0.07794  loss_rpn_loc: 0.1985  time: 0.6159  data_time: 0.2727  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:38:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:38:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:38:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:38:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:38:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:38:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0708 s/iter. Eval: 0.0112 s/iter. Total: 0.0827 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0007 s/iter. Inference: 0.0729 s/iter. Eval: 0.0154 s/iter. Total: 0.0891 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 18:38:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.495121 (0.090475 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:38:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073176 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:38:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:38:24 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25745382531424565\n",
      "\u001b[32m[01/10 18:38:33 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 17679  total_loss: 1.247  loss_cls: 0.2382  loss_box_reg: 0.4574  loss_mask: 0.283  loss_rpn_cls: 0.04431  loss_rpn_loc: 0.167  time: 0.6157  data_time: 0.2430  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:38:45 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 17699  total_loss: 1.286  loss_cls: 0.2597  loss_box_reg: 0.4969  loss_mask: 0.2867  loss_rpn_cls: 0.06974  loss_rpn_loc: 0.1732  time: 0.6156  data_time: 0.2645  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:38:56 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 17719  total_loss: 1.325  loss_cls: 0.2876  loss_box_reg: 0.4902  loss_mask: 0.3139  loss_rpn_cls: 0.07144  loss_rpn_loc: 0.1754  time: 0.6154  data_time: 0.2196  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:39:06 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 17739  total_loss: 1.234  loss_cls: 0.2598  loss_box_reg: 0.4684  loss_mask: 0.2838  loss_rpn_cls: 0.02765  loss_rpn_loc: 0.1563  time: 0.6152  data_time: 0.2018  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:39:17 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 17759  total_loss: 1.291  loss_cls: 0.2948  loss_box_reg: 0.4589  loss_mask: 0.2892  loss_rpn_cls: 0.06674  loss_rpn_loc: 0.1721  time: 0.6151  data_time: 0.2450  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:39:28 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 17779  total_loss: 1.26  loss_cls: 0.2692  loss_box_reg: 0.4802  loss_mask: 0.2907  loss_rpn_cls: 0.04453  loss_rpn_loc: 0.177  time: 0.6148  data_time: 0.2058  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:39:41 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 17799  total_loss: 1.374  loss_cls: 0.2875  loss_box_reg: 0.4817  loss_mask: 0.2998  loss_rpn_cls: 0.07677  loss_rpn_loc: 0.1987  time: 0.6149  data_time: 0.3295  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:39:54 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 17819  total_loss: 1.263  loss_cls: 0.2976  loss_box_reg: 0.4406  loss_mask: 0.2833  loss_rpn_cls: 0.06396  loss_rpn_loc: 0.1813  time: 0.6150  data_time: 0.3058  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:40:04 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 17839  total_loss: 1.241  loss_cls: 0.2472  loss_box_reg: 0.4514  loss_mask: 0.2981  loss_rpn_cls: 0.0487  loss_rpn_loc: 0.1836  time: 0.6147  data_time: 0.2052  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:40:18 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 17859  total_loss: 1.343  loss_cls: 0.3009  loss_box_reg: 0.4978  loss_mask: 0.3024  loss_rpn_cls: 0.05863  loss_rpn_loc: 0.2022  time: 0.6149  data_time: 0.3517  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:40:29 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 17879  total_loss: 1.278  loss_cls: 0.2851  loss_box_reg: 0.4972  loss_mask: 0.3038  loss_rpn_cls: 0.05289  loss_rpn_loc: 0.1638  time: 0.6148  data_time: 0.2741  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:40:42 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 17899  total_loss: 1.35  loss_cls: 0.2979  loss_box_reg: 0.4547  loss_mask: 0.2761  loss_rpn_cls: 0.06881  loss_rpn_loc: 0.1985  time: 0.6148  data_time: 0.2854  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:40:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:40:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:40:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:40:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:40:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:40:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:40:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0721 s/iter. Eval: 0.0121 s/iter. Total: 0.0848 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:40:53 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0162 s/iter. Total: 0.0904 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 18:40:58 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0737 s/iter. Eval: 0.0169 s/iter. Total: 0.0913 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:40:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.673559 (0.092013 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:40:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073718 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:40:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:40:58 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2507536921380088\n",
      "\u001b[32m[01/10 18:41:03 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 17919  total_loss: 1.379  loss_cls: 0.3004  loss_box_reg: 0.4789  loss_mask: 0.2897  loss_rpn_cls: 0.06121  loss_rpn_loc: 0.1963  time: 0.6144  data_time: 0.1341  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:41:19 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 17939  total_loss: 1.348  loss_cls: 0.3108  loss_box_reg: 0.4428  loss_mask: 0.2871  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.1895  time: 0.6149  data_time: 0.4623  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:41:30 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 17959  total_loss: 1.261  loss_cls: 0.2442  loss_box_reg: 0.4693  loss_mask: 0.2651  loss_rpn_cls: 0.04622  loss_rpn_loc: 0.1638  time: 0.6148  data_time: 0.2387  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:41:45 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 17979  total_loss: 1.244  loss_cls: 0.2618  loss_box_reg: 0.4626  loss_mask: 0.2732  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.1808  time: 0.6151  data_time: 0.4321  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:41:57 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 17999  total_loss: 1.444  loss_cls: 0.325  loss_box_reg: 0.486  loss_mask: 0.2992  loss_rpn_cls: 0.06709  loss_rpn_loc: 0.1849  time: 0.6150  data_time: 0.2463  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:42:05 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 18019  total_loss: 1.232  loss_cls: 0.2786  loss_box_reg: 0.447  loss_mask: 0.2815  loss_rpn_cls: 0.05767  loss_rpn_loc: 0.1677  time: 0.6145  data_time: 0.0971  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:42:16 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 18039  total_loss: 1.211  loss_cls: 0.2599  loss_box_reg: 0.442  loss_mask: 0.2919  loss_rpn_cls: 0.04491  loss_rpn_loc: 0.172  time: 0.6144  data_time: 0.2665  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:42:29 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 18059  total_loss: 1.286  loss_cls: 0.3116  loss_box_reg: 0.4643  loss_mask: 0.2861  loss_rpn_cls: 0.05108  loss_rpn_loc: 0.1921  time: 0.6144  data_time: 0.3069  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:42:43 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 18079  total_loss: 1.255  loss_cls: 0.2799  loss_box_reg: 0.4492  loss_mask: 0.2944  loss_rpn_cls: 0.08536  loss_rpn_loc: 0.1957  time: 0.6147  data_time: 0.3734  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:42:53 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 18099  total_loss: 1.306  loss_cls: 0.2677  loss_box_reg: 0.4572  loss_mask: 0.2908  loss_rpn_cls: 0.04435  loss_rpn_loc: 0.1811  time: 0.6144  data_time: 0.1673  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:43:05 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 18119  total_loss: 1.227  loss_cls: 0.2368  loss_box_reg: 0.4542  loss_mask: 0.2886  loss_rpn_cls: 0.03887  loss_rpn_loc: 0.1734  time: 0.6144  data_time: 0.2993  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:43:17 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 18139  total_loss: 1.338  loss_cls: 0.3418  loss_box_reg: 0.4911  loss_mask: 0.2927  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.1781  time: 0.6143  data_time: 0.2655  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:43:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:43:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:43:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:43:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:43:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:43:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0151 s/iter. Total: 0.0875 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0165 s/iter. Total: 0.0911 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0737 s/iter. Eval: 0.0167 s/iter. Total: 0.0912 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:43:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.658300 (0.091882 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:43:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:43:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:43:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2582958598312214\n",
      "\u001b[32m[01/10 18:43:37 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 18159  total_loss: 1.201  loss_cls: 0.2359  loss_box_reg: 0.4432  loss_mask: 0.2853  loss_rpn_cls: 0.03639  loss_rpn_loc: 0.1574  time: 0.6137  data_time: 0.0719  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:43:50 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 18179  total_loss: 1.326  loss_cls: 0.2433  loss_box_reg: 0.4642  loss_mask: 0.3076  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.1965  time: 0.6138  data_time: 0.3189  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:44:02 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 18199  total_loss: 1.261  loss_cls: 0.2735  loss_box_reg: 0.4928  loss_mask: 0.3016  loss_rpn_cls: 0.03922  loss_rpn_loc: 0.1715  time: 0.6138  data_time: 0.2852  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:44:15 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 18219  total_loss: 1.366  loss_cls: 0.2988  loss_box_reg: 0.4782  loss_mask: 0.2933  loss_rpn_cls: 0.06096  loss_rpn_loc: 0.1875  time: 0.6139  data_time: 0.3356  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:44:29 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 18239  total_loss: 1.34  loss_cls: 0.3191  loss_box_reg: 0.4752  loss_mask: 0.2935  loss_rpn_cls: 0.08345  loss_rpn_loc: 0.1915  time: 0.6141  data_time: 0.3972  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:44:46 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 18259  total_loss: 1.388  loss_cls: 0.3203  loss_box_reg: 0.4687  loss_mask: 0.2954  loss_rpn_cls: 0.08619  loss_rpn_loc: 0.2068  time: 0.6146  data_time: 0.4759  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:44:57 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 18279  total_loss: 1.317  loss_cls: 0.2749  loss_box_reg: 0.4975  loss_mask: 0.2888  loss_rpn_cls: 0.05565  loss_rpn_loc: 0.1916  time: 0.6145  data_time: 0.2585  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:45:07 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 18299  total_loss: 1.196  loss_cls: 0.2456  loss_box_reg: 0.4347  loss_mask: 0.2767  loss_rpn_cls: 0.0573  loss_rpn_loc: 0.1704  time: 0.6142  data_time: 0.1650  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:45:15 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 18319  total_loss: 1.223  loss_cls: 0.2615  loss_box_reg: 0.4553  loss_mask: 0.2847  loss_rpn_cls: 0.04589  loss_rpn_loc: 0.1576  time: 0.6137  data_time: 0.1010  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:45:30 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 18339  total_loss: 1.361  loss_cls: 0.3137  loss_box_reg: 0.4633  loss_mask: 0.305  loss_rpn_cls: 0.09339  loss_rpn_loc: 0.1953  time: 0.6140  data_time: 0.4161  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:45:41 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 18359  total_loss: 1.331  loss_cls: 0.2729  loss_box_reg: 0.47  loss_mask: 0.2889  loss_rpn_cls: 0.07554  loss_rpn_loc: 0.1913  time: 0.6140  data_time: 0.2615  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:45:58 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 18379  total_loss: 1.361  loss_cls: 0.319  loss_box_reg: 0.4515  loss_mask: 0.3147  loss_rpn_cls: 0.08735  loss_rpn_loc: 0.1972  time: 0.6145  data_time: 0.5017  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:46:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:46:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:46:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:46:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:46:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:46:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0137 s/iter. Total: 0.0863 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0742 s/iter. Eval: 0.0173 s/iter. Total: 0.0922 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0173 s/iter. Total: 0.0926 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:46:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.849270 (0.093528 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:46:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074681 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:46:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:46:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25458888612767705\n",
      "\u001b[32m[01/10 18:46:21 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 18399  total_loss: 1.241  loss_cls: 0.2612  loss_box_reg: 0.46  loss_mask: 0.2877  loss_rpn_cls: 0.03849  loss_rpn_loc: 0.1854  time: 0.6143  data_time: 0.1925  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:46:32 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 18419  total_loss: 1.247  loss_cls: 0.2625  loss_box_reg: 0.4367  loss_mask: 0.2837  loss_rpn_cls: 0.06653  loss_rpn_loc: 0.1825  time: 0.6142  data_time: 0.2398  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:46:42 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 18439  total_loss: 1.281  loss_cls: 0.2483  loss_box_reg: 0.4814  loss_mask: 0.2881  loss_rpn_cls: 0.04646  loss_rpn_loc: 0.1747  time: 0.6139  data_time: 0.1841  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:46:53 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 18459  total_loss: 1.284  loss_cls: 0.2762  loss_box_reg: 0.4655  loss_mask: 0.2938  loss_rpn_cls: 0.0518  loss_rpn_loc: 0.1806  time: 0.6137  data_time: 0.1925  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:47:02 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 18479  total_loss: 1.348  loss_cls: 0.3093  loss_box_reg: 0.4691  loss_mask: 0.2987  loss_rpn_cls: 0.05008  loss_rpn_loc: 0.1799  time: 0.6133  data_time: 0.1227  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:47:13 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 18499  total_loss: 1.174  loss_cls: 0.2617  loss_box_reg: 0.4618  loss_mask: 0.2948  loss_rpn_cls: 0.05023  loss_rpn_loc: 0.1588  time: 0.6132  data_time: 0.2564  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:47:23 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 18519  total_loss: 1.219  loss_cls: 0.2824  loss_box_reg: 0.4489  loss_mask: 0.2868  loss_rpn_cls: 0.03433  loss_rpn_loc: 0.1557  time: 0.6129  data_time: 0.1586  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:47:34 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 18539  total_loss: 1.227  loss_cls: 0.2363  loss_box_reg: 0.4562  loss_mask: 0.2916  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.1863  time: 0.6128  data_time: 0.2688  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:47:47 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 18559  total_loss: 1.309  loss_cls: 0.2521  loss_box_reg: 0.4521  loss_mask: 0.2813  loss_rpn_cls: 0.06061  loss_rpn_loc: 0.1806  time: 0.6128  data_time: 0.2851  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:48:01 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 18579  total_loss: 1.351  loss_cls: 0.2884  loss_box_reg: 0.4886  loss_mask: 0.3149  loss_rpn_cls: 0.08668  loss_rpn_loc: 0.2112  time: 0.6131  data_time: 0.4013  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:48:15 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 18599  total_loss: 1.374  loss_cls: 0.3212  loss_box_reg: 0.4851  loss_mask: 0.2835  loss_rpn_cls: 0.08337  loss_rpn_loc: 0.1967  time: 0.6133  data_time: 0.3562  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:48:26 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 18619  total_loss: 1.25  loss_cls: 0.2661  loss_box_reg: 0.4577  loss_mask: 0.2901  loss_rpn_cls: 0.05217  loss_rpn_loc: 0.1635  time: 0.6131  data_time: 0.2203  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:48:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:48:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:48:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:48:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:48:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:48:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0714 s/iter. Eval: 0.0129 s/iter. Total: 0.0851 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0734 s/iter. Eval: 0.0166 s/iter. Total: 0.0907 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 18:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0169 s/iter. Total: 0.0916 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:48:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.702710 (0.092265 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:48:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073894 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:48:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:48:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24730513218572464\n",
      "\u001b[32m[01/10 18:48:49 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 18639  total_loss: 1.19  loss_cls: 0.2419  loss_box_reg: 0.4428  loss_mask: 0.2861  loss_rpn_cls: 0.03715  loss_rpn_loc: 0.1715  time: 0.6130  data_time: 0.2541  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:49:01 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 18659  total_loss: 1.296  loss_cls: 0.2802  loss_box_reg: 0.4832  loss_mask: 0.295  loss_rpn_cls: 0.05347  loss_rpn_loc: 0.1709  time: 0.6129  data_time: 0.2658  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:49:11 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 18679  total_loss: 1.256  loss_cls: 0.2605  loss_box_reg: 0.4892  loss_mask: 0.2846  loss_rpn_cls: 0.03966  loss_rpn_loc: 0.1708  time: 0.6127  data_time: 0.1896  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:49:23 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 18699  total_loss: 1.384  loss_cls: 0.3124  loss_box_reg: 0.4609  loss_mask: 0.2906  loss_rpn_cls: 0.06852  loss_rpn_loc: 0.2063  time: 0.6127  data_time: 0.2762  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:49:35 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 18719  total_loss: 1.273  loss_cls: 0.249  loss_box_reg: 0.472  loss_mask: 0.2981  loss_rpn_cls: 0.05122  loss_rpn_loc: 0.1868  time: 0.6126  data_time: 0.2468  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:49:44 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 18739  total_loss: 1.301  loss_cls: 0.272  loss_box_reg: 0.4726  loss_mask: 0.3014  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.1837  time: 0.6122  data_time: 0.1400  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:49:53 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 18759  total_loss: 1.21  loss_cls: 0.2392  loss_box_reg: 0.4615  loss_mask: 0.2794  loss_rpn_cls: 0.04032  loss_rpn_loc: 0.1571  time: 0.6119  data_time: 0.1578  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:50:05 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 18779  total_loss: 1.358  loss_cls: 0.3019  loss_box_reg: 0.455  loss_mask: 0.2953  loss_rpn_cls: 0.06719  loss_rpn_loc: 0.1926  time: 0.6118  data_time: 0.2672  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:50:22 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 18799  total_loss: 1.247  loss_cls: 0.2794  loss_box_reg: 0.4426  loss_mask: 0.2853  loss_rpn_cls: 0.073  loss_rpn_loc: 0.1713  time: 0.6123  data_time: 0.4815  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:50:34 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 18819  total_loss: 1.341  loss_cls: 0.2731  loss_box_reg: 0.4906  loss_mask: 0.2998  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.1952  time: 0.6124  data_time: 0.3181  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:50:42 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 18839  total_loss: 1.214  loss_cls: 0.2214  loss_box_reg: 0.4756  loss_mask: 0.2982  loss_rpn_cls: 0.03345  loss_rpn_loc: 0.1651  time: 0.6119  data_time: 0.0852  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:50:53 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 18859  total_loss: 1.318  loss_cls: 0.31  loss_box_reg: 0.4866  loss_mask: 0.2903  loss_rpn_cls: 0.06767  loss_rpn_loc: 0.1777  time: 0.6118  data_time: 0.2475  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:51:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:51:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:51:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:51:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:51:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:51:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:51:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0133 s/iter. Total: 0.0885 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:51:13 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0753 s/iter. Eval: 0.0168 s/iter. Total: 0.0929 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:51:18 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0167 s/iter. Total: 0.0920 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:51:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.752754 (0.092696 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:51:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074507 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:51:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:51:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2541079920769916\n",
      "\u001b[32m[01/10 18:51:20 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 18879  total_loss: 1.296  loss_cls: 0.2612  loss_box_reg: 0.4511  loss_mask: 0.3047  loss_rpn_cls: 0.06117  loss_rpn_loc: 0.2  time: 0.6120  data_time: 0.3669  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:51:34 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 18899  total_loss: 1.344  loss_cls: 0.3132  loss_box_reg: 0.4863  loss_mask: 0.3113  loss_rpn_cls: 0.06746  loss_rpn_loc: 0.1935  time: 0.6123  data_time: 0.4008  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:51:45 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 18919  total_loss: 1.196  loss_cls: 0.2605  loss_box_reg: 0.4589  loss_mask: 0.2813  loss_rpn_cls: 0.04539  loss_rpn_loc: 0.1582  time: 0.6121  data_time: 0.2425  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:51:56 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 18939  total_loss: 1.325  loss_cls: 0.2864  loss_box_reg: 0.4592  loss_mask: 0.3004  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.178  time: 0.6119  data_time: 0.2183  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:52:09 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 18959  total_loss: 1.32  loss_cls: 0.3005  loss_box_reg: 0.4762  loss_mask: 0.2952  loss_rpn_cls: 0.06438  loss_rpn_loc: 0.197  time: 0.6120  data_time: 0.3135  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:52:19 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 18979  total_loss: 1.247  loss_cls: 0.2533  loss_box_reg: 0.475  loss_mask: 0.2897  loss_rpn_cls: 0.04794  loss_rpn_loc: 0.1717  time: 0.6117  data_time: 0.1705  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:52:31 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 18999  total_loss: 1.199  loss_cls: 0.2433  loss_box_reg: 0.44  loss_mask: 0.2931  loss_rpn_cls: 0.03386  loss_rpn_loc: 0.1547  time: 0.6117  data_time: 0.2943  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:52:42 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 19019  total_loss: 1.305  loss_cls: 0.3107  loss_box_reg: 0.4886  loss_mask: 0.2882  loss_rpn_cls: 0.0578  loss_rpn_loc: 0.1693  time: 0.6116  data_time: 0.2648  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:52:55 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 19039  total_loss: 1.31  loss_cls: 0.2873  loss_box_reg: 0.4795  loss_mask: 0.3089  loss_rpn_cls: 0.05498  loss_rpn_loc: 0.1854  time: 0.6116  data_time: 0.2875  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:53:06 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 19059  total_loss: 1.282  loss_cls: 0.2919  loss_box_reg: 0.4339  loss_mask: 0.293  loss_rpn_cls: 0.05871  loss_rpn_loc: 0.172  time: 0.6115  data_time: 0.2324  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:53:18 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 19079  total_loss: 1.376  loss_cls: 0.3126  loss_box_reg: 0.4605  loss_mask: 0.2959  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.1746  time: 0.6116  data_time: 0.3122  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:53:28 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 19099  total_loss: 1.287  loss_cls: 0.2696  loss_box_reg: 0.4496  loss_mask: 0.2779  loss_rpn_cls: 0.04344  loss_rpn_loc: 0.1697  time: 0.6113  data_time: 0.1787  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:53:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:53:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:53:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:53:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:53:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:53:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0714 s/iter. Eval: 0.0134 s/iter. Total: 0.0855 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0167 s/iter. Total: 0.0910 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0172 s/iter. Total: 0.0919 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:53:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.721166 (0.092424 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:53:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073879 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:53:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:53:51 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2551409449078675\n",
      "\u001b[32m[01/10 18:53:51 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 19119  total_loss: 1.333  loss_cls: 0.2823  loss_box_reg: 0.4637  loss_mask: 0.2973  loss_rpn_cls: 0.08063  loss_rpn_loc: 0.1763  time: 0.6112  data_time: 0.2592  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:54:06 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 19139  total_loss: 1.294  loss_cls: 0.2667  loss_box_reg: 0.4506  loss_mask: 0.2903  loss_rpn_cls: 0.07168  loss_rpn_loc: 0.164  time: 0.6114  data_time: 0.3986  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:54:17 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 19159  total_loss: 1.223  loss_cls: 0.2588  loss_box_reg: 0.4575  loss_mask: 0.2711  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.1896  time: 0.6113  data_time: 0.2296  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:54:30 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 19179  total_loss: 1.309  loss_cls: 0.2901  loss_box_reg: 0.4593  loss_mask: 0.2982  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.1866  time: 0.6114  data_time: 0.3139  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:54:42 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 19199  total_loss: 1.306  loss_cls: 0.2545  loss_box_reg: 0.4356  loss_mask: 0.2838  loss_rpn_cls: 0.0652  loss_rpn_loc: 0.1843  time: 0.6114  data_time: 0.2978  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:54:53 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 19219  total_loss: 1.29  loss_cls: 0.2657  loss_box_reg: 0.4773  loss_mask: 0.2905  loss_rpn_cls: 0.05332  loss_rpn_loc: 0.1815  time: 0.6112  data_time: 0.2415  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:55:07 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 19239  total_loss: 1.252  loss_cls: 0.252  loss_box_reg: 0.4888  loss_mask: 0.2841  loss_rpn_cls: 0.0657  loss_rpn_loc: 0.1893  time: 0.6114  data_time: 0.3870  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:55:17 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 19259  total_loss: 1.255  loss_cls: 0.2841  loss_box_reg: 0.4765  loss_mask: 0.3003  loss_rpn_cls: 0.04605  loss_rpn_loc: 0.1716  time: 0.6112  data_time: 0.1754  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:55:30 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 19279  total_loss: 1.265  loss_cls: 0.2961  loss_box_reg: 0.4479  loss_mask: 0.2869  loss_rpn_cls: 0.06895  loss_rpn_loc: 0.177  time: 0.6113  data_time: 0.3034  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:55:44 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 19299  total_loss: 1.226  loss_cls: 0.2567  loss_box_reg: 0.4421  loss_mask: 0.2833  loss_rpn_cls: 0.04497  loss_rpn_loc: 0.1587  time: 0.6115  data_time: 0.3899  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:55:53 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 19319  total_loss: 1.276  loss_cls: 0.3256  loss_box_reg: 0.4841  loss_mask: 0.274  loss_rpn_cls: 0.05123  loss_rpn_loc: 0.179  time: 0.6111  data_time: 0.1289  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:56:03 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 19339  total_loss: 1.248  loss_cls: 0.2722  loss_box_reg: 0.5206  loss_mask: 0.2927  loss_rpn_cls: 0.05335  loss_rpn_loc: 0.1872  time: 0.6109  data_time: 0.2011  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:56:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:56:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:56:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:56:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:56:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:56:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0725 s/iter. Eval: 0.0158 s/iter. Total: 0.0890 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0008 s/iter. Inference: 0.0739 s/iter. Eval: 0.0170 s/iter. Total: 0.0917 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0171 s/iter. Total: 0.0917 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 18:56:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.714755 (0.092369 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:56:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073824 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:56:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:56:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24932297937480224\n",
      "\u001b[32m[01/10 18:56:31 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 19359  total_loss: 1.354  loss_cls: 0.2947  loss_box_reg: 0.4698  loss_mask: 0.301  loss_rpn_cls: 0.07828  loss_rpn_loc: 0.1914  time: 0.6113  data_time: 0.4512  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:56:42 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 19379  total_loss: 1.294  loss_cls: 0.2436  loss_box_reg: 0.4766  loss_mask: 0.2826  loss_rpn_cls: 0.0468  loss_rpn_loc: 0.1727  time: 0.6111  data_time: 0.2246  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:56:56 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 19399  total_loss: 1.341  loss_cls: 0.2863  loss_box_reg: 0.4684  loss_mask: 0.2945  loss_rpn_cls: 0.06617  loss_rpn_loc: 0.1947  time: 0.6113  data_time: 0.3547  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:57:08 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 19419  total_loss: 1.22  loss_cls: 0.2605  loss_box_reg: 0.4633  loss_mask: 0.2811  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.1656  time: 0.6113  data_time: 0.2993  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:57:19 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 19439  total_loss: 1.296  loss_cls: 0.2725  loss_box_reg: 0.4687  loss_mask: 0.2907  loss_rpn_cls: 0.06722  loss_rpn_loc: 0.1792  time: 0.6112  data_time: 0.2282  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:57:29 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 19459  total_loss: 1.219  loss_cls: 0.2452  loss_box_reg: 0.4696  loss_mask: 0.2967  loss_rpn_cls: 0.04746  loss_rpn_loc: 0.1772  time: 0.6110  data_time: 0.2062  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:57:39 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 19479  total_loss: 1.204  loss_cls: 0.2482  loss_box_reg: 0.4771  loss_mask: 0.2808  loss_rpn_cls: 0.04134  loss_rpn_loc: 0.1608  time: 0.6107  data_time: 0.1723  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:57:50 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 19499  total_loss: 1.22  loss_cls: 0.2431  loss_box_reg: 0.4662  loss_mask: 0.2998  loss_rpn_cls: 0.05023  loss_rpn_loc: 0.175  time: 0.6105  data_time: 0.2076  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:58:02 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 19519  total_loss: 1.318  loss_cls: 0.3175  loss_box_reg: 0.4773  loss_mask: 0.2913  loss_rpn_cls: 0.0796  loss_rpn_loc: 0.1994  time: 0.6106  data_time: 0.2748  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:58:14 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 19539  total_loss: 1.296  loss_cls: 0.2791  loss_box_reg: 0.479  loss_mask: 0.2925  loss_rpn_cls: 0.06341  loss_rpn_loc: 0.1939  time: 0.6105  data_time: 0.2460  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:58:27 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 19559  total_loss: 1.26  loss_cls: 0.2628  loss_box_reg: 0.4684  loss_mask: 0.2881  loss_rpn_cls: 0.06026  loss_rpn_loc: 0.1694  time: 0.6106  data_time: 0.3691  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:58:40 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 19579  total_loss: 1.225  loss_cls: 0.2896  loss_box_reg: 0.4575  loss_mask: 0.3018  loss_rpn_cls: 0.03871  loss_rpn_loc: 0.1787  time: 0.6107  data_time: 0.3196  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:58:51 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 19599  total_loss: 1.279  loss_cls: 0.2792  loss_box_reg: 0.4919  loss_mask: 0.2968  loss_rpn_cls: 0.05692  loss_rpn_loc: 0.158  time: 0.6106  data_time: 0.2495  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:58:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:58:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 18:58:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 18:58:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 18:58:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 18:58:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 18:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0721 s/iter. Eval: 0.0163 s/iter. Total: 0.0892 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 18:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0739 s/iter. Eval: 0.0167 s/iter. Total: 0.0914 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 18:59:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.633505 (0.091668 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:59:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073741 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 18:59:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 18:59:04 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2526435461509559\n",
      "\u001b[32m[01/10 18:59:14 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 19619  total_loss: 1.269  loss_cls: 0.2688  loss_box_reg: 0.4969  loss_mask: 0.2926  loss_rpn_cls: 0.04909  loss_rpn_loc: 0.1803  time: 0.6104  data_time: 0.2147  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:59:26 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 19639  total_loss: 1.19  loss_cls: 0.2564  loss_box_reg: 0.436  loss_mask: 0.269  loss_rpn_cls: 0.05481  loss_rpn_loc: 0.1773  time: 0.6104  data_time: 0.2933  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:59:40 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 19659  total_loss: 1.302  loss_cls: 0.2845  loss_box_reg: 0.4551  loss_mask: 0.2863  loss_rpn_cls: 0.07335  loss_rpn_loc: 0.1953  time: 0.6106  data_time: 0.3626  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 18:59:55 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 19679  total_loss: 1.257  loss_cls: 0.2804  loss_box_reg: 0.4216  loss_mask: 0.2764  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.1887  time: 0.6109  data_time: 0.3853  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:00:07 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 19699  total_loss: 1.316  loss_cls: 0.2716  loss_box_reg: 0.4583  loss_mask: 0.2898  loss_rpn_cls: 0.08533  loss_rpn_loc: 0.1877  time: 0.6108  data_time: 0.2688  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:00:20 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 19719  total_loss: 1.295  loss_cls: 0.2651  loss_box_reg: 0.4538  loss_mask: 0.2934  loss_rpn_cls: 0.07366  loss_rpn_loc: 0.1817  time: 0.6109  data_time: 0.3314  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:00:28 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 19739  total_loss: 1.236  loss_cls: 0.2394  loss_box_reg: 0.4623  loss_mask: 0.2681  loss_rpn_cls: 0.04658  loss_rpn_loc: 0.1677  time: 0.6105  data_time: 0.1086  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:00:40 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 19759  total_loss: 1.196  loss_cls: 0.2344  loss_box_reg: 0.4391  loss_mask: 0.2998  loss_rpn_cls: 0.03613  loss_rpn_loc: 0.1708  time: 0.6105  data_time: 0.2970  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:00:51 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 19779  total_loss: 1.282  loss_cls: 0.2743  loss_box_reg: 0.4513  loss_mask: 0.2992  loss_rpn_cls: 0.05528  loss_rpn_loc: 0.1738  time: 0.6104  data_time: 0.2235  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:01:03 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 19799  total_loss: 1.292  loss_cls: 0.2829  loss_box_reg: 0.4601  loss_mask: 0.2906  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.176  time: 0.6103  data_time: 0.2721  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:01:19 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 19819  total_loss: 1.309  loss_cls: 0.302  loss_box_reg: 0.4269  loss_mask: 0.2816  loss_rpn_cls: 0.06634  loss_rpn_loc: 0.1862  time: 0.6107  data_time: 0.4666  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:01:30 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 19839  total_loss: 1.197  loss_cls: 0.2354  loss_box_reg: 0.4147  loss_mask: 0.2751  loss_rpn_cls: 0.04358  loss_rpn_loc: 0.1554  time: 0.6106  data_time: 0.2204  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:01:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 19:01:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 19:01:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 19:01:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 19:01:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 19:01:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 19:01:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0729 s/iter. Eval: 0.0136 s/iter. Total: 0.0873 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 19:01:39 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0745 s/iter. Eval: 0.0170 s/iter. Total: 0.0923 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/10 19:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0742 s/iter. Eval: 0.0166 s/iter. Total: 0.0916 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 19:01:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.701821 (0.092257 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 19:01:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074193 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 19:01:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 19:01:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2570953931655368\n",
      "\u001b[32m[01/10 19:01:55 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 19859  total_loss: 1.214  loss_cls: 0.2684  loss_box_reg: 0.4504  loss_mask: 0.2955  loss_rpn_cls: 0.0596  loss_rpn_loc: 0.1766  time: 0.6106  data_time: 0.3068  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:02:05 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 19879  total_loss: 1.322  loss_cls: 0.2747  loss_box_reg: 0.4965  loss_mask: 0.3017  loss_rpn_cls: 0.05338  loss_rpn_loc: 0.1754  time: 0.6104  data_time: 0.2020  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:02:17 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 19899  total_loss: 1.374  loss_cls: 0.3285  loss_box_reg: 0.5018  loss_mask: 0.2998  loss_rpn_cls: 0.07943  loss_rpn_loc: 0.1858  time: 0.6104  data_time: 0.2911  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:02:29 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 19919  total_loss: 1.248  loss_cls: 0.294  loss_box_reg: 0.4668  loss_mask: 0.2888  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.1756  time: 0.6104  data_time: 0.2692  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:02:37 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 19939  total_loss: 1.295  loss_cls: 0.2682  loss_box_reg: 0.4932  loss_mask: 0.2822  loss_rpn_cls: 0.04531  loss_rpn_loc: 0.167  time: 0.6100  data_time: 0.0914  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:02:52 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 19959  total_loss: 1.372  loss_cls: 0.3262  loss_box_reg: 0.4472  loss_mask: 0.2918  loss_rpn_cls: 0.0721  loss_rpn_loc: 0.1965  time: 0.6103  data_time: 0.4288  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:03:03 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 19979  total_loss: 1.365  loss_cls: 0.3019  loss_box_reg: 0.4939  loss_mask: 0.3092  loss_rpn_cls: 0.07385  loss_rpn_loc: 0.1847  time: 0.6102  data_time: 0.2363  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:03:19 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 19999  total_loss: 1.296  loss_cls: 0.2885  loss_box_reg: 0.4639  loss_mask: 0.3125  loss_rpn_cls: 0.06912  loss_rpn_loc: 0.1856  time: 0.6105  data_time: 0.4359  lr: 0.0005  max_mem: 6703M\n",
      "\u001b[32m[01/10 19:03:19 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:41:44 (0.6105 s / it)\n",
      "\u001b[32m[01/10 19:03:19 d2.engine.hooks]: \u001b[0mTotal training time: 1:50:11 (0:08:27 on hooks)\n",
      "\u001b[32m[01/10 19:03:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 19:03:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/10 19:03:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 19:03:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/10 19:03:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[01/10 19:03:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/10 19:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0128 s/iter. Total: 0.0854 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/10 19:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0007 s/iter. Inference: 0.0736 s/iter. Eval: 0.0164 s/iter. Total: 0.0908 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/10 19:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0738 s/iter. Eval: 0.0167 s/iter. Total: 0.0913 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/10 19:03:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.672482 (0.092004 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 19:03:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073801 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/10 19:03:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[01/10 19:03:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25303239100015973\n"
     ]
    }
   ],
   "source": [
    "# It seems like the model hasn't converged yet, we add more training iterations\n",
    "cfg.SOLVER.MAX_ITER = 20000\n",
    "\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a1211-7af8-4ed0-9990-b2ce528d7a5b",
   "metadata": {},
   "source": [
    "Highest mAP is 0.2622, obtained after iteration 11359"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
