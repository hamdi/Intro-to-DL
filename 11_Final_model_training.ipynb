{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86397ef-2320-47be-a881-8f0ebcd315cb",
   "metadata": {},
   "source": [
    "### Notebook 11: Final model training\n",
    "\n",
    "Here we take the best model from the previous notebook and we train it on the validation data then again on the training data with a lower learning rate before making our final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05048cc-4d1c-471a-bb1b-22274f6a3f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import pycocotools.mask as mask_util\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.modeling import DatasetMapperTTA\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb2721d-ec83-42a5-b68d-a28314460ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=Path('../')\n",
    "register_coco_instances('sartorius_val',{}, '../sartorius-annotations-coco-format/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_train',{},'../sartorius-annotations-coco-format/annotations_val.json', dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e223e8-1373-48e1-96ed-fc1dc645436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = [0.204, 0.386, 0.568]\n",
    "min_mask_area = [75, 150, 75]\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    false_positives = np.sum(matches, axis=0) == 0\n",
    "    if len(matches.shape)>1:\n",
    "        false_negatives = np.sum(matches, axis=1) == 0\n",
    "        true_positives = np.sum(matches, axis=1) == 1\n",
    "    else:\n",
    "        false_negatives = 0\n",
    "        true_positives = 0\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n",
    "    take = pred['instances'].scores >= score_threshold[pred_class]\n",
    "    pred_masks = pred['instances'].pred_masks[take].cpu().numpy()\n",
    "    if len(pred_masks)==0:\n",
    "        return 0.\n",
    "    else:\n",
    "        enc_preds = []\n",
    "        used = np.zeros(pred_masks[0].shape, dtype=int)\n",
    "        for mask in pred_masks:\n",
    "            mask = (mask * (1-used)).astype(bool)\n",
    "            if mask.sum() >= min_mask_area[pred_class]:\n",
    "                used += mask\n",
    "                enc_preds.append(mask_util.encode(np.asarray(mask, order='F')) )\n",
    "        enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "        ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "        prec = []\n",
    "        for t in np.arange(0.5, 1.0, 0.05):\n",
    "            tp, fp, fn = precision_at(t, ious)\n",
    "            p = tp / (tp + fp + fn)\n",
    "            prec.append(p)\n",
    "        return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"mAP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "        T.RandomContrast(0.95,1.05),\n",
    "        T.RandomBrightness(0.95,1.05),\n",
    "        T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.ResizeShortestEdge(short_edge_length=(832, 864, 896, 928, 960, 992, 1024), max_size=9999, sample_style='choice')\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f03977-0dcc-414f-863c-8c21062e31ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/13 11:03:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 11:03:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 11:03:13 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/13 11:03:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomContrast(intensity_min=0.95, intensity_max=1.05), RandomBrightness(intensity_min=0.95, intensity_max=1.05), RandomFlip(prob=0.5), RandomFlip(prob=0.5, horizontal=False, vertical=True), ResizeShortestEdge(short_edge_length=(832, 864, 896, 928, 960, 992, 1024), max_size=9999, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:03:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 11:03:13 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 121 images left.\n",
      "\u001b[32m[02/13 11:03:13 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/13 11:03:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/13 11:03:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:03:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 11:03:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/13 11:03:34 d2.utils.events]: \u001b[0m eta: 0:36:37  iter: 19  total_loss: 1.42  loss_cls: 0.3744  loss_box_reg: 0.5738  loss_mask: 0.2941  loss_rpn_cls: 0.04519  loss_rpn_loc: 0.1105  time: 0.8887  data_time: 0.2772  lr: 3.2362e-06  max_mem: 7961M\n",
      "\u001b[32m[02/13 11:03:52 d2.utils.events]: \u001b[0m eta: 0:37:05  iter: 39  total_loss: 1.392  loss_cls: 0.3584  loss_box_reg: 0.5753  loss_mask: 0.3034  loss_rpn_cls: 0.04174  loss_rpn_loc: 0.1149  time: 0.9118  data_time: 0.2166  lr: 6.4322e-06  max_mem: 8235M\n",
      "\u001b[32m[02/13 11:04:11 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 59  total_loss: 1.324  loss_cls: 0.3392  loss_box_reg: 0.5418  loss_mask: 0.2838  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.1064  time: 0.9201  data_time: 0.2265  lr: 9.6282e-06  max_mem: 8235M\n",
      "\u001b[32m[02/13 11:04:26 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 79  total_loss: 1.267  loss_cls: 0.3406  loss_box_reg: 0.5228  loss_mask: 0.281  loss_rpn_cls: 0.02557  loss_rpn_loc: 0.0964  time: 0.8680  data_time: 0.0402  lr: 1.2824e-05  max_mem: 8235M\n",
      "\u001b[32m[02/13 11:04:44 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 99  total_loss: 1.343  loss_cls: 0.3563  loss_box_reg: 0.5586  loss_mask: 0.3  loss_rpn_cls: 0.04066  loss_rpn_loc: 0.1167  time: 0.8778  data_time: 0.2033  lr: 1.602e-05  max_mem: 8489M\n",
      "\u001b[32m[02/13 11:05:04 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 119  total_loss: 1.396  loss_cls: 0.3705  loss_box_reg: 0.5614  loss_mask: 0.2994  loss_rpn_cls: 0.05078  loss_rpn_loc: 0.1245  time: 0.8976  data_time: 0.2803  lr: 1.9216e-05  max_mem: 8489M\n",
      "\u001b[32m[02/13 11:05:05 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:05:06 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/13 11:05:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:05:06 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:05:06 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:05:06 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:05:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:05:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1640 s/iter. Eval: 0.2209 s/iter. Total: 0.3857 s/iter. ETA=0:03:02\n",
      "\u001b[32m[02/13 11:05:16 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1590 s/iter. Eval: 0.1705 s/iter. Total: 0.3304 s/iter. ETA=0:02:30\n",
      "\u001b[32m[02/13 11:05:21 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1617 s/iter. Eval: 0.1564 s/iter. Total: 0.3191 s/iter. ETA=0:02:20\n",
      "\u001b[32m[02/13 11:05:26 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1570 s/iter. Total: 0.3188 s/iter. ETA=0:02:15\n",
      "\u001b[32m[02/13 11:05:32 d2.evaluation.evaluator]: \u001b[0mInference done 81/485. Dataloading: 0.0009 s/iter. Inference: 0.1579 s/iter. Eval: 0.1449 s/iter. Total: 0.3038 s/iter. ETA=0:02:02\n",
      "\u001b[32m[02/13 11:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0009 s/iter. Inference: 0.1586 s/iter. Eval: 0.1422 s/iter. Total: 0.3018 s/iter. ETA=0:01:56\n",
      "\u001b[32m[02/13 11:05:42 d2.evaluation.evaluator]: \u001b[0mInference done 114/485. Dataloading: 0.0009 s/iter. Inference: 0.1602 s/iter. Eval: 0.1469 s/iter. Total: 0.3081 s/iter. ETA=0:01:54\n",
      "\u001b[32m[02/13 11:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 131/485. Dataloading: 0.0009 s/iter. Inference: 0.1588 s/iter. Eval: 0.1475 s/iter. Total: 0.3073 s/iter. ETA=0:01:48\n",
      "\u001b[32m[02/13 11:05:53 d2.evaluation.evaluator]: \u001b[0mInference done 147/485. Dataloading: 0.0009 s/iter. Inference: 0.1588 s/iter. Eval: 0.1520 s/iter. Total: 0.3118 s/iter. ETA=0:01:45\n",
      "\u001b[32m[02/13 11:05:58 d2.evaluation.evaluator]: \u001b[0mInference done 169/485. Dataloading: 0.0009 s/iter. Inference: 0.1578 s/iter. Eval: 0.1437 s/iter. Total: 0.3026 s/iter. ETA=0:01:35\n",
      "\u001b[32m[02/13 11:06:03 d2.evaluation.evaluator]: \u001b[0mInference done 186/485. Dataloading: 0.0009 s/iter. Inference: 0.1575 s/iter. Eval: 0.1435 s/iter. Total: 0.3021 s/iter. ETA=0:01:30\n",
      "\u001b[32m[02/13 11:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 203/485. Dataloading: 0.0009 s/iter. Inference: 0.1574 s/iter. Eval: 0.1435 s/iter. Total: 0.3020 s/iter. ETA=0:01:25\n",
      "\u001b[32m[02/13 11:06:13 d2.evaluation.evaluator]: \u001b[0mInference done 220/485. Dataloading: 0.0009 s/iter. Inference: 0.1571 s/iter. Eval: 0.1435 s/iter. Total: 0.3016 s/iter. ETA=0:01:19\n",
      "\u001b[32m[02/13 11:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 237/485. Dataloading: 0.0009 s/iter. Inference: 0.1568 s/iter. Eval: 0.1435 s/iter. Total: 0.3012 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 11:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 249/485. Dataloading: 0.0009 s/iter. Inference: 0.1574 s/iter. Eval: 0.1489 s/iter. Total: 0.3073 s/iter. ETA=0:01:12\n",
      "\u001b[32m[02/13 11:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 265/485. Dataloading: 0.0009 s/iter. Inference: 0.1578 s/iter. Eval: 0.1498 s/iter. Total: 0.3087 s/iter. ETA=0:01:07\n",
      "\u001b[32m[02/13 11:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 281/485. Dataloading: 0.0010 s/iter. Inference: 0.1580 s/iter. Eval: 0.1504 s/iter. Total: 0.3093 s/iter. ETA=0:01:03\n",
      "\u001b[32m[02/13 11:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 301/485. Dataloading: 0.0010 s/iter. Inference: 0.1574 s/iter. Eval: 0.1486 s/iter. Total: 0.3070 s/iter. ETA=0:00:56\n",
      "\u001b[32m[02/13 11:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 317/485. Dataloading: 0.0010 s/iter. Inference: 0.1578 s/iter. Eval: 0.1490 s/iter. Total: 0.3078 s/iter. ETA=0:00:51\n",
      "\u001b[32m[02/13 11:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 330/485. Dataloading: 0.0010 s/iter. Inference: 0.1582 s/iter. Eval: 0.1522 s/iter. Total: 0.3114 s/iter. ETA=0:00:48\n",
      "\u001b[32m[02/13 11:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 349/485. Dataloading: 0.0010 s/iter. Inference: 0.1578 s/iter. Eval: 0.1504 s/iter. Total: 0.3092 s/iter. ETA=0:00:42\n",
      "\u001b[32m[02/13 11:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 366/485. Dataloading: 0.0010 s/iter. Inference: 0.1576 s/iter. Eval: 0.1514 s/iter. Total: 0.3100 s/iter. ETA=0:00:36\n",
      "\u001b[32m[02/13 11:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 387/485. Dataloading: 0.0010 s/iter. Inference: 0.1572 s/iter. Eval: 0.1480 s/iter. Total: 0.3063 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/13 11:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 406/485. Dataloading: 0.0010 s/iter. Inference: 0.1569 s/iter. Eval: 0.1465 s/iter. Total: 0.3044 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/13 11:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 420/485. Dataloading: 0.0010 s/iter. Inference: 0.1573 s/iter. Eval: 0.1496 s/iter. Total: 0.3079 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/13 11:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 438/485. Dataloading: 0.0010 s/iter. Inference: 0.1571 s/iter. Eval: 0.1486 s/iter. Total: 0.3067 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 11:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 455/485. Dataloading: 0.0010 s/iter. Inference: 0.1572 s/iter. Eval: 0.1481 s/iter. Total: 0.3063 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 11:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 475/485. Dataloading: 0.0010 s/iter. Inference: 0.1568 s/iter. Eval: 0.1464 s/iter. Total: 0.3042 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 11:07:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:25.915061 (0.303990 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:07:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:15 (0.156822 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:07:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:07:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3041720305821364\n",
      "\u001b[32m[02/13 11:07:50 d2.utils.events]: \u001b[0m eta: 0:35:03  iter: 139  total_loss: 1.326  loss_cls: 0.3543  loss_box_reg: 0.5243  loss_mask: 0.2871  loss_rpn_cls: 0.04212  loss_rpn_loc: 0.107  time: 0.8887  data_time: 0.1186  lr: 2.2412e-05  max_mem: 8489M\n",
      "\u001b[32m[02/13 11:07:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:07:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:08:15 d2.utils.events]: \u001b[0m eta: 0:34:50  iter: 159  total_loss: 1.369  loss_cls: 0.3746  loss_box_reg: 0.5313  loss_mask: 0.2965  loss_rpn_cls: 0.04329  loss_rpn_loc: 0.1218  time: 0.9326  data_time: 0.3256  lr: 2.5608e-05  max_mem: 8489M\n",
      "\u001b[32m[02/13 11:08:33 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 179  total_loss: 1.455  loss_cls: 0.3624  loss_box_reg: 0.5716  loss_mask: 0.3069  loss_rpn_cls: 0.04378  loss_rpn_loc: 0.1143  time: 0.9260  data_time: 0.1680  lr: 2.8804e-05  max_mem: 8876M\n",
      "\u001b[32m[02/13 11:08:50 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 199  total_loss: 1.296  loss_cls: 0.3457  loss_box_reg: 0.5477  loss_mask: 0.2913  loss_rpn_cls: 0.04164  loss_rpn_loc: 0.1169  time: 0.9182  data_time: 0.1508  lr: 3.2e-05  max_mem: 8876M\n",
      "\u001b[32m[02/13 11:09:08 d2.utils.events]: \u001b[0m eta: 0:34:02  iter: 219  total_loss: 1.441  loss_cls: 0.3844  loss_box_reg: 0.5919  loss_mask: 0.3117  loss_rpn_cls: 0.04491  loss_rpn_loc: 0.1156  time: 0.9164  data_time: 0.1665  lr: 3.5196e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:09:25 d2.utils.events]: \u001b[0m eta: 0:33:43  iter: 239  total_loss: 1.26  loss_cls: 0.3275  loss_box_reg: 0.5044  loss_mask: 0.2833  loss_rpn_cls: 0.03698  loss_rpn_loc: 0.1014  time: 0.9094  data_time: 0.1428  lr: 3.8392e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:09:27 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:09:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:09:28 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:09:28 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:09:28 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:09:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1635 s/iter. Eval: 0.2188 s/iter. Total: 0.3830 s/iter. ETA=0:03:01\n",
      "\u001b[32m[02/13 11:09:38 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1594 s/iter. Eval: 0.1683 s/iter. Total: 0.3286 s/iter. ETA=0:02:30\n",
      "\u001b[32m[02/13 11:09:43 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1622 s/iter. Eval: 0.1536 s/iter. Total: 0.3167 s/iter. ETA=0:02:19\n",
      "\u001b[32m[02/13 11:09:48 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1613 s/iter. Eval: 0.1543 s/iter. Total: 0.3166 s/iter. ETA=0:02:14\n",
      "\u001b[32m[02/13 11:09:54 d2.evaluation.evaluator]: \u001b[0mInference done 81/485. Dataloading: 0.0009 s/iter. Inference: 0.1584 s/iter. Eval: 0.1424 s/iter. Total: 0.3017 s/iter. ETA=0:02:01\n",
      "\u001b[32m[02/13 11:09:59 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0009 s/iter. Inference: 0.1590 s/iter. Eval: 0.1398 s/iter. Total: 0.2999 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 11:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 114/485. Dataloading: 0.0009 s/iter. Inference: 0.1607 s/iter. Eval: 0.1443 s/iter. Total: 0.3060 s/iter. ETA=0:01:53\n",
      "\u001b[32m[02/13 11:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 131/485. Dataloading: 0.0009 s/iter. Inference: 0.1594 s/iter. Eval: 0.1450 s/iter. Total: 0.3053 s/iter. ETA=0:01:48\n",
      "\u001b[32m[02/13 11:10:15 d2.evaluation.evaluator]: \u001b[0mInference done 147/485. Dataloading: 0.0009 s/iter. Inference: 0.1593 s/iter. Eval: 0.1495 s/iter. Total: 0.3098 s/iter. ETA=0:01:44\n",
      "\u001b[32m[02/13 11:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 169/485. Dataloading: 0.0009 s/iter. Inference: 0.1583 s/iter. Eval: 0.1413 s/iter. Total: 0.3006 s/iter. ETA=0:01:35\n",
      "\u001b[32m[02/13 11:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 186/485. Dataloading: 0.0009 s/iter. Inference: 0.1580 s/iter. Eval: 0.1411 s/iter. Total: 0.3000 s/iter. ETA=0:01:29\n",
      "\u001b[32m[02/13 11:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 203/485. Dataloading: 0.0009 s/iter. Inference: 0.1579 s/iter. Eval: 0.1411 s/iter. Total: 0.2999 s/iter. ETA=0:01:24\n",
      "\u001b[32m[02/13 11:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 220/485. Dataloading: 0.0009 s/iter. Inference: 0.1575 s/iter. Eval: 0.1410 s/iter. Total: 0.2995 s/iter. ETA=0:01:19\n",
      "\u001b[32m[02/13 11:10:40 d2.evaluation.evaluator]: \u001b[0mInference done 237/485. Dataloading: 0.0009 s/iter. Inference: 0.1574 s/iter. Eval: 0.1411 s/iter. Total: 0.2995 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 11:10:45 d2.evaluation.evaluator]: \u001b[0mInference done 248/485. Dataloading: 0.0009 s/iter. Inference: 0.1585 s/iter. Eval: 0.1472 s/iter. Total: 0.3066 s/iter. ETA=0:01:12\n",
      "\u001b[32m[02/13 11:10:51 d2.evaluation.evaluator]: \u001b[0mInference done 265/485. Dataloading: 0.0009 s/iter. Inference: 0.1588 s/iter. Eval: 0.1478 s/iter. Total: 0.3076 s/iter. ETA=0:01:07\n",
      "\u001b[32m[02/13 11:10:56 d2.evaluation.evaluator]: \u001b[0mInference done 280/485. Dataloading: 0.0009 s/iter. Inference: 0.1592 s/iter. Eval: 0.1489 s/iter. Total: 0.3091 s/iter. ETA=0:01:03\n",
      "\u001b[32m[02/13 11:11:01 d2.evaluation.evaluator]: \u001b[0mInference done 301/485. Dataloading: 0.0009 s/iter. Inference: 0.1585 s/iter. Eval: 0.1469 s/iter. Total: 0.3064 s/iter. ETA=0:00:56\n",
      "\u001b[32m[02/13 11:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 317/485. Dataloading: 0.0009 s/iter. Inference: 0.1589 s/iter. Eval: 0.1472 s/iter. Total: 0.3071 s/iter. ETA=0:00:51\n",
      "\u001b[32m[02/13 11:11:12 d2.evaluation.evaluator]: \u001b[0mInference done 330/485. Dataloading: 0.0009 s/iter. Inference: 0.1592 s/iter. Eval: 0.1503 s/iter. Total: 0.3105 s/iter. ETA=0:00:48\n",
      "\u001b[32m[02/13 11:11:17 d2.evaluation.evaluator]: \u001b[0mInference done 349/485. Dataloading: 0.0009 s/iter. Inference: 0.1587 s/iter. Eval: 0.1484 s/iter. Total: 0.3082 s/iter. ETA=0:00:41\n",
      "\u001b[32m[02/13 11:11:22 d2.evaluation.evaluator]: \u001b[0mInference done 366/485. Dataloading: 0.0009 s/iter. Inference: 0.1586 s/iter. Eval: 0.1493 s/iter. Total: 0.3089 s/iter. ETA=0:00:36\n",
      "\u001b[32m[02/13 11:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 387/485. Dataloading: 0.0009 s/iter. Inference: 0.1581 s/iter. Eval: 0.1460 s/iter. Total: 0.3052 s/iter. ETA=0:00:29\n",
      "\u001b[32m[02/13 11:11:32 d2.evaluation.evaluator]: \u001b[0mInference done 406/485. Dataloading: 0.0009 s/iter. Inference: 0.1578 s/iter. Eval: 0.1445 s/iter. Total: 0.3033 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 11:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 420/485. Dataloading: 0.0009 s/iter. Inference: 0.1582 s/iter. Eval: 0.1476 s/iter. Total: 0.3068 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/13 11:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 439/485. Dataloading: 0.0009 s/iter. Inference: 0.1579 s/iter. Eval: 0.1464 s/iter. Total: 0.3053 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 11:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 456/485. Dataloading: 0.0009 s/iter. Inference: 0.1580 s/iter. Eval: 0.1459 s/iter. Total: 0.3049 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/13 11:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 476/485. Dataloading: 0.0009 s/iter. Inference: 0.1575 s/iter. Eval: 0.1442 s/iter. Total: 0.3028 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/13 11:11:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:25.358783 (0.302831 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:11:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:15 (0.157633 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:11:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:11:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30414961819728065\n",
      "\u001b[32m[02/13 11:12:10 d2.utils.events]: \u001b[0m eta: 0:33:27  iter: 259  total_loss: 1.324  loss_cls: 0.3358  loss_box_reg: 0.5445  loss_mask: 0.2961  loss_rpn_cls: 0.03462  loss_rpn_loc: 0.1059  time: 0.9034  data_time: 0.1241  lr: 4.1588e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:12:31 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 279  total_loss: 1.398  loss_cls: 0.3768  loss_box_reg: 0.5698  loss_mask: 0.3087  loss_rpn_cls: 0.0465  loss_rpn_loc: 0.1217  time: 0.9116  data_time: 0.2846  lr: 4.4784e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:12:48 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 299  total_loss: 1.312  loss_cls: 0.337  loss_box_reg: 0.5297  loss_mask: 0.2775  loss_rpn_cls: 0.03936  loss_rpn_loc: 0.1132  time: 0.9073  data_time: 0.1414  lr: 4.798e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:13:06 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 319  total_loss: 1.396  loss_cls: 0.3654  loss_box_reg: 0.5795  loss_mask: 0.3168  loss_rpn_cls: 0.03951  loss_rpn_loc: 0.1113  time: 0.9082  data_time: 0.2322  lr: 5.1176e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:13:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:13:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:13:27 d2.utils.events]: \u001b[0m eta: 0:32:24  iter: 339  total_loss: 1.371  loss_cls: 0.3571  loss_box_reg: 0.5478  loss_mask: 0.2961  loss_rpn_cls: 0.05502  loss_rpn_loc: 0.1176  time: 0.9168  data_time: 0.1786  lr: 5.4372e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:13:47 d2.utils.events]: \u001b[0m eta: 0:32:13  iter: 359  total_loss: 1.338  loss_cls: 0.3598  loss_box_reg: 0.5445  loss_mask: 0.2956  loss_rpn_cls: 0.04745  loss_rpn_loc: 0.1193  time: 0.9185  data_time: 0.2323  lr: 5.7568e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:13:49 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:13:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:13:49 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:13:49 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:13:50 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:13:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0007 s/iter. Inference: 0.1637 s/iter. Eval: 0.2220 s/iter. Total: 0.3864 s/iter. ETA=0:03:03\n",
      "\u001b[32m[02/13 11:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1596 s/iter. Eval: 0.1696 s/iter. Total: 0.3301 s/iter. ETA=0:02:30\n",
      "\u001b[32m[02/13 11:14:05 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1630 s/iter. Eval: 0.1539 s/iter. Total: 0.3178 s/iter. ETA=0:02:19\n",
      "\u001b[32m[02/13 11:14:10 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1637 s/iter. Eval: 0.1559 s/iter. Total: 0.3206 s/iter. ETA=0:02:15\n",
      "\u001b[32m[02/13 11:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1621 s/iter. Eval: 0.1446 s/iter. Total: 0.3077 s/iter. ETA=0:02:04\n",
      "\u001b[32m[02/13 11:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 98/485. Dataloading: 0.0009 s/iter. Inference: 0.1629 s/iter. Eval: 0.1386 s/iter. Total: 0.3024 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 11:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0009 s/iter. Inference: 0.1646 s/iter. Eval: 0.1458 s/iter. Total: 0.3113 s/iter. ETA=0:01:56\n",
      "\u001b[32m[02/13 11:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0009 s/iter. Inference: 0.1635 s/iter. Eval: 0.1451 s/iter. Total: 0.3096 s/iter. ETA=0:01:50\n",
      "\u001b[32m[02/13 11:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 145/485. Dataloading: 0.0009 s/iter. Inference: 0.1633 s/iter. Eval: 0.1499 s/iter. Total: 0.3142 s/iter. ETA=0:01:46\n",
      "\u001b[32m[02/13 11:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 164/485. Dataloading: 0.0009 s/iter. Inference: 0.1623 s/iter. Eval: 0.1457 s/iter. Total: 0.3089 s/iter. ETA=0:01:39\n",
      "\u001b[32m[02/13 11:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0009 s/iter. Inference: 0.1614 s/iter. Eval: 0.1414 s/iter. Total: 0.3038 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 11:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 199/485. Dataloading: 0.0009 s/iter. Inference: 0.1614 s/iter. Eval: 0.1449 s/iter. Total: 0.3073 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 11:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0009 s/iter. Inference: 0.1607 s/iter. Eval: 0.1440 s/iter. Total: 0.3057 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 11:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 235/485. Dataloading: 0.0009 s/iter. Inference: 0.1606 s/iter. Eval: 0.1426 s/iter. Total: 0.3042 s/iter. ETA=0:01:16\n",
      "\u001b[32m[02/13 11:15:08 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0009 s/iter. Inference: 0.1613 s/iter. Eval: 0.1492 s/iter. Total: 0.3115 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 11:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 264/485. Dataloading: 0.0009 s/iter. Inference: 0.1613 s/iter. Eval: 0.1484 s/iter. Total: 0.3106 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 11:15:18 d2.evaluation.evaluator]: \u001b[0mInference done 278/485. Dataloading: 0.0009 s/iter. Inference: 0.1617 s/iter. Eval: 0.1509 s/iter. Total: 0.3136 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 11:15:23 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0009 s/iter. Inference: 0.1606 s/iter. Eval: 0.1471 s/iter. Total: 0.3087 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 11:15:28 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0009 s/iter. Inference: 0.1610 s/iter. Eval: 0.1485 s/iter. Total: 0.3105 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 11:15:33 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0009 s/iter. Inference: 0.1612 s/iter. Eval: 0.1506 s/iter. Total: 0.3128 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 11:15:38 d2.evaluation.evaluator]: \u001b[0mInference done 345/485. Dataloading: 0.0009 s/iter. Inference: 0.1609 s/iter. Eval: 0.1500 s/iter. Total: 0.3119 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 11:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 363/485. Dataloading: 0.0009 s/iter. Inference: 0.1604 s/iter. Eval: 0.1490 s/iter. Total: 0.3104 s/iter. ETA=0:00:37\n",
      "\u001b[32m[02/13 11:15:49 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0009 s/iter. Inference: 0.1603 s/iter. Eval: 0.1484 s/iter. Total: 0.3097 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/13 11:15:54 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1475 s/iter. Total: 0.3086 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 11:15:59 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0009 s/iter. Inference: 0.1599 s/iter. Eval: 0.1473 s/iter. Total: 0.3082 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 11:16:04 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1481 s/iter. Total: 0.3091 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 11:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1489 s/iter. Total: 0.3100 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 11:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0009 s/iter. Inference: 0.1596 s/iter. Eval: 0.1461 s/iter. Total: 0.3068 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 11:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0009 s/iter. Inference: 0.1595 s/iter. Eval: 0.1452 s/iter. Total: 0.3057 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 11:16:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:26.706089 (0.305638 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:16:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.159441 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:16:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:16:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30105959553681416\n",
      "\u001b[32m[02/13 11:16:33 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 379  total_loss: 1.376  loss_cls: 0.3554  loss_box_reg: 0.5562  loss_mask: 0.2991  loss_rpn_cls: 0.03995  loss_rpn_loc: 0.1266  time: 0.9113  data_time: 0.0940  lr: 6.0764e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:16:56 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 399  total_loss: 1.436  loss_cls: 0.3698  loss_box_reg: 0.5638  loss_mask: 0.2951  loss_rpn_cls: 0.05514  loss_rpn_loc: 0.12  time: 0.9246  data_time: 0.4470  lr: 6.396e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:17:12 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 419  total_loss: 1.399  loss_cls: 0.3504  loss_box_reg: 0.5682  loss_mask: 0.2982  loss_rpn_cls: 0.05416  loss_rpn_loc: 0.1146  time: 0.9183  data_time: 0.1123  lr: 6.7156e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:17:32 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 439  total_loss: 1.437  loss_cls: 0.3763  loss_box_reg: 0.565  loss_mask: 0.3028  loss_rpn_cls: 0.04559  loss_rpn_loc: 0.1157  time: 0.9219  data_time: 0.2452  lr: 7.0352e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:17:49 d2.utils.events]: \u001b[0m eta: 0:31:02  iter: 459  total_loss: 1.348  loss_cls: 0.3486  loss_box_reg: 0.5508  loss_mask: 0.2851  loss_rpn_cls: 0.04163  loss_rpn_loc: 0.1088  time: 0.9185  data_time: 0.1559  lr: 7.3548e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:18:05 d2.utils.events]: \u001b[0m eta: 0:30:45  iter: 479  total_loss: 1.32  loss_cls: 0.3369  loss_box_reg: 0.5731  loss_mask: 0.2928  loss_rpn_cls: 0.0361  loss_rpn_loc: 0.1117  time: 0.9121  data_time: 0.0617  lr: 7.6744e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:18:08 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:18:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:18:09 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:18:09 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:18:09 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:18:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1651 s/iter. Eval: 0.2248 s/iter. Total: 0.3906 s/iter. ETA=0:03:05\n",
      "\u001b[32m[02/13 11:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1744 s/iter. Total: 0.3362 s/iter. ETA=0:02:33\n",
      "\u001b[32m[02/13 11:18:25 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1644 s/iter. Eval: 0.1574 s/iter. Total: 0.3228 s/iter. ETA=0:02:22\n",
      "\u001b[32m[02/13 11:18:30 d2.evaluation.evaluator]: \u001b[0mInference done 60/485. Dataloading: 0.0009 s/iter. Inference: 0.1662 s/iter. Eval: 0.1593 s/iter. Total: 0.3265 s/iter. ETA=0:02:18\n",
      "\u001b[32m[02/13 11:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 78/485. Dataloading: 0.0009 s/iter. Inference: 0.1639 s/iter. Eval: 0.1508 s/iter. Total: 0.3156 s/iter. ETA=0:02:08\n",
      "\u001b[32m[02/13 11:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 97/485. Dataloading: 0.0009 s/iter. Inference: 0.1643 s/iter. Eval: 0.1427 s/iter. Total: 0.3080 s/iter. ETA=0:01:59\n",
      "\u001b[32m[02/13 11:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0010 s/iter. Inference: 0.1648 s/iter. Eval: 0.1492 s/iter. Total: 0.3151 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 11:18:51 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0009 s/iter. Inference: 0.1640 s/iter. Eval: 0.1495 s/iter. Total: 0.3145 s/iter. ETA=0:01:51\n",
      "\u001b[32m[02/13 11:18:56 d2.evaluation.evaluator]: \u001b[0mInference done 144/485. Dataloading: 0.0010 s/iter. Inference: 0.1641 s/iter. Eval: 0.1527 s/iter. Total: 0.3178 s/iter. ETA=0:01:48\n",
      "\u001b[32m[02/13 11:19:01 d2.evaluation.evaluator]: \u001b[0mInference done 159/485. Dataloading: 0.0010 s/iter. Inference: 0.1648 s/iter. Eval: 0.1542 s/iter. Total: 0.3199 s/iter. ETA=0:01:44\n",
      "\u001b[32m[02/13 11:19:06 d2.evaluation.evaluator]: \u001b[0mInference done 180/485. Dataloading: 0.0010 s/iter. Inference: 0.1643 s/iter. Eval: 0.1476 s/iter. Total: 0.3129 s/iter. ETA=0:01:35\n",
      "\u001b[32m[02/13 11:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 195/485. Dataloading: 0.0010 s/iter. Inference: 0.1646 s/iter. Eval: 0.1497 s/iter. Total: 0.3154 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 11:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 210/485. Dataloading: 0.0010 s/iter. Inference: 0.1652 s/iter. Eval: 0.1509 s/iter. Total: 0.3171 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 11:19:22 d2.evaluation.evaluator]: \u001b[0mInference done 227/485. Dataloading: 0.0010 s/iter. Inference: 0.1651 s/iter. Eval: 0.1518 s/iter. Total: 0.3179 s/iter. ETA=0:01:22\n",
      "\u001b[32m[02/13 11:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 244/485. Dataloading: 0.0010 s/iter. Inference: 0.1652 s/iter. Eval: 0.1520 s/iter. Total: 0.3183 s/iter. ETA=0:01:16\n",
      "\u001b[32m[02/13 11:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 256/485. Dataloading: 0.0010 s/iter. Inference: 0.1659 s/iter. Eval: 0.1568 s/iter. Total: 0.3237 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 11:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 273/485. Dataloading: 0.0010 s/iter. Inference: 0.1655 s/iter. Eval: 0.1573 s/iter. Total: 0.3237 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 11:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 289/485. Dataloading: 0.0010 s/iter. Inference: 0.1652 s/iter. Eval: 0.1572 s/iter. Total: 0.3234 s/iter. ETA=0:01:03\n",
      "\u001b[32m[02/13 11:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 308/485. Dataloading: 0.0010 s/iter. Inference: 0.1645 s/iter. Eval: 0.1542 s/iter. Total: 0.3197 s/iter. ETA=0:00:56\n",
      "\u001b[32m[02/13 11:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 322/485. Dataloading: 0.0010 s/iter. Inference: 0.1649 s/iter. Eval: 0.1568 s/iter. Total: 0.3227 s/iter. ETA=0:00:52\n",
      "\u001b[32m[02/13 11:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 336/485. Dataloading: 0.0010 s/iter. Inference: 0.1650 s/iter. Eval: 0.1582 s/iter. Total: 0.3242 s/iter. ETA=0:00:48\n",
      "\u001b[32m[02/13 11:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 354/485. Dataloading: 0.0010 s/iter. Inference: 0.1643 s/iter. Eval: 0.1569 s/iter. Total: 0.3222 s/iter. ETA=0:00:42\n",
      "\u001b[32m[02/13 11:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 371/485. Dataloading: 0.0010 s/iter. Inference: 0.1639 s/iter. Eval: 0.1563 s/iter. Total: 0.3212 s/iter. ETA=0:00:36\n",
      "\u001b[32m[02/13 11:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 391/485. Dataloading: 0.0010 s/iter. Inference: 0.1634 s/iter. Eval: 0.1533 s/iter. Total: 0.3177 s/iter. ETA=0:00:29\n",
      "\u001b[32m[02/13 11:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 408/485. Dataloading: 0.0010 s/iter. Inference: 0.1631 s/iter. Eval: 0.1530 s/iter. Total: 0.3171 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/13 11:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 421/485. Dataloading: 0.0010 s/iter. Inference: 0.1632 s/iter. Eval: 0.1553 s/iter. Total: 0.3195 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/13 11:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 439/485. Dataloading: 0.0010 s/iter. Inference: 0.1629 s/iter. Eval: 0.1542 s/iter. Total: 0.3182 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 11:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 456/485. Dataloading: 0.0010 s/iter. Inference: 0.1629 s/iter. Eval: 0.1535 s/iter. Total: 0.3175 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 11:20:40 d2.evaluation.evaluator]: \u001b[0mInference done 475/485. Dataloading: 0.0010 s/iter. Inference: 0.1624 s/iter. Eval: 0.1520 s/iter. Total: 0.3154 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 11:20:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:31.187396 (0.314974 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:20:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:17 (0.162348 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:20:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3021322823868674\n",
      "\u001b[32m[02/13 11:20:56 d2.utils.events]: \u001b[0m eta: 0:30:29  iter: 499  total_loss: 1.34  loss_cls: 0.3542  loss_box_reg: 0.5363  loss_mask: 0.281  loss_rpn_cls: 0.04123  loss_rpn_loc: 0.1308  time: 0.9089  data_time: 0.1479  lr: 7.994e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:21:13 d2.utils.events]: \u001b[0m eta: 0:30:15  iter: 519  total_loss: 1.376  loss_cls: 0.3632  loss_box_reg: 0.5598  loss_mask: 0.3033  loss_rpn_cls: 0.05322  loss_rpn_loc: 0.1079  time: 0.9064  data_time: 0.1287  lr: 8.3136e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:21:33 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 539  total_loss: 1.312  loss_cls: 0.3292  loss_box_reg: 0.5391  loss_mask: 0.2808  loss_rpn_cls: 0.03909  loss_rpn_loc: 0.1044  time: 0.9088  data_time: 0.2052  lr: 8.6332e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:21:50 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 559  total_loss: 1.339  loss_cls: 0.3423  loss_box_reg: 0.5611  loss_mask: 0.2935  loss_rpn_cls: 0.03778  loss_rpn_loc: 0.09683  time: 0.9067  data_time: 0.1482  lr: 8.9528e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:22:08 d2.utils.events]: \u001b[0m eta: 0:29:31  iter: 579  total_loss: 1.38  loss_cls: 0.3475  loss_box_reg: 0.5736  loss_mask: 0.3091  loss_rpn_cls: 0.03876  loss_rpn_loc: 0.1031  time: 0.9071  data_time: 0.2027  lr: 9.2724e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:22:29 d2.utils.events]: \u001b[0m eta: 0:29:19  iter: 599  total_loss: 1.366  loss_cls: 0.3522  loss_box_reg: 0.5552  loss_mask: 0.2929  loss_rpn_cls: 0.04449  loss_rpn_loc: 0.1241  time: 0.9113  data_time: 0.3101  lr: 9.592e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:22:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:22:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:22:39 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:22:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:22:40 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:22:40 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:22:40 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:22:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1651 s/iter. Eval: 0.2319 s/iter. Total: 0.3978 s/iter. ETA=0:03:08\n",
      "\u001b[32m[02/13 11:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1629 s/iter. Eval: 0.1753 s/iter. Total: 0.3392 s/iter. ETA=0:02:34\n",
      "\u001b[32m[02/13 11:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1677 s/iter. Eval: 0.1582 s/iter. Total: 0.3268 s/iter. ETA=0:02:23\n",
      "\u001b[32m[02/13 11:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1663 s/iter. Eval: 0.1589 s/iter. Total: 0.3262 s/iter. ETA=0:02:18\n",
      "\u001b[32m[02/13 11:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1635 s/iter. Eval: 0.1469 s/iter. Total: 0.3113 s/iter. ETA=0:02:06\n",
      "\u001b[32m[02/13 11:23:11 d2.evaluation.evaluator]: \u001b[0mInference done 98/485. Dataloading: 0.0009 s/iter. Inference: 0.1638 s/iter. Eval: 0.1408 s/iter. Total: 0.3056 s/iter. ETA=0:01:58\n",
      "\u001b[32m[02/13 11:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0009 s/iter. Inference: 0.1647 s/iter. Eval: 0.1481 s/iter. Total: 0.3139 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 11:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0009 s/iter. Inference: 0.1637 s/iter. Eval: 0.1477 s/iter. Total: 0.3124 s/iter. ETA=0:01:51\n",
      "\u001b[32m[02/13 11:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 144/485. Dataloading: 0.0009 s/iter. Inference: 0.1636 s/iter. Eval: 0.1509 s/iter. Total: 0.3155 s/iter. ETA=0:01:47\n",
      "\u001b[32m[02/13 11:23:32 d2.evaluation.evaluator]: \u001b[0mInference done 161/485. Dataloading: 0.0010 s/iter. Inference: 0.1630 s/iter. Eval: 0.1499 s/iter. Total: 0.3139 s/iter. ETA=0:01:41\n",
      "\u001b[32m[02/13 11:23:37 d2.evaluation.evaluator]: \u001b[0mInference done 181/485. Dataloading: 0.0010 s/iter. Inference: 0.1625 s/iter. Eval: 0.1444 s/iter. Total: 0.3079 s/iter. ETA=0:01:33\n",
      "\u001b[32m[02/13 11:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 197/485. Dataloading: 0.0010 s/iter. Inference: 0.1625 s/iter. Eval: 0.1474 s/iter. Total: 0.3109 s/iter. ETA=0:01:29\n",
      "\u001b[32m[02/13 11:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 213/485. Dataloading: 0.0010 s/iter. Inference: 0.1627 s/iter. Eval: 0.1479 s/iter. Total: 0.3116 s/iter. ETA=0:01:24\n",
      "\u001b[32m[02/13 11:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 229/485. Dataloading: 0.0010 s/iter. Inference: 0.1627 s/iter. Eval: 0.1485 s/iter. Total: 0.3122 s/iter. ETA=0:01:19\n",
      "\u001b[32m[02/13 11:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 245/485. Dataloading: 0.0010 s/iter. Inference: 0.1625 s/iter. Eval: 0.1490 s/iter. Total: 0.3125 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 11:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 257/485. Dataloading: 0.0010 s/iter. Inference: 0.1636 s/iter. Eval: 0.1544 s/iter. Total: 0.3190 s/iter. ETA=0:01:12\n",
      "\u001b[32m[02/13 11:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 275/485. Dataloading: 0.0010 s/iter. Inference: 0.1634 s/iter. Eval: 0.1532 s/iter. Total: 0.3176 s/iter. ETA=0:01:06\n",
      "\u001b[32m[02/13 11:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 292/485. Dataloading: 0.0010 s/iter. Inference: 0.1633 s/iter. Eval: 0.1525 s/iter. Total: 0.3168 s/iter. ETA=0:01:01\n",
      "\u001b[32m[02/13 11:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 309/485. Dataloading: 0.0010 s/iter. Inference: 0.1633 s/iter. Eval: 0.1514 s/iter. Total: 0.3157 s/iter. ETA=0:00:55\n",
      "\u001b[32m[02/13 11:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 322/485. Dataloading: 0.0010 s/iter. Inference: 0.1638 s/iter. Eval: 0.1538 s/iter. Total: 0.3186 s/iter. ETA=0:00:51\n",
      "\u001b[32m[02/13 11:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 336/485. Dataloading: 0.0010 s/iter. Inference: 0.1640 s/iter. Eval: 0.1554 s/iter. Total: 0.3204 s/iter. ETA=0:00:47\n",
      "\u001b[32m[02/13 11:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 354/485. Dataloading: 0.0010 s/iter. Inference: 0.1633 s/iter. Eval: 0.1541 s/iter. Total: 0.3185 s/iter. ETA=0:00:41\n",
      "\u001b[32m[02/13 11:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 371/485. Dataloading: 0.0010 s/iter. Inference: 0.1631 s/iter. Eval: 0.1535 s/iter. Total: 0.3177 s/iter. ETA=0:00:36\n",
      "\u001b[32m[02/13 11:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 391/485. Dataloading: 0.0010 s/iter. Inference: 0.1628 s/iter. Eval: 0.1506 s/iter. Total: 0.3145 s/iter. ETA=0:00:29\n",
      "\u001b[32m[02/13 11:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 408/485. Dataloading: 0.0010 s/iter. Inference: 0.1625 s/iter. Eval: 0.1504 s/iter. Total: 0.3139 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/13 11:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 421/485. Dataloading: 0.0010 s/iter. Inference: 0.1627 s/iter. Eval: 0.1525 s/iter. Total: 0.3163 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/13 11:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 439/485. Dataloading: 0.0010 s/iter. Inference: 0.1624 s/iter. Eval: 0.1515 s/iter. Total: 0.3149 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 11:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 456/485. Dataloading: 0.0010 s/iter. Inference: 0.1625 s/iter. Eval: 0.1508 s/iter. Total: 0.3144 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 11:25:10 d2.evaluation.evaluator]: \u001b[0mInference done 475/485. Dataloading: 0.0010 s/iter. Inference: 0.1620 s/iter. Eval: 0.1493 s/iter. Total: 0.3123 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 11:25:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:29.783726 (0.312049 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:25:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:17 (0.162056 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:25:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:25:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3026067086034192\n",
      "\u001b[32m[02/13 11:25:26 d2.utils.events]: \u001b[0m eta: 0:29:06  iter: 619  total_loss: 1.546  loss_cls: 0.4199  loss_box_reg: 0.5941  loss_mask: 0.3231  loss_rpn_cls: 0.05692  loss_rpn_loc: 0.1506  time: 0.9198  data_time: 0.2955  lr: 9.9116e-05  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:25:43 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 639  total_loss: 1.387  loss_cls: 0.3504  loss_box_reg: 0.5529  loss_mask: 0.307  loss_rpn_cls: 0.03887  loss_rpn_loc: 0.1027  time: 0.9173  data_time: 0.1361  lr: 0.00010231  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:25:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:25:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:26:05 d2.utils.events]: \u001b[0m eta: 0:28:37  iter: 659  total_loss: 1.345  loss_cls: 0.3526  loss_box_reg: 0.5124  loss_mask: 0.2824  loss_rpn_cls: 0.04145  loss_rpn_loc: 0.1085  time: 0.9220  data_time: 0.1527  lr: 0.00010551  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:26:21 d2.utils.events]: \u001b[0m eta: 0:28:23  iter: 679  total_loss: 1.408  loss_cls: 0.3487  loss_box_reg: 0.5787  loss_mask: 0.2933  loss_rpn_cls: 0.05747  loss_rpn_loc: 0.1155  time: 0.9186  data_time: 0.1041  lr: 0.0001087  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:26:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:26:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:26:45 d2.utils.events]: \u001b[0m eta: 0:28:11  iter: 699  total_loss: 1.398  loss_cls: 0.3791  loss_box_reg: 0.5712  loss_mask: 0.2951  loss_rpn_cls: 0.03914  loss_rpn_loc: 0.1165  time: 0.9270  data_time: 0.3075  lr: 0.0001119  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:26:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:27:06 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 719  total_loss: 1.294  loss_cls: 0.3297  loss_box_reg: 0.5536  loss_mask: 0.3135  loss_rpn_cls: 0.03454  loss_rpn_loc: 0.09357  time: 0.9297  data_time: 0.2197  lr: 0.0001151  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:27:10 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:27:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:27:11 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:27:11 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:27:11 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:27:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1647 s/iter. Eval: 0.2253 s/iter. Total: 0.3908 s/iter. ETA=0:03:05\n",
      "\u001b[32m[02/13 11:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1609 s/iter. Eval: 0.1729 s/iter. Total: 0.3348 s/iter. ETA=0:02:32\n",
      "\u001b[32m[02/13 11:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1665 s/iter. Eval: 0.1572 s/iter. Total: 0.3247 s/iter. ETA=0:02:22\n",
      "\u001b[32m[02/13 11:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1649 s/iter. Eval: 0.1585 s/iter. Total: 0.3244 s/iter. ETA=0:02:17\n",
      "\u001b[32m[02/13 11:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1628 s/iter. Eval: 0.1476 s/iter. Total: 0.3113 s/iter. ETA=0:02:06\n",
      "\u001b[32m[02/13 11:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 97/485. Dataloading: 0.0009 s/iter. Inference: 0.1645 s/iter. Eval: 0.1432 s/iter. Total: 0.3087 s/iter. ETA=0:01:59\n",
      "\u001b[32m[02/13 11:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0009 s/iter. Inference: 0.1657 s/iter. Eval: 0.1501 s/iter. Total: 0.3168 s/iter. ETA=0:01:58\n",
      "\u001b[32m[02/13 11:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0009 s/iter. Inference: 0.1651 s/iter. Eval: 0.1496 s/iter. Total: 0.3157 s/iter. ETA=0:01:52\n",
      "\u001b[32m[02/13 11:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 144/485. Dataloading: 0.0009 s/iter. Inference: 0.1651 s/iter. Eval: 0.1525 s/iter. Total: 0.3186 s/iter. ETA=0:01:48\n",
      "\u001b[32m[02/13 11:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 161/485. Dataloading: 0.0009 s/iter. Inference: 0.1643 s/iter. Eval: 0.1516 s/iter. Total: 0.3169 s/iter. ETA=0:01:42\n",
      "\u001b[32m[02/13 11:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 180/485. Dataloading: 0.0010 s/iter. Inference: 0.1639 s/iter. Eval: 0.1476 s/iter. Total: 0.3126 s/iter. ETA=0:01:35\n",
      "\u001b[32m[02/13 11:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 196/485. Dataloading: 0.0010 s/iter. Inference: 0.1636 s/iter. Eval: 0.1488 s/iter. Total: 0.3135 s/iter. ETA=0:01:30\n",
      "\u001b[32m[02/13 11:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 212/485. Dataloading: 0.0010 s/iter. Inference: 0.1639 s/iter. Eval: 0.1508 s/iter. Total: 0.3157 s/iter. ETA=0:01:26\n",
      "\u001b[32m[02/13 11:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 228/485. Dataloading: 0.0010 s/iter. Inference: 0.1636 s/iter. Eval: 0.1515 s/iter. Total: 0.3161 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 11:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 245/485. Dataloading: 0.0010 s/iter. Inference: 0.1631 s/iter. Eval: 0.1516 s/iter. Total: 0.3157 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 11:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 257/485. Dataloading: 0.0010 s/iter. Inference: 0.1641 s/iter. Eval: 0.1568 s/iter. Total: 0.3219 s/iter. ETA=0:01:13\n",
      "\u001b[32m[02/13 11:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 274/485. Dataloading: 0.0010 s/iter. Inference: 0.1637 s/iter. Eval: 0.1556 s/iter. Total: 0.3203 s/iter. ETA=0:01:07\n",
      "\u001b[32m[02/13 11:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 290/485. Dataloading: 0.0010 s/iter. Inference: 0.1637 s/iter. Eval: 0.1555 s/iter. Total: 0.3203 s/iter. ETA=0:01:02\n",
      "\u001b[32m[02/13 11:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 309/485. Dataloading: 0.0010 s/iter. Inference: 0.1634 s/iter. Eval: 0.1536 s/iter. Total: 0.3180 s/iter. ETA=0:00:55\n",
      "\u001b[32m[02/13 11:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 323/485. Dataloading: 0.0010 s/iter. Inference: 0.1636 s/iter. Eval: 0.1556 s/iter. Total: 0.3202 s/iter. ETA=0:00:51\n",
      "\u001b[32m[02/13 11:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 337/485. Dataloading: 0.0010 s/iter. Inference: 0.1639 s/iter. Eval: 0.1572 s/iter. Total: 0.3221 s/iter. ETA=0:00:47\n",
      "\u001b[32m[02/13 11:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 354/485. Dataloading: 0.0010 s/iter. Inference: 0.1635 s/iter. Eval: 0.1564 s/iter. Total: 0.3210 s/iter. ETA=0:00:42\n",
      "\u001b[32m[02/13 11:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 371/485. Dataloading: 0.0010 s/iter. Inference: 0.1635 s/iter. Eval: 0.1558 s/iter. Total: 0.3203 s/iter. ETA=0:00:36\n",
      "\u001b[32m[02/13 11:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 391/485. Dataloading: 0.0010 s/iter. Inference: 0.1630 s/iter. Eval: 0.1528 s/iter. Total: 0.3169 s/iter. ETA=0:00:29\n",
      "\u001b[32m[02/13 11:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 408/485. Dataloading: 0.0010 s/iter. Inference: 0.1629 s/iter. Eval: 0.1527 s/iter. Total: 0.3166 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/13 11:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 420/485. Dataloading: 0.0010 s/iter. Inference: 0.1633 s/iter. Eval: 0.1555 s/iter. Total: 0.3199 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/13 11:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 437/485. Dataloading: 0.0010 s/iter. Inference: 0.1632 s/iter. Eval: 0.1550 s/iter. Total: 0.3192 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 11:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 453/485. Dataloading: 0.0010 s/iter. Inference: 0.1635 s/iter. Eval: 0.1546 s/iter. Total: 0.3192 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/13 11:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 472/485. Dataloading: 0.0010 s/iter. Inference: 0.1630 s/iter. Eval: 0.1531 s/iter. Total: 0.3172 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 11:29:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:31.723051 (0.316090 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:29:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:18 (0.162946 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:29:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:29:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30195839127371776\n",
      "\u001b[32m[02/13 11:30:00 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 739  total_loss: 1.374  loss_cls: 0.3684  loss_box_reg: 0.5439  loss_mask: 0.2928  loss_rpn_cls: 0.05812  loss_rpn_loc: 0.1164  time: 0.9294  data_time: 0.1841  lr: 0.00011829  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:30:14 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 759  total_loss: 1.329  loss_cls: 0.3411  loss_box_reg: 0.5494  loss_mask: 0.2831  loss_rpn_cls: 0.03439  loss_rpn_loc: 0.1106  time: 0.9233  data_time: 0.0184  lr: 0.00012149  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:30:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:30:38 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 779  total_loss: 1.388  loss_cls: 0.3626  loss_box_reg: 0.5692  loss_mask: 0.2957  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.1222  time: 0.9301  data_time: 0.3500  lr: 0.00012468  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:30:56 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 799  total_loss: 1.323  loss_cls: 0.3298  loss_box_reg: 0.5482  loss_mask: 0.2791  loss_rpn_cls: 0.03659  loss_rpn_loc: 0.1127  time: 0.9300  data_time: 0.1912  lr: 0.00012788  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:31:14 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 819  total_loss: 1.379  loss_cls: 0.3634  loss_box_reg: 0.5762  loss_mask: 0.3093  loss_rpn_cls: 0.0387  loss_rpn_loc: 0.1193  time: 0.9296  data_time: 0.1826  lr: 0.00013108  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:31:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:31:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:31:36 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 839  total_loss: 1.338  loss_cls: 0.3314  loss_box_reg: 0.5436  loss_mask: 0.2886  loss_rpn_cls: 0.03522  loss_rpn_loc: 0.108  time: 0.9332  data_time: 0.1565  lr: 0.00013427  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:31:42 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:31:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:31:43 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:31:43 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:31:43 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:31:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0007 s/iter. Inference: 0.1677 s/iter. Eval: 0.2273 s/iter. Total: 0.3958 s/iter. ETA=0:03:07\n",
      "\u001b[32m[02/13 11:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1652 s/iter. Eval: 0.1744 s/iter. Total: 0.3405 s/iter. ETA=0:02:35\n",
      "\u001b[32m[02/13 11:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1694 s/iter. Eval: 0.1588 s/iter. Total: 0.3293 s/iter. ETA=0:02:24\n",
      "\u001b[32m[02/13 11:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0010 s/iter. Inference: 0.1688 s/iter. Eval: 0.1597 s/iter. Total: 0.3295 s/iter. ETA=0:02:19\n",
      "\u001b[32m[02/13 11:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0010 s/iter. Inference: 0.1651 s/iter. Eval: 0.1477 s/iter. Total: 0.3138 s/iter. ETA=0:02:07\n",
      "\u001b[32m[02/13 11:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 98/485. Dataloading: 0.0010 s/iter. Inference: 0.1654 s/iter. Eval: 0.1412 s/iter. Total: 0.3077 s/iter. ETA=0:01:59\n",
      "\u001b[32m[02/13 11:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0010 s/iter. Inference: 0.1674 s/iter. Eval: 0.1490 s/iter. Total: 0.3175 s/iter. ETA=0:01:58\n",
      "\u001b[32m[02/13 11:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0010 s/iter. Inference: 0.1659 s/iter. Eval: 0.1475 s/iter. Total: 0.3144 s/iter. ETA=0:01:51\n",
      "\u001b[32m[02/13 11:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 144/485. Dataloading: 0.0010 s/iter. Inference: 0.1657 s/iter. Eval: 0.1508 s/iter. Total: 0.3175 s/iter. ETA=0:01:48\n",
      "\u001b[32m[02/13 11:32:35 d2.evaluation.evaluator]: \u001b[0mInference done 160/485. Dataloading: 0.0010 s/iter. Inference: 0.1660 s/iter. Eval: 0.1512 s/iter. Total: 0.3182 s/iter. ETA=0:01:43\n",
      "\u001b[32m[02/13 11:32:40 d2.evaluation.evaluator]: \u001b[0mInference done 180/485. Dataloading: 0.0010 s/iter. Inference: 0.1655 s/iter. Eval: 0.1456 s/iter. Total: 0.3121 s/iter. ETA=0:01:35\n",
      "\u001b[32m[02/13 11:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 195/485. Dataloading: 0.0010 s/iter. Inference: 0.1655 s/iter. Eval: 0.1477 s/iter. Total: 0.3142 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 11:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 211/485. Dataloading: 0.0010 s/iter. Inference: 0.1656 s/iter. Eval: 0.1480 s/iter. Total: 0.3146 s/iter. ETA=0:01:26\n",
      "\u001b[32m[02/13 11:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 227/485. Dataloading: 0.0010 s/iter. Inference: 0.1656 s/iter. Eval: 0.1493 s/iter. Total: 0.3159 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 11:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 244/485. Dataloading: 0.0010 s/iter. Inference: 0.1652 s/iter. Eval: 0.1489 s/iter. Total: 0.3151 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 11:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 256/485. Dataloading: 0.0010 s/iter. Inference: 0.1662 s/iter. Eval: 0.1545 s/iter. Total: 0.3217 s/iter. ETA=0:01:13\n",
      "\u001b[32m[02/13 11:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 272/485. Dataloading: 0.0010 s/iter. Inference: 0.1659 s/iter. Eval: 0.1544 s/iter. Total: 0.3214 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 11:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 286/485. Dataloading: 0.0010 s/iter. Inference: 0.1666 s/iter. Eval: 0.1566 s/iter. Total: 0.3243 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 11:33:22 d2.evaluation.evaluator]: \u001b[0mInference done 306/485. Dataloading: 0.0010 s/iter. Inference: 0.1661 s/iter. Eval: 0.1535 s/iter. Total: 0.3207 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 11:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 321/485. Dataloading: 0.0010 s/iter. Inference: 0.1667 s/iter. Eval: 0.1551 s/iter. Total: 0.3228 s/iter. ETA=0:00:52\n",
      "\u001b[32m[02/13 11:33:33 d2.evaluation.evaluator]: \u001b[0mInference done 334/485. Dataloading: 0.0010 s/iter. Inference: 0.1669 s/iter. Eval: 0.1577 s/iter. Total: 0.3256 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 11:33:38 d2.evaluation.evaluator]: \u001b[0mInference done 352/485. Dataloading: 0.0010 s/iter. Inference: 0.1666 s/iter. Eval: 0.1565 s/iter. Total: 0.3242 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 11:33:43 d2.evaluation.evaluator]: \u001b[0mInference done 369/485. Dataloading: 0.0010 s/iter. Inference: 0.1661 s/iter. Eval: 0.1557 s/iter. Total: 0.3228 s/iter. ETA=0:00:37\n",
      "\u001b[32m[02/13 11:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 390/485. Dataloading: 0.0010 s/iter. Inference: 0.1656 s/iter. Eval: 0.1524 s/iter. Total: 0.3190 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/13 11:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 408/485. Dataloading: 0.0010 s/iter. Inference: 0.1654 s/iter. Eval: 0.1521 s/iter. Total: 0.3185 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/13 11:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 420/485. Dataloading: 0.0010 s/iter. Inference: 0.1658 s/iter. Eval: 0.1548 s/iter. Total: 0.3217 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/13 11:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 437/485. Dataloading: 0.0010 s/iter. Inference: 0.1656 s/iter. Eval: 0.1541 s/iter. Total: 0.3208 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 11:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 453/485. Dataloading: 0.0010 s/iter. Inference: 0.1659 s/iter. Eval: 0.1537 s/iter. Total: 0.3207 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/13 11:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 472/485. Dataloading: 0.0010 s/iter. Inference: 0.1654 s/iter. Eval: 0.1520 s/iter. Total: 0.3185 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 11:34:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:32.348984 (0.317394 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:34:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:19 (0.165364 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:34:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:34:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29840406166473016\n",
      "\u001b[32m[02/13 11:34:31 d2.utils.events]: \u001b[0m eta: 0:26:17  iter: 859  total_loss: 1.387  loss_cls: 0.3624  loss_box_reg: 0.5665  loss_mask: 0.3087  loss_rpn_cls: 0.04715  loss_rpn_loc: 0.11  time: 0.9327  data_time: 0.1711  lr: 0.00013747  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:34:52 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 879  total_loss: 1.408  loss_cls: 0.3566  loss_box_reg: 0.5669  loss_mask: 0.3131  loss_rpn_cls: 0.04272  loss_rpn_loc: 0.1131  time: 0.9364  data_time: 0.3513  lr: 0.00014066  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:34:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:35:11 d2.utils.events]: \u001b[0m eta: 0:25:54  iter: 899  total_loss: 1.303  loss_cls: 0.332  loss_box_reg: 0.5262  loss_mask: 0.2868  loss_rpn_cls: 0.04205  loss_rpn_loc: 0.1157  time: 0.9360  data_time: 0.1301  lr: 0.00014386  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:35:28 d2.utils.events]: \u001b[0m eta: 0:25:37  iter: 919  total_loss: 1.413  loss_cls: 0.3781  loss_box_reg: 0.5817  loss_mask: 0.3139  loss_rpn_cls: 0.04762  loss_rpn_loc: 0.1037  time: 0.9346  data_time: 0.1577  lr: 0.00014706  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:35:46 d2.utils.events]: \u001b[0m eta: 0:25:25  iter: 939  total_loss: 1.368  loss_cls: 0.3697  loss_box_reg: 0.5746  loss_mask: 0.2921  loss_rpn_cls: 0.03711  loss_rpn_loc: 0.1268  time: 0.9329  data_time: 0.1323  lr: 0.00015025  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:36:05 d2.utils.events]: \u001b[0m eta: 0:25:10  iter: 959  total_loss: 1.344  loss_cls: 0.3412  loss_box_reg: 0.5567  loss_mask: 0.3019  loss_rpn_cls: 0.04547  loss_rpn_loc: 0.1091  time: 0.9339  data_time: 0.2418  lr: 0.00015345  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:36:13 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:36:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:36:14 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:36:14 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:36:14 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:36:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1708 s/iter. Eval: 0.2254 s/iter. Total: 0.3970 s/iter. ETA=0:03:08\n",
      "\u001b[32m[02/13 11:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1654 s/iter. Eval: 0.1747 s/iter. Total: 0.3411 s/iter. ETA=0:02:35\n",
      "\u001b[32m[02/13 11:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1678 s/iter. Eval: 0.1571 s/iter. Total: 0.3259 s/iter. ETA=0:02:23\n",
      "\u001b[32m[02/13 11:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1677 s/iter. Eval: 0.1588 s/iter. Total: 0.3275 s/iter. ETA=0:02:18\n",
      "\u001b[32m[02/13 11:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 79/485. Dataloading: 0.0009 s/iter. Inference: 0.1659 s/iter. Eval: 0.1501 s/iter. Total: 0.3170 s/iter. ETA=0:02:08\n",
      "\u001b[32m[02/13 11:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 97/485. Dataloading: 0.0009 s/iter. Inference: 0.1665 s/iter. Eval: 0.1436 s/iter. Total: 0.3110 s/iter. ETA=0:02:00\n",
      "\u001b[32m[02/13 11:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0009 s/iter. Inference: 0.1672 s/iter. Eval: 0.1490 s/iter. Total: 0.3172 s/iter. ETA=0:01:58\n",
      "\u001b[32m[02/13 11:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0009 s/iter. Inference: 0.1656 s/iter. Eval: 0.1479 s/iter. Total: 0.3145 s/iter. ETA=0:01:51\n",
      "\u001b[32m[02/13 11:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 145/485. Dataloading: 0.0009 s/iter. Inference: 0.1654 s/iter. Eval: 0.1526 s/iter. Total: 0.3190 s/iter. ETA=0:01:48\n",
      "\u001b[32m[02/13 11:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 164/485. Dataloading: 0.0010 s/iter. Inference: 0.1646 s/iter. Eval: 0.1483 s/iter. Total: 0.3139 s/iter. ETA=0:01:40\n",
      "\u001b[32m[02/13 11:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0010 s/iter. Inference: 0.1642 s/iter. Eval: 0.1437 s/iter. Total: 0.3089 s/iter. ETA=0:01:32\n",
      "\u001b[32m[02/13 11:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 198/485. Dataloading: 0.0010 s/iter. Inference: 0.1641 s/iter. Eval: 0.1477 s/iter. Total: 0.3128 s/iter. ETA=0:01:29\n",
      "\u001b[32m[02/13 11:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0010 s/iter. Inference: 0.1637 s/iter. Eval: 0.1467 s/iter. Total: 0.3114 s/iter. ETA=0:01:23\n",
      "\u001b[32m[02/13 11:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 233/485. Dataloading: 0.0010 s/iter. Inference: 0.1639 s/iter. Eval: 0.1469 s/iter. Total: 0.3118 s/iter. ETA=0:01:18\n",
      "\u001b[32m[02/13 11:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 246/485. Dataloading: 0.0010 s/iter. Inference: 0.1646 s/iter. Eval: 0.1525 s/iter. Total: 0.3181 s/iter. ETA=0:01:16\n",
      "\u001b[32m[02/13 11:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 260/485. Dataloading: 0.0010 s/iter. Inference: 0.1652 s/iter. Eval: 0.1548 s/iter. Total: 0.3211 s/iter. ETA=0:01:12\n",
      "\u001b[32m[02/13 11:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 276/485. Dataloading: 0.0010 s/iter. Inference: 0.1652 s/iter. Eval: 0.1551 s/iter. Total: 0.3213 s/iter. ETA=0:01:07\n",
      "\u001b[32m[02/13 11:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 295/485. Dataloading: 0.0010 s/iter. Inference: 0.1645 s/iter. Eval: 0.1525 s/iter. Total: 0.3181 s/iter. ETA=0:01:00\n",
      "\u001b[32m[02/13 11:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 310/485. Dataloading: 0.0010 s/iter. Inference: 0.1649 s/iter. Eval: 0.1538 s/iter. Total: 0.3197 s/iter. ETA=0:00:55\n",
      "\u001b[32m[02/13 11:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 324/485. Dataloading: 0.0010 s/iter. Inference: 0.1653 s/iter. Eval: 0.1561 s/iter. Total: 0.3225 s/iter. ETA=0:00:51\n",
      "\u001b[32m[02/13 11:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 339/485. Dataloading: 0.0010 s/iter. Inference: 0.1656 s/iter. Eval: 0.1578 s/iter. Total: 0.3244 s/iter. ETA=0:00:47\n",
      "\u001b[32m[02/13 11:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 358/485. Dataloading: 0.0010 s/iter. Inference: 0.1649 s/iter. Eval: 0.1553 s/iter. Total: 0.3212 s/iter. ETA=0:00:40\n",
      "\u001b[32m[02/13 11:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 374/485. Dataloading: 0.0010 s/iter. Inference: 0.1648 s/iter. Eval: 0.1557 s/iter. Total: 0.3215 s/iter. ETA=0:00:35\n",
      "\u001b[32m[02/13 11:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 393/485. Dataloading: 0.0010 s/iter. Inference: 0.1645 s/iter. Eval: 0.1535 s/iter. Total: 0.3190 s/iter. ETA=0:00:29\n",
      "\u001b[32m[02/13 11:38:26 d2.evaluation.evaluator]: \u001b[0mInference done 411/485. Dataloading: 0.0010 s/iter. Inference: 0.1640 s/iter. Eval: 0.1526 s/iter. Total: 0.3176 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 11:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 425/485. Dataloading: 0.0010 s/iter. Inference: 0.1641 s/iter. Eval: 0.1542 s/iter. Total: 0.3193 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/13 11:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 441/485. Dataloading: 0.0010 s/iter. Inference: 0.1642 s/iter. Eval: 0.1546 s/iter. Total: 0.3198 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 11:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 459/485. Dataloading: 0.0010 s/iter. Inference: 0.1644 s/iter. Eval: 0.1530 s/iter. Total: 0.3184 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/13 11:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 479/485. Dataloading: 0.0010 s/iter. Inference: 0.1641 s/iter. Eval: 0.1511 s/iter. Total: 0.3162 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/13 11:38:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:31.820544 (0.316293 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:38:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:18 (0.164105 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:38:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:38:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3023473607163784\n",
      "\u001b[32m[02/13 11:39:00 d2.utils.events]: \u001b[0m eta: 0:24:56  iter: 979  total_loss: 1.411  loss_cls: 0.3851  loss_box_reg: 0.5564  loss_mask: 0.3001  loss_rpn_cls: 0.05025  loss_rpn_loc: 0.1326  time: 0.9345  data_time: 0.2185  lr: 0.00015664  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:39:16 d2.utils.events]: \u001b[0m eta: 0:24:40  iter: 999  total_loss: 1.287  loss_cls: 0.3113  loss_box_reg: 0.5308  loss_mask: 0.2903  loss_rpn_cls: 0.04171  loss_rpn_loc: 0.08825  time: 0.9312  data_time: 0.0599  lr: 0.00015984  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:39:36 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 1019  total_loss: 1.442  loss_cls: 0.4021  loss_box_reg: 0.5892  loss_mask: 0.3078  loss_rpn_cls: 0.05126  loss_rpn_loc: 0.1342  time: 0.9325  data_time: 0.2495  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:39:54 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 1039  total_loss: 1.325  loss_cls: 0.3567  loss_box_reg: 0.5473  loss_mask: 0.2846  loss_rpn_cls: 0.03446  loss_rpn_loc: 0.08353  time: 0.9320  data_time: 0.1780  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:40:15 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 1059  total_loss: 1.409  loss_cls: 0.3653  loss_box_reg: 0.5788  loss_mask: 0.3102  loss_rpn_cls: 0.04734  loss_rpn_loc: 0.1096  time: 0.9343  data_time: 0.2958  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:40:32 d2.utils.events]: \u001b[0m eta: 0:23:46  iter: 1079  total_loss: 1.397  loss_cls: 0.3769  loss_box_reg: 0.5573  loss_mask: 0.2961  loss_rpn_cls: 0.05712  loss_rpn_loc: 0.1158  time: 0.9329  data_time: 0.1217  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:40:43 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:40:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:40:43 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:40:44 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:40:44 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:40:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1798 s/iter. Eval: 0.2484 s/iter. Total: 0.4290 s/iter. ETA=0:03:23\n",
      "\u001b[32m[02/13 11:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 27/485. Dataloading: 0.0009 s/iter. Inference: 0.1741 s/iter. Eval: 0.1785 s/iter. Total: 0.3536 s/iter. ETA=0:02:41\n",
      "\u001b[32m[02/13 11:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 43/485. Dataloading: 0.0010 s/iter. Inference: 0.1773 s/iter. Eval: 0.1627 s/iter. Total: 0.3411 s/iter. ETA=0:02:30\n",
      "\u001b[32m[02/13 11:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 58/485. Dataloading: 0.0010 s/iter. Inference: 0.1739 s/iter. Eval: 0.1654 s/iter. Total: 0.3403 s/iter. ETA=0:02:25\n",
      "\u001b[32m[02/13 11:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 74/485. Dataloading: 0.0010 s/iter. Inference: 0.1739 s/iter. Eval: 0.1672 s/iter. Total: 0.3421 s/iter. ETA=0:02:20\n",
      "\u001b[32m[02/13 11:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 94/485. Dataloading: 0.0010 s/iter. Inference: 0.1724 s/iter. Eval: 0.1505 s/iter. Total: 0.3239 s/iter. ETA=0:02:06\n",
      "\u001b[32m[02/13 11:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 108/485. Dataloading: 0.0010 s/iter. Inference: 0.1753 s/iter. Eval: 0.1604 s/iter. Total: 0.3367 s/iter. ETA=0:02:06\n",
      "\u001b[32m[02/13 11:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 125/485. Dataloading: 0.0010 s/iter. Inference: 0.1735 s/iter. Eval: 0.1564 s/iter. Total: 0.3310 s/iter. ETA=0:01:59\n",
      "\u001b[32m[02/13 11:41:31 d2.evaluation.evaluator]: \u001b[0mInference done 138/485. Dataloading: 0.0010 s/iter. Inference: 0.1734 s/iter. Eval: 0.1625 s/iter. Total: 0.3370 s/iter. ETA=0:01:56\n",
      "\u001b[32m[02/13 11:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 153/485. Dataloading: 0.0010 s/iter. Inference: 0.1733 s/iter. Eval: 0.1631 s/iter. Total: 0.3375 s/iter. ETA=0:01:52\n",
      "\u001b[32m[02/13 11:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 175/485. Dataloading: 0.0010 s/iter. Inference: 0.1714 s/iter. Eval: 0.1515 s/iter. Total: 0.3239 s/iter. ETA=0:01:40\n",
      "\u001b[32m[02/13 11:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 189/485. Dataloading: 0.0010 s/iter. Inference: 0.1717 s/iter. Eval: 0.1542 s/iter. Total: 0.3270 s/iter. ETA=0:01:36\n",
      "\u001b[32m[02/13 11:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 204/485. Dataloading: 0.0010 s/iter. Inference: 0.1721 s/iter. Eval: 0.1571 s/iter. Total: 0.3302 s/iter. ETA=0:01:32\n",
      "\u001b[32m[02/13 11:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 221/485. Dataloading: 0.0010 s/iter. Inference: 0.1720 s/iter. Eval: 0.1554 s/iter. Total: 0.3284 s/iter. ETA=0:01:26\n",
      "\u001b[32m[02/13 11:42:03 d2.evaluation.evaluator]: \u001b[0mInference done 237/485. Dataloading: 0.0010 s/iter. Inference: 0.1717 s/iter. Eval: 0.1554 s/iter. Total: 0.3282 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 11:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0010 s/iter. Inference: 0.1726 s/iter. Eval: 0.1620 s/iter. Total: 0.3356 s/iter. ETA=0:01:19\n",
      "\u001b[32m[02/13 11:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 262/485. Dataloading: 0.0010 s/iter. Inference: 0.1732 s/iter. Eval: 0.1621 s/iter. Total: 0.3364 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 11:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 277/485. Dataloading: 0.0010 s/iter. Inference: 0.1734 s/iter. Eval: 0.1641 s/iter. Total: 0.3386 s/iter. ETA=0:01:10\n",
      "\u001b[32m[02/13 11:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 298/485. Dataloading: 0.0010 s/iter. Inference: 0.1720 s/iter. Eval: 0.1590 s/iter. Total: 0.3320 s/iter. ETA=0:01:02\n",
      "\u001b[32m[02/13 11:42:29 d2.evaluation.evaluator]: \u001b[0mInference done 313/485. Dataloading: 0.0010 s/iter. Inference: 0.1723 s/iter. Eval: 0.1598 s/iter. Total: 0.3332 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 11:42:34 d2.evaluation.evaluator]: \u001b[0mInference done 326/485. Dataloading: 0.0010 s/iter. Inference: 0.1724 s/iter. Eval: 0.1621 s/iter. Total: 0.3355 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 11:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 339/485. Dataloading: 0.0010 s/iter. Inference: 0.1730 s/iter. Eval: 0.1648 s/iter. Total: 0.3388 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 11:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 357/485. Dataloading: 0.0010 s/iter. Inference: 0.1727 s/iter. Eval: 0.1627 s/iter. Total: 0.3364 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 11:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 372/485. Dataloading: 0.0010 s/iter. Inference: 0.1726 s/iter. Eval: 0.1631 s/iter. Total: 0.3367 s/iter. ETA=0:00:38\n",
      "\u001b[32m[02/13 11:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 393/485. Dataloading: 0.0010 s/iter. Inference: 0.1721 s/iter. Eval: 0.1598 s/iter. Total: 0.3329 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/13 11:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 411/485. Dataloading: 0.0010 s/iter. Inference: 0.1719 s/iter. Eval: 0.1591 s/iter. Total: 0.3320 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/13 11:43:07 d2.evaluation.evaluator]: \u001b[0mInference done 425/485. Dataloading: 0.0010 s/iter. Inference: 0.1722 s/iter. Eval: 0.1610 s/iter. Total: 0.3342 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/13 11:43:12 d2.evaluation.evaluator]: \u001b[0mInference done 441/485. Dataloading: 0.0010 s/iter. Inference: 0.1721 s/iter. Eval: 0.1611 s/iter. Total: 0.3343 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 11:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 459/485. Dataloading: 0.0010 s/iter. Inference: 0.1720 s/iter. Eval: 0.1593 s/iter. Total: 0.3324 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/13 11:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 478/485. Dataloading: 0.0010 s/iter. Inference: 0.1715 s/iter. Eval: 0.1574 s/iter. Total: 0.3300 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/13 11:43:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:38.421382 (0.330045 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:43:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:22 (0.171543 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:43:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:43:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2928145839090858\n",
      "\u001b[32m[02/13 11:43:36 d2.utils.events]: \u001b[0m eta: 0:23:32  iter: 1099  total_loss: 1.455  loss_cls: 0.3822  loss_box_reg: 0.5835  loss_mask: 0.3033  loss_rpn_cls: 0.05543  loss_rpn_loc: 0.1412  time: 0.9348  data_time: 0.2554  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:43:51 d2.utils.events]: \u001b[0m eta: 0:23:16  iter: 1119  total_loss: 1.255  loss_cls: 0.3155  loss_box_reg: 0.5385  loss_mask: 0.2854  loss_rpn_cls: 0.02654  loss_rpn_loc: 0.09654  time: 0.9313  data_time: 0.0481  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:44:08 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 1139  total_loss: 1.377  loss_cls: 0.3641  loss_box_reg: 0.5569  loss_mask: 0.2992  loss_rpn_cls: 0.03173  loss_rpn_loc: 0.1207  time: 0.9299  data_time: 0.1213  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:44:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:44:29 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 1159  total_loss: 1.419  loss_cls: 0.3639  loss_box_reg: 0.5436  loss_mask: 0.3013  loss_rpn_cls: 0.05405  loss_rpn_loc: 0.1107  time: 0.9325  data_time: 0.2489  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:44:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:44:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:44:56 d2.utils.events]: \u001b[0m eta: 0:22:33  iter: 1179  total_loss: 1.503  loss_cls: 0.4001  loss_box_reg: 0.5789  loss_mask: 0.3117  loss_rpn_cls: 0.0567  loss_rpn_loc: 0.1309  time: 0.9389  data_time: 0.3826  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:45:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:45:15 d2.utils.events]: \u001b[0m eta: 0:22:18  iter: 1199  total_loss: 1.258  loss_cls: 0.3197  loss_box_reg: 0.5382  loss_mask: 0.2883  loss_rpn_cls: 0.0268  loss_rpn_loc: 0.09707  time: 0.9394  data_time: 0.1539  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:45:23 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:45:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:45:24 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:45:24 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:45:24 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:45:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1702 s/iter. Eval: 0.2241 s/iter. Total: 0.3951 s/iter. ETA=0:03:07\n",
      "\u001b[32m[02/13 11:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1669 s/iter. Eval: 0.1792 s/iter. Total: 0.3472 s/iter. ETA=0:02:38\n",
      "\u001b[32m[02/13 11:45:40 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0010 s/iter. Inference: 0.1689 s/iter. Eval: 0.1612 s/iter. Total: 0.3311 s/iter. ETA=0:02:25\n",
      "\u001b[32m[02/13 11:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 60/485. Dataloading: 0.0010 s/iter. Inference: 0.1696 s/iter. Eval: 0.1625 s/iter. Total: 0.3331 s/iter. ETA=0:02:21\n",
      "\u001b[32m[02/13 11:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 77/485. Dataloading: 0.0010 s/iter. Inference: 0.1679 s/iter. Eval: 0.1559 s/iter. Total: 0.3247 s/iter. ETA=0:02:12\n",
      "\u001b[32m[02/13 11:45:56 d2.evaluation.evaluator]: \u001b[0mInference done 97/485. Dataloading: 0.0010 s/iter. Inference: 0.1675 s/iter. Eval: 0.1462 s/iter. Total: 0.3148 s/iter. ETA=0:02:02\n",
      "\u001b[32m[02/13 11:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 111/485. Dataloading: 0.0010 s/iter. Inference: 0.1690 s/iter. Eval: 0.1505 s/iter. Total: 0.3205 s/iter. ETA=0:01:59\n",
      "\u001b[32m[02/13 11:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 127/485. Dataloading: 0.0010 s/iter. Inference: 0.1686 s/iter. Eval: 0.1519 s/iter. Total: 0.3216 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 11:46:11 d2.evaluation.evaluator]: \u001b[0mInference done 142/485. Dataloading: 0.0010 s/iter. Inference: 0.1686 s/iter. Eval: 0.1563 s/iter. Total: 0.3259 s/iter. ETA=0:01:51\n",
      "\u001b[32m[02/13 11:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 158/485. Dataloading: 0.0010 s/iter. Inference: 0.1677 s/iter. Eval: 0.1562 s/iter. Total: 0.3249 s/iter. ETA=0:01:46\n",
      "\u001b[32m[02/13 11:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 180/485. Dataloading: 0.0010 s/iter. Inference: 0.1662 s/iter. Eval: 0.1486 s/iter. Total: 0.3159 s/iter. ETA=0:01:36\n",
      "\u001b[32m[02/13 11:46:27 d2.evaluation.evaluator]: \u001b[0mInference done 195/485. Dataloading: 0.0010 s/iter. Inference: 0.1661 s/iter. Eval: 0.1502 s/iter. Total: 0.3174 s/iter. ETA=0:01:32\n",
      "\u001b[32m[02/13 11:46:32 d2.evaluation.evaluator]: \u001b[0mInference done 211/485. Dataloading: 0.0010 s/iter. Inference: 0.1663 s/iter. Eval: 0.1503 s/iter. Total: 0.3177 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 11:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 227/485. Dataloading: 0.0010 s/iter. Inference: 0.1663 s/iter. Eval: 0.1518 s/iter. Total: 0.3191 s/iter. ETA=0:01:22\n",
      "\u001b[32m[02/13 11:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 244/485. Dataloading: 0.0010 s/iter. Inference: 0.1656 s/iter. Eval: 0.1508 s/iter. Total: 0.3175 s/iter. ETA=0:01:16\n",
      "\u001b[32m[02/13 11:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 256/485. Dataloading: 0.0010 s/iter. Inference: 0.1667 s/iter. Eval: 0.1559 s/iter. Total: 0.3236 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 11:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 271/485. Dataloading: 0.0010 s/iter. Inference: 0.1669 s/iter. Eval: 0.1563 s/iter. Total: 0.3242 s/iter. ETA=0:01:09\n",
      "\u001b[32m[02/13 11:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 286/485. Dataloading: 0.0010 s/iter. Inference: 0.1673 s/iter. Eval: 0.1577 s/iter. Total: 0.3261 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 11:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 306/485. Dataloading: 0.0010 s/iter. Inference: 0.1668 s/iter. Eval: 0.1544 s/iter. Total: 0.3222 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 11:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 321/485. Dataloading: 0.0010 s/iter. Inference: 0.1672 s/iter. Eval: 0.1558 s/iter. Total: 0.3241 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 11:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 334/485. Dataloading: 0.0010 s/iter. Inference: 0.1674 s/iter. Eval: 0.1582 s/iter. Total: 0.3267 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 11:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 352/485. Dataloading: 0.0010 s/iter. Inference: 0.1670 s/iter. Eval: 0.1570 s/iter. Total: 0.3250 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 11:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 369/485. Dataloading: 0.0010 s/iter. Inference: 0.1666 s/iter. Eval: 0.1563 s/iter. Total: 0.3240 s/iter. ETA=0:00:37\n",
      "\u001b[32m[02/13 11:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 390/485. Dataloading: 0.0010 s/iter. Inference: 0.1659 s/iter. Eval: 0.1530 s/iter. Total: 0.3200 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/13 11:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 408/485. Dataloading: 0.0010 s/iter. Inference: 0.1656 s/iter. Eval: 0.1525 s/iter. Total: 0.3192 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/13 11:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 420/485. Dataloading: 0.0010 s/iter. Inference: 0.1660 s/iter. Eval: 0.1551 s/iter. Total: 0.3221 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/13 11:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 437/485. Dataloading: 0.0010 s/iter. Inference: 0.1658 s/iter. Eval: 0.1544 s/iter. Total: 0.3213 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 11:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 454/485. Dataloading: 0.0010 s/iter. Inference: 0.1657 s/iter. Eval: 0.1537 s/iter. Total: 0.3205 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 11:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 473/485. Dataloading: 0.0010 s/iter. Inference: 0.1652 s/iter. Eval: 0.1522 s/iter. Total: 0.3184 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 11:47:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:32.240374 (0.317167 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:47:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:19 (0.164971 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:47:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:47:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3021667683293261\n",
      "\u001b[32m[02/13 11:48:09 d2.utils.events]: \u001b[0m eta: 0:22:03  iter: 1219  total_loss: 1.294  loss_cls: 0.3296  loss_box_reg: 0.5378  loss_mask: 0.2964  loss_rpn_cls: 0.02478  loss_rpn_loc: 0.09903  time: 0.9382  data_time: 0.1495  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:48:26 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 1239  total_loss: 1.326  loss_cls: 0.355  loss_box_reg: 0.5394  loss_mask: 0.2752  loss_rpn_cls: 0.04697  loss_rpn_loc: 0.1195  time: 0.9374  data_time: 0.1487  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:48:44 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 1259  total_loss: 1.32  loss_cls: 0.3374  loss_box_reg: 0.5471  loss_mask: 0.3066  loss_rpn_cls: 0.03392  loss_rpn_loc: 0.0979  time: 0.9361  data_time: 0.1392  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:49:05 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 1279  total_loss: 1.37  loss_cls: 0.3535  loss_box_reg: 0.5497  loss_mask: 0.2996  loss_rpn_cls: 0.03747  loss_rpn_loc: 0.1215  time: 0.9379  data_time: 0.2826  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:49:24 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 1299  total_loss: 1.393  loss_cls: 0.3608  loss_box_reg: 0.5534  loss_mask: 0.3075  loss_rpn_cls: 0.04579  loss_rpn_loc: 0.109  time: 0.9381  data_time: 0.2208  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:49:43 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 1319  total_loss: 1.319  loss_cls: 0.3489  loss_box_reg: 0.5518  loss_mask: 0.2943  loss_rpn_cls: 0.04087  loss_rpn_loc: 0.1138  time: 0.9380  data_time: 0.1835  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:49:54 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:49:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:49:55 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:49:55 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:49:55 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:49:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1774 s/iter. Eval: 0.2378 s/iter. Total: 0.4160 s/iter. ETA=0:03:17\n",
      "\u001b[32m[02/13 11:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 27/485. Dataloading: 0.0009 s/iter. Inference: 0.1701 s/iter. Eval: 0.1711 s/iter. Total: 0.3422 s/iter. ETA=0:02:36\n",
      "\u001b[32m[02/13 11:50:10 d2.evaluation.evaluator]: \u001b[0mInference done 43/485. Dataloading: 0.0010 s/iter. Inference: 0.1748 s/iter. Eval: 0.1568 s/iter. Total: 0.3327 s/iter. ETA=0:02:27\n",
      "\u001b[32m[02/13 11:50:15 d2.evaluation.evaluator]: \u001b[0mInference done 58/485. Dataloading: 0.0010 s/iter. Inference: 0.1728 s/iter. Eval: 0.1600 s/iter. Total: 0.3338 s/iter. ETA=0:02:22\n",
      "\u001b[32m[02/13 11:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 74/485. Dataloading: 0.0010 s/iter. Inference: 0.1701 s/iter. Eval: 0.1611 s/iter. Total: 0.3323 s/iter. ETA=0:02:16\n",
      "\u001b[32m[02/13 11:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 95/485. Dataloading: 0.0010 s/iter. Inference: 0.1676 s/iter. Eval: 0.1446 s/iter. Total: 0.3133 s/iter. ETA=0:02:02\n",
      "\u001b[32m[02/13 11:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 108/485. Dataloading: 0.0010 s/iter. Inference: 0.1699 s/iter. Eval: 0.1549 s/iter. Total: 0.3258 s/iter. ETA=0:02:02\n",
      "\u001b[32m[02/13 11:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 127/485. Dataloading: 0.0010 s/iter. Inference: 0.1675 s/iter. Eval: 0.1518 s/iter. Total: 0.3204 s/iter. ETA=0:01:54\n",
      "\u001b[32m[02/13 11:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 142/485. Dataloading: 0.0010 s/iter. Inference: 0.1670 s/iter. Eval: 0.1557 s/iter. Total: 0.3237 s/iter. ETA=0:01:51\n",
      "\u001b[32m[02/13 11:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 159/485. Dataloading: 0.0010 s/iter. Inference: 0.1657 s/iter. Eval: 0.1540 s/iter. Total: 0.3208 s/iter. ETA=0:01:44\n",
      "\u001b[32m[02/13 11:50:52 d2.evaluation.evaluator]: \u001b[0mInference done 180/485. Dataloading: 0.0010 s/iter. Inference: 0.1644 s/iter. Eval: 0.1471 s/iter. Total: 0.3126 s/iter. ETA=0:01:35\n",
      "\u001b[32m[02/13 11:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 195/485. Dataloading: 0.0010 s/iter. Inference: 0.1648 s/iter. Eval: 0.1492 s/iter. Total: 0.3151 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 11:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 210/485. Dataloading: 0.0010 s/iter. Inference: 0.1655 s/iter. Eval: 0.1505 s/iter. Total: 0.3170 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 11:51:08 d2.evaluation.evaluator]: \u001b[0mInference done 226/485. Dataloading: 0.0010 s/iter. Inference: 0.1657 s/iter. Eval: 0.1510 s/iter. Total: 0.3177 s/iter. ETA=0:01:22\n",
      "\u001b[32m[02/13 11:51:13 d2.evaluation.evaluator]: \u001b[0mInference done 243/485. Dataloading: 0.0010 s/iter. Inference: 0.1657 s/iter. Eval: 0.1502 s/iter. Total: 0.3169 s/iter. ETA=0:01:16\n",
      "\u001b[32m[02/13 11:51:18 d2.evaluation.evaluator]: \u001b[0mInference done 254/485. Dataloading: 0.0010 s/iter. Inference: 0.1666 s/iter. Eval: 0.1558 s/iter. Total: 0.3235 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 11:51:23 d2.evaluation.evaluator]: \u001b[0mInference done 268/485. Dataloading: 0.0010 s/iter. Inference: 0.1665 s/iter. Eval: 0.1578 s/iter. Total: 0.3254 s/iter. ETA=0:01:10\n",
      "\u001b[32m[02/13 11:51:29 d2.evaluation.evaluator]: \u001b[0mInference done 285/485. Dataloading: 0.0010 s/iter. Inference: 0.1667 s/iter. Eval: 0.1579 s/iter. Total: 0.3256 s/iter. ETA=0:01:05\n",
      "\u001b[32m[02/13 11:51:34 d2.evaluation.evaluator]: \u001b[0mInference done 303/485. Dataloading: 0.0010 s/iter. Inference: 0.1661 s/iter. Eval: 0.1558 s/iter. Total: 0.3230 s/iter. ETA=0:00:58\n",
      "\u001b[32m[02/13 11:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 318/485. Dataloading: 0.0010 s/iter. Inference: 0.1664 s/iter. Eval: 0.1562 s/iter. Total: 0.3237 s/iter. ETA=0:00:54\n",
      "\u001b[32m[02/13 11:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 330/485. Dataloading: 0.0010 s/iter. Inference: 0.1670 s/iter. Eval: 0.1603 s/iter. Total: 0.3284 s/iter. ETA=0:00:50\n",
      "\u001b[32m[02/13 11:51:49 d2.evaluation.evaluator]: \u001b[0mInference done 348/485. Dataloading: 0.0010 s/iter. Inference: 0.1668 s/iter. Eval: 0.1580 s/iter. Total: 0.3259 s/iter. ETA=0:00:44\n",
      "\u001b[32m[02/13 11:51:54 d2.evaluation.evaluator]: \u001b[0mInference done 363/485. Dataloading: 0.0010 s/iter. Inference: 0.1668 s/iter. Eval: 0.1585 s/iter. Total: 0.3263 s/iter. ETA=0:00:39\n",
      "\u001b[32m[02/13 11:52:00 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0010 s/iter. Inference: 0.1666 s/iter. Eval: 0.1577 s/iter. Total: 0.3253 s/iter. ETA=0:00:34\n",
      "\u001b[32m[02/13 11:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1664 s/iter. Eval: 0.1567 s/iter. Total: 0.3241 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/13 11:52:10 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1664 s/iter. Eval: 0.1566 s/iter. Total: 0.3240 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 11:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 429/485. Dataloading: 0.0010 s/iter. Inference: 0.1667 s/iter. Eval: 0.1579 s/iter. Total: 0.3257 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/13 11:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 444/485. Dataloading: 0.0010 s/iter. Inference: 0.1670 s/iter. Eval: 0.1588 s/iter. Total: 0.3269 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 11:52:26 d2.evaluation.evaluator]: \u001b[0mInference done 463/485. Dataloading: 0.0010 s/iter. Inference: 0.1669 s/iter. Eval: 0.1564 s/iter. Total: 0.3243 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/13 11:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1664 s/iter. Eval: 0.1546 s/iter. Total: 0.3220 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 11:52:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:34.550148 (0.321979 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:52:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:19 (0.166331 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:52:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:52:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3038336897213612\n",
      "\u001b[32m[02/13 11:52:40 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 1339  total_loss: 1.355  loss_cls: 0.3365  loss_box_reg: 0.5487  loss_mask: 0.2889  loss_rpn_cls: 0.0392  loss_rpn_loc: 0.108  time: 0.9382  data_time: 0.1870  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:52:59 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 1359  total_loss: 1.375  loss_cls: 0.3629  loss_box_reg: 0.5576  loss_mask: 0.2905  loss_rpn_cls: 0.03914  loss_rpn_loc: 0.1118  time: 0.9383  data_time: 0.1761  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:53:19 d2.utils.events]: \u001b[0m eta: 0:20:14  iter: 1379  total_loss: 1.407  loss_cls: 0.3745  loss_box_reg: 0.5855  loss_mask: 0.3161  loss_rpn_cls: 0.05446  loss_rpn_loc: 0.1115  time: 0.9390  data_time: 0.2454  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:53:36 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 1399  total_loss: 1.273  loss_cls: 0.332  loss_box_reg: 0.5104  loss_mask: 0.2752  loss_rpn_cls: 0.03397  loss_rpn_loc: 0.1004  time: 0.9380  data_time: 0.1347  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:53:55 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 1419  total_loss: 1.492  loss_cls: 0.3872  loss_box_reg: 0.5996  loss_mask: 0.3196  loss_rpn_cls: 0.04971  loss_rpn_loc: 0.1319  time: 0.9382  data_time: 0.2046  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:54:17 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 1439  total_loss: 1.352  loss_cls: 0.3668  loss_box_reg: 0.541  loss_mask: 0.2974  loss_rpn_cls: 0.0388  loss_rpn_loc: 0.116  time: 0.9399  data_time: 0.2871  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:54:26 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:54:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:54:27 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:54:27 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:54:27 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:54:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1770 s/iter. Eval: 0.2437 s/iter. Total: 0.4216 s/iter. ETA=0:03:19\n",
      "\u001b[32m[02/13 11:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 27/485. Dataloading: 0.0009 s/iter. Inference: 0.1688 s/iter. Eval: 0.1730 s/iter. Total: 0.3428 s/iter. ETA=0:02:36\n",
      "\u001b[32m[02/13 11:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 43/485. Dataloading: 0.0010 s/iter. Inference: 0.1723 s/iter. Eval: 0.1595 s/iter. Total: 0.3328 s/iter. ETA=0:02:27\n",
      "\u001b[32m[02/13 11:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 58/485. Dataloading: 0.0010 s/iter. Inference: 0.1723 s/iter. Eval: 0.1622 s/iter. Total: 0.3355 s/iter. ETA=0:02:23\n",
      "\u001b[32m[02/13 11:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 74/485. Dataloading: 0.0010 s/iter. Inference: 0.1720 s/iter. Eval: 0.1652 s/iter. Total: 0.3383 s/iter. ETA=0:02:19\n",
      "\u001b[32m[02/13 11:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 94/485. Dataloading: 0.0010 s/iter. Inference: 0.1693 s/iter. Eval: 0.1489 s/iter. Total: 0.3192 s/iter. ETA=0:02:04\n",
      "\u001b[32m[02/13 11:55:04 d2.evaluation.evaluator]: \u001b[0mInference done 108/485. Dataloading: 0.0010 s/iter. Inference: 0.1710 s/iter. Eval: 0.1587 s/iter. Total: 0.3308 s/iter. ETA=0:02:04\n",
      "\u001b[32m[02/13 11:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 126/485. Dataloading: 0.0010 s/iter. Inference: 0.1687 s/iter. Eval: 0.1534 s/iter. Total: 0.3231 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 11:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 139/485. Dataloading: 0.0010 s/iter. Inference: 0.1685 s/iter. Eval: 0.1595 s/iter. Total: 0.3291 s/iter. ETA=0:01:53\n",
      "\u001b[32m[02/13 11:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 154/485. Dataloading: 0.0010 s/iter. Inference: 0.1687 s/iter. Eval: 0.1606 s/iter. Total: 0.3303 s/iter. ETA=0:01:49\n",
      "\u001b[32m[02/13 11:55:25 d2.evaluation.evaluator]: \u001b[0mInference done 176/485. Dataloading: 0.0010 s/iter. Inference: 0.1675 s/iter. Eval: 0.1520 s/iter. Total: 0.3206 s/iter. ETA=0:01:39\n",
      "\u001b[32m[02/13 11:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 193/485. Dataloading: 0.0010 s/iter. Inference: 0.1674 s/iter. Eval: 0.1528 s/iter. Total: 0.3213 s/iter. ETA=0:01:33\n",
      "\u001b[32m[02/13 11:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 209/485. Dataloading: 0.0010 s/iter. Inference: 0.1677 s/iter. Eval: 0.1558 s/iter. Total: 0.3245 s/iter. ETA=0:01:29\n",
      "\u001b[32m[02/13 11:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 226/485. Dataloading: 0.0010 s/iter. Inference: 0.1673 s/iter. Eval: 0.1556 s/iter. Total: 0.3241 s/iter. ETA=0:01:23\n",
      "\u001b[32m[02/13 11:55:47 d2.evaluation.evaluator]: \u001b[0mInference done 243/485. Dataloading: 0.0010 s/iter. Inference: 0.1671 s/iter. Eval: 0.1544 s/iter. Total: 0.3226 s/iter. ETA=0:01:18\n",
      "\u001b[32m[02/13 11:55:52 d2.evaluation.evaluator]: \u001b[0mInference done 254/485. Dataloading: 0.0010 s/iter. Inference: 0.1680 s/iter. Eval: 0.1598 s/iter. Total: 0.3289 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 11:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 268/485. Dataloading: 0.0010 s/iter. Inference: 0.1680 s/iter. Eval: 0.1618 s/iter. Total: 0.3308 s/iter. ETA=0:01:11\n",
      "\u001b[32m[02/13 11:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 285/485. Dataloading: 0.0010 s/iter. Inference: 0.1679 s/iter. Eval: 0.1611 s/iter. Total: 0.3301 s/iter. ETA=0:01:06\n",
      "\u001b[32m[02/13 11:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 303/485. Dataloading: 0.0010 s/iter. Inference: 0.1672 s/iter. Eval: 0.1587 s/iter. Total: 0.3270 s/iter. ETA=0:00:59\n",
      "\u001b[32m[02/13 11:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 318/485. Dataloading: 0.0010 s/iter. Inference: 0.1675 s/iter. Eval: 0.1589 s/iter. Total: 0.3275 s/iter. ETA=0:00:54\n",
      "\u001b[32m[02/13 11:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 330/485. Dataloading: 0.0010 s/iter. Inference: 0.1679 s/iter. Eval: 0.1624 s/iter. Total: 0.3315 s/iter. ETA=0:00:51\n",
      "\u001b[32m[02/13 11:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 348/485. Dataloading: 0.0010 s/iter. Inference: 0.1675 s/iter. Eval: 0.1601 s/iter. Total: 0.3287 s/iter. ETA=0:00:45\n",
      "\u001b[32m[02/13 11:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 364/485. Dataloading: 0.0010 s/iter. Inference: 0.1673 s/iter. Eval: 0.1601 s/iter. Total: 0.3284 s/iter. ETA=0:00:39\n",
      "\u001b[32m[02/13 11:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 379/485. Dataloading: 0.0010 s/iter. Inference: 0.1674 s/iter. Eval: 0.1602 s/iter. Total: 0.3287 s/iter. ETA=0:00:34\n",
      "\u001b[32m[02/13 11:56:38 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1673 s/iter. Eval: 0.1591 s/iter. Total: 0.3275 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/13 11:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1670 s/iter. Eval: 0.1590 s/iter. Total: 0.3271 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 11:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 429/485. Dataloading: 0.0010 s/iter. Inference: 0.1671 s/iter. Eval: 0.1601 s/iter. Total: 0.3283 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/13 11:56:54 d2.evaluation.evaluator]: \u001b[0mInference done 444/485. Dataloading: 0.0010 s/iter. Inference: 0.1671 s/iter. Eval: 0.1611 s/iter. Total: 0.3293 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 11:56:59 d2.evaluation.evaluator]: \u001b[0mInference done 464/485. Dataloading: 0.0010 s/iter. Inference: 0.1666 s/iter. Eval: 0.1582 s/iter. Total: 0.3259 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/13 11:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1662 s/iter. Eval: 0.1566 s/iter. Total: 0.3239 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 11:57:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:35.454004 (0.323863 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:57:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:19 (0.166156 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 11:57:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 11:57:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3050789349346319\n",
      "\u001b[32m[02/13 11:57:12 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 1459  total_loss: 1.289  loss_cls: 0.3224  loss_box_reg: 0.5559  loss_mask: 0.2911  loss_rpn_cls: 0.0352  loss_rpn_loc: 0.0877  time: 0.9379  data_time: 0.1004  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:57:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:57:33 d2.utils.events]: \u001b[0m eta: 0:19:04  iter: 1479  total_loss: 1.315  loss_cls: 0.3398  loss_box_reg: 0.5558  loss_mask: 0.3049  loss_rpn_cls: 0.03285  loss_rpn_loc: 0.112  time: 0.9395  data_time: 0.2164  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:57:50 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 1499  total_loss: 1.436  loss_cls: 0.3668  loss_box_reg: 0.5492  loss_mask: 0.297  loss_rpn_cls: 0.03149  loss_rpn_loc: 0.1048  time: 0.9377  data_time: 0.0752  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:57:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:58:13 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 1519  total_loss: 1.36  loss_cls: 0.3571  loss_box_reg: 0.568  loss_mask: 0.3125  loss_rpn_cls: 0.04281  loss_rpn_loc: 0.1198  time: 0.9404  data_time: 0.2611  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:58:32 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 1539  total_loss: 1.423  loss_cls: 0.3669  loss_box_reg: 0.5693  loss_mask: 0.2948  loss_rpn_cls: 0.06066  loss_rpn_loc: 0.1237  time: 0.9409  data_time: 0.2203  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:58:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 11:58:52 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 1559  total_loss: 1.38  loss_cls: 0.356  loss_box_reg: 0.5458  loss_mask: 0.303  loss_rpn_cls: 0.04076  loss_rpn_loc: 0.1068  time: 0.9416  data_time: 0.2031  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 11:59:03 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:59:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 11:59:04 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 11:59:04 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 11:59:04 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 11:59:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 11:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1783 s/iter. Eval: 0.2424 s/iter. Total: 0.4215 s/iter. ETA=0:03:19\n",
      "\u001b[32m[02/13 11:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 27/485. Dataloading: 0.0010 s/iter. Inference: 0.1724 s/iter. Eval: 0.1750 s/iter. Total: 0.3484 s/iter. ETA=0:02:39\n",
      "\u001b[32m[02/13 11:59:20 d2.evaluation.evaluator]: \u001b[0mInference done 42/485. Dataloading: 0.0010 s/iter. Inference: 0.1783 s/iter. Eval: 0.1647 s/iter. Total: 0.3440 s/iter. ETA=0:02:32\n",
      "\u001b[32m[02/13 11:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 57/485. Dataloading: 0.0010 s/iter. Inference: 0.1788 s/iter. Eval: 0.1666 s/iter. Total: 0.3464 s/iter. ETA=0:02:28\n",
      "\u001b[32m[02/13 11:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 73/485. Dataloading: 0.0010 s/iter. Inference: 0.1765 s/iter. Eval: 0.1623 s/iter. Total: 0.3398 s/iter. ETA=0:02:20\n",
      "\u001b[32m[02/13 11:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 91/485. Dataloading: 0.0010 s/iter. Inference: 0.1748 s/iter. Eval: 0.1520 s/iter. Total: 0.3279 s/iter. ETA=0:02:09\n",
      "\u001b[32m[02/13 11:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 105/485. Dataloading: 0.0010 s/iter. Inference: 0.1756 s/iter. Eval: 0.1558 s/iter. Total: 0.3324 s/iter. ETA=0:02:06\n",
      "\u001b[32m[02/13 11:59:45 d2.evaluation.evaluator]: \u001b[0mInference done 120/485. Dataloading: 0.0010 s/iter. Inference: 0.1751 s/iter. Eval: 0.1590 s/iter. Total: 0.3352 s/iter. ETA=0:02:02\n",
      "\u001b[32m[02/13 11:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 136/485. Dataloading: 0.0010 s/iter. Inference: 0.1744 s/iter. Eval: 0.1622 s/iter. Total: 0.3376 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 11:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 151/485. Dataloading: 0.0010 s/iter. Inference: 0.1739 s/iter. Eval: 0.1628 s/iter. Total: 0.3378 s/iter. ETA=0:01:52\n",
      "\u001b[32m[02/13 12:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 172/485. Dataloading: 0.0010 s/iter. Inference: 0.1718 s/iter. Eval: 0.1528 s/iter. Total: 0.3257 s/iter. ETA=0:01:41\n",
      "\u001b[32m[02/13 12:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 187/485. Dataloading: 0.0010 s/iter. Inference: 0.1716 s/iter. Eval: 0.1543 s/iter. Total: 0.3270 s/iter. ETA=0:01:37\n",
      "\u001b[32m[02/13 12:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 203/485. Dataloading: 0.0010 s/iter. Inference: 0.1713 s/iter. Eval: 0.1541 s/iter. Total: 0.3265 s/iter. ETA=0:01:32\n",
      "\u001b[32m[02/13 12:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 219/485. Dataloading: 0.0010 s/iter. Inference: 0.1707 s/iter. Eval: 0.1538 s/iter. Total: 0.3256 s/iter. ETA=0:01:26\n",
      "\u001b[32m[02/13 12:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 236/485. Dataloading: 0.0010 s/iter. Inference: 0.1702 s/iter. Eval: 0.1525 s/iter. Total: 0.3238 s/iter. ETA=0:01:20\n",
      "\u001b[32m[02/13 12:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0010 s/iter. Inference: 0.1710 s/iter. Eval: 0.1597 s/iter. Total: 0.3318 s/iter. ETA=0:01:18\n",
      "\u001b[32m[02/13 12:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 262/485. Dataloading: 0.0010 s/iter. Inference: 0.1713 s/iter. Eval: 0.1598 s/iter. Total: 0.3321 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 12:00:38 d2.evaluation.evaluator]: \u001b[0mInference done 277/485. Dataloading: 0.0010 s/iter. Inference: 0.1712 s/iter. Eval: 0.1615 s/iter. Total: 0.3338 s/iter. ETA=0:01:09\n",
      "\u001b[32m[02/13 12:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 298/485. Dataloading: 0.0010 s/iter. Inference: 0.1700 s/iter. Eval: 0.1565 s/iter. Total: 0.3276 s/iter. ETA=0:01:01\n",
      "\u001b[32m[02/13 12:00:48 d2.evaluation.evaluator]: \u001b[0mInference done 312/485. Dataloading: 0.0010 s/iter. Inference: 0.1704 s/iter. Eval: 0.1575 s/iter. Total: 0.3289 s/iter. ETA=0:00:56\n",
      "\u001b[32m[02/13 12:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 325/485. Dataloading: 0.0010 s/iter. Inference: 0.1706 s/iter. Eval: 0.1598 s/iter. Total: 0.3315 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 12:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 339/485. Dataloading: 0.0010 s/iter. Inference: 0.1708 s/iter. Eval: 0.1615 s/iter. Total: 0.3334 s/iter. ETA=0:00:48\n",
      "\u001b[32m[02/13 12:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 358/485. Dataloading: 0.0010 s/iter. Inference: 0.1699 s/iter. Eval: 0.1588 s/iter. Total: 0.3297 s/iter. ETA=0:00:41\n",
      "\u001b[32m[02/13 12:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 373/485. Dataloading: 0.0010 s/iter. Inference: 0.1701 s/iter. Eval: 0.1591 s/iter. Total: 0.3302 s/iter. ETA=0:00:36\n",
      "\u001b[32m[02/13 12:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 393/485. Dataloading: 0.0010 s/iter. Inference: 0.1696 s/iter. Eval: 0.1563 s/iter. Total: 0.3270 s/iter. ETA=0:00:30\n",
      "\u001b[32m[02/13 12:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 411/485. Dataloading: 0.0010 s/iter. Inference: 0.1691 s/iter. Eval: 0.1553 s/iter. Total: 0.3255 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/13 12:01:24 d2.evaluation.evaluator]: \u001b[0mInference done 425/485. Dataloading: 0.0010 s/iter. Inference: 0.1693 s/iter. Eval: 0.1569 s/iter. Total: 0.3272 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/13 12:01:30 d2.evaluation.evaluator]: \u001b[0mInference done 441/485. Dataloading: 0.0010 s/iter. Inference: 0.1692 s/iter. Eval: 0.1572 s/iter. Total: 0.3274 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 12:01:35 d2.evaluation.evaluator]: \u001b[0mInference done 459/485. Dataloading: 0.0010 s/iter. Inference: 0.1691 s/iter. Eval: 0.1555 s/iter. Total: 0.3256 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/13 12:01:40 d2.evaluation.evaluator]: \u001b[0mInference done 478/485. Dataloading: 0.0010 s/iter. Inference: 0.1685 s/iter. Eval: 0.1536 s/iter. Total: 0.3231 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/13 12:01:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:35.121261 (0.323169 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:01:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:20 (0.168511 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:01:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:01:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30287360436660776\n",
      "\u001b[32m[02/13 12:01:47 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 1579  total_loss: 1.31  loss_cls: 0.3464  loss_box_reg: 0.55  loss_mask: 0.2788  loss_rpn_cls: 0.03792  loss_rpn_loc: 0.1248  time: 0.9395  data_time: 0.0477  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:02:05 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 1599  total_loss: 1.377  loss_cls: 0.3593  loss_box_reg: 0.5664  loss_mask: 0.295  loss_rpn_cls: 0.04798  loss_rpn_loc: 0.1228  time: 0.9392  data_time: 0.1786  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:02:27 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 1619  total_loss: 1.424  loss_cls: 0.3822  loss_box_reg: 0.5818  loss_mask: 0.3238  loss_rpn_cls: 0.05653  loss_rpn_loc: 0.1204  time: 0.9411  data_time: 0.3017  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:02:46 d2.utils.events]: \u001b[0m eta: 0:17:11  iter: 1639  total_loss: 1.301  loss_cls: 0.3329  loss_box_reg: 0.528  loss_mask: 0.2873  loss_rpn_cls: 0.04107  loss_rpn_loc: 0.1081  time: 0.9411  data_time: 0.1874  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:03:07 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 1659  total_loss: 1.361  loss_cls: 0.3648  loss_box_reg: 0.5366  loss_mask: 0.2839  loss_rpn_cls: 0.04125  loss_rpn_loc: 0.11  time: 0.9422  data_time: 0.2846  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:03:23 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 1679  total_loss: 1.326  loss_cls: 0.3405  loss_box_reg: 0.5589  loss_mask: 0.2939  loss_rpn_cls: 0.03736  loss_rpn_loc: 0.1145  time: 0.9404  data_time: 0.0945  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:03:38 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:03:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:03:38 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:03:38 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:03:39 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:03:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0009 s/iter. Inference: 0.1758 s/iter. Eval: 0.2371 s/iter. Total: 0.4138 s/iter. ETA=0:03:16\n",
      "\u001b[32m[02/13 12:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1684 s/iter. Eval: 0.1812 s/iter. Total: 0.3505 s/iter. ETA=0:02:40\n",
      "\u001b[32m[02/13 12:03:55 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1715 s/iter. Eval: 0.1623 s/iter. Total: 0.3349 s/iter. ETA=0:02:27\n",
      "\u001b[32m[02/13 12:04:00 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1697 s/iter. Eval: 0.1633 s/iter. Total: 0.3340 s/iter. ETA=0:02:21\n",
      "\u001b[32m[02/13 12:04:05 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0010 s/iter. Inference: 0.1658 s/iter. Eval: 0.1512 s/iter. Total: 0.3181 s/iter. ETA=0:02:08\n",
      "\u001b[32m[02/13 12:04:10 d2.evaluation.evaluator]: \u001b[0mInference done 98/485. Dataloading: 0.0010 s/iter. Inference: 0.1657 s/iter. Eval: 0.1446 s/iter. Total: 0.3113 s/iter. ETA=0:02:00\n",
      "\u001b[32m[02/13 12:04:15 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0010 s/iter. Inference: 0.1671 s/iter. Eval: 0.1518 s/iter. Total: 0.3200 s/iter. ETA=0:01:59\n",
      "\u001b[32m[02/13 12:04:21 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0010 s/iter. Inference: 0.1662 s/iter. Eval: 0.1514 s/iter. Total: 0.3186 s/iter. ETA=0:01:53\n",
      "\u001b[32m[02/13 12:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 145/485. Dataloading: 0.0010 s/iter. Inference: 0.1657 s/iter. Eval: 0.1560 s/iter. Total: 0.3227 s/iter. ETA=0:01:49\n",
      "\u001b[32m[02/13 12:04:31 d2.evaluation.evaluator]: \u001b[0mInference done 163/485. Dataloading: 0.0010 s/iter. Inference: 0.1647 s/iter. Eval: 0.1524 s/iter. Total: 0.3181 s/iter. ETA=0:01:42\n",
      "\u001b[32m[02/13 12:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 183/485. Dataloading: 0.0010 s/iter. Inference: 0.1638 s/iter. Eval: 0.1465 s/iter. Total: 0.3113 s/iter. ETA=0:01:34\n",
      "\u001b[32m[02/13 12:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 197/485. Dataloading: 0.0010 s/iter. Inference: 0.1636 s/iter. Eval: 0.1502 s/iter. Total: 0.3148 s/iter. ETA=0:01:30\n",
      "\u001b[32m[02/13 12:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 213/485. Dataloading: 0.0010 s/iter. Inference: 0.1634 s/iter. Eval: 0.1502 s/iter. Total: 0.3146 s/iter. ETA=0:01:25\n",
      "\u001b[32m[02/13 12:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 229/485. Dataloading: 0.0010 s/iter. Inference: 0.1632 s/iter. Eval: 0.1509 s/iter. Total: 0.3151 s/iter. ETA=0:01:20\n",
      "\u001b[32m[02/13 12:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 245/485. Dataloading: 0.0010 s/iter. Inference: 0.1629 s/iter. Eval: 0.1517 s/iter. Total: 0.3156 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 12:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 257/485. Dataloading: 0.0010 s/iter. Inference: 0.1638 s/iter. Eval: 0.1570 s/iter. Total: 0.3219 s/iter. ETA=0:01:13\n",
      "\u001b[32m[02/13 12:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 273/485. Dataloading: 0.0010 s/iter. Inference: 0.1638 s/iter. Eval: 0.1566 s/iter. Total: 0.3215 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 288/485. Dataloading: 0.0010 s/iter. Inference: 0.1643 s/iter. Eval: 0.1574 s/iter. Total: 0.3227 s/iter. ETA=0:01:03\n",
      "\u001b[32m[02/13 12:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 306/485. Dataloading: 0.0010 s/iter. Inference: 0.1641 s/iter. Eval: 0.1550 s/iter. Total: 0.3201 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 321/485. Dataloading: 0.0010 s/iter. Inference: 0.1645 s/iter. Eval: 0.1565 s/iter. Total: 0.3220 s/iter. ETA=0:00:52\n",
      "\u001b[32m[02/13 12:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 333/485. Dataloading: 0.0010 s/iter. Inference: 0.1650 s/iter. Eval: 0.1596 s/iter. Total: 0.3256 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 351/485. Dataloading: 0.0010 s/iter. Inference: 0.1646 s/iter. Eval: 0.1576 s/iter. Total: 0.3232 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 12:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 367/485. Dataloading: 0.0010 s/iter. Inference: 0.1643 s/iter. Eval: 0.1577 s/iter. Total: 0.3230 s/iter. ETA=0:00:38\n",
      "\u001b[32m[02/13 12:05:43 d2.evaluation.evaluator]: \u001b[0mInference done 387/485. Dataloading: 0.0010 s/iter. Inference: 0.1638 s/iter. Eval: 0.1546 s/iter. Total: 0.3194 s/iter. ETA=0:00:31\n",
      "\u001b[32m[02/13 12:05:48 d2.evaluation.evaluator]: \u001b[0mInference done 406/485. Dataloading: 0.0010 s/iter. Inference: 0.1634 s/iter. Eval: 0.1527 s/iter. Total: 0.3171 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 12:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 419/485. Dataloading: 0.0010 s/iter. Inference: 0.1636 s/iter. Eval: 0.1551 s/iter. Total: 0.3198 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 436/485. Dataloading: 0.0010 s/iter. Inference: 0.1635 s/iter. Eval: 0.1554 s/iter. Total: 0.3199 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 12:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 453/485. Dataloading: 0.0010 s/iter. Inference: 0.1635 s/iter. Eval: 0.1546 s/iter. Total: 0.3191 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/13 12:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 472/485. Dataloading: 0.0010 s/iter. Inference: 0.1629 s/iter. Eval: 0.1530 s/iter. Total: 0.3169 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 12:06:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:31.544634 (0.315718 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:06:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:18 (0.162792 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:06:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:06:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3040540588431374\n",
      "\u001b[32m[02/13 12:06:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:06:21 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 1699  total_loss: 1.341  loss_cls: 0.3468  loss_box_reg: 0.5566  loss_mask: 0.3119  loss_rpn_cls: 0.03452  loss_rpn_loc: 0.1048  time: 0.9424  data_time: 0.2484  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:06:40 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 1719  total_loss: 1.337  loss_cls: 0.3401  loss_box_reg: 0.5558  loss_mask: 0.2888  loss_rpn_cls: 0.02607  loss_rpn_loc: 0.09939  time: 0.9425  data_time: 0.2611  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:06:59 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 1739  total_loss: 1.403  loss_cls: 0.3527  loss_box_reg: 0.5653  loss_mask: 0.293  loss_rpn_cls: 0.0537  loss_rpn_loc: 0.113  time: 0.9427  data_time: 0.2412  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:07:15 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 1759  total_loss: 1.365  loss_cls: 0.364  loss_box_reg: 0.5637  loss_mask: 0.2934  loss_rpn_cls: 0.03123  loss_rpn_loc: 0.1053  time: 0.9411  data_time: 0.0949  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:07:34 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 1779  total_loss: 1.42  loss_cls: 0.3713  loss_box_reg: 0.5622  loss_mask: 0.3024  loss_rpn_cls: 0.04478  loss_rpn_loc: 0.126  time: 0.9412  data_time: 0.2453  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:07:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:07:55 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 1799  total_loss: 1.329  loss_cls: 0.3409  loss_box_reg: 0.5369  loss_mask: 0.2754  loss_rpn_cls: 0.02925  loss_rpn_loc: 0.1079  time: 0.9421  data_time: 0.2138  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:08:10 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:08:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:08:10 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:08:10 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:08:11 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:08:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:08:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1643 s/iter. Eval: 0.2234 s/iter. Total: 0.3886 s/iter. ETA=0:03:04\n",
      "\u001b[32m[02/13 12:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1610 s/iter. Eval: 0.1720 s/iter. Total: 0.3339 s/iter. ETA=0:02:32\n",
      "\u001b[32m[02/13 12:08:26 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0010 s/iter. Inference: 0.1649 s/iter. Eval: 0.1534 s/iter. Total: 0.3193 s/iter. ETA=0:02:20\n",
      "\u001b[32m[02/13 12:08:31 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0010 s/iter. Inference: 0.1640 s/iter. Eval: 0.1542 s/iter. Total: 0.3192 s/iter. ETA=0:02:15\n",
      "\u001b[32m[02/13 12:08:36 d2.evaluation.evaluator]: \u001b[0mInference done 81/485. Dataloading: 0.0010 s/iter. Inference: 0.1608 s/iter. Eval: 0.1426 s/iter. Total: 0.3044 s/iter. ETA=0:02:02\n",
      "\u001b[32m[02/13 12:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0010 s/iter. Inference: 0.1617 s/iter. Eval: 0.1397 s/iter. Total: 0.3024 s/iter. ETA=0:01:56\n",
      "\u001b[32m[02/13 12:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 113/485. Dataloading: 0.0010 s/iter. Inference: 0.1630 s/iter. Eval: 0.1456 s/iter. Total: 0.3096 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 12:08:52 d2.evaluation.evaluator]: \u001b[0mInference done 130/485. Dataloading: 0.0010 s/iter. Inference: 0.1621 s/iter. Eval: 0.1467 s/iter. Total: 0.3098 s/iter. ETA=0:01:49\n",
      "\u001b[32m[02/13 12:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 146/485. Dataloading: 0.0010 s/iter. Inference: 0.1613 s/iter. Eval: 0.1484 s/iter. Total: 0.3107 s/iter. ETA=0:01:45\n",
      "\u001b[32m[02/13 12:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 165/485. Dataloading: 0.0010 s/iter. Inference: 0.1607 s/iter. Eval: 0.1437 s/iter. Total: 0.3054 s/iter. ETA=0:01:37\n",
      "\u001b[32m[02/13 12:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1400 s/iter. Total: 0.3012 s/iter. ETA=0:01:30\n",
      "\u001b[32m[02/13 12:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 199/485. Dataloading: 0.0010 s/iter. Inference: 0.1604 s/iter. Eval: 0.1439 s/iter. Total: 0.3054 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 12:09:18 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1433 s/iter. Total: 0.3043 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 12:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 236/485. Dataloading: 0.0010 s/iter. Inference: 0.1594 s/iter. Eval: 0.1412 s/iter. Total: 0.3016 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 12:09:28 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1486 s/iter. Total: 0.3099 s/iter. ETA=0:01:13\n",
      "\u001b[32m[02/13 12:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 264/485. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1477 s/iter. Total: 0.3092 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:09:38 d2.evaluation.evaluator]: \u001b[0mInference done 278/485. Dataloading: 0.0010 s/iter. Inference: 0.1610 s/iter. Eval: 0.1503 s/iter. Total: 0.3123 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 12:09:44 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1466 s/iter. Total: 0.3077 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0010 s/iter. Inference: 0.1606 s/iter. Eval: 0.1480 s/iter. Total: 0.3096 s/iter. ETA=0:00:52\n",
      "\u001b[32m[02/13 12:09:54 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0010 s/iter. Inference: 0.1608 s/iter. Eval: 0.1502 s/iter. Total: 0.3120 s/iter. ETA=0:00:48\n",
      "\u001b[32m[02/13 12:09:59 d2.evaluation.evaluator]: \u001b[0mInference done 345/485. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1497 s/iter. Total: 0.3112 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 12:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 362/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1492 s/iter. Total: 0.3105 s/iter. ETA=0:00:38\n",
      "\u001b[32m[02/13 12:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1483 s/iter. Total: 0.3095 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/13 12:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1601 s/iter. Eval: 0.1474 s/iter. Total: 0.3085 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 12:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1473 s/iter. Total: 0.3082 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0010 s/iter. Inference: 0.1601 s/iter. Eval: 0.1481 s/iter. Total: 0.3093 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1491 s/iter. Total: 0.3103 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1464 s/iter. Total: 0.3072 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 12:10:40 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1454 s/iter. Total: 0.3063 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:10:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:27.011042 (0.306273 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:10:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.159841 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:10:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:10:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3001739474184701\n",
      "\u001b[32m[02/13 12:10:44 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 1819  total_loss: 1.287  loss_cls: 0.342  loss_box_reg: 0.5545  loss_mask: 0.2935  loss_rpn_cls: 0.04021  loss_rpn_loc: 0.0855  time: 0.9415  data_time: 0.1858  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:11:01 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 1839  total_loss: 1.509  loss_cls: 0.3862  loss_box_reg: 0.587  loss_mask: 0.3  loss_rpn_cls: 0.04475  loss_rpn_loc: 0.116  time: 0.9406  data_time: 0.1489  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:11:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:11:25 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 1859  total_loss: 1.386  loss_cls: 0.3746  loss_box_reg: 0.548  loss_mask: 0.3021  loss_rpn_cls: 0.05537  loss_rpn_loc: 0.1123  time: 0.9437  data_time: 0.3767  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:11:44 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 1879  total_loss: 1.339  loss_cls: 0.3543  loss_box_reg: 0.5478  loss_mask: 0.299  loss_rpn_cls: 0.03235  loss_rpn_loc: 0.1173  time: 0.9435  data_time: 0.2121  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:11:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:12:04 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 1899  total_loss: 1.355  loss_cls: 0.3614  loss_box_reg: 0.5343  loss_mask: 0.2869  loss_rpn_cls: 0.05503  loss_rpn_loc: 0.1192  time: 0.9439  data_time: 0.1483  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:12:22 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 1919  total_loss: 1.335  loss_cls: 0.3468  loss_box_reg: 0.5655  loss_mask: 0.2929  loss_rpn_cls: 0.03765  loss_rpn_loc: 0.1024  time: 0.9434  data_time: 0.2104  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:12:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:12:37 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:12:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:12:37 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:12:38 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:12:38 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:12:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1644 s/iter. Eval: 0.2211 s/iter. Total: 0.3863 s/iter. ETA=0:03:03\n",
      "\u001b[32m[02/13 12:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1605 s/iter. Eval: 0.1712 s/iter. Total: 0.3327 s/iter. ETA=0:02:32\n",
      "\u001b[32m[02/13 12:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0010 s/iter. Inference: 0.1640 s/iter. Eval: 0.1540 s/iter. Total: 0.3190 s/iter. ETA=0:02:20\n",
      "\u001b[32m[02/13 12:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0010 s/iter. Inference: 0.1634 s/iter. Eval: 0.1550 s/iter. Total: 0.3194 s/iter. ETA=0:02:15\n",
      "\u001b[32m[02/13 12:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1444 s/iter. Total: 0.3057 s/iter. ETA=0:02:03\n",
      "\u001b[32m[02/13 12:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0010 s/iter. Inference: 0.1612 s/iter. Eval: 0.1416 s/iter. Total: 0.3038 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 12:13:14 d2.evaluation.evaluator]: \u001b[0mInference done 113/485. Dataloading: 0.0010 s/iter. Inference: 0.1628 s/iter. Eval: 0.1476 s/iter. Total: 0.3114 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 12:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 130/485. Dataloading: 0.0010 s/iter. Inference: 0.1619 s/iter. Eval: 0.1486 s/iter. Total: 0.3116 s/iter. ETA=0:01:50\n",
      "\u001b[32m[02/13 12:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 146/485. Dataloading: 0.0010 s/iter. Inference: 0.1611 s/iter. Eval: 0.1497 s/iter. Total: 0.3119 s/iter. ETA=0:01:45\n",
      "\u001b[32m[02/13 12:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 165/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1452 s/iter. Total: 0.3065 s/iter. ETA=0:01:38\n",
      "\u001b[32m[02/13 12:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1416 s/iter. Total: 0.3025 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 12:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 199/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1452 s/iter. Total: 0.3063 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 12:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1444 s/iter. Total: 0.3051 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 12:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 236/485. Dataloading: 0.0010 s/iter. Inference: 0.1590 s/iter. Eval: 0.1422 s/iter. Total: 0.3023 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 12:13:56 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1494 s/iter. Total: 0.3103 s/iter. ETA=0:01:13\n",
      "\u001b[32m[02/13 12:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 264/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1486 s/iter. Total: 0.3097 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 278/485. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1512 s/iter. Total: 0.3127 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 12:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1474 s/iter. Total: 0.3080 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0010 s/iter. Inference: 0.1601 s/iter. Eval: 0.1488 s/iter. Total: 0.3099 s/iter. ETA=0:00:52\n",
      "\u001b[32m[02/13 12:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1510 s/iter. Total: 0.3124 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 345/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1505 s/iter. Total: 0.3117 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 12:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 363/485. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1496 s/iter. Total: 0.3104 s/iter. ETA=0:00:37\n",
      "\u001b[32m[02/13 12:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1489 s/iter. Total: 0.3098 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/13 12:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1479 s/iter. Total: 0.3087 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 12:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1595 s/iter. Eval: 0.1477 s/iter. Total: 0.3083 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1485 s/iter. Total: 0.3092 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1494 s/iter. Total: 0.3101 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0010 s/iter. Inference: 0.1594 s/iter. Eval: 0.1467 s/iter. Total: 0.3071 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 12:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1593 s/iter. Eval: 0.1457 s/iter. Total: 0.3060 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:15:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:26.878633 (0.305997 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:15:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.159252 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:15:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:15:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30124103023330334\n",
      "\u001b[32m[02/13 12:15:10 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 1939  total_loss: 1.373  loss_cls: 0.3508  loss_box_reg: 0.5853  loss_mask: 0.3055  loss_rpn_cls: 0.02621  loss_rpn_loc: 0.1044  time: 0.9427  data_time: 0.0945  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:15:28 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 1959  total_loss: 1.407  loss_cls: 0.3658  loss_box_reg: 0.5521  loss_mask: 0.2972  loss_rpn_cls: 0.04055  loss_rpn_loc: 0.1276  time: 0.9423  data_time: 0.1961  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:15:45 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 1979  total_loss: 1.284  loss_cls: 0.3372  loss_box_reg: 0.5329  loss_mask: 0.278  loss_rpn_cls: 0.03587  loss_rpn_loc: 0.109  time: 0.9414  data_time: 0.1518  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:15:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:16:05 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 1999  total_loss: 1.301  loss_cls: 0.3353  loss_box_reg: 0.5382  loss_mask: 0.2863  loss_rpn_cls: 0.03401  loss_rpn_loc: 0.1202  time: 0.9417  data_time: 0.1717  lr: 0.00016  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:16:23 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 2019  total_loss: 1.371  loss_cls: 0.3687  loss_box_reg: 0.5486  loss_mask: 0.3051  loss_rpn_cls: 0.04806  loss_rpn_loc: 0.1205  time: 0.9414  data_time: 0.1840  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:16:40 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 2039  total_loss: 1.337  loss_cls: 0.3383  loss_box_reg: 0.5305  loss_mask: 0.2983  loss_rpn_cls: 0.04027  loss_rpn_loc: 0.1095  time: 0.9405  data_time: 0.1612  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:16:55 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:16:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:16:56 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:16:56 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:16:56 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:16:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:17:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1638 s/iter. Eval: 0.2255 s/iter. Total: 0.3902 s/iter. ETA=0:03:04\n",
      "\u001b[32m[02/13 12:17:06 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1593 s/iter. Eval: 0.1729 s/iter. Total: 0.3332 s/iter. ETA=0:02:32\n",
      "\u001b[32m[02/13 12:17:12 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1629 s/iter. Eval: 0.1551 s/iter. Total: 0.3190 s/iter. ETA=0:02:20\n",
      "\u001b[32m[02/13 12:17:17 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1619 s/iter. Eval: 0.1560 s/iter. Total: 0.3190 s/iter. ETA=0:02:15\n",
      "\u001b[32m[02/13 12:17:22 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1588 s/iter. Eval: 0.1453 s/iter. Total: 0.3050 s/iter. ETA=0:02:03\n",
      "\u001b[32m[02/13 12:17:27 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0009 s/iter. Inference: 0.1598 s/iter. Eval: 0.1423 s/iter. Total: 0.3031 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 12:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 113/485. Dataloading: 0.0010 s/iter. Inference: 0.1610 s/iter. Eval: 0.1483 s/iter. Total: 0.3103 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 12:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 130/485. Dataloading: 0.0009 s/iter. Inference: 0.1602 s/iter. Eval: 0.1496 s/iter. Total: 0.3108 s/iter. ETA=0:01:50\n",
      "\u001b[32m[02/13 12:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 146/485. Dataloading: 0.0009 s/iter. Inference: 0.1594 s/iter. Eval: 0.1507 s/iter. Total: 0.3111 s/iter. ETA=0:01:45\n",
      "\u001b[32m[02/13 12:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 165/485. Dataloading: 0.0009 s/iter. Inference: 0.1588 s/iter. Eval: 0.1461 s/iter. Total: 0.3059 s/iter. ETA=0:01:37\n",
      "\u001b[32m[02/13 12:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0009 s/iter. Inference: 0.1583 s/iter. Eval: 0.1426 s/iter. Total: 0.3019 s/iter. ETA=0:01:30\n",
      "\u001b[32m[02/13 12:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 199/485. Dataloading: 0.0009 s/iter. Inference: 0.1586 s/iter. Eval: 0.1464 s/iter. Total: 0.3059 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 12:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0009 s/iter. Inference: 0.1581 s/iter. Eval: 0.1457 s/iter. Total: 0.3047 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 12:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 236/485. Dataloading: 0.0009 s/iter. Inference: 0.1575 s/iter. Eval: 0.1435 s/iter. Total: 0.3020 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 12:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0009 s/iter. Inference: 0.1584 s/iter. Eval: 0.1509 s/iter. Total: 0.3103 s/iter. ETA=0:01:13\n",
      "\u001b[32m[02/13 12:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 264/485. Dataloading: 0.0010 s/iter. Inference: 0.1585 s/iter. Eval: 0.1501 s/iter. Total: 0.3097 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 278/485. Dataloading: 0.0010 s/iter. Inference: 0.1591 s/iter. Eval: 0.1527 s/iter. Total: 0.3128 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 12:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0010 s/iter. Inference: 0.1581 s/iter. Eval: 0.1489 s/iter. Total: 0.3081 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0010 s/iter. Inference: 0.1586 s/iter. Eval: 0.1503 s/iter. Total: 0.3099 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 12:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0010 s/iter. Inference: 0.1590 s/iter. Eval: 0.1525 s/iter. Total: 0.3125 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 345/485. Dataloading: 0.0010 s/iter. Inference: 0.1587 s/iter. Eval: 0.1519 s/iter. Total: 0.3117 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 12:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 363/485. Dataloading: 0.0010 s/iter. Inference: 0.1583 s/iter. Eval: 0.1510 s/iter. Total: 0.3104 s/iter. ETA=0:00:37\n",
      "\u001b[32m[02/13 12:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0010 s/iter. Inference: 0.1583 s/iter. Eval: 0.1504 s/iter. Total: 0.3097 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/13 12:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1582 s/iter. Eval: 0.1494 s/iter. Total: 0.3086 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 12:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1581 s/iter. Eval: 0.1492 s/iter. Total: 0.3083 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0010 s/iter. Inference: 0.1583 s/iter. Eval: 0.1501 s/iter. Total: 0.3093 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0010 s/iter. Inference: 0.1583 s/iter. Eval: 0.1510 s/iter. Total: 0.3103 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0010 s/iter. Inference: 0.1579 s/iter. Eval: 0.1482 s/iter. Total: 0.3072 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 12:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1578 s/iter. Eval: 0.1472 s/iter. Total: 0.3061 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:19:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:26.910746 (0.306064 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:19:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:15 (0.157785 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:19:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:19:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3050330009357687\n",
      "\u001b[32m[02/13 12:19:28 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 2059  total_loss: 1.385  loss_cls: 0.3635  loss_box_reg: 0.5461  loss_mask: 0.3047  loss_rpn_cls: 0.04368  loss_rpn_loc: 0.1135  time: 0.9396  data_time: 0.1545  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:19:49 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 2079  total_loss: 1.278  loss_cls: 0.3372  loss_box_reg: 0.5355  loss_mask: 0.2819  loss_rpn_cls: 0.03457  loss_rpn_loc: 0.12  time: 0.9407  data_time: 0.3069  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:20:07 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 2099  total_loss: 1.364  loss_cls: 0.3401  loss_box_reg: 0.5563  loss_mask: 0.2983  loss_rpn_cls: 0.04325  loss_rpn_loc: 0.09798  time: 0.9401  data_time: 0.1742  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:20:24 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 2119  total_loss: 1.276  loss_cls: 0.3386  loss_box_reg: 0.5373  loss_mask: 0.2906  loss_rpn_cls: 0.03035  loss_rpn_loc: 0.08286  time: 0.9395  data_time: 0.1864  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:20:41 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 2139  total_loss: 1.389  loss_cls: 0.3608  loss_box_reg: 0.5539  loss_mask: 0.2992  loss_rpn_cls: 0.03016  loss_rpn_loc: 0.1091  time: 0.9385  data_time: 0.1322  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:21:01 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 2159  total_loss: 1.416  loss_cls: 0.3686  loss_box_reg: 0.5652  loss_mask: 0.3047  loss_rpn_cls: 0.05143  loss_rpn_loc: 0.1236  time: 0.9392  data_time: 0.2930  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:21:18 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:21:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:21:19 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:21:19 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:21:19 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:21:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1650 s/iter. Eval: 0.2201 s/iter. Total: 0.3859 s/iter. ETA=0:03:02\n",
      "\u001b[32m[02/13 12:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1614 s/iter. Eval: 0.1699 s/iter. Total: 0.3323 s/iter. ETA=0:02:31\n",
      "\u001b[32m[02/13 12:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1648 s/iter. Eval: 0.1526 s/iter. Total: 0.3183 s/iter. ETA=0:02:20\n",
      "\u001b[32m[02/13 12:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1640 s/iter. Eval: 0.1538 s/iter. Total: 0.3188 s/iter. ETA=0:02:15\n",
      "\u001b[32m[02/13 12:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1435 s/iter. Total: 0.3053 s/iter. ETA=0:02:03\n",
      "\u001b[32m[02/13 12:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0009 s/iter. Inference: 0.1616 s/iter. Eval: 0.1409 s/iter. Total: 0.3035 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 12:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 114/485. Dataloading: 0.0009 s/iter. Inference: 0.1631 s/iter. Eval: 0.1457 s/iter. Total: 0.3097 s/iter. ETA=0:01:54\n",
      "\u001b[32m[02/13 12:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 130/485. Dataloading: 0.0009 s/iter. Inference: 0.1621 s/iter. Eval: 0.1474 s/iter. Total: 0.3104 s/iter. ETA=0:01:50\n",
      "\u001b[32m[02/13 12:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 146/485. Dataloading: 0.0009 s/iter. Inference: 0.1613 s/iter. Eval: 0.1487 s/iter. Total: 0.3109 s/iter. ETA=0:01:45\n",
      "\u001b[32m[02/13 12:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 165/485. Dataloading: 0.0009 s/iter. Inference: 0.1606 s/iter. Eval: 0.1443 s/iter. Total: 0.3059 s/iter. ETA=0:01:37\n",
      "\u001b[32m[02/13 12:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1407 s/iter. Total: 0.3018 s/iter. ETA=0:01:30\n",
      "\u001b[32m[02/13 12:22:21 d2.evaluation.evaluator]: \u001b[0mInference done 199/485. Dataloading: 0.0009 s/iter. Inference: 0.1604 s/iter. Eval: 0.1443 s/iter. Total: 0.3057 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 12:22:26 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0009 s/iter. Inference: 0.1599 s/iter. Eval: 0.1436 s/iter. Total: 0.3045 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 12:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 235/485. Dataloading: 0.0009 s/iter. Inference: 0.1595 s/iter. Eval: 0.1420 s/iter. Total: 0.3024 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 12:22:37 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0009 s/iter. Inference: 0.1602 s/iter. Eval: 0.1486 s/iter. Total: 0.3098 s/iter. ETA=0:01:13\n",
      "\u001b[32m[02/13 12:22:42 d2.evaluation.evaluator]: \u001b[0mInference done 264/485. Dataloading: 0.0009 s/iter. Inference: 0.1603 s/iter. Eval: 0.1478 s/iter. Total: 0.3091 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:22:47 d2.evaluation.evaluator]: \u001b[0mInference done 278/485. Dataloading: 0.0010 s/iter. Inference: 0.1608 s/iter. Eval: 0.1504 s/iter. Total: 0.3122 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 12:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1467 s/iter. Total: 0.3076 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0010 s/iter. Inference: 0.1604 s/iter. Eval: 0.1481 s/iter. Total: 0.3095 s/iter. ETA=0:00:52\n",
      "\u001b[32m[02/13 12:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0010 s/iter. Inference: 0.1608 s/iter. Eval: 0.1504 s/iter. Total: 0.3122 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 345/485. Dataloading: 0.0010 s/iter. Inference: 0.1606 s/iter. Eval: 0.1498 s/iter. Total: 0.3114 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 12:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 362/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1493 s/iter. Total: 0.3106 s/iter. ETA=0:00:38\n",
      "\u001b[32m[02/13 12:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1484 s/iter. Total: 0.3096 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/13 12:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1473 s/iter. Total: 0.3085 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 12:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1471 s/iter. Total: 0.3081 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1479 s/iter. Total: 0.3091 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1488 s/iter. Total: 0.3101 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1461 s/iter. Total: 0.3070 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 12:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1452 s/iter. Total: 0.3060 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:23:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:26.876448 (0.305993 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:23:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.159743 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:23:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:23:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3026979440246221\n",
      "\u001b[32m[02/13 12:23:50 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 2179  total_loss: 1.335  loss_cls: 0.3606  loss_box_reg: 0.5462  loss_mask: 0.2895  loss_rpn_cls: 0.03417  loss_rpn_loc: 0.1053  time: 0.9388  data_time: 0.1871  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:24:09 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 2199  total_loss: 1.443  loss_cls: 0.3769  loss_box_reg: 0.5731  loss_mask: 0.3116  loss_rpn_cls: 0.04401  loss_rpn_loc: 0.1265  time: 0.9389  data_time: 0.2282  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:24:23 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 2219  total_loss: 1.218  loss_cls: 0.3009  loss_box_reg: 0.5531  loss_mask: 0.2835  loss_rpn_cls: 0.02699  loss_rpn_loc: 0.08289  time: 0.9367  data_time: 0.0189  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:24:43 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 2239  total_loss: 1.449  loss_cls: 0.3858  loss_box_reg: 0.5581  loss_mask: 0.2993  loss_rpn_cls: 0.04829  loss_rpn_loc: 0.1252  time: 0.9374  data_time: 0.2756  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:25:01 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 2259  total_loss: 1.317  loss_cls: 0.348  loss_box_reg: 0.5387  loss_mask: 0.2939  loss_rpn_cls: 0.03234  loss_rpn_loc: 0.1023  time: 0.9369  data_time: 0.1799  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:25:19 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 2279  total_loss: 1.363  loss_cls: 0.3476  loss_box_reg: 0.5658  loss_mask: 0.2932  loss_rpn_cls: 0.04271  loss_rpn_loc: 0.1179  time: 0.9364  data_time: 0.1776  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:25:37 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:25:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:25:38 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:25:38 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:25:38 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:25:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:25:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1646 s/iter. Eval: 0.2227 s/iter. Total: 0.3881 s/iter. ETA=0:03:03\n",
      "\u001b[32m[02/13 12:25:48 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1728 s/iter. Total: 0.3345 s/iter. ETA=0:02:32\n",
      "\u001b[32m[02/13 12:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1646 s/iter. Eval: 0.1571 s/iter. Total: 0.3227 s/iter. ETA=0:02:21\n",
      "\u001b[32m[02/13 12:25:59 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1638 s/iter. Eval: 0.1572 s/iter. Total: 0.3220 s/iter. ETA=0:02:16\n",
      "\u001b[32m[02/13 12:26:04 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1606 s/iter. Eval: 0.1461 s/iter. Total: 0.3077 s/iter. ETA=0:02:04\n",
      "\u001b[32m[02/13 12:26:09 d2.evaluation.evaluator]: \u001b[0mInference done 98/485. Dataloading: 0.0009 s/iter. Inference: 0.1610 s/iter. Eval: 0.1401 s/iter. Total: 0.3021 s/iter. ETA=0:01:56\n",
      "\u001b[32m[02/13 12:26:14 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0009 s/iter. Inference: 0.1612 s/iter. Eval: 0.1472 s/iter. Total: 0.3094 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 12:26:19 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0009 s/iter. Inference: 0.1603 s/iter. Eval: 0.1464 s/iter. Total: 0.3077 s/iter. ETA=0:01:49\n",
      "\u001b[32m[02/13 12:26:24 d2.evaluation.evaluator]: \u001b[0mInference done 145/485. Dataloading: 0.0009 s/iter. Inference: 0.1603 s/iter. Eval: 0.1512 s/iter. Total: 0.3125 s/iter. ETA=0:01:46\n",
      "\u001b[32m[02/13 12:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 164/485. Dataloading: 0.0009 s/iter. Inference: 0.1596 s/iter. Eval: 0.1471 s/iter. Total: 0.3077 s/iter. ETA=0:01:38\n",
      "\u001b[32m[02/13 12:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0009 s/iter. Inference: 0.1592 s/iter. Eval: 0.1429 s/iter. Total: 0.3030 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 12:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 199/485. Dataloading: 0.0009 s/iter. Inference: 0.1594 s/iter. Eval: 0.1466 s/iter. Total: 0.3071 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 12:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0009 s/iter. Inference: 0.1591 s/iter. Eval: 0.1457 s/iter. Total: 0.3058 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 12:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 235/485. Dataloading: 0.0009 s/iter. Inference: 0.1587 s/iter. Eval: 0.1441 s/iter. Total: 0.3038 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 12:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0009 s/iter. Inference: 0.1595 s/iter. Eval: 0.1507 s/iter. Total: 0.3113 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 12:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 264/485. Dataloading: 0.0009 s/iter. Inference: 0.1597 s/iter. Eval: 0.1499 s/iter. Total: 0.3106 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 278/485. Dataloading: 0.0009 s/iter. Inference: 0.1602 s/iter. Eval: 0.1525 s/iter. Total: 0.3137 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 12:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0010 s/iter. Inference: 0.1594 s/iter. Eval: 0.1487 s/iter. Total: 0.3090 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1501 s/iter. Total: 0.3110 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 12:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1523 s/iter. Total: 0.3135 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 345/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1517 s/iter. Total: 0.3127 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 12:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 363/485. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1508 s/iter. Total: 0.3114 s/iter. ETA=0:00:37\n",
      "\u001b[32m[02/13 12:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1502 s/iter. Total: 0.3112 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/13 12:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1491 s/iter. Total: 0.3100 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 12:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1489 s/iter. Total: 0.3096 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1498 s/iter. Total: 0.3107 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1507 s/iter. Total: 0.3117 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1480 s/iter. Total: 0.3086 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 12:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1595 s/iter. Eval: 0.1470 s/iter. Total: 0.3075 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:28:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:27.580326 (0.307459 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:28:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.159446 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:28:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:28:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3009826452295788\n",
      "\u001b[32m[02/13 12:28:09 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 2299  total_loss: 1.389  loss_cls: 0.3642  loss_box_reg: 0.5564  loss_mask: 0.3145  loss_rpn_cls: 0.04529  loss_rpn_loc: 0.1049  time: 0.9364  data_time: 0.2074  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:28:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:28:29 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 2319  total_loss: 1.363  loss_cls: 0.3387  loss_box_reg: 0.5677  loss_mask: 0.3096  loss_rpn_cls: 0.03886  loss_rpn_loc: 0.1096  time: 0.9371  data_time: 0.2076  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:28:45 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 2339  total_loss: 1.374  loss_cls: 0.3418  loss_box_reg: 0.5647  loss_mask: 0.2864  loss_rpn_cls: 0.04033  loss_rpn_loc: 0.1184  time: 0.9357  data_time: 0.0862  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:29:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:29:06 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 2359  total_loss: 1.417  loss_cls: 0.3743  loss_box_reg: 0.5477  loss_mask: 0.2908  loss_rpn_cls: 0.04677  loss_rpn_loc: 0.1129  time: 0.9364  data_time: 0.1921  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:29:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:29:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:29:28 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 2379  total_loss: 1.352  loss_cls: 0.3373  loss_box_reg: 0.5403  loss_mask: 0.3041  loss_rpn_cls: 0.03581  loss_rpn_loc: 0.1094  time: 0.9380  data_time: 0.2186  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:29:44 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 2399  total_loss: 1.319  loss_cls: 0.345  loss_box_reg: 0.5475  loss_mask: 0.2814  loss_rpn_cls: 0.02998  loss_rpn_loc: 0.1016  time: 0.9366  data_time: 0.1032  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:29:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:30:05 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:30:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:30:05 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:30:05 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:30:05 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:30:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1655 s/iter. Eval: 0.2248 s/iter. Total: 0.3910 s/iter. ETA=0:03:05\n",
      "\u001b[32m[02/13 12:30:16 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1729 s/iter. Total: 0.3346 s/iter. ETA=0:02:32\n",
      "\u001b[32m[02/13 12:30:21 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1642 s/iter. Eval: 0.1565 s/iter. Total: 0.3216 s/iter. ETA=0:02:21\n",
      "\u001b[32m[02/13 12:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1636 s/iter. Eval: 0.1568 s/iter. Total: 0.3214 s/iter. ETA=0:02:16\n",
      "\u001b[32m[02/13 12:30:31 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1604 s/iter. Eval: 0.1460 s/iter. Total: 0.3075 s/iter. ETA=0:02:04\n",
      "\u001b[32m[02/13 12:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0009 s/iter. Inference: 0.1613 s/iter. Eval: 0.1427 s/iter. Total: 0.3050 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 12:30:42 d2.evaluation.evaluator]: \u001b[0mInference done 113/485. Dataloading: 0.0009 s/iter. Inference: 0.1626 s/iter. Eval: 0.1484 s/iter. Total: 0.3120 s/iter. ETA=0:01:56\n",
      "\u001b[32m[02/13 12:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 130/485. Dataloading: 0.0009 s/iter. Inference: 0.1618 s/iter. Eval: 0.1494 s/iter. Total: 0.3122 s/iter. ETA=0:01:50\n",
      "\u001b[32m[02/13 12:30:52 d2.evaluation.evaluator]: \u001b[0mInference done 146/485. Dataloading: 0.0009 s/iter. Inference: 0.1611 s/iter. Eval: 0.1504 s/iter. Total: 0.3124 s/iter. ETA=0:01:45\n",
      "\u001b[32m[02/13 12:30:57 d2.evaluation.evaluator]: \u001b[0mInference done 165/485. Dataloading: 0.0009 s/iter. Inference: 0.1603 s/iter. Eval: 0.1456 s/iter. Total: 0.3069 s/iter. ETA=0:01:38\n",
      "\u001b[32m[02/13 12:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0009 s/iter. Inference: 0.1598 s/iter. Eval: 0.1420 s/iter. Total: 0.3028 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 12:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 199/485. Dataloading: 0.0009 s/iter. Inference: 0.1600 s/iter. Eval: 0.1458 s/iter. Total: 0.3069 s/iter. ETA=0:01:27\n",
      "\u001b[32m[02/13 12:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0009 s/iter. Inference: 0.1596 s/iter. Eval: 0.1452 s/iter. Total: 0.3058 s/iter. ETA=0:01:21\n",
      "\u001b[32m[02/13 12:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 235/485. Dataloading: 0.0009 s/iter. Inference: 0.1592 s/iter. Eval: 0.1436 s/iter. Total: 0.3038 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 12:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0009 s/iter. Inference: 0.1600 s/iter. Eval: 0.1506 s/iter. Total: 0.3115 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 12:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 264/485. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1498 s/iter. Total: 0.3109 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:31:34 d2.evaluation.evaluator]: \u001b[0mInference done 278/485. Dataloading: 0.0009 s/iter. Inference: 0.1606 s/iter. Eval: 0.1525 s/iter. Total: 0.3141 s/iter. ETA=0:01:05\n",
      "\u001b[32m[02/13 12:31:39 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0009 s/iter. Inference: 0.1597 s/iter. Eval: 0.1487 s/iter. Total: 0.3094 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0009 s/iter. Inference: 0.1602 s/iter. Eval: 0.1502 s/iter. Total: 0.3114 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 12:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0009 s/iter. Inference: 0.1605 s/iter. Eval: 0.1523 s/iter. Total: 0.3138 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 345/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1519 s/iter. Total: 0.3132 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 12:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 362/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1513 s/iter. Total: 0.3123 s/iter. ETA=0:00:38\n",
      "\u001b[32m[02/13 12:32:05 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1503 s/iter. Total: 0.3112 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/13 12:32:10 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1493 s/iter. Total: 0.3102 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 12:32:15 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1492 s/iter. Total: 0.3099 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1501 s/iter. Total: 0.3111 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1510 s/iter. Total: 0.3120 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1483 s/iter. Total: 0.3089 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 12:32:35 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1595 s/iter. Eval: 0.1474 s/iter. Total: 0.3078 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:32:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:27.760020 (0.307833 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:32:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.159438 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:32:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:32:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29965939219604953\n",
      "\u001b[32m[02/13 12:32:36 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 2419  total_loss: 1.373  loss_cls: 0.3767  loss_box_reg: 0.5572  loss_mask: 0.2936  loss_rpn_cls: 0.04183  loss_rpn_loc: 0.1191  time: 0.9373  data_time: 0.1998  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:32:53 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 2439  total_loss: 1.34  loss_cls: 0.3467  loss_box_reg: 0.5337  loss_mask: 0.2865  loss_rpn_cls: 0.04  loss_rpn_loc: 0.1075  time: 0.9368  data_time: 0.1798  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:32:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:33:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:33:16 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 2459  total_loss: 1.374  loss_cls: 0.3678  loss_box_reg: 0.5684  loss_mask: 0.316  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.09925  time: 0.9381  data_time: 0.1997  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:33:34 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 2479  total_loss: 1.23  loss_cls: 0.3078  loss_box_reg: 0.5102  loss_mask: 0.2779  loss_rpn_cls: 0.02989  loss_rpn_loc: 0.1044  time: 0.9381  data_time: 0.2425  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:33:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:33:53 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 2499  total_loss: 1.373  loss_cls: 0.3447  loss_box_reg: 0.5821  loss_mask: 0.3022  loss_rpn_cls: 0.04487  loss_rpn_loc: 0.1124  time: 0.9379  data_time: 0.1205  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:34:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:34:16 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 2519  total_loss: 1.411  loss_cls: 0.3672  loss_box_reg: 0.5667  loss_mask: 0.2968  loss_rpn_cls: 0.04664  loss_rpn_loc: 0.124  time: 0.9397  data_time: 0.3469  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:34:33 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 2539  total_loss: 1.24  loss_cls: 0.3374  loss_box_reg: 0.5148  loss_mask: 0.2796  loss_rpn_cls: 0.03022  loss_rpn_loc: 0.09135  time: 0.9391  data_time: 0.1600  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:34:34 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:34:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:34:35 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:34:35 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:34:35 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:34:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:34:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1636 s/iter. Eval: 0.2147 s/iter. Total: 0.3791 s/iter. ETA=0:02:59\n",
      "\u001b[32m[02/13 12:34:45 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1590 s/iter. Eval: 0.1663 s/iter. Total: 0.3263 s/iter. ETA=0:02:29\n",
      "\u001b[32m[02/13 12:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1617 s/iter. Eval: 0.1502 s/iter. Total: 0.3130 s/iter. ETA=0:02:17\n",
      "\u001b[32m[02/13 12:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1612 s/iter. Eval: 0.1510 s/iter. Total: 0.3132 s/iter. ETA=0:02:12\n",
      "\u001b[32m[02/13 12:35:01 d2.evaluation.evaluator]: \u001b[0mInference done 81/485. Dataloading: 0.0009 s/iter. Inference: 0.1584 s/iter. Eval: 0.1400 s/iter. Total: 0.2994 s/iter. ETA=0:02:00\n",
      "\u001b[32m[02/13 12:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0010 s/iter. Inference: 0.1591 s/iter. Eval: 0.1378 s/iter. Total: 0.2979 s/iter. ETA=0:01:54\n",
      "\u001b[32m[02/13 12:35:11 d2.evaluation.evaluator]: \u001b[0mInference done 114/485. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1428 s/iter. Total: 0.3042 s/iter. ETA=0:01:52\n",
      "\u001b[32m[02/13 12:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 131/485. Dataloading: 0.0010 s/iter. Inference: 0.1593 s/iter. Eval: 0.1434 s/iter. Total: 0.3037 s/iter. ETA=0:01:47\n",
      "\u001b[32m[02/13 12:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 147/485. Dataloading: 0.0010 s/iter. Inference: 0.1592 s/iter. Eval: 0.1479 s/iter. Total: 0.3081 s/iter. ETA=0:01:44\n",
      "\u001b[32m[02/13 12:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 169/485. Dataloading: 0.0010 s/iter. Inference: 0.1582 s/iter. Eval: 0.1398 s/iter. Total: 0.2989 s/iter. ETA=0:01:34\n",
      "\u001b[32m[02/13 12:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 187/485. Dataloading: 0.0010 s/iter. Inference: 0.1580 s/iter. Eval: 0.1396 s/iter. Total: 0.2985 s/iter. ETA=0:01:28\n",
      "\u001b[32m[02/13 12:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 204/485. Dataloading: 0.0010 s/iter. Inference: 0.1579 s/iter. Eval: 0.1410 s/iter. Total: 0.2999 s/iter. ETA=0:01:24\n",
      "\u001b[32m[02/13 12:35:43 d2.evaluation.evaluator]: \u001b[0mInference done 223/485. Dataloading: 0.0010 s/iter. Inference: 0.1573 s/iter. Eval: 0.1388 s/iter. Total: 0.2971 s/iter. ETA=0:01:17\n",
      "\u001b[32m[02/13 12:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 241/485. Dataloading: 0.0010 s/iter. Inference: 0.1569 s/iter. Eval: 0.1382 s/iter. Total: 0.2961 s/iter. ETA=0:01:12\n",
      "\u001b[32m[02/13 12:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 252/485. Dataloading: 0.0010 s/iter. Inference: 0.1581 s/iter. Eval: 0.1451 s/iter. Total: 0.3042 s/iter. ETA=0:01:10\n",
      "\u001b[32m[02/13 12:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 267/485. Dataloading: 0.0010 s/iter. Inference: 0.1583 s/iter. Eval: 0.1468 s/iter. Total: 0.3061 s/iter. ETA=0:01:06\n",
      "\u001b[32m[02/13 12:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 285/485. Dataloading: 0.0010 s/iter. Inference: 0.1583 s/iter. Eval: 0.1463 s/iter. Total: 0.3056 s/iter. ETA=0:01:01\n",
      "\u001b[32m[02/13 12:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 305/485. Dataloading: 0.0010 s/iter. Inference: 0.1577 s/iter. Eval: 0.1438 s/iter. Total: 0.3025 s/iter. ETA=0:00:54\n",
      "\u001b[32m[02/13 12:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 320/485. Dataloading: 0.0010 s/iter. Inference: 0.1580 s/iter. Eval: 0.1452 s/iter. Total: 0.3042 s/iter. ETA=0:00:50\n",
      "\u001b[32m[02/13 12:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 333/485. Dataloading: 0.0010 s/iter. Inference: 0.1586 s/iter. Eval: 0.1486 s/iter. Total: 0.3082 s/iter. ETA=0:00:46\n",
      "\u001b[32m[02/13 12:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 352/485. Dataloading: 0.0010 s/iter. Inference: 0.1582 s/iter. Eval: 0.1472 s/iter. Total: 0.3064 s/iter. ETA=0:00:40\n",
      "\u001b[32m[02/13 12:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 370/485. Dataloading: 0.0010 s/iter. Inference: 0.1578 s/iter. Eval: 0.1463 s/iter. Total: 0.3052 s/iter. ETA=0:00:35\n",
      "\u001b[32m[02/13 12:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 391/485. Dataloading: 0.0010 s/iter. Inference: 0.1576 s/iter. Eval: 0.1435 s/iter. Total: 0.3021 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/13 12:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 409/485. Dataloading: 0.0010 s/iter. Inference: 0.1574 s/iter. Eval: 0.1429 s/iter. Total: 0.3013 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 12:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 423/485. Dataloading: 0.0010 s/iter. Inference: 0.1576 s/iter. Eval: 0.1448 s/iter. Total: 0.3034 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/13 12:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 441/485. Dataloading: 0.0010 s/iter. Inference: 0.1577 s/iter. Eval: 0.1452 s/iter. Total: 0.3039 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 12:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 461/485. Dataloading: 0.0010 s/iter. Inference: 0.1577 s/iter. Eval: 0.1441 s/iter. Total: 0.3028 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/13 12:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 483/485. Dataloading: 0.0010 s/iter. Inference: 0.1572 s/iter. Eval: 0.1413 s/iter. Total: 0.2995 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:37:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:24.185794 (0.300387 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:37:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:15 (0.157261 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:37:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:37:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.303498620763383\n",
      "\u001b[32m[02/13 12:37:21 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 2559  total_loss: 1.33  loss_cls: 0.3417  loss_box_reg: 0.5501  loss_mask: 0.296  loss_rpn_cls: 0.04315  loss_rpn_loc: 0.1138  time: 0.9395  data_time: 0.2738  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:37:36 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 2579  total_loss: 1.309  loss_cls: 0.3392  loss_box_reg: 0.5464  loss_mask: 0.2923  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.09476  time: 0.9378  data_time: 0.0462  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:37:54 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 2599  total_loss: 1.436  loss_cls: 0.3636  loss_box_reg: 0.5751  loss_mask: 0.3092  loss_rpn_cls: 0.04251  loss_rpn_loc: 0.1095  time: 0.9375  data_time: 0.2043  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:37:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:38:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:38:18 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 2619  total_loss: 1.412  loss_cls: 0.3793  loss_box_reg: 0.5402  loss_mask: 0.3068  loss_rpn_cls: 0.04048  loss_rpn_loc: 0.1284  time: 0.9395  data_time: 0.3045  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:38:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:38:36 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 2639  total_loss: 1.427  loss_cls: 0.356  loss_box_reg: 0.5726  loss_mask: 0.2953  loss_rpn_cls: 0.03792  loss_rpn_loc: 0.1076  time: 0.9394  data_time: 0.1073  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:38:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:38:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:38:58 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 2659  total_loss: 1.289  loss_cls: 0.3484  loss_box_reg: 0.5229  loss_mask: 0.2823  loss_rpn_cls: 0.04245  loss_rpn_loc: 0.1094  time: 0.9406  data_time: 0.2101  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:39:02 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:39:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:39:02 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:39:02 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:39:03 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:39:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1658 s/iter. Eval: 0.2239 s/iter. Total: 0.3904 s/iter. ETA=0:03:05\n",
      "\u001b[32m[02/13 12:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1613 s/iter. Eval: 0.1747 s/iter. Total: 0.3369 s/iter. ETA=0:02:33\n",
      "\u001b[32m[02/13 12:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1655 s/iter. Eval: 0.1571 s/iter. Total: 0.3235 s/iter. ETA=0:02:22\n",
      "\u001b[32m[02/13 12:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1645 s/iter. Eval: 0.1579 s/iter. Total: 0.3234 s/iter. ETA=0:02:17\n",
      "\u001b[32m[02/13 12:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1611 s/iter. Eval: 0.1465 s/iter. Total: 0.3086 s/iter. ETA=0:02:04\n",
      "\u001b[32m[02/13 12:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0009 s/iter. Inference: 0.1620 s/iter. Eval: 0.1435 s/iter. Total: 0.3065 s/iter. ETA=0:01:58\n",
      "\u001b[32m[02/13 12:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 114/485. Dataloading: 0.0009 s/iter. Inference: 0.1620 s/iter. Eval: 0.1485 s/iter. Total: 0.3116 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 12:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 130/485. Dataloading: 0.0009 s/iter. Inference: 0.1612 s/iter. Eval: 0.1502 s/iter. Total: 0.3125 s/iter. ETA=0:01:50\n",
      "\u001b[32m[02/13 12:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 146/485. Dataloading: 0.0009 s/iter. Inference: 0.1605 s/iter. Eval: 0.1513 s/iter. Total: 0.3128 s/iter. ETA=0:01:46\n",
      "\u001b[32m[02/13 12:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 165/485. Dataloading: 0.0009 s/iter. Inference: 0.1598 s/iter. Eval: 0.1469 s/iter. Total: 0.3077 s/iter. ETA=0:01:38\n",
      "\u001b[32m[02/13 12:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0009 s/iter. Inference: 0.1594 s/iter. Eval: 0.1435 s/iter. Total: 0.3038 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 12:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 198/485. Dataloading: 0.0009 s/iter. Inference: 0.1595 s/iter. Eval: 0.1473 s/iter. Total: 0.3078 s/iter. ETA=0:01:28\n",
      "\u001b[32m[02/13 12:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0009 s/iter. Inference: 0.1593 s/iter. Eval: 0.1466 s/iter. Total: 0.3069 s/iter. ETA=0:01:22\n",
      "\u001b[32m[02/13 12:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 235/485. Dataloading: 0.0010 s/iter. Inference: 0.1589 s/iter. Eval: 0.1449 s/iter. Total: 0.3048 s/iter. ETA=0:01:16\n",
      "\u001b[32m[02/13 12:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1518 s/iter. Total: 0.3125 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 12:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 264/485. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1510 s/iter. Total: 0.3119 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 278/485. Dataloading: 0.0010 s/iter. Inference: 0.1604 s/iter. Eval: 0.1537 s/iter. Total: 0.3151 s/iter. ETA=0:01:05\n",
      "\u001b[32m[02/13 12:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0009 s/iter. Inference: 0.1595 s/iter. Eval: 0.1498 s/iter. Total: 0.3102 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1513 s/iter. Total: 0.3122 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 12:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1535 s/iter. Total: 0.3148 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 345/485. Dataloading: 0.0010 s/iter. Inference: 0.1601 s/iter. Eval: 0.1529 s/iter. Total: 0.3140 s/iter. ETA=0:00:43\n",
      "\u001b[32m[02/13 12:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 362/485. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1523 s/iter. Total: 0.3131 s/iter. ETA=0:00:38\n",
      "\u001b[32m[02/13 12:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 379/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1516 s/iter. Total: 0.3123 s/iter. ETA=0:00:33\n",
      "\u001b[32m[02/13 12:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1503 s/iter. Total: 0.3110 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/13 12:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1595 s/iter. Eval: 0.1501 s/iter. Total: 0.3106 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:41:18 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1510 s/iter. Total: 0.3118 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1519 s/iter. Total: 0.3127 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0010 s/iter. Inference: 0.1594 s/iter. Eval: 0.1492 s/iter. Total: 0.3095 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 12:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1593 s/iter. Eval: 0.1482 s/iter. Total: 0.3085 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:41:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:28.055326 (0.308449 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:41:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.159236 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:41:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:41:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3011516007045841\n",
      "\u001b[32m[02/13 12:41:47 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 2679  total_loss: 1.353  loss_cls: 0.3351  loss_box_reg: 0.5531  loss_mask: 0.3041  loss_rpn_cls: 0.03692  loss_rpn_loc: 0.1093  time: 0.9398  data_time: 0.1341  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:42:09 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 2699  total_loss: 1.36  loss_cls: 0.3503  loss_box_reg: 0.527  loss_mask: 0.2946  loss_rpn_cls: 0.04025  loss_rpn_loc: 0.1115  time: 0.9407  data_time: 0.3276  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:42:26 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 2719  total_loss: 1.306  loss_cls: 0.3295  loss_box_reg: 0.5426  loss_mask: 0.2885  loss_rpn_cls: 0.03491  loss_rpn_loc: 0.1072  time: 0.9403  data_time: 0.1844  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:42:43 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 2739  total_loss: 1.282  loss_cls: 0.3434  loss_box_reg: 0.5485  loss_mask: 0.3073  loss_rpn_cls: 0.04237  loss_rpn_loc: 0.0955  time: 0.9397  data_time: 0.1587  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:43:04 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 2759  total_loss: 1.431  loss_cls: 0.378  loss_box_reg: 0.5881  loss_mask: 0.306  loss_rpn_cls: 0.04641  loss_rpn_loc: 0.1194  time: 0.9404  data_time: 0.3114  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:43:21 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2779  total_loss: 1.281  loss_cls: 0.3287  loss_box_reg: 0.5144  loss_mask: 0.2807  loss_rpn_cls: 0.03859  loss_rpn_loc: 0.09915  time: 0.9395  data_time: 0.1127  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:43:25 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:43:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:43:25 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:43:25 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:43:26 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:43:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1634 s/iter. Eval: 0.2169 s/iter. Total: 0.3811 s/iter. ETA=0:03:00\n",
      "\u001b[32m[02/13 12:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1589 s/iter. Eval: 0.1674 s/iter. Total: 0.3272 s/iter. ETA=0:02:29\n",
      "\u001b[32m[02/13 12:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1620 s/iter. Eval: 0.1509 s/iter. Total: 0.3138 s/iter. ETA=0:02:18\n",
      "\u001b[32m[02/13 12:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1612 s/iter. Eval: 0.1517 s/iter. Total: 0.3139 s/iter. ETA=0:02:13\n",
      "\u001b[32m[02/13 12:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 81/485. Dataloading: 0.0009 s/iter. Inference: 0.1583 s/iter. Eval: 0.1410 s/iter. Total: 0.3003 s/iter. ETA=0:02:01\n",
      "\u001b[32m[02/13 12:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 99/485. Dataloading: 0.0009 s/iter. Inference: 0.1591 s/iter. Eval: 0.1386 s/iter. Total: 0.2988 s/iter. ETA=0:01:55\n",
      "\u001b[32m[02/13 12:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 114/485. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1443 s/iter. Total: 0.3053 s/iter. ETA=0:01:53\n",
      "\u001b[32m[02/13 12:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 131/485. Dataloading: 0.0009 s/iter. Inference: 0.1589 s/iter. Eval: 0.1451 s/iter. Total: 0.3050 s/iter. ETA=0:01:47\n",
      "\u001b[32m[02/13 12:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 147/485. Dataloading: 0.0009 s/iter. Inference: 0.1590 s/iter. Eval: 0.1504 s/iter. Total: 0.3104 s/iter. ETA=0:01:44\n",
      "\u001b[32m[02/13 12:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 168/485. Dataloading: 0.0010 s/iter. Inference: 0.1587 s/iter. Eval: 0.1424 s/iter. Total: 0.3021 s/iter. ETA=0:01:35\n",
      "\u001b[32m[02/13 12:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 185/485. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1437 s/iter. Total: 0.3044 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 12:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 202/485. Dataloading: 0.0010 s/iter. Inference: 0.1595 s/iter. Eval: 0.1435 s/iter. Total: 0.3040 s/iter. ETA=0:01:26\n",
      "\u001b[32m[02/13 12:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 219/485. Dataloading: 0.0010 s/iter. Inference: 0.1591 s/iter. Eval: 0.1435 s/iter. Total: 0.3036 s/iter. ETA=0:01:20\n",
      "\u001b[32m[02/13 12:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 237/485. Dataloading: 0.0010 s/iter. Inference: 0.1589 s/iter. Eval: 0.1436 s/iter. Total: 0.3035 s/iter. ETA=0:01:15\n",
      "\u001b[32m[02/13 12:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 248/485. Dataloading: 0.0010 s/iter. Inference: 0.1600 s/iter. Eval: 0.1498 s/iter. Total: 0.3109 s/iter. ETA=0:01:13\n",
      "\u001b[32m[02/13 12:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 265/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1501 s/iter. Total: 0.3113 s/iter. ETA=0:01:08\n",
      "\u001b[32m[02/13 12:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 280/485. Dataloading: 0.0010 s/iter. Inference: 0.1608 s/iter. Eval: 0.1510 s/iter. Total: 0.3128 s/iter. ETA=0:01:04\n",
      "\u001b[32m[02/13 12:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 300/485. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1479 s/iter. Total: 0.3091 s/iter. ETA=0:00:57\n",
      "\u001b[32m[02/13 12:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 314/485. Dataloading: 0.0010 s/iter. Inference: 0.1613 s/iter. Eval: 0.1502 s/iter. Total: 0.3125 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 12:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 328/485. Dataloading: 0.0010 s/iter. Inference: 0.1617 s/iter. Eval: 0.1523 s/iter. Total: 0.3150 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 343/485. Dataloading: 0.0010 s/iter. Inference: 0.1619 s/iter. Eval: 0.1530 s/iter. Total: 0.3159 s/iter. ETA=0:00:44\n",
      "\u001b[32m[02/13 12:45:21 d2.evaluation.evaluator]: \u001b[0mInference done 362/485. Dataloading: 0.0010 s/iter. Inference: 0.1617 s/iter. Eval: 0.1521 s/iter. Total: 0.3149 s/iter. ETA=0:00:38\n",
      "\u001b[32m[02/13 12:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 380/485. Dataloading: 0.0010 s/iter. Inference: 0.1615 s/iter. Eval: 0.1509 s/iter. Total: 0.3135 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/13 12:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1613 s/iter. Eval: 0.1498 s/iter. Total: 0.3121 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/13 12:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1611 s/iter. Eval: 0.1494 s/iter. Total: 0.3115 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 430/485. Dataloading: 0.0010 s/iter. Inference: 0.1612 s/iter. Eval: 0.1502 s/iter. Total: 0.3123 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 445/485. Dataloading: 0.0010 s/iter. Inference: 0.1611 s/iter. Eval: 0.1510 s/iter. Total: 0.3132 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 466/485. Dataloading: 0.0010 s/iter. Inference: 0.1606 s/iter. Eval: 0.1482 s/iter. Total: 0.3099 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 12:45:56 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1472 s/iter. Total: 0.3087 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:45:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:28.160840 (0.308668 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:45:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.160400 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:45:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:45:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3024971141001381\n",
      "\u001b[32m[02/13 12:46:11 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 2799  total_loss: 1.408  loss_cls: 0.3536  loss_box_reg: 0.5702  loss_mask: 0.2917  loss_rpn_cls: 0.04452  loss_rpn_loc: 0.1211  time: 0.9392  data_time: 0.1808  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:46:26 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 2819  total_loss: 1.367  loss_cls: 0.3375  loss_box_reg: 0.5383  loss_mask: 0.2955  loss_rpn_cls: 0.02973  loss_rpn_loc: 0.08737  time: 0.9380  data_time: 0.0954  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:46:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:46:50 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 2839  total_loss: 1.382  loss_cls: 0.3616  loss_box_reg: 0.5687  loss_mask: 0.2976  loss_rpn_cls: 0.05305  loss_rpn_loc: 0.1179  time: 0.9397  data_time: 0.3411  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:47:08 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 2859  total_loss: 1.314  loss_cls: 0.3437  loss_box_reg: 0.5469  loss_mask: 0.2819  loss_rpn_cls: 0.03879  loss_rpn_loc: 0.1175  time: 0.9394  data_time: 0.1977  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:47:26 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 2879  total_loss: 1.292  loss_cls: 0.3348  loss_box_reg: 0.5101  loss_mask: 0.2877  loss_rpn_cls: 0.03941  loss_rpn_loc: 0.1105  time: 0.9390  data_time: 0.1747  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:47:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:47:46 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 2899  total_loss: 1.316  loss_cls: 0.3459  loss_box_reg: 0.5515  loss_mask: 0.3017  loss_rpn_cls: 0.04172  loss_rpn_loc: 0.1171  time: 0.9396  data_time: 0.2327  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:47:50 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:47:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:47:50 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:47:50 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:47:51 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:47:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0007 s/iter. Inference: 0.1657 s/iter. Eval: 0.2242 s/iter. Total: 0.3905 s/iter. ETA=0:03:05\n",
      "\u001b[32m[02/13 12:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1620 s/iter. Eval: 0.1740 s/iter. Total: 0.3370 s/iter. ETA=0:02:33\n",
      "\u001b[32m[02/13 12:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1653 s/iter. Eval: 0.1572 s/iter. Total: 0.3235 s/iter. ETA=0:02:22\n",
      "\u001b[32m[02/13 12:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1647 s/iter. Eval: 0.1579 s/iter. Total: 0.3235 s/iter. ETA=0:02:17\n",
      "\u001b[32m[02/13 12:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1613 s/iter. Eval: 0.1471 s/iter. Total: 0.3093 s/iter. ETA=0:02:05\n",
      "\u001b[32m[02/13 12:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 98/485. Dataloading: 0.0009 s/iter. Inference: 0.1617 s/iter. Eval: 0.1406 s/iter. Total: 0.3032 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 12:48:27 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0009 s/iter. Inference: 0.1633 s/iter. Eval: 0.1483 s/iter. Total: 0.3126 s/iter. ETA=0:01:56\n",
      "\u001b[32m[02/13 12:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0009 s/iter. Inference: 0.1623 s/iter. Eval: 0.1478 s/iter. Total: 0.3111 s/iter. ETA=0:01:50\n",
      "\u001b[32m[02/13 12:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 145/485. Dataloading: 0.0009 s/iter. Inference: 0.1621 s/iter. Eval: 0.1528 s/iter. Total: 0.3159 s/iter. ETA=0:01:47\n",
      "\u001b[32m[02/13 12:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 164/485. Dataloading: 0.0009 s/iter. Inference: 0.1614 s/iter. Eval: 0.1485 s/iter. Total: 0.3110 s/iter. ETA=0:01:39\n",
      "\u001b[32m[02/13 12:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1441 s/iter. Total: 0.3059 s/iter. ETA=0:01:32\n",
      "\u001b[32m[02/13 12:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 198/485. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1484 s/iter. Total: 0.3102 s/iter. ETA=0:01:29\n",
      "\u001b[32m[02/13 12:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 216/485. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1462 s/iter. Total: 0.3077 s/iter. ETA=0:01:22\n",
      "\u001b[32m[02/13 12:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 231/485. Dataloading: 0.0010 s/iter. Inference: 0.1606 s/iter. Eval: 0.1480 s/iter. Total: 0.3096 s/iter. ETA=0:01:18\n",
      "\u001b[32m[02/13 12:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 246/485. Dataloading: 0.0010 s/iter. Inference: 0.1608 s/iter. Eval: 0.1515 s/iter. Total: 0.3133 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 12:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 260/485. Dataloading: 0.0010 s/iter. Inference: 0.1615 s/iter. Eval: 0.1539 s/iter. Total: 0.3164 s/iter. ETA=0:01:11\n",
      "\u001b[32m[02/13 12:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 276/485. Dataloading: 0.0010 s/iter. Inference: 0.1615 s/iter. Eval: 0.1541 s/iter. Total: 0.3166 s/iter. ETA=0:01:06\n",
      "\u001b[32m[02/13 12:49:24 d2.evaluation.evaluator]: \u001b[0mInference done 295/485. Dataloading: 0.0010 s/iter. Inference: 0.1607 s/iter. Eval: 0.1514 s/iter. Total: 0.3132 s/iter. ETA=0:00:59\n",
      "\u001b[32m[02/13 12:49:29 d2.evaluation.evaluator]: \u001b[0mInference done 310/485. Dataloading: 0.0010 s/iter. Inference: 0.1611 s/iter. Eval: 0.1523 s/iter. Total: 0.3144 s/iter. ETA=0:00:55\n",
      "\u001b[32m[02/13 12:49:34 d2.evaluation.evaluator]: \u001b[0mInference done 324/485. Dataloading: 0.0010 s/iter. Inference: 0.1615 s/iter. Eval: 0.1543 s/iter. Total: 0.3168 s/iter. ETA=0:00:51\n",
      "\u001b[32m[02/13 12:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 339/485. Dataloading: 0.0010 s/iter. Inference: 0.1618 s/iter. Eval: 0.1560 s/iter. Total: 0.3189 s/iter. ETA=0:00:46\n",
      "\u001b[32m[02/13 12:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 359/485. Dataloading: 0.0010 s/iter. Inference: 0.1610 s/iter. Eval: 0.1532 s/iter. Total: 0.3152 s/iter. ETA=0:00:39\n",
      "\u001b[32m[02/13 12:49:50 d2.evaluation.evaluator]: \u001b[0mInference done 375/485. Dataloading: 0.0010 s/iter. Inference: 0.1610 s/iter. Eval: 0.1534 s/iter. Total: 0.3154 s/iter. ETA=0:00:34\n",
      "\u001b[32m[02/13 12:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 395/485. Dataloading: 0.0010 s/iter. Inference: 0.1607 s/iter. Eval: 0.1506 s/iter. Total: 0.3123 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/13 12:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 412/485. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1502 s/iter. Total: 0.3117 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 12:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 426/485. Dataloading: 0.0010 s/iter. Inference: 0.1607 s/iter. Eval: 0.1520 s/iter. Total: 0.3137 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/13 12:50:10 d2.evaluation.evaluator]: \u001b[0mInference done 442/485. Dataloading: 0.0010 s/iter. Inference: 0.1607 s/iter. Eval: 0.1521 s/iter. Total: 0.3138 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 12:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 461/485. Dataloading: 0.0010 s/iter. Inference: 0.1607 s/iter. Eval: 0.1512 s/iter. Total: 0.3129 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/13 12:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 483/485. Dataloading: 0.0010 s/iter. Inference: 0.1603 s/iter. Eval: 0.1482 s/iter. Total: 0.3095 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:50:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:28.967947 (0.310350 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:50:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.160300 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:50:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:50:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3010007542033179\n",
      "\u001b[32m[02/13 12:50:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:50:40 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 2919  total_loss: 1.446  loss_cls: 0.3676  loss_box_reg: 0.5862  loss_mask: 0.3103  loss_rpn_cls: 0.04601  loss_rpn_loc: 0.1299  time: 0.9401  data_time: 0.1942  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:50:58 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 2939  total_loss: 1.329  loss_cls: 0.3376  loss_box_reg: 0.5334  loss_mask: 0.3019  loss_rpn_cls: 0.04791  loss_rpn_loc: 0.1114  time: 0.9401  data_time: 0.2204  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:51:15 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 2959  total_loss: 1.318  loss_cls: 0.3326  loss_box_reg: 0.5283  loss_mask: 0.288  loss_rpn_cls: 0.03893  loss_rpn_loc: 0.1039  time: 0.9393  data_time: 0.1369  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:51:31 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 2979  total_loss: 1.279  loss_cls: 0.35  loss_box_reg: 0.5201  loss_mask: 0.2841  loss_rpn_cls: 0.03384  loss_rpn_loc: 0.09614  time: 0.9383  data_time: 0.0592  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:51:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f1d0fede310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 12:51:54 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 1.464  loss_cls: 0.387  loss_box_reg: 0.5421  loss_mask: 0.2946  loss_rpn_cls: 0.04484  loss_rpn_loc: 0.1147  time: 0.9398  data_time: 0.2955  lr: 0.000128  max_mem: 9220M\n",
      "\u001b[32m[02/13 12:51:54 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:46:57 (0.9398 s / it)\n",
      "\u001b[32m[02/13 12:51:54 d2.engine.hooks]: \u001b[0mTotal training time: 1:48:36 (1:01:39 on hooks)\n",
      "\u001b[32m[02/13 12:51:55 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:51:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 12:51:56 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 12:51:56 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 12:51:56 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 12:51:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n",
      "\u001b[32m[02/13 12:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0008 s/iter. Inference: 0.1662 s/iter. Eval: 0.2176 s/iter. Total: 0.3846 s/iter. ETA=0:03:02\n",
      "\u001b[32m[02/13 12:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 28/485. Dataloading: 0.0009 s/iter. Inference: 0.1627 s/iter. Eval: 0.1696 s/iter. Total: 0.3333 s/iter. ETA=0:02:32\n",
      "\u001b[32m[02/13 12:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 45/485. Dataloading: 0.0009 s/iter. Inference: 0.1660 s/iter. Eval: 0.1548 s/iter. Total: 0.3218 s/iter. ETA=0:02:21\n",
      "\u001b[32m[02/13 12:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0009 s/iter. Inference: 0.1660 s/iter. Eval: 0.1558 s/iter. Total: 0.3228 s/iter. ETA=0:02:16\n",
      "\u001b[32m[02/13 12:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 80/485. Dataloading: 0.0009 s/iter. Inference: 0.1627 s/iter. Eval: 0.1455 s/iter. Total: 0.3092 s/iter. ETA=0:02:05\n",
      "\u001b[32m[02/13 12:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 98/485. Dataloading: 0.0009 s/iter. Inference: 0.1634 s/iter. Eval: 0.1397 s/iter. Total: 0.3041 s/iter. ETA=0:01:57\n",
      "\u001b[32m[02/13 12:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 112/485. Dataloading: 0.0009 s/iter. Inference: 0.1636 s/iter. Eval: 0.1468 s/iter. Total: 0.3114 s/iter. ETA=0:01:56\n",
      "\u001b[32m[02/13 12:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 129/485. Dataloading: 0.0009 s/iter. Inference: 0.1626 s/iter. Eval: 0.1458 s/iter. Total: 0.3094 s/iter. ETA=0:01:50\n",
      "\u001b[32m[02/13 12:52:43 d2.evaluation.evaluator]: \u001b[0mInference done 145/485. Dataloading: 0.0009 s/iter. Inference: 0.1624 s/iter. Eval: 0.1505 s/iter. Total: 0.3139 s/iter. ETA=0:01:46\n",
      "\u001b[32m[02/13 12:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 164/485. Dataloading: 0.0009 s/iter. Inference: 0.1619 s/iter. Eval: 0.1465 s/iter. Total: 0.3094 s/iter. ETA=0:01:39\n",
      "\u001b[32m[02/13 12:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 184/485. Dataloading: 0.0009 s/iter. Inference: 0.1613 s/iter. Eval: 0.1421 s/iter. Total: 0.3044 s/iter. ETA=0:01:31\n",
      "\u001b[32m[02/13 12:52:59 d2.evaluation.evaluator]: \u001b[0mInference done 199/485. Dataloading: 0.0009 s/iter. Inference: 0.1615 s/iter. Eval: 0.1459 s/iter. Total: 0.3084 s/iter. ETA=0:01:28\n",
      "\u001b[32m[02/13 12:53:04 d2.evaluation.evaluator]: \u001b[0mInference done 217/485. Dataloading: 0.0009 s/iter. Inference: 0.1611 s/iter. Eval: 0.1449 s/iter. Total: 0.3070 s/iter. ETA=0:01:22\n",
      "\u001b[32m[02/13 12:53:09 d2.evaluation.evaluator]: \u001b[0mInference done 235/485. Dataloading: 0.0009 s/iter. Inference: 0.1607 s/iter. Eval: 0.1432 s/iter. Total: 0.3049 s/iter. ETA=0:01:16\n",
      "\u001b[32m[02/13 12:53:15 d2.evaluation.evaluator]: \u001b[0mInference done 247/485. Dataloading: 0.0009 s/iter. Inference: 0.1620 s/iter. Eval: 0.1501 s/iter. Total: 0.3130 s/iter. ETA=0:01:14\n",
      "\u001b[32m[02/13 12:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 263/485. Dataloading: 0.0009 s/iter. Inference: 0.1623 s/iter. Eval: 0.1499 s/iter. Total: 0.3133 s/iter. ETA=0:01:09\n",
      "\u001b[32m[02/13 12:53:25 d2.evaluation.evaluator]: \u001b[0mInference done 277/485. Dataloading: 0.0010 s/iter. Inference: 0.1627 s/iter. Eval: 0.1522 s/iter. Total: 0.3160 s/iter. ETA=0:01:05\n",
      "\u001b[32m[02/13 12:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 298/485. Dataloading: 0.0010 s/iter. Inference: 0.1618 s/iter. Eval: 0.1478 s/iter. Total: 0.3106 s/iter. ETA=0:00:58\n",
      "\u001b[32m[02/13 12:53:35 d2.evaluation.evaluator]: \u001b[0mInference done 313/485. Dataloading: 0.0010 s/iter. Inference: 0.1624 s/iter. Eval: 0.1491 s/iter. Total: 0.3125 s/iter. ETA=0:00:53\n",
      "\u001b[32m[02/13 12:53:41 d2.evaluation.evaluator]: \u001b[0mInference done 327/485. Dataloading: 0.0010 s/iter. Inference: 0.1629 s/iter. Eval: 0.1524 s/iter. Total: 0.3163 s/iter. ETA=0:00:49\n",
      "\u001b[32m[02/13 12:53:46 d2.evaluation.evaluator]: \u001b[0mInference done 343/485. Dataloading: 0.0010 s/iter. Inference: 0.1632 s/iter. Eval: 0.1523 s/iter. Total: 0.3165 s/iter. ETA=0:00:44\n",
      "\u001b[32m[02/13 12:53:51 d2.evaluation.evaluator]: \u001b[0mInference done 362/485. Dataloading: 0.0010 s/iter. Inference: 0.1627 s/iter. Eval: 0.1510 s/iter. Total: 0.3147 s/iter. ETA=0:00:38\n",
      "\u001b[32m[02/13 12:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 379/485. Dataloading: 0.0010 s/iter. Inference: 0.1626 s/iter. Eval: 0.1502 s/iter. Total: 0.3138 s/iter. ETA=0:00:33\n",
      "\u001b[32m[02/13 12:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 398/485. Dataloading: 0.0010 s/iter. Inference: 0.1624 s/iter. Eval: 0.1490 s/iter. Total: 0.3125 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/13 12:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 415/485. Dataloading: 0.0010 s/iter. Inference: 0.1622 s/iter. Eval: 0.1487 s/iter. Total: 0.3120 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 12:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 429/485. Dataloading: 0.0010 s/iter. Inference: 0.1626 s/iter. Eval: 0.1503 s/iter. Total: 0.3140 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 12:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 444/485. Dataloading: 0.0010 s/iter. Inference: 0.1628 s/iter. Eval: 0.1516 s/iter. Total: 0.3154 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 12:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 465/485. Dataloading: 0.0010 s/iter. Inference: 0.1624 s/iter. Eval: 0.1488 s/iter. Total: 0.3123 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/13 12:54:28 d2.evaluation.evaluator]: \u001b[0mInference done 484/485. Dataloading: 0.0010 s/iter. Inference: 0.1622 s/iter. Eval: 0.1476 s/iter. Total: 0.3108 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 12:54:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:29.184100 (0.310800 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:54:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:17 (0.162181 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 12:54:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 12:54:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3016170889677091\n"
     ]
    }
   ],
   "source": [
    "# train on validation set\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.INPUT.MIN_SIZE_TEST = 1024\n",
    "cfg.INPUT.MAX_SIZE_TEST = 3000\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_10.2/model_0009679.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0002\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "cfg.SOLVER.STEPS = list(range(1000,3000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 4000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24], [40], [80], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 3.0]]\n",
    "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.7]\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.75\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.03\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 700\n",
    "cfg.TEST.EVAL_PERIOD = 2*len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_11.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb93523-8094-4ba7-98b7-44e498eb5cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/13 13:03:09 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 13:03:10 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 13:03:13 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/13 13:03:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomContrast(intensity_min=0.95, intensity_max=1.05), RandomBrightness(intensity_min=0.95, intensity_max=1.05), RandomFlip(prob=0.5), RandomFlip(prob=0.5, horizontal=False, vertical=True), ResizeShortestEdge(short_edge_length=(832, 864, 896, 928, 960, 992, 1024), max_size=9999, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:03:13 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/13 13:03:13 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/13 13:03:13 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/13 13:03:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/13 13:03:13 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:03:14 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[02/13 13:03:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/13 13:03:33 d2.utils.events]: \u001b[0m eta: 1:56:50  iter: 19  total_loss: 1.251  loss_cls: 0.3154  loss_box_reg: 0.4978  loss_mask: 0.2924  loss_rpn_cls: 0.03218  loss_rpn_loc: 0.106  time: 0.8024  data_time: 0.2694  lr: 1.9981e-06  max_mem: 8018M\n",
      "\u001b[32m[02/13 13:03:50 d2.utils.events]: \u001b[0m eta: 1:53:56  iter: 39  total_loss: 1.265  loss_cls: 0.3243  loss_box_reg: 0.5256  loss_mask: 0.2806  loss_rpn_cls: 0.03559  loss_rpn_loc: 0.09594  time: 0.8130  data_time: 0.1411  lr: 3.9961e-06  max_mem: 8018M\n",
      "\u001b[32m[02/13 13:03:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:04:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:04:13 d2.utils.events]: \u001b[0m eta: 1:58:03  iter: 59  total_loss: 1.359  loss_cls: 0.341  loss_box_reg: 0.563  loss_mask: 0.2898  loss_rpn_cls: 0.04548  loss_rpn_loc: 0.1179  time: 0.9290  data_time: 0.1899  lr: 5.9941e-06  max_mem: 8018M\n",
      "\u001b[32m[02/13 13:04:29 d2.utils.events]: \u001b[0m eta: 1:56:57  iter: 79  total_loss: 1.347  loss_cls: 0.3373  loss_box_reg: 0.541  loss_mask: 0.2954  loss_rpn_cls: 0.04117  loss_rpn_loc: 0.1138  time: 0.8943  data_time: 0.1303  lr: 7.9921e-06  max_mem: 8018M\n",
      "\u001b[32m[02/13 13:04:49 d2.utils.events]: \u001b[0m eta: 1:59:16  iter: 99  total_loss: 1.422  loss_cls: 0.3689  loss_box_reg: 0.5521  loss_mask: 0.3077  loss_rpn_cls: 0.06128  loss_rpn_loc: 0.113  time: 0.9140  data_time: 0.2217  lr: 9.9901e-06  max_mem: 8252M\n",
      "\u001b[32m[02/13 13:05:06 d2.utils.events]: \u001b[0m eta: 2:01:05  iter: 119  total_loss: 1.332  loss_cls: 0.3385  loss_box_reg: 0.5603  loss_mask: 0.2994  loss_rpn_cls: 0.03983  loss_rpn_loc: 0.1178  time: 0.9088  data_time: 0.1214  lr: 1.1988e-05  max_mem: 8252M\n",
      "\u001b[32m[02/13 13:05:26 d2.utils.events]: \u001b[0m eta: 2:03:24  iter: 139  total_loss: 1.348  loss_cls: 0.3511  loss_box_reg: 0.5338  loss_mask: 0.2779  loss_rpn_cls: 0.04689  loss_rpn_loc: 0.1101  time: 0.9186  data_time: 0.2275  lr: 1.3986e-05  max_mem: 8252M\n",
      "\u001b[32m[02/13 13:05:46 d2.utils.events]: \u001b[0m eta: 2:04:16  iter: 159  total_loss: 1.362  loss_cls: 0.3597  loss_box_reg: 0.5317  loss_mask: 0.2887  loss_rpn_cls: 0.0516  loss_rpn_loc: 0.1221  time: 0.9270  data_time: 0.2454  lr: 1.5984e-05  max_mem: 8252M\n",
      "\u001b[32m[02/13 13:06:02 d2.utils.events]: \u001b[0m eta: 2:04:23  iter: 179  total_loss: 1.314  loss_cls: 0.3437  loss_box_reg: 0.5473  loss_mask: 0.2971  loss_rpn_cls: 0.04851  loss_rpn_loc: 0.1184  time: 0.9170  data_time: 0.0965  lr: 1.7982e-05  max_mem: 8252M\n",
      "\u001b[32m[02/13 13:06:22 d2.utils.events]: \u001b[0m eta: 2:04:43  iter: 199  total_loss: 1.383  loss_cls: 0.365  loss_box_reg: 0.5454  loss_mask: 0.2817  loss_rpn_cls: 0.05569  loss_rpn_loc: 0.1159  time: 0.9252  data_time: 0.2342  lr: 1.998e-05  max_mem: 8252M\n",
      "\u001b[32m[02/13 13:06:39 d2.utils.events]: \u001b[0m eta: 2:04:27  iter: 219  total_loss: 1.334  loss_cls: 0.3438  loss_box_reg: 0.532  loss_mask: 0.2921  loss_rpn_cls: 0.04241  loss_rpn_loc: 0.1052  time: 0.9172  data_time: 0.1112  lr: 2.1978e-05  max_mem: 8252M\n",
      "\u001b[32m[02/13 13:06:56 d2.utils.events]: \u001b[0m eta: 2:03:55  iter: 239  total_loss: 1.296  loss_cls: 0.3422  loss_box_reg: 0.5369  loss_mask: 0.2904  loss_rpn_cls: 0.04051  loss_rpn_loc: 0.09871  time: 0.9127  data_time: 0.1302  lr: 2.3976e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:06:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:06:58 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/13 13:06:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:06:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:06:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:06:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:06:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1541 s/iter. Eval: 0.0537 s/iter. Total: 0.2085 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0009 s/iter. Inference: 0.1644 s/iter. Eval: 0.1247 s/iter. Total: 0.2900 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/13 13:07:12 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0010 s/iter. Inference: 0.1659 s/iter. Eval: 0.1366 s/iter. Total: 0.3035 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 13:07:17 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0010 s/iter. Inference: 0.1643 s/iter. Eval: 0.1334 s/iter. Total: 0.2988 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 13:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0010 s/iter. Inference: 0.1664 s/iter. Eval: 0.1456 s/iter. Total: 0.3130 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 13:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0010 s/iter. Inference: 0.1701 s/iter. Eval: 0.1587 s/iter. Total: 0.3299 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/13 13:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0010 s/iter. Inference: 0.1692 s/iter. Eval: 0.1624 s/iter. Total: 0.3327 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 13:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0010 s/iter. Inference: 0.1684 s/iter. Eval: 0.1572 s/iter. Total: 0.3267 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 13:07:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.955267 (0.327201 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:07:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.168431 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:07:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:07:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3062732650427011\n",
      "\u001b[32m[02/13 13:07:53 d2.utils.events]: \u001b[0m eta: 2:03:22  iter: 259  total_loss: 1.244  loss_cls: 0.3296  loss_box_reg: 0.5285  loss_mask: 0.2812  loss_rpn_cls: 0.02306  loss_rpn_loc: 0.07595  time: 0.9046  data_time: 0.0900  lr: 2.5974e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:08:12 d2.utils.events]: \u001b[0m eta: 2:03:24  iter: 279  total_loss: 1.23  loss_cls: 0.3269  loss_box_reg: 0.5134  loss_mask: 0.2899  loss_rpn_cls: 0.03228  loss_rpn_loc: 0.09228  time: 0.9107  data_time: 0.2154  lr: 2.7972e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:08:31 d2.utils.events]: \u001b[0m eta: 2:02:52  iter: 299  total_loss: 1.366  loss_cls: 0.3507  loss_box_reg: 0.539  loss_mask: 0.2921  loss_rpn_cls: 0.03806  loss_rpn_loc: 0.09863  time: 0.9102  data_time: 0.1910  lr: 2.997e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:08:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:08:50 d2.utils.events]: \u001b[0m eta: 2:02:37  iter: 319  total_loss: 1.392  loss_cls: 0.3585  loss_box_reg: 0.5564  loss_mask: 0.295  loss_rpn_cls: 0.04677  loss_rpn_loc: 0.1178  time: 0.9147  data_time: 0.1851  lr: 3.1968e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:09:05 d2.utils.events]: \u001b[0m eta: 2:02:09  iter: 339  total_loss: 1.332  loss_cls: 0.3446  loss_box_reg: 0.5369  loss_mask: 0.2903  loss_rpn_cls: 0.03938  loss_rpn_loc: 0.115  time: 0.9045  data_time: 0.0550  lr: 3.3966e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:09:20 d2.utils.events]: \u001b[0m eta: 2:01:17  iter: 359  total_loss: 1.313  loss_cls: 0.333  loss_box_reg: 0.5138  loss_mask: 0.2756  loss_rpn_cls: 0.03616  loss_rpn_loc: 0.0964  time: 0.8961  data_time: 0.0595  lr: 3.5964e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:09:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:09:42 d2.utils.events]: \u001b[0m eta: 2:00:51  iter: 379  total_loss: 1.301  loss_cls: 0.3433  loss_box_reg: 0.5194  loss_mask: 0.2956  loss_rpn_cls: 0.03476  loss_rpn_loc: 0.1073  time: 0.9066  data_time: 0.2867  lr: 3.7962e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:10:03 d2.utils.events]: \u001b[0m eta: 2:01:10  iter: 399  total_loss: 1.406  loss_cls: 0.3636  loss_box_reg: 0.5732  loss_mask: 0.3073  loss_rpn_cls: 0.05143  loss_rpn_loc: 0.1197  time: 0.9133  data_time: 0.2732  lr: 3.996e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:10:20 d2.utils.events]: \u001b[0m eta: 2:00:41  iter: 419  total_loss: 1.332  loss_cls: 0.3415  loss_box_reg: 0.5552  loss_mask: 0.2876  loss_rpn_cls: 0.03396  loss_rpn_loc: 0.09777  time: 0.9096  data_time: 0.1234  lr: 4.1958e-05  max_mem: 8316M\n",
      "\u001b[32m[02/13 13:10:39 d2.utils.events]: \u001b[0m eta: 2:00:25  iter: 439  total_loss: 1.384  loss_cls: 0.3533  loss_box_reg: 0.5767  loss_mask: 0.3162  loss_rpn_cls: 0.03061  loss_rpn_loc: 0.1031  time: 0.9126  data_time: 0.2374  lr: 4.3956e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:10:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:11:00 d2.utils.events]: \u001b[0m eta: 2:00:09  iter: 459  total_loss: 1.375  loss_cls: 0.3713  loss_box_reg: 0.5556  loss_mask: 0.3007  loss_rpn_cls: 0.0496  loss_rpn_loc: 0.1199  time: 0.9182  data_time: 0.1804  lr: 4.5954e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:11:17 d2.utils.events]: \u001b[0m eta: 2:00:02  iter: 479  total_loss: 1.272  loss_cls: 0.3408  loss_box_reg: 0.5194  loss_mask: 0.2925  loss_rpn_cls: 0.03883  loss_rpn_loc: 0.09966  time: 0.9160  data_time: 0.1322  lr: 4.7952e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:11:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:11:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:11:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:11:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:11:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:11:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:11:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1527 s/iter. Eval: 0.0529 s/iter. Total: 0.2064 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1601 s/iter. Eval: 0.1142 s/iter. Total: 0.2753 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1607 s/iter. Eval: 0.1388 s/iter. Total: 0.3005 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:11:40 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0009 s/iter. Inference: 0.1564 s/iter. Eval: 0.1281 s/iter. Total: 0.2856 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 13:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1610 s/iter. Eval: 0.1474 s/iter. Total: 0.3094 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 13:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1636 s/iter. Eval: 0.1576 s/iter. Total: 0.3222 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 13:11:55 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1620 s/iter. Eval: 0.1549 s/iter. Total: 0.3179 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 13:11:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.323435 (0.313133 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:11:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.161781 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:11:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:11:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30830037357965795\n",
      "\u001b[32m[02/13 13:12:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:12:18 d2.utils.events]: \u001b[0m eta: 1:59:41  iter: 499  total_loss: 1.318  loss_cls: 0.3282  loss_box_reg: 0.5404  loss_mask: 0.3015  loss_rpn_cls: 0.04306  loss_rpn_loc: 0.109  time: 0.9230  data_time: 0.2598  lr: 4.995e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:12:36 d2.utils.events]: \u001b[0m eta: 1:59:21  iter: 519  total_loss: 1.351  loss_cls: 0.3566  loss_box_reg: 0.5539  loss_mask: 0.2999  loss_rpn_cls: 0.04659  loss_rpn_loc: 0.1222  time: 0.9235  data_time: 0.2303  lr: 5.1948e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:12:54 d2.utils.events]: \u001b[0m eta: 1:58:39  iter: 539  total_loss: 1.29  loss_cls: 0.3094  loss_box_reg: 0.5505  loss_mask: 0.301  loss_rpn_cls: 0.02429  loss_rpn_loc: 0.0848  time: 0.9213  data_time: 0.1738  lr: 5.3946e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:13:11 d2.utils.events]: \u001b[0m eta: 1:58:24  iter: 559  total_loss: 1.263  loss_cls: 0.3323  loss_box_reg: 0.5457  loss_mask: 0.2729  loss_rpn_cls: 0.04578  loss_rpn_loc: 0.1262  time: 0.9202  data_time: 0.1697  lr: 5.5944e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:13:31 d2.utils.events]: \u001b[0m eta: 1:58:28  iter: 579  total_loss: 1.381  loss_cls: 0.3549  loss_box_reg: 0.5484  loss_mask: 0.296  loss_rpn_cls: 0.03869  loss_rpn_loc: 0.1201  time: 0.9221  data_time: 0.2232  lr: 5.7942e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:13:49 d2.utils.events]: \u001b[0m eta: 1:57:59  iter: 599  total_loss: 1.365  loss_cls: 0.3569  loss_box_reg: 0.5327  loss_mask: 0.2871  loss_rpn_cls: 0.04382  loss_rpn_loc: 0.121  time: 0.9214  data_time: 0.1853  lr: 5.994e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:14:05 d2.utils.events]: \u001b[0m eta: 1:57:40  iter: 619  total_loss: 1.342  loss_cls: 0.3551  loss_box_reg: 0.5569  loss_mask: 0.3017  loss_rpn_cls: 0.03972  loss_rpn_loc: 0.1125  time: 0.9179  data_time: 0.1206  lr: 6.1938e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:14:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:14:26 d2.utils.events]: \u001b[0m eta: 1:57:24  iter: 639  total_loss: 1.237  loss_cls: 0.307  loss_box_reg: 0.5293  loss_mask: 0.2781  loss_rpn_cls: 0.02663  loss_rpn_loc: 0.08925  time: 0.9219  data_time: 0.2123  lr: 6.3936e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:14:40 d2.utils.events]: \u001b[0m eta: 1:56:45  iter: 659  total_loss: 1.305  loss_cls: 0.3208  loss_box_reg: 0.5484  loss_mask: 0.2999  loss_rpn_cls: 0.02762  loss_rpn_loc: 0.07926  time: 0.9153  data_time: 0.0154  lr: 6.5934e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:15:01 d2.utils.events]: \u001b[0m eta: 1:56:48  iter: 679  total_loss: 1.41  loss_cls: 0.3624  loss_box_reg: 0.5535  loss_mask: 0.3034  loss_rpn_cls: 0.04953  loss_rpn_loc: 0.1192  time: 0.9191  data_time: 0.2869  lr: 6.7932e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:15:17 d2.utils.events]: \u001b[0m eta: 1:56:17  iter: 699  total_loss: 1.249  loss_cls: 0.3201  loss_box_reg: 0.5282  loss_mask: 0.2782  loss_rpn_cls: 0.03354  loss_rpn_loc: 0.1014  time: 0.9156  data_time: 0.0969  lr: 6.993e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:15:34 d2.utils.events]: \u001b[0m eta: 1:56:00  iter: 719  total_loss: 1.24  loss_cls: 0.3307  loss_box_reg: 0.507  loss_mask: 0.2854  loss_rpn_cls: 0.03694  loss_rpn_loc: 0.08807  time: 0.9129  data_time: 0.1070  lr: 7.1928e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:15:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:15:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:15:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:15:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:15:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:15:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1488 s/iter. Eval: 0.0526 s/iter. Total: 0.2022 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0010 s/iter. Inference: 0.1545 s/iter. Eval: 0.1159 s/iter. Total: 0.2714 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:15:53 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1573 s/iter. Eval: 0.1401 s/iter. Total: 0.2984 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:15:58 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1542 s/iter. Eval: 0.1293 s/iter. Total: 0.2846 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 13:16:04 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1573 s/iter. Eval: 0.1486 s/iter. Total: 0.3069 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 13:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1609 s/iter. Eval: 0.1599 s/iter. Total: 0.3218 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 13:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0010 s/iter. Inference: 0.1608 s/iter. Eval: 0.1589 s/iter. Total: 0.3207 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 13:16:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.485190 (0.314528 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:16:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.160146 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:16:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:16:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30723279559979105\n",
      "\u001b[32m[02/13 13:16:28 d2.utils.events]: \u001b[0m eta: 1:55:49  iter: 739  total_loss: 1.392  loss_cls: 0.3574  loss_box_reg: 0.5573  loss_mask: 0.3125  loss_rpn_cls: 0.03702  loss_rpn_loc: 0.1025  time: 0.9102  data_time: 0.0838  lr: 7.3926e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:16:46 d2.utils.events]: \u001b[0m eta: 1:55:34  iter: 759  total_loss: 1.307  loss_cls: 0.3324  loss_box_reg: 0.5344  loss_mask: 0.2955  loss_rpn_cls: 0.038  loss_rpn_loc: 0.1047  time: 0.9101  data_time: 0.1930  lr: 7.5924e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:17:06 d2.utils.events]: \u001b[0m eta: 1:55:21  iter: 779  total_loss: 1.422  loss_cls: 0.3591  loss_box_reg: 0.5614  loss_mask: 0.295  loss_rpn_cls: 0.06246  loss_rpn_loc: 0.1292  time: 0.9113  data_time: 0.2152  lr: 7.7922e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:17:25 d2.utils.events]: \u001b[0m eta: 1:55:09  iter: 799  total_loss: 1.307  loss_cls: 0.3363  loss_box_reg: 0.5524  loss_mask: 0.297  loss_rpn_cls: 0.04742  loss_rpn_loc: 0.1114  time: 0.9129  data_time: 0.2560  lr: 7.992e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:17:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:17:45 d2.utils.events]: \u001b[0m eta: 1:54:54  iter: 819  total_loss: 1.294  loss_cls: 0.3282  loss_box_reg: 0.4812  loss_mask: 0.2862  loss_rpn_cls: 0.02884  loss_rpn_loc: 0.1028  time: 0.9148  data_time: 0.1735  lr: 8.1918e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:18:03 d2.utils.events]: \u001b[0m eta: 1:54:36  iter: 839  total_loss: 1.294  loss_cls: 0.3289  loss_box_reg: 0.5281  loss_mask: 0.2826  loss_rpn_cls: 0.0491  loss_rpn_loc: 0.1168  time: 0.9147  data_time: 0.1869  lr: 8.3916e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:18:19 d2.utils.events]: \u001b[0m eta: 1:54:13  iter: 859  total_loss: 1.298  loss_cls: 0.3207  loss_box_reg: 0.5246  loss_mask: 0.2886  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.08585  time: 0.9119  data_time: 0.0924  lr: 8.5914e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:18:35 d2.utils.events]: \u001b[0m eta: 1:53:56  iter: 879  total_loss: 1.306  loss_cls: 0.3382  loss_box_reg: 0.5459  loss_mask: 0.2925  loss_rpn_cls: 0.03841  loss_rpn_loc: 0.1056  time: 0.9089  data_time: 0.0945  lr: 8.7912e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:18:55 d2.utils.events]: \u001b[0m eta: 1:53:45  iter: 899  total_loss: 1.507  loss_cls: 0.4121  loss_box_reg: 0.5564  loss_mask: 0.3004  loss_rpn_cls: 0.06032  loss_rpn_loc: 0.1262  time: 0.9111  data_time: 0.2733  lr: 8.991e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:19:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:19:16 d2.utils.events]: \u001b[0m eta: 1:53:29  iter: 919  total_loss: 1.355  loss_cls: 0.365  loss_box_reg: 0.5392  loss_mask: 0.2906  loss_rpn_cls: 0.04989  loss_rpn_loc: 0.1097  time: 0.9145  data_time: 0.2218  lr: 9.1908e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:19:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:19:37 d2.utils.events]: \u001b[0m eta: 1:53:09  iter: 939  total_loss: 1.298  loss_cls: 0.3465  loss_box_reg: 0.5384  loss_mask: 0.2929  loss_rpn_cls: 0.04091  loss_rpn_loc: 0.1033  time: 0.9169  data_time: 0.1978  lr: 9.3906e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:19:54 d2.utils.events]: \u001b[0m eta: 1:52:56  iter: 959  total_loss: 1.236  loss_cls: 0.3199  loss_box_reg: 0.5313  loss_mask: 0.2854  loss_rpn_cls: 0.031  loss_rpn_loc: 0.07769  time: 0.9159  data_time: 0.1445  lr: 9.5904e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:20:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:20:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:20:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:20:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:20:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:20:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1447 s/iter. Eval: 0.0510 s/iter. Total: 0.1965 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 13:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1541 s/iter. Eval: 0.1259 s/iter. Total: 0.2810 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1563 s/iter. Eval: 0.1372 s/iter. Total: 0.2945 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1538 s/iter. Eval: 0.1272 s/iter. Total: 0.2820 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 13:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1584 s/iter. Eval: 0.1465 s/iter. Total: 0.3059 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 13:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1613 s/iter. Eval: 0.1574 s/iter. Total: 0.3197 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 13:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1604 s/iter. Eval: 0.1545 s/iter. Total: 0.3160 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 13:20:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.083971 (0.311069 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:20:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.160117 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:20:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:20:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30413255864932737\n",
      "\u001b[32m[02/13 13:20:50 d2.utils.events]: \u001b[0m eta: 1:52:34  iter: 979  total_loss: 1.302  loss_cls: 0.3406  loss_box_reg: 0.5315  loss_mask: 0.2839  loss_rpn_cls: 0.02896  loss_rpn_loc: 0.1137  time: 0.9152  data_time: 0.1631  lr: 9.7902e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:21:04 d2.utils.events]: \u001b[0m eta: 1:51:57  iter: 999  total_loss: 1.252  loss_cls: 0.3272  loss_box_reg: 0.5309  loss_mask: 0.2783  loss_rpn_cls: 0.03656  loss_rpn_loc: 0.07696  time: 0.9108  data_time: 0.0344  lr: 9.99e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:21:19 d2.utils.events]: \u001b[0m eta: 1:51:44  iter: 1019  total_loss: 1.292  loss_cls: 0.2955  loss_box_reg: 0.5205  loss_mask: 0.2835  loss_rpn_cls: 0.0364  loss_rpn_loc: 0.08107  time: 0.9082  data_time: 0.0738  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:21:40 d2.utils.events]: \u001b[0m eta: 1:51:34  iter: 1039  total_loss: 1.383  loss_cls: 0.3489  loss_box_reg: 0.5615  loss_mask: 0.2937  loss_rpn_cls: 0.04428  loss_rpn_loc: 0.1146  time: 0.9103  data_time: 0.2720  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:21:57 d2.utils.events]: \u001b[0m eta: 1:51:34  iter: 1059  total_loss: 1.324  loss_cls: 0.3495  loss_box_reg: 0.5281  loss_mask: 0.2819  loss_rpn_cls: 0.04405  loss_rpn_loc: 0.1117  time: 0.9098  data_time: 0.1352  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:22:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:22:19 d2.utils.events]: \u001b[0m eta: 1:51:32  iter: 1079  total_loss: 1.326  loss_cls: 0.3486  loss_box_reg: 0.5194  loss_mask: 0.2821  loss_rpn_cls: 0.03338  loss_rpn_loc: 0.1095  time: 0.9132  data_time: 0.2172  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:22:37 d2.utils.events]: \u001b[0m eta: 1:51:13  iter: 1099  total_loss: 1.23  loss_cls: 0.2901  loss_box_reg: 0.5002  loss_mask: 0.2778  loss_rpn_cls: 0.02742  loss_rpn_loc: 0.1019  time: 0.9123  data_time: 0.1380  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:22:53 d2.utils.events]: \u001b[0m eta: 1:50:45  iter: 1119  total_loss: 1.333  loss_cls: 0.3332  loss_box_reg: 0.5383  loss_mask: 0.2928  loss_rpn_cls: 0.04345  loss_rpn_loc: 0.1047  time: 0.9106  data_time: 0.0903  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:23:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:23:17 d2.utils.events]: \u001b[0m eta: 1:50:22  iter: 1139  total_loss: 1.318  loss_cls: 0.3374  loss_box_reg: 0.548  loss_mask: 0.2943  loss_rpn_cls: 0.04009  loss_rpn_loc: 0.1083  time: 0.9162  data_time: 0.3703  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:23:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:23:42 d2.utils.events]: \u001b[0m eta: 1:50:28  iter: 1159  total_loss: 1.395  loss_cls: 0.3777  loss_box_reg: 0.5451  loss_mask: 0.2884  loss_rpn_cls: 0.05651  loss_rpn_loc: 0.1231  time: 0.9213  data_time: 0.3430  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:23:59 d2.utils.events]: \u001b[0m eta: 1:49:57  iter: 1179  total_loss: 1.266  loss_cls: 0.325  loss_box_reg: 0.5403  loss_mask: 0.3065  loss_rpn_cls: 0.04077  loss_rpn_loc: 0.084  time: 0.9199  data_time: 0.1226  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:24:15 d2.utils.events]: \u001b[0m eta: 1:49:34  iter: 1199  total_loss: 1.312  loss_cls: 0.349  loss_box_reg: 0.5519  loss_mask: 0.2908  loss_rpn_cls: 0.03805  loss_rpn_loc: 0.1179  time: 0.9186  data_time: 0.1084  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:24:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:24:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:24:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:24:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:24:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:24:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1510 s/iter. Eval: 0.0517 s/iter. Total: 0.2035 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1615 s/iter. Eval: 0.1127 s/iter. Total: 0.2752 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1630 s/iter. Eval: 0.1368 s/iter. Total: 0.3008 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1609 s/iter. Eval: 0.1291 s/iter. Total: 0.2910 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 13:24:50 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1619 s/iter. Eval: 0.1408 s/iter. Total: 0.3037 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 13:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1653 s/iter. Eval: 0.1526 s/iter. Total: 0.3189 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 13:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1658 s/iter. Eval: 0.1548 s/iter. Total: 0.3217 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 13:25:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.594485 (0.315470 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:25:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.164937 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:25:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:25:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3074865162929041\n",
      "\u001b[32m[02/13 13:25:14 d2.utils.events]: \u001b[0m eta: 1:49:18  iter: 1219  total_loss: 1.42  loss_cls: 0.3708  loss_box_reg: 0.5541  loss_mask: 0.2932  loss_rpn_cls: 0.05587  loss_rpn_loc: 0.1222  time: 0.9195  data_time: 0.2507  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:25:31 d2.utils.events]: \u001b[0m eta: 1:49:03  iter: 1239  total_loss: 1.175  loss_cls: 0.293  loss_box_reg: 0.5141  loss_mask: 0.2842  loss_rpn_cls: 0.03269  loss_rpn_loc: 0.07901  time: 0.9187  data_time: 0.1365  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:25:47 d2.utils.events]: \u001b[0m eta: 1:48:50  iter: 1259  total_loss: 1.346  loss_cls: 0.3626  loss_box_reg: 0.5389  loss_mask: 0.2781  loss_rpn_cls: 0.05002  loss_rpn_loc: 0.1134  time: 0.9169  data_time: 0.0879  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:26:05 d2.utils.events]: \u001b[0m eta: 1:48:30  iter: 1279  total_loss: 1.243  loss_cls: 0.3051  loss_box_reg: 0.5221  loss_mask: 0.2856  loss_rpn_cls: 0.02763  loss_rpn_loc: 0.1013  time: 0.9164  data_time: 0.1451  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:26:23 d2.utils.events]: \u001b[0m eta: 1:48:19  iter: 1299  total_loss: 1.378  loss_cls: 0.3499  loss_box_reg: 0.5614  loss_mask: 0.2874  loss_rpn_cls: 0.04594  loss_rpn_loc: 0.1046  time: 0.9163  data_time: 0.1713  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:26:39 d2.utils.events]: \u001b[0m eta: 1:48:03  iter: 1319  total_loss: 1.316  loss_cls: 0.3393  loss_box_reg: 0.5362  loss_mask: 0.2966  loss_rpn_cls: 0.03378  loss_rpn_loc: 0.1124  time: 0.9145  data_time: 0.0833  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:26:57 d2.utils.events]: \u001b[0m eta: 1:47:49  iter: 1339  total_loss: 1.314  loss_cls: 0.338  loss_box_reg: 0.5196  loss_mask: 0.2842  loss_rpn_cls: 0.03182  loss_rpn_loc: 0.1037  time: 0.9143  data_time: 0.1826  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:27:16 d2.utils.events]: \u001b[0m eta: 1:47:42  iter: 1359  total_loss: 1.222  loss_cls: 0.3123  loss_box_reg: 0.5207  loss_mask: 0.2841  loss_rpn_cls: 0.0367  loss_rpn_loc: 0.1041  time: 0.9148  data_time: 0.2173  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:27:33 d2.utils.events]: \u001b[0m eta: 1:47:35  iter: 1379  total_loss: 1.289  loss_cls: 0.3358  loss_box_reg: 0.5268  loss_mask: 0.2837  loss_rpn_cls: 0.0327  loss_rpn_loc: 0.1033  time: 0.9142  data_time: 0.1389  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:27:49 d2.utils.events]: \u001b[0m eta: 1:47:02  iter: 1399  total_loss: 1.348  loss_cls: 0.3628  loss_box_reg: 0.5336  loss_mask: 0.2886  loss_rpn_cls: 0.04106  loss_rpn_loc: 0.1116  time: 0.9122  data_time: 0.0571  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:28:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:28:12 d2.utils.events]: \u001b[0m eta: 1:47:11  iter: 1419  total_loss: 1.398  loss_cls: 0.3536  loss_box_reg: 0.5621  loss_mask: 0.3116  loss_rpn_cls: 0.05251  loss_rpn_loc: 0.1191  time: 0.9156  data_time: 0.2952  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:28:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:28:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:28:36 d2.utils.events]: \u001b[0m eta: 1:47:01  iter: 1439  total_loss: 1.318  loss_cls: 0.3535  loss_box_reg: 0.5375  loss_mask: 0.3059  loss_rpn_cls: 0.03533  loss_rpn_loc: 0.1201  time: 0.9199  data_time: 0.2555  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:28:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:28:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:28:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:28:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:28:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:28:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:28:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1510 s/iter. Eval: 0.0519 s/iter. Total: 0.2036 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1591 s/iter. Eval: 0.1145 s/iter. Total: 0.2746 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1625 s/iter. Eval: 0.1304 s/iter. Total: 0.2939 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0010 s/iter. Inference: 0.1613 s/iter. Eval: 0.1277 s/iter. Total: 0.2900 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 13:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0010 s/iter. Inference: 0.1638 s/iter. Eval: 0.1388 s/iter. Total: 0.3036 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 13:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0010 s/iter. Inference: 0.1687 s/iter. Eval: 0.1517 s/iter. Total: 0.3214 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/13 13:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0010 s/iter. Inference: 0.1691 s/iter. Eval: 0.1572 s/iter. Total: 0.3274 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/13 13:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0010 s/iter. Inference: 0.1684 s/iter. Eval: 0.1519 s/iter. Total: 0.3214 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 13:29:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.351241 (0.321993 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:29:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.168579 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:29:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:29:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3060375366788728\n",
      "\u001b[32m[02/13 13:29:39 d2.utils.events]: \u001b[0m eta: 1:46:55  iter: 1459  total_loss: 1.302  loss_cls: 0.3328  loss_box_reg: 0.5093  loss_mask: 0.2832  loss_rpn_cls: 0.03644  loss_rpn_loc: 0.1085  time: 0.9229  data_time: 0.2477  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:29:55 d2.utils.events]: \u001b[0m eta: 1:46:37  iter: 1479  total_loss: 1.305  loss_cls: 0.3293  loss_box_reg: 0.5508  loss_mask: 0.2859  loss_rpn_cls: 0.03343  loss_rpn_loc: 0.1144  time: 0.9216  data_time: 0.0911  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:30:14 d2.utils.events]: \u001b[0m eta: 1:46:25  iter: 1499  total_loss: 1.416  loss_cls: 0.3696  loss_box_reg: 0.579  loss_mask: 0.3324  loss_rpn_cls: 0.05598  loss_rpn_loc: 0.1098  time: 0.9218  data_time: 0.1978  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:30:35 d2.utils.events]: \u001b[0m eta: 1:46:19  iter: 1519  total_loss: 1.424  loss_cls: 0.388  loss_box_reg: 0.5724  loss_mask: 0.2973  loss_rpn_cls: 0.06363  loss_rpn_loc: 0.1222  time: 0.9233  data_time: 0.2366  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:30:53 d2.utils.events]: \u001b[0m eta: 1:46:07  iter: 1539  total_loss: 1.216  loss_cls: 0.3199  loss_box_reg: 0.5159  loss_mask: 0.282  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.09676  time: 0.9231  data_time: 0.1769  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:31:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:31:11 d2.utils.events]: \u001b[0m eta: 1:45:52  iter: 1559  total_loss: 1.154  loss_cls: 0.2975  loss_box_reg: 0.4901  loss_mask: 0.268  loss_rpn_cls: 0.03269  loss_rpn_loc: 0.0721  time: 0.9231  data_time: 0.1180  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:31:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:31:32 d2.utils.events]: \u001b[0m eta: 1:45:39  iter: 1579  total_loss: 1.342  loss_cls: 0.3474  loss_box_reg: 0.5413  loss_mask: 0.2802  loss_rpn_cls: 0.04866  loss_rpn_loc: 0.1198  time: 0.9245  data_time: 0.1359  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:31:51 d2.utils.events]: \u001b[0m eta: 1:45:30  iter: 1599  total_loss: 1.425  loss_cls: 0.3631  loss_box_reg: 0.5783  loss_mask: 0.2996  loss_rpn_cls: 0.05296  loss_rpn_loc: 0.1242  time: 0.9247  data_time: 0.2034  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:32:08 d2.utils.events]: \u001b[0m eta: 1:45:17  iter: 1619  total_loss: 1.318  loss_cls: 0.3446  loss_box_reg: 0.5276  loss_mask: 0.2839  loss_rpn_cls: 0.03599  loss_rpn_loc: 0.09457  time: 0.9238  data_time: 0.1118  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:32:30 d2.utils.events]: \u001b[0m eta: 1:45:05  iter: 1639  total_loss: 1.282  loss_cls: 0.3403  loss_box_reg: 0.5213  loss_mask: 0.2972  loss_rpn_cls: 0.04684  loss_rpn_loc: 0.1133  time: 0.9259  data_time: 0.3429  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:32:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:32:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:32:52 d2.utils.events]: \u001b[0m eta: 1:45:06  iter: 1659  total_loss: 1.346  loss_cls: 0.3475  loss_box_reg: 0.5486  loss_mask: 0.2964  loss_rpn_cls: 0.04339  loss_rpn_loc: 0.1023  time: 0.9279  data_time: 0.1414  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:33:09 d2.utils.events]: \u001b[0m eta: 1:44:44  iter: 1679  total_loss: 1.255  loss_cls: 0.3005  loss_box_reg: 0.5062  loss_mask: 0.283  loss_rpn_cls: 0.02898  loss_rpn_loc: 0.09441  time: 0.9271  data_time: 0.1087  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:33:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:33:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:33:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:33:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:33:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:33:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1499 s/iter. Eval: 0.0532 s/iter. Total: 0.2039 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:33:30 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1584 s/iter. Eval: 0.1166 s/iter. Total: 0.2760 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1647 s/iter. Eval: 0.1328 s/iter. Total: 0.2985 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:33:41 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0010 s/iter. Inference: 0.1625 s/iter. Eval: 0.1298 s/iter. Total: 0.2934 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 13:33:46 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0010 s/iter. Inference: 0.1635 s/iter. Eval: 0.1394 s/iter. Total: 0.3040 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 13:33:51 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0010 s/iter. Inference: 0.1668 s/iter. Eval: 0.1542 s/iter. Total: 0.3220 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/13 13:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0010 s/iter. Inference: 0.1687 s/iter. Eval: 0.1602 s/iter. Total: 0.3300 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 13:34:01 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0010 s/iter. Inference: 0.1679 s/iter. Eval: 0.1554 s/iter. Total: 0.3243 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 13:34:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.674253 (0.324778 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:34:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.167863 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:34:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:34:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30602391537910156\n",
      "\u001b[32m[02/13 13:34:06 d2.utils.events]: \u001b[0m eta: 1:44:36  iter: 1699  total_loss: 1.355  loss_cls: 0.3488  loss_box_reg: 0.5482  loss_mask: 0.3098  loss_rpn_cls: 0.03489  loss_rpn_loc: 0.09174  time: 0.9265  data_time: 0.1482  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:34:26 d2.utils.events]: \u001b[0m eta: 1:44:30  iter: 1719  total_loss: 1.334  loss_cls: 0.3438  loss_box_reg: 0.5159  loss_mask: 0.283  loss_rpn_cls: 0.05234  loss_rpn_loc: 0.1183  time: 0.9272  data_time: 0.2123  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:34:42 d2.utils.events]: \u001b[0m eta: 1:44:11  iter: 1739  total_loss: 1.251  loss_cls: 0.3058  loss_box_reg: 0.5412  loss_mask: 0.2911  loss_rpn_cls: 0.02023  loss_rpn_loc: 0.07479  time: 0.9256  data_time: 0.0675  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:35:00 d2.utils.events]: \u001b[0m eta: 1:44:03  iter: 1759  total_loss: 1.322  loss_cls: 0.3393  loss_box_reg: 0.543  loss_mask: 0.2873  loss_rpn_cls: 0.03154  loss_rpn_loc: 0.09743  time: 0.9257  data_time: 0.1771  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:35:21 d2.utils.events]: \u001b[0m eta: 1:43:57  iter: 1779  total_loss: 1.343  loss_cls: 0.3519  loss_box_reg: 0.5608  loss_mask: 0.2848  loss_rpn_cls: 0.02925  loss_rpn_loc: 0.1193  time: 0.9267  data_time: 0.2532  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:35:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:35:42 d2.utils.events]: \u001b[0m eta: 1:43:42  iter: 1799  total_loss: 1.32  loss_cls: 0.36  loss_box_reg: 0.535  loss_mask: 0.2807  loss_rpn_cls: 0.03666  loss_rpn_loc: 0.1197  time: 0.9285  data_time: 0.1811  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:36:02 d2.utils.events]: \u001b[0m eta: 1:43:28  iter: 1819  total_loss: 1.364  loss_cls: 0.3521  loss_box_reg: 0.5551  loss_mask: 0.3012  loss_rpn_cls: 0.0415  loss_rpn_loc: 0.1139  time: 0.9287  data_time: 0.2059  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:36:18 d2.utils.events]: \u001b[0m eta: 1:43:15  iter: 1839  total_loss: 1.255  loss_cls: 0.3115  loss_box_reg: 0.5108  loss_mask: 0.2791  loss_rpn_cls: 0.02165  loss_rpn_loc: 0.08869  time: 0.9276  data_time: 0.1131  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:36:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:36:38 d2.utils.events]: \u001b[0m eta: 1:43:03  iter: 1859  total_loss: 1.207  loss_cls: 0.3104  loss_box_reg: 0.5123  loss_mask: 0.2807  loss_rpn_cls: 0.03417  loss_rpn_loc: 0.0841  time: 0.9283  data_time: 0.1678  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:36:57 d2.utils.events]: \u001b[0m eta: 1:43:06  iter: 1879  total_loss: 1.4  loss_cls: 0.352  loss_box_reg: 0.5456  loss_mask: 0.2999  loss_rpn_cls: 0.05882  loss_rpn_loc: 0.1221  time: 0.9284  data_time: 0.1946  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:37:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:37:18 d2.utils.events]: \u001b[0m eta: 1:42:54  iter: 1899  total_loss: 1.364  loss_cls: 0.3413  loss_box_reg: 0.5381  loss_mask: 0.3028  loss_rpn_cls: 0.05318  loss_rpn_loc: 0.1092  time: 0.9301  data_time: 0.1893  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:37:36 d2.utils.events]: \u001b[0m eta: 1:42:41  iter: 1919  total_loss: 1.299  loss_cls: 0.3259  loss_box_reg: 0.5327  loss_mask: 0.2863  loss_rpn_cls: 0.02675  loss_rpn_loc: 0.09006  time: 0.9297  data_time: 0.1498  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:37:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:37:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:37:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:37:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:37:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:37:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:37:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1515 s/iter. Eval: 0.0528 s/iter. Total: 0.2051 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:37:58 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0009 s/iter. Inference: 0.1661 s/iter. Eval: 0.1216 s/iter. Total: 0.2887 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/13 13:38:03 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1646 s/iter. Eval: 0.1313 s/iter. Total: 0.2969 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:38:08 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0010 s/iter. Inference: 0.1623 s/iter. Eval: 0.1280 s/iter. Total: 0.2913 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 13:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0010 s/iter. Inference: 0.1631 s/iter. Eval: 0.1366 s/iter. Total: 0.3008 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 13:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0010 s/iter. Inference: 0.1664 s/iter. Eval: 0.1497 s/iter. Total: 0.3171 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 13:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0010 s/iter. Inference: 0.1676 s/iter. Eval: 0.1542 s/iter. Total: 0.3228 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 13:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0010 s/iter. Inference: 0.1670 s/iter. Eval: 0.1507 s/iter. Total: 0.3187 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 13:38:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.028190 (0.319209 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:38:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.167017 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:38:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:38:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3056940513529149\n",
      "\u001b[32m[02/13 13:38:32 d2.utils.events]: \u001b[0m eta: 1:42:30  iter: 1939  total_loss: 1.28  loss_cls: 0.3146  loss_box_reg: 0.5284  loss_mask: 0.2843  loss_rpn_cls: 0.04688  loss_rpn_loc: 0.1086  time: 0.9285  data_time: 0.0671  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:38:50 d2.utils.events]: \u001b[0m eta: 1:42:22  iter: 1959  total_loss: 1.334  loss_cls: 0.3575  loss_box_reg: 0.5407  loss_mask: 0.2947  loss_rpn_cls: 0.03567  loss_rpn_loc: 0.1054  time: 0.9284  data_time: 0.1726  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:39:11 d2.utils.events]: \u001b[0m eta: 1:42:22  iter: 1979  total_loss: 1.46  loss_cls: 0.3742  loss_box_reg: 0.5746  loss_mask: 0.3039  loss_rpn_cls: 0.06287  loss_rpn_loc: 0.1352  time: 0.9298  data_time: 0.2869  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:39:29 d2.utils.events]: \u001b[0m eta: 1:42:32  iter: 1999  total_loss: 1.404  loss_cls: 0.3735  loss_box_reg: 0.5724  loss_mask: 0.2877  loss_rpn_cls: 0.05207  loss_rpn_loc: 0.133  time: 0.9293  data_time: 0.1360  lr: 0.0001  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:39:44 d2.utils.events]: \u001b[0m eta: 1:42:18  iter: 2019  total_loss: 1.238  loss_cls: 0.2987  loss_box_reg: 0.5408  loss_mask: 0.2956  loss_rpn_cls: 0.02539  loss_rpn_loc: 0.07168  time: 0.9277  data_time: 0.0330  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:40:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:40:05 d2.utils.events]: \u001b[0m eta: 1:42:02  iter: 2039  total_loss: 1.273  loss_cls: 0.3452  loss_box_reg: 0.5342  loss_mask: 0.2804  loss_rpn_cls: 0.03717  loss_rpn_loc: 0.07766  time: 0.9286  data_time: 0.1524  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:40:23 d2.utils.events]: \u001b[0m eta: 1:41:47  iter: 2059  total_loss: 1.361  loss_cls: 0.3524  loss_box_reg: 0.5479  loss_mask: 0.2919  loss_rpn_cls: 0.04208  loss_rpn_loc: 0.1164  time: 0.9282  data_time: 0.1346  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:40:43 d2.utils.events]: \u001b[0m eta: 1:41:40  iter: 2079  total_loss: 1.415  loss_cls: 0.3573  loss_box_reg: 0.5578  loss_mask: 0.2878  loss_rpn_cls: 0.04181  loss_rpn_loc: 0.1118  time: 0.9291  data_time: 0.2313  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:41:00 d2.utils.events]: \u001b[0m eta: 1:41:24  iter: 2099  total_loss: 1.307  loss_cls: 0.3262  loss_box_reg: 0.5092  loss_mask: 0.2968  loss_rpn_cls: 0.03068  loss_rpn_loc: 0.08258  time: 0.9284  data_time: 0.1287  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:41:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:41:22 d2.utils.events]: \u001b[0m eta: 1:41:18  iter: 2119  total_loss: 1.313  loss_cls: 0.3404  loss_box_reg: 0.5512  loss_mask: 0.2942  loss_rpn_cls: 0.03059  loss_rpn_loc: 0.09319  time: 0.9299  data_time: 0.2320  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:41:41 d2.utils.events]: \u001b[0m eta: 1:41:04  iter: 2139  total_loss: 1.312  loss_cls: 0.3515  loss_box_reg: 0.5172  loss_mask: 0.2816  loss_rpn_cls: 0.04192  loss_rpn_loc: 0.1122  time: 0.9302  data_time: 0.1847  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:41:58 d2.utils.events]: \u001b[0m eta: 1:40:30  iter: 2159  total_loss: 1.272  loss_cls: 0.3377  loss_box_reg: 0.5021  loss_mask: 0.2871  loss_rpn_cls: 0.03859  loss_rpn_loc: 0.1151  time: 0.9296  data_time: 0.1394  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:42:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:42:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:42:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:42:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:42:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:42:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1502 s/iter. Eval: 0.0512 s/iter. Total: 0.2022 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1587 s/iter. Eval: 0.1142 s/iter. Total: 0.2739 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1624 s/iter. Eval: 0.1306 s/iter. Total: 0.2939 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0009 s/iter. Inference: 0.1637 s/iter. Eval: 0.1293 s/iter. Total: 0.2940 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 13:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0010 s/iter. Inference: 0.1649 s/iter. Eval: 0.1387 s/iter. Total: 0.3046 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 13:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0010 s/iter. Inference: 0.1675 s/iter. Eval: 0.1509 s/iter. Total: 0.3194 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/13 13:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0010 s/iter. Inference: 0.1681 s/iter. Eval: 0.1567 s/iter. Total: 0.3258 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/13 13:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0010 s/iter. Inference: 0.1672 s/iter. Eval: 0.1520 s/iter. Total: 0.3202 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/13 13:42:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.219189 (0.320855 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:42:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.167236 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:42:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:42:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3064437432673591\n",
      "\u001b[32m[02/13 13:42:56 d2.utils.events]: \u001b[0m eta: 1:40:15  iter: 2179  total_loss: 1.264  loss_cls: 0.3275  loss_box_reg: 0.5377  loss_mask: 0.2877  loss_rpn_cls: 0.04091  loss_rpn_loc: 0.105  time: 0.9293  data_time: 0.1328  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:43:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:43:18 d2.utils.events]: \u001b[0m eta: 1:40:03  iter: 2199  total_loss: 1.333  loss_cls: 0.3449  loss_box_reg: 0.5323  loss_mask: 0.2952  loss_rpn_cls: 0.04852  loss_rpn_loc: 0.1104  time: 0.9311  data_time: 0.2172  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:43:37 d2.utils.events]: \u001b[0m eta: 1:39:47  iter: 2219  total_loss: 1.321  loss_cls: 0.3393  loss_box_reg: 0.5547  loss_mask: 0.2932  loss_rpn_cls: 0.03738  loss_rpn_loc: 0.1096  time: 0.9310  data_time: 0.1588  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:43:57 d2.utils.events]: \u001b[0m eta: 1:39:46  iter: 2239  total_loss: 1.346  loss_cls: 0.3463  loss_box_reg: 0.5415  loss_mask: 0.291  loss_rpn_cls: 0.02999  loss_rpn_loc: 0.1036  time: 0.9319  data_time: 0.2684  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:44:18 d2.utils.events]: \u001b[0m eta: 1:39:35  iter: 2259  total_loss: 1.306  loss_cls: 0.3299  loss_box_reg: 0.5222  loss_mask: 0.2801  loss_rpn_cls: 0.02744  loss_rpn_loc: 0.1092  time: 0.9328  data_time: 0.2593  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:44:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:44:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:44:41 d2.utils.events]: \u001b[0m eta: 1:39:29  iter: 2279  total_loss: 1.356  loss_cls: 0.3502  loss_box_reg: 0.539  loss_mask: 0.291  loss_rpn_cls: 0.03652  loss_rpn_loc: 0.1067  time: 0.9346  data_time: 0.1849  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:44:56 d2.utils.events]: \u001b[0m eta: 1:39:14  iter: 2299  total_loss: 1.3  loss_cls: 0.3221  loss_box_reg: 0.5451  loss_mask: 0.2897  loss_rpn_cls: 0.02478  loss_rpn_loc: 0.1009  time: 0.9331  data_time: 0.0400  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:45:14 d2.utils.events]: \u001b[0m eta: 1:39:07  iter: 2319  total_loss: 1.352  loss_cls: 0.3398  loss_box_reg: 0.5391  loss_mask: 0.2809  loss_rpn_cls: 0.04285  loss_rpn_loc: 0.1089  time: 0.9327  data_time: 0.1374  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:45:35 d2.utils.events]: \u001b[0m eta: 1:38:54  iter: 2339  total_loss: 1.359  loss_cls: 0.3568  loss_box_reg: 0.5339  loss_mask: 0.2978  loss_rpn_cls: 0.04911  loss_rpn_loc: 0.1127  time: 0.9338  data_time: 0.2984  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:45:50 d2.utils.events]: \u001b[0m eta: 1:38:36  iter: 2359  total_loss: 1.238  loss_cls: 0.3235  loss_box_reg: 0.5093  loss_mask: 0.2869  loss_rpn_cls: 0.03444  loss_rpn_loc: 0.08009  time: 0.9324  data_time: 0.0465  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:46:07 d2.utils.events]: \u001b[0m eta: 1:38:22  iter: 2379  total_loss: 1.299  loss_cls: 0.3506  loss_box_reg: 0.5375  loss_mask: 0.29  loss_rpn_cls: 0.03283  loss_rpn_loc: 0.1081  time: 0.9314  data_time: 0.0899  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:46:23 d2.utils.events]: \u001b[0m eta: 1:38:05  iter: 2399  total_loss: 1.253  loss_cls: 0.3381  loss_box_reg: 0.5356  loss_mask: 0.2856  loss_rpn_cls: 0.02976  loss_rpn_loc: 0.08968  time: 0.9305  data_time: 0.1346  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:46:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:46:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:46:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:46:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:46:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:46:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1447 s/iter. Eval: 0.0516 s/iter. Total: 0.1970 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 13:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1534 s/iter. Eval: 0.1178 s/iter. Total: 0.2722 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1586 s/iter. Eval: 0.1317 s/iter. Total: 0.2913 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 13:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1567 s/iter. Eval: 0.1327 s/iter. Total: 0.2904 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 13:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1577 s/iter. Eval: 0.1425 s/iter. Total: 0.3012 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 13:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1605 s/iter. Eval: 0.1536 s/iter. Total: 0.3151 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 13:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1627 s/iter. Eval: 0.1574 s/iter. Total: 0.3210 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 13:47:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.643476 (0.315892 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:47:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.162455 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:47:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:47:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30476197527059207\n",
      "\u001b[32m[02/13 13:47:21 d2.utils.events]: \u001b[0m eta: 1:37:44  iter: 2419  total_loss: 1.293  loss_cls: 0.3357  loss_box_reg: 0.5377  loss_mask: 0.2868  loss_rpn_cls: 0.03639  loss_rpn_loc: 0.1116  time: 0.9308  data_time: 0.2356  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:47:36 d2.utils.events]: \u001b[0m eta: 1:37:18  iter: 2439  total_loss: 1.294  loss_cls: 0.3325  loss_box_reg: 0.5135  loss_mask: 0.2918  loss_rpn_cls: 0.04345  loss_rpn_loc: 0.1083  time: 0.9294  data_time: 0.0460  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:47:52 d2.utils.events]: \u001b[0m eta: 1:36:40  iter: 2459  total_loss: 1.293  loss_cls: 0.3236  loss_box_reg: 0.5492  loss_mask: 0.2926  loss_rpn_cls: 0.04181  loss_rpn_loc: 0.09811  time: 0.9284  data_time: 0.0962  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:48:15 d2.utils.events]: \u001b[0m eta: 1:36:39  iter: 2479  total_loss: 1.28  loss_cls: 0.3417  loss_box_reg: 0.5446  loss_mask: 0.2816  loss_rpn_cls: 0.03861  loss_rpn_loc: 0.1053  time: 0.9298  data_time: 0.3429  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:48:37 d2.utils.events]: \u001b[0m eta: 1:36:25  iter: 2499  total_loss: 1.345  loss_cls: 0.3399  loss_box_reg: 0.5478  loss_mask: 0.2965  loss_rpn_cls: 0.04531  loss_rpn_loc: 0.1179  time: 0.9312  data_time: 0.3634  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:48:53 d2.utils.events]: \u001b[0m eta: 1:35:54  iter: 2519  total_loss: 1.285  loss_cls: 0.3041  loss_box_reg: 0.5344  loss_mask: 0.2957  loss_rpn_cls: 0.03225  loss_rpn_loc: 0.09569  time: 0.9301  data_time: 0.0687  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:49:09 d2.utils.events]: \u001b[0m eta: 1:35:38  iter: 2539  total_loss: 1.407  loss_cls: 0.3719  loss_box_reg: 0.5514  loss_mask: 0.3087  loss_rpn_cls: 0.02971  loss_rpn_loc: 0.1135  time: 0.9294  data_time: 0.1450  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:49:25 d2.utils.events]: \u001b[0m eta: 1:35:11  iter: 2559  total_loss: 1.263  loss_cls: 0.3279  loss_box_reg: 0.5125  loss_mask: 0.2724  loss_rpn_cls: 0.03565  loss_rpn_loc: 0.1037  time: 0.9283  data_time: 0.0996  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:49:45 d2.utils.events]: \u001b[0m eta: 1:34:48  iter: 2579  total_loss: 1.378  loss_cls: 0.3526  loss_box_reg: 0.5656  loss_mask: 0.2907  loss_rpn_cls: 0.04601  loss_rpn_loc: 0.1232  time: 0.9288  data_time: 0.2472  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:50:02 d2.utils.events]: \u001b[0m eta: 1:34:24  iter: 2599  total_loss: 1.217  loss_cls: 0.3056  loss_box_reg: 0.5132  loss_mask: 0.2793  loss_rpn_cls: 0.03011  loss_rpn_loc: 0.09789  time: 0.9281  data_time: 0.1341  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:50:19 d2.utils.events]: \u001b[0m eta: 1:34:05  iter: 2619  total_loss: 1.399  loss_cls: 0.3508  loss_box_reg: 0.5517  loss_mask: 0.2953  loss_rpn_cls: 0.06252  loss_rpn_loc: 0.12  time: 0.9276  data_time: 0.1494  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:50:35 d2.utils.events]: \u001b[0m eta: 1:33:39  iter: 2639  total_loss: 1.196  loss_cls: 0.3065  loss_box_reg: 0.516  loss_mask: 0.2735  loss_rpn_cls: 0.02199  loss_rpn_loc: 0.08412  time: 0.9266  data_time: 0.1069  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:50:52 d2.utils.events]: \u001b[0m eta: 1:33:23  iter: 2659  total_loss: 1.195  loss_cls: 0.3196  loss_box_reg: 0.4843  loss_mask: 0.2789  loss_rpn_cls: 0.03875  loss_rpn_loc: 0.1024  time: 0.9259  data_time: 0.1028  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:50:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:50:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:50:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:50:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:50:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:50:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:50:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1451 s/iter. Eval: 0.0500 s/iter. Total: 0.1957 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 13:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1537 s/iter. Eval: 0.1218 s/iter. Total: 0.2764 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1550 s/iter. Eval: 0.1303 s/iter. Total: 0.2862 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 13:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0009 s/iter. Inference: 0.1520 s/iter. Eval: 0.1197 s/iter. Total: 0.2726 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/13 13:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1562 s/iter. Eval: 0.1415 s/iter. Total: 0.2986 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 13:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0009 s/iter. Inference: 0.1589 s/iter. Eval: 0.1493 s/iter. Total: 0.3091 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/13 13:51:32 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0009 s/iter. Inference: 0.1575 s/iter. Eval: 0.1459 s/iter. Total: 0.3044 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 13:51:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.043343 (0.302098 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:51:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157689 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:51:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:51:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3064013453157539\n",
      "\u001b[32m[02/13 13:51:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:51:54 d2.utils.events]: \u001b[0m eta: 1:33:08  iter: 2679  total_loss: 1.243  loss_cls: 0.3225  loss_box_reg: 0.5389  loss_mask: 0.2913  loss_rpn_cls: 0.04215  loss_rpn_loc: 0.1039  time: 0.9285  data_time: 0.2875  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:52:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:52:16 d2.utils.events]: \u001b[0m eta: 1:32:53  iter: 2699  total_loss: 1.286  loss_cls: 0.3321  loss_box_reg: 0.5078  loss_mask: 0.2735  loss_rpn_cls: 0.02762  loss_rpn_loc: 0.0986  time: 0.9295  data_time: 0.2465  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:52:31 d2.utils.events]: \u001b[0m eta: 1:32:26  iter: 2719  total_loss: 1.357  loss_cls: 0.3466  loss_box_reg: 0.5463  loss_mask: 0.2909  loss_rpn_cls: 0.03987  loss_rpn_loc: 0.1036  time: 0.9284  data_time: 0.0922  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:52:47 d2.utils.events]: \u001b[0m eta: 1:32:11  iter: 2739  total_loss: 1.255  loss_cls: 0.3271  loss_box_reg: 0.5566  loss_mask: 0.293  loss_rpn_cls: 0.02769  loss_rpn_loc: 0.09637  time: 0.9275  data_time: 0.1045  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:53:06 d2.utils.events]: \u001b[0m eta: 1:31:53  iter: 2759  total_loss: 1.339  loss_cls: 0.343  loss_box_reg: 0.5535  loss_mask: 0.2969  loss_rpn_cls: 0.04146  loss_rpn_loc: 0.1158  time: 0.9275  data_time: 0.1929  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:53:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:53:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:53:28 d2.utils.events]: \u001b[0m eta: 1:31:34  iter: 2779  total_loss: 1.249  loss_cls: 0.3422  loss_box_reg: 0.5257  loss_mask: 0.2674  loss_rpn_cls: 0.03281  loss_rpn_loc: 0.09229  time: 0.9289  data_time: 0.1770  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:53:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:53:50 d2.utils.events]: \u001b[0m eta: 1:31:16  iter: 2799  total_loss: 1.364  loss_cls: 0.3475  loss_box_reg: 0.5467  loss_mask: 0.2933  loss_rpn_cls: 0.04176  loss_rpn_loc: 0.1212  time: 0.9301  data_time: 0.2239  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:54:06 d2.utils.events]: \u001b[0m eta: 1:30:55  iter: 2819  total_loss: 1.304  loss_cls: 0.3514  loss_box_reg: 0.5226  loss_mask: 0.2935  loss_rpn_cls: 0.04211  loss_rpn_loc: 0.08132  time: 0.9290  data_time: 0.0881  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:54:24 d2.utils.events]: \u001b[0m eta: 1:30:36  iter: 2839  total_loss: 1.45  loss_cls: 0.3762  loss_box_reg: 0.5543  loss_mask: 0.3112  loss_rpn_cls: 0.05118  loss_rpn_loc: 0.1146  time: 0.9288  data_time: 0.1808  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:54:43 d2.utils.events]: \u001b[0m eta: 1:30:28  iter: 2859  total_loss: 1.302  loss_cls: 0.332  loss_box_reg: 0.516  loss_mask: 0.2817  loss_rpn_cls: 0.03695  loss_rpn_loc: 0.1049  time: 0.9290  data_time: 0.2379  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:55:03 d2.utils.events]: \u001b[0m eta: 1:30:06  iter: 2879  total_loss: 1.338  loss_cls: 0.3625  loss_box_reg: 0.5394  loss_mask: 0.2964  loss_rpn_cls: 0.03535  loss_rpn_loc: 0.1099  time: 0.9295  data_time: 0.2847  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:55:23 d2.utils.events]: \u001b[0m eta: 1:29:38  iter: 2899  total_loss: 1.235  loss_cls: 0.3061  loss_box_reg: 0.51  loss_mask: 0.2736  loss_rpn_cls: 0.04094  loss_rpn_loc: 0.08127  time: 0.9299  data_time: 0.2881  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:55:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:55:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:55:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:55:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:55:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:55:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1439 s/iter. Eval: 0.0505 s/iter. Total: 0.1951 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 13:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1527 s/iter. Eval: 0.1253 s/iter. Total: 0.2790 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 13:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0010 s/iter. Inference: 0.1540 s/iter. Eval: 0.1343 s/iter. Total: 0.2894 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 13:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1540 s/iter. Eval: 0.1265 s/iter. Total: 0.2815 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 13:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1568 s/iter. Eval: 0.1456 s/iter. Total: 0.3034 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 13:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1554 s/iter. Total: 0.3160 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 13:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1579 s/iter. Eval: 0.1517 s/iter. Total: 0.3107 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 13:56:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.640919 (0.307249 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:56:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157999 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 13:56:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 13:56:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30626709999214785\n",
      "\u001b[32m[02/13 13:56:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:56:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:56:24 d2.utils.events]: \u001b[0m eta: 1:29:25  iter: 2919  total_loss: 1.349  loss_cls: 0.353  loss_box_reg: 0.5427  loss_mask: 0.2936  loss_rpn_cls: 0.04881  loss_rpn_loc: 0.1213  time: 0.9317  data_time: 0.2702  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:56:40 d2.utils.events]: \u001b[0m eta: 1:28:58  iter: 2939  total_loss: 1.271  loss_cls: 0.3259  loss_box_reg: 0.5187  loss_mask: 0.2863  loss_rpn_cls: 0.03144  loss_rpn_loc: 0.1034  time: 0.9307  data_time: 0.0833  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:56:57 d2.utils.events]: \u001b[0m eta: 1:28:34  iter: 2959  total_loss: 1.248  loss_cls: 0.3444  loss_box_reg: 0.5105  loss_mask: 0.284  loss_rpn_cls: 0.02596  loss_rpn_loc: 0.06908  time: 0.9302  data_time: 0.1574  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:57:14 d2.utils.events]: \u001b[0m eta: 1:28:11  iter: 2979  total_loss: 1.359  loss_cls: 0.3711  loss_box_reg: 0.5421  loss_mask: 0.2815  loss_rpn_cls: 0.04249  loss_rpn_loc: 0.09995  time: 0.9296  data_time: 0.1429  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:57:31 d2.utils.events]: \u001b[0m eta: 1:27:48  iter: 2999  total_loss: 1.352  loss_cls: 0.3247  loss_box_reg: 0.5459  loss_mask: 0.2931  loss_rpn_cls: 0.03303  loss_rpn_loc: 0.1199  time: 0.9292  data_time: 0.1544  lr: 8e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:57:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:57:51 d2.utils.events]: \u001b[0m eta: 1:27:15  iter: 3019  total_loss: 1.239  loss_cls: 0.3253  loss_box_reg: 0.5341  loss_mask: 0.2833  loss_rpn_cls: 0.03135  loss_rpn_loc: 0.09519  time: 0.9294  data_time: 0.1433  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:58:08 d2.utils.events]: \u001b[0m eta: 1:27:00  iter: 3039  total_loss: 1.41  loss_cls: 0.3734  loss_box_reg: 0.5711  loss_mask: 0.3024  loss_rpn_cls: 0.04284  loss_rpn_loc: 0.1204  time: 0.9289  data_time: 0.1364  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:58:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:58:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:58:31 d2.utils.events]: \u001b[0m eta: 1:26:30  iter: 3059  total_loss: 1.351  loss_cls: 0.3508  loss_box_reg: 0.5272  loss_mask: 0.3002  loss_rpn_cls: 0.04141  loss_rpn_loc: 0.1147  time: 0.9304  data_time: 0.2754  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:58:47 d2.utils.events]: \u001b[0m eta: 1:26:10  iter: 3079  total_loss: 1.23  loss_cls: 0.3058  loss_box_reg: 0.512  loss_mask: 0.2845  loss_rpn_cls: 0.02921  loss_rpn_loc: 0.08937  time: 0.9295  data_time: 0.1009  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:58:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:59:05 d2.utils.events]: \u001b[0m eta: 1:25:49  iter: 3099  total_loss: 1.262  loss_cls: 0.3251  loss_box_reg: 0.5052  loss_mask: 0.2872  loss_rpn_cls: 0.0356  loss_rpn_loc: 0.1082  time: 0.9296  data_time: 0.1404  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:59:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 13:59:28 d2.utils.events]: \u001b[0m eta: 1:25:34  iter: 3119  total_loss: 1.403  loss_cls: 0.3824  loss_box_reg: 0.5391  loss_mask: 0.2941  loss_rpn_cls: 0.05508  loss_rpn_loc: 0.1214  time: 0.9308  data_time: 0.3255  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:59:43 d2.utils.events]: \u001b[0m eta: 1:25:10  iter: 3139  total_loss: 1.308  loss_cls: 0.3139  loss_box_reg: 0.5493  loss_mask: 0.2971  loss_rpn_cls: 0.02692  loss_rpn_loc: 0.1078  time: 0.9298  data_time: 0.0569  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 13:59:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:59:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 13:59:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 13:59:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 13:59:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 13:59:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 13:59:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1426 s/iter. Eval: 0.0523 s/iter. Total: 0.1956 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 13:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1519 s/iter. Eval: 0.1255 s/iter. Total: 0.2783 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1534 s/iter. Eval: 0.1346 s/iter. Total: 0.2890 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0009 s/iter. Inference: 0.1507 s/iter. Eval: 0.1252 s/iter. Total: 0.2769 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 14:00:13 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1543 s/iter. Eval: 0.1459 s/iter. Total: 0.3012 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1574 s/iter. Eval: 0.1555 s/iter. Total: 0.3139 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1563 s/iter. Eval: 0.1536 s/iter. Total: 0.3109 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:00:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.486000 (0.305914 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:00:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.156060 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:00:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:00:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3044039159119936\n",
      "\u001b[32m[02/13 14:00:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:00:40 d2.utils.events]: \u001b[0m eta: 1:24:57  iter: 3159  total_loss: 1.366  loss_cls: 0.3571  loss_box_reg: 0.5415  loss_mask: 0.2947  loss_rpn_cls: 0.04358  loss_rpn_loc: 0.1179  time: 0.9298  data_time: 0.1347  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:00:56 d2.utils.events]: \u001b[0m eta: 1:24:35  iter: 3179  total_loss: 1.242  loss_cls: 0.2986  loss_box_reg: 0.5375  loss_mask: 0.2816  loss_rpn_cls: 0.02458  loss_rpn_loc: 0.1033  time: 0.9290  data_time: 0.1137  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:01:13 d2.utils.events]: \u001b[0m eta: 1:24:16  iter: 3199  total_loss: 1.302  loss_cls: 0.3517  loss_box_reg: 0.55  loss_mask: 0.2987  loss_rpn_cls: 0.03276  loss_rpn_loc: 0.1085  time: 0.9287  data_time: 0.1605  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:01:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:01:34 d2.utils.events]: \u001b[0m eta: 1:23:56  iter: 3219  total_loss: 1.252  loss_cls: 0.3277  loss_box_reg: 0.525  loss_mask: 0.2866  loss_rpn_cls: 0.02785  loss_rpn_loc: 0.1006  time: 0.9294  data_time: 0.2226  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:01:52 d2.utils.events]: \u001b[0m eta: 1:23:35  iter: 3239  total_loss: 1.379  loss_cls: 0.3427  loss_box_reg: 0.5492  loss_mask: 0.2902  loss_rpn_cls: 0.05182  loss_rpn_loc: 0.1191  time: 0.9292  data_time: 0.2032  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:02:11 d2.utils.events]: \u001b[0m eta: 1:23:08  iter: 3259  total_loss: 1.296  loss_cls: 0.3289  loss_box_reg: 0.5263  loss_mask: 0.2955  loss_rpn_cls: 0.03578  loss_rpn_loc: 0.1101  time: 0.9293  data_time: 0.2489  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:02:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:02:34 d2.utils.events]: \u001b[0m eta: 1:22:46  iter: 3279  total_loss: 1.361  loss_cls: 0.3594  loss_box_reg: 0.5337  loss_mask: 0.2903  loss_rpn_cls: 0.05349  loss_rpn_loc: 0.1103  time: 0.9305  data_time: 0.3312  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:02:52 d2.utils.events]: \u001b[0m eta: 1:22:31  iter: 3299  total_loss: 1.302  loss_cls: 0.3361  loss_box_reg: 0.5201  loss_mask: 0.2821  loss_rpn_cls: 0.04381  loss_rpn_loc: 0.102  time: 0.9306  data_time: 0.2023  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:03:11 d2.utils.events]: \u001b[0m eta: 1:22:09  iter: 3319  total_loss: 1.307  loss_cls: 0.3315  loss_box_reg: 0.5356  loss_mask: 0.2854  loss_rpn_cls: 0.03861  loss_rpn_loc: 0.1097  time: 0.9305  data_time: 0.2234  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:03:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:03:30 d2.utils.events]: \u001b[0m eta: 1:21:46  iter: 3339  total_loss: 1.239  loss_cls: 0.3161  loss_box_reg: 0.5214  loss_mask: 0.2802  loss_rpn_cls: 0.03641  loss_rpn_loc: 0.08647  time: 0.9307  data_time: 0.1667  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:03:46 d2.utils.events]: \u001b[0m eta: 1:21:30  iter: 3359  total_loss: 1.236  loss_cls: 0.31  loss_box_reg: 0.5136  loss_mask: 0.277  loss_rpn_cls: 0.03649  loss_rpn_loc: 0.1115  time: 0.9300  data_time: 0.1094  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:03:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:04:06 d2.utils.events]: \u001b[0m eta: 1:21:12  iter: 3379  total_loss: 1.367  loss_cls: 0.3462  loss_box_reg: 0.5532  loss_mask: 0.3017  loss_rpn_cls: 0.04329  loss_rpn_loc: 0.1076  time: 0.9302  data_time: 0.1900  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:04:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:04:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:04:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:04:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:04:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:04:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1453 s/iter. Eval: 0.0531 s/iter. Total: 0.1992 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1537 s/iter. Eval: 0.1271 s/iter. Total: 0.2818 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1557 s/iter. Eval: 0.1393 s/iter. Total: 0.2960 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1555 s/iter. Eval: 0.1313 s/iter. Total: 0.2878 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 14:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1576 s/iter. Eval: 0.1495 s/iter. Total: 0.3081 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1602 s/iter. Total: 0.3214 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1590 s/iter. Eval: 0.1578 s/iter. Total: 0.3178 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:04:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.250266 (0.312502 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:04:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158650 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:04:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:04:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30576358482690735\n",
      "\u001b[32m[02/13 14:05:04 d2.utils.events]: \u001b[0m eta: 1:21:03  iter: 3399  total_loss: 1.366  loss_cls: 0.345  loss_box_reg: 0.5568  loss_mask: 0.2972  loss_rpn_cls: 0.05  loss_rpn_loc: 0.1182  time: 0.9307  data_time: 0.2830  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:05:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:05:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:05:29 d2.utils.events]: \u001b[0m eta: 1:20:48  iter: 3419  total_loss: 1.342  loss_cls: 0.3328  loss_box_reg: 0.5556  loss_mask: 0.3026  loss_rpn_cls: 0.04502  loss_rpn_loc: 0.101  time: 0.9325  data_time: 0.3197  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:05:45 d2.utils.events]: \u001b[0m eta: 1:20:36  iter: 3439  total_loss: 1.186  loss_cls: 0.3061  loss_box_reg: 0.5011  loss_mask: 0.2725  loss_rpn_cls: 0.02748  loss_rpn_loc: 0.09799  time: 0.9318  data_time: 0.1182  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:06:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:06:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:06:07 d2.utils.events]: \u001b[0m eta: 1:20:16  iter: 3459  total_loss: 1.203  loss_cls: 0.3064  loss_box_reg: 0.5134  loss_mask: 0.2782  loss_rpn_cls: 0.03162  loss_rpn_loc: 0.0728  time: 0.9328  data_time: 0.1405  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:06:25 d2.utils.events]: \u001b[0m eta: 1:19:54  iter: 3479  total_loss: 1.295  loss_cls: 0.3248  loss_box_reg: 0.5407  loss_mask: 0.2915  loss_rpn_cls: 0.03784  loss_rpn_loc: 0.08881  time: 0.9324  data_time: 0.1616  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:06:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:06:44 d2.utils.events]: \u001b[0m eta: 1:19:28  iter: 3499  total_loss: 1.382  loss_cls: 0.3652  loss_box_reg: 0.5619  loss_mask: 0.3048  loss_rpn_cls: 0.04163  loss_rpn_loc: 0.1105  time: 0.9327  data_time: 0.1532  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:07:03 d2.utils.events]: \u001b[0m eta: 1:19:19  iter: 3519  total_loss: 1.357  loss_cls: 0.3361  loss_box_reg: 0.5398  loss_mask: 0.3016  loss_rpn_cls: 0.05513  loss_rpn_loc: 0.1183  time: 0.9327  data_time: 0.2237  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:07:18 d2.utils.events]: \u001b[0m eta: 1:18:59  iter: 3539  total_loss: 1.353  loss_cls: 0.3345  loss_box_reg: 0.571  loss_mask: 0.2933  loss_rpn_cls: 0.03615  loss_rpn_loc: 0.1074  time: 0.9316  data_time: 0.0375  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:07:34 d2.utils.events]: \u001b[0m eta: 1:18:51  iter: 3559  total_loss: 1.322  loss_cls: 0.3207  loss_box_reg: 0.5312  loss_mask: 0.2868  loss_rpn_cls: 0.03864  loss_rpn_loc: 0.1035  time: 0.9310  data_time: 0.1291  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:07:54 d2.utils.events]: \u001b[0m eta: 1:18:32  iter: 3579  total_loss: 1.33  loss_cls: 0.3251  loss_box_reg: 0.5658  loss_mask: 0.3  loss_rpn_cls: 0.03592  loss_rpn_loc: 0.1044  time: 0.9313  data_time: 0.2615  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:08:13 d2.utils.events]: \u001b[0m eta: 1:18:20  iter: 3599  total_loss: 1.386  loss_cls: 0.3603  loss_box_reg: 0.5429  loss_mask: 0.2954  loss_rpn_cls: 0.03946  loss_rpn_loc: 0.1155  time: 0.9315  data_time: 0.2547  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:08:31 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 3619  total_loss: 1.321  loss_cls: 0.3589  loss_box_reg: 0.5599  loss_mask: 0.2917  loss_rpn_cls: 0.04362  loss_rpn_loc: 0.1063  time: 0.9313  data_time: 0.1882  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:08:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:08:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:08:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:08:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:08:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:08:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1432 s/iter. Eval: 0.0518 s/iter. Total: 0.1959 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1526 s/iter. Eval: 0.1276 s/iter. Total: 0.2812 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:08:54 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1573 s/iter. Eval: 0.1390 s/iter. Total: 0.2973 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1537 s/iter. Eval: 0.1281 s/iter. Total: 0.2828 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 14:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1566 s/iter. Eval: 0.1470 s/iter. Total: 0.3046 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1592 s/iter. Eval: 0.1564 s/iter. Total: 0.3167 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1580 s/iter. Eval: 0.1542 s/iter. Total: 0.3131 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:09:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.793966 (0.308569 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:09:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157635 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:09:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:09:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3061114182725094\n",
      "\u001b[32m[02/13 14:09:25 d2.utils.events]: \u001b[0m eta: 1:18:02  iter: 3639  total_loss: 1.337  loss_cls: 0.3584  loss_box_reg: 0.5134  loss_mask: 0.2814  loss_rpn_cls: 0.04808  loss_rpn_loc: 0.1135  time: 0.9305  data_time: 0.0869  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:09:42 d2.utils.events]: \u001b[0m eta: 1:17:38  iter: 3659  total_loss: 1.327  loss_cls: 0.3493  loss_box_reg: 0.5482  loss_mask: 0.3031  loss_rpn_cls: 0.03802  loss_rpn_loc: 0.09998  time: 0.9300  data_time: 0.1193  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:10:01 d2.utils.events]: \u001b[0m eta: 1:17:22  iter: 3679  total_loss: 1.322  loss_cls: 0.3535  loss_box_reg: 0.5257  loss_mask: 0.2927  loss_rpn_cls: 0.03818  loss_rpn_loc: 0.1128  time: 0.9303  data_time: 0.2873  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:10:21 d2.utils.events]: \u001b[0m eta: 1:17:01  iter: 3699  total_loss: 1.228  loss_cls: 0.3089  loss_box_reg: 0.4944  loss_mask: 0.2792  loss_rpn_cls: 0.02767  loss_rpn_loc: 0.09498  time: 0.9306  data_time: 0.2816  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:10:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:10:44 d2.utils.events]: \u001b[0m eta: 1:16:46  iter: 3719  total_loss: 1.25  loss_cls: 0.3249  loss_box_reg: 0.5027  loss_mask: 0.3007  loss_rpn_cls: 0.03707  loss_rpn_loc: 0.08968  time: 0.9316  data_time: 0.2749  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:10:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:11:02 d2.utils.events]: \u001b[0m eta: 1:16:34  iter: 3739  total_loss: 1.308  loss_cls: 0.3417  loss_box_reg: 0.5316  loss_mask: 0.2851  loss_rpn_cls: 0.02732  loss_rpn_loc: 0.1079  time: 0.9316  data_time: 0.1230  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:11:18 d2.utils.events]: \u001b[0m eta: 1:16:16  iter: 3759  total_loss: 1.293  loss_cls: 0.3125  loss_box_reg: 0.5433  loss_mask: 0.3029  loss_rpn_cls: 0.04145  loss_rpn_loc: 0.1043  time: 0.9309  data_time: 0.0859  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:11:34 d2.utils.events]: \u001b[0m eta: 1:16:02  iter: 3779  total_loss: 1.345  loss_cls: 0.3492  loss_box_reg: 0.5468  loss_mask: 0.3019  loss_rpn_cls: 0.02654  loss_rpn_loc: 0.1139  time: 0.9302  data_time: 0.0993  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:11:50 d2.utils.events]: \u001b[0m eta: 1:15:42  iter: 3799  total_loss: 1.168  loss_cls: 0.2832  loss_box_reg: 0.5018  loss_mask: 0.2785  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.07227  time: 0.9294  data_time: 0.0944  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:12:10 d2.utils.events]: \u001b[0m eta: 1:15:31  iter: 3819  total_loss: 1.264  loss_cls: 0.3343  loss_box_reg: 0.5233  loss_mask: 0.2857  loss_rpn_cls: 0.04036  loss_rpn_loc: 0.1131  time: 0.9297  data_time: 0.2770  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:12:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:12:30 d2.utils.events]: \u001b[0m eta: 1:15:19  iter: 3839  total_loss: 1.381  loss_cls: 0.3498  loss_box_reg: 0.5468  loss_mask: 0.3092  loss_rpn_cls: 0.02895  loss_rpn_loc: 0.1039  time: 0.9302  data_time: 0.1999  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:12:47 d2.utils.events]: \u001b[0m eta: 1:15:02  iter: 3859  total_loss: 1.307  loss_cls: 0.3426  loss_box_reg: 0.5356  loss_mask: 0.2925  loss_rpn_cls: 0.04678  loss_rpn_loc: 0.12  time: 0.9297  data_time: 0.1397  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:12:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:12:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:12:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:12:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:12:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:12:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1457 s/iter. Eval: 0.0539 s/iter. Total: 0.2004 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1523 s/iter. Eval: 0.1167 s/iter. Total: 0.2699 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:13:10 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1558 s/iter. Eval: 0.1407 s/iter. Total: 0.2975 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1557 s/iter. Eval: 0.1318 s/iter. Total: 0.2885 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 14:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1580 s/iter. Eval: 0.1494 s/iter. Total: 0.3084 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1595 s/iter. Total: 0.3213 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0009 s/iter. Inference: 0.1595 s/iter. Eval: 0.1570 s/iter. Total: 0.3175 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:13:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.249871 (0.312499 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:13:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:13:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:13:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3046504992016705\n",
      "\u001b[32m[02/13 14:13:42 d2.utils.events]: \u001b[0m eta: 1:14:49  iter: 3879  total_loss: 1.431  loss_cls: 0.3626  loss_box_reg: 0.5748  loss_mask: 0.299  loss_rpn_cls: 0.05474  loss_rpn_loc: 0.1188  time: 0.9291  data_time: 0.1286  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:13:59 d2.utils.events]: \u001b[0m eta: 1:14:35  iter: 3899  total_loss: 1.279  loss_cls: 0.3261  loss_box_reg: 0.5563  loss_mask: 0.2814  loss_rpn_cls: 0.02863  loss_rpn_loc: 0.1024  time: 0.9289  data_time: 0.1639  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:14:19 d2.utils.events]: \u001b[0m eta: 1:14:22  iter: 3919  total_loss: 1.479  loss_cls: 0.3856  loss_box_reg: 0.5508  loss_mask: 0.3012  loss_rpn_cls: 0.04688  loss_rpn_loc: 0.1265  time: 0.9293  data_time: 0.2712  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:14:38 d2.utils.events]: \u001b[0m eta: 1:14:11  iter: 3939  total_loss: 1.386  loss_cls: 0.3369  loss_box_reg: 0.5858  loss_mask: 0.3106  loss_rpn_cls: 0.04068  loss_rpn_loc: 0.1038  time: 0.9293  data_time: 0.2158  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:14:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:14:58 d2.utils.events]: \u001b[0m eta: 1:13:53  iter: 3959  total_loss: 1.234  loss_cls: 0.3091  loss_box_reg: 0.5287  loss_mask: 0.2739  loss_rpn_cls: 0.03083  loss_rpn_loc: 0.08495  time: 0.9296  data_time: 0.2087  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:15:12 d2.utils.events]: \u001b[0m eta: 1:13:35  iter: 3979  total_loss: 1.207  loss_cls: 0.2915  loss_box_reg: 0.5053  loss_mask: 0.2864  loss_rpn_cls: 0.02376  loss_rpn_loc: 0.07407  time: 0.9286  data_time: 0.0672  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:15:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:15:32 d2.utils.events]: \u001b[0m eta: 1:13:22  iter: 3999  total_loss: 1.413  loss_cls: 0.3736  loss_box_reg: 0.5603  loss_mask: 0.3006  loss_rpn_cls: 0.05503  loss_rpn_loc: 0.116  time: 0.9289  data_time: 0.1744  lr: 6.4e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:15:48 d2.utils.events]: \u001b[0m eta: 1:13:09  iter: 4019  total_loss: 1.37  loss_cls: 0.3617  loss_box_reg: 0.5319  loss_mask: 0.2968  loss_rpn_cls: 0.05163  loss_rpn_loc: 0.1191  time: 0.9283  data_time: 0.1300  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:15:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:16:10 d2.utils.events]: \u001b[0m eta: 1:12:54  iter: 4039  total_loss: 1.276  loss_cls: 0.3551  loss_box_reg: 0.5069  loss_mask: 0.2949  loss_rpn_cls: 0.03288  loss_rpn_loc: 0.1007  time: 0.9292  data_time: 0.2804  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:16:27 d2.utils.events]: \u001b[0m eta: 1:12:35  iter: 4059  total_loss: 1.28  loss_cls: 0.3234  loss_box_reg: 0.5373  loss_mask: 0.2956  loss_rpn_cls: 0.03499  loss_rpn_loc: 0.08186  time: 0.9288  data_time: 0.1392  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:16:42 d2.utils.events]: \u001b[0m eta: 1:12:22  iter: 4079  total_loss: 1.298  loss_cls: 0.3437  loss_box_reg: 0.5286  loss_mask: 0.2841  loss_rpn_cls: 0.04338  loss_rpn_loc: 0.1054  time: 0.9279  data_time: 0.0379  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:17:01 d2.utils.events]: \u001b[0m eta: 1:12:06  iter: 4099  total_loss: 1.294  loss_cls: 0.3468  loss_box_reg: 0.5324  loss_mask: 0.2879  loss_rpn_cls: 0.03521  loss_rpn_loc: 0.1004  time: 0.9278  data_time: 0.2032  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:17:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:17:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:17:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:17:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:17:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:17:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:17:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1431 s/iter. Eval: 0.0511 s/iter. Total: 0.1950 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:17:22 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1523 s/iter. Eval: 0.1263 s/iter. Total: 0.2796 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:17:27 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1541 s/iter. Eval: 0.1386 s/iter. Total: 0.2937 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1516 s/iter. Eval: 0.1285 s/iter. Total: 0.2811 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 14:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1561 s/iter. Eval: 0.1471 s/iter. Total: 0.3042 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1587 s/iter. Eval: 0.1566 s/iter. Total: 0.3163 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1571 s/iter. Eval: 0.1529 s/iter. Total: 0.3110 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:17:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.657785 (0.307395 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:17:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157033 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:17:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:17:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30528019939761936\n",
      "\u001b[32m[02/13 14:17:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:18:00 d2.utils.events]: \u001b[0m eta: 1:11:52  iter: 4119  total_loss: 1.355  loss_cls: 0.3589  loss_box_reg: 0.5405  loss_mask: 0.2969  loss_rpn_cls: 0.05351  loss_rpn_loc: 0.1174  time: 0.9286  data_time: 0.2821  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:18:17 d2.utils.events]: \u001b[0m eta: 1:11:36  iter: 4139  total_loss: 1.344  loss_cls: 0.3524  loss_box_reg: 0.5399  loss_mask: 0.2993  loss_rpn_cls: 0.03087  loss_rpn_loc: 0.1082  time: 0.9283  data_time: 0.1581  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:18:36 d2.utils.events]: \u001b[0m eta: 1:11:22  iter: 4159  total_loss: 1.403  loss_cls: 0.3707  loss_box_reg: 0.5514  loss_mask: 0.303  loss_rpn_cls: 0.05526  loss_rpn_loc: 0.1225  time: 0.9283  data_time: 0.2084  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:18:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:18:58 d2.utils.events]: \u001b[0m eta: 1:11:06  iter: 4179  total_loss: 1.307  loss_cls: 0.3416  loss_box_reg: 0.526  loss_mask: 0.2929  loss_rpn_cls: 0.04289  loss_rpn_loc: 0.1065  time: 0.9290  data_time: 0.2416  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:19:16 d2.utils.events]: \u001b[0m eta: 1:10:54  iter: 4199  total_loss: 1.408  loss_cls: 0.3785  loss_box_reg: 0.5691  loss_mask: 0.2975  loss_rpn_cls: 0.05234  loss_rpn_loc: 0.1164  time: 0.9289  data_time: 0.1890  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:19:35 d2.utils.events]: \u001b[0m eta: 1:10:37  iter: 4219  total_loss: 1.341  loss_cls: 0.3432  loss_box_reg: 0.5366  loss_mask: 0.292  loss_rpn_cls: 0.03478  loss_rpn_loc: 0.112  time: 0.9290  data_time: 0.2466  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:19:49 d2.utils.events]: \u001b[0m eta: 1:10:15  iter: 4239  total_loss: 1.256  loss_cls: 0.326  loss_box_reg: 0.5314  loss_mask: 0.2815  loss_rpn_cls: 0.03898  loss_rpn_loc: 0.09869  time: 0.9280  data_time: 0.0582  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:20:10 d2.utils.events]: \u001b[0m eta: 1:10:02  iter: 4259  total_loss: 1.292  loss_cls: 0.3289  loss_box_reg: 0.5526  loss_mask: 0.2884  loss_rpn_cls: 0.03807  loss_rpn_loc: 0.109  time: 0.9287  data_time: 0.3627  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:20:28 d2.utils.events]: \u001b[0m eta: 1:09:48  iter: 4279  total_loss: 1.301  loss_cls: 0.3312  loss_box_reg: 0.5329  loss_mask: 0.3009  loss_rpn_cls: 0.03735  loss_rpn_loc: 0.1041  time: 0.9284  data_time: 0.1473  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:20:45 d2.utils.events]: \u001b[0m eta: 1:09:28  iter: 4299  total_loss: 1.295  loss_cls: 0.338  loss_box_reg: 0.5375  loss_mask: 0.2786  loss_rpn_cls: 0.02199  loss_rpn_loc: 0.0985  time: 0.9280  data_time: 0.1404  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:20:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:21:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:21:06 d2.utils.events]: \u001b[0m eta: 1:09:17  iter: 4319  total_loss: 1.321  loss_cls: 0.3381  loss_box_reg: 0.5394  loss_mask: 0.2823  loss_rpn_cls: 0.03614  loss_rpn_loc: 0.1112  time: 0.9287  data_time: 0.1721  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:21:25 d2.utils.events]: \u001b[0m eta: 1:09:06  iter: 4339  total_loss: 1.398  loss_cls: 0.362  loss_box_reg: 0.5188  loss_mask: 0.2928  loss_rpn_cls: 0.05151  loss_rpn_loc: 0.1317  time: 0.9286  data_time: 0.1879  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:21:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:21:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:21:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:21:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:21:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:21:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1439 s/iter. Eval: 0.0512 s/iter. Total: 0.1960 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1535 s/iter. Eval: 0.1267 s/iter. Total: 0.2812 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1555 s/iter. Eval: 0.1377 s/iter. Total: 0.2942 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1554 s/iter. Eval: 0.1297 s/iter. Total: 0.2862 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 14:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1576 s/iter. Eval: 0.1467 s/iter. Total: 0.3053 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1615 s/iter. Eval: 0.1566 s/iter. Total: 0.3192 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1527 s/iter. Total: 0.3134 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:22:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.951042 (0.309923 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:22:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159531 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:22:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:22:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3053909198451669\n",
      "\u001b[32m[02/13 14:22:19 d2.utils.events]: \u001b[0m eta: 1:08:53  iter: 4359  total_loss: 1.287  loss_cls: 0.3407  loss_box_reg: 0.5299  loss_mask: 0.2791  loss_rpn_cls: 0.03876  loss_rpn_loc: 0.09927  time: 0.9281  data_time: 0.1204  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:22:34 d2.utils.events]: \u001b[0m eta: 1:08:30  iter: 4379  total_loss: 1.173  loss_cls: 0.299  loss_box_reg: 0.5021  loss_mask: 0.272  loss_rpn_cls: 0.0243  loss_rpn_loc: 0.0809  time: 0.9272  data_time: 0.0612  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:22:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:22:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:23:01 d2.utils.events]: \u001b[0m eta: 1:08:13  iter: 4399  total_loss: 1.244  loss_cls: 0.3292  loss_box_reg: 0.5155  loss_mask: 0.2857  loss_rpn_cls: 0.03395  loss_rpn_loc: 0.107  time: 0.9292  data_time: 0.4237  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:23:17 d2.utils.events]: \u001b[0m eta: 1:08:01  iter: 4419  total_loss: 1.265  loss_cls: 0.3264  loss_box_reg: 0.5187  loss_mask: 0.2886  loss_rpn_cls: 0.03031  loss_rpn_loc: 0.09909  time: 0.9286  data_time: 0.0956  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:23:38 d2.utils.events]: \u001b[0m eta: 1:07:48  iter: 4439  total_loss: 1.366  loss_cls: 0.3509  loss_box_reg: 0.5512  loss_mask: 0.2959  loss_rpn_cls: 0.04353  loss_rpn_loc: 0.1168  time: 0.9291  data_time: 0.2948  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:23:54 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 4459  total_loss: 1.191  loss_cls: 0.2955  loss_box_reg: 0.516  loss_mask: 0.282  loss_rpn_cls: 0.0342  loss_rpn_loc: 0.09299  time: 0.9286  data_time: 0.1058  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:24:10 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 4479  total_loss: 1.354  loss_cls: 0.334  loss_box_reg: 0.5548  loss_mask: 0.2955  loss_rpn_cls: 0.0289  loss_rpn_loc: 0.1068  time: 0.9281  data_time: 0.1324  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:24:29 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 4499  total_loss: 1.363  loss_cls: 0.3549  loss_box_reg: 0.5488  loss_mask: 0.295  loss_rpn_cls: 0.04109  loss_rpn_loc: 0.1268  time: 0.9280  data_time: 0.1803  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:24:47 d2.utils.events]: \u001b[0m eta: 1:06:51  iter: 4519  total_loss: 1.405  loss_cls: 0.3594  loss_box_reg: 0.5786  loss_mask: 0.3058  loss_rpn_cls: 0.04637  loss_rpn_loc: 0.1184  time: 0.9280  data_time: 0.2084  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:25:05 d2.utils.events]: \u001b[0m eta: 1:06:36  iter: 4539  total_loss: 1.303  loss_cls: 0.342  loss_box_reg: 0.5374  loss_mask: 0.2954  loss_rpn_cls: 0.03085  loss_rpn_loc: 0.1037  time: 0.9277  data_time: 0.1712  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:25:23 d2.utils.events]: \u001b[0m eta: 1:06:21  iter: 4559  total_loss: 1.18  loss_cls: 0.314  loss_box_reg: 0.5021  loss_mask: 0.276  loss_rpn_cls: 0.03408  loss_rpn_loc: 0.08887  time: 0.9278  data_time: 0.2361  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:25:41 d2.utils.events]: \u001b[0m eta: 1:06:05  iter: 4579  total_loss: 1.248  loss_cls: 0.3321  loss_box_reg: 0.521  loss_mask: 0.2955  loss_rpn_cls: 0.04031  loss_rpn_loc: 0.09589  time: 0.9277  data_time: 0.1958  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:25:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:26:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:26:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:26:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:26:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:26:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:26:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:26:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1446 s/iter. Eval: 0.0533 s/iter. Total: 0.1988 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1532 s/iter. Eval: 0.1285 s/iter. Total: 0.2827 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 14:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1551 s/iter. Eval: 0.1398 s/iter. Total: 0.2959 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1532 s/iter. Eval: 0.1315 s/iter. Total: 0.2856 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 14:26:29 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1556 s/iter. Eval: 0.1492 s/iter. Total: 0.3058 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1602 s/iter. Total: 0.3214 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:26:39 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1588 s/iter. Eval: 0.1574 s/iter. Total: 0.3172 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:26:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.216559 (0.312212 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:26:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158373 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:26:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:26:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3035720016342454\n",
      "\u001b[32m[02/13 14:26:44 d2.utils.events]: \u001b[0m eta: 1:05:50  iter: 4599  total_loss: 1.405  loss_cls: 0.3497  loss_box_reg: 0.574  loss_mask: 0.3155  loss_rpn_cls: 0.0449  loss_rpn_loc: 0.1094  time: 0.9288  data_time: 0.2490  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:27:02 d2.utils.events]: \u001b[0m eta: 1:05:36  iter: 4619  total_loss: 1.34  loss_cls: 0.3489  loss_box_reg: 0.5535  loss_mask: 0.297  loss_rpn_cls: 0.04745  loss_rpn_loc: 0.1255  time: 0.9288  data_time: 0.1941  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:27:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:27:22 d2.utils.events]: \u001b[0m eta: 1:05:20  iter: 4639  total_loss: 1.211  loss_cls: 0.3051  loss_box_reg: 0.4902  loss_mask: 0.2786  loss_rpn_cls: 0.02716  loss_rpn_loc: 0.09101  time: 0.9290  data_time: 0.1397  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:27:41 d2.utils.events]: \u001b[0m eta: 1:05:07  iter: 4659  total_loss: 1.337  loss_cls: 0.3589  loss_box_reg: 0.5326  loss_mask: 0.2974  loss_rpn_cls: 0.05106  loss_rpn_loc: 0.112  time: 0.9291  data_time: 0.2205  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:27:57 d2.utils.events]: \u001b[0m eta: 1:04:52  iter: 4679  total_loss: 1.395  loss_cls: 0.3707  loss_box_reg: 0.5714  loss_mask: 0.2887  loss_rpn_cls: 0.041  loss_rpn_loc: 0.1212  time: 0.9287  data_time: 0.1281  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:28:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:28:17 d2.utils.events]: \u001b[0m eta: 1:04:38  iter: 4699  total_loss: 1.238  loss_cls: 0.3237  loss_box_reg: 0.5145  loss_mask: 0.286  loss_rpn_cls: 0.02529  loss_rpn_loc: 0.09577  time: 0.9289  data_time: 0.1468  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:28:33 d2.utils.events]: \u001b[0m eta: 1:04:23  iter: 4719  total_loss: 1.217  loss_cls: 0.3254  loss_box_reg: 0.5081  loss_mask: 0.2832  loss_rpn_cls: 0.03036  loss_rpn_loc: 0.06876  time: 0.9283  data_time: 0.1100  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:28:49 d2.utils.events]: \u001b[0m eta: 1:04:09  iter: 4739  total_loss: 1.395  loss_cls: 0.3353  loss_box_reg: 0.5465  loss_mask: 0.299  loss_rpn_cls: 0.03748  loss_rpn_loc: 0.1098  time: 0.9278  data_time: 0.0983  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:29:07 d2.utils.events]: \u001b[0m eta: 1:03:54  iter: 4759  total_loss: 1.284  loss_cls: 0.3333  loss_box_reg: 0.529  loss_mask: 0.2943  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.09977  time: 0.9277  data_time: 0.1945  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:29:23 d2.utils.events]: \u001b[0m eta: 1:03:36  iter: 4779  total_loss: 1.242  loss_cls: 0.3056  loss_box_reg: 0.5202  loss_mask: 0.2926  loss_rpn_cls: 0.03304  loss_rpn_loc: 0.1085  time: 0.9271  data_time: 0.1121  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:29:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:29:46 d2.utils.events]: \u001b[0m eta: 1:03:30  iter: 4799  total_loss: 1.363  loss_cls: 0.3539  loss_box_reg: 0.5437  loss_mask: 0.3013  loss_rpn_cls: 0.05288  loss_rpn_loc: 0.1099  time: 0.9282  data_time: 0.3740  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:30:03 d2.utils.events]: \u001b[0m eta: 1:03:13  iter: 4819  total_loss: 1.352  loss_cls: 0.3513  loss_box_reg: 0.5289  loss_mask: 0.2831  loss_rpn_cls: 0.04314  loss_rpn_loc: 0.1142  time: 0.9277  data_time: 0.1054  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:30:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:30:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:30:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:30:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:30:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:30:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1437 s/iter. Eval: 0.0515 s/iter. Total: 0.1960 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1524 s/iter. Eval: 0.1265 s/iter. Total: 0.2799 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1545 s/iter. Eval: 0.1394 s/iter. Total: 0.2949 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1524 s/iter. Eval: 0.1316 s/iter. Total: 0.2849 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 14:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1549 s/iter. Eval: 0.1488 s/iter. Total: 0.3047 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1578 s/iter. Eval: 0.1585 s/iter. Total: 0.3173 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1563 s/iter. Eval: 0.1544 s/iter. Total: 0.3118 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:30:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.773979 (0.308396 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:30:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.156405 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:30:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:30:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30524600386793377\n",
      "\u001b[32m[02/13 14:30:57 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 4839  total_loss: 1.324  loss_cls: 0.3431  loss_box_reg: 0.5704  loss_mask: 0.303  loss_rpn_cls: 0.04232  loss_rpn_loc: 0.1144  time: 0.9273  data_time: 0.1235  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:31:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:31:18 d2.utils.events]: \u001b[0m eta: 1:02:45  iter: 4859  total_loss: 1.389  loss_cls: 0.3555  loss_box_reg: 0.5652  loss_mask: 0.295  loss_rpn_cls: 0.03274  loss_rpn_loc: 0.1019  time: 0.9277  data_time: 0.1991  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:31:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:31:40 d2.utils.events]: \u001b[0m eta: 1:02:28  iter: 4879  total_loss: 1.335  loss_cls: 0.3341  loss_box_reg: 0.5672  loss_mask: 0.2976  loss_rpn_cls: 0.03903  loss_rpn_loc: 0.09317  time: 0.9285  data_time: 0.2597  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:31:58 d2.utils.events]: \u001b[0m eta: 1:02:12  iter: 4899  total_loss: 1.263  loss_cls: 0.3291  loss_box_reg: 0.528  loss_mask: 0.2864  loss_rpn_cls: 0.04159  loss_rpn_loc: 0.0938  time: 0.9283  data_time: 0.1755  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:32:14 d2.utils.events]: \u001b[0m eta: 1:01:52  iter: 4919  total_loss: 1.278  loss_cls: 0.3412  loss_box_reg: 0.5361  loss_mask: 0.291  loss_rpn_cls: 0.04092  loss_rpn_loc: 0.104  time: 0.9277  data_time: 0.0987  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:32:31 d2.utils.events]: \u001b[0m eta: 1:01:43  iter: 4939  total_loss: 1.229  loss_cls: 0.3065  loss_box_reg: 0.5369  loss_mask: 0.2853  loss_rpn_cls: 0.02937  loss_rpn_loc: 0.09836  time: 0.9276  data_time: 0.1600  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:32:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:32:50 d2.utils.events]: \u001b[0m eta: 1:01:29  iter: 4959  total_loss: 1.228  loss_cls: 0.3145  loss_box_reg: 0.5474  loss_mask: 0.282  loss_rpn_cls: 0.02793  loss_rpn_loc: 0.0881  time: 0.9276  data_time: 0.1438  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:32:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:33:12 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 4979  total_loss: 1.297  loss_cls: 0.351  loss_box_reg: 0.5622  loss_mask: 0.281  loss_rpn_cls: 0.03803  loss_rpn_loc: 0.1078  time: 0.9283  data_time: 0.2897  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:33:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:33:33 d2.utils.events]: \u001b[0m eta: 1:00:51  iter: 4999  total_loss: 1.227  loss_cls: 0.3089  loss_box_reg: 0.5238  loss_mask: 0.3057  loss_rpn_cls: 0.03664  loss_rpn_loc: 0.09752  time: 0.9287  data_time: 0.2148  lr: 5.12e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:33:49 d2.utils.events]: \u001b[0m eta: 1:00:37  iter: 5019  total_loss: 1.202  loss_cls: 0.2833  loss_box_reg: 0.5007  loss_mask: 0.2801  loss_rpn_cls: 0.02456  loss_rpn_loc: 0.06833  time: 0.9283  data_time: 0.1515  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:34:06 d2.utils.events]: \u001b[0m eta: 1:00:19  iter: 5039  total_loss: 1.311  loss_cls: 0.3318  loss_box_reg: 0.5412  loss_mask: 0.2842  loss_rpn_cls: 0.02812  loss_rpn_loc: 0.1041  time: 0.9279  data_time: 0.1197  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:34:27 d2.utils.events]: \u001b[0m eta: 1:00:19  iter: 5059  total_loss: 1.398  loss_cls: 0.3659  loss_box_reg: 0.5494  loss_mask: 0.2898  loss_rpn_cls: 0.04841  loss_rpn_loc: 0.1236  time: 0.9285  data_time: 0.3256  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:34:47 d2.utils.events]: \u001b[0m eta: 1:00:06  iter: 5079  total_loss: 1.353  loss_cls: 0.3642  loss_box_reg: 0.5236  loss_mask: 0.3021  loss_rpn_cls: 0.05156  loss_rpn_loc: 0.1108  time: 0.9288  data_time: 0.2868  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:34:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:34:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:34:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:34:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:34:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:34:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1420 s/iter. Eval: 0.0505 s/iter. Total: 0.1932 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1517 s/iter. Eval: 0.1265 s/iter. Total: 0.2793 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1570 s/iter. Eval: 0.1394 s/iter. Total: 0.2974 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1534 s/iter. Eval: 0.1297 s/iter. Total: 0.2841 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 14:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1561 s/iter. Eval: 0.1487 s/iter. Total: 0.3059 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1585 s/iter. Total: 0.3197 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1587 s/iter. Eval: 0.1561 s/iter. Total: 0.3158 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:35:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.009423 (0.310426 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:35:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158191 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:35:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:35:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30707437654906894\n",
      "\u001b[32m[02/13 14:35:44 d2.utils.events]: \u001b[0m eta: 1:00:03  iter: 5099  total_loss: 1.358  loss_cls: 0.3405  loss_box_reg: 0.536  loss_mask: 0.2987  loss_rpn_cls: 0.04431  loss_rpn_loc: 0.1178  time: 0.9288  data_time: 0.1948  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:36:03 d2.utils.events]: \u001b[0m eta: 0:59:38  iter: 5119  total_loss: 1.352  loss_cls: 0.3208  loss_box_reg: 0.546  loss_mask: 0.2882  loss_rpn_cls: 0.03706  loss_rpn_loc: 0.09089  time: 0.9287  data_time: 0.2168  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:36:20 d2.utils.events]: \u001b[0m eta: 0:59:28  iter: 5139  total_loss: 1.361  loss_cls: 0.3338  loss_box_reg: 0.5329  loss_mask: 0.2937  loss_rpn_cls: 0.05166  loss_rpn_loc: 0.1271  time: 0.9285  data_time: 0.1588  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:36:40 d2.utils.events]: \u001b[0m eta: 0:59:08  iter: 5159  total_loss: 1.21  loss_cls: 0.3157  loss_box_reg: 0.5108  loss_mask: 0.2824  loss_rpn_cls: 0.03457  loss_rpn_loc: 0.1098  time: 0.9288  data_time: 0.2736  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:37:00 d2.utils.events]: \u001b[0m eta: 0:58:58  iter: 5179  total_loss: 1.341  loss_cls: 0.3446  loss_box_reg: 0.5298  loss_mask: 0.2979  loss_rpn_cls: 0.03775  loss_rpn_loc: 0.1066  time: 0.9290  data_time: 0.2631  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:37:17 d2.utils.events]: \u001b[0m eta: 0:58:39  iter: 5199  total_loss: 1.314  loss_cls: 0.3536  loss_box_reg: 0.517  loss_mask: 0.2912  loss_rpn_cls: 0.03431  loss_rpn_loc: 0.1091  time: 0.9288  data_time: 0.1663  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:37:36 d2.utils.events]: \u001b[0m eta: 0:58:35  iter: 5219  total_loss: 1.36  loss_cls: 0.3675  loss_box_reg: 0.5538  loss_mask: 0.285  loss_rpn_cls: 0.03664  loss_rpn_loc: 0.1224  time: 0.9288  data_time: 0.2090  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:37:54 d2.utils.events]: \u001b[0m eta: 0:58:28  iter: 5239  total_loss: 1.301  loss_cls: 0.339  loss_box_reg: 0.5258  loss_mask: 0.2907  loss_rpn_cls: 0.03083  loss_rpn_loc: 0.116  time: 0.9287  data_time: 0.1785  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:38:09 d2.utils.events]: \u001b[0m eta: 0:58:08  iter: 5259  total_loss: 1.353  loss_cls: 0.3504  loss_box_reg: 0.5296  loss_mask: 0.2783  loss_rpn_cls: 0.02498  loss_rpn_loc: 0.1068  time: 0.9281  data_time: 0.0815  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:38:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:38:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:38:32 d2.utils.events]: \u001b[0m eta: 0:57:54  iter: 5279  total_loss: 1.335  loss_cls: 0.353  loss_box_reg: 0.5708  loss_mask: 0.3047  loss_rpn_cls: 0.04508  loss_rpn_loc: 0.1071  time: 0.9289  data_time: 0.2267  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:38:48 d2.utils.events]: \u001b[0m eta: 0:57:40  iter: 5299  total_loss: 1.347  loss_cls: 0.3605  loss_box_reg: 0.5238  loss_mask: 0.2973  loss_rpn_cls: 0.03521  loss_rpn_loc: 0.08808  time: 0.9285  data_time: 0.1053  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:38:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:39:11 d2.utils.events]: \u001b[0m eta: 0:57:25  iter: 5319  total_loss: 1.278  loss_cls: 0.3257  loss_box_reg: 0.5231  loss_mask: 0.2895  loss_rpn_cls: 0.04634  loss_rpn_loc: 0.0983  time: 0.9293  data_time: 0.3193  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:39:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:39:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:39:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:39:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:39:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:39:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:39:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1440 s/iter. Eval: 0.0522 s/iter. Total: 0.1970 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:39:24 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1528 s/iter. Eval: 0.1286 s/iter. Total: 0.2824 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:39:29 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1579 s/iter. Eval: 0.1411 s/iter. Total: 0.3000 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1547 s/iter. Eval: 0.1330 s/iter. Total: 0.2887 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 14:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1572 s/iter. Eval: 0.1508 s/iter. Total: 0.3090 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:39:46 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1612 s/iter. Eval: 0.1613 s/iter. Total: 0.3235 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:39:51 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1597 s/iter. Eval: 0.1590 s/iter. Total: 0.3197 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:39:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.476376 (0.314452 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:39:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159303 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:39:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:39:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3070330010283197\n",
      "\u001b[32m[02/13 14:40:07 d2.utils.events]: \u001b[0m eta: 0:57:07  iter: 5339  total_loss: 1.215  loss_cls: 0.2802  loss_box_reg: 0.5054  loss_mask: 0.2853  loss_rpn_cls: 0.03107  loss_rpn_loc: 0.07968  time: 0.9291  data_time: 0.1373  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:40:27 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 5359  total_loss: 1.364  loss_cls: 0.3447  loss_box_reg: 0.5584  loss_mask: 0.2948  loss_rpn_cls: 0.0487  loss_rpn_loc: 0.1246  time: 0.9294  data_time: 0.2839  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:40:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:40:46 d2.utils.events]: \u001b[0m eta: 0:56:41  iter: 5379  total_loss: 1.281  loss_cls: 0.3192  loss_box_reg: 0.5197  loss_mask: 0.2838  loss_rpn_cls: 0.02982  loss_rpn_loc: 0.107  time: 0.9294  data_time: 0.1476  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:41:03 d2.utils.events]: \u001b[0m eta: 0:56:27  iter: 5399  total_loss: 1.332  loss_cls: 0.352  loss_box_reg: 0.5418  loss_mask: 0.3026  loss_rpn_cls: 0.04079  loss_rpn_loc: 0.1025  time: 0.9291  data_time: 0.1330  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:41:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:41:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:41:30 d2.utils.events]: \u001b[0m eta: 0:56:12  iter: 5419  total_loss: 1.32  loss_cls: 0.3522  loss_box_reg: 0.5173  loss_mask: 0.2865  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.1105  time: 0.9305  data_time: 0.3127  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:41:47 d2.utils.events]: \u001b[0m eta: 0:55:57  iter: 5439  total_loss: 1.334  loss_cls: 0.3369  loss_box_reg: 0.5595  loss_mask: 0.2862  loss_rpn_cls: 0.04387  loss_rpn_loc: 0.1097  time: 0.9303  data_time: 0.1493  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:42:04 d2.utils.events]: \u001b[0m eta: 0:55:43  iter: 5459  total_loss: 1.287  loss_cls: 0.3057  loss_box_reg: 0.5251  loss_mask: 0.2897  loss_rpn_cls: 0.03362  loss_rpn_loc: 0.1085  time: 0.9300  data_time: 0.1494  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:42:20 d2.utils.events]: \u001b[0m eta: 0:55:28  iter: 5479  total_loss: 1.281  loss_cls: 0.3339  loss_box_reg: 0.5241  loss_mask: 0.2916  loss_rpn_cls: 0.03894  loss_rpn_loc: 0.09251  time: 0.9296  data_time: 0.1123  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:42:40 d2.utils.events]: \u001b[0m eta: 0:55:19  iter: 5499  total_loss: 1.317  loss_cls: 0.3421  loss_box_reg: 0.5221  loss_mask: 0.2907  loss_rpn_cls: 0.05079  loss_rpn_loc: 0.1128  time: 0.9297  data_time: 0.2623  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:42:56 d2.utils.events]: \u001b[0m eta: 0:55:05  iter: 5519  total_loss: 1.209  loss_cls: 0.3073  loss_box_reg: 0.5044  loss_mask: 0.2745  loss_rpn_cls: 0.02984  loss_rpn_loc: 0.09455  time: 0.9294  data_time: 0.1376  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:43:11 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 5539  total_loss: 1.274  loss_cls: 0.3271  loss_box_reg: 0.5357  loss_mask: 0.2844  loss_rpn_cls: 0.02875  loss_rpn_loc: 0.09944  time: 0.9287  data_time: 0.0465  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:43:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:43:32 d2.utils.events]: \u001b[0m eta: 0:54:30  iter: 5559  total_loss: 1.238  loss_cls: 0.3204  loss_box_reg: 0.5326  loss_mask: 0.2848  loss_rpn_cls: 0.03469  loss_rpn_loc: 0.1073  time: 0.9291  data_time: 0.2284  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:43:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:43:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:43:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:43:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:43:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:43:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1432 s/iter. Eval: 0.0526 s/iter. Total: 0.1966 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:43:50 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1527 s/iter. Eval: 0.1289 s/iter. Total: 0.2827 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 14:43:55 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1550 s/iter. Eval: 0.1409 s/iter. Total: 0.2970 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1522 s/iter. Eval: 0.1306 s/iter. Total: 0.2838 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 14:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1553 s/iter. Eval: 0.1497 s/iter. Total: 0.3061 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1581 s/iter. Eval: 0.1592 s/iter. Total: 0.3183 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1567 s/iter. Eval: 0.1549 s/iter. Total: 0.3126 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:44:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.870011 (0.309224 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:44:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.156710 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:44:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:44:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3056279702987177\n",
      "\u001b[32m[02/13 14:44:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:44:33 d2.utils.events]: \u001b[0m eta: 0:54:22  iter: 5579  total_loss: 1.306  loss_cls: 0.3442  loss_box_reg: 0.5414  loss_mask: 0.2926  loss_rpn_cls: 0.04412  loss_rpn_loc: 0.1111  time: 0.9300  data_time: 0.3391  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:44:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:44:57 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 5599  total_loss: 1.223  loss_cls: 0.3262  loss_box_reg: 0.4996  loss_mask: 0.2726  loss_rpn_cls: 0.03669  loss_rpn_loc: 0.1054  time: 0.9308  data_time: 0.2855  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:45:15 d2.utils.events]: \u001b[0m eta: 0:53:52  iter: 5619  total_loss: 1.371  loss_cls: 0.3443  loss_box_reg: 0.5555  loss_mask: 0.2999  loss_rpn_cls: 0.04638  loss_rpn_loc: 0.1136  time: 0.9308  data_time: 0.1985  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:45:31 d2.utils.events]: \u001b[0m eta: 0:53:32  iter: 5639  total_loss: 1.13  loss_cls: 0.2718  loss_box_reg: 0.4855  loss_mask: 0.279  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.0843  time: 0.9303  data_time: 0.1025  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:45:51 d2.utils.events]: \u001b[0m eta: 0:53:15  iter: 5659  total_loss: 1.371  loss_cls: 0.3409  loss_box_reg: 0.5754  loss_mask: 0.3181  loss_rpn_cls: 0.04934  loss_rpn_loc: 0.113  time: 0.9305  data_time: 0.2949  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:46:08 d2.utils.events]: \u001b[0m eta: 0:53:01  iter: 5679  total_loss: 1.269  loss_cls: 0.334  loss_box_reg: 0.5057  loss_mask: 0.2706  loss_rpn_cls: 0.02902  loss_rpn_loc: 0.1117  time: 0.9303  data_time: 0.1578  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:46:26 d2.utils.events]: \u001b[0m eta: 0:52:47  iter: 5699  total_loss: 1.239  loss_cls: 0.3234  loss_box_reg: 0.5209  loss_mask: 0.2782  loss_rpn_cls: 0.03481  loss_rpn_loc: 0.1148  time: 0.9302  data_time: 0.1916  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:46:43 d2.utils.events]: \u001b[0m eta: 0:52:32  iter: 5719  total_loss: 1.254  loss_cls: 0.3309  loss_box_reg: 0.5292  loss_mask: 0.2915  loss_rpn_cls: 0.03858  loss_rpn_loc: 0.1006  time: 0.9299  data_time: 0.1470  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:47:00 d2.utils.events]: \u001b[0m eta: 0:52:17  iter: 5739  total_loss: 1.403  loss_cls: 0.3588  loss_box_reg: 0.59  loss_mask: 0.3076  loss_rpn_cls: 0.038  loss_rpn_loc: 0.1217  time: 0.9295  data_time: 0.1197  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:47:17 d2.utils.events]: \u001b[0m eta: 0:52:01  iter: 5759  total_loss: 1.274  loss_cls: 0.3206  loss_box_reg: 0.5301  loss_mask: 0.2755  loss_rpn_cls: 0.03294  loss_rpn_loc: 0.09491  time: 0.9292  data_time: 0.1456  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:47:37 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 5779  total_loss: 1.419  loss_cls: 0.385  loss_box_reg: 0.5791  loss_mask: 0.3109  loss_rpn_cls: 0.04051  loss_rpn_loc: 0.1307  time: 0.9295  data_time: 0.2603  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:47:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:47:58 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 5799  total_loss: 1.257  loss_cls: 0.325  loss_box_reg: 0.5075  loss_mask: 0.2834  loss_rpn_cls: 0.02675  loss_rpn_loc: 0.09685  time: 0.9300  data_time: 0.2154  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:48:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:48:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:48:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:48:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:48:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:48:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1434 s/iter. Eval: 0.0525 s/iter. Total: 0.1967 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1528 s/iter. Eval: 0.1288 s/iter. Total: 0.2827 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 14:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1547 s/iter. Eval: 0.1406 s/iter. Total: 0.2963 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1547 s/iter. Eval: 0.1329 s/iter. Total: 0.2886 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 14:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1563 s/iter. Eval: 0.1447 s/iter. Total: 0.3021 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1590 s/iter. Eval: 0.1557 s/iter. Total: 0.3158 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1583 s/iter. Eval: 0.1571 s/iter. Total: 0.3165 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 14:48:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.225164 (0.312286 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:48:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157907 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:48:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:48:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30532058318101113\n",
      "\u001b[32m[02/13 14:48:54 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 5819  total_loss: 1.29  loss_cls: 0.3465  loss_box_reg: 0.537  loss_mask: 0.292  loss_rpn_cls: 0.04316  loss_rpn_loc: 0.1021  time: 0.9298  data_time: 0.1846  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:49:12 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 5839  total_loss: 1.29  loss_cls: 0.3355  loss_box_reg: 0.5386  loss_mask: 0.2896  loss_rpn_cls: 0.04074  loss_rpn_loc: 0.0986  time: 0.9296  data_time: 0.2090  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:49:30 d2.utils.events]: \u001b[0m eta: 0:50:41  iter: 5859  total_loss: 1.37  loss_cls: 0.3549  loss_box_reg: 0.5368  loss_mask: 0.2913  loss_rpn_cls: 0.04258  loss_rpn_loc: 0.09906  time: 0.9296  data_time: 0.2215  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:49:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:49:53 d2.utils.events]: \u001b[0m eta: 0:50:24  iter: 5879  total_loss: 1.352  loss_cls: 0.3551  loss_box_reg: 0.5439  loss_mask: 0.3058  loss_rpn_cls: 0.04204  loss_rpn_loc: 0.1206  time: 0.9303  data_time: 0.3229  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:50:10 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 5899  total_loss: 1.368  loss_cls: 0.3612  loss_box_reg: 0.5573  loss_mask: 0.3024  loss_rpn_cls: 0.0434  loss_rpn_loc: 0.1195  time: 0.9300  data_time: 0.1446  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:50:28 d2.utils.events]: \u001b[0m eta: 0:49:55  iter: 5919  total_loss: 1.243  loss_cls: 0.3343  loss_box_reg: 0.5301  loss_mask: 0.2864  loss_rpn_cls: 0.02223  loss_rpn_loc: 0.1019  time: 0.9300  data_time: 0.1913  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:50:45 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 5939  total_loss: 1.294  loss_cls: 0.3413  loss_box_reg: 0.5515  loss_mask: 0.2846  loss_rpn_cls: 0.02243  loss_rpn_loc: 0.09722  time: 0.9296  data_time: 0.0993  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:51:02 d2.utils.events]: \u001b[0m eta: 0:49:25  iter: 5959  total_loss: 1.397  loss_cls: 0.3633  loss_box_reg: 0.5565  loss_mask: 0.2845  loss_rpn_cls: 0.05214  loss_rpn_loc: 0.125  time: 0.9294  data_time: 0.1839  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:51:19 d2.utils.events]: \u001b[0m eta: 0:49:08  iter: 5979  total_loss: 1.233  loss_cls: 0.3121  loss_box_reg: 0.524  loss_mask: 0.2856  loss_rpn_cls: 0.02614  loss_rpn_loc: 0.07598  time: 0.9292  data_time: 0.1607  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:51:36 d2.utils.events]: \u001b[0m eta: 0:48:59  iter: 5999  total_loss: 1.317  loss_cls: 0.3355  loss_box_reg: 0.5255  loss_mask: 0.2885  loss_rpn_cls: 0.03634  loss_rpn_loc: 0.1098  time: 0.9289  data_time: 0.1383  lr: 4.096e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:51:54 d2.utils.events]: \u001b[0m eta: 0:48:50  iter: 6019  total_loss: 1.31  loss_cls: 0.354  loss_box_reg: 0.5238  loss_mask: 0.29  loss_rpn_cls: 0.0453  loss_rpn_loc: 0.1122  time: 0.9288  data_time: 0.1993  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:52:13 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 6039  total_loss: 1.343  loss_cls: 0.3657  loss_box_reg: 0.5305  loss_mask: 0.2732  loss_rpn_cls: 0.05119  loss_rpn_loc: 0.1071  time: 0.9288  data_time: 0.2318  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:52:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:52:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:52:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:52:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:52:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:52:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1445 s/iter. Eval: 0.0534 s/iter. Total: 0.1987 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1522 s/iter. Eval: 0.1178 s/iter. Total: 0.2710 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:52:35 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1557 s/iter. Eval: 0.1416 s/iter. Total: 0.2983 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:52:40 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1533 s/iter. Eval: 0.1328 s/iter. Total: 0.2871 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 14:52:46 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1559 s/iter. Eval: 0.1504 s/iter. Total: 0.3073 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:52:51 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1588 s/iter. Eval: 0.1607 s/iter. Total: 0.3205 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:52:56 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1577 s/iter. Eval: 0.1576 s/iter. Total: 0.3163 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:52:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.094908 (0.311163 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:52:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157406 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:52:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:52:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30684768476030816\n",
      "\u001b[32m[02/13 14:53:08 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 6059  total_loss: 1.373  loss_cls: 0.3704  loss_box_reg: 0.539  loss_mask: 0.3012  loss_rpn_cls: 0.04677  loss_rpn_loc: 0.1172  time: 0.9286  data_time: 0.1525  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:53:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:53:31 d2.utils.events]: \u001b[0m eta: 0:48:01  iter: 6079  total_loss: 1.317  loss_cls: 0.3361  loss_box_reg: 0.529  loss_mask: 0.2949  loss_rpn_cls: 0.04028  loss_rpn_loc: 0.1052  time: 0.9292  data_time: 0.2792  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:53:47 d2.utils.events]: \u001b[0m eta: 0:47:43  iter: 6099  total_loss: 1.243  loss_cls: 0.3259  loss_box_reg: 0.5161  loss_mask: 0.2782  loss_rpn_cls: 0.03904  loss_rpn_loc: 0.0987  time: 0.9288  data_time: 0.0933  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:53:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:54:08 d2.utils.events]: \u001b[0m eta: 0:47:29  iter: 6119  total_loss: 1.338  loss_cls: 0.3475  loss_box_reg: 0.54  loss_mask: 0.2985  loss_rpn_cls: 0.0275  loss_rpn_loc: 0.1093  time: 0.9292  data_time: 0.2662  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:54:25 d2.utils.events]: \u001b[0m eta: 0:47:14  iter: 6139  total_loss: 1.33  loss_cls: 0.3261  loss_box_reg: 0.512  loss_mask: 0.2918  loss_rpn_cls: 0.03758  loss_rpn_loc: 0.09486  time: 0.9290  data_time: 0.1665  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:54:42 d2.utils.events]: \u001b[0m eta: 0:47:01  iter: 6159  total_loss: 1.31  loss_cls: 0.3369  loss_box_reg: 0.539  loss_mask: 0.2912  loss_rpn_cls: 0.05002  loss_rpn_loc: 0.1091  time: 0.9288  data_time: 0.1661  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:54:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:55:03 d2.utils.events]: \u001b[0m eta: 0:46:46  iter: 6179  total_loss: 1.307  loss_cls: 0.3148  loss_box_reg: 0.5452  loss_mask: 0.3081  loss_rpn_cls: 0.03952  loss_rpn_loc: 0.08907  time: 0.9291  data_time: 0.2172  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:55:19 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 6199  total_loss: 1.307  loss_cls: 0.3293  loss_box_reg: 0.5496  loss_mask: 0.2844  loss_rpn_cls: 0.0321  loss_rpn_loc: 0.1  time: 0.9286  data_time: 0.1034  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:55:39 d2.utils.events]: \u001b[0m eta: 0:46:14  iter: 6219  total_loss: 1.393  loss_cls: 0.362  loss_box_reg: 0.5588  loss_mask: 0.2959  loss_rpn_cls: 0.05307  loss_rpn_loc: 0.123  time: 0.9288  data_time: 0.2468  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:55:53 d2.utils.events]: \u001b[0m eta: 0:45:55  iter: 6239  total_loss: 1.185  loss_cls: 0.2723  loss_box_reg: 0.5214  loss_mask: 0.2843  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.08554  time: 0.9282  data_time: 0.0403  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:56:10 d2.utils.events]: \u001b[0m eta: 0:45:45  iter: 6259  total_loss: 1.355  loss_cls: 0.3529  loss_box_reg: 0.5505  loss_mask: 0.2883  loss_rpn_cls: 0.04563  loss_rpn_loc: 0.113  time: 0.9279  data_time: 0.1163  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:56:27 d2.utils.events]: \u001b[0m eta: 0:45:25  iter: 6279  total_loss: 1.251  loss_cls: 0.3168  loss_box_reg: 0.5202  loss_mask: 0.2732  loss_rpn_cls: 0.02836  loss_rpn_loc: 0.09192  time: 0.9277  data_time: 0.1673  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:56:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:56:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:56:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:56:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 14:56:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 14:56:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 14:56:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 14:56:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 14:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1425 s/iter. Eval: 0.0528 s/iter. Total: 0.1961 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 14:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1527 s/iter. Eval: 0.1248 s/iter. Total: 0.2785 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 14:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1546 s/iter. Eval: 0.1367 s/iter. Total: 0.2923 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 14:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1518 s/iter. Eval: 0.1273 s/iter. Total: 0.2802 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 14:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1563 s/iter. Eval: 0.1460 s/iter. Total: 0.3033 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 14:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1591 s/iter. Eval: 0.1558 s/iter. Total: 0.3159 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 14:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1576 s/iter. Eval: 0.1520 s/iter. Total: 0.3106 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 14:57:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.628524 (0.307142 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:57:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157517 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 14:57:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 14:57:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30605737069666916\n",
      "\u001b[32m[02/13 14:57:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:57:36 d2.utils.events]: \u001b[0m eta: 0:45:16  iter: 6299  total_loss: 1.345  loss_cls: 0.3453  loss_box_reg: 0.541  loss_mask: 0.3033  loss_rpn_cls: 0.04225  loss_rpn_loc: 0.1057  time: 0.9297  data_time: 0.4661  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:57:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:57:55 d2.utils.events]: \u001b[0m eta: 0:45:01  iter: 6319  total_loss: 1.363  loss_cls: 0.3462  loss_box_reg: 0.5606  loss_mask: 0.291  loss_rpn_cls: 0.04293  loss_rpn_loc: 0.1206  time: 0.9297  data_time: 0.1637  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:58:13 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 6339  total_loss: 1.25  loss_cls: 0.3193  loss_box_reg: 0.5241  loss_mask: 0.2855  loss_rpn_cls: 0.0288  loss_rpn_loc: 0.09433  time: 0.9296  data_time: 0.1539  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:58:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:58:33 d2.utils.events]: \u001b[0m eta: 0:44:32  iter: 6359  total_loss: 1.3  loss_cls: 0.3077  loss_box_reg: 0.5485  loss_mask: 0.3092  loss_rpn_cls: 0.02988  loss_rpn_loc: 0.09577  time: 0.9298  data_time: 0.1846  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:58:49 d2.utils.events]: \u001b[0m eta: 0:44:17  iter: 6379  total_loss: 1.249  loss_cls: 0.321  loss_box_reg: 0.5098  loss_mask: 0.2845  loss_rpn_cls: 0.0357  loss_rpn_loc: 0.09052  time: 0.9295  data_time: 0.1434  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:59:09 d2.utils.events]: \u001b[0m eta: 0:44:04  iter: 6399  total_loss: 1.287  loss_cls: 0.3297  loss_box_reg: 0.5266  loss_mask: 0.2796  loss_rpn_cls: 0.04528  loss_rpn_loc: 0.1191  time: 0.9296  data_time: 0.2125  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:59:26 d2.utils.events]: \u001b[0m eta: 0:43:49  iter: 6419  total_loss: 1.386  loss_cls: 0.3661  loss_box_reg: 0.5701  loss_mask: 0.3009  loss_rpn_cls: 0.0459  loss_rpn_loc: 0.1094  time: 0.9295  data_time: 0.1745  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 14:59:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 14:59:46 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 6439  total_loss: 1.374  loss_cls: 0.3595  loss_box_reg: 0.5303  loss_mask: 0.2994  loss_rpn_cls: 0.04131  loss_rpn_loc: 0.1089  time: 0.9297  data_time: 0.2129  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:00:03 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 6459  total_loss: 1.307  loss_cls: 0.3387  loss_box_reg: 0.5292  loss_mask: 0.2703  loss_rpn_cls: 0.03515  loss_rpn_loc: 0.1045  time: 0.9293  data_time: 0.0993  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:00:21 d2.utils.events]: \u001b[0m eta: 0:43:10  iter: 6479  total_loss: 1.329  loss_cls: 0.346  loss_box_reg: 0.5495  loss_mask: 0.292  loss_rpn_cls: 0.04539  loss_rpn_loc: 0.1182  time: 0.9292  data_time: 0.1611  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:00:40 d2.utils.events]: \u001b[0m eta: 0:42:50  iter: 6499  total_loss: 1.311  loss_cls: 0.3444  loss_box_reg: 0.5315  loss_mask: 0.2842  loss_rpn_cls: 0.05133  loss_rpn_loc: 0.09903  time: 0.9294  data_time: 0.2755  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:00:56 d2.utils.events]: \u001b[0m eta: 0:42:34  iter: 6519  total_loss: 1.227  loss_cls: 0.318  loss_box_reg: 0.5009  loss_mask: 0.2774  loss_rpn_cls: 0.03438  loss_rpn_loc: 0.09298  time: 0.9290  data_time: 0.1063  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:01:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:01:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:01:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:01:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:01:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:01:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1442 s/iter. Eval: 0.0525 s/iter. Total: 0.1975 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 15:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1532 s/iter. Eval: 0.1277 s/iter. Total: 0.2819 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1553 s/iter. Eval: 0.1385 s/iter. Total: 0.2948 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1553 s/iter. Eval: 0.1304 s/iter. Total: 0.2867 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:01:33 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1575 s/iter. Eval: 0.1475 s/iter. Total: 0.3060 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 15:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1601 s/iter. Eval: 0.1577 s/iter. Total: 0.3189 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:01:43 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1589 s/iter. Eval: 0.1551 s/iter. Total: 0.3150 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 15:01:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.958408 (0.309986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:01:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158483 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:01:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:01:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30528986682501535\n",
      "\u001b[32m[02/13 15:01:50 d2.utils.events]: \u001b[0m eta: 0:42:20  iter: 6539  total_loss: 1.291  loss_cls: 0.3189  loss_box_reg: 0.5532  loss_mask: 0.2789  loss_rpn_cls: 0.02569  loss_rpn_loc: 0.08439  time: 0.9286  data_time: 0.0768  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:01:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:02:13 d2.utils.events]: \u001b[0m eta: 0:42:10  iter: 6559  total_loss: 1.306  loss_cls: 0.3493  loss_box_reg: 0.5428  loss_mask: 0.2822  loss_rpn_cls: 0.04679  loss_rpn_loc: 0.1087  time: 0.9292  data_time: 0.2646  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:02:29 d2.utils.events]: \u001b[0m eta: 0:41:51  iter: 6579  total_loss: 1.351  loss_cls: 0.3431  loss_box_reg: 0.5454  loss_mask: 0.2931  loss_rpn_cls: 0.0426  loss_rpn_loc: 0.1075  time: 0.9288  data_time: 0.1066  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:02:46 d2.utils.events]: \u001b[0m eta: 0:41:33  iter: 6599  total_loss: 1.2  loss_cls: 0.3116  loss_box_reg: 0.5013  loss_mask: 0.279  loss_rpn_cls: 0.03456  loss_rpn_loc: 0.09719  time: 0.9286  data_time: 0.1719  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:03:04 d2.utils.events]: \u001b[0m eta: 0:41:16  iter: 6619  total_loss: 1.318  loss_cls: 0.3337  loss_box_reg: 0.5271  loss_mask: 0.3046  loss_rpn_cls: 0.04067  loss_rpn_loc: 0.1  time: 0.9286  data_time: 0.1817  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:03:23 d2.utils.events]: \u001b[0m eta: 0:41:06  iter: 6639  total_loss: 1.303  loss_cls: 0.3377  loss_box_reg: 0.5178  loss_mask: 0.2854  loss_rpn_cls: 0.0451  loss_rpn_loc: 0.1053  time: 0.9285  data_time: 0.1957  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:03:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:03:47 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 6659  total_loss: 1.354  loss_cls: 0.3553  loss_box_reg: 0.5267  loss_mask: 0.2931  loss_rpn_cls: 0.0495  loss_rpn_loc: 0.1207  time: 0.9293  data_time: 0.3147  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:04:03 d2.utils.events]: \u001b[0m eta: 0:40:41  iter: 6679  total_loss: 1.224  loss_cls: 0.2886  loss_box_reg: 0.5404  loss_mask: 0.2812  loss_rpn_cls: 0.03504  loss_rpn_loc: 0.08296  time: 0.9289  data_time: 0.1014  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:04:22 d2.utils.events]: \u001b[0m eta: 0:40:28  iter: 6699  total_loss: 1.187  loss_cls: 0.3006  loss_box_reg: 0.4953  loss_mask: 0.2716  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.08967  time: 0.9291  data_time: 0.2647  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:04:40 d2.utils.events]: \u001b[0m eta: 0:40:15  iter: 6719  total_loss: 1.392  loss_cls: 0.3735  loss_box_reg: 0.5781  loss_mask: 0.3058  loss_rpn_cls: 0.04727  loss_rpn_loc: 0.1216  time: 0.9289  data_time: 0.1482  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:04:57 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 6739  total_loss: 1.354  loss_cls: 0.3717  loss_box_reg: 0.5565  loss_mask: 0.3089  loss_rpn_cls: 0.0513  loss_rpn_loc: 0.1138  time: 0.9288  data_time: 0.1850  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:05:16 d2.utils.events]: \u001b[0m eta: 0:39:50  iter: 6759  total_loss: 1.258  loss_cls: 0.3305  loss_box_reg: 0.5327  loss_mask: 0.289  loss_rpn_cls: 0.04272  loss_rpn_loc: 0.1047  time: 0.9287  data_time: 0.1829  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:05:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:05:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:05:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:05:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:05:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:05:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:05:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:05:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1504 s/iter. Eval: 0.0560 s/iter. Total: 0.2072 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1578 s/iter. Eval: 0.1253 s/iter. Total: 0.2841 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 15:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1599 s/iter. Eval: 0.1366 s/iter. Total: 0.2975 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.1574 s/iter. Eval: 0.1284 s/iter. Total: 0.2868 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1612 s/iter. Eval: 0.1398 s/iter. Total: 0.3020 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 15:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1642 s/iter. Eval: 0.1505 s/iter. Total: 0.3157 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1635 s/iter. Eval: 0.1520 s/iter. Total: 0.3166 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.243393 (0.312443 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.163190 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:06:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:06:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30554693608910816\n",
      "\u001b[32m[02/13 15:06:17 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 6779  total_loss: 1.114  loss_cls: 0.2829  loss_box_reg: 0.4992  loss_mask: 0.2756  loss_rpn_cls: 0.02087  loss_rpn_loc: 0.07  time: 0.9294  data_time: 0.2277  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:06:35 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 6799  total_loss: 1.394  loss_cls: 0.3665  loss_box_reg: 0.5653  loss_mask: 0.2979  loss_rpn_cls: 0.04604  loss_rpn_loc: 0.1041  time: 0.9292  data_time: 0.1594  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:06:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:06:56 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 6819  total_loss: 1.334  loss_cls: 0.3646  loss_box_reg: 0.5139  loss_mask: 0.2976  loss_rpn_cls: 0.04474  loss_rpn_loc: 0.1158  time: 0.9296  data_time: 0.2271  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:07:12 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 6839  total_loss: 1.217  loss_cls: 0.3102  loss_box_reg: 0.5067  loss_mask: 0.2792  loss_rpn_cls: 0.03633  loss_rpn_loc: 0.08097  time: 0.9293  data_time: 0.1217  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:07:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:07:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:07:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:07:39 d2.utils.events]: \u001b[0m eta: 0:38:38  iter: 6859  total_loss: 1.342  loss_cls: 0.3601  loss_box_reg: 0.548  loss_mask: 0.2923  loss_rpn_cls: 0.0245  loss_rpn_loc: 0.106  time: 0.9304  data_time: 0.2961  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:07:55 d2.utils.events]: \u001b[0m eta: 0:38:24  iter: 6879  total_loss: 1.333  loss_cls: 0.3473  loss_box_reg: 0.5519  loss_mask: 0.2983  loss_rpn_cls: 0.0422  loss_rpn_loc: 0.1043  time: 0.9301  data_time: 0.1187  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:08:13 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 6899  total_loss: 1.292  loss_cls: 0.3247  loss_box_reg: 0.5286  loss_mask: 0.2791  loss_rpn_cls: 0.02995  loss_rpn_loc: 0.1034  time: 0.9300  data_time: 0.1826  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:08:32 d2.utils.events]: \u001b[0m eta: 0:37:53  iter: 6919  total_loss: 1.333  loss_cls: 0.3472  loss_box_reg: 0.5534  loss_mask: 0.3057  loss_rpn_cls: 0.04341  loss_rpn_loc: 0.1047  time: 0.9301  data_time: 0.2738  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:08:52 d2.utils.events]: \u001b[0m eta: 0:37:40  iter: 6939  total_loss: 1.264  loss_cls: 0.3141  loss_box_reg: 0.5088  loss_mask: 0.2726  loss_rpn_cls: 0.03555  loss_rpn_loc: 0.1026  time: 0.9302  data_time: 0.2291  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:09:06 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 6959  total_loss: 1.31  loss_cls: 0.3424  loss_box_reg: 0.5247  loss_mask: 0.2859  loss_rpn_cls: 0.03485  loss_rpn_loc: 0.08813  time: 0.9296  data_time: 0.0431  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:09:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:09:25 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 6979  total_loss: 1.244  loss_cls: 0.3232  loss_box_reg: 0.5205  loss_mask: 0.284  loss_rpn_cls: 0.02145  loss_rpn_loc: 0.09568  time: 0.9297  data_time: 0.1769  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:09:42 d2.utils.events]: \u001b[0m eta: 0:36:56  iter: 6999  total_loss: 1.328  loss_cls: 0.3289  loss_box_reg: 0.5475  loss_mask: 0.2991  loss_rpn_cls: 0.03644  loss_rpn_loc: 0.1233  time: 0.9294  data_time: 0.1118  lr: 3.2768e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:09:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:09:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:09:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:09:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:09:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:09:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:10:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1454 s/iter. Eval: 0.0537 s/iter. Total: 0.1999 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 15:10:07 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1537 s/iter. Eval: 0.1247 s/iter. Total: 0.2793 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:10:12 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.1547 s/iter. Eval: 0.1342 s/iter. Total: 0.2899 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 15:10:17 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1536 s/iter. Eval: 0.1274 s/iter. Total: 0.2821 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 15:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1570 s/iter. Eval: 0.1435 s/iter. Total: 0.3016 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 15:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1552 s/iter. Total: 0.3164 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1596 s/iter. Eval: 0.1566 s/iter. Total: 0.3172 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:10:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.315173 (0.313062 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:10:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159378 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:10:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:10:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.306219797859363\n",
      "\u001b[32m[02/13 15:10:38 d2.utils.events]: \u001b[0m eta: 0:36:39  iter: 7019  total_loss: 1.358  loss_cls: 0.3514  loss_box_reg: 0.5546  loss_mask: 0.2991  loss_rpn_cls: 0.03598  loss_rpn_loc: 0.1156  time: 0.9292  data_time: 0.1396  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:10:56 d2.utils.events]: \u001b[0m eta: 0:36:27  iter: 7039  total_loss: 1.328  loss_cls: 0.3644  loss_box_reg: 0.5447  loss_mask: 0.2852  loss_rpn_cls: 0.04075  loss_rpn_loc: 0.1156  time: 0.9292  data_time: 0.1664  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:11:11 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 7059  total_loss: 1.142  loss_cls: 0.272  loss_box_reg: 0.4843  loss_mask: 0.2694  loss_rpn_cls: 0.02391  loss_rpn_loc: 0.08547  time: 0.9287  data_time: 0.0883  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:11:29 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 7079  total_loss: 1.202  loss_cls: 0.317  loss_box_reg: 0.4962  loss_mask: 0.2724  loss_rpn_cls: 0.02806  loss_rpn_loc: 0.06217  time: 0.9286  data_time: 0.1731  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:11:49 d2.utils.events]: \u001b[0m eta: 0:35:40  iter: 7099  total_loss: 1.327  loss_cls: 0.3429  loss_box_reg: 0.5385  loss_mask: 0.2961  loss_rpn_cls: 0.03554  loss_rpn_loc: 0.112  time: 0.9288  data_time: 0.2554  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:12:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:12:09 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 7119  total_loss: 1.319  loss_cls: 0.3501  loss_box_reg: 0.5397  loss_mask: 0.2921  loss_rpn_cls: 0.04182  loss_rpn_loc: 0.1097  time: 0.9290  data_time: 0.1983  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:12:25 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 7139  total_loss: 1.332  loss_cls: 0.3208  loss_box_reg: 0.5512  loss_mask: 0.2966  loss_rpn_cls: 0.03325  loss_rpn_loc: 0.1067  time: 0.9287  data_time: 0.0798  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:12:43 d2.utils.events]: \u001b[0m eta: 0:34:59  iter: 7159  total_loss: 1.394  loss_cls: 0.353  loss_box_reg: 0.5465  loss_mask: 0.2957  loss_rpn_cls: 0.04277  loss_rpn_loc: 0.114  time: 0.9285  data_time: 0.1390  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:12:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:13:07 d2.utils.events]: \u001b[0m eta: 0:34:46  iter: 7179  total_loss: 1.354  loss_cls: 0.3547  loss_box_reg: 0.546  loss_mask: 0.2935  loss_rpn_cls: 0.04458  loss_rpn_loc: 0.1125  time: 0.9293  data_time: 0.2884  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:13:26 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 7199  total_loss: 1.371  loss_cls: 0.362  loss_box_reg: 0.564  loss_mask: 0.3075  loss_rpn_cls: 0.04462  loss_rpn_loc: 0.1096  time: 0.9293  data_time: 0.1659  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:13:46 d2.utils.events]: \u001b[0m eta: 0:34:22  iter: 7219  total_loss: 1.334  loss_cls: 0.3369  loss_box_reg: 0.5439  loss_mask: 0.3005  loss_rpn_cls: 0.04185  loss_rpn_loc: 0.1149  time: 0.9295  data_time: 0.2268  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:14:03 d2.utils.events]: \u001b[0m eta: 0:34:09  iter: 7239  total_loss: 1.264  loss_cls: 0.3087  loss_box_reg: 0.5317  loss_mask: 0.2776  loss_rpn_cls: 0.03529  loss_rpn_loc: 0.08796  time: 0.9293  data_time: 0.1404  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:14:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:14:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:14:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:14:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:14:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:14:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:14:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:14:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1449 s/iter. Eval: 0.0515 s/iter. Total: 0.1972 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/13 15:14:30 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1560 s/iter. Eval: 0.1136 s/iter. Total: 0.2705 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:14:35 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0011 s/iter. Inference: 0.1571 s/iter. Eval: 0.1305 s/iter. Total: 0.2888 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:14:40 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0011 s/iter. Inference: 0.1564 s/iter. Eval: 0.1300 s/iter. Total: 0.2875 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0011 s/iter. Inference: 0.1581 s/iter. Eval: 0.1438 s/iter. Total: 0.3031 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 15:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0011 s/iter. Inference: 0.1610 s/iter. Eval: 0.1549 s/iter. Total: 0.3170 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1610 s/iter. Eval: 0.1579 s/iter. Total: 0.3201 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:15:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.554525 (0.315125 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:15:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.161189 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:15:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:15:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3054096799303366\n",
      "\u001b[32m[02/13 15:15:00 d2.utils.events]: \u001b[0m eta: 0:33:54  iter: 7259  total_loss: 1.27  loss_cls: 0.3165  loss_box_reg: 0.5127  loss_mask: 0.2825  loss_rpn_cls: 0.04203  loss_rpn_loc: 0.1031  time: 0.9293  data_time: 0.1093  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:15:19 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 7279  total_loss: 1.317  loss_cls: 0.3433  loss_box_reg: 0.5164  loss_mask: 0.2921  loss_rpn_cls: 0.03991  loss_rpn_loc: 0.103  time: 0.9293  data_time: 0.1797  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:15:36 d2.utils.events]: \u001b[0m eta: 0:33:26  iter: 7299  total_loss: 1.298  loss_cls: 0.3236  loss_box_reg: 0.5515  loss_mask: 0.2987  loss_rpn_cls: 0.03867  loss_rpn_loc: 0.108  time: 0.9291  data_time: 0.1541  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:15:56 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 7319  total_loss: 1.375  loss_cls: 0.3473  loss_box_reg: 0.5742  loss_mask: 0.3001  loss_rpn_cls: 0.02864  loss_rpn_loc: 0.1084  time: 0.9292  data_time: 0.2409  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:16:14 d2.utils.events]: \u001b[0m eta: 0:32:56  iter: 7339  total_loss: 1.299  loss_cls: 0.3326  loss_box_reg: 0.5248  loss_mask: 0.2981  loss_rpn_cls: 0.04047  loss_rpn_loc: 0.09982  time: 0.9292  data_time: 0.1836  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:16:28 d2.utils.events]: \u001b[0m eta: 0:32:40  iter: 7359  total_loss: 1.196  loss_cls: 0.3008  loss_box_reg: 0.499  loss_mask: 0.2673  loss_rpn_cls: 0.02732  loss_rpn_loc: 0.09502  time: 0.9286  data_time: 0.0430  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:16:44 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 7379  total_loss: 1.218  loss_cls: 0.3182  loss_box_reg: 0.4936  loss_mask: 0.2809  loss_rpn_cls: 0.02815  loss_rpn_loc: 0.07676  time: 0.9283  data_time: 0.0862  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:17:02 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 7399  total_loss: 1.341  loss_cls: 0.3488  loss_box_reg: 0.5419  loss_mask: 0.2859  loss_rpn_cls: 0.03858  loss_rpn_loc: 0.1126  time: 0.9282  data_time: 0.1809  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:17:20 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 7419  total_loss: 1.32  loss_cls: 0.3409  loss_box_reg: 0.5432  loss_mask: 0.2806  loss_rpn_cls: 0.04042  loss_rpn_loc: 0.1106  time: 0.9281  data_time: 0.1773  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:17:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:17:41 d2.utils.events]: \u001b[0m eta: 0:31:42  iter: 7439  total_loss: 1.234  loss_cls: 0.3118  loss_box_reg: 0.5156  loss_mask: 0.2756  loss_rpn_cls: 0.02455  loss_rpn_loc: 0.09052  time: 0.9284  data_time: 0.2390  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:17:58 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 7459  total_loss: 1.275  loss_cls: 0.3276  loss_box_reg: 0.5101  loss_mask: 0.2784  loss_rpn_cls: 0.04389  loss_rpn_loc: 0.1132  time: 0.9282  data_time: 0.1363  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:18:15 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 7479  total_loss: 1.394  loss_cls: 0.3634  loss_box_reg: 0.5685  loss_mask: 0.3018  loss_rpn_cls: 0.05302  loss_rpn_loc: 0.1199  time: 0.9280  data_time: 0.1262  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:18:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:18:36 d2.utils.events]: \u001b[0m eta: 0:30:59  iter: 7499  total_loss: 1.381  loss_cls: 0.3567  loss_box_reg: 0.5456  loss_mask: 0.2983  loss_rpn_cls: 0.04858  loss_rpn_loc: 0.1126  time: 0.9284  data_time: 0.2473  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:18:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:18:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:18:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:18:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:18:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:18:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:18:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1465 s/iter. Eval: 0.0543 s/iter. Total: 0.2016 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1540 s/iter. Eval: 0.1251 s/iter. Total: 0.2800 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:18:52 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1556 s/iter. Eval: 0.1372 s/iter. Total: 0.2938 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0009 s/iter. Inference: 0.1530 s/iter. Eval: 0.1273 s/iter. Total: 0.2812 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 15:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.1561 s/iter. Eval: 0.1460 s/iter. Total: 0.3031 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 15:19:08 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1608 s/iter. Eval: 0.1560 s/iter. Total: 0.3178 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1590 s/iter. Eval: 0.1520 s/iter. Total: 0.3120 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 15:19:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.800296 (0.308623 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:19:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158926 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:19:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:19:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30698098631164417\n",
      "\u001b[32m[02/13 15:19:31 d2.utils.events]: \u001b[0m eta: 0:30:43  iter: 7519  total_loss: 1.279  loss_cls: 0.3293  loss_box_reg: 0.5319  loss_mask: 0.2805  loss_rpn_cls: 0.03025  loss_rpn_loc: 0.1021  time: 0.9282  data_time: 0.1563  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:19:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:19:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:19:55 d2.utils.events]: \u001b[0m eta: 0:30:30  iter: 7539  total_loss: 1.382  loss_cls: 0.3586  loss_box_reg: 0.5622  loss_mask: 0.294  loss_rpn_cls: 0.03958  loss_rpn_loc: 0.1166  time: 0.9288  data_time: 0.2638  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:20:12 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 7559  total_loss: 1.318  loss_cls: 0.3433  loss_box_reg: 0.5158  loss_mask: 0.2807  loss_rpn_cls: 0.04638  loss_rpn_loc: 0.1111  time: 0.9286  data_time: 0.1485  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:20:29 d2.utils.events]: \u001b[0m eta: 0:29:58  iter: 7579  total_loss: 1.322  loss_cls: 0.3526  loss_box_reg: 0.5066  loss_mask: 0.2794  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.1124  time: 0.9284  data_time: 0.1458  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:20:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:20:50 d2.utils.events]: \u001b[0m eta: 0:29:45  iter: 7599  total_loss: 1.251  loss_cls: 0.3179  loss_box_reg: 0.5053  loss_mask: 0.2867  loss_rpn_cls: 0.03701  loss_rpn_loc: 0.1048  time: 0.9287  data_time: 0.2240  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:21:05 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 7619  total_loss: 1.28  loss_cls: 0.3277  loss_box_reg: 0.5375  loss_mask: 0.2912  loss_rpn_cls: 0.02972  loss_rpn_loc: 0.1044  time: 0.9283  data_time: 0.0722  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:21:23 d2.utils.events]: \u001b[0m eta: 0:29:13  iter: 7639  total_loss: 1.435  loss_cls: 0.3718  loss_box_reg: 0.5718  loss_mask: 0.3043  loss_rpn_cls: 0.04706  loss_rpn_loc: 0.1196  time: 0.9282  data_time: 0.1660  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:21:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:21:45 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 7659  total_loss: 1.376  loss_cls: 0.3499  loss_box_reg: 0.5634  loss_mask: 0.3045  loss_rpn_cls: 0.04376  loss_rpn_loc: 0.1064  time: 0.9286  data_time: 0.2928  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:22:03 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 7679  total_loss: 1.325  loss_cls: 0.3318  loss_box_reg: 0.534  loss_mask: 0.2875  loss_rpn_cls: 0.03889  loss_rpn_loc: 0.09774  time: 0.9286  data_time: 0.2061  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:22:20 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 7699  total_loss: 1.277  loss_cls: 0.3112  loss_box_reg: 0.5172  loss_mask: 0.2795  loss_rpn_cls: 0.02663  loss_rpn_loc: 0.1046  time: 0.9284  data_time: 0.1412  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:22:40 d2.utils.events]: \u001b[0m eta: 0:28:11  iter: 7719  total_loss: 1.373  loss_cls: 0.3658  loss_box_reg: 0.5337  loss_mask: 0.2865  loss_rpn_cls: 0.04193  loss_rpn_loc: 0.1036  time: 0.9286  data_time: 0.2875  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:22:58 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 7739  total_loss: 1.356  loss_cls: 0.3667  loss_box_reg: 0.551  loss_mask: 0.304  loss_rpn_cls: 0.0427  loss_rpn_loc: 0.1126  time: 0.9285  data_time: 0.1566  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:23:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:23:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:23:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:23:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:23:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:23:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1471 s/iter. Eval: 0.0535 s/iter. Total: 0.2013 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1544 s/iter. Eval: 0.1146 s/iter. Total: 0.2699 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1563 s/iter. Eval: 0.1306 s/iter. Total: 0.2879 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1554 s/iter. Eval: 0.1331 s/iter. Total: 0.2895 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1566 s/iter. Eval: 0.1422 s/iter. Total: 0.2998 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 15:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1601 s/iter. Eval: 0.1535 s/iter. Total: 0.3147 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:23:36 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1594 s/iter. Eval: 0.1549 s/iter. Total: 0.3153 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:23:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.114549 (0.311332 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:23:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159200 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:23:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:23:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30613110726427806\n",
      "\u001b[32m[02/13 15:23:52 d2.utils.events]: \u001b[0m eta: 0:27:40  iter: 7759  total_loss: 1.311  loss_cls: 0.3271  loss_box_reg: 0.5569  loss_mask: 0.2895  loss_rpn_cls: 0.03149  loss_rpn_loc: 0.09961  time: 0.9281  data_time: 0.0531  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:24:08 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 7779  total_loss: 1.31  loss_cls: 0.332  loss_box_reg: 0.5309  loss_mask: 0.2743  loss_rpn_cls: 0.04666  loss_rpn_loc: 0.1079  time: 0.9278  data_time: 0.1316  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:24:24 d2.utils.events]: \u001b[0m eta: 0:27:09  iter: 7799  total_loss: 1.201  loss_cls: 0.2843  loss_box_reg: 0.5205  loss_mask: 0.2819  loss_rpn_cls: 0.0285  loss_rpn_loc: 0.0623  time: 0.9274  data_time: 0.1030  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:24:39 d2.utils.events]: \u001b[0m eta: 0:26:52  iter: 7819  total_loss: 1.32  loss_cls: 0.3036  loss_box_reg: 0.5309  loss_mask: 0.2756  loss_rpn_cls: 0.02981  loss_rpn_loc: 0.08256  time: 0.9269  data_time: 0.0678  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:24:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:25:00 d2.utils.events]: \u001b[0m eta: 0:26:38  iter: 7839  total_loss: 1.377  loss_cls: 0.3538  loss_box_reg: 0.5574  loss_mask: 0.2937  loss_rpn_cls: 0.04677  loss_rpn_loc: 0.1114  time: 0.9273  data_time: 0.2648  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:25:21 d2.utils.events]: \u001b[0m eta: 0:26:24  iter: 7859  total_loss: 1.313  loss_cls: 0.3554  loss_box_reg: 0.5389  loss_mask: 0.279  loss_rpn_cls: 0.04336  loss_rpn_loc: 0.1147  time: 0.9276  data_time: 0.2976  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:25:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:25:45 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 7879  total_loss: 1.423  loss_cls: 0.3756  loss_box_reg: 0.5746  loss_mask: 0.3055  loss_rpn_cls: 0.05356  loss_rpn_loc: 0.1199  time: 0.9283  data_time: 0.3772  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:26:02 d2.utils.events]: \u001b[0m eta: 0:25:57  iter: 7899  total_loss: 1.211  loss_cls: 0.3075  loss_box_reg: 0.5061  loss_mask: 0.2847  loss_rpn_cls: 0.03066  loss_rpn_loc: 0.1043  time: 0.9281  data_time: 0.1233  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:26:20 d2.utils.events]: \u001b[0m eta: 0:25:42  iter: 7919  total_loss: 1.241  loss_cls: 0.3248  loss_box_reg: 0.5194  loss_mask: 0.2949  loss_rpn_cls: 0.02686  loss_rpn_loc: 0.1165  time: 0.9280  data_time: 0.1868  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:26:38 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 7939  total_loss: 1.239  loss_cls: 0.3325  loss_box_reg: 0.4891  loss_mask: 0.2748  loss_rpn_cls: 0.04681  loss_rpn_loc: 0.1049  time: 0.9279  data_time: 0.1531  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:26:56 d2.utils.events]: \u001b[0m eta: 0:25:14  iter: 7959  total_loss: 1.416  loss_cls: 0.3676  loss_box_reg: 0.5576  loss_mask: 0.2964  loss_rpn_cls: 0.05306  loss_rpn_loc: 0.1138  time: 0.9279  data_time: 0.2059  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:27:11 d2.utils.events]: \u001b[0m eta: 0:25:00  iter: 7979  total_loss: 1.242  loss_cls: 0.313  loss_box_reg: 0.5261  loss_mask: 0.279  loss_rpn_cls: 0.02925  loss_rpn_loc: 0.09316  time: 0.9275  data_time: 0.0630  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:27:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:27:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:27:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:27:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:27:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:27:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1546 s/iter. Eval: 0.0582 s/iter. Total: 0.2136 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 15:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0009 s/iter. Inference: 0.1602 s/iter. Eval: 0.1248 s/iter. Total: 0.2860 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 15:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1590 s/iter. Eval: 0.1333 s/iter. Total: 0.2933 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1569 s/iter. Eval: 0.1346 s/iter. Total: 0.2925 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1610 s/iter. Eval: 0.1447 s/iter. Total: 0.3067 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 15:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1637 s/iter. Eval: 0.1556 s/iter. Total: 0.3203 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1629 s/iter. Eval: 0.1569 s/iter. Total: 0.3208 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:27:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.729612 (0.316635 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:27:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.162185 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:27:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:27:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30425828359984064\n",
      "\u001b[32m[02/13 15:28:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:28:13 d2.utils.events]: \u001b[0m eta: 0:24:45  iter: 7999  total_loss: 1.37  loss_cls: 0.3688  loss_box_reg: 0.5271  loss_mask: 0.3068  loss_rpn_cls: 0.05433  loss_rpn_loc: 0.108  time: 0.9280  data_time: 0.2945  lr: 2.6214e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:28:29 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 8019  total_loss: 1.05  loss_cls: 0.2538  loss_box_reg: 0.4582  loss_mask: 0.2566  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.05369  time: 0.9276  data_time: 0.1162  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:28:45 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 8039  total_loss: 1.376  loss_cls: 0.3448  loss_box_reg: 0.5434  loss_mask: 0.2953  loss_rpn_cls: 0.04  loss_rpn_loc: 0.1159  time: 0.9274  data_time: 0.0991  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:29:00 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 8059  total_loss: 1.286  loss_cls: 0.313  loss_box_reg: 0.5444  loss_mask: 0.2921  loss_rpn_cls: 0.03337  loss_rpn_loc: 0.09092  time: 0.9269  data_time: 0.0369  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:29:15 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 8079  total_loss: 1.337  loss_cls: 0.3583  loss_box_reg: 0.5466  loss_mask: 0.2907  loss_rpn_cls: 0.04038  loss_rpn_loc: 0.1199  time: 0.9265  data_time: 0.0728  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:29:37 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 8099  total_loss: 1.385  loss_cls: 0.3598  loss_box_reg: 0.5283  loss_mask: 0.2916  loss_rpn_cls: 0.04328  loss_rpn_loc: 0.1175  time: 0.9269  data_time: 0.3496  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:29:55 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 8119  total_loss: 1.407  loss_cls: 0.3478  loss_box_reg: 0.5755  loss_mask: 0.3058  loss_rpn_cls: 0.04572  loss_rpn_loc: 0.1218  time: 0.9268  data_time: 0.1919  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:30:12 d2.utils.events]: \u001b[0m eta: 0:22:58  iter: 8139  total_loss: 1.237  loss_cls: 0.3096  loss_box_reg: 0.5322  loss_mask: 0.2944  loss_rpn_cls: 0.02616  loss_rpn_loc: 0.09247  time: 0.9267  data_time: 0.1238  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:30:32 d2.utils.events]: \u001b[0m eta: 0:22:44  iter: 8159  total_loss: 1.385  loss_cls: 0.3645  loss_box_reg: 0.5422  loss_mask: 0.3052  loss_rpn_cls: 0.0488  loss_rpn_loc: 0.1243  time: 0.9268  data_time: 0.2239  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:30:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:30:54 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 8179  total_loss: 1.272  loss_cls: 0.3331  loss_box_reg: 0.5205  loss_mask: 0.2893  loss_rpn_cls: 0.03391  loss_rpn_loc: 0.08959  time: 0.9272  data_time: 0.2991  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:31:15 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 8199  total_loss: 1.281  loss_cls: 0.315  loss_box_reg: 0.5284  loss_mask: 0.2867  loss_rpn_cls: 0.02563  loss_rpn_loc: 0.09011  time: 0.9275  data_time: 0.2878  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:31:32 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 8219  total_loss: 1.298  loss_cls: 0.3472  loss_box_reg: 0.5152  loss_mask: 0.2769  loss_rpn_cls: 0.0423  loss_rpn_loc: 0.1208  time: 0.9274  data_time: 0.1675  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:31:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:31:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:31:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:31:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:31:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:31:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1480 s/iter. Eval: 0.0577 s/iter. Total: 0.2065 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1559 s/iter. Eval: 0.1280 s/iter. Total: 0.2850 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 15:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1398 s/iter. Total: 0.3008 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:32:00 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0010 s/iter. Inference: 0.1561 s/iter. Eval: 0.1296 s/iter. Total: 0.2867 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:32:05 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1593 s/iter. Eval: 0.1482 s/iter. Total: 0.3085 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 15:32:10 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1631 s/iter. Eval: 0.1579 s/iter. Total: 0.3220 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:32:15 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0010 s/iter. Inference: 0.1615 s/iter. Eval: 0.1550 s/iter. Total: 0.3175 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 15:32:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.224519 (0.312280 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:32:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.160942 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:32:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:32:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30617297557072104\n",
      "\u001b[32m[02/13 15:32:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:32:33 d2.utils.events]: \u001b[0m eta: 0:21:41  iter: 8239  total_loss: 1.181  loss_cls: 0.3074  loss_box_reg: 0.5042  loss_mask: 0.2675  loss_rpn_cls: 0.02678  loss_rpn_loc: 0.09466  time: 0.9278  data_time: 0.2767  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:32:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:32:55 d2.utils.events]: \u001b[0m eta: 0:21:25  iter: 8259  total_loss: 1.278  loss_cls: 0.311  loss_box_reg: 0.5243  loss_mask: 0.2855  loss_rpn_cls: 0.04469  loss_rpn_loc: 0.09944  time: 0.9283  data_time: 0.2891  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:33:10 d2.utils.events]: \u001b[0m eta: 0:21:07  iter: 8279  total_loss: 1.23  loss_cls: 0.3197  loss_box_reg: 0.5157  loss_mask: 0.2892  loss_rpn_cls: 0.04023  loss_rpn_loc: 0.1091  time: 0.9278  data_time: 0.0414  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:33:26 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 8299  total_loss: 1.278  loss_cls: 0.3195  loss_box_reg: 0.5216  loss_mask: 0.2854  loss_rpn_cls: 0.03274  loss_rpn_loc: 0.09852  time: 0.9275  data_time: 0.0751  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:33:44 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 8319  total_loss: 1.354  loss_cls: 0.3435  loss_box_reg: 0.5441  loss_mask: 0.2878  loss_rpn_cls: 0.0468  loss_rpn_loc: 0.116  time: 0.9274  data_time: 0.1670  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:34:00 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 8339  total_loss: 1.315  loss_cls: 0.3367  loss_box_reg: 0.538  loss_mask: 0.2902  loss_rpn_cls: 0.0481  loss_rpn_loc: 0.09991  time: 0.9271  data_time: 0.1042  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:34:17 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 8359  total_loss: 1.332  loss_cls: 0.3391  loss_box_reg: 0.5294  loss_mask: 0.2912  loss_rpn_cls: 0.0365  loss_rpn_loc: 0.109  time: 0.9270  data_time: 0.1365  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:34:37 d2.utils.events]: \u001b[0m eta: 0:19:58  iter: 8379  total_loss: 1.307  loss_cls: 0.3463  loss_box_reg: 0.5341  loss_mask: 0.2932  loss_rpn_cls: 0.04356  loss_rpn_loc: 0.1086  time: 0.9271  data_time: 0.2663  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:34:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:34:59 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 8399  total_loss: 1.303  loss_cls: 0.3395  loss_box_reg: 0.5264  loss_mask: 0.31  loss_rpn_cls: 0.03993  loss_rpn_loc: 0.1053  time: 0.9275  data_time: 0.2508  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:35:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:35:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:35:23 d2.utils.events]: \u001b[0m eta: 0:19:30  iter: 8419  total_loss: 1.309  loss_cls: 0.3456  loss_box_reg: 0.5329  loss_mask: 0.2789  loss_rpn_cls: 0.04823  loss_rpn_loc: 0.1062  time: 0.9281  data_time: 0.2814  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:35:41 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 8439  total_loss: 1.321  loss_cls: 0.3258  loss_box_reg: 0.5532  loss_mask: 0.2893  loss_rpn_cls: 0.03607  loss_rpn_loc: 0.106  time: 0.9281  data_time: 0.1919  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:36:01 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 8459  total_loss: 1.19  loss_cls: 0.2955  loss_box_reg: 0.5059  loss_mask: 0.2702  loss_rpn_cls: 0.02869  loss_rpn_loc: 0.09976  time: 0.9283  data_time: 0.2888  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:36:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:36:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:36:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:36:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:36:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:36:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:36:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.1473 s/iter. Eval: 0.0575 s/iter. Total: 0.2058 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0010 s/iter. Inference: 0.1550 s/iter. Eval: 0.1281 s/iter. Total: 0.2841 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 15:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.1602 s/iter. Eval: 0.1402 s/iter. Total: 0.3015 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1571 s/iter. Eval: 0.1323 s/iter. Total: 0.2904 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1591 s/iter. Eval: 0.1441 s/iter. Total: 0.3043 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 15:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1636 s/iter. Eval: 0.1558 s/iter. Total: 0.3205 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1622 s/iter. Eval: 0.1571 s/iter. Total: 0.3204 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:36:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.666954 (0.316094 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:36:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.161605 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:36:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:36:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30629756112965695\n",
      "\u001b[32m[02/13 15:37:03 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 8479  total_loss: 1.366  loss_cls: 0.3655  loss_box_reg: 0.5181  loss_mask: 0.3141  loss_rpn_cls: 0.04195  loss_rpn_loc: 0.1198  time: 0.9287  data_time: 0.2340  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:37:19 d2.utils.events]: \u001b[0m eta: 0:18:33  iter: 8499  total_loss: 1.312  loss_cls: 0.344  loss_box_reg: 0.5163  loss_mask: 0.292  loss_rpn_cls: 0.03995  loss_rpn_loc: 0.1121  time: 0.9285  data_time: 0.1178  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:37:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:37:41 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 8519  total_loss: 1.255  loss_cls: 0.3287  loss_box_reg: 0.5242  loss_mask: 0.2958  loss_rpn_cls: 0.02813  loss_rpn_loc: 0.07934  time: 0.9288  data_time: 0.2289  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:37:58 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 8539  total_loss: 1.132  loss_cls: 0.2965  loss_box_reg: 0.5001  loss_mask: 0.2645  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.08251  time: 0.9287  data_time: 0.1679  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:38:16 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 8559  total_loss: 1.368  loss_cls: 0.3543  loss_box_reg: 0.558  loss_mask: 0.3092  loss_rpn_cls: 0.04837  loss_rpn_loc: 0.1108  time: 0.9286  data_time: 0.1595  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:38:30 d2.utils.events]: \u001b[0m eta: 0:17:33  iter: 8579  total_loss: 1.295  loss_cls: 0.3355  loss_box_reg: 0.5581  loss_mask: 0.2998  loss_rpn_cls: 0.03433  loss_rpn_loc: 0.1045  time: 0.9281  data_time: 0.0215  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:38:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:38:51 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 8599  total_loss: 1.402  loss_cls: 0.3655  loss_box_reg: 0.5691  loss_mask: 0.2997  loss_rpn_cls: 0.04827  loss_rpn_loc: 0.1212  time: 0.9284  data_time: 0.2353  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:39:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:39:12 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 8619  total_loss: 1.369  loss_cls: 0.3313  loss_box_reg: 0.5595  loss_mask: 0.2904  loss_rpn_cls: 0.04431  loss_rpn_loc: 0.1089  time: 0.9286  data_time: 0.2165  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:39:28 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 8639  total_loss: 1.276  loss_cls: 0.3157  loss_box_reg: 0.5289  loss_mask: 0.2875  loss_rpn_cls: 0.03438  loss_rpn_loc: 0.09793  time: 0.9283  data_time: 0.0817  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:39:46 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 8659  total_loss: 1.407  loss_cls: 0.3619  loss_box_reg: 0.5635  loss_mask: 0.2907  loss_rpn_cls: 0.0459  loss_rpn_loc: 0.1112  time: 0.9283  data_time: 0.1794  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:40:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:40:07 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 8679  total_loss: 1.303  loss_cls: 0.3385  loss_box_reg: 0.5214  loss_mask: 0.2854  loss_rpn_cls: 0.03932  loss_rpn_loc: 0.104  time: 0.9286  data_time: 0.2688  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:40:28 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 8699  total_loss: 1.212  loss_cls: 0.2923  loss_box_reg: 0.5135  loss_mask: 0.2728  loss_rpn_cls: 0.02725  loss_rpn_loc: 0.09509  time: 0.9289  data_time: 0.3079  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:40:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:40:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:40:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:40:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:40:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:40:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1461 s/iter. Eval: 0.0588 s/iter. Total: 0.2058 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1538 s/iter. Eval: 0.1171 s/iter. Total: 0.2719 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1553 s/iter. Eval: 0.1331 s/iter. Total: 0.2894 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1544 s/iter. Eval: 0.1351 s/iter. Total: 0.2905 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1570 s/iter. Eval: 0.1450 s/iter. Total: 0.3030 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 15:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1567 s/iter. Total: 0.3176 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1593 s/iter. Eval: 0.1582 s/iter. Total: 0.3185 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:41:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.540514 (0.315004 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:41:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159632 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:41:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:41:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3054863913369476\n",
      "\u001b[32m[02/13 15:41:23 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 8719  total_loss: 1.27  loss_cls: 0.3166  loss_box_reg: 0.5261  loss_mask: 0.2893  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.09707  time: 0.9285  data_time: 0.0525  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:41:43 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 8739  total_loss: 1.323  loss_cls: 0.3321  loss_box_reg: 0.5191  loss_mask: 0.277  loss_rpn_cls: 0.03374  loss_rpn_loc: 0.1084  time: 0.9287  data_time: 0.2725  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:41:59 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 8759  total_loss: 1.272  loss_cls: 0.3313  loss_box_reg: 0.5322  loss_mask: 0.2864  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.0839  time: 0.9284  data_time: 0.1071  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:42:17 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 8779  total_loss: 1.249  loss_cls: 0.3198  loss_box_reg: 0.5287  loss_mask: 0.2734  loss_rpn_cls: 0.04427  loss_rpn_loc: 0.1062  time: 0.9284  data_time: 0.1865  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:42:34 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 8799  total_loss: 1.201  loss_cls: 0.3026  loss_box_reg: 0.5184  loss_mask: 0.2899  loss_rpn_cls: 0.0287  loss_rpn_loc: 0.08864  time: 0.9282  data_time: 0.1252  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:42:52 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 8819  total_loss: 1.267  loss_cls: 0.338  loss_box_reg: 0.5279  loss_mask: 0.3057  loss_rpn_cls: 0.04417  loss_rpn_loc: 0.09539  time: 0.9281  data_time: 0.1689  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:43:11 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 8839  total_loss: 1.414  loss_cls: 0.3565  loss_box_reg: 0.5729  loss_mask: 0.3071  loss_rpn_cls: 0.05177  loss_rpn_loc: 0.1176  time: 0.9281  data_time: 0.1816  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:43:27 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 8859  total_loss: 1.267  loss_cls: 0.3105  loss_box_reg: 0.5365  loss_mask: 0.2964  loss_rpn_cls: 0.03096  loss_rpn_loc: 0.09122  time: 0.9278  data_time: 0.0718  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:43:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:43:48 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 8879  total_loss: 1.282  loss_cls: 0.3231  loss_box_reg: 0.5192  loss_mask: 0.2831  loss_rpn_cls: 0.03131  loss_rpn_loc: 0.1039  time: 0.9282  data_time: 0.2826  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:44:07 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 8899  total_loss: 1.334  loss_cls: 0.3309  loss_box_reg: 0.5368  loss_mask: 0.2832  loss_rpn_cls: 0.05276  loss_rpn_loc: 0.1121  time: 0.9283  data_time: 0.2358  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:44:27 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 8919  total_loss: 1.328  loss_cls: 0.343  loss_box_reg: 0.5358  loss_mask: 0.2991  loss_rpn_cls: 0.04305  loss_rpn_loc: 0.1061  time: 0.9284  data_time: 0.2329  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:44:47 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 8939  total_loss: 1.347  loss_cls: 0.3364  loss_box_reg: 0.53  loss_mask: 0.2865  loss_rpn_cls: 0.04879  loss_rpn_loc: 0.1183  time: 0.9285  data_time: 0.2705  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:45:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:45:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:45:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:45:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:45:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:45:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1469 s/iter. Eval: 0.0601 s/iter. Total: 0.2079 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0010 s/iter. Inference: 0.1578 s/iter. Eval: 0.1308 s/iter. Total: 0.2897 s/iter. ETA=0:00:27\n",
      "\u001b[32m[02/13 15:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0010 s/iter. Inference: 0.1582 s/iter. Eval: 0.1397 s/iter. Total: 0.2990 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 15:45:21 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0010 s/iter. Inference: 0.1559 s/iter. Eval: 0.1395 s/iter. Total: 0.2964 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 15:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1571 s/iter. Eval: 0.1496 s/iter. Total: 0.3077 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 15:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1599 s/iter. Eval: 0.1605 s/iter. Total: 0.3214 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1598 s/iter. Eval: 0.1630 s/iter. Total: 0.3239 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:45:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.966749 (0.318679 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:45:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.159956 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:45:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:45:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3059727034677932\n",
      "\u001b[32m[02/13 15:45:45 d2.utils.events]: \u001b[0m eta: 0:12:57  iter: 8959  total_loss: 1.375  loss_cls: 0.3375  loss_box_reg: 0.5646  loss_mask: 0.2956  loss_rpn_cls: 0.04169  loss_rpn_loc: 0.1012  time: 0.9285  data_time: 0.2107  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:46:02 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 8979  total_loss: 1.23  loss_cls: 0.3134  loss_box_reg: 0.5259  loss_mask: 0.2961  loss_rpn_cls: 0.02342  loss_rpn_loc: 0.09637  time: 0.9283  data_time: 0.1316  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:46:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:46:19 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 8999  total_loss: 1.28  loss_cls: 0.3242  loss_box_reg: 0.5624  loss_mask: 0.2835  loss_rpn_cls: 0.03223  loss_rpn_loc: 0.097  time: 0.9282  data_time: 0.1047  lr: 2.0972e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:46:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:46:42 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 9019  total_loss: 1.469  loss_cls: 0.3726  loss_box_reg: 0.5709  loss_mask: 0.3027  loss_rpn_cls: 0.05646  loss_rpn_loc: 0.131  time: 0.9287  data_time: 0.2429  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:47:00 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 9039  total_loss: 1.305  loss_cls: 0.3185  loss_box_reg: 0.5114  loss_mask: 0.2813  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.1135  time: 0.9286  data_time: 0.1861  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:47:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:47:22 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 9059  total_loss: 1.3  loss_cls: 0.3302  loss_box_reg: 0.5442  loss_mask: 0.2914  loss_rpn_cls: 0.04125  loss_rpn_loc: 0.1078  time: 0.9290  data_time: 0.3028  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:47:41 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 9079  total_loss: 1.242  loss_cls: 0.3038  loss_box_reg: 0.5372  loss_mask: 0.312  loss_rpn_cls: 0.03925  loss_rpn_loc: 0.08741  time: 0.9291  data_time: 0.2330  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:47:56 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 9099  total_loss: 1.242  loss_cls: 0.3206  loss_box_reg: 0.5106  loss_mask: 0.2738  loss_rpn_cls: 0.02971  loss_rpn_loc: 0.105  time: 0.9287  data_time: 0.0659  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:48:14 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 9119  total_loss: 1.21  loss_cls: 0.2955  loss_box_reg: 0.5316  loss_mask: 0.2851  loss_rpn_cls: 0.03257  loss_rpn_loc: 0.07067  time: 0.9286  data_time: 0.1701  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:48:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:48:35 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 9139  total_loss: 1.441  loss_cls: 0.3512  loss_box_reg: 0.5478  loss_mask: 0.2979  loss_rpn_cls: 0.06074  loss_rpn_loc: 0.1149  time: 0.9289  data_time: 0.2262  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:48:55 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 9159  total_loss: 1.244  loss_cls: 0.3359  loss_box_reg: 0.4931  loss_mask: 0.2761  loss_rpn_cls: 0.04128  loss_rpn_loc: 0.09862  time: 0.9290  data_time: 0.2371  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:49:12 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 9179  total_loss: 1.367  loss_cls: 0.3278  loss_box_reg: 0.5481  loss_mask: 0.291  loss_rpn_cls: 0.0346  loss_rpn_loc: 0.1078  time: 0.9289  data_time: 0.1678  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:49:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:49:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:49:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:49:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:49:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:49:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1484 s/iter. Eval: 0.0587 s/iter. Total: 0.2080 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0009 s/iter. Inference: 0.1536 s/iter. Eval: 0.1238 s/iter. Total: 0.2785 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.1594 s/iter. Eval: 0.1372 s/iter. Total: 0.2976 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1569 s/iter. Eval: 0.1381 s/iter. Total: 0.2960 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 15:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0009 s/iter. Inference: 0.1578 s/iter. Eval: 0.1467 s/iter. Total: 0.3055 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 15:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0009 s/iter. Inference: 0.1621 s/iter. Eval: 0.1581 s/iter. Total: 0.3211 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0009 s/iter. Inference: 0.1612 s/iter. Eval: 0.1609 s/iter. Total: 0.3231 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:50:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.795530 (0.317203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:50:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.160480 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:50:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:50:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3054575101939959\n",
      "\u001b[32m[02/13 15:50:09 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 9199  total_loss: 1.281  loss_cls: 0.3522  loss_box_reg: 0.5505  loss_mask: 0.2794  loss_rpn_cls: 0.0274  loss_rpn_loc: 0.108  time: 0.9288  data_time: 0.2154  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:50:27 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 9219  total_loss: 1.278  loss_cls: 0.3027  loss_box_reg: 0.5281  loss_mask: 0.2916  loss_rpn_cls: 0.03078  loss_rpn_loc: 0.1069  time: 0.9287  data_time: 0.1839  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:50:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:50:49 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 9239  total_loss: 1.309  loss_cls: 0.3438  loss_box_reg: 0.5492  loss_mask: 0.3213  loss_rpn_cls: 0.04248  loss_rpn_loc: 0.115  time: 0.9291  data_time: 0.2757  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:51:08 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 9259  total_loss: 1.334  loss_cls: 0.3501  loss_box_reg: 0.5301  loss_mask: 0.2865  loss_rpn_cls: 0.04343  loss_rpn_loc: 0.1098  time: 0.9291  data_time: 0.2166  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:51:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:51:29 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 9279  total_loss: 1.292  loss_cls: 0.341  loss_box_reg: 0.5292  loss_mask: 0.2876  loss_rpn_cls: 0.0368  loss_rpn_loc: 0.08952  time: 0.9294  data_time: 0.2345  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:51:49 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 9299  total_loss: 1.223  loss_cls: 0.3182  loss_box_reg: 0.516  loss_mask: 0.2771  loss_rpn_cls: 0.04239  loss_rpn_loc: 0.1098  time: 0.9295  data_time: 0.2747  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:52:04 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 9319  total_loss: 1.302  loss_cls: 0.3346  loss_box_reg: 0.5386  loss_mask: 0.287  loss_rpn_cls: 0.03231  loss_rpn_loc: 0.0995  time: 0.9292  data_time: 0.0880  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:52:21 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 9339  total_loss: 1.313  loss_cls: 0.33  loss_box_reg: 0.5503  loss_mask: 0.292  loss_rpn_cls: 0.03109  loss_rpn_loc: 0.08968  time: 0.9290  data_time: 0.1335  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:52:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:52:43 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 9359  total_loss: 1.366  loss_cls: 0.3381  loss_box_reg: 0.5574  loss_mask: 0.3022  loss_rpn_cls: 0.04055  loss_rpn_loc: 0.1043  time: 0.9293  data_time: 0.2566  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:52:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:53:06 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 9379  total_loss: 1.272  loss_cls: 0.3254  loss_box_reg: 0.5098  loss_mask: 0.287  loss_rpn_cls: 0.02695  loss_rpn_loc: 0.09536  time: 0.9299  data_time: 0.3679  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:53:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:53:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:53:28 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 9399  total_loss: 1.321  loss_cls: 0.357  loss_box_reg: 0.5272  loss_mask: 0.2843  loss_rpn_cls: 0.04266  loss_rpn_loc: 0.103  time: 0.9301  data_time: 0.1230  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:53:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:53:47 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 9419  total_loss: 1.332  loss_cls: 0.3338  loss_box_reg: 0.5399  loss_mask: 0.2804  loss_rpn_cls: 0.03602  loss_rpn_loc: 0.1142  time: 0.9302  data_time: 0.1759  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:54:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:54:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:54:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:54:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:54:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:54:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:54:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1467 s/iter. Eval: 0.0654 s/iter. Total: 0.2130 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 15:54:09 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0010 s/iter. Inference: 0.1519 s/iter. Eval: 0.1211 s/iter. Total: 0.2741 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:54:14 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0010 s/iter. Inference: 0.1566 s/iter. Eval: 0.1340 s/iter. Total: 0.2917 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:54:19 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1548 s/iter. Eval: 0.1355 s/iter. Total: 0.2913 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:54:24 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1561 s/iter. Eval: 0.1444 s/iter. Total: 0.3015 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 15:54:29 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1588 s/iter. Eval: 0.1554 s/iter. Total: 0.3152 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:54:34 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0010 s/iter. Inference: 0.1595 s/iter. Eval: 0.1576 s/iter. Total: 0.3180 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:54:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.185169 (0.311941 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:54:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158758 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:54:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:54:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30555649298221443\n",
      "\u001b[32m[02/13 15:54:40 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 9439  total_loss: 1.201  loss_cls: 0.3171  loss_box_reg: 0.5227  loss_mask: 0.2947  loss_rpn_cls: 0.0307  loss_rpn_loc: 0.06534  time: 0.9298  data_time: 0.0574  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:55:00 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 9459  total_loss: 1.316  loss_cls: 0.3344  loss_box_reg: 0.524  loss_mask: 0.2833  loss_rpn_cls: 0.04323  loss_rpn_loc: 0.114  time: 0.9300  data_time: 0.2641  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:55:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:55:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:55:21 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 9479  total_loss: 1.167  loss_cls: 0.2974  loss_box_reg: 0.5026  loss_mask: 0.3007  loss_rpn_cls: 0.0311  loss_rpn_loc: 0.09728  time: 0.9302  data_time: 0.1462  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:55:37 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 9499  total_loss: 1.195  loss_cls: 0.313  loss_box_reg: 0.5202  loss_mask: 0.2911  loss_rpn_cls: 0.03137  loss_rpn_loc: 0.1037  time: 0.9299  data_time: 0.0973  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:55:54 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 9519  total_loss: 1.401  loss_cls: 0.386  loss_box_reg: 0.5639  loss_mask: 0.2978  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.1147  time: 0.9297  data_time: 0.1532  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:56:10 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 9539  total_loss: 1.239  loss_cls: 0.3308  loss_box_reg: 0.5019  loss_mask: 0.2688  loss_rpn_cls: 0.0304  loss_rpn_loc: 0.09814  time: 0.9295  data_time: 0.1133  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:56:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:56:31 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 9559  total_loss: 1.314  loss_cls: 0.3387  loss_box_reg: 0.5414  loss_mask: 0.2916  loss_rpn_cls: 0.04999  loss_rpn_loc: 0.1029  time: 0.9297  data_time: 0.1867  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:56:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:56:53 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 9579  total_loss: 1.234  loss_cls: 0.299  loss_box_reg: 0.5035  loss_mask: 0.2856  loss_rpn_cls: 0.02783  loss_rpn_loc: 0.08871  time: 0.9300  data_time: 0.2667  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:57:12 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 9599  total_loss: 1.29  loss_cls: 0.3372  loss_box_reg: 0.5158  loss_mask: 0.2927  loss_rpn_cls: 0.03967  loss_rpn_loc: 0.1114  time: 0.9301  data_time: 0.2498  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:57:28 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 9619  total_loss: 1.29  loss_cls: 0.3314  loss_box_reg: 0.5121  loss_mask: 0.2858  loss_rpn_cls: 0.03611  loss_rpn_loc: 0.1005  time: 0.9299  data_time: 0.1319  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:57:45 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 9639  total_loss: 1.294  loss_cls: 0.3165  loss_box_reg: 0.542  loss_mask: 0.2961  loss_rpn_cls: 0.03427  loss_rpn_loc: 0.1052  time: 0.9297  data_time: 0.1236  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:57:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:58:06 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 9659  total_loss: 1.227  loss_cls: 0.3252  loss_box_reg: 0.4976  loss_mask: 0.2804  loss_rpn_cls: 0.03462  loss_rpn_loc: 0.1052  time: 0.9300  data_time: 0.2651  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:58:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:58:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 15:58:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 15:58:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 15:58:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 15:58:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 15:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1477 s/iter. Eval: 0.0666 s/iter. Total: 0.2152 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 15:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0010 s/iter. Inference: 0.1522 s/iter. Eval: 0.1215 s/iter. Total: 0.2748 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/13 15:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0010 s/iter. Inference: 0.1575 s/iter. Eval: 0.1345 s/iter. Total: 0.2931 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 15:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0010 s/iter. Inference: 0.1553 s/iter. Eval: 0.1356 s/iter. Total: 0.2920 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/13 15:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1564 s/iter. Eval: 0.1442 s/iter. Total: 0.3017 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 15:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1592 s/iter. Eval: 0.1548 s/iter. Total: 0.3150 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 15:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1594 s/iter. Eval: 0.1556 s/iter. Total: 0.3161 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 15:59:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.130111 (0.311466 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:59:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.158871 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 15:59:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 15:59:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.3067978080834429\n",
      "\u001b[32m[02/13 15:59:02 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 9679  total_loss: 1.277  loss_cls: 0.3329  loss_box_reg: 0.5207  loss_mask: 0.2776  loss_rpn_cls: 0.03045  loss_rpn_loc: 0.1154  time: 0.9298  data_time: 0.1428  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:59:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 15:59:22 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 9699  total_loss: 1.465  loss_cls: 0.4015  loss_box_reg: 0.5738  loss_mask: 0.3009  loss_rpn_cls: 0.03888  loss_rpn_loc: 0.1356  time: 0.9300  data_time: 0.1785  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:59:39 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 9719  total_loss: 1.345  loss_cls: 0.347  loss_box_reg: 0.546  loss_mask: 0.2827  loss_rpn_cls: 0.03489  loss_rpn_loc: 0.1017  time: 0.9299  data_time: 0.1565  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 15:59:59 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 9739  total_loss: 1.291  loss_cls: 0.3432  loss_box_reg: 0.5019  loss_mask: 0.2957  loss_rpn_cls: 0.04447  loss_rpn_loc: 0.1054  time: 0.9300  data_time: 0.2829  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:00:17 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 9759  total_loss: 1.373  loss_cls: 0.3442  loss_box_reg: 0.5554  loss_mask: 0.3044  loss_rpn_cls: 0.05161  loss_rpn_loc: 0.1238  time: 0.9299  data_time: 0.1977  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:00:35 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 9779  total_loss: 1.313  loss_cls: 0.3254  loss_box_reg: 0.5191  loss_mask: 0.2918  loss_rpn_cls: 0.04812  loss_rpn_loc: 0.1097  time: 0.9299  data_time: 0.2240  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:00:52 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 9799  total_loss: 1.309  loss_cls: 0.331  loss_box_reg: 0.5384  loss_mask: 0.2872  loss_rpn_cls: 0.03368  loss_rpn_loc: 0.1111  time: 0.9297  data_time: 0.1256  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:00:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 16:01:12 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 9819  total_loss: 1.366  loss_cls: 0.3378  loss_box_reg: 0.5554  loss_mask: 0.2945  loss_rpn_cls: 0.05613  loss_rpn_loc: 0.1032  time: 0.9298  data_time: 0.1988  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:01:29 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 9839  total_loss: 1.311  loss_cls: 0.3396  loss_box_reg: 0.5297  loss_mask: 0.2961  loss_rpn_cls: 0.04128  loss_rpn_loc: 0.1098  time: 0.9297  data_time: 0.1385  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:01:46 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 9859  total_loss: 1.314  loss_cls: 0.3338  loss_box_reg: 0.5351  loss_mask: 0.2995  loss_rpn_cls: 0.04605  loss_rpn_loc: 0.1176  time: 0.9295  data_time: 0.1563  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:02:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 16:02:07 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 9879  total_loss: 1.398  loss_cls: 0.3527  loss_box_reg: 0.5725  loss_mask: 0.2944  loss_rpn_cls: 0.03927  loss_rpn_loc: 0.1194  time: 0.9297  data_time: 0.2091  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:02:24 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 9899  total_loss: 1.227  loss_cls: 0.3209  loss_box_reg: 0.508  loss_mask: 0.2825  loss_rpn_cls: 0.02257  loss_rpn_loc: 0.08751  time: 0.9296  data_time: 0.1247  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:02:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 16:02:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 16:02:48 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 9919  total_loss: 1.268  loss_cls: 0.3314  loss_box_reg: 0.5242  loss_mask: 0.2856  loss_rpn_cls: 0.02422  loss_rpn_loc: 0.1018  time: 0.9301  data_time: 0.2850  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:02:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 16:02:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 16:02:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 16:02:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 16:02:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 16:02:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 16:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1473 s/iter. Eval: 0.0624 s/iter. Total: 0.2105 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 16:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1532 s/iter. Eval: 0.1313 s/iter. Total: 0.2855 s/iter. ETA=0:00:26\n",
      "\u001b[32m[02/13 16:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.1551 s/iter. Eval: 0.1409 s/iter. Total: 0.2970 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/13 16:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0009 s/iter. Inference: 0.1520 s/iter. Eval: 0.1306 s/iter. Total: 0.2836 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/13 16:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0010 s/iter. Inference: 0.1568 s/iter. Eval: 0.1486 s/iter. Total: 0.3064 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/13 16:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0010 s/iter. Inference: 0.1593 s/iter. Eval: 0.1577 s/iter. Total: 0.3181 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 16:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0010 s/iter. Inference: 0.1578 s/iter. Eval: 0.1533 s/iter. Total: 0.3120 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/13 16:03:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.790963 (0.308543 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 16:03:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157650 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 16:03:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 16:03:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30784786966904965\n",
      "\u001b[32m[02/13 16:03:42 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 9939  total_loss: 1.232  loss_cls: 0.34  loss_box_reg: 0.5391  loss_mask: 0.2783  loss_rpn_cls: 0.03234  loss_rpn_loc: 0.1023  time: 0.9299  data_time: 0.1118  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:04:02 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 9959  total_loss: 1.3  loss_cls: 0.3586  loss_box_reg: 0.542  loss_mask: 0.2931  loss_rpn_cls: 0.04283  loss_rpn_loc: 0.1139  time: 0.9300  data_time: 0.2809  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:04:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7ff0e10fe310> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/13 16:04:21 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 9979  total_loss: 1.431  loss_cls: 0.3519  loss_box_reg: 0.5793  loss_mask: 0.2971  loss_rpn_cls: 0.03962  loss_rpn_loc: 0.1113  time: 0.9300  data_time: 0.1198  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:04:37 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.279  loss_cls: 0.3334  loss_box_reg: 0.5108  loss_mask: 0.2813  loss_rpn_cls: 0.03803  loss_rpn_loc: 0.1012  time: 0.9297  data_time: 0.0845  lr: 1.6777e-05  max_mem: 9424M\n",
      "\u001b[32m[02/13 16:04:37 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 2:34:55 (0.9297 s / it)\n",
      "\u001b[32m[02/13 16:04:37 d2.engine.hooks]: \u001b[0mTotal training time: 3:01:17 (0:26:22 on hooks)\n",
      "\u001b[32m[02/13 16:04:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 16:04:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=3000, sample_style='choice')]\n",
      "\u001b[32m[02/13 16:04:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/13 16:04:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/13 16:04:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/13 16:04:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/13 16:04:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1465 s/iter. Eval: 0.0625 s/iter. Total: 0.2100 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 16:04:45 d2.evaluation.evaluator]: \u001b[0mInference done 26/121. Dataloading: 0.0010 s/iter. Inference: 0.1557 s/iter. Eval: 0.1435 s/iter. Total: 0.3003 s/iter. ETA=0:00:28\n",
      "\u001b[32m[02/13 16:04:50 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0010 s/iter. Inference: 0.1550 s/iter. Eval: 0.1434 s/iter. Total: 0.2995 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/13 16:04:56 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0010 s/iter. Inference: 0.1538 s/iter. Eval: 0.1426 s/iter. Total: 0.2975 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/13 16:05:01 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0010 s/iter. Inference: 0.1553 s/iter. Eval: 0.1514 s/iter. Total: 0.3077 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/13 16:05:06 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1581 s/iter. Eval: 0.1627 s/iter. Total: 0.3219 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/13 16:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0010 s/iter. Inference: 0.1575 s/iter. Eval: 0.1633 s/iter. Total: 0.3219 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/13 16:05:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.834779 (0.317541 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 16:05:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.157304 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/13 16:05:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/13 16:05:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30611399673148504\n"
     ]
    }
   ],
   "source": [
    "# train on training set\n",
    "dataDir=Path('../')\n",
    "register_coco_instances('sartorius_train',{}, '../sartorius-annotations-coco-format/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_val',{},'../sartorius-annotations-coco-format/annotations_val.json', dataDir)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.INPUT.MIN_SIZE_TEST = 1024\n",
    "cfg.INPUT.MAX_SIZE_TEST = 3000\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_11.1/model_0001439.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 4000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24], [40], [80], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 3.0]]\n",
    "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.7]\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.75\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.03\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 700\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_11.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff37819-f9fc-41b7-96ae-15e59da6a42a",
   "metadata": {},
   "source": [
    "We select the model obtained after iteration 9919 (which has the best score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
