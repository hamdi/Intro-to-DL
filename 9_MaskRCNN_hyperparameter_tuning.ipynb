{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd0dbe7-a285-48c1-8f6f-352ba4597e89",
   "metadata": {},
   "source": [
    "### Notebook 9: Mask R-CNN hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e627df94-333c-441a-8fa3-7adfa975d59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import pycocotools.mask as mask_util\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5766de-f622-480f-bedc-7183e08b00f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/06 18:20:17 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n"
     ]
    }
   ],
   "source": [
    "dataDir=Path('../')\n",
    "register_coco_instances('sartorius_train',{}, '../sartorius-annotations-coco-format/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_val',{},'../sartorius-annotations-coco-format/annotations_val.json', dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff644be9-5ec4-4269-9ebd-5d049827291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = [0.204, 0.386, 0.568]\n",
    "min_mask_area = [75, 180, 75]\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    false_positives = np.sum(matches, axis=0) == 0\n",
    "    if len(matches.shape)>1:\n",
    "        false_negatives = np.sum(matches, axis=1) == 0\n",
    "        true_positives = np.sum(matches, axis=1) == 1\n",
    "    else:\n",
    "        false_negatives = 0\n",
    "        true_positives = 0\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n",
    "    take = pred['instances'].scores >= score_threshold[pred_class]\n",
    "    pred_masks = pred['instances'].pred_masks[take].cpu().numpy()\n",
    "    if len(pred_masks)==0:\n",
    "        return 0.\n",
    "    else:\n",
    "        enc_preds = []\n",
    "        used = np.zeros(pred_masks[0].shape, dtype=int)\n",
    "        for mask in pred_masks:\n",
    "            mask = (mask * (1-used)).astype(bool)\n",
    "            if mask.sum() >= min_mask_area[pred_class]:\n",
    "                used += mask\n",
    "                enc_preds.append(mask_util.encode(np.asarray(mask, order='F')) )\n",
    "        enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "        ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "        prec = []\n",
    "        for t in np.arange(0.5, 1.0, 0.05):\n",
    "            tp, fp, fn = precision_at(t, ious)\n",
    "            p = tp / (tp + fp + fn)\n",
    "            prec.append(p)\n",
    "        return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"mAP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c0e1f2-9d98-4df0-b6ff-df43e1f7ee16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/03 16:46:35 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/03 16:46:36 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/03 16:46:39 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/03 16:46:39 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/03 16:46:40 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/03 16:46:40 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/03 16:46:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/03 16:46:40 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/03 16:46:40 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:46:40 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/03 16:46:40 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/03 16:46:52 d2.utils.events]: \u001b[0m eta: 1:07:12  iter: 19  total_loss: 3.051  loss_cls: 1.419  loss_box_reg: 0.3043  loss_mask: 0.6935  loss_rpn_cls: 0.3503  loss_rpn_loc: 0.2986  time: 0.5016  data_time: 0.1857  lr: 9.9905e-06  max_mem: 3969M\n",
      "\u001b[32m[02/03 16:47:03 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 39  total_loss: 2.779  loss_cls: 1.318  loss_box_reg: 0.1775  loss_mask: 0.6867  loss_rpn_cls: 0.3173  loss_rpn_loc: 0.2404  time: 0.5358  data_time: 0.2030  lr: 1.998e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:47:19 d2.utils.events]: \u001b[0m eta: 1:06:06  iter: 59  total_loss: 2.71  loss_cls: 1.118  loss_box_reg: 0.2774  loss_mask: 0.6758  loss_rpn_cls: 0.3015  loss_rpn_loc: 0.264  time: 0.6170  data_time: 0.3703  lr: 2.997e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:47:31 d2.utils.events]: \u001b[0m eta: 1:06:26  iter: 79  total_loss: 2.493  loss_cls: 0.9342  loss_box_reg: 0.4445  loss_mask: 0.6509  loss_rpn_cls: 0.2431  loss_rpn_loc: 0.2533  time: 0.6229  data_time: 0.2430  lr: 3.9961e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:47:44 d2.utils.events]: \u001b[0m eta: 1:05:36  iter: 99  total_loss: 2.293  loss_cls: 0.7727  loss_box_reg: 0.4439  loss_mask: 0.6222  loss_rpn_cls: 0.1845  loss_rpn_loc: 0.2224  time: 0.6253  data_time: 0.2576  lr: 4.9951e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:47:56 d2.utils.events]: \u001b[0m eta: 1:05:36  iter: 119  total_loss: 2.317  loss_cls: 0.7128  loss_box_reg: 0.4827  loss_mask: 0.5966  loss_rpn_cls: 0.2036  loss_rpn_loc: 0.2426  time: 0.6167  data_time: 0.1778  lr: 5.9941e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:48:09 d2.utils.events]: \u001b[0m eta: 1:05:48  iter: 139  total_loss: 2.16  loss_cls: 0.6741  loss_box_reg: 0.4641  loss_mask: 0.5664  loss_rpn_cls: 0.2122  loss_rpn_loc: 0.2296  time: 0.6279  data_time: 0.2988  lr: 6.993e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:48:29 d2.utils.events]: \u001b[0m eta: 1:06:46  iter: 159  total_loss: 2.139  loss_cls: 0.6619  loss_box_reg: 0.5086  loss_mask: 0.5537  loss_rpn_cls: 0.1893  loss_rpn_loc: 0.261  time: 0.6699  data_time: 0.5457  lr: 7.9921e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:48:42 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 179  total_loss: 2.055  loss_cls: 0.627  loss_box_reg: 0.526  loss_mask: 0.499  loss_rpn_cls: 0.1527  loss_rpn_loc: 0.2274  time: 0.6703  data_time: 0.2595  lr: 8.991e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:48:54 d2.utils.events]: \u001b[0m eta: 1:07:46  iter: 199  total_loss: 2.064  loss_cls: 0.6241  loss_box_reg: 0.5645  loss_mask: 0.4862  loss_rpn_cls: 0.147  loss_rpn_loc: 0.2118  time: 0.6608  data_time: 0.1668  lr: 9.9901e-05  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:49:04 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 219  total_loss: 1.964  loss_cls: 0.555  loss_box_reg: 0.6163  loss_mask: 0.4516  loss_rpn_cls: 0.1256  loss_rpn_loc: 0.2158  time: 0.6466  data_time: 0.1055  lr: 0.00010989  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:49:16 d2.utils.events]: \u001b[0m eta: 1:07:29  iter: 239  total_loss: 2.04  loss_cls: 0.6179  loss_box_reg: 0.6248  loss_mask: 0.4343  loss_rpn_cls: 0.1284  loss_rpn_loc: 0.2162  time: 0.6426  data_time: 0.2035  lr: 0.00011988  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:49:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:49:17 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/03 16:49:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:49:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:49:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:49:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:49:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0618 s/iter. Eval: 0.0000 s/iter. Total: 0.0624 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/03 16:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0623 s/iter. Eval: 0.0000 s/iter. Total: 0.0631 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/03 16:49:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.361905 (0.063465 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:49:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.062123 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:49:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:49:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.0\n",
      "\u001b[32m[02/03 16:49:34 d2.utils.events]: \u001b[0m eta: 1:06:56  iter: 259  total_loss: 1.996  loss_cls: 0.5781  loss_box_reg: 0.6715  loss_mask: 0.4024  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.2204  time: 0.6314  data_time: 0.1055  lr: 0.00012987  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:49:47 d2.utils.events]: \u001b[0m eta: 1:06:45  iter: 279  total_loss: 1.777  loss_cls: 0.512  loss_box_reg: 0.6165  loss_mask: 0.364  loss_rpn_cls: 0.112  loss_rpn_loc: 0.2148  time: 0.6309  data_time: 0.2174  lr: 0.00013986  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:49:57 d2.utils.events]: \u001b[0m eta: 1:06:31  iter: 299  total_loss: 1.719  loss_cls: 0.4179  loss_box_reg: 0.6582  loss_mask: 0.3541  loss_rpn_cls: 0.1232  loss_rpn_loc: 0.2111  time: 0.6250  data_time: 0.1501  lr: 0.00014985  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:50:09 d2.utils.events]: \u001b[0m eta: 1:06:19  iter: 319  total_loss: 1.718  loss_cls: 0.4442  loss_box_reg: 0.6555  loss_mask: 0.3268  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2216  time: 0.6209  data_time: 0.1704  lr: 0.00015984  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:50:22 d2.utils.events]: \u001b[0m eta: 1:06:14  iter: 339  total_loss: 1.693  loss_cls: 0.4186  loss_box_reg: 0.5562  loss_mask: 0.3318  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.23  time: 0.6236  data_time: 0.2547  lr: 0.00016983  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:50:36 d2.utils.events]: \u001b[0m eta: 1:06:15  iter: 359  total_loss: 1.751  loss_cls: 0.4678  loss_box_reg: 0.5826  loss_mask: 0.3337  loss_rpn_cls: 0.149  loss_rpn_loc: 0.2295  time: 0.6281  data_time: 0.2952  lr: 0.00017982  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:50:49 d2.utils.events]: \u001b[0m eta: 1:06:37  iter: 379  total_loss: 1.642  loss_cls: 0.3831  loss_box_reg: 0.5807  loss_mask: 0.3133  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.2282  time: 0.6284  data_time: 0.2286  lr: 0.00018981  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:51:04 d2.utils.events]: \u001b[0m eta: 1:06:41  iter: 399  total_loss: 1.785  loss_cls: 0.4852  loss_box_reg: 0.6144  loss_mask: 0.3224  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.2265  time: 0.6345  data_time: 0.3312  lr: 0.0001998  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:51:17 d2.utils.events]: \u001b[0m eta: 1:06:52  iter: 419  total_loss: 1.691  loss_cls: 0.4146  loss_box_reg: 0.5665  loss_mask: 0.3201  loss_rpn_cls: 0.1401  loss_rpn_loc: 0.2021  time: 0.6367  data_time: 0.2639  lr: 0.00020979  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:51:27 d2.utils.events]: \u001b[0m eta: 1:06:25  iter: 439  total_loss: 1.641  loss_cls: 0.3717  loss_box_reg: 0.6256  loss_mask: 0.3067  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.2223  time: 0.6294  data_time: 0.0890  lr: 0.00021978  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:51:40 d2.utils.events]: \u001b[0m eta: 1:06:31  iter: 459  total_loss: 1.741  loss_cls: 0.4519  loss_box_reg: 0.5555  loss_mask: 0.324  loss_rpn_cls: 0.1387  loss_rpn_loc: 0.2466  time: 0.6305  data_time: 0.2459  lr: 0.00022977  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:51:53 d2.utils.events]: \u001b[0m eta: 1:06:17  iter: 479  total_loss: 1.659  loss_cls: 0.4006  loss_box_reg: 0.5838  loss_mask: 0.3209  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.2023  time: 0.6317  data_time: 0.2511  lr: 0.00023976  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:51:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:51:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:51:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:51:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:51:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:51:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0727 s/iter. Eval: 0.0320 s/iter. Total: 0.1054 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 16:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0725 s/iter. Eval: 0.0486 s/iter. Total: 0.1218 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 16:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0718 s/iter. Eval: 0.0525 s/iter. Total: 0.1250 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 16:52:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.102243 (0.121571 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:52:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070967 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:52:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:52:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2120453797631606\n",
      "\u001b[32m[02/03 16:52:19 d2.utils.events]: \u001b[0m eta: 1:06:00  iter: 499  total_loss: 1.576  loss_cls: 0.369  loss_box_reg: 0.5559  loss_mask: 0.3065  loss_rpn_cls: 0.1229  loss_rpn_loc: 0.2147  time: 0.6275  data_time: 0.1276  lr: 0.00024975  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:52:34 d2.utils.events]: \u001b[0m eta: 1:06:06  iter: 519  total_loss: 1.651  loss_cls: 0.3923  loss_box_reg: 0.56  loss_mask: 0.3136  loss_rpn_cls: 0.1371  loss_rpn_loc: 0.2375  time: 0.6321  data_time: 0.3338  lr: 0.00025974  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:52:46 d2.utils.events]: \u001b[0m eta: 1:06:00  iter: 539  total_loss: 1.624  loss_cls: 0.3875  loss_box_reg: 0.5582  loss_mask: 0.3233  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2185  time: 0.6304  data_time: 0.1844  lr: 0.00026973  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:52:57 d2.utils.events]: \u001b[0m eta: 1:05:50  iter: 559  total_loss: 1.549  loss_cls: 0.3726  loss_box_reg: 0.571  loss_mask: 0.314  loss_rpn_cls: 0.0839  loss_rpn_loc: 0.221  time: 0.6279  data_time: 0.1655  lr: 0.00027972  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:53:10 d2.utils.events]: \u001b[0m eta: 1:05:48  iter: 579  total_loss: 1.644  loss_cls: 0.416  loss_box_reg: 0.5675  loss_mask: 0.2965  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.2172  time: 0.6286  data_time: 0.2413  lr: 0.00028971  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:53:25 d2.utils.events]: \u001b[0m eta: 1:05:42  iter: 599  total_loss: 1.593  loss_cls: 0.3477  loss_box_reg: 0.5735  loss_mask: 0.3022  loss_rpn_cls: 0.08625  loss_rpn_loc: 0.2018  time: 0.6328  data_time: 0.3392  lr: 0.0002997  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:53:35 d2.utils.events]: \u001b[0m eta: 1:05:31  iter: 619  total_loss: 1.534  loss_cls: 0.3667  loss_box_reg: 0.5557  loss_mask: 0.3058  loss_rpn_cls: 0.09071  loss_rpn_loc: 0.193  time: 0.6277  data_time: 0.0807  lr: 0.00030969  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:53:47 d2.utils.events]: \u001b[0m eta: 1:05:29  iter: 639  total_loss: 1.49  loss_cls: 0.3517  loss_box_reg: 0.5161  loss_mask: 0.3214  loss_rpn_cls: 0.08107  loss_rpn_loc: 0.197  time: 0.6274  data_time: 0.2050  lr: 0.00031968  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:53:57 d2.utils.events]: \u001b[0m eta: 1:05:11  iter: 659  total_loss: 1.456  loss_cls: 0.2934  loss_box_reg: 0.5142  loss_mask: 0.3012  loss_rpn_cls: 0.08452  loss_rpn_loc: 0.1871  time: 0.6238  data_time: 0.1285  lr: 0.00032967  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:54:11 d2.utils.events]: \u001b[0m eta: 1:05:02  iter: 679  total_loss: 1.613  loss_cls: 0.3701  loss_box_reg: 0.5621  loss_mask: 0.3185  loss_rpn_cls: 0.1377  loss_rpn_loc: 0.2388  time: 0.6255  data_time: 0.2666  lr: 0.00033966  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:54:25 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 699  total_loss: 1.519  loss_cls: 0.3645  loss_box_reg: 0.5605  loss_mask: 0.3023  loss_rpn_cls: 0.09598  loss_rpn_loc: 0.2047  time: 0.6279  data_time: 0.2930  lr: 0.00034965  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:54:38 d2.utils.events]: \u001b[0m eta: 1:04:52  iter: 719  total_loss: 1.69  loss_cls: 0.4152  loss_box_reg: 0.5916  loss_mask: 0.3334  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.2359  time: 0.6289  data_time: 0.2475  lr: 0.00035964  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:54:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:54:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:54:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:54:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:54:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:54:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0307 s/iter. Total: 0.0993 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 16:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 54/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0449 s/iter. Total: 0.1160 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/03 16:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0474 s/iter. Total: 0.1185 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/03 16:54:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.568678 (0.116971 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:54:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070147 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:54:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:54:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2307970286374739\n",
      "\u001b[32m[02/03 16:55:06 d2.utils.events]: \u001b[0m eta: 1:04:40  iter: 739  total_loss: 1.476  loss_cls: 0.3207  loss_box_reg: 0.5384  loss_mask: 0.3137  loss_rpn_cls: 0.08551  loss_rpn_loc: 0.1969  time: 0.6287  data_time: 0.2088  lr: 0.00036963  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:55:17 d2.utils.events]: \u001b[0m eta: 1:04:32  iter: 759  total_loss: 1.564  loss_cls: 0.3843  loss_box_reg: 0.5785  loss_mask: 0.2987  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.2067  time: 0.6265  data_time: 0.1393  lr: 0.00037962  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:55:30 d2.utils.events]: \u001b[0m eta: 1:04:35  iter: 779  total_loss: 1.495  loss_cls: 0.3313  loss_box_reg: 0.5218  loss_mask: 0.3035  loss_rpn_cls: 0.07557  loss_rpn_loc: 0.2039  time: 0.6280  data_time: 0.2525  lr: 0.00038961  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:55:42 d2.utils.events]: \u001b[0m eta: 1:04:22  iter: 799  total_loss: 1.535  loss_cls: 0.3534  loss_box_reg: 0.5417  loss_mask: 0.312  loss_rpn_cls: 0.09427  loss_rpn_loc: 0.2039  time: 0.6266  data_time: 0.1644  lr: 0.0003996  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:55:54 d2.utils.events]: \u001b[0m eta: 1:04:20  iter: 819  total_loss: 1.6  loss_cls: 0.3684  loss_box_reg: 0.5636  loss_mask: 0.3141  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.2248  time: 0.6258  data_time: 0.1786  lr: 0.00040959  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:56:08 d2.utils.events]: \u001b[0m eta: 1:04:12  iter: 839  total_loss: 1.522  loss_cls: 0.3681  loss_box_reg: 0.5469  loss_mask: 0.3061  loss_rpn_cls: 0.08708  loss_rpn_loc: 0.2038  time: 0.6274  data_time: 0.2861  lr: 0.00041958  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:56:21 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 859  total_loss: 1.554  loss_cls: 0.3473  loss_box_reg: 0.586  loss_mask: 0.3067  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2156  time: 0.6285  data_time: 0.2897  lr: 0.00042957  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:56:33 d2.utils.events]: \u001b[0m eta: 1:03:42  iter: 879  total_loss: 1.441  loss_cls: 0.3443  loss_box_reg: 0.5214  loss_mask: 0.3003  loss_rpn_cls: 0.08945  loss_rpn_loc: 0.2  time: 0.6283  data_time: 0.2179  lr: 0.00043956  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:56:46 d2.utils.events]: \u001b[0m eta: 1:03:31  iter: 899  total_loss: 1.478  loss_cls: 0.3251  loss_box_reg: 0.5596  loss_mask: 0.3156  loss_rpn_cls: 0.08475  loss_rpn_loc: 0.2098  time: 0.6280  data_time: 0.2188  lr: 0.00044955  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:56:56 d2.utils.events]: \u001b[0m eta: 1:03:22  iter: 919  total_loss: 1.492  loss_cls: 0.339  loss_box_reg: 0.5507  loss_mask: 0.3061  loss_rpn_cls: 0.09961  loss_rpn_loc: 0.1961  time: 0.6259  data_time: 0.1379  lr: 0.00045954  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:57:11 d2.utils.events]: \u001b[0m eta: 1:03:14  iter: 939  total_loss: 1.572  loss_cls: 0.4214  loss_box_reg: 0.5499  loss_mask: 0.3125  loss_rpn_cls: 0.109  loss_rpn_loc: 0.215  time: 0.6283  data_time: 0.3204  lr: 0.00046953  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:57:25 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 959  total_loss: 1.601  loss_cls: 0.3762  loss_box_reg: 0.4901  loss_mask: 0.3229  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.2236  time: 0.6300  data_time: 0.2979  lr: 0.00047952  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:57:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:57:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 16:57:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 16:57:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 16:57:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 16:57:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 16:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0335 s/iter. Total: 0.1021 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 16:57:36 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0506 s/iter. Total: 0.1215 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 16:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0538 s/iter. Total: 0.1251 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 16:57:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.270391 (0.123021 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:57:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070204 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 16:57:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 16:57:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2461782350354576\n",
      "\u001b[32m[02/03 16:57:53 d2.utils.events]: \u001b[0m eta: 1:03:11  iter: 979  total_loss: 1.507  loss_cls: 0.3714  loss_box_reg: 0.5389  loss_mask: 0.3037  loss_rpn_cls: 0.101  loss_rpn_loc: 0.2114  time: 0.6290  data_time: 0.1756  lr: 0.00048951  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:58:08 d2.utils.events]: \u001b[0m eta: 1:03:04  iter: 999  total_loss: 1.523  loss_cls: 0.3537  loss_box_reg: 0.5152  loss_mask: 0.3138  loss_rpn_cls: 0.116  loss_rpn_loc: 0.2162  time: 0.6322  data_time: 0.3690  lr: 0.0004995  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:58:21 d2.utils.events]: \u001b[0m eta: 1:03:02  iter: 1019  total_loss: 1.551  loss_cls: 0.3752  loss_box_reg: 0.547  loss_mask: 0.3338  loss_rpn_cls: 0.09365  loss_rpn_loc: 0.2396  time: 0.6320  data_time: 0.2083  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:58:32 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 1039  total_loss: 1.603  loss_cls: 0.3584  loss_box_reg: 0.5521  loss_mask: 0.3303  loss_rpn_cls: 0.09246  loss_rpn_loc: 0.2243  time: 0.6307  data_time: 0.1712  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:58:49 d2.utils.events]: \u001b[0m eta: 1:02:52  iter: 1059  total_loss: 1.534  loss_cls: 0.3618  loss_box_reg: 0.5145  loss_mask: 0.3034  loss_rpn_cls: 0.106  loss_rpn_loc: 0.2161  time: 0.6350  data_time: 0.4404  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:59:01 d2.utils.events]: \u001b[0m eta: 1:02:43  iter: 1079  total_loss: 1.617  loss_cls: 0.3863  loss_box_reg: 0.5471  loss_mask: 0.3076  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.2091  time: 0.6338  data_time: 0.1643  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:59:15 d2.utils.events]: \u001b[0m eta: 1:02:41  iter: 1099  total_loss: 1.512  loss_cls: 0.3607  loss_box_reg: 0.5485  loss_mask: 0.2992  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.2161  time: 0.6350  data_time: 0.2902  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:59:27 d2.utils.events]: \u001b[0m eta: 1:02:33  iter: 1119  total_loss: 1.459  loss_cls: 0.3318  loss_box_reg: 0.5408  loss_mask: 0.3053  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.1947  time: 0.6345  data_time: 0.1994  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:59:39 d2.utils.events]: \u001b[0m eta: 1:02:24  iter: 1139  total_loss: 1.518  loss_cls: 0.3386  loss_box_reg: 0.5368  loss_mask: 0.2935  loss_rpn_cls: 0.0984  loss_rpn_loc: 0.195  time: 0.6337  data_time: 0.1875  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 16:59:48 d2.utils.events]: \u001b[0m eta: 1:02:05  iter: 1159  total_loss: 1.552  loss_cls: 0.3692  loss_box_reg: 0.5583  loss_mask: 0.3142  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.2001  time: 0.6307  data_time: 0.0849  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:00:00 d2.utils.events]: \u001b[0m eta: 1:01:59  iter: 1179  total_loss: 1.463  loss_cls: 0.3771  loss_box_reg: 0.5373  loss_mask: 0.2849  loss_rpn_cls: 0.08553  loss_rpn_loc: 0.2036  time: 0.6306  data_time: 0.2054  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:00:10 d2.utils.events]: \u001b[0m eta: 1:01:42  iter: 1199  total_loss: 1.341  loss_cls: 0.2973  loss_box_reg: 0.5246  loss_mask: 0.2982  loss_rpn_cls: 0.06861  loss_rpn_loc: 0.172  time: 0.6280  data_time: 0.0915  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:00:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:00:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:00:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:00:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:00:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:00:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0674 s/iter. Eval: 0.0313 s/iter. Total: 0.0993 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 17:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0701 s/iter. Eval: 0.0504 s/iter. Total: 0.1212 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0547 s/iter. Total: 0.1261 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 17:00:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.418799 (0.124300 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:00:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070344 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:00:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:00:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2518109210352617\n",
      "\u001b[32m[02/03 17:00:39 d2.utils.events]: \u001b[0m eta: 1:01:34  iter: 1219  total_loss: 1.506  loss_cls: 0.3394  loss_box_reg: 0.5266  loss_mask: 0.3045  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.2079  time: 0.6287  data_time: 0.2723  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:00:52 d2.utils.events]: \u001b[0m eta: 1:01:25  iter: 1239  total_loss: 1.423  loss_cls: 0.3084  loss_box_reg: 0.5178  loss_mask: 0.2979  loss_rpn_cls: 0.09679  loss_rpn_loc: 0.2006  time: 0.6293  data_time: 0.2635  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:01:06 d2.utils.events]: \u001b[0m eta: 1:01:21  iter: 1259  total_loss: 1.45  loss_cls: 0.3318  loss_box_reg: 0.5383  loss_mask: 0.2984  loss_rpn_cls: 0.09243  loss_rpn_loc: 0.1936  time: 0.6301  data_time: 0.2815  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:01:19 d2.utils.events]: \u001b[0m eta: 1:01:15  iter: 1279  total_loss: 1.502  loss_cls: 0.3603  loss_box_reg: 0.5354  loss_mask: 0.3178  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.2106  time: 0.6303  data_time: 0.2390  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:01:31 d2.utils.events]: \u001b[0m eta: 1:01:09  iter: 1299  total_loss: 1.555  loss_cls: 0.3535  loss_box_reg: 0.541  loss_mask: 0.3087  loss_rpn_cls: 0.08892  loss_rpn_loc: 0.1946  time: 0.6302  data_time: 0.2133  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:01:44 d2.utils.events]: \u001b[0m eta: 1:01:02  iter: 1319  total_loss: 1.52  loss_cls: 0.3469  loss_box_reg: 0.5321  loss_mask: 0.3056  loss_rpn_cls: 0.08316  loss_rpn_loc: 0.2014  time: 0.6303  data_time: 0.2379  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:01:55 d2.utils.events]: \u001b[0m eta: 1:00:51  iter: 1339  total_loss: 1.443  loss_cls: 0.3635  loss_box_reg: 0.513  loss_mask: 0.2992  loss_rpn_cls: 0.09078  loss_rpn_loc: 0.2159  time: 0.6292  data_time: 0.1640  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:02:08 d2.utils.events]: \u001b[0m eta: 1:00:40  iter: 1359  total_loss: 1.509  loss_cls: 0.3587  loss_box_reg: 0.5329  loss_mask: 0.3002  loss_rpn_cls: 0.08859  loss_rpn_loc: 0.2104  time: 0.6293  data_time: 0.2394  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:02:20 d2.utils.events]: \u001b[0m eta: 1:00:30  iter: 1379  total_loss: 1.546  loss_cls: 0.3782  loss_box_reg: 0.5573  loss_mask: 0.2976  loss_rpn_cls: 0.08983  loss_rpn_loc: 0.2229  time: 0.6291  data_time: 0.2171  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:02:31 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 1399  total_loss: 1.542  loss_cls: 0.3827  loss_box_reg: 0.5438  loss_mask: 0.3014  loss_rpn_cls: 0.09999  loss_rpn_loc: 0.2131  time: 0.6278  data_time: 0.1395  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:02:42 d2.utils.events]: \u001b[0m eta: 1:00:05  iter: 1419  total_loss: 1.505  loss_cls: 0.3563  loss_box_reg: 0.523  loss_mask: 0.3035  loss_rpn_cls: 0.09333  loss_rpn_loc: 0.2134  time: 0.6265  data_time: 0.1413  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:02:55 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 1439  total_loss: 1.464  loss_cls: 0.339  loss_box_reg: 0.5193  loss_mask: 0.2984  loss_rpn_cls: 0.08465  loss_rpn_loc: 0.2187  time: 0.6272  data_time: 0.2797  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:03:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:03:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:03:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:03:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:03:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:03:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0684 s/iter. Eval: 0.0385 s/iter. Total: 0.1075 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:03:11 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0536 s/iter. Total: 0.1249 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0709 s/iter. Eval: 0.0567 s/iter. Total: 0.1284 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:03:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.743929 (0.127103 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:03:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070680 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:03:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:03:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25719160206218417\n",
      "\u001b[32m[02/03 17:03:25 d2.utils.events]: \u001b[0m eta: 0:59:53  iter: 1459  total_loss: 1.54  loss_cls: 0.324  loss_box_reg: 0.5105  loss_mask: 0.3156  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.2029  time: 0.6281  data_time: 0.2842  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:03:39 d2.utils.events]: \u001b[0m eta: 0:59:48  iter: 1479  total_loss: 1.528  loss_cls: 0.3578  loss_box_reg: 0.5403  loss_mask: 0.3087  loss_rpn_cls: 0.07943  loss_rpn_loc: 0.2132  time: 0.6288  data_time: 0.2621  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:03:49 d2.utils.events]: \u001b[0m eta: 0:59:38  iter: 1499  total_loss: 1.464  loss_cls: 0.2997  loss_box_reg: 0.5196  loss_mask: 0.3129  loss_rpn_cls: 0.08709  loss_rpn_loc: 0.2138  time: 0.6273  data_time: 0.1281  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:04:00 d2.utils.events]: \u001b[0m eta: 0:59:28  iter: 1519  total_loss: 1.532  loss_cls: 0.3567  loss_box_reg: 0.5379  loss_mask: 0.3067  loss_rpn_cls: 0.08152  loss_rpn_loc: 0.2018  time: 0.6262  data_time: 0.1312  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:04:10 d2.utils.events]: \u001b[0m eta: 0:59:16  iter: 1539  total_loss: 1.419  loss_cls: 0.3489  loss_box_reg: 0.5309  loss_mask: 0.288  loss_rpn_cls: 0.07543  loss_rpn_loc: 0.183  time: 0.6245  data_time: 0.0949  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:04:25 d2.utils.events]: \u001b[0m eta: 0:59:13  iter: 1559  total_loss: 1.556  loss_cls: 0.3661  loss_box_reg: 0.5185  loss_mask: 0.3012  loss_rpn_cls: 0.09326  loss_rpn_loc: 0.1951  time: 0.6260  data_time: 0.3174  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:04:40 d2.utils.events]: \u001b[0m eta: 0:59:05  iter: 1579  total_loss: 1.443  loss_cls: 0.3386  loss_box_reg: 0.493  loss_mask: 0.2952  loss_rpn_cls: 0.09553  loss_rpn_loc: 0.202  time: 0.6278  data_time: 0.3485  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:04:52 d2.utils.events]: \u001b[0m eta: 0:58:55  iter: 1599  total_loss: 1.374  loss_cls: 0.318  loss_box_reg: 0.5319  loss_mask: 0.308  loss_rpn_cls: 0.06635  loss_rpn_loc: 0.1957  time: 0.6273  data_time: 0.1792  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:05:04 d2.utils.events]: \u001b[0m eta: 0:58:48  iter: 1619  total_loss: 1.409  loss_cls: 0.3183  loss_box_reg: 0.5048  loss_mask: 0.296  loss_rpn_cls: 0.07564  loss_rpn_loc: 0.188  time: 0.6269  data_time: 0.2006  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:05:16 d2.utils.events]: \u001b[0m eta: 0:58:33  iter: 1639  total_loss: 1.356  loss_cls: 0.302  loss_box_reg: 0.5233  loss_mask: 0.3064  loss_rpn_cls: 0.06446  loss_rpn_loc: 0.1917  time: 0.6265  data_time: 0.1949  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:05:27 d2.utils.events]: \u001b[0m eta: 0:58:38  iter: 1659  total_loss: 1.593  loss_cls: 0.3921  loss_box_reg: 0.5303  loss_mask: 0.2947  loss_rpn_cls: 0.09218  loss_rpn_loc: 0.1956  time: 0.6259  data_time: 0.1482  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:05:41 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 1679  total_loss: 1.501  loss_cls: 0.3398  loss_box_reg: 0.5296  loss_mask: 0.2915  loss_rpn_cls: 0.0941  loss_rpn_loc: 0.2039  time: 0.6268  data_time: 0.2864  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:05:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:05:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:05:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:05:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:05:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:05:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:05:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0355 s/iter. Total: 0.1040 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:05:58 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.0516 s/iter. Total: 0.1226 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:06:03 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.0538 s/iter. Total: 0.1252 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/03 17:06:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.331489 (0.123547 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:06:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070329 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:06:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:06:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2540609616381369\n",
      "\u001b[32m[02/03 17:06:11 d2.utils.events]: \u001b[0m eta: 0:58:22  iter: 1699  total_loss: 1.482  loss_cls: 0.3489  loss_box_reg: 0.535  loss_mask: 0.2979  loss_rpn_cls: 0.08871  loss_rpn_loc: 0.2096  time: 0.6276  data_time: 0.2834  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:06:23 d2.utils.events]: \u001b[0m eta: 0:58:12  iter: 1719  total_loss: 1.446  loss_cls: 0.3184  loss_box_reg: 0.5131  loss_mask: 0.2956  loss_rpn_cls: 0.07755  loss_rpn_loc: 0.2018  time: 0.6272  data_time: 0.1849  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:06:34 d2.utils.events]: \u001b[0m eta: 0:58:04  iter: 1739  total_loss: 1.425  loss_cls: 0.3168  loss_box_reg: 0.514  loss_mask: 0.308  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.1834  time: 0.6264  data_time: 0.1572  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:06:46 d2.utils.events]: \u001b[0m eta: 0:57:55  iter: 1759  total_loss: 1.52  loss_cls: 0.3776  loss_box_reg: 0.5232  loss_mask: 0.3095  loss_rpn_cls: 0.086  loss_rpn_loc: 0.2083  time: 0.6260  data_time: 0.1904  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:06:57 d2.utils.events]: \u001b[0m eta: 0:57:38  iter: 1779  total_loss: 1.549  loss_cls: 0.3657  loss_box_reg: 0.568  loss_mask: 0.3159  loss_rpn_cls: 0.07349  loss_rpn_loc: 0.2022  time: 0.6250  data_time: 0.1243  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:07:10 d2.utils.events]: \u001b[0m eta: 0:57:35  iter: 1799  total_loss: 1.41  loss_cls: 0.3201  loss_box_reg: 0.5023  loss_mask: 0.2933  loss_rpn_cls: 0.09054  loss_rpn_loc: 0.2102  time: 0.6257  data_time: 0.2927  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:07:22 d2.utils.events]: \u001b[0m eta: 0:57:21  iter: 1819  total_loss: 1.512  loss_cls: 0.3649  loss_box_reg: 0.5294  loss_mask: 0.3026  loss_rpn_cls: 0.08522  loss_rpn_loc: 0.2203  time: 0.6253  data_time: 0.1990  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:07:36 d2.utils.events]: \u001b[0m eta: 0:57:14  iter: 1839  total_loss: 1.513  loss_cls: 0.364  loss_box_reg: 0.5149  loss_mask: 0.2945  loss_rpn_cls: 0.08623  loss_rpn_loc: 0.2192  time: 0.6258  data_time: 0.2531  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:07:47 d2.utils.events]: \u001b[0m eta: 0:57:04  iter: 1859  total_loss: 1.449  loss_cls: 0.3383  loss_box_reg: 0.5303  loss_mask: 0.2975  loss_rpn_cls: 0.07235  loss_rpn_loc: 0.1938  time: 0.6251  data_time: 0.1656  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:07:57 d2.utils.events]: \u001b[0m eta: 0:56:53  iter: 1879  total_loss: 1.431  loss_cls: 0.3272  loss_box_reg: 0.534  loss_mask: 0.3068  loss_rpn_cls: 0.06386  loss_rpn_loc: 0.1942  time: 0.6237  data_time: 0.1030  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:08:10 d2.utils.events]: \u001b[0m eta: 0:56:53  iter: 1899  total_loss: 1.584  loss_cls: 0.3893  loss_box_reg: 0.519  loss_mask: 0.3136  loss_rpn_cls: 0.09099  loss_rpn_loc: 0.217  time: 0.6241  data_time: 0.2520  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:08:26 d2.utils.events]: \u001b[0m eta: 0:56:50  iter: 1919  total_loss: 1.487  loss_cls: 0.3432  loss_box_reg: 0.5087  loss_mask: 0.3075  loss_rpn_cls: 0.08621  loss_rpn_loc: 0.2051  time: 0.6259  data_time: 0.3685  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:08:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:08:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:08:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:08:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:08:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:08:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.0305 s/iter. Total: 0.0994 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 17:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0715 s/iter. Eval: 0.0510 s/iter. Total: 0.1233 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0719 s/iter. Eval: 0.0546 s/iter. Total: 0.1272 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:08:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.562478 (0.125539 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:08:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071294 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:08:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:08:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2512886267799331\n",
      "\u001b[32m[02/03 17:08:53 d2.utils.events]: \u001b[0m eta: 0:56:43  iter: 1939  total_loss: 1.405  loss_cls: 0.3357  loss_box_reg: 0.5178  loss_mask: 0.3035  loss_rpn_cls: 0.0832  loss_rpn_loc: 0.1943  time: 0.6253  data_time: 0.1609  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:09:05 d2.utils.events]: \u001b[0m eta: 0:56:27  iter: 1959  total_loss: 1.469  loss_cls: 0.3285  loss_box_reg: 0.5166  loss_mask: 0.3021  loss_rpn_cls: 0.06677  loss_rpn_loc: 0.2011  time: 0.6248  data_time: 0.1797  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:09:18 d2.utils.events]: \u001b[0m eta: 0:56:20  iter: 1979  total_loss: 1.385  loss_cls: 0.3322  loss_box_reg: 0.5244  loss_mask: 0.2907  loss_rpn_cls: 0.09317  loss_rpn_loc: 0.1939  time: 0.6251  data_time: 0.2538  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:09:30 d2.utils.events]: \u001b[0m eta: 0:56:09  iter: 1999  total_loss: 1.461  loss_cls: 0.3632  loss_box_reg: 0.5398  loss_mask: 0.3105  loss_rpn_cls: 0.09483  loss_rpn_loc: 0.2003  time: 0.6246  data_time: 0.1823  lr: 0.0005  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:09:43 d2.utils.events]: \u001b[0m eta: 0:56:01  iter: 2019  total_loss: 1.415  loss_cls: 0.3095  loss_box_reg: 0.5335  loss_mask: 0.3007  loss_rpn_cls: 0.08085  loss_rpn_loc: 0.1958  time: 0.6250  data_time: 0.2537  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:09:54 d2.utils.events]: \u001b[0m eta: 0:55:51  iter: 2039  total_loss: 1.44  loss_cls: 0.3551  loss_box_reg: 0.5344  loss_mask: 0.2973  loss_rpn_cls: 0.07003  loss_rpn_loc: 0.185  time: 0.6245  data_time: 0.1782  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:10:07 d2.utils.events]: \u001b[0m eta: 0:55:33  iter: 2059  total_loss: 1.401  loss_cls: 0.3251  loss_box_reg: 0.5194  loss_mask: 0.3049  loss_rpn_cls: 0.06567  loss_rpn_loc: 0.1956  time: 0.6246  data_time: 0.2317  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:10:21 d2.utils.events]: \u001b[0m eta: 0:55:32  iter: 2079  total_loss: 1.523  loss_cls: 0.3615  loss_box_reg: 0.531  loss_mask: 0.312  loss_rpn_cls: 0.08953  loss_rpn_loc: 0.2087  time: 0.6251  data_time: 0.2533  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:10:38 d2.utils.events]: \u001b[0m eta: 0:55:28  iter: 2099  total_loss: 1.435  loss_cls: 0.3392  loss_box_reg: 0.4918  loss_mask: 0.3032  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2151  time: 0.6276  data_time: 0.4614  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:10:51 d2.utils.events]: \u001b[0m eta: 0:55:23  iter: 2119  total_loss: 1.351  loss_cls: 0.2841  loss_box_reg: 0.4781  loss_mask: 0.3022  loss_rpn_cls: 0.08666  loss_rpn_loc: 0.1966  time: 0.6275  data_time: 0.2029  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:11:00 d2.utils.events]: \u001b[0m eta: 0:55:11  iter: 2139  total_loss: 1.49  loss_cls: 0.352  loss_box_reg: 0.5218  loss_mask: 0.3021  loss_rpn_cls: 0.09154  loss_rpn_loc: 0.2047  time: 0.6261  data_time: 0.0829  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:11:12 d2.utils.events]: \u001b[0m eta: 0:55:11  iter: 2159  total_loss: 1.397  loss_cls: 0.3044  loss_box_reg: 0.5212  loss_mask: 0.3078  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.201  time: 0.6259  data_time: 0.2093  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:11:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:11:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:11:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:11:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:11:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:11:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:11:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0727 s/iter. Eval: 0.0352 s/iter. Total: 0.1085 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0743 s/iter. Eval: 0.0548 s/iter. Total: 0.1299 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0741 s/iter. Eval: 0.0582 s/iter. Total: 0.1332 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:11:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.315248 (0.132028 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:11:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074170 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:11:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:11:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2618722098312322\n",
      "\u001b[32m[02/03 17:11:39 d2.utils.events]: \u001b[0m eta: 0:54:54  iter: 2179  total_loss: 1.348  loss_cls: 0.3433  loss_box_reg: 0.5218  loss_mask: 0.3072  loss_rpn_cls: 0.07112  loss_rpn_loc: 0.1807  time: 0.6249  data_time: 0.1161  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:11:51 d2.utils.events]: \u001b[0m eta: 0:54:54  iter: 2199  total_loss: 1.496  loss_cls: 0.3572  loss_box_reg: 0.5258  loss_mask: 0.3048  loss_rpn_cls: 0.08776  loss_rpn_loc: 0.21  time: 0.6246  data_time: 0.1772  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:12:07 d2.utils.events]: \u001b[0m eta: 0:54:50  iter: 2219  total_loss: 1.424  loss_cls: 0.3296  loss_box_reg: 0.5159  loss_mask: 0.3147  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.2076  time: 0.6260  data_time: 0.3551  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:12:19 d2.utils.events]: \u001b[0m eta: 0:54:47  iter: 2239  total_loss: 1.317  loss_cls: 0.31  loss_box_reg: 0.491  loss_mask: 0.3038  loss_rpn_cls: 0.06117  loss_rpn_loc: 0.1871  time: 0.6260  data_time: 0.2223  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:12:32 d2.utils.events]: \u001b[0m eta: 0:54:35  iter: 2259  total_loss: 1.443  loss_cls: 0.3413  loss_box_reg: 0.5198  loss_mask: 0.3044  loss_rpn_cls: 0.07949  loss_rpn_loc: 0.1763  time: 0.6260  data_time: 0.2226  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:12:47 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 2279  total_loss: 1.491  loss_cls: 0.3321  loss_box_reg: 0.5071  loss_mask: 0.3136  loss_rpn_cls: 0.09444  loss_rpn_loc: 0.211  time: 0.6272  data_time: 0.3507  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:12:56 d2.utils.events]: \u001b[0m eta: 0:54:12  iter: 2299  total_loss: 1.391  loss_cls: 0.3171  loss_box_reg: 0.5128  loss_mask: 0.2934  loss_rpn_cls: 0.06131  loss_rpn_loc: 0.1724  time: 0.6254  data_time: 0.0403  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:13:07 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 2319  total_loss: 1.482  loss_cls: 0.3372  loss_box_reg: 0.5287  loss_mask: 0.2925  loss_rpn_cls: 0.08605  loss_rpn_loc: 0.1979  time: 0.6251  data_time: 0.1852  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:13:24 d2.utils.events]: \u001b[0m eta: 0:54:00  iter: 2339  total_loss: 1.498  loss_cls: 0.3619  loss_box_reg: 0.5071  loss_mask: 0.3016  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.1989  time: 0.6269  data_time: 0.4102  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:13:36 d2.utils.events]: \u001b[0m eta: 0:53:58  iter: 2359  total_loss: 1.381  loss_cls: 0.3409  loss_box_reg: 0.5015  loss_mask: 0.2913  loss_rpn_cls: 0.08705  loss_rpn_loc: 0.1726  time: 0.6267  data_time: 0.1926  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:13:50 d2.utils.events]: \u001b[0m eta: 0:53:55  iter: 2379  total_loss: 1.446  loss_cls: 0.3031  loss_box_reg: 0.5011  loss_mask: 0.2984  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.21  time: 0.6270  data_time: 0.2528  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:14:00 d2.utils.events]: \u001b[0m eta: 0:53:46  iter: 2399  total_loss: 1.362  loss_cls: 0.2939  loss_box_reg: 0.5149  loss_mask: 0.2988  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.1923  time: 0.6263  data_time: 0.1405  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:14:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:14:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:14:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:14:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:14:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:14:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0360 s/iter. Total: 0.1046 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:14:20 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0727 s/iter. Eval: 0.0562 s/iter. Total: 0.1296 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:14:25 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0730 s/iter. Eval: 0.0602 s/iter. Total: 0.1341 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:14:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.221227 (0.131217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:14:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072219 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:14:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:14:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2622191347947404\n",
      "\u001b[32m[02/03 17:14:30 d2.utils.events]: \u001b[0m eta: 0:53:38  iter: 2419  total_loss: 1.401  loss_cls: 0.2919  loss_box_reg: 0.5125  loss_mask: 0.3049  loss_rpn_cls: 0.09445  loss_rpn_loc: 0.21  time: 0.6263  data_time: 0.2185  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:14:40 d2.utils.events]: \u001b[0m eta: 0:53:29  iter: 2439  total_loss: 1.417  loss_cls: 0.3268  loss_box_reg: 0.528  loss_mask: 0.3047  loss_rpn_cls: 0.08053  loss_rpn_loc: 0.1821  time: 0.6255  data_time: 0.1275  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:14:54 d2.utils.events]: \u001b[0m eta: 0:53:21  iter: 2459  total_loss: 1.416  loss_cls: 0.3641  loss_box_reg: 0.4955  loss_mask: 0.3128  loss_rpn_cls: 0.09252  loss_rpn_loc: 0.1927  time: 0.6262  data_time: 0.2804  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:15:08 d2.utils.events]: \u001b[0m eta: 0:53:13  iter: 2479  total_loss: 1.406  loss_cls: 0.3558  loss_box_reg: 0.5144  loss_mask: 0.301  loss_rpn_cls: 0.08101  loss_rpn_loc: 0.1996  time: 0.6266  data_time: 0.2687  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:15:20 d2.utils.events]: \u001b[0m eta: 0:53:06  iter: 2499  total_loss: 1.516  loss_cls: 0.3721  loss_box_reg: 0.5199  loss_mask: 0.2939  loss_rpn_cls: 0.09911  loss_rpn_loc: 0.2162  time: 0.6263  data_time: 0.1726  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:15:33 d2.utils.events]: \u001b[0m eta: 0:52:58  iter: 2519  total_loss: 1.475  loss_cls: 0.3343  loss_box_reg: 0.5115  loss_mask: 0.3118  loss_rpn_cls: 0.08461  loss_rpn_loc: 0.2137  time: 0.6267  data_time: 0.2711  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:15:45 d2.utils.events]: \u001b[0m eta: 0:52:50  iter: 2539  total_loss: 1.418  loss_cls: 0.3178  loss_box_reg: 0.5262  loss_mask: 0.3145  loss_rpn_cls: 0.06974  loss_rpn_loc: 0.1808  time: 0.6265  data_time: 0.1896  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:15:57 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 2559  total_loss: 1.473  loss_cls: 0.3289  loss_box_reg: 0.5125  loss_mask: 0.2985  loss_rpn_cls: 0.0831  loss_rpn_loc: 0.2019  time: 0.6263  data_time: 0.2007  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:16:10 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 2579  total_loss: 1.356  loss_cls: 0.2955  loss_box_reg: 0.4759  loss_mask: 0.2991  loss_rpn_cls: 0.06396  loss_rpn_loc: 0.2027  time: 0.6264  data_time: 0.2353  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:16:22 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 2599  total_loss: 1.43  loss_cls: 0.3411  loss_box_reg: 0.4902  loss_mask: 0.3162  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.2203  time: 0.6260  data_time: 0.1890  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:16:32 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 2619  total_loss: 1.413  loss_cls: 0.2943  loss_box_reg: 0.5173  loss_mask: 0.3  loss_rpn_cls: 0.07681  loss_rpn_loc: 0.2024  time: 0.6253  data_time: 0.1410  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:16:44 d2.utils.events]: \u001b[0m eta: 0:52:04  iter: 2639  total_loss: 1.353  loss_cls: 0.2775  loss_box_reg: 0.5212  loss_mask: 0.2928  loss_rpn_cls: 0.0571  loss_rpn_loc: 0.1847  time: 0.6252  data_time: 0.2208  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:16:57 d2.utils.events]: \u001b[0m eta: 0:51:43  iter: 2659  total_loss: 1.424  loss_cls: 0.3115  loss_box_reg: 0.5085  loss_mask: 0.2868  loss_rpn_cls: 0.08695  loss_rpn_loc: 0.2211  time: 0.6253  data_time: 0.2456  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:16:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:16:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:16:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:16:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:16:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:16:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:17:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0676 s/iter. Eval: 0.0347 s/iter. Total: 0.1029 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:17:05 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0707 s/iter. Eval: 0.0541 s/iter. Total: 0.1256 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0715 s/iter. Eval: 0.0579 s/iter. Total: 0.1302 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:17:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.019850 (0.129481 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:17:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071344 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:17:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:17:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.261671836501449\n",
      "\u001b[32m[02/03 17:17:26 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 2679  total_loss: 1.309  loss_cls: 0.3281  loss_box_reg: 0.5013  loss_mask: 0.2792  loss_rpn_cls: 0.07025  loss_rpn_loc: 0.1847  time: 0.6250  data_time: 0.1572  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:17:37 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 2699  total_loss: 1.48  loss_cls: 0.3189  loss_box_reg: 0.5199  loss_mask: 0.3193  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.1913  time: 0.6245  data_time: 0.1601  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:17:49 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 2719  total_loss: 1.414  loss_cls: 0.3045  loss_box_reg: 0.5098  loss_mask: 0.3026  loss_rpn_cls: 0.07357  loss_rpn_loc: 0.1975  time: 0.6242  data_time: 0.1931  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:18:02 d2.utils.events]: \u001b[0m eta: 0:51:12  iter: 2739  total_loss: 1.477  loss_cls: 0.3664  loss_box_reg: 0.5334  loss_mask: 0.2957  loss_rpn_cls: 0.09099  loss_rpn_loc: 0.2127  time: 0.6244  data_time: 0.2103  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:18:16 d2.utils.events]: \u001b[0m eta: 0:51:09  iter: 2759  total_loss: 1.33  loss_cls: 0.274  loss_box_reg: 0.485  loss_mask: 0.2978  loss_rpn_cls: 0.06702  loss_rpn_loc: 0.1754  time: 0.6251  data_time: 0.2912  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:18:31 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 2779  total_loss: 1.391  loss_cls: 0.3279  loss_box_reg: 0.5207  loss_mask: 0.3084  loss_rpn_cls: 0.0844  loss_rpn_loc: 0.199  time: 0.6260  data_time: 0.3224  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:18:44 d2.utils.events]: \u001b[0m eta: 0:51:07  iter: 2799  total_loss: 1.479  loss_cls: 0.337  loss_box_reg: 0.5137  loss_mask: 0.303  loss_rpn_cls: 0.1113  loss_rpn_loc: 0.1966  time: 0.6264  data_time: 0.2404  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:18:57 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 2819  total_loss: 1.467  loss_cls: 0.3649  loss_box_reg: 0.5059  loss_mask: 0.3031  loss_rpn_cls: 0.06837  loss_rpn_loc: 0.1963  time: 0.6263  data_time: 0.1962  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:19:09 d2.utils.events]: \u001b[0m eta: 0:50:56  iter: 2839  total_loss: 1.388  loss_cls: 0.3108  loss_box_reg: 0.5034  loss_mask: 0.3057  loss_rpn_cls: 0.07083  loss_rpn_loc: 0.1832  time: 0.6260  data_time: 0.1731  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:19:22 d2.utils.events]: \u001b[0m eta: 0:50:51  iter: 2859  total_loss: 1.46  loss_cls: 0.338  loss_box_reg: 0.5237  loss_mask: 0.3035  loss_rpn_cls: 0.08336  loss_rpn_loc: 0.2113  time: 0.6264  data_time: 0.2846  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:19:34 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 2879  total_loss: 1.443  loss_cls: 0.3339  loss_box_reg: 0.5209  loss_mask: 0.3161  loss_rpn_cls: 0.08333  loss_rpn_loc: 0.201  time: 0.6263  data_time: 0.1966  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:19:48 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 2899  total_loss: 1.385  loss_cls: 0.3234  loss_box_reg: 0.5025  loss_mask: 0.3026  loss_rpn_cls: 0.08293  loss_rpn_loc: 0.1981  time: 0.6266  data_time: 0.2651  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:19:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:19:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:19:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:19:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:19:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:19:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0743 s/iter. Eval: 0.0394 s/iter. Total: 0.1144 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 17:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0770 s/iter. Eval: 0.0566 s/iter. Total: 0.1345 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0775 s/iter. Eval: 0.0603 s/iter. Total: 0.1386 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 17:20:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.804520 (0.136246 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:20:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077135 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:20:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:20:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2590543588602275\n",
      "\u001b[32m[02/03 17:20:18 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 2919  total_loss: 1.498  loss_cls: 0.3487  loss_box_reg: 0.5459  loss_mask: 0.2977  loss_rpn_cls: 0.08352  loss_rpn_loc: 0.198  time: 0.6268  data_time: 0.2013  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:20:32 d2.utils.events]: \u001b[0m eta: 0:50:21  iter: 2939  total_loss: 1.403  loss_cls: 0.3134  loss_box_reg: 0.512  loss_mask: 0.3124  loss_rpn_cls: 0.07636  loss_rpn_loc: 0.2105  time: 0.6271  data_time: 0.2393  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:20:46 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 2959  total_loss: 1.479  loss_cls: 0.3224  loss_box_reg: 0.5108  loss_mask: 0.3092  loss_rpn_cls: 0.09023  loss_rpn_loc: 0.2109  time: 0.6276  data_time: 0.2670  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:20:59 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 2979  total_loss: 1.366  loss_cls: 0.2996  loss_box_reg: 0.5137  loss_mask: 0.2976  loss_rpn_cls: 0.08086  loss_rpn_loc: 0.2022  time: 0.6279  data_time: 0.2312  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:21:12 d2.utils.events]: \u001b[0m eta: 0:50:19  iter: 2999  total_loss: 1.432  loss_cls: 0.3684  loss_box_reg: 0.4798  loss_mask: 0.2838  loss_rpn_cls: 0.09818  loss_rpn_loc: 0.2142  time: 0.6280  data_time: 0.1999  lr: 0.0004  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:21:25 d2.utils.events]: \u001b[0m eta: 0:50:15  iter: 3019  total_loss: 1.463  loss_cls: 0.3311  loss_box_reg: 0.4902  loss_mask: 0.3037  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.1866  time: 0.6280  data_time: 0.1740  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:21:36 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 3039  total_loss: 1.42  loss_cls: 0.3169  loss_box_reg: 0.5277  loss_mask: 0.3046  loss_rpn_cls: 0.07725  loss_rpn_loc: 0.1782  time: 0.6276  data_time: 0.1407  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:21:47 d2.utils.events]: \u001b[0m eta: 0:50:03  iter: 3059  total_loss: 1.476  loss_cls: 0.3144  loss_box_reg: 0.5243  loss_mask: 0.2957  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.1839  time: 0.6272  data_time: 0.1257  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:22:01 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 3079  total_loss: 1.335  loss_cls: 0.2857  loss_box_reg: 0.4928  loss_mask: 0.2966  loss_rpn_cls: 0.07903  loss_rpn_loc: 0.1867  time: 0.6277  data_time: 0.2687  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:22:14 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 3099  total_loss: 1.42  loss_cls: 0.3477  loss_box_reg: 0.4941  loss_mask: 0.2912  loss_rpn_cls: 0.08573  loss_rpn_loc: 0.1828  time: 0.6276  data_time: 0.1709  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:22:30 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 3119  total_loss: 1.46  loss_cls: 0.3436  loss_box_reg: 0.505  loss_mask: 0.3056  loss_rpn_cls: 0.08226  loss_rpn_loc: 0.2162  time: 0.6289  data_time: 0.3844  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:22:46 d2.utils.events]: \u001b[0m eta: 0:49:54  iter: 3139  total_loss: 1.406  loss_cls: 0.3311  loss_box_reg: 0.5136  loss_mask: 0.3032  loss_rpn_cls: 0.09596  loss_rpn_loc: 0.2014  time: 0.6300  data_time: 0.3361  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:22:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:22:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:22:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:22:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:22:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:22:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0742 s/iter. Eval: 0.0358 s/iter. Total: 0.1107 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 17:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0772 s/iter. Eval: 0.0560 s/iter. Total: 0.1340 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0773 s/iter. Eval: 0.0591 s/iter. Total: 0.1372 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 17:23:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.684779 (0.135214 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:23:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076948 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:23:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:23:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26030986446716564\n",
      "\u001b[32m[02/03 17:23:16 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 3159  total_loss: 1.334  loss_cls: 0.3117  loss_box_reg: 0.5031  loss_mask: 0.2923  loss_rpn_cls: 0.06971  loss_rpn_loc: 0.181  time: 0.6299  data_time: 0.1901  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:23:30 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 3179  total_loss: 1.337  loss_cls: 0.2834  loss_box_reg: 0.4857  loss_mask: 0.3032  loss_rpn_cls: 0.06474  loss_rpn_loc: 0.1893  time: 0.6302  data_time: 0.2331  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:23:45 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 3199  total_loss: 1.431  loss_cls: 0.3285  loss_box_reg: 0.5007  loss_mask: 0.2944  loss_rpn_cls: 0.06056  loss_rpn_loc: 0.1629  time: 0.6310  data_time: 0.3015  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:24:00 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 3219  total_loss: 1.382  loss_cls: 0.3011  loss_box_reg: 0.5106  loss_mask: 0.3071  loss_rpn_cls: 0.09516  loss_rpn_loc: 0.2115  time: 0.6319  data_time: 0.3256  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:24:14 d2.utils.events]: \u001b[0m eta: 0:49:43  iter: 3239  total_loss: 1.397  loss_cls: 0.3597  loss_box_reg: 0.51  loss_mask: 0.2979  loss_rpn_cls: 0.08025  loss_rpn_loc: 0.2052  time: 0.6321  data_time: 0.2202  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:24:26 d2.utils.events]: \u001b[0m eta: 0:49:39  iter: 3259  total_loss: 1.426  loss_cls: 0.3191  loss_box_reg: 0.4997  loss_mask: 0.3054  loss_rpn_cls: 0.09205  loss_rpn_loc: 0.1834  time: 0.6322  data_time: 0.2140  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:24:40 d2.utils.events]: \u001b[0m eta: 0:49:31  iter: 3279  total_loss: 1.497  loss_cls: 0.3533  loss_box_reg: 0.4898  loss_mask: 0.2975  loss_rpn_cls: 0.08725  loss_rpn_loc: 0.2089  time: 0.6324  data_time: 0.2342  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:24:49 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 3299  total_loss: 1.501  loss_cls: 0.3242  loss_box_reg: 0.538  loss_mask: 0.3023  loss_rpn_cls: 0.08102  loss_rpn_loc: 0.1889  time: 0.6315  data_time: 0.0974  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:25:02 d2.utils.events]: \u001b[0m eta: 0:49:16  iter: 3319  total_loss: 1.448  loss_cls: 0.3353  loss_box_reg: 0.5006  loss_mask: 0.3129  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.2042  time: 0.6315  data_time: 0.2219  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:25:15 d2.utils.events]: \u001b[0m eta: 0:49:05  iter: 3339  total_loss: 1.442  loss_cls: 0.3385  loss_box_reg: 0.4967  loss_mask: 0.2887  loss_rpn_cls: 0.06959  loss_rpn_loc: 0.1856  time: 0.6316  data_time: 0.2243  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:25:26 d2.utils.events]: \u001b[0m eta: 0:48:55  iter: 3359  total_loss: 1.336  loss_cls: 0.2791  loss_box_reg: 0.5069  loss_mask: 0.3111  loss_rpn_cls: 0.05613  loss_rpn_loc: 0.1865  time: 0.6310  data_time: 0.1343  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:25:36 d2.utils.events]: \u001b[0m eta: 0:48:46  iter: 3379  total_loss: 1.318  loss_cls: 0.3005  loss_box_reg: 0.5051  loss_mask: 0.2757  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.1823  time: 0.6305  data_time: 0.1430  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:25:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:25:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:25:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:25:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:25:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:25:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:25:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.0363 s/iter. Total: 0.1052 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:25:48 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0713 s/iter. Eval: 0.0544 s/iter. Total: 0.1265 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:25:53 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0725 s/iter. Eval: 0.0579 s/iter. Total: 0.1312 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:25:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.042058 (0.129673 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:25:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071859 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:25:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:25:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26347494928678544\n",
      "\u001b[32m[02/03 17:26:03 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 3399  total_loss: 1.357  loss_cls: 0.3049  loss_box_reg: 0.5212  loss_mask: 0.3  loss_rpn_cls: 0.06154  loss_rpn_loc: 0.1788  time: 0.6297  data_time: 0.1163  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:26:14 d2.utils.events]: \u001b[0m eta: 0:48:21  iter: 3419  total_loss: 1.287  loss_cls: 0.2944  loss_box_reg: 0.4655  loss_mask: 0.3068  loss_rpn_cls: 0.09173  loss_rpn_loc: 0.1773  time: 0.6291  data_time: 0.1440  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:26:28 d2.utils.events]: \u001b[0m eta: 0:48:20  iter: 3439  total_loss: 1.418  loss_cls: 0.3291  loss_box_reg: 0.5034  loss_mask: 0.296  loss_rpn_cls: 0.09468  loss_rpn_loc: 0.2016  time: 0.6296  data_time: 0.3058  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:26:41 d2.utils.events]: \u001b[0m eta: 0:48:08  iter: 3459  total_loss: 1.349  loss_cls: 0.3051  loss_box_reg: 0.489  loss_mask: 0.31  loss_rpn_cls: 0.08141  loss_rpn_loc: 0.2098  time: 0.6299  data_time: 0.2620  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:26:52 d2.utils.events]: \u001b[0m eta: 0:47:55  iter: 3479  total_loss: 1.423  loss_cls: 0.3312  loss_box_reg: 0.4816  loss_mask: 0.2919  loss_rpn_cls: 0.06137  loss_rpn_loc: 0.1826  time: 0.6294  data_time: 0.1509  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:27:07 d2.utils.events]: \u001b[0m eta: 0:47:47  iter: 3499  total_loss: 1.369  loss_cls: 0.2919  loss_box_reg: 0.4984  loss_mask: 0.3037  loss_rpn_cls: 0.07212  loss_rpn_loc: 0.1918  time: 0.6298  data_time: 0.3051  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:27:19 d2.utils.events]: \u001b[0m eta: 0:47:37  iter: 3519  total_loss: 1.492  loss_cls: 0.317  loss_box_reg: 0.5206  loss_mask: 0.3005  loss_rpn_cls: 0.09323  loss_rpn_loc: 0.2041  time: 0.6297  data_time: 0.1994  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:27:30 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 3539  total_loss: 1.552  loss_cls: 0.3589  loss_box_reg: 0.5333  loss_mask: 0.3046  loss_rpn_cls: 0.08659  loss_rpn_loc: 0.2154  time: 0.6293  data_time: 0.1582  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:27:43 d2.utils.events]: \u001b[0m eta: 0:47:23  iter: 3559  total_loss: 1.405  loss_cls: 0.3135  loss_box_reg: 0.5141  loss_mask: 0.2988  loss_rpn_cls: 0.07928  loss_rpn_loc: 0.2027  time: 0.6295  data_time: 0.2427  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:27:57 d2.utils.events]: \u001b[0m eta: 0:47:11  iter: 3579  total_loss: 1.335  loss_cls: 0.3151  loss_box_reg: 0.4995  loss_mask: 0.2992  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.1873  time: 0.6298  data_time: 0.2715  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:28:10 d2.utils.events]: \u001b[0m eta: 0:47:04  iter: 3599  total_loss: 1.457  loss_cls: 0.3336  loss_box_reg: 0.5173  loss_mask: 0.3034  loss_rpn_cls: 0.09642  loss_rpn_loc: 0.2169  time: 0.6298  data_time: 0.2334  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:28:21 d2.utils.events]: \u001b[0m eta: 0:46:55  iter: 3619  total_loss: 1.453  loss_cls: 0.2908  loss_box_reg: 0.5297  loss_mask: 0.2898  loss_rpn_cls: 0.06031  loss_rpn_loc: 0.1821  time: 0.6295  data_time: 0.1612  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:28:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:28:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:28:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:28:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:28:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:28:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0686 s/iter. Eval: 0.0347 s/iter. Total: 0.1040 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0715 s/iter. Eval: 0.0537 s/iter. Total: 0.1260 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:28:38 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0722 s/iter. Eval: 0.0577 s/iter. Total: 0.1306 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:28:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.014712 (0.129437 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:28:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071776 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:28:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:28:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2650320483870402\n",
      "\u001b[32m[02/03 17:28:49 d2.utils.events]: \u001b[0m eta: 0:46:50  iter: 3639  total_loss: 1.331  loss_cls: 0.2898  loss_box_reg: 0.4904  loss_mask: 0.2761  loss_rpn_cls: 0.07408  loss_rpn_loc: 0.1883  time: 0.6292  data_time: 0.1679  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:29:04 d2.utils.events]: \u001b[0m eta: 0:46:42  iter: 3659  total_loss: 1.378  loss_cls: 0.2941  loss_box_reg: 0.4943  loss_mask: 0.2932  loss_rpn_cls: 0.0888  loss_rpn_loc: 0.1752  time: 0.6297  data_time: 0.3053  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:29:14 d2.utils.events]: \u001b[0m eta: 0:46:34  iter: 3679  total_loss: 1.387  loss_cls: 0.3166  loss_box_reg: 0.513  loss_mask: 0.2971  loss_rpn_cls: 0.08317  loss_rpn_loc: 0.1881  time: 0.6293  data_time: 0.1404  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:29:26 d2.utils.events]: \u001b[0m eta: 0:46:25  iter: 3699  total_loss: 1.504  loss_cls: 0.3361  loss_box_reg: 0.5122  loss_mask: 0.2983  loss_rpn_cls: 0.07437  loss_rpn_loc: 0.2046  time: 0.6289  data_time: 0.1483  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:29:37 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 3719  total_loss: 1.392  loss_cls: 0.3285  loss_box_reg: 0.4967  loss_mask: 0.2965  loss_rpn_cls: 0.07436  loss_rpn_loc: 0.1839  time: 0.6285  data_time: 0.1536  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:29:51 d2.utils.events]: \u001b[0m eta: 0:46:01  iter: 3739  total_loss: 1.395  loss_cls: 0.3696  loss_box_reg: 0.5014  loss_mask: 0.2904  loss_rpn_cls: 0.09719  loss_rpn_loc: 0.2013  time: 0.6290  data_time: 0.3112  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:30:02 d2.utils.events]: \u001b[0m eta: 0:45:48  iter: 3759  total_loss: 1.431  loss_cls: 0.3087  loss_box_reg: 0.5013  loss_mask: 0.2973  loss_rpn_cls: 0.08219  loss_rpn_loc: 0.1945  time: 0.6286  data_time: 0.1549  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:30:12 d2.utils.events]: \u001b[0m eta: 0:45:35  iter: 3779  total_loss: 1.331  loss_cls: 0.2889  loss_box_reg: 0.5117  loss_mask: 0.3075  loss_rpn_cls: 0.05736  loss_rpn_loc: 0.1836  time: 0.6278  data_time: 0.0846  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:30:25 d2.utils.events]: \u001b[0m eta: 0:45:23  iter: 3799  total_loss: 1.476  loss_cls: 0.3468  loss_box_reg: 0.5129  loss_mask: 0.3027  loss_rpn_cls: 0.09143  loss_rpn_loc: 0.2036  time: 0.6279  data_time: 0.2350  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:30:39 d2.utils.events]: \u001b[0m eta: 0:45:13  iter: 3819  total_loss: 1.332  loss_cls: 0.2931  loss_box_reg: 0.4749  loss_mask: 0.2985  loss_rpn_cls: 0.07077  loss_rpn_loc: 0.1871  time: 0.6282  data_time: 0.2804  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:30:50 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 3839  total_loss: 1.306  loss_cls: 0.2734  loss_box_reg: 0.496  loss_mask: 0.2973  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.1817  time: 0.6279  data_time: 0.1670  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:31:04 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 3859  total_loss: 1.418  loss_cls: 0.3132  loss_box_reg: 0.5206  loss_mask: 0.31  loss_rpn_cls: 0.08124  loss_rpn_loc: 0.2168  time: 0.6283  data_time: 0.2792  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:31:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:31:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:31:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:31:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:31:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:31:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0695 s/iter. Eval: 0.0362 s/iter. Total: 0.1063 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:31:21 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0533 s/iter. Total: 0.1253 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:31:26 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0720 s/iter. Eval: 0.0571 s/iter. Total: 0.1299 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:31:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.950754 (0.128886 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:31:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071648 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:31:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:31:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.265836435491836\n",
      "\u001b[32m[02/03 17:31:38 d2.utils.events]: \u001b[0m eta: 0:44:48  iter: 3879  total_loss: 1.409  loss_cls: 0.3406  loss_box_reg: 0.4636  loss_mask: 0.2915  loss_rpn_cls: 0.08414  loss_rpn_loc: 0.2233  time: 0.6296  data_time: 0.4503  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:31:50 d2.utils.events]: \u001b[0m eta: 0:44:35  iter: 3899  total_loss: 1.411  loss_cls: 0.3125  loss_box_reg: 0.5122  loss_mask: 0.2965  loss_rpn_cls: 0.05804  loss_rpn_loc: 0.1873  time: 0.6294  data_time: 0.1857  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:32:02 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 3919  total_loss: 1.374  loss_cls: 0.3055  loss_box_reg: 0.4823  loss_mask: 0.2989  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.191  time: 0.6293  data_time: 0.1971  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:32:17 d2.utils.events]: \u001b[0m eta: 0:44:12  iter: 3939  total_loss: 1.351  loss_cls: 0.3379  loss_box_reg: 0.4924  loss_mask: 0.2891  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.1957  time: 0.6298  data_time: 0.3195  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:32:32 d2.utils.events]: \u001b[0m eta: 0:43:58  iter: 3959  total_loss: 1.488  loss_cls: 0.3267  loss_box_reg: 0.5102  loss_mask: 0.3108  loss_rpn_cls: 0.0975  loss_rpn_loc: 0.2113  time: 0.6304  data_time: 0.3230  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:32:43 d2.utils.events]: \u001b[0m eta: 0:43:36  iter: 3979  total_loss: 1.362  loss_cls: 0.3015  loss_box_reg: 0.5031  loss_mask: 0.2869  loss_rpn_cls: 0.07181  loss_rpn_loc: 0.1713  time: 0.6300  data_time: 0.1578  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:32:54 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 3999  total_loss: 1.344  loss_cls: 0.3069  loss_box_reg: 0.5083  loss_mask: 0.2883  loss_rpn_cls: 0.06344  loss_rpn_loc: 0.183  time: 0.6296  data_time: 0.1485  lr: 0.00032  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:33:05 d2.utils.events]: \u001b[0m eta: 0:43:08  iter: 4019  total_loss: 1.379  loss_cls: 0.3085  loss_box_reg: 0.5094  loss_mask: 0.3055  loss_rpn_cls: 0.08574  loss_rpn_loc: 0.1848  time: 0.6293  data_time: 0.1824  lr: 0.000256  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:33:19 d2.utils.events]: \u001b[0m eta: 0:43:01  iter: 4039  total_loss: 1.375  loss_cls: 0.3266  loss_box_reg: 0.4794  loss_mask: 0.2982  loss_rpn_cls: 0.083  loss_rpn_loc: 0.192  time: 0.6297  data_time: 0.2768  lr: 0.000256  max_mem: 6384M\n",
      "\u001b[32m[02/03 17:33:34 d2.utils.events]: \u001b[0m eta: 0:42:54  iter: 4059  total_loss: 1.594  loss_cls: 0.3809  loss_box_reg: 0.4986  loss_mask: 0.3213  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.2293  time: 0.6303  data_time: 0.3247  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:33:46 d2.utils.events]: \u001b[0m eta: 0:42:44  iter: 4079  total_loss: 1.389  loss_cls: 0.2836  loss_box_reg: 0.5268  loss_mask: 0.3056  loss_rpn_cls: 0.06546  loss_rpn_loc: 0.1958  time: 0.6300  data_time: 0.1578  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:34:00 d2.utils.events]: \u001b[0m eta: 0:42:32  iter: 4099  total_loss: 1.431  loss_cls: 0.3309  loss_box_reg: 0.5029  loss_mask: 0.2937  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.2209  time: 0.6304  data_time: 0.2903  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:34:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:34:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:34:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:34:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:34:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:34:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.0362 s/iter. Total: 0.1047 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0726 s/iter. Eval: 0.0570 s/iter. Total: 0.1304 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0730 s/iter. Eval: 0.0610 s/iter. Total: 0.1348 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:34:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.348790 (0.132317 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:34:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072355 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:34:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:34:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2693090667321689\n",
      "\u001b[32m[02/03 17:34:27 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 4119  total_loss: 1.41  loss_cls: 0.296  loss_box_reg: 0.5397  loss_mask: 0.2996  loss_rpn_cls: 0.07875  loss_rpn_loc: 0.1989  time: 0.6299  data_time: 0.1350  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:34:41 d2.utils.events]: \u001b[0m eta: 0:41:52  iter: 4139  total_loss: 1.452  loss_cls: 0.3378  loss_box_reg: 0.4972  loss_mask: 0.2888  loss_rpn_cls: 0.07645  loss_rpn_loc: 0.2139  time: 0.6300  data_time: 0.2427  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:34:52 d2.utils.events]: \u001b[0m eta: 0:41:42  iter: 4159  total_loss: 1.479  loss_cls: 0.3351  loss_box_reg: 0.5276  loss_mask: 0.2861  loss_rpn_cls: 0.06408  loss_rpn_loc: 0.1826  time: 0.6296  data_time: 0.1367  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:35:03 d2.utils.events]: \u001b[0m eta: 0:41:29  iter: 4179  total_loss: 1.338  loss_cls: 0.2939  loss_box_reg: 0.5066  loss_mask: 0.2924  loss_rpn_cls: 0.05854  loss_rpn_loc: 0.1804  time: 0.6293  data_time: 0.1632  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:35:15 d2.utils.events]: \u001b[0m eta: 0:41:09  iter: 4199  total_loss: 1.301  loss_cls: 0.2664  loss_box_reg: 0.4994  loss_mask: 0.304  loss_rpn_cls: 0.05455  loss_rpn_loc: 0.1769  time: 0.6293  data_time: 0.2313  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:35:28 d2.utils.events]: \u001b[0m eta: 0:40:58  iter: 4219  total_loss: 1.537  loss_cls: 0.3632  loss_box_reg: 0.5035  loss_mask: 0.2993  loss_rpn_cls: 0.09785  loss_rpn_loc: 0.2116  time: 0.6293  data_time: 0.2189  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:35:38 d2.utils.events]: \u001b[0m eta: 0:40:43  iter: 4239  total_loss: 1.375  loss_cls: 0.3018  loss_box_reg: 0.5076  loss_mask: 0.2944  loss_rpn_cls: 0.08187  loss_rpn_loc: 0.1826  time: 0.6288  data_time: 0.1211  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:35:50 d2.utils.events]: \u001b[0m eta: 0:40:34  iter: 4259  total_loss: 1.448  loss_cls: 0.3299  loss_box_reg: 0.5044  loss_mask: 0.3086  loss_rpn_cls: 0.07731  loss_rpn_loc: 0.2124  time: 0.6286  data_time: 0.1707  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:36:02 d2.utils.events]: \u001b[0m eta: 0:40:18  iter: 4279  total_loss: 1.369  loss_cls: 0.32  loss_box_reg: 0.5167  loss_mask: 0.2939  loss_rpn_cls: 0.0755  loss_rpn_loc: 0.1845  time: 0.6285  data_time: 0.2088  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:36:14 d2.utils.events]: \u001b[0m eta: 0:40:16  iter: 4299  total_loss: 1.373  loss_cls: 0.2985  loss_box_reg: 0.4897  loss_mask: 0.296  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.1824  time: 0.6283  data_time: 0.1935  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:36:29 d2.utils.events]: \u001b[0m eta: 0:40:07  iter: 4319  total_loss: 1.388  loss_cls: 0.3282  loss_box_reg: 0.5003  loss_mask: 0.3186  loss_rpn_cls: 0.09032  loss_rpn_loc: 0.2162  time: 0.6289  data_time: 0.3534  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:36:41 d2.utils.events]: \u001b[0m eta: 0:39:56  iter: 4339  total_loss: 1.37  loss_cls: 0.3209  loss_box_reg: 0.4889  loss_mask: 0.3072  loss_rpn_cls: 0.05594  loss_rpn_loc: 0.1693  time: 0.6288  data_time: 0.2093  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:36:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:36:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:36:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:36:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:36:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:36:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0697 s/iter. Eval: 0.0369 s/iter. Total: 0.1073 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0720 s/iter. Eval: 0.0552 s/iter. Total: 0.1280 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0720 s/iter. Eval: 0.0588 s/iter. Total: 0.1316 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:37:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.242571 (0.131401 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:37:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072022 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:37:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:37:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2646804240861786\n",
      "\u001b[32m[02/03 17:37:11 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 4359  total_loss: 1.436  loss_cls: 0.3  loss_box_reg: 0.4947  loss_mask: 0.2893  loss_rpn_cls: 0.09852  loss_rpn_loc: 0.1924  time: 0.6288  data_time: 0.2121  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:37:26 d2.utils.events]: \u001b[0m eta: 0:39:43  iter: 4379  total_loss: 1.323  loss_cls: 0.3098  loss_box_reg: 0.4829  loss_mask: 0.3114  loss_rpn_cls: 0.06708  loss_rpn_loc: 0.1839  time: 0.6295  data_time: 0.3801  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:37:40 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 4399  total_loss: 1.521  loss_cls: 0.3768  loss_box_reg: 0.5078  loss_mask: 0.2969  loss_rpn_cls: 0.09885  loss_rpn_loc: 0.2151  time: 0.6297  data_time: 0.2510  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:37:53 d2.utils.events]: \u001b[0m eta: 0:39:32  iter: 4419  total_loss: 1.415  loss_cls: 0.325  loss_box_reg: 0.5026  loss_mask: 0.301  loss_rpn_cls: 0.0857  loss_rpn_loc: 0.1861  time: 0.6297  data_time: 0.2200  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:38:08 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 4439  total_loss: 1.378  loss_cls: 0.3026  loss_box_reg: 0.477  loss_mask: 0.3093  loss_rpn_cls: 0.06826  loss_rpn_loc: 0.2061  time: 0.6304  data_time: 0.3774  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:38:22 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 4459  total_loss: 1.444  loss_cls: 0.3391  loss_box_reg: 0.5014  loss_mask: 0.293  loss_rpn_cls: 0.104  loss_rpn_loc: 0.2097  time: 0.6307  data_time: 0.2801  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:38:32 d2.utils.events]: \u001b[0m eta: 0:39:10  iter: 4479  total_loss: 1.41  loss_cls: 0.3359  loss_box_reg: 0.5516  loss_mask: 0.2953  loss_rpn_cls: 0.06971  loss_rpn_loc: 0.18  time: 0.6300  data_time: 0.0811  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:38:44 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 4499  total_loss: 1.325  loss_cls: 0.3024  loss_box_reg: 0.4842  loss_mask: 0.2962  loss_rpn_cls: 0.06843  loss_rpn_loc: 0.1815  time: 0.6299  data_time: 0.1969  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:38:57 d2.utils.events]: \u001b[0m eta: 0:38:51  iter: 4519  total_loss: 1.513  loss_cls: 0.3585  loss_box_reg: 0.5042  loss_mask: 0.3119  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2256  time: 0.6300  data_time: 0.2421  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:39:08 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 4539  total_loss: 1.4  loss_cls: 0.2901  loss_box_reg: 0.5061  loss_mask: 0.2964  loss_rpn_cls: 0.0677  loss_rpn_loc: 0.1847  time: 0.6296  data_time: 0.1412  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:39:21 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 4559  total_loss: 1.376  loss_cls: 0.3144  loss_box_reg: 0.5067  loss_mask: 0.3011  loss_rpn_cls: 0.07943  loss_rpn_loc: 0.2043  time: 0.6298  data_time: 0.2549  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:39:31 d2.utils.events]: \u001b[0m eta: 0:38:27  iter: 4579  total_loss: 1.265  loss_cls: 0.3141  loss_box_reg: 0.4874  loss_mask: 0.2967  loss_rpn_cls: 0.05896  loss_rpn_loc: 0.1519  time: 0.6292  data_time: 0.1067  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:39:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:39:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:39:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:39:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:39:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:39:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0353 s/iter. Total: 0.1037 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0548 s/iter. Total: 0.1273 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0723 s/iter. Eval: 0.0587 s/iter. Total: 0.1318 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:39:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.265676 (0.131601 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:39:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072791 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:39:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:39:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26859617700911825\n",
      "\u001b[32m[02/03 17:39:59 d2.utils.events]: \u001b[0m eta: 0:38:17  iter: 4599  total_loss: 1.392  loss_cls: 0.3306  loss_box_reg: 0.5301  loss_mask: 0.2951  loss_rpn_cls: 0.0671  loss_rpn_loc: 0.1937  time: 0.6289  data_time: 0.1443  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:40:10 d2.utils.events]: \u001b[0m eta: 0:38:07  iter: 4619  total_loss: 1.367  loss_cls: 0.2726  loss_box_reg: 0.5026  loss_mask: 0.3022  loss_rpn_cls: 0.07477  loss_rpn_loc: 0.1836  time: 0.6285  data_time: 0.1447  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:40:24 d2.utils.events]: \u001b[0m eta: 0:37:57  iter: 4639  total_loss: 1.497  loss_cls: 0.3472  loss_box_reg: 0.5084  loss_mask: 0.3017  loss_rpn_cls: 0.053  loss_rpn_loc: 0.2108  time: 0.6288  data_time: 0.2746  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:40:34 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 4659  total_loss: 1.433  loss_cls: 0.3175  loss_box_reg: 0.5342  loss_mask: 0.288  loss_rpn_cls: 0.07373  loss_rpn_loc: 0.1867  time: 0.6284  data_time: 0.1393  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:40:44 d2.utils.events]: \u001b[0m eta: 0:37:42  iter: 4679  total_loss: 1.425  loss_cls: 0.328  loss_box_reg: 0.4912  loss_mask: 0.2988  loss_rpn_cls: 0.08249  loss_rpn_loc: 0.2113  time: 0.6278  data_time: 0.1127  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:40:57 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 4699  total_loss: 1.404  loss_cls: 0.3259  loss_box_reg: 0.5308  loss_mask: 0.3126  loss_rpn_cls: 0.08189  loss_rpn_loc: 0.204  time: 0.6278  data_time: 0.2240  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:41:11 d2.utils.events]: \u001b[0m eta: 0:37:26  iter: 4719  total_loss: 1.406  loss_cls: 0.3545  loss_box_reg: 0.4749  loss_mask: 0.2954  loss_rpn_cls: 0.07531  loss_rpn_loc: 0.1936  time: 0.6280  data_time: 0.2741  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:41:25 d2.utils.events]: \u001b[0m eta: 0:37:17  iter: 4739  total_loss: 1.295  loss_cls: 0.2571  loss_box_reg: 0.4778  loss_mask: 0.2923  loss_rpn_cls: 0.08423  loss_rpn_loc: 0.1977  time: 0.6285  data_time: 0.3303  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:41:37 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 4759  total_loss: 1.426  loss_cls: 0.3252  loss_box_reg: 0.5056  loss_mask: 0.294  loss_rpn_cls: 0.07955  loss_rpn_loc: 0.1861  time: 0.6284  data_time: 0.2126  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:41:48 d2.utils.events]: \u001b[0m eta: 0:37:03  iter: 4779  total_loss: 1.345  loss_cls: 0.2786  loss_box_reg: 0.4816  loss_mask: 0.2922  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1986  time: 0.6281  data_time: 0.1455  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:42:04 d2.utils.events]: \u001b[0m eta: 0:36:55  iter: 4799  total_loss: 1.364  loss_cls: 0.295  loss_box_reg: 0.4815  loss_mask: 0.3168  loss_rpn_cls: 0.08922  loss_rpn_loc: 0.1886  time: 0.6287  data_time: 0.3561  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:42:18 d2.utils.events]: \u001b[0m eta: 0:36:46  iter: 4819  total_loss: 1.51  loss_cls: 0.3779  loss_box_reg: 0.5248  loss_mask: 0.3037  loss_rpn_cls: 0.09466  loss_rpn_loc: 0.2064  time: 0.6290  data_time: 0.3069  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:42:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:42:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:42:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:42:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:42:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:42:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0677 s/iter. Eval: 0.0354 s/iter. Total: 0.1037 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0555 s/iter. Total: 0.1270 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0587 s/iter. Total: 0.1307 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:42:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.038671 (0.129644 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:42:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070972 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:42:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:42:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2692200414514127\n",
      "\u001b[32m[02/03 17:42:48 d2.utils.events]: \u001b[0m eta: 0:36:38  iter: 4839  total_loss: 1.395  loss_cls: 0.2903  loss_box_reg: 0.5079  loss_mask: 0.3062  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.199  time: 0.6291  data_time: 0.2389  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:42:59 d2.utils.events]: \u001b[0m eta: 0:36:31  iter: 4859  total_loss: 1.395  loss_cls: 0.3204  loss_box_reg: 0.5218  loss_mask: 0.3007  loss_rpn_cls: 0.0696  loss_rpn_loc: 0.199  time: 0.6289  data_time: 0.1736  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:43:11 d2.utils.events]: \u001b[0m eta: 0:36:18  iter: 4879  total_loss: 1.338  loss_cls: 0.291  loss_box_reg: 0.4816  loss_mask: 0.3009  loss_rpn_cls: 0.05451  loss_rpn_loc: 0.197  time: 0.6288  data_time: 0.1998  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:43:22 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 4899  total_loss: 1.518  loss_cls: 0.3569  loss_box_reg: 0.5396  loss_mask: 0.3105  loss_rpn_cls: 0.088  loss_rpn_loc: 0.1848  time: 0.6284  data_time: 0.1307  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:43:35 d2.utils.events]: \u001b[0m eta: 0:36:03  iter: 4919  total_loss: 1.389  loss_cls: 0.3094  loss_box_reg: 0.513  loss_mask: 0.2925  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.2  time: 0.6285  data_time: 0.2353  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:43:49 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 4939  total_loss: 1.352  loss_cls: 0.2624  loss_box_reg: 0.4813  loss_mask: 0.3068  loss_rpn_cls: 0.05222  loss_rpn_loc: 0.191  time: 0.6289  data_time: 0.3002  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:44:02 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 4959  total_loss: 1.394  loss_cls: 0.3251  loss_box_reg: 0.5026  loss_mask: 0.2917  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.194  time: 0.6288  data_time: 0.1890  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:44:13 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 4979  total_loss: 1.472  loss_cls: 0.3227  loss_box_reg: 0.5383  loss_mask: 0.3087  loss_rpn_cls: 0.07002  loss_rpn_loc: 0.2152  time: 0.6285  data_time: 0.1473  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:44:26 d2.utils.events]: \u001b[0m eta: 0:35:30  iter: 4999  total_loss: 1.421  loss_cls: 0.3471  loss_box_reg: 0.489  loss_mask: 0.2908  loss_rpn_cls: 0.07649  loss_rpn_loc: 0.1812  time: 0.6287  data_time: 0.2729  lr: 0.000256  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:44:38 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 5019  total_loss: 1.232  loss_cls: 0.2493  loss_box_reg: 0.4564  loss_mask: 0.2822  loss_rpn_cls: 0.04199  loss_rpn_loc: 0.1503  time: 0.6286  data_time: 0.2084  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:44:51 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 5039  total_loss: 1.398  loss_cls: 0.3319  loss_box_reg: 0.4905  loss_mask: 0.2911  loss_rpn_cls: 0.08001  loss_rpn_loc: 0.1798  time: 0.6285  data_time: 0.1845  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:45:03 d2.utils.events]: \u001b[0m eta: 0:34:59  iter: 5059  total_loss: 1.386  loss_cls: 0.2964  loss_box_reg: 0.4898  loss_mask: 0.3042  loss_rpn_cls: 0.04691  loss_rpn_loc: 0.1982  time: 0.6284  data_time: 0.1858  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:45:16 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 5079  total_loss: 1.411  loss_cls: 0.321  loss_box_reg: 0.5029  loss_mask: 0.3051  loss_rpn_cls: 0.09574  loss_rpn_loc: 0.1974  time: 0.6287  data_time: 0.2955  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:45:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:45:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:45:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:45:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:45:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:45:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.0394 s/iter. Total: 0.1106 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 17:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0731 s/iter. Eval: 0.0553 s/iter. Total: 0.1292 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0730 s/iter. Eval: 0.0587 s/iter. Total: 0.1325 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:45:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.153124 (0.130630 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:45:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072353 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:45:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:45:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2669181237274736\n",
      "\u001b[32m[02/03 17:45:43 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 5099  total_loss: 1.375  loss_cls: 0.3249  loss_box_reg: 0.4631  loss_mask: 0.2783  loss_rpn_cls: 0.08307  loss_rpn_loc: 0.1838  time: 0.6281  data_time: 0.0815  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:45:57 d2.utils.events]: \u001b[0m eta: 0:34:39  iter: 5119  total_loss: 1.457  loss_cls: 0.3357  loss_box_reg: 0.518  loss_mask: 0.3064  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1927  time: 0.6283  data_time: 0.2335  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:46:10 d2.utils.events]: \u001b[0m eta: 0:34:30  iter: 5139  total_loss: 1.277  loss_cls: 0.2887  loss_box_reg: 0.4692  loss_mask: 0.2956  loss_rpn_cls: 0.07119  loss_rpn_loc: 0.1636  time: 0.6285  data_time: 0.2594  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:46:25 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 5159  total_loss: 1.393  loss_cls: 0.3098  loss_box_reg: 0.4597  loss_mask: 0.2903  loss_rpn_cls: 0.07504  loss_rpn_loc: 0.1845  time: 0.6290  data_time: 0.3293  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:46:36 d2.utils.events]: \u001b[0m eta: 0:34:13  iter: 5179  total_loss: 1.393  loss_cls: 0.3214  loss_box_reg: 0.4913  loss_mask: 0.2919  loss_rpn_cls: 0.0594  loss_rpn_loc: 0.1747  time: 0.6287  data_time: 0.1414  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:46:49 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 5199  total_loss: 1.433  loss_cls: 0.298  loss_box_reg: 0.5144  loss_mask: 0.2994  loss_rpn_cls: 0.09774  loss_rpn_loc: 0.1983  time: 0.6288  data_time: 0.2303  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:47:04 d2.utils.events]: \u001b[0m eta: 0:33:58  iter: 5219  total_loss: 1.44  loss_cls: 0.3204  loss_box_reg: 0.5115  loss_mask: 0.3122  loss_rpn_cls: 0.09014  loss_rpn_loc: 0.2104  time: 0.6291  data_time: 0.3035  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:47:18 d2.utils.events]: \u001b[0m eta: 0:33:52  iter: 5239  total_loss: 1.419  loss_cls: 0.3356  loss_box_reg: 0.4946  loss_mask: 0.2997  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.2004  time: 0.6294  data_time: 0.2754  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:47:29 d2.utils.events]: \u001b[0m eta: 0:33:40  iter: 5259  total_loss: 1.338  loss_cls: 0.2919  loss_box_reg: 0.5093  loss_mask: 0.2974  loss_rpn_cls: 0.05751  loss_rpn_loc: 0.1698  time: 0.6292  data_time: 0.1667  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:47:43 d2.utils.events]: \u001b[0m eta: 0:33:33  iter: 5279  total_loss: 1.366  loss_cls: 0.2909  loss_box_reg: 0.4841  loss_mask: 0.3001  loss_rpn_cls: 0.06993  loss_rpn_loc: 0.2021  time: 0.6294  data_time: 0.2580  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:47:57 d2.utils.events]: \u001b[0m eta: 0:33:27  iter: 5299  total_loss: 1.499  loss_cls: 0.3277  loss_box_reg: 0.5102  loss_mask: 0.3082  loss_rpn_cls: 0.09833  loss_rpn_loc: 0.2053  time: 0.6297  data_time: 0.2952  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:48:08 d2.utils.events]: \u001b[0m eta: 0:33:16  iter: 5319  total_loss: 1.39  loss_cls: 0.2931  loss_box_reg: 0.5203  loss_mask: 0.3006  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.1817  time: 0.6294  data_time: 0.1707  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:48:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:48:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:48:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:48:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:48:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:48:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:48:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.0368 s/iter. Total: 0.1057 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0545 s/iter. Total: 0.1265 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0579 s/iter. Total: 0.1305 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:48:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.066133 (0.129880 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:48:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071538 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:48:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:48:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26994568462651225\n",
      "\u001b[32m[02/03 17:48:36 d2.utils.events]: \u001b[0m eta: 0:33:09  iter: 5339  total_loss: 1.377  loss_cls: 0.2988  loss_box_reg: 0.4986  loss_mask: 0.2979  loss_rpn_cls: 0.07722  loss_rpn_loc: 0.1888  time: 0.6291  data_time: 0.1581  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:48:49 d2.utils.events]: \u001b[0m eta: 0:32:59  iter: 5359  total_loss: 1.372  loss_cls: 0.3135  loss_box_reg: 0.5122  loss_mask: 0.2979  loss_rpn_cls: 0.05239  loss_rpn_loc: 0.1748  time: 0.6291  data_time: 0.2145  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:49:00 d2.utils.events]: \u001b[0m eta: 0:32:51  iter: 5379  total_loss: 1.434  loss_cls: 0.3444  loss_box_reg: 0.4732  loss_mask: 0.2883  loss_rpn_cls: 0.07858  loss_rpn_loc: 0.1971  time: 0.6290  data_time: 0.1692  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:49:10 d2.utils.events]: \u001b[0m eta: 0:32:41  iter: 5399  total_loss: 1.345  loss_cls: 0.3236  loss_box_reg: 0.5131  loss_mask: 0.2894  loss_rpn_cls: 0.06167  loss_rpn_loc: 0.1621  time: 0.6285  data_time: 0.0905  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:49:23 d2.utils.events]: \u001b[0m eta: 0:32:33  iter: 5419  total_loss: 1.389  loss_cls: 0.2887  loss_box_reg: 0.4787  loss_mask: 0.2946  loss_rpn_cls: 0.08494  loss_rpn_loc: 0.1979  time: 0.6286  data_time: 0.2408  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:49:32 d2.utils.events]: \u001b[0m eta: 0:32:23  iter: 5439  total_loss: 1.318  loss_cls: 0.2816  loss_box_reg: 0.5105  loss_mask: 0.2885  loss_rpn_cls: 0.0377  loss_rpn_loc: 0.1731  time: 0.6280  data_time: 0.0691  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:49:46 d2.utils.events]: \u001b[0m eta: 0:32:16  iter: 5459  total_loss: 1.393  loss_cls: 0.3419  loss_box_reg: 0.4893  loss_mask: 0.2928  loss_rpn_cls: 0.08605  loss_rpn_loc: 0.1885  time: 0.6282  data_time: 0.2562  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:50:00 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 5479  total_loss: 1.441  loss_cls: 0.3047  loss_box_reg: 0.4731  loss_mask: 0.3038  loss_rpn_cls: 0.09908  loss_rpn_loc: 0.1996  time: 0.6285  data_time: 0.2968  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:50:12 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 5499  total_loss: 1.475  loss_cls: 0.3315  loss_box_reg: 0.5197  loss_mask: 0.3078  loss_rpn_cls: 0.0887  loss_rpn_loc: 0.2024  time: 0.6284  data_time: 0.1983  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:50:24 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 5519  total_loss: 1.412  loss_cls: 0.3247  loss_box_reg: 0.5026  loss_mask: 0.2997  loss_rpn_cls: 0.07962  loss_rpn_loc: 0.1821  time: 0.6281  data_time: 0.1516  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:50:38 d2.utils.events]: \u001b[0m eta: 0:31:43  iter: 5539  total_loss: 1.365  loss_cls: 0.3006  loss_box_reg: 0.4951  loss_mask: 0.3004  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.1973  time: 0.6284  data_time: 0.2916  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:50:51 d2.utils.events]: \u001b[0m eta: 0:31:35  iter: 5559  total_loss: 1.344  loss_cls: 0.3007  loss_box_reg: 0.4747  loss_mask: 0.2882  loss_rpn_cls: 0.05829  loss_rpn_loc: 0.1801  time: 0.6285  data_time: 0.2443  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:50:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:50:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:50:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:50:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:50:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:50:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0693 s/iter. Eval: 0.0361 s/iter. Total: 0.1060 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:51:02 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0717 s/iter. Eval: 0.0539 s/iter. Total: 0.1264 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 17:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0720 s/iter. Eval: 0.0575 s/iter. Total: 0.1303 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:51:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.995245 (0.129269 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:51:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071708 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:51:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:51:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26519389985965214\n",
      "\u001b[32m[02/03 17:51:21 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 5579  total_loss: 1.409  loss_cls: 0.292  loss_box_reg: 0.4805  loss_mask: 0.3086  loss_rpn_cls: 0.06954  loss_rpn_loc: 0.2058  time: 0.6286  data_time: 0.2303  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:51:34 d2.utils.events]: \u001b[0m eta: 0:31:22  iter: 5599  total_loss: 1.372  loss_cls: 0.3191  loss_box_reg: 0.4845  loss_mask: 0.2961  loss_rpn_cls: 0.07318  loss_rpn_loc: 0.183  time: 0.6287  data_time: 0.2389  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:51:47 d2.utils.events]: \u001b[0m eta: 0:31:20  iter: 5619  total_loss: 1.436  loss_cls: 0.3323  loss_box_reg: 0.5308  loss_mask: 0.2968  loss_rpn_cls: 0.07982  loss_rpn_loc: 0.1996  time: 0.6287  data_time: 0.2163  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:52:00 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 5639  total_loss: 1.35  loss_cls: 0.2932  loss_box_reg: 0.4651  loss_mask: 0.2993  loss_rpn_cls: 0.09851  loss_rpn_loc: 0.195  time: 0.6289  data_time: 0.2540  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:52:15 d2.utils.events]: \u001b[0m eta: 0:31:07  iter: 5659  total_loss: 1.397  loss_cls: 0.2983  loss_box_reg: 0.477  loss_mask: 0.2965  loss_rpn_cls: 0.09363  loss_rpn_loc: 0.2086  time: 0.6293  data_time: 0.3362  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:52:28 d2.utils.events]: \u001b[0m eta: 0:30:58  iter: 5679  total_loss: 1.371  loss_cls: 0.3144  loss_box_reg: 0.5073  loss_mask: 0.2968  loss_rpn_cls: 0.08572  loss_rpn_loc: 0.204  time: 0.6293  data_time: 0.2090  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:52:38 d2.utils.events]: \u001b[0m eta: 0:30:48  iter: 5699  total_loss: 1.364  loss_cls: 0.3007  loss_box_reg: 0.502  loss_mask: 0.2857  loss_rpn_cls: 0.07193  loss_rpn_loc: 0.1822  time: 0.6289  data_time: 0.0960  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:52:50 d2.utils.events]: \u001b[0m eta: 0:30:40  iter: 5719  total_loss: 1.262  loss_cls: 0.3029  loss_box_reg: 0.4992  loss_mask: 0.3042  loss_rpn_cls: 0.05179  loss_rpn_loc: 0.1846  time: 0.6288  data_time: 0.2008  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:53:01 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 5739  total_loss: 1.421  loss_cls: 0.3244  loss_box_reg: 0.4947  loss_mask: 0.3172  loss_rpn_cls: 0.06006  loss_rpn_loc: 0.18  time: 0.6285  data_time: 0.1422  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:53:13 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 5759  total_loss: 1.467  loss_cls: 0.3225  loss_box_reg: 0.4761  loss_mask: 0.2917  loss_rpn_cls: 0.07362  loss_rpn_loc: 0.1985  time: 0.6285  data_time: 0.2001  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:53:27 d2.utils.events]: \u001b[0m eta: 0:30:15  iter: 5779  total_loss: 1.388  loss_cls: 0.2883  loss_box_reg: 0.4912  loss_mask: 0.3144  loss_rpn_cls: 0.07218  loss_rpn_loc: 0.2136  time: 0.6288  data_time: 0.3169  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:53:40 d2.utils.events]: \u001b[0m eta: 0:30:05  iter: 5799  total_loss: 1.265  loss_cls: 0.2771  loss_box_reg: 0.4943  loss_mask: 0.2996  loss_rpn_cls: 0.04993  loss_rpn_loc: 0.1779  time: 0.6288  data_time: 0.2237  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:53:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:53:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:53:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:53:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:53:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:53:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0680 s/iter. Eval: 0.0358 s/iter. Total: 0.1045 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:53:54 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0542 s/iter. Total: 0.1268 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:53:59 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0722 s/iter. Eval: 0.0576 s/iter. Total: 0.1306 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.061874 (0.129844 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072092 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:54:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26883372084889035\n",
      "\u001b[32m[02/03 17:54:10 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 5819  total_loss: 1.331  loss_cls: 0.3052  loss_box_reg: 0.4906  loss_mask: 0.2881  loss_rpn_cls: 0.08818  loss_rpn_loc: 0.17  time: 0.6288  data_time: 0.2189  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:54:23 d2.utils.events]: \u001b[0m eta: 0:29:48  iter: 5839  total_loss: 1.312  loss_cls: 0.2984  loss_box_reg: 0.4821  loss_mask: 0.2848  loss_rpn_cls: 0.06621  loss_rpn_loc: 0.1747  time: 0.6290  data_time: 0.2634  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:54:36 d2.utils.events]: \u001b[0m eta: 0:29:40  iter: 5859  total_loss: 1.383  loss_cls: 0.2684  loss_box_reg: 0.4865  loss_mask: 0.2991  loss_rpn_cls: 0.06727  loss_rpn_loc: 0.1873  time: 0.6290  data_time: 0.2111  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:54:51 d2.utils.events]: \u001b[0m eta: 0:29:32  iter: 5879  total_loss: 1.449  loss_cls: 0.3298  loss_box_reg: 0.4906  loss_mask: 0.3007  loss_rpn_cls: 0.09358  loss_rpn_loc: 0.2079  time: 0.6294  data_time: 0.3368  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:55:02 d2.utils.events]: \u001b[0m eta: 0:29:22  iter: 5899  total_loss: 1.312  loss_cls: 0.2715  loss_box_reg: 0.4987  loss_mask: 0.2981  loss_rpn_cls: 0.05021  loss_rpn_loc: 0.1761  time: 0.6291  data_time: 0.1492  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:55:16 d2.utils.events]: \u001b[0m eta: 0:29:14  iter: 5919  total_loss: 1.31  loss_cls: 0.2965  loss_box_reg: 0.445  loss_mask: 0.2755  loss_rpn_cls: 0.0718  loss_rpn_loc: 0.1938  time: 0.6294  data_time: 0.2906  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:55:27 d2.utils.events]: \u001b[0m eta: 0:29:06  iter: 5939  total_loss: 1.423  loss_cls: 0.315  loss_box_reg: 0.5137  loss_mask: 0.3055  loss_rpn_cls: 0.0891  loss_rpn_loc: 0.1852  time: 0.6292  data_time: 0.1349  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:55:40 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 5959  total_loss: 1.324  loss_cls: 0.2787  loss_box_reg: 0.4558  loss_mask: 0.2956  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.174  time: 0.6293  data_time: 0.2560  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:55:55 d2.utils.events]: \u001b[0m eta: 0:28:48  iter: 5979  total_loss: 1.311  loss_cls: 0.3127  loss_box_reg: 0.4788  loss_mask: 0.3049  loss_rpn_cls: 0.09111  loss_rpn_loc: 0.182  time: 0.6296  data_time: 0.3331  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:56:08 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 5999  total_loss: 1.454  loss_cls: 0.3309  loss_box_reg: 0.5113  loss_mask: 0.3066  loss_rpn_cls: 0.07686  loss_rpn_loc: 0.1915  time: 0.6296  data_time: 0.2221  lr: 0.0002048  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:56:17 d2.utils.events]: \u001b[0m eta: 0:28:31  iter: 6019  total_loss: 1.449  loss_cls: 0.3154  loss_box_reg: 0.5326  loss_mask: 0.2858  loss_rpn_cls: 0.07227  loss_rpn_loc: 0.167  time: 0.6291  data_time: 0.0665  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:56:28 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 6039  total_loss: 1.397  loss_cls: 0.3061  loss_box_reg: 0.4853  loss_mask: 0.3017  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.1786  time: 0.6288  data_time: 0.1293  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:56:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:56:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:56:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:56:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:56:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:56:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0688 s/iter. Eval: 0.0359 s/iter. Total: 0.1054 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 17:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0712 s/iter. Eval: 0.0549 s/iter. Total: 0.1269 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 17:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0598 s/iter. Total: 0.1325 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 17:56:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.254690 (0.131506 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:56:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071812 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:56:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:56:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27002572692865096\n",
      "\u001b[32m[02/03 17:56:56 d2.utils.events]: \u001b[0m eta: 0:28:14  iter: 6059  total_loss: 1.443  loss_cls: 0.3514  loss_box_reg: 0.5149  loss_mask: 0.3024  loss_rpn_cls: 0.06498  loss_rpn_loc: 0.1902  time: 0.6286  data_time: 0.1656  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:57:09 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 6079  total_loss: 1.247  loss_cls: 0.2747  loss_box_reg: 0.4674  loss_mask: 0.2899  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.1771  time: 0.6286  data_time: 0.2073  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:57:22 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 6099  total_loss: 1.434  loss_cls: 0.3122  loss_box_reg: 0.4953  loss_mask: 0.2885  loss_rpn_cls: 0.07857  loss_rpn_loc: 0.2153  time: 0.6287  data_time: 0.2363  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:57:33 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 6119  total_loss: 1.412  loss_cls: 0.3042  loss_box_reg: 0.5034  loss_mask: 0.307  loss_rpn_cls: 0.06874  loss_rpn_loc: 0.1882  time: 0.6285  data_time: 0.1544  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:57:46 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 6139  total_loss: 1.332  loss_cls: 0.3162  loss_box_reg: 0.4988  loss_mask: 0.3068  loss_rpn_cls: 0.05151  loss_rpn_loc: 0.1878  time: 0.6286  data_time: 0.2450  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:57:59 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 6159  total_loss: 1.311  loss_cls: 0.307  loss_box_reg: 0.4835  loss_mask: 0.2887  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.1855  time: 0.6286  data_time: 0.2234  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:58:14 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 6179  total_loss: 1.428  loss_cls: 0.3465  loss_box_reg: 0.496  loss_mask: 0.2945  loss_rpn_cls: 0.08696  loss_rpn_loc: 0.189  time: 0.6290  data_time: 0.3293  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:58:28 d2.utils.events]: \u001b[0m eta: 0:27:15  iter: 6199  total_loss: 1.479  loss_cls: 0.3147  loss_box_reg: 0.4774  loss_mask: 0.3051  loss_rpn_cls: 0.09531  loss_rpn_loc: 0.1855  time: 0.6293  data_time: 0.2821  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:58:39 d2.utils.events]: \u001b[0m eta: 0:27:04  iter: 6219  total_loss: 1.464  loss_cls: 0.3354  loss_box_reg: 0.4904  loss_mask: 0.3033  loss_rpn_cls: 0.08204  loss_rpn_loc: 0.1857  time: 0.6291  data_time: 0.1690  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:58:50 d2.utils.events]: \u001b[0m eta: 0:26:55  iter: 6239  total_loss: 1.317  loss_cls: 0.3151  loss_box_reg: 0.4908  loss_mask: 0.289  loss_rpn_cls: 0.05514  loss_rpn_loc: 0.174  time: 0.6287  data_time: 0.1163  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:59:03 d2.utils.events]: \u001b[0m eta: 0:26:46  iter: 6259  total_loss: 1.417  loss_cls: 0.2956  loss_box_reg: 0.5134  loss_mask: 0.3096  loss_rpn_cls: 0.06679  loss_rpn_loc: 0.2032  time: 0.6287  data_time: 0.2387  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:59:14 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 6279  total_loss: 1.403  loss_cls: 0.3503  loss_box_reg: 0.4999  loss_mask: 0.2897  loss_rpn_cls: 0.07836  loss_rpn_loc: 0.1938  time: 0.6286  data_time: 0.1694  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:59:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:59:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 17:59:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 17:59:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 17:59:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 17:59:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 17:59:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0703 s/iter. Eval: 0.0442 s/iter. Total: 0.1152 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 17:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0750 s/iter. Eval: 0.0597 s/iter. Total: 0.1355 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 17:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0755 s/iter. Eval: 0.0636 s/iter. Total: 0.1400 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 17:59:38 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0755 s/iter. Eval: 0.0609 s/iter. Total: 0.1372 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/03 17:59:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.970399 (0.137676 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:59:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075490 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 17:59:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 17:59:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2701075585174616\n",
      "\u001b[32m[02/03 17:59:43 d2.utils.events]: \u001b[0m eta: 0:26:23  iter: 6299  total_loss: 1.331  loss_cls: 0.3109  loss_box_reg: 0.4801  loss_mask: 0.288  loss_rpn_cls: 0.07553  loss_rpn_loc: 0.1678  time: 0.6283  data_time: 0.1359  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 17:59:55 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 6319  total_loss: 1.288  loss_cls: 0.2759  loss_box_reg: 0.5016  loss_mask: 0.2922  loss_rpn_cls: 0.06137  loss_rpn_loc: 0.1686  time: 0.6283  data_time: 0.1928  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:00:05 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 6339  total_loss: 1.369  loss_cls: 0.2809  loss_box_reg: 0.5241  loss_mask: 0.3236  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.1797  time: 0.6279  data_time: 0.1106  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:00:20 d2.utils.events]: \u001b[0m eta: 0:25:56  iter: 6359  total_loss: 1.288  loss_cls: 0.3085  loss_box_reg: 0.4458  loss_mask: 0.2913  loss_rpn_cls: 0.07975  loss_rpn_loc: 0.1914  time: 0.6281  data_time: 0.2895  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:00:35 d2.utils.events]: \u001b[0m eta: 0:25:50  iter: 6379  total_loss: 1.466  loss_cls: 0.3571  loss_box_reg: 0.4843  loss_mask: 0.2939  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.2015  time: 0.6286  data_time: 0.3486  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:00:46 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 6399  total_loss: 1.453  loss_cls: 0.318  loss_box_reg: 0.513  loss_mask: 0.2824  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.1846  time: 0.6284  data_time: 0.1510  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:00:58 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 6419  total_loss: 1.359  loss_cls: 0.3066  loss_box_reg: 0.5221  loss_mask: 0.3091  loss_rpn_cls: 0.08141  loss_rpn_loc: 0.1882  time: 0.6282  data_time: 0.1792  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:01:12 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 6439  total_loss: 1.342  loss_cls: 0.2875  loss_box_reg: 0.5051  loss_mask: 0.3077  loss_rpn_cls: 0.06811  loss_rpn_loc: 0.1835  time: 0.6284  data_time: 0.2652  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:01:25 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 6459  total_loss: 1.406  loss_cls: 0.316  loss_box_reg: 0.4817  loss_mask: 0.2976  loss_rpn_cls: 0.08183  loss_rpn_loc: 0.194  time: 0.6285  data_time: 0.2568  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:01:38 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 6479  total_loss: 1.407  loss_cls: 0.3109  loss_box_reg: 0.5045  loss_mask: 0.2922  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.1917  time: 0.6286  data_time: 0.2178  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:01:53 d2.utils.events]: \u001b[0m eta: 0:24:59  iter: 6499  total_loss: 1.274  loss_cls: 0.2716  loss_box_reg: 0.4676  loss_mask: 0.2947  loss_rpn_cls: 0.06555  loss_rpn_loc: 0.1916  time: 0.6289  data_time: 0.3176  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:02:07 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 6519  total_loss: 1.44  loss_cls: 0.3248  loss_box_reg: 0.4988  loss_mask: 0.2955  loss_rpn_cls: 0.09403  loss_rpn_loc: 0.1959  time: 0.6292  data_time: 0.2832  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:02:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:02:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:02:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:02:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:02:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:02:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0708 s/iter. Eval: 0.0381 s/iter. Total: 0.1095 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 18:02:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0729 s/iter. Eval: 0.0567 s/iter. Total: 0.1304 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:02:28 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0740 s/iter. Eval: 0.0620 s/iter. Total: 0.1368 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 18:02:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.666927 (0.135060 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:02:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073219 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:02:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:02:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27138432755974584\n",
      "\u001b[32m[02/03 18:02:36 d2.utils.events]: \u001b[0m eta: 0:24:41  iter: 6539  total_loss: 1.217  loss_cls: 0.2534  loss_box_reg: 0.4671  loss_mask: 0.2819  loss_rpn_cls: 0.04405  loss_rpn_loc: 0.1693  time: 0.6290  data_time: 0.1809  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:02:48 d2.utils.events]: \u001b[0m eta: 0:24:35  iter: 6559  total_loss: 1.352  loss_cls: 0.3227  loss_box_reg: 0.5109  loss_mask: 0.2933  loss_rpn_cls: 0.07407  loss_rpn_loc: 0.2035  time: 0.6290  data_time: 0.2047  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:02:59 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 6579  total_loss: 1.483  loss_cls: 0.3437  loss_box_reg: 0.5147  loss_mask: 0.2959  loss_rpn_cls: 0.08176  loss_rpn_loc: 0.1881  time: 0.6286  data_time: 0.1107  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:03:10 d2.utils.events]: \u001b[0m eta: 0:24:16  iter: 6599  total_loss: 1.37  loss_cls: 0.3223  loss_box_reg: 0.4969  loss_mask: 0.3011  loss_rpn_cls: 0.0782  loss_rpn_loc: 0.1903  time: 0.6285  data_time: 0.1739  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:03:23 d2.utils.events]: \u001b[0m eta: 0:24:05  iter: 6619  total_loss: 1.385  loss_cls: 0.3175  loss_box_reg: 0.5113  loss_mask: 0.2957  loss_rpn_cls: 0.07484  loss_rpn_loc: 0.1924  time: 0.6285  data_time: 0.2230  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:03:36 d2.utils.events]: \u001b[0m eta: 0:23:55  iter: 6639  total_loss: 1.362  loss_cls: 0.305  loss_box_reg: 0.4851  loss_mask: 0.315  loss_rpn_cls: 0.05553  loss_rpn_loc: 0.177  time: 0.6286  data_time: 0.2740  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:03:47 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 6659  total_loss: 1.299  loss_cls: 0.28  loss_box_reg: 0.4921  loss_mask: 0.2925  loss_rpn_cls: 0.05438  loss_rpn_loc: 0.1714  time: 0.6283  data_time: 0.1277  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:04:01 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 6679  total_loss: 1.37  loss_cls: 0.3132  loss_box_reg: 0.5011  loss_mask: 0.2952  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.2043  time: 0.6285  data_time: 0.2785  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:04:13 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 6699  total_loss: 1.36  loss_cls: 0.3  loss_box_reg: 0.4867  loss_mask: 0.3023  loss_rpn_cls: 0.06534  loss_rpn_loc: 0.2037  time: 0.6284  data_time: 0.1956  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:04:25 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 6719  total_loss: 1.347  loss_cls: 0.2961  loss_box_reg: 0.4991  loss_mask: 0.2943  loss_rpn_cls: 0.04779  loss_rpn_loc: 0.1945  time: 0.6284  data_time: 0.2066  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:04:40 d2.utils.events]: \u001b[0m eta: 0:23:12  iter: 6739  total_loss: 1.331  loss_cls: 0.31  loss_box_reg: 0.4884  loss_mask: 0.2878  loss_rpn_cls: 0.0513  loss_rpn_loc: 0.1694  time: 0.6287  data_time: 0.3370  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:04:53 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 6759  total_loss: 1.331  loss_cls: 0.2646  loss_box_reg: 0.4631  loss_mask: 0.2909  loss_rpn_cls: 0.04803  loss_rpn_loc: 0.1548  time: 0.6289  data_time: 0.2786  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:05:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:05:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:05:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:05:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:05:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:05:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0684 s/iter. Eval: 0.0360 s/iter. Total: 0.1050 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 18:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0712 s/iter. Eval: 0.0551 s/iter. Total: 0.1272 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0589 s/iter. Total: 0.1316 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:05:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.279599 (0.131721 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:05:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072245 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:05:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:05:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2691091655099896\n",
      "\u001b[32m[02/03 18:05:28 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 6779  total_loss: 1.454  loss_cls: 0.3284  loss_box_reg: 0.4825  loss_mask: 0.3053  loss_rpn_cls: 0.0807  loss_rpn_loc: 0.2135  time: 0.6296  data_time: 0.4531  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:05:44 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 6799  total_loss: 1.463  loss_cls: 0.3508  loss_box_reg: 0.4801  loss_mask: 0.3045  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.2069  time: 0.6302  data_time: 0.4011  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:05:57 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 6819  total_loss: 1.398  loss_cls: 0.3343  loss_box_reg: 0.5108  loss_mask: 0.2899  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.1881  time: 0.6302  data_time: 0.2348  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:06:10 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 6839  total_loss: 1.325  loss_cls: 0.2811  loss_box_reg: 0.4566  loss_mask: 0.2809  loss_rpn_cls: 0.07675  loss_rpn_loc: 0.1941  time: 0.6302  data_time: 0.2055  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:06:20 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 6859  total_loss: 1.482  loss_cls: 0.337  loss_box_reg: 0.5277  loss_mask: 0.3096  loss_rpn_cls: 0.08677  loss_rpn_loc: 0.198  time: 0.6299  data_time: 0.1305  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:06:34 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 6879  total_loss: 1.365  loss_cls: 0.3108  loss_box_reg: 0.4619  loss_mask: 0.2972  loss_rpn_cls: 0.0802  loss_rpn_loc: 0.2112  time: 0.6301  data_time: 0.2988  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:06:46 d2.utils.events]: \u001b[0m eta: 0:22:10  iter: 6899  total_loss: 1.325  loss_cls: 0.2988  loss_box_reg: 0.4789  loss_mask: 0.2881  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.1927  time: 0.6300  data_time: 0.1949  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:06:57 d2.utils.events]: \u001b[0m eta: 0:21:58  iter: 6919  total_loss: 1.346  loss_cls: 0.3078  loss_box_reg: 0.4774  loss_mask: 0.2805  loss_rpn_cls: 0.06581  loss_rpn_loc: 0.1798  time: 0.6297  data_time: 0.1152  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:07:07 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 6939  total_loss: 1.337  loss_cls: 0.2889  loss_box_reg: 0.5016  loss_mask: 0.2998  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.1784  time: 0.6293  data_time: 0.1173  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:07:20 d2.utils.events]: \u001b[0m eta: 0:21:39  iter: 6959  total_loss: 1.241  loss_cls: 0.2911  loss_box_reg: 0.4804  loss_mask: 0.2834  loss_rpn_cls: 0.07015  loss_rpn_loc: 0.1701  time: 0.6294  data_time: 0.2540  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:07:33 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 6979  total_loss: 1.37  loss_cls: 0.2626  loss_box_reg: 0.508  loss_mask: 0.2964  loss_rpn_cls: 0.05309  loss_rpn_loc: 0.1824  time: 0.6295  data_time: 0.2498  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:07:44 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 6999  total_loss: 1.48  loss_cls: 0.3306  loss_box_reg: 0.514  loss_mask: 0.3095  loss_rpn_cls: 0.06237  loss_rpn_loc: 0.2032  time: 0.6293  data_time: 0.1415  lr: 0.00016384  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:07:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:07:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:07:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:07:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:07:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:07:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0687 s/iter. Eval: 0.0370 s/iter. Total: 0.1062 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 18:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0711 s/iter. Eval: 0.0546 s/iter. Total: 0.1265 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 18:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0715 s/iter. Eval: 0.0582 s/iter. Total: 0.1305 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:08:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.042817 (0.129679 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:08:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071288 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:08:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:08:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2696930926816709\n",
      "\u001b[32m[02/03 18:08:14 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 7019  total_loss: 1.415  loss_cls: 0.3299  loss_box_reg: 0.4731  loss_mask: 0.3083  loss_rpn_cls: 0.09058  loss_rpn_loc: 0.2139  time: 0.6294  data_time: 0.2652  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:08:26 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 7039  total_loss: 1.406  loss_cls: 0.3246  loss_box_reg: 0.5258  loss_mask: 0.3013  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.2026  time: 0.6292  data_time: 0.1591  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:08:36 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 7059  total_loss: 1.346  loss_cls: 0.2967  loss_box_reg: 0.4932  loss_mask: 0.2921  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.1598  time: 0.6289  data_time: 0.1130  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:08:48 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 7079  total_loss: 1.34  loss_cls: 0.3086  loss_box_reg: 0.4716  loss_mask: 0.2886  loss_rpn_cls: 0.07441  loss_rpn_loc: 0.1906  time: 0.6288  data_time: 0.1797  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:09:00 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 7099  total_loss: 1.3  loss_cls: 0.2819  loss_box_reg: 0.4725  loss_mask: 0.2913  loss_rpn_cls: 0.05008  loss_rpn_loc: 0.1736  time: 0.6287  data_time: 0.1958  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:09:14 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 7119  total_loss: 1.43  loss_cls: 0.3339  loss_box_reg: 0.4876  loss_mask: 0.3141  loss_rpn_cls: 0.07364  loss_rpn_loc: 0.2  time: 0.6289  data_time: 0.2826  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:09:26 d2.utils.events]: \u001b[0m eta: 0:20:20  iter: 7139  total_loss: 1.353  loss_cls: 0.3324  loss_box_reg: 0.4893  loss_mask: 0.2928  loss_rpn_cls: 0.07884  loss_rpn_loc: 0.1777  time: 0.6288  data_time: 0.1899  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:09:41 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 7159  total_loss: 1.428  loss_cls: 0.3246  loss_box_reg: 0.4929  loss_mask: 0.3062  loss_rpn_cls: 0.07775  loss_rpn_loc: 0.2015  time: 0.6292  data_time: 0.3193  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:09:54 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 7179  total_loss: 1.395  loss_cls: 0.3207  loss_box_reg: 0.4874  loss_mask: 0.2935  loss_rpn_cls: 0.07649  loss_rpn_loc: 0.1844  time: 0.6293  data_time: 0.2514  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:10:06 d2.utils.events]: \u001b[0m eta: 0:19:52  iter: 7199  total_loss: 1.369  loss_cls: 0.3  loss_box_reg: 0.49  loss_mask: 0.3069  loss_rpn_cls: 0.07251  loss_rpn_loc: 0.1893  time: 0.6291  data_time: 0.1700  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:10:16 d2.utils.events]: \u001b[0m eta: 0:19:44  iter: 7219  total_loss: 1.265  loss_cls: 0.2723  loss_box_reg: 0.4999  loss_mask: 0.2853  loss_rpn_cls: 0.04669  loss_rpn_loc: 0.1696  time: 0.6288  data_time: 0.1400  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:10:26 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 7239  total_loss: 1.278  loss_cls: 0.275  loss_box_reg: 0.4967  loss_mask: 0.2945  loss_rpn_cls: 0.06007  loss_rpn_loc: 0.1876  time: 0.6285  data_time: 0.1077  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:10:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:10:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:10:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:10:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:10:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:10:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0688 s/iter. Eval: 0.0392 s/iter. Total: 0.1087 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/03 18:10:46 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0708 s/iter. Eval: 0.0550 s/iter. Total: 0.1266 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 18:10:51 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0712 s/iter. Eval: 0.0584 s/iter. Total: 0.1304 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:10:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.048732 (0.129730 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:10:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071192 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:10:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:10:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2680909981950702\n",
      "\u001b[32m[02/03 18:10:55 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 7259  total_loss: 1.456  loss_cls: 0.3126  loss_box_reg: 0.489  loss_mask: 0.3127  loss_rpn_cls: 0.08596  loss_rpn_loc: 0.2156  time: 0.6285  data_time: 0.2427  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:11:09 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 7279  total_loss: 1.438  loss_cls: 0.2991  loss_box_reg: 0.4979  loss_mask: 0.2983  loss_rpn_cls: 0.07105  loss_rpn_loc: 0.1923  time: 0.6286  data_time: 0.2456  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:11:24 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 7299  total_loss: 1.5  loss_cls: 0.3429  loss_box_reg: 0.4695  loss_mask: 0.3209  loss_rpn_cls: 0.09808  loss_rpn_loc: 0.1989  time: 0.6289  data_time: 0.3381  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:11:34 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 7319  total_loss: 1.304  loss_cls: 0.3162  loss_box_reg: 0.4984  loss_mask: 0.2874  loss_rpn_cls: 0.07864  loss_rpn_loc: 0.1795  time: 0.6286  data_time: 0.1147  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:11:45 d2.utils.events]: \u001b[0m eta: 0:18:54  iter: 7339  total_loss: 1.293  loss_cls: 0.2695  loss_box_reg: 0.5028  loss_mask: 0.2919  loss_rpn_cls: 0.06485  loss_rpn_loc: 0.1718  time: 0.6283  data_time: 0.1410  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:11:56 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 7359  total_loss: 1.308  loss_cls: 0.2939  loss_box_reg: 0.4534  loss_mask: 0.3015  loss_rpn_cls: 0.06109  loss_rpn_loc: 0.1832  time: 0.6282  data_time: 0.1546  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:12:09 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 7379  total_loss: 1.393  loss_cls: 0.2922  loss_box_reg: 0.5361  loss_mask: 0.2917  loss_rpn_cls: 0.07248  loss_rpn_loc: 0.1851  time: 0.6282  data_time: 0.2252  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:12:25 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 7399  total_loss: 1.297  loss_cls: 0.2773  loss_box_reg: 0.4567  loss_mask: 0.2818  loss_rpn_cls: 0.06905  loss_rpn_loc: 0.1806  time: 0.6286  data_time: 0.3825  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:12:37 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 7419  total_loss: 1.35  loss_cls: 0.3063  loss_box_reg: 0.4997  loss_mask: 0.2982  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.182  time: 0.6286  data_time: 0.2031  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:12:50 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 7439  total_loss: 1.402  loss_cls: 0.3228  loss_box_reg: 0.4764  loss_mask: 0.2976  loss_rpn_cls: 0.06626  loss_rpn_loc: 0.1962  time: 0.6287  data_time: 0.2577  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:13:00 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 7459  total_loss: 1.33  loss_cls: 0.288  loss_box_reg: 0.5179  loss_mask: 0.2971  loss_rpn_cls: 0.04883  loss_rpn_loc: 0.182  time: 0.6283  data_time: 0.0897  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:13:11 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 7479  total_loss: 1.355  loss_cls: 0.3017  loss_box_reg: 0.5022  loss_mask: 0.2902  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.1907  time: 0.6281  data_time: 0.1673  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:13:29 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 7499  total_loss: 1.306  loss_cls: 0.3104  loss_box_reg: 0.4563  loss_mask: 0.2918  loss_rpn_cls: 0.08162  loss_rpn_loc: 0.1906  time: 0.6288  data_time: 0.4543  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:13:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:13:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:13:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:13:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:13:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:13:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0441 s/iter. Total: 0.1169 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 18:13:39 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0008 s/iter. Inference: 0.0715 s/iter. Eval: 0.0543 s/iter. Total: 0.1266 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 18:13:44 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0563 s/iter. Total: 0.1291 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:13:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.935399 (0.128753 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:13:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072169 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:13:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:13:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2652314169185733\n",
      "\u001b[32m[02/03 18:13:59 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 7519  total_loss: 1.43  loss_cls: 0.3399  loss_box_reg: 0.5095  loss_mask: 0.3093  loss_rpn_cls: 0.05597  loss_rpn_loc: 0.1921  time: 0.6289  data_time: 0.2492  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:14:12 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 7539  total_loss: 1.412  loss_cls: 0.3391  loss_box_reg: 0.474  loss_mask: 0.307  loss_rpn_cls: 0.08593  loss_rpn_loc: 0.2026  time: 0.6291  data_time: 0.2668  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:14:23 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 7559  total_loss: 1.375  loss_cls: 0.2909  loss_box_reg: 0.4743  loss_mask: 0.3085  loss_rpn_cls: 0.06095  loss_rpn_loc: 0.1907  time: 0.6288  data_time: 0.1298  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:14:35 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 7579  total_loss: 1.302  loss_cls: 0.2771  loss_box_reg: 0.4954  loss_mask: 0.3003  loss_rpn_cls: 0.05934  loss_rpn_loc: 0.1906  time: 0.6287  data_time: 0.1792  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:14:45 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 7599  total_loss: 1.336  loss_cls: 0.2868  loss_box_reg: 0.4901  loss_mask: 0.2911  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.1775  time: 0.6283  data_time: 0.0973  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:14:58 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 7619  total_loss: 1.366  loss_cls: 0.3315  loss_box_reg: 0.4703  loss_mask: 0.2921  loss_rpn_cls: 0.08204  loss_rpn_loc: 0.1893  time: 0.6285  data_time: 0.2650  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:15:13 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 7639  total_loss: 1.374  loss_cls: 0.3032  loss_box_reg: 0.4869  loss_mask: 0.3018  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.1957  time: 0.6287  data_time: 0.2998  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:15:28 d2.utils.events]: \u001b[0m eta: 0:16:36  iter: 7659  total_loss: 1.427  loss_cls: 0.3345  loss_box_reg: 0.518  loss_mask: 0.2978  loss_rpn_cls: 0.07645  loss_rpn_loc: 0.1934  time: 0.6291  data_time: 0.3747  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:15:39 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 7679  total_loss: 1.445  loss_cls: 0.3229  loss_box_reg: 0.5098  loss_mask: 0.3082  loss_rpn_cls: 0.0574  loss_rpn_loc: 0.1923  time: 0.6289  data_time: 0.1461  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:15:49 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 7699  total_loss: 1.333  loss_cls: 0.3027  loss_box_reg: 0.5104  loss_mask: 0.2853  loss_rpn_cls: 0.05561  loss_rpn_loc: 0.1572  time: 0.6286  data_time: 0.1034  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:16:02 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 7719  total_loss: 1.303  loss_cls: 0.2843  loss_box_reg: 0.4656  loss_mask: 0.3085  loss_rpn_cls: 0.06472  loss_rpn_loc: 0.1816  time: 0.6286  data_time: 0.2319  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:16:16 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 7739  total_loss: 1.331  loss_cls: 0.331  loss_box_reg: 0.4826  loss_mask: 0.2981  loss_rpn_cls: 0.06582  loss_rpn_loc: 0.1797  time: 0.6288  data_time: 0.3167  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:16:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:16:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:16:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:16:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:16:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:16:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0694 s/iter. Eval: 0.0422 s/iter. Total: 0.1123 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 18:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0708 s/iter. Eval: 0.0547 s/iter. Total: 0.1264 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/03 18:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0711 s/iter. Eval: 0.0576 s/iter. Total: 0.1295 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:16:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.943713 (0.128825 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:16:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.070901 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:16:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:16:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2682940012101897\n",
      "\u001b[32m[02/03 18:16:46 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 7759  total_loss: 1.389  loss_cls: 0.3347  loss_box_reg: 0.5132  loss_mask: 0.2825  loss_rpn_cls: 0.07577  loss_rpn_loc: 0.1895  time: 0.6288  data_time: 0.2164  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:16:56 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 7779  total_loss: 1.356  loss_cls: 0.331  loss_box_reg: 0.5059  loss_mask: 0.2875  loss_rpn_cls: 0.064  loss_rpn_loc: 0.1805  time: 0.6286  data_time: 0.1319  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:17:10 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 7799  total_loss: 1.437  loss_cls: 0.3567  loss_box_reg: 0.4833  loss_mask: 0.3112  loss_rpn_cls: 0.07145  loss_rpn_loc: 0.1983  time: 0.6288  data_time: 0.2798  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:17:22 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 7819  total_loss: 1.366  loss_cls: 0.311  loss_box_reg: 0.4481  loss_mask: 0.296  loss_rpn_cls: 0.0903  loss_rpn_loc: 0.2079  time: 0.6287  data_time: 0.1724  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:17:35 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 7839  total_loss: 1.307  loss_cls: 0.2916  loss_box_reg: 0.4883  loss_mask: 0.2831  loss_rpn_cls: 0.07169  loss_rpn_loc: 0.1909  time: 0.6287  data_time: 0.2327  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:17:48 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 7859  total_loss: 1.4  loss_cls: 0.3227  loss_box_reg: 0.5185  loss_mask: 0.3037  loss_rpn_cls: 0.07709  loss_rpn_loc: 0.1986  time: 0.6287  data_time: 0.2297  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:18:02 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 7879  total_loss: 1.397  loss_cls: 0.3289  loss_box_reg: 0.465  loss_mask: 0.2985  loss_rpn_cls: 0.08348  loss_rpn_loc: 0.196  time: 0.6289  data_time: 0.2857  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:18:12 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 7899  total_loss: 1.365  loss_cls: 0.2928  loss_box_reg: 0.4988  loss_mask: 0.2942  loss_rpn_cls: 0.06043  loss_rpn_loc: 0.175  time: 0.6286  data_time: 0.1150  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:18:26 d2.utils.events]: \u001b[0m eta: 0:14:45  iter: 7919  total_loss: 1.32  loss_cls: 0.2962  loss_box_reg: 0.4764  loss_mask: 0.2875  loss_rpn_cls: 0.07486  loss_rpn_loc: 0.1801  time: 0.6288  data_time: 0.2783  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:18:37 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 7939  total_loss: 1.274  loss_cls: 0.2752  loss_box_reg: 0.493  loss_mask: 0.3002  loss_rpn_cls: 0.07099  loss_rpn_loc: 0.1705  time: 0.6286  data_time: 0.1414  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:18:48 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 7959  total_loss: 1.367  loss_cls: 0.3038  loss_box_reg: 0.5023  loss_mask: 0.2932  loss_rpn_cls: 0.06756  loss_rpn_loc: 0.188  time: 0.6284  data_time: 0.1479  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:19:01 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 7979  total_loss: 1.363  loss_cls: 0.3333  loss_box_reg: 0.469  loss_mask: 0.2951  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.184  time: 0.6284  data_time: 0.2230  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:19:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:19:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:19:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:19:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:19:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:19:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:19:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0012 s/iter. Inference: 0.0729 s/iter. Eval: 0.0513 s/iter. Total: 0.1255 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.0752 s/iter. Eval: 0.0670 s/iter. Total: 0.1431 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 18:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0734 s/iter. Eval: 0.0643 s/iter. Total: 0.1386 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 18:19:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.658344 (0.134986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:19:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072467 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:19:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:19:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26974886269070786\n",
      "\u001b[32m[02/03 18:19:28 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 7999  total_loss: 1.285  loss_cls: 0.2598  loss_box_reg: 0.4855  loss_mask: 0.2945  loss_rpn_cls: 0.05735  loss_rpn_loc: 0.1661  time: 0.6281  data_time: 0.1021  lr: 0.00013107  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:19:39 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 8019  total_loss: 1.341  loss_cls: 0.3084  loss_box_reg: 0.5105  loss_mask: 0.2969  loss_rpn_cls: 0.07201  loss_rpn_loc: 0.1691  time: 0.6279  data_time: 0.1668  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:19:51 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 8039  total_loss: 1.355  loss_cls: 0.313  loss_box_reg: 0.5016  loss_mask: 0.3054  loss_rpn_cls: 0.07941  loss_rpn_loc: 0.1879  time: 0.6278  data_time: 0.1863  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:20:01 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 8059  total_loss: 1.331  loss_cls: 0.2894  loss_box_reg: 0.5115  loss_mask: 0.2929  loss_rpn_cls: 0.06891  loss_rpn_loc: 0.2115  time: 0.6275  data_time: 0.1025  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:20:15 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 8079  total_loss: 1.298  loss_cls: 0.3109  loss_box_reg: 0.4697  loss_mask: 0.27  loss_rpn_cls: 0.05693  loss_rpn_loc: 0.1605  time: 0.6276  data_time: 0.2567  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:20:26 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 8099  total_loss: 1.238  loss_cls: 0.2557  loss_box_reg: 0.4806  loss_mask: 0.2843  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.1695  time: 0.6275  data_time: 0.1709  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:20:39 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 8119  total_loss: 1.301  loss_cls: 0.2901  loss_box_reg: 0.4901  loss_mask: 0.2899  loss_rpn_cls: 0.08124  loss_rpn_loc: 0.187  time: 0.6275  data_time: 0.2049  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:20:52 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 8139  total_loss: 1.349  loss_cls: 0.2857  loss_box_reg: 0.4826  loss_mask: 0.2921  loss_rpn_cls: 0.09279  loss_rpn_loc: 0.1961  time: 0.6276  data_time: 0.2171  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:21:06 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 8159  total_loss: 1.323  loss_cls: 0.3079  loss_box_reg: 0.507  loss_mask: 0.2974  loss_rpn_cls: 0.06881  loss_rpn_loc: 0.1856  time: 0.6278  data_time: 0.2821  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:21:18 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 8179  total_loss: 1.395  loss_cls: 0.3206  loss_box_reg: 0.4985  loss_mask: 0.299  loss_rpn_cls: 0.08576  loss_rpn_loc: 0.1711  time: 0.6277  data_time: 0.1978  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:21:30 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 8199  total_loss: 1.445  loss_cls: 0.2849  loss_box_reg: 0.5272  loss_mask: 0.3123  loss_rpn_cls: 0.06863  loss_rpn_loc: 0.1891  time: 0.6276  data_time: 0.2014  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:21:43 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 8219  total_loss: 1.381  loss_cls: 0.2988  loss_box_reg: 0.4995  loss_mask: 0.3062  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.1931  time: 0.6277  data_time: 0.2175  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:21:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:21:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:21:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:21:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:21:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:21:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0705 s/iter. Eval: 0.0511 s/iter. Total: 0.1223 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0722 s/iter. Eval: 0.0583 s/iter. Total: 0.1313 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:22:02 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0740 s/iter. Eval: 0.0617 s/iter. Total: 0.1365 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:22:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.519070 (0.133785 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:22:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.073025 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:22:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2684495627584937\n",
      "\u001b[32m[02/03 18:22:15 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 8239  total_loss: 1.344  loss_cls: 0.304  loss_box_reg: 0.5043  loss_mask: 0.3117  loss_rpn_cls: 0.07484  loss_rpn_loc: 0.1929  time: 0.6280  data_time: 0.3361  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:22:29 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 8259  total_loss: 1.379  loss_cls: 0.3021  loss_box_reg: 0.4779  loss_mask: 0.2934  loss_rpn_cls: 0.07726  loss_rpn_loc: 0.1847  time: 0.6282  data_time: 0.3118  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:22:44 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 8279  total_loss: 1.333  loss_cls: 0.3085  loss_box_reg: 0.4912  loss_mask: 0.2992  loss_rpn_cls: 0.08081  loss_rpn_loc: 0.1858  time: 0.6285  data_time: 0.3261  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:22:57 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 8299  total_loss: 1.313  loss_cls: 0.2919  loss_box_reg: 0.5054  loss_mask: 0.2926  loss_rpn_cls: 0.0627  loss_rpn_loc: 0.189  time: 0.6285  data_time: 0.2363  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:23:09 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 8319  total_loss: 1.368  loss_cls: 0.2825  loss_box_reg: 0.4719  loss_mask: 0.3076  loss_rpn_cls: 0.07525  loss_rpn_loc: 0.2076  time: 0.6284  data_time: 0.1913  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:23:23 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 8339  total_loss: 1.392  loss_cls: 0.2847  loss_box_reg: 0.4802  loss_mask: 0.3095  loss_rpn_cls: 0.09164  loss_rpn_loc: 0.1954  time: 0.6286  data_time: 0.2758  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:23:32 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 8359  total_loss: 1.419  loss_cls: 0.3173  loss_box_reg: 0.539  loss_mask: 0.311  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.1836  time: 0.6281  data_time: 0.0510  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:23:45 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 8379  total_loss: 1.323  loss_cls: 0.2841  loss_box_reg: 0.4927  loss_mask: 0.2913  loss_rpn_cls: 0.06252  loss_rpn_loc: 0.1835  time: 0.6282  data_time: 0.2542  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:23:59 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 8399  total_loss: 1.232  loss_cls: 0.2583  loss_box_reg: 0.4616  loss_mask: 0.296  loss_rpn_cls: 0.07127  loss_rpn_loc: 0.1859  time: 0.6284  data_time: 0.3042  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:24:11 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 8419  total_loss: 1.325  loss_cls: 0.3038  loss_box_reg: 0.479  loss_mask: 0.2861  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.1808  time: 0.6284  data_time: 0.2046  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:24:24 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 8439  total_loss: 1.401  loss_cls: 0.3371  loss_box_reg: 0.5058  loss_mask: 0.3022  loss_rpn_cls: 0.08254  loss_rpn_loc: 0.1888  time: 0.6283  data_time: 0.1981  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:24:37 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 8459  total_loss: 1.386  loss_cls: 0.3188  loss_box_reg: 0.4658  loss_mask: 0.2955  loss_rpn_cls: 0.08425  loss_rpn_loc: 0.1854  time: 0.6284  data_time: 0.2506  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:24:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:24:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:24:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:24:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:24:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:24:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0696 s/iter. Eval: 0.0481 s/iter. Total: 0.1185 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:24:50 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0016 s/iter. Inference: 0.0713 s/iter. Eval: 0.0580 s/iter. Total: 0.1309 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0012 s/iter. Inference: 0.0722 s/iter. Eval: 0.0618 s/iter. Total: 0.1353 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:25:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.493163 (0.133562 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:25:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072178 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:25:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:25:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2702353269689064\n",
      "\u001b[32m[02/03 18:25:05 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 8479  total_loss: 1.372  loss_cls: 0.3212  loss_box_reg: 0.516  loss_mask: 0.288  loss_rpn_cls: 0.05235  loss_rpn_loc: 0.1886  time: 0.6283  data_time: 0.1583  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:25:20 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 8499  total_loss: 1.391  loss_cls: 0.2965  loss_box_reg: 0.4864  loss_mask: 0.2982  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.1933  time: 0.6286  data_time: 0.3226  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:25:35 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 8519  total_loss: 1.413  loss_cls: 0.3417  loss_box_reg: 0.4719  loss_mask: 0.3025  loss_rpn_cls: 0.09138  loss_rpn_loc: 0.2201  time: 0.6288  data_time: 0.3000  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:25:45 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 8539  total_loss: 1.359  loss_cls: 0.2853  loss_box_reg: 0.5154  loss_mask: 0.2811  loss_rpn_cls: 0.05865  loss_rpn_loc: 0.1814  time: 0.6285  data_time: 0.1083  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:25:57 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 8559  total_loss: 1.378  loss_cls: 0.2845  loss_box_reg: 0.4995  loss_mask: 0.3116  loss_rpn_cls: 0.05518  loss_rpn_loc: 0.1941  time: 0.6284  data_time: 0.1768  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:26:10 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 8579  total_loss: 1.34  loss_cls: 0.2902  loss_box_reg: 0.4836  loss_mask: 0.2912  loss_rpn_cls: 0.07184  loss_rpn_loc: 0.1863  time: 0.6284  data_time: 0.2116  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:26:21 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 8599  total_loss: 1.286  loss_cls: 0.2947  loss_box_reg: 0.5084  loss_mask: 0.2895  loss_rpn_cls: 0.0531  loss_rpn_loc: 0.1687  time: 0.6282  data_time: 0.1401  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:26:34 d2.utils.events]: \u001b[0m eta: 0:09:52  iter: 8619  total_loss: 1.39  loss_cls: 0.2983  loss_box_reg: 0.4717  loss_mask: 0.2955  loss_rpn_cls: 0.06154  loss_rpn_loc: 0.183  time: 0.6283  data_time: 0.2439  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:26:43 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 8639  total_loss: 1.32  loss_cls: 0.2811  loss_box_reg: 0.5041  loss_mask: 0.2934  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.1767  time: 0.6279  data_time: 0.0561  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:26:55 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 8659  total_loss: 1.363  loss_cls: 0.2928  loss_box_reg: 0.4945  loss_mask: 0.293  loss_rpn_cls: 0.07328  loss_rpn_loc: 0.1873  time: 0.6279  data_time: 0.2026  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:27:07 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 8679  total_loss: 1.354  loss_cls: 0.3453  loss_box_reg: 0.4797  loss_mask: 0.2946  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.1873  time: 0.6278  data_time: 0.2027  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:27:22 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 8699  total_loss: 1.216  loss_cls: 0.2618  loss_box_reg: 0.4596  loss_mask: 0.2956  loss_rpn_cls: 0.08543  loss_rpn_loc: 0.1851  time: 0.6281  data_time: 0.3190  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:27:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:27:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:27:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:27:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:27:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:27:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0710 s/iter. Eval: 0.0463 s/iter. Total: 0.1181 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/03 18:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0009 s/iter. Inference: 0.0711 s/iter. Eval: 0.0569 s/iter. Total: 0.1290 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0008 s/iter. Inference: 0.0713 s/iter. Eval: 0.0594 s/iter. Total: 0.1316 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:27:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.137822 (0.130498 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:27:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071035 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:27:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:27:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26681301370832006\n",
      "\u001b[32m[02/03 18:27:51 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 8719  total_loss: 1.388  loss_cls: 0.2914  loss_box_reg: 0.5104  loss_mask: 0.3001  loss_rpn_cls: 0.08135  loss_rpn_loc: 0.1738  time: 0.6281  data_time: 0.2161  lr: 0.00010486  max_mem: 6401M\n",
      "\u001b[32m[02/03 18:28:05 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 8739  total_loss: 1.358  loss_cls: 0.3099  loss_box_reg: 0.4774  loss_mask: 0.3004  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1899  time: 0.6282  data_time: 0.2651  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:28:17 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 8759  total_loss: 1.456  loss_cls: 0.3265  loss_box_reg: 0.4961  loss_mask: 0.3077  loss_rpn_cls: 0.08176  loss_rpn_loc: 0.2025  time: 0.6281  data_time: 0.1578  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:28:32 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 8779  total_loss: 1.445  loss_cls: 0.3527  loss_box_reg: 0.4863  loss_mask: 0.2852  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.2184  time: 0.6284  data_time: 0.3341  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:28:43 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 8799  total_loss: 1.35  loss_cls: 0.3149  loss_box_reg: 0.4906  loss_mask: 0.2876  loss_rpn_cls: 0.0719  loss_rpn_loc: 0.1862  time: 0.6282  data_time: 0.1615  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:28:55 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 8819  total_loss: 1.358  loss_cls: 0.2973  loss_box_reg: 0.4851  loss_mask: 0.2984  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.1939  time: 0.6282  data_time: 0.1918  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:29:11 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 8839  total_loss: 1.442  loss_cls: 0.3426  loss_box_reg: 0.5024  loss_mask: 0.306  loss_rpn_cls: 0.09654  loss_rpn_loc: 0.2031  time: 0.6285  data_time: 0.3735  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:29:21 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 8859  total_loss: 1.258  loss_cls: 0.2626  loss_box_reg: 0.4761  loss_mask: 0.2876  loss_rpn_cls: 0.05032  loss_rpn_loc: 0.1615  time: 0.6283  data_time: 0.1199  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:29:30 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 8879  total_loss: 1.294  loss_cls: 0.268  loss_box_reg: 0.4825  loss_mask: 0.2833  loss_rpn_cls: 0.05887  loss_rpn_loc: 0.1766  time: 0.6279  data_time: 0.0654  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:29:42 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 8899  total_loss: 1.253  loss_cls: 0.2662  loss_box_reg: 0.4361  loss_mask: 0.3011  loss_rpn_cls: 0.07885  loss_rpn_loc: 0.1864  time: 0.6278  data_time: 0.1908  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:29:54 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 8919  total_loss: 1.347  loss_cls: 0.3162  loss_box_reg: 0.4845  loss_mask: 0.2964  loss_rpn_cls: 0.06497  loss_rpn_loc: 0.1832  time: 0.6278  data_time: 0.1913  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:30:08 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 8939  total_loss: 1.333  loss_cls: 0.296  loss_box_reg: 0.4889  loss_mask: 0.2979  loss_rpn_cls: 0.07777  loss_rpn_loc: 0.1931  time: 0.6279  data_time: 0.2710  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:30:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:30:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:30:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:30:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:30:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:30:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0705 s/iter. Eval: 0.0480 s/iter. Total: 0.1193 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.0714 s/iter. Eval: 0.0571 s/iter. Total: 0.1294 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0601 s/iter. Total: 0.1326 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:30:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.241491 (0.131392 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:30:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:30:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:30:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26526968607480234\n",
      "\u001b[32m[02/03 18:30:35 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 8959  total_loss: 1.431  loss_cls: 0.3015  loss_box_reg: 0.5115  loss_mask: 0.2979  loss_rpn_cls: 0.06554  loss_rpn_loc: 0.1896  time: 0.6277  data_time: 0.1253  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:30:51 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 8979  total_loss: 1.286  loss_cls: 0.2965  loss_box_reg: 0.4558  loss_mask: 0.2905  loss_rpn_cls: 0.06826  loss_rpn_loc: 0.1689  time: 0.6281  data_time: 0.3938  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:31:01 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 8999  total_loss: 1.354  loss_cls: 0.3114  loss_box_reg: 0.5269  loss_mask: 0.3002  loss_rpn_cls: 0.06858  loss_rpn_loc: 0.176  time: 0.6278  data_time: 0.0965  lr: 0.00010486  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:31:16 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 9019  total_loss: 1.264  loss_cls: 0.2793  loss_box_reg: 0.4623  loss_mask: 0.2891  loss_rpn_cls: 0.05766  loss_rpn_loc: 0.1706  time: 0.6280  data_time: 0.3086  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:31:29 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 9039  total_loss: 1.363  loss_cls: 0.3254  loss_box_reg: 0.5231  loss_mask: 0.2968  loss_rpn_cls: 0.08577  loss_rpn_loc: 0.2056  time: 0.6281  data_time: 0.2528  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:31:44 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 9059  total_loss: 1.346  loss_cls: 0.292  loss_box_reg: 0.461  loss_mask: 0.3038  loss_rpn_cls: 0.07933  loss_rpn_loc: 0.1836  time: 0.6284  data_time: 0.3140  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:31:56 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 9079  total_loss: 1.288  loss_cls: 0.275  loss_box_reg: 0.4776  loss_mask: 0.2922  loss_rpn_cls: 0.05286  loss_rpn_loc: 0.1711  time: 0.6283  data_time: 0.1872  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:32:05 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 9099  total_loss: 1.321  loss_cls: 0.2984  loss_box_reg: 0.5124  loss_mask: 0.2938  loss_rpn_cls: 0.05216  loss_rpn_loc: 0.1799  time: 0.6279  data_time: 0.0442  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:32:15 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 9119  total_loss: 1.469  loss_cls: 0.3292  loss_box_reg: 0.5265  loss_mask: 0.3062  loss_rpn_cls: 0.06197  loss_rpn_loc: 0.2031  time: 0.6276  data_time: 0.1246  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:32:28 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 9139  total_loss: 1.273  loss_cls: 0.288  loss_box_reg: 0.4732  loss_mask: 0.2874  loss_rpn_cls: 0.08261  loss_rpn_loc: 0.1838  time: 0.6277  data_time: 0.2318  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:32:37 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 9159  total_loss: 1.386  loss_cls: 0.3028  loss_box_reg: 0.4904  loss_mask: 0.3044  loss_rpn_cls: 0.05657  loss_rpn_loc: 0.1921  time: 0.6273  data_time: 0.0772  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:32:50 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 9179  total_loss: 1.336  loss_cls: 0.2782  loss_box_reg: 0.4786  loss_mask: 0.3037  loss_rpn_cls: 0.05371  loss_rpn_loc: 0.1675  time: 0.6273  data_time: 0.2026  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:33:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:33:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:33:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:33:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:33:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:33:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.0530 s/iter. Total: 0.1239 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:33:07 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0719 s/iter. Eval: 0.0595 s/iter. Total: 0.1324 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0725 s/iter. Eval: 0.0630 s/iter. Total: 0.1364 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:33:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.488792 (0.133524 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:33:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072023 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:33:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:33:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26716048666415704\n",
      "\u001b[32m[02/03 18:33:18 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 9199  total_loss: 1.4  loss_cls: 0.3116  loss_box_reg: 0.4915  loss_mask: 0.296  loss_rpn_cls: 0.06832  loss_rpn_loc: 0.1877  time: 0.6271  data_time: 0.1435  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:33:36 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 9219  total_loss: 1.428  loss_cls: 0.3395  loss_box_reg: 0.4761  loss_mask: 0.3008  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.2137  time: 0.6277  data_time: 0.4622  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:33:50 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 9239  total_loss: 1.39  loss_cls: 0.329  loss_box_reg: 0.5021  loss_mask: 0.2892  loss_rpn_cls: 0.07473  loss_rpn_loc: 0.187  time: 0.6279  data_time: 0.2880  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:34:02 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 9259  total_loss: 1.348  loss_cls: 0.2808  loss_box_reg: 0.4852  loss_mask: 0.2898  loss_rpn_cls: 0.07802  loss_rpn_loc: 0.1871  time: 0.6278  data_time: 0.1621  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:34:13 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 9279  total_loss: 1.308  loss_cls: 0.3102  loss_box_reg: 0.4868  loss_mask: 0.2897  loss_rpn_cls: 0.07377  loss_rpn_loc: 0.1803  time: 0.6276  data_time: 0.1754  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:34:24 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 9299  total_loss: 1.25  loss_cls: 0.2399  loss_box_reg: 0.4662  loss_mask: 0.2747  loss_rpn_cls: 0.04911  loss_rpn_loc: 0.1645  time: 0.6274  data_time: 0.1188  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:34:34 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 9319  total_loss: 1.318  loss_cls: 0.2744  loss_box_reg: 0.4918  loss_mask: 0.2935  loss_rpn_cls: 0.0469  loss_rpn_loc: 0.1668  time: 0.6272  data_time: 0.1259  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:34:46 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 9339  total_loss: 1.318  loss_cls: 0.2723  loss_box_reg: 0.4889  loss_mask: 0.3074  loss_rpn_cls: 0.06443  loss_rpn_loc: 0.1827  time: 0.6271  data_time: 0.2096  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:34:58 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 9359  total_loss: 1.33  loss_cls: 0.2729  loss_box_reg: 0.4875  loss_mask: 0.2791  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.1804  time: 0.6270  data_time: 0.1698  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:35:09 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 9379  total_loss: 1.307  loss_cls: 0.2893  loss_box_reg: 0.4688  loss_mask: 0.2772  loss_rpn_cls: 0.06492  loss_rpn_loc: 0.1694  time: 0.6269  data_time: 0.1822  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:35:24 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9399  total_loss: 1.478  loss_cls: 0.3757  loss_box_reg: 0.4989  loss_mask: 0.295  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2164  time: 0.6272  data_time: 0.3061  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:35:35 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 9419  total_loss: 1.427  loss_cls: 0.3331  loss_box_reg: 0.5218  loss_mask: 0.302  loss_rpn_cls: 0.08657  loss_rpn_loc: 0.1882  time: 0.6270  data_time: 0.1269  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:35:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:35:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:35:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:35:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:35:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:35:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0726 s/iter. Eval: 0.0490 s/iter. Total: 0.1224 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0594 s/iter. Total: 0.1320 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0718 s/iter. Eval: 0.0612 s/iter. Total: 0.1339 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:36:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.306832 (0.131955 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:36:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071508 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:36:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:36:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26796713160940727\n",
      "\u001b[32m[02/03 18:36:08 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 9439  total_loss: 1.316  loss_cls: 0.2734  loss_box_reg: 0.4889  loss_mask: 0.3016  loss_rpn_cls: 0.07545  loss_rpn_loc: 0.185  time: 0.6274  data_time: 0.4033  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:36:23 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 9459  total_loss: 1.362  loss_cls: 0.3132  loss_box_reg: 0.4721  loss_mask: 0.2935  loss_rpn_cls: 0.06608  loss_rpn_loc: 0.1803  time: 0.6276  data_time: 0.3246  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:36:35 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 9479  total_loss: 1.303  loss_cls: 0.2991  loss_box_reg: 0.4739  loss_mask: 0.2872  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.1761  time: 0.6275  data_time: 0.1961  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:36:45 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 9499  total_loss: 1.402  loss_cls: 0.2977  loss_box_reg: 0.4881  loss_mask: 0.2915  loss_rpn_cls: 0.07237  loss_rpn_loc: 0.1935  time: 0.6273  data_time: 0.1083  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:37:03 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 9519  total_loss: 1.34  loss_cls: 0.3141  loss_box_reg: 0.4631  loss_mask: 0.3016  loss_rpn_cls: 0.0755  loss_rpn_loc: 0.1997  time: 0.6278  data_time: 0.4544  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:37:17 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 9539  total_loss: 1.333  loss_cls: 0.3247  loss_box_reg: 0.509  loss_mask: 0.3109  loss_rpn_cls: 0.06206  loss_rpn_loc: 0.1879  time: 0.6280  data_time: 0.2730  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:37:29 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9559  total_loss: 1.444  loss_cls: 0.3246  loss_box_reg: 0.4909  loss_mask: 0.3044  loss_rpn_cls: 0.08058  loss_rpn_loc: 0.1964  time: 0.6280  data_time: 0.2162  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:37:40 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 9579  total_loss: 1.334  loss_cls: 0.2892  loss_box_reg: 0.48  loss_mask: 0.2979  loss_rpn_cls: 0.06105  loss_rpn_loc: 0.1663  time: 0.6278  data_time: 0.1674  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:37:53 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 9599  total_loss: 1.281  loss_cls: 0.2943  loss_box_reg: 0.4642  loss_mask: 0.2872  loss_rpn_cls: 0.06517  loss_rpn_loc: 0.1962  time: 0.6278  data_time: 0.2209  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:38:02 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 9619  total_loss: 1.397  loss_cls: 0.2835  loss_box_reg: 0.5329  loss_mask: 0.3068  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.202  time: 0.6275  data_time: 0.0758  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:38:15 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 9639  total_loss: 1.316  loss_cls: 0.2976  loss_box_reg: 0.5026  loss_mask: 0.2789  loss_rpn_cls: 0.06245  loss_rpn_loc: 0.1677  time: 0.6275  data_time: 0.2557  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:38:26 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 9659  total_loss: 1.277  loss_cls: 0.2802  loss_box_reg: 0.4709  loss_mask: 0.2843  loss_rpn_cls: 0.03929  loss_rpn_loc: 0.1678  time: 0.6273  data_time: 0.1443  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:38:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:38:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:38:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:38:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:38:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:38:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0699 s/iter. Eval: 0.0505 s/iter. Total: 0.1213 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0720 s/iter. Eval: 0.0595 s/iter. Total: 0.1323 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0721 s/iter. Eval: 0.0624 s/iter. Total: 0.1353 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/03 18:38:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.433646 (0.133049 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:38:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071657 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:38:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:38:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27151921240098315\n",
      "\u001b[32m[02/03 18:38:56 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 9679  total_loss: 1.327  loss_cls: 0.2793  loss_box_reg: 0.475  loss_mask: 0.2893  loss_rpn_cls: 0.08304  loss_rpn_loc: 0.1909  time: 0.6274  data_time: 0.2732  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:39:10 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 9699  total_loss: 1.351  loss_cls: 0.2959  loss_box_reg: 0.4828  loss_mask: 0.3056  loss_rpn_cls: 0.09325  loss_rpn_loc: 0.1948  time: 0.6276  data_time: 0.2731  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:39:21 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 9719  total_loss: 1.363  loss_cls: 0.2853  loss_box_reg: 0.4864  loss_mask: 0.3053  loss_rpn_cls: 0.0649  loss_rpn_loc: 0.1916  time: 0.6274  data_time: 0.1492  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:39:34 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 9739  total_loss: 1.321  loss_cls: 0.3245  loss_box_reg: 0.5221  loss_mask: 0.2899  loss_rpn_cls: 0.08502  loss_rpn_loc: 0.1743  time: 0.6275  data_time: 0.2671  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:39:45 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 9759  total_loss: 1.397  loss_cls: 0.311  loss_box_reg: 0.5098  loss_mask: 0.2938  loss_rpn_cls: 0.0651  loss_rpn_loc: 0.1965  time: 0.6273  data_time: 0.1490  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:39:58 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9779  total_loss: 1.237  loss_cls: 0.2772  loss_box_reg: 0.4678  loss_mask: 0.297  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.1871  time: 0.6273  data_time: 0.2153  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:40:09 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 9799  total_loss: 1.304  loss_cls: 0.2666  loss_box_reg: 0.4762  loss_mask: 0.2994  loss_rpn_cls: 0.05107  loss_rpn_loc: 0.1766  time: 0.6271  data_time: 0.1666  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:40:20 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 9819  total_loss: 1.411  loss_cls: 0.2994  loss_box_reg: 0.5  loss_mask: 0.3124  loss_rpn_cls: 0.06544  loss_rpn_loc: 0.1836  time: 0.6270  data_time: 0.1628  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:40:36 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 9839  total_loss: 1.425  loss_cls: 0.3044  loss_box_reg: 0.4802  loss_mask: 0.306  loss_rpn_cls: 0.09887  loss_rpn_loc: 0.1996  time: 0.6273  data_time: 0.3572  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:40:47 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 9859  total_loss: 1.286  loss_cls: 0.3028  loss_box_reg: 0.4924  loss_mask: 0.2936  loss_rpn_cls: 0.08043  loss_rpn_loc: 0.1714  time: 0.6272  data_time: 0.1852  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:41:03 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 9879  total_loss: 1.41  loss_cls: 0.3171  loss_box_reg: 0.4685  loss_mask: 0.2965  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.1898  time: 0.6275  data_time: 0.3437  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:41:17 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 9899  total_loss: 1.319  loss_cls: 0.271  loss_box_reg: 0.4864  loss_mask: 0.288  loss_rpn_cls: 0.0737  loss_rpn_loc: 0.1876  time: 0.6277  data_time: 0.2731  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:41:31 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 9919  total_loss: 1.327  loss_cls: 0.2964  loss_box_reg: 0.4635  loss_mask: 0.2909  loss_rpn_cls: 0.07737  loss_rpn_loc: 0.1899  time: 0.6278  data_time: 0.2831  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:41:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:41:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:41:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:41:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:41:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:41:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0725 s/iter. Eval: 0.0521 s/iter. Total: 0.1254 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:41:39 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0722 s/iter. Eval: 0.0617 s/iter. Total: 0.1348 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/03 18:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0723 s/iter. Eval: 0.0637 s/iter. Total: 0.1368 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 18:41:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.621154 (0.134665 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:41:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.071940 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:41:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:41:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2704541049945185\n",
      "\u001b[32m[02/03 18:41:59 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 9939  total_loss: 1.417  loss_cls: 0.3284  loss_box_reg: 0.5066  loss_mask: 0.3011  loss_rpn_cls: 0.0699  loss_rpn_loc: 0.1844  time: 0.6277  data_time: 0.1720  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:42:14 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 9959  total_loss: 1.398  loss_cls: 0.307  loss_box_reg: 0.483  loss_mask: 0.2982  loss_rpn_cls: 0.07898  loss_rpn_loc: 0.19  time: 0.6279  data_time: 0.3112  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:42:26 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 9979  total_loss: 1.508  loss_cls: 0.3529  loss_box_reg: 0.5169  loss_mask: 0.2832  loss_rpn_cls: 0.08382  loss_rpn_loc: 0.202  time: 0.6279  data_time: 0.2084  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:42:38 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.381  loss_cls: 0.3138  loss_box_reg: 0.4955  loss_mask: 0.2989  loss_rpn_cls: 0.0824  loss_rpn_loc: 0.1973  time: 0.6278  data_time: 0.1799  lr: 8.3886e-05  max_mem: 6500M\n",
      "\u001b[32m[02/03 18:42:38 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:44:36 (0.6278 s / it)\n",
      "\u001b[32m[02/03 18:42:38 d2.engine.hooks]: \u001b[0mTotal training time: 1:55:55 (0:11:18 on hooks)\n",
      "\u001b[32m[02/03 18:42:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:42:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/03 18:42:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/03 18:42:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/03 18:42:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/03 18:42:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/03 18:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0710 s/iter. Eval: 0.0509 s/iter. Total: 0.1228 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/03 18:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0009 s/iter. Inference: 0.0729 s/iter. Eval: 0.0674 s/iter. Total: 0.1412 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/03 18:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0725 s/iter. Eval: 0.0661 s/iter. Total: 0.1395 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/03 18:42:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.777279 (0.136011 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:42:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.072065 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/03 18:42:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/03 18:42:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27178667618979735\n"
     ]
    }
   ],
   "source": [
    "# Increasing the batch size per image (the number of ROIs per image) to 512\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bab4e3-874b-4b99-ad6b-15877056e425",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 09:00:32 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 09:00:33 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 09:00:37 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/04 09:00:37 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 09:00:37 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/04 09:00:38 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/04 09:00:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/04 09:00:38 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/04 09:00:38 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:00:38 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 09:00:38 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 09:00:51 d2.utils.events]: \u001b[0m eta: 1:09:39  iter: 19  total_loss: 3.216  loss_cls: 1.44  loss_box_reg: 0.4789  loss_mask: 0.6903  loss_rpn_cls: 0.3186  loss_rpn_loc: 0.2651  time: 0.5583  data_time: 0.1971  lr: 9.9905e-06  max_mem: 4337M\n",
      "\u001b[32m[02/04 09:01:04 d2.utils.events]: \u001b[0m eta: 1:10:42  iter: 39  total_loss: 3.182  loss_cls: 1.354  loss_box_reg: 0.4957  loss_mask: 0.6846  loss_rpn_cls: 0.3067  loss_rpn_loc: 0.2616  time: 0.6065  data_time: 0.2247  lr: 1.998e-05  max_mem: 5909M\n",
      "\u001b[32m[02/04 09:01:17 d2.utils.events]: \u001b[0m eta: 1:12:30  iter: 59  total_loss: 3.021  loss_cls: 1.198  loss_box_reg: 0.5968  loss_mask: 0.673  loss_rpn_cls: 0.2879  loss_rpn_loc: 0.2574  time: 0.6170  data_time: 0.2070  lr: 2.997e-05  max_mem: 5909M\n",
      "\u001b[32m[02/04 09:01:28 d2.utils.events]: \u001b[0m eta: 1:10:58  iter: 79  total_loss: 2.756  loss_cls: 0.9924  loss_box_reg: 0.6185  loss_mask: 0.6453  loss_rpn_cls: 0.2398  loss_rpn_loc: 0.2479  time: 0.6047  data_time: 0.1540  lr: 3.9961e-05  max_mem: 5909M\n",
      "\u001b[32m[02/04 09:01:45 d2.utils.events]: \u001b[0m eta: 1:12:43  iter: 99  total_loss: 2.646  loss_cls: 0.8952  loss_box_reg: 0.6423  loss_mask: 0.6269  loss_rpn_cls: 0.2267  loss_rpn_loc: 0.2628  time: 0.6541  data_time: 0.3804  lr: 4.9951e-05  max_mem: 5909M\n",
      "\u001b[32m[02/04 09:01:59 d2.utils.events]: \u001b[0m eta: 1:13:26  iter: 119  total_loss: 2.485  loss_cls: 0.7422  loss_box_reg: 0.7168  loss_mask: 0.5883  loss_rpn_cls: 0.1849  loss_rpn_loc: 0.2233  time: 0.6654  data_time: 0.2714  lr: 5.9941e-05  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:02:10 d2.utils.events]: \u001b[0m eta: 1:12:51  iter: 139  total_loss: 2.477  loss_cls: 0.7326  loss_box_reg: 0.795  loss_mask: 0.564  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.2142  time: 0.6438  data_time: 0.0753  lr: 6.993e-05  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:02:23 d2.utils.events]: \u001b[0m eta: 1:13:44  iter: 159  total_loss: 2.404  loss_cls: 0.6764  loss_box_reg: 0.7509  loss_mask: 0.5347  loss_rpn_cls: 0.1712  loss_rpn_loc: 0.2461  time: 0.6485  data_time: 0.2265  lr: 7.9921e-05  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:02:34 d2.utils.events]: \u001b[0m eta: 1:13:36  iter: 179  total_loss: 2.282  loss_cls: 0.6748  loss_box_reg: 0.788  loss_mask: 0.5117  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.2045  time: 0.6330  data_time: 0.0713  lr: 8.991e-05  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:02:44 d2.utils.events]: \u001b[0m eta: 1:13:35  iter: 199  total_loss: 2.277  loss_cls: 0.6433  loss_box_reg: 0.7776  loss_mask: 0.4735  loss_rpn_cls: 0.1437  loss_rpn_loc: 0.2252  time: 0.6226  data_time: 0.0971  lr: 9.9901e-05  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:02:58 d2.utils.events]: \u001b[0m eta: 1:13:53  iter: 219  total_loss: 2.168  loss_cls: 0.6018  loss_box_reg: 0.7716  loss_mask: 0.4469  loss_rpn_cls: 0.1412  loss_rpn_loc: 0.2321  time: 0.6275  data_time: 0.2288  lr: 0.00010989  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:03:12 d2.utils.events]: \u001b[0m eta: 1:14:01  iter: 239  total_loss: 2.139  loss_cls: 0.566  loss_box_reg: 0.7261  loss_mask: 0.4444  loss_rpn_cls: 0.1532  loss_rpn_loc: 0.2483  time: 0.6333  data_time: 0.2467  lr: 0.00011988  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:03:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:03:13 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/04 09:03:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:03:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:03:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:03:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:03:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:03:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0783 s/iter. Eval: 0.0078 s/iter. Total: 0.0867 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 09:03:19 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0783 s/iter. Eval: 0.0086 s/iter. Total: 0.0877 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 09:03:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.996379 (0.086176 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:03:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077727 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:03:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:03:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.07350581859542622\n",
      "\u001b[32m[02/04 09:03:36 d2.utils.events]: \u001b[0m eta: 1:13:49  iter: 259  total_loss: 2.004  loss_cls: 0.4922  loss_box_reg: 0.752  loss_mask: 0.4022  loss_rpn_cls: 0.1123  loss_rpn_loc: 0.2249  time: 0.6332  data_time: 0.1902  lr: 0.00012987  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:03:50 d2.utils.events]: \u001b[0m eta: 1:13:56  iter: 279  total_loss: 1.923  loss_cls: 0.4638  loss_box_reg: 0.7347  loss_mask: 0.3614  loss_rpn_cls: 0.1291  loss_rpn_loc: 0.2174  time: 0.6400  data_time: 0.2739  lr: 0.00013986  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:04:03 d2.utils.events]: \u001b[0m eta: 1:14:07  iter: 299  total_loss: 1.938  loss_cls: 0.5034  loss_box_reg: 0.7523  loss_mask: 0.3842  loss_rpn_cls: 0.1322  loss_rpn_loc: 0.2442  time: 0.6393  data_time: 0.1752  lr: 0.00014985  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:04:16 d2.utils.events]: \u001b[0m eta: 1:13:58  iter: 319  total_loss: 1.827  loss_cls: 0.4272  loss_box_reg: 0.7299  loss_mask: 0.3499  loss_rpn_cls: 0.1257  loss_rpn_loc: 0.221  time: 0.6419  data_time: 0.2356  lr: 0.00015984  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:04:25 d2.utils.events]: \u001b[0m eta: 1:13:21  iter: 339  total_loss: 1.79  loss_cls: 0.3955  loss_box_reg: 0.7061  loss_mask: 0.3486  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.2226  time: 0.6300  data_time: 0.0186  lr: 0.00016983  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:04:39 d2.utils.events]: \u001b[0m eta: 1:13:12  iter: 359  total_loss: 1.754  loss_cls: 0.389  loss_box_reg: 0.6817  loss_mask: 0.3284  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.2265  time: 0.6319  data_time: 0.2130  lr: 0.00017982  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:04:52 d2.utils.events]: \u001b[0m eta: 1:13:19  iter: 379  total_loss: 1.671  loss_cls: 0.3548  loss_box_reg: 0.671  loss_mask: 0.3168  loss_rpn_cls: 0.09937  loss_rpn_loc: 0.1922  time: 0.6353  data_time: 0.2449  lr: 0.00018981  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:05:04 d2.utils.events]: \u001b[0m eta: 1:12:54  iter: 399  total_loss: 1.571  loss_cls: 0.3265  loss_box_reg: 0.6307  loss_mask: 0.3097  loss_rpn_cls: 0.09166  loss_rpn_loc: 0.2096  time: 0.6315  data_time: 0.1253  lr: 0.0001998  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:05:18 d2.utils.events]: \u001b[0m eta: 1:12:54  iter: 419  total_loss: 1.87  loss_cls: 0.3783  loss_box_reg: 0.6736  loss_mask: 0.3382  loss_rpn_cls: 0.1624  loss_rpn_loc: 0.2457  time: 0.6351  data_time: 0.2570  lr: 0.00020979  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:05:30 d2.utils.events]: \u001b[0m eta: 1:12:45  iter: 439  total_loss: 1.733  loss_cls: 0.3782  loss_box_reg: 0.6967  loss_mask: 0.3242  loss_rpn_cls: 0.1354  loss_rpn_loc: 0.2168  time: 0.6343  data_time: 0.1842  lr: 0.00021978  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:05:41 d2.utils.events]: \u001b[0m eta: 1:12:24  iter: 459  total_loss: 1.713  loss_cls: 0.3572  loss_box_reg: 0.6661  loss_mask: 0.3209  loss_rpn_cls: 0.1154  loss_rpn_loc: 0.2276  time: 0.6293  data_time: 0.0936  lr: 0.00022977  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:05:55 d2.utils.events]: \u001b[0m eta: 1:12:19  iter: 479  total_loss: 1.854  loss_cls: 0.4363  loss_box_reg: 0.6838  loss_mask: 0.337  loss_rpn_cls: 0.112  loss_rpn_loc: 0.2255  time: 0.6331  data_time: 0.2644  lr: 0.00023976  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:05:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:05:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:05:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:05:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:05:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:05:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0797 s/iter. Eval: 0.0378 s/iter. Total: 0.1181 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 09:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0814 s/iter. Eval: 0.0503 s/iter. Total: 0.1325 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 09:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0818 s/iter. Eval: 0.0529 s/iter. Total: 0.1354 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 09:06:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.560923 (0.134146 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:06:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.081531 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:06:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:06:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20809179313207277\n",
      "\u001b[32m[02/04 09:06:22 d2.utils.events]: \u001b[0m eta: 1:12:08  iter: 499  total_loss: 1.719  loss_cls: 0.3818  loss_box_reg: 0.6653  loss_mask: 0.3191  loss_rpn_cls: 0.1269  loss_rpn_loc: 0.2009  time: 0.6272  data_time: 0.0653  lr: 0.00024975  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:06:36 d2.utils.events]: \u001b[0m eta: 1:11:59  iter: 519  total_loss: 1.604  loss_cls: 0.3417  loss_box_reg: 0.619  loss_mask: 0.3076  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2105  time: 0.6314  data_time: 0.3083  lr: 0.00025974  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:06:52 d2.utils.events]: \u001b[0m eta: 1:11:55  iter: 539  total_loss: 1.651  loss_cls: 0.3741  loss_box_reg: 0.6742  loss_mask: 0.3162  loss_rpn_cls: 0.09948  loss_rpn_loc: 0.1987  time: 0.6368  data_time: 0.3234  lr: 0.00026973  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:07:05 d2.utils.events]: \u001b[0m eta: 1:11:54  iter: 559  total_loss: 1.582  loss_cls: 0.3538  loss_box_reg: 0.6264  loss_mask: 0.2982  loss_rpn_cls: 0.09848  loss_rpn_loc: 0.1963  time: 0.6376  data_time: 0.2033  lr: 0.00027972  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:07:17 d2.utils.events]: \u001b[0m eta: 1:11:49  iter: 579  total_loss: 1.636  loss_cls: 0.3793  loss_box_reg: 0.6438  loss_mask: 0.3144  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2087  time: 0.6365  data_time: 0.1618  lr: 0.00028971  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:07:28 d2.utils.events]: \u001b[0m eta: 1:11:40  iter: 599  total_loss: 1.612  loss_cls: 0.3579  loss_box_reg: 0.6418  loss_mask: 0.3266  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.2114  time: 0.6332  data_time: 0.0964  lr: 0.0002997  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:07:40 d2.utils.events]: \u001b[0m eta: 1:11:35  iter: 619  total_loss: 1.596  loss_cls: 0.3447  loss_box_reg: 0.618  loss_mask: 0.3097  loss_rpn_cls: 0.08924  loss_rpn_loc: 0.2193  time: 0.6319  data_time: 0.1558  lr: 0.00030969  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:07:54 d2.utils.events]: \u001b[0m eta: 1:11:26  iter: 639  total_loss: 1.611  loss_cls: 0.3494  loss_box_reg: 0.6295  loss_mask: 0.3095  loss_rpn_cls: 0.09712  loss_rpn_loc: 0.2121  time: 0.6337  data_time: 0.2402  lr: 0.00031968  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:08:08 d2.utils.events]: \u001b[0m eta: 1:11:17  iter: 659  total_loss: 1.607  loss_cls: 0.3503  loss_box_reg: 0.6076  loss_mask: 0.313  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.2038  time: 0.6366  data_time: 0.2793  lr: 0.00032967  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:08:21 d2.utils.events]: \u001b[0m eta: 1:11:12  iter: 679  total_loss: 1.683  loss_cls: 0.3717  loss_box_reg: 0.6656  loss_mask: 0.322  loss_rpn_cls: 0.09784  loss_rpn_loc: 0.218  time: 0.6372  data_time: 0.2090  lr: 0.00033966  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:08:34 d2.utils.events]: \u001b[0m eta: 1:11:01  iter: 699  total_loss: 1.625  loss_cls: 0.3523  loss_box_reg: 0.6272  loss_mask: 0.3208  loss_rpn_cls: 0.09889  loss_rpn_loc: 0.2164  time: 0.6374  data_time: 0.2012  lr: 0.00034965  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:08:51 d2.utils.events]: \u001b[0m eta: 1:10:59  iter: 719  total_loss: 1.719  loss_cls: 0.3786  loss_box_reg: 0.6486  loss_mask: 0.3304  loss_rpn_cls: 0.1271  loss_rpn_loc: 0.2191  time: 0.6423  data_time: 0.3486  lr: 0.00035964  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:08:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:08:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:08:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:08:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:08:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:08:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0839 s/iter. Eval: 0.0445 s/iter. Total: 0.1290 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0865 s/iter. Eval: 0.0633 s/iter. Total: 0.1506 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0865 s/iter. Eval: 0.0639 s/iter. Total: 0.1511 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0869 s/iter. Eval: 0.0662 s/iter. Total: 0.1538 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:09:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.891479 (0.154237 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:09:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086930 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:09:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:09:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22814944670380014\n",
      "\u001b[32m[02/04 09:09:22 d2.utils.events]: \u001b[0m eta: 1:10:51  iter: 739  total_loss: 1.58  loss_cls: 0.3441  loss_box_reg: 0.6411  loss_mask: 0.3081  loss_rpn_cls: 0.09506  loss_rpn_loc: 0.2181  time: 0.6405  data_time: 0.1345  lr: 0.00036963  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:09:35 d2.utils.events]: \u001b[0m eta: 1:10:44  iter: 759  total_loss: 1.679  loss_cls: 0.3408  loss_box_reg: 0.617  loss_mask: 0.3271  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.2189  time: 0.6417  data_time: 0.2345  lr: 0.00037962  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:09:47 d2.utils.events]: \u001b[0m eta: 1:10:32  iter: 779  total_loss: 1.64  loss_cls: 0.3525  loss_box_reg: 0.6121  loss_mask: 0.3267  loss_rpn_cls: 0.114  loss_rpn_loc: 0.2254  time: 0.6401  data_time: 0.1472  lr: 0.00038961  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:09:56 d2.utils.events]: \u001b[0m eta: 1:10:09  iter: 799  total_loss: 1.555  loss_cls: 0.3478  loss_box_reg: 0.6181  loss_mask: 0.2954  loss_rpn_cls: 0.07098  loss_rpn_loc: 0.1939  time: 0.6358  data_time: 0.0425  lr: 0.0003996  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:10:10 d2.utils.events]: \u001b[0m eta: 1:10:06  iter: 819  total_loss: 1.589  loss_cls: 0.3599  loss_box_reg: 0.6195  loss_mask: 0.3308  loss_rpn_cls: 0.08832  loss_rpn_loc: 0.2236  time: 0.6372  data_time: 0.2337  lr: 0.00040959  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:10:23 d2.utils.events]: \u001b[0m eta: 1:10:02  iter: 839  total_loss: 1.619  loss_cls: 0.3585  loss_box_reg: 0.5922  loss_mask: 0.3231  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.2175  time: 0.6373  data_time: 0.1979  lr: 0.00041958  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:10:36 d2.utils.events]: \u001b[0m eta: 1:09:55  iter: 859  total_loss: 1.604  loss_cls: 0.3546  loss_box_reg: 0.6099  loss_mask: 0.3087  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.2386  time: 0.6377  data_time: 0.2012  lr: 0.00042957  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:10:47 d2.utils.events]: \u001b[0m eta: 1:09:45  iter: 879  total_loss: 1.57  loss_cls: 0.3468  loss_box_reg: 0.6125  loss_mask: 0.3079  loss_rpn_cls: 0.08514  loss_rpn_loc: 0.209  time: 0.6351  data_time: 0.0873  lr: 0.00043956  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:11:03 d2.utils.events]: \u001b[0m eta: 1:09:38  iter: 899  total_loss: 1.682  loss_cls: 0.3813  loss_box_reg: 0.6102  loss_mask: 0.3188  loss_rpn_cls: 0.1208  loss_rpn_loc: 0.2124  time: 0.6387  data_time: 0.3328  lr: 0.00044955  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:11:14 d2.utils.events]: \u001b[0m eta: 1:09:25  iter: 919  total_loss: 1.42  loss_cls: 0.2961  loss_box_reg: 0.5563  loss_mask: 0.2884  loss_rpn_cls: 0.07743  loss_rpn_loc: 0.193  time: 0.6372  data_time: 0.1380  lr: 0.00045954  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:11:30 d2.utils.events]: \u001b[0m eta: 1:09:13  iter: 939  total_loss: 1.587  loss_cls: 0.3522  loss_box_reg: 0.6197  loss_mask: 0.3218  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.215  time: 0.6403  data_time: 0.3245  lr: 0.00046953  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:11:43 d2.utils.events]: \u001b[0m eta: 1:09:09  iter: 959  total_loss: 1.524  loss_cls: 0.3585  loss_box_reg: 0.599  loss_mask: 0.3051  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.1919  time: 0.6407  data_time: 0.2004  lr: 0.00047952  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:11:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:11:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:11:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:11:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0831 s/iter. Eval: 0.0391 s/iter. Total: 0.1227 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 09:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0857 s/iter. Eval: 0.0623 s/iter. Total: 0.1487 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0007 s/iter. Inference: 0.0859 s/iter. Eval: 0.0636 s/iter. Total: 0.1503 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:12:08 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0007 s/iter. Inference: 0.0857 s/iter. Eval: 0.0643 s/iter. Total: 0.1508 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:12:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.537835 (0.151188 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:12:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085650 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:12:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:12:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24960048350737765\n",
      "\u001b[32m[02/04 09:12:17 d2.utils.events]: \u001b[0m eta: 1:09:01  iter: 979  total_loss: 1.496  loss_cls: 0.3175  loss_box_reg: 0.5647  loss_mask: 0.3047  loss_rpn_cls: 0.09376  loss_rpn_loc: 0.2151  time: 0.6429  data_time: 0.2923  lr: 0.00048951  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:12:32 d2.utils.events]: \u001b[0m eta: 1:08:55  iter: 999  total_loss: 1.765  loss_cls: 0.4145  loss_box_reg: 0.6264  loss_mask: 0.3259  loss_rpn_cls: 0.1269  loss_rpn_loc: 0.2239  time: 0.6449  data_time: 0.2762  lr: 0.0004995  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:12:44 d2.utils.events]: \u001b[0m eta: 1:08:45  iter: 1019  total_loss: 1.532  loss_cls: 0.3501  loss_box_reg: 0.5906  loss_mask: 0.3007  loss_rpn_cls: 0.09577  loss_rpn_loc: 0.1931  time: 0.6447  data_time: 0.2108  lr: 0.0005  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:12:58 d2.utils.events]: \u001b[0m eta: 1:08:37  iter: 1039  total_loss: 1.552  loss_cls: 0.3298  loss_box_reg: 0.5915  loss_mask: 0.3147  loss_rpn_cls: 0.08851  loss_rpn_loc: 0.2086  time: 0.6449  data_time: 0.2229  lr: 0.0005  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:13:07 d2.utils.events]: \u001b[0m eta: 1:08:23  iter: 1059  total_loss: 1.322  loss_cls: 0.2744  loss_box_reg: 0.5546  loss_mask: 0.3011  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.1886  time: 0.6413  data_time: 0.0559  lr: 0.0005  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:13:20 d2.utils.events]: \u001b[0m eta: 1:08:15  iter: 1079  total_loss: 1.592  loss_cls: 0.3455  loss_box_reg: 0.585  loss_mask: 0.3224  loss_rpn_cls: 0.08086  loss_rpn_loc: 0.2127  time: 0.6419  data_time: 0.2553  lr: 0.0005  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:13:32 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 1099  total_loss: 1.51  loss_cls: 0.3308  loss_box_reg: 0.5819  loss_mask: 0.3117  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2085  time: 0.6410  data_time: 0.1867  lr: 0.0005  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:13:45 d2.utils.events]: \u001b[0m eta: 1:07:53  iter: 1119  total_loss: 1.554  loss_cls: 0.3618  loss_box_reg: 0.6151  loss_mask: 0.3099  loss_rpn_cls: 0.07953  loss_rpn_loc: 0.1924  time: 0.6414  data_time: 0.2270  lr: 0.0005  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:13:56 d2.utils.events]: \u001b[0m eta: 1:07:46  iter: 1139  total_loss: 1.524  loss_cls: 0.3382  loss_box_reg: 0.5954  loss_mask: 0.3  loss_rpn_cls: 0.08499  loss_rpn_loc: 0.1888  time: 0.6396  data_time: 0.1230  lr: 0.0005  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:14:10 d2.utils.events]: \u001b[0m eta: 1:07:27  iter: 1159  total_loss: 1.553  loss_cls: 0.3355  loss_box_reg: 0.5807  loss_mask: 0.3148  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.198  time: 0.6405  data_time: 0.2727  lr: 0.0005  max_mem: 6291M\n",
      "\u001b[32m[02/04 09:14:24 d2.utils.events]: \u001b[0m eta: 1:07:14  iter: 1179  total_loss: 1.675  loss_cls: 0.3931  loss_box_reg: 0.6505  loss_mask: 0.3278  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.2359  time: 0.6419  data_time: 0.2959  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:14:38 d2.utils.events]: \u001b[0m eta: 1:07:03  iter: 1199  total_loss: 1.62  loss_cls: 0.3479  loss_box_reg: 0.5922  loss_mask: 0.3163  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.205  time: 0.6426  data_time: 0.2601  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:14:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:14:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:14:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:14:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:14:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:14:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0797 s/iter. Eval: 0.0410 s/iter. Total: 0.1213 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 09:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0825 s/iter. Eval: 0.0616 s/iter. Total: 0.1449 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0827 s/iter. Eval: 0.0637 s/iter. Total: 0.1472 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0007 s/iter. Inference: 0.0826 s/iter. Eval: 0.0627 s/iter. Total: 0.1461 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:15:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.978734 (0.146368 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:15:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.082584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:15:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:15:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2513108612886302\n",
      "\u001b[32m[02/04 09:15:06 d2.utils.events]: \u001b[0m eta: 1:06:44  iter: 1219  total_loss: 1.35  loss_cls: 0.2262  loss_box_reg: 0.5417  loss_mask: 0.3062  loss_rpn_cls: 0.07037  loss_rpn_loc: 0.1883  time: 0.6402  data_time: 0.0897  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:15:20 d2.utils.events]: \u001b[0m eta: 1:06:29  iter: 1239  total_loss: 1.624  loss_cls: 0.3545  loss_box_reg: 0.6068  loss_mask: 0.3151  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2228  time: 0.6408  data_time: 0.2500  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:15:30 d2.utils.events]: \u001b[0m eta: 1:06:16  iter: 1259  total_loss: 1.511  loss_cls: 0.3158  loss_box_reg: 0.5921  loss_mask: 0.31  loss_rpn_cls: 0.07844  loss_rpn_loc: 0.2083  time: 0.6383  data_time: 0.0786  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:15:42 d2.utils.events]: \u001b[0m eta: 1:05:59  iter: 1279  total_loss: 1.539  loss_cls: 0.3488  loss_box_reg: 0.6024  loss_mask: 0.3225  loss_rpn_cls: 0.09075  loss_rpn_loc: 0.2113  time: 0.6380  data_time: 0.1989  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:15:55 d2.utils.events]: \u001b[0m eta: 1:05:50  iter: 1299  total_loss: 1.658  loss_cls: 0.3764  loss_box_reg: 0.6433  loss_mask: 0.323  loss_rpn_cls: 0.09835  loss_rpn_loc: 0.2176  time: 0.6383  data_time: 0.2219  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:16:05 d2.utils.events]: \u001b[0m eta: 1:05:36  iter: 1319  total_loss: 1.526  loss_cls: 0.3231  loss_box_reg: 0.6143  loss_mask: 0.2988  loss_rpn_cls: 0.08051  loss_rpn_loc: 0.1844  time: 0.6362  data_time: 0.0829  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:16:16 d2.utils.events]: \u001b[0m eta: 1:05:22  iter: 1339  total_loss: 1.464  loss_cls: 0.3125  loss_box_reg: 0.5894  loss_mask: 0.29  loss_rpn_cls: 0.07385  loss_rpn_loc: 0.1856  time: 0.6346  data_time: 0.1152  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:16:28 d2.utils.events]: \u001b[0m eta: 1:05:10  iter: 1359  total_loss: 1.651  loss_cls: 0.3697  loss_box_reg: 0.5973  loss_mask: 0.3255  loss_rpn_cls: 0.09445  loss_rpn_loc: 0.1998  time: 0.6339  data_time: 0.1636  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:16:41 d2.utils.events]: \u001b[0m eta: 1:05:00  iter: 1379  total_loss: 1.56  loss_cls: 0.349  loss_box_reg: 0.5867  loss_mask: 0.3064  loss_rpn_cls: 0.09103  loss_rpn_loc: 0.2168  time: 0.6344  data_time: 0.2383  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:16:59 d2.utils.events]: \u001b[0m eta: 1:05:01  iter: 1399  total_loss: 1.594  loss_cls: 0.3908  loss_box_reg: 0.579  loss_mask: 0.3194  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.2229  time: 0.6382  data_time: 0.4427  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:17:10 d2.utils.events]: \u001b[0m eta: 1:04:45  iter: 1419  total_loss: 1.598  loss_cls: 0.3676  loss_box_reg: 0.6001  loss_mask: 0.3046  loss_rpn_cls: 0.09005  loss_rpn_loc: 0.197  time: 0.6372  data_time: 0.1467  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:17:23 d2.utils.events]: \u001b[0m eta: 1:04:34  iter: 1439  total_loss: 1.362  loss_cls: 0.2494  loss_box_reg: 0.5582  loss_mask: 0.3006  loss_rpn_cls: 0.0845  loss_rpn_loc: 0.1916  time: 0.6373  data_time: 0.2155  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:17:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:17:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:17:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:17:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:17:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:17:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0796 s/iter. Eval: 0.0403 s/iter. Total: 0.1205 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 09:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0825 s/iter. Eval: 0.0620 s/iter. Total: 0.1453 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0827 s/iter. Eval: 0.0638 s/iter. Total: 0.1473 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0007 s/iter. Inference: 0.0826 s/iter. Eval: 0.0630 s/iter. Total: 0.1463 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:17:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.061736 (0.147084 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:17:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.082624 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:17:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:17:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2559902530792229\n",
      "\u001b[32m[02/04 09:17:53 d2.utils.events]: \u001b[0m eta: 1:04:30  iter: 1459  total_loss: 1.502  loss_cls: 0.3597  loss_box_reg: 0.5672  loss_mask: 0.3136  loss_rpn_cls: 0.08262  loss_rpn_loc: 0.1946  time: 0.6365  data_time: 0.1537  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:18:07 d2.utils.events]: \u001b[0m eta: 1:04:16  iter: 1479  total_loss: 1.577  loss_cls: 0.3446  loss_box_reg: 0.5985  loss_mask: 0.3248  loss_rpn_cls: 0.09685  loss_rpn_loc: 0.2022  time: 0.6368  data_time: 0.2370  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:18:18 d2.utils.events]: \u001b[0m eta: 1:04:06  iter: 1499  total_loss: 1.508  loss_cls: 0.3356  loss_box_reg: 0.5969  loss_mask: 0.2995  loss_rpn_cls: 0.08729  loss_rpn_loc: 0.2005  time: 0.6362  data_time: 0.1664  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:18:31 d2.utils.events]: \u001b[0m eta: 1:03:47  iter: 1519  total_loss: 1.531  loss_cls: 0.3353  loss_box_reg: 0.5703  loss_mask: 0.2911  loss_rpn_cls: 0.08258  loss_rpn_loc: 0.2053  time: 0.6359  data_time: 0.1950  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:18:41 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 1539  total_loss: 1.366  loss_cls: 0.2951  loss_box_reg: 0.5649  loss_mask: 0.2934  loss_rpn_cls: 0.06488  loss_rpn_loc: 0.1964  time: 0.6342  data_time: 0.0946  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:18:55 d2.utils.events]: \u001b[0m eta: 1:03:13  iter: 1559  total_loss: 1.467  loss_cls: 0.2977  loss_box_reg: 0.5523  loss_mask: 0.2967  loss_rpn_cls: 0.08954  loss_rpn_loc: 0.1836  time: 0.6353  data_time: 0.2937  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:19:06 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 1579  total_loss: 1.517  loss_cls: 0.3382  loss_box_reg: 0.5712  loss_mask: 0.3009  loss_rpn_cls: 0.08886  loss_rpn_loc: 0.2095  time: 0.6338  data_time: 0.0904  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:19:20 d2.utils.events]: \u001b[0m eta: 1:02:46  iter: 1599  total_loss: 1.528  loss_cls: 0.3361  loss_box_reg: 0.5761  loss_mask: 0.2936  loss_rpn_cls: 0.08841  loss_rpn_loc: 0.2131  time: 0.6346  data_time: 0.2656  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:19:29 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 1619  total_loss: 1.565  loss_cls: 0.3571  loss_box_reg: 0.607  loss_mask: 0.3043  loss_rpn_cls: 0.08205  loss_rpn_loc: 0.2057  time: 0.6327  data_time: 0.0656  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:19:46 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 1639  total_loss: 1.503  loss_cls: 0.3498  loss_box_reg: 0.5894  loss_mask: 0.3185  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.2054  time: 0.6351  data_time: 0.3827  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:19:58 d2.utils.events]: \u001b[0m eta: 1:02:07  iter: 1659  total_loss: 1.404  loss_cls: 0.2982  loss_box_reg: 0.5571  loss_mask: 0.3015  loss_rpn_cls: 0.06085  loss_rpn_loc: 0.1879  time: 0.6350  data_time: 0.2046  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:20:09 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 1679  total_loss: 1.612  loss_cls: 0.3703  loss_box_reg: 0.5991  loss_mask: 0.3187  loss_rpn_cls: 0.07736  loss_rpn_loc: 0.215  time: 0.6339  data_time: 0.1185  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:20:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:20:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:20:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:20:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:20:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:20:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:20:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0809 s/iter. Eval: 0.0476 s/iter. Total: 0.1290 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:20:24 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0660 s/iter. Total: 0.1500 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0672 s/iter. Total: 0.1513 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0677 s/iter. Total: 0.1519 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:20:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.701032 (0.152595 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:20:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083500 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:20:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:20:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25250755861896357\n",
      "\u001b[32m[02/04 09:20:40 d2.utils.events]: \u001b[0m eta: 1:01:37  iter: 1699  total_loss: 1.62  loss_cls: 0.3326  loss_box_reg: 0.5959  loss_mask: 0.3157  loss_rpn_cls: 0.09524  loss_rpn_loc: 0.2278  time: 0.6331  data_time: 0.1531  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:20:54 d2.utils.events]: \u001b[0m eta: 1:01:22  iter: 1719  total_loss: 1.499  loss_cls: 0.3396  loss_box_reg: 0.5489  loss_mask: 0.2984  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.197  time: 0.6341  data_time: 0.2893  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:21:06 d2.utils.events]: \u001b[0m eta: 1:01:07  iter: 1739  total_loss: 1.389  loss_cls: 0.304  loss_box_reg: 0.5608  loss_mask: 0.2958  loss_rpn_cls: 0.05171  loss_rpn_loc: 0.1896  time: 0.6334  data_time: 0.1618  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:21:19 d2.utils.events]: \u001b[0m eta: 1:00:52  iter: 1759  total_loss: 1.557  loss_cls: 0.3278  loss_box_reg: 0.6173  loss_mask: 0.3207  loss_rpn_cls: 0.08566  loss_rpn_loc: 0.2073  time: 0.6339  data_time: 0.2531  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:21:33 d2.utils.events]: \u001b[0m eta: 1:00:47  iter: 1779  total_loss: 1.619  loss_cls: 0.3603  loss_box_reg: 0.6006  loss_mask: 0.3292  loss_rpn_cls: 0.09051  loss_rpn_loc: 0.2162  time: 0.6347  data_time: 0.2671  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:21:46 d2.utils.events]: \u001b[0m eta: 1:00:41  iter: 1799  total_loss: 1.423  loss_cls: 0.3396  loss_box_reg: 0.5768  loss_mask: 0.3002  loss_rpn_cls: 0.07251  loss_rpn_loc: 0.2049  time: 0.6349  data_time: 0.2219  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:21:58 d2.utils.events]: \u001b[0m eta: 1:00:24  iter: 1819  total_loss: 1.608  loss_cls: 0.3488  loss_box_reg: 0.5965  loss_mask: 0.3137  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.207  time: 0.6342  data_time: 0.1474  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:22:13 d2.utils.events]: \u001b[0m eta: 1:00:18  iter: 1839  total_loss: 1.605  loss_cls: 0.3508  loss_box_reg: 0.5943  loss_mask: 0.3354  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2072  time: 0.6354  data_time: 0.2950  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:22:23 d2.utils.events]: \u001b[0m eta: 1:00:03  iter: 1859  total_loss: 1.525  loss_cls: 0.305  loss_box_reg: 0.5704  loss_mask: 0.3082  loss_rpn_cls: 0.08739  loss_rpn_loc: 0.2193  time: 0.6344  data_time: 0.1314  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:22:35 d2.utils.events]: \u001b[0m eta: 0:59:51  iter: 1879  total_loss: 1.529  loss_cls: 0.3293  loss_box_reg: 0.5951  loss_mask: 0.3072  loss_rpn_cls: 0.08852  loss_rpn_loc: 0.2194  time: 0.6338  data_time: 0.1680  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:22:46 d2.utils.events]: \u001b[0m eta: 0:59:33  iter: 1899  total_loss: 1.43  loss_cls: 0.3129  loss_box_reg: 0.5777  loss_mask: 0.3095  loss_rpn_cls: 0.07816  loss_rpn_loc: 0.1893  time: 0.6328  data_time: 0.1216  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:23:01 d2.utils.events]: \u001b[0m eta: 0:59:24  iter: 1919  total_loss: 1.561  loss_cls: 0.3626  loss_box_reg: 0.6007  loss_mask: 0.2949  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.2123  time: 0.6341  data_time: 0.3196  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:23:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:23:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:23:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:23:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:23:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:23:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0804 s/iter. Eval: 0.0444 s/iter. Total: 0.1254 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 09:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0649 s/iter. Total: 0.1489 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0668 s/iter. Total: 0.1508 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0666 s/iter. Total: 0.1506 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:23:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.536680 (0.151178 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:23:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083310 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:23:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:23:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26263281151281387\n",
      "\u001b[32m[02/04 09:23:31 d2.utils.events]: \u001b[0m eta: 0:59:02  iter: 1939  total_loss: 1.468  loss_cls: 0.3177  loss_box_reg: 0.5852  loss_mask: 0.2869  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.197  time: 0.6329  data_time: 0.1110  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:23:43 d2.utils.events]: \u001b[0m eta: 0:58:38  iter: 1959  total_loss: 1.373  loss_cls: 0.2935  loss_box_reg: 0.5405  loss_mask: 0.288  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.1796  time: 0.6327  data_time: 0.1940  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:23:55 d2.utils.events]: \u001b[0m eta: 0:58:19  iter: 1979  total_loss: 1.522  loss_cls: 0.3065  loss_box_reg: 0.5689  loss_mask: 0.3062  loss_rpn_cls: 0.07124  loss_rpn_loc: 0.1989  time: 0.6322  data_time: 0.1742  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:24:07 d2.utils.events]: \u001b[0m eta: 0:58:07  iter: 1999  total_loss: 1.573  loss_cls: 0.3521  loss_box_reg: 0.5767  loss_mask: 0.3015  loss_rpn_cls: 0.08353  loss_rpn_loc: 0.1834  time: 0.6319  data_time: 0.1730  lr: 0.0005  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:24:19 d2.utils.events]: \u001b[0m eta: 0:58:00  iter: 2019  total_loss: 1.557  loss_cls: 0.3612  loss_box_reg: 0.5809  loss_mask: 0.3105  loss_rpn_cls: 0.08702  loss_rpn_loc: 0.2129  time: 0.6318  data_time: 0.2045  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:24:34 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 2039  total_loss: 1.685  loss_cls: 0.3801  loss_box_reg: 0.6024  loss_mask: 0.3239  loss_rpn_cls: 0.0956  loss_rpn_loc: 0.2207  time: 0.6332  data_time: 0.3332  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:24:47 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 2059  total_loss: 1.471  loss_cls: 0.319  loss_box_reg: 0.5782  loss_mask: 0.2967  loss_rpn_cls: 0.05497  loss_rpn_loc: 0.1686  time: 0.6331  data_time: 0.1897  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:25:02 d2.utils.events]: \u001b[0m eta: 0:57:46  iter: 2079  total_loss: 1.485  loss_cls: 0.3301  loss_box_reg: 0.5753  loss_mask: 0.3042  loss_rpn_cls: 0.08278  loss_rpn_loc: 0.2101  time: 0.6340  data_time: 0.2998  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:25:13 d2.utils.events]: \u001b[0m eta: 0:57:33  iter: 2099  total_loss: 1.428  loss_cls: 0.3127  loss_box_reg: 0.5405  loss_mask: 0.2939  loss_rpn_cls: 0.07108  loss_rpn_loc: 0.1931  time: 0.6332  data_time: 0.1421  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:25:22 d2.utils.events]: \u001b[0m eta: 0:57:23  iter: 2119  total_loss: 1.456  loss_cls: 0.3058  loss_box_reg: 0.5539  loss_mask: 0.2956  loss_rpn_cls: 0.06035  loss_rpn_loc: 0.2  time: 0.6319  data_time: 0.0862  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:25:35 d2.utils.events]: \u001b[0m eta: 0:57:15  iter: 2139  total_loss: 1.442  loss_cls: 0.3142  loss_box_reg: 0.5628  loss_mask: 0.3165  loss_rpn_cls: 0.08827  loss_rpn_loc: 0.1849  time: 0.6317  data_time: 0.1804  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:25:47 d2.utils.events]: \u001b[0m eta: 0:57:07  iter: 2159  total_loss: 1.564  loss_cls: 0.3517  loss_box_reg: 0.6187  loss_mask: 0.3152  loss_rpn_cls: 0.09976  loss_rpn_loc: 0.2134  time: 0.6315  data_time: 0.1841  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:26:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:26:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:26:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:26:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:26:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:26:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:26:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0465 s/iter. Total: 0.1279 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0655 s/iter. Total: 0.1495 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0665 s/iter. Total: 0.1505 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0684 s/iter. Total: 0.1526 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:26:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.649908 (0.152154 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:26:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083401 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:26:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:26:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.258221020086296\n",
      "\u001b[32m[02/04 09:26:21 d2.utils.events]: \u001b[0m eta: 0:56:58  iter: 2179  total_loss: 1.556  loss_cls: 0.3462  loss_box_reg: 0.5835  loss_mask: 0.3188  loss_rpn_cls: 0.09699  loss_rpn_loc: 0.2137  time: 0.6326  data_time: 0.3075  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:26:32 d2.utils.events]: \u001b[0m eta: 0:56:48  iter: 2199  total_loss: 1.388  loss_cls: 0.3193  loss_box_reg: 0.5606  loss_mask: 0.2904  loss_rpn_cls: 0.07966  loss_rpn_loc: 0.1881  time: 0.6320  data_time: 0.1517  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:26:47 d2.utils.events]: \u001b[0m eta: 0:56:40  iter: 2219  total_loss: 1.524  loss_cls: 0.3361  loss_box_reg: 0.5863  loss_mask: 0.3118  loss_rpn_cls: 0.08431  loss_rpn_loc: 0.1978  time: 0.6328  data_time: 0.3133  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:26:59 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 2239  total_loss: 1.478  loss_cls: 0.3131  loss_box_reg: 0.5742  loss_mask: 0.2964  loss_rpn_cls: 0.08287  loss_rpn_loc: 0.2045  time: 0.6326  data_time: 0.1720  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:27:11 d2.utils.events]: \u001b[0m eta: 0:56:23  iter: 2259  total_loss: 1.544  loss_cls: 0.3306  loss_box_reg: 0.5995  loss_mask: 0.3019  loss_rpn_cls: 0.112  loss_rpn_loc: 0.1978  time: 0.6321  data_time: 0.1654  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:27:22 d2.utils.events]: \u001b[0m eta: 0:56:14  iter: 2279  total_loss: 1.511  loss_cls: 0.3356  loss_box_reg: 0.5668  loss_mask: 0.2991  loss_rpn_cls: 0.06857  loss_rpn_loc: 0.1804  time: 0.6315  data_time: 0.1424  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:27:35 d2.utils.events]: \u001b[0m eta: 0:56:03  iter: 2299  total_loss: 1.481  loss_cls: 0.342  loss_box_reg: 0.5385  loss_mask: 0.2957  loss_rpn_cls: 0.0621  loss_rpn_loc: 0.1916  time: 0.6317  data_time: 0.2279  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:27:47 d2.utils.events]: \u001b[0m eta: 0:55:56  iter: 2319  total_loss: 1.48  loss_cls: 0.3046  loss_box_reg: 0.5774  loss_mask: 0.3142  loss_rpn_cls: 0.06443  loss_rpn_loc: 0.1904  time: 0.6314  data_time: 0.1748  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:28:06 d2.utils.events]: \u001b[0m eta: 0:56:00  iter: 2339  total_loss: 1.535  loss_cls: 0.3309  loss_box_reg: 0.585  loss_mask: 0.3164  loss_rpn_cls: 0.09357  loss_rpn_loc: 0.2098  time: 0.6342  data_time: 0.5124  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:28:19 d2.utils.events]: \u001b[0m eta: 0:55:47  iter: 2359  total_loss: 1.59  loss_cls: 0.3628  loss_box_reg: 0.5846  loss_mask: 0.3144  loss_rpn_cls: 0.09244  loss_rpn_loc: 0.2178  time: 0.6342  data_time: 0.1942  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:28:32 d2.utils.events]: \u001b[0m eta: 0:55:38  iter: 2379  total_loss: 1.487  loss_cls: 0.3278  loss_box_reg: 0.5828  loss_mask: 0.3032  loss_rpn_cls: 0.09668  loss_rpn_loc: 0.1914  time: 0.6343  data_time: 0.2227  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:28:43 d2.utils.events]: \u001b[0m eta: 0:55:22  iter: 2399  total_loss: 1.494  loss_cls: 0.3334  loss_box_reg: 0.5608  loss_mask: 0.3121  loss_rpn_cls: 0.07721  loss_rpn_loc: 0.2017  time: 0.6338  data_time: 0.1645  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:28:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:28:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:28:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:28:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:28:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:28:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0461 s/iter. Total: 0.1275 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0659 s/iter. Total: 0.1500 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0832 s/iter. Eval: 0.0675 s/iter. Total: 0.1516 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0835 s/iter. Eval: 0.0696 s/iter. Total: 0.1540 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:29:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.841442 (0.153806 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:29:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083499 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:29:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:29:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2614501894211878\n",
      "\u001b[32m[02/04 09:29:14 d2.utils.events]: \u001b[0m eta: 0:55:13  iter: 2419  total_loss: 1.521  loss_cls: 0.32  loss_box_reg: 0.5744  loss_mask: 0.3011  loss_rpn_cls: 0.09557  loss_rpn_loc: 0.2037  time: 0.6334  data_time: 0.1554  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:29:29 d2.utils.events]: \u001b[0m eta: 0:55:09  iter: 2439  total_loss: 1.587  loss_cls: 0.3711  loss_box_reg: 0.5962  loss_mask: 0.3081  loss_rpn_cls: 0.09081  loss_rpn_loc: 0.216  time: 0.6340  data_time: 0.2663  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:29:41 d2.utils.events]: \u001b[0m eta: 0:54:56  iter: 2459  total_loss: 1.504  loss_cls: 0.3246  loss_box_reg: 0.5589  loss_mask: 0.3023  loss_rpn_cls: 0.08656  loss_rpn_loc: 0.1964  time: 0.6338  data_time: 0.1891  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:29:53 d2.utils.events]: \u001b[0m eta: 0:54:47  iter: 2479  total_loss: 1.52  loss_cls: 0.3447  loss_box_reg: 0.5844  loss_mask: 0.2942  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.186  time: 0.6335  data_time: 0.1749  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:30:04 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 2499  total_loss: 1.533  loss_cls: 0.3289  loss_box_reg: 0.5666  loss_mask: 0.3063  loss_rpn_cls: 0.06807  loss_rpn_loc: 0.1961  time: 0.6328  data_time: 0.1230  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:30:18 d2.utils.events]: \u001b[0m eta: 0:54:42  iter: 2519  total_loss: 1.447  loss_cls: 0.3302  loss_box_reg: 0.5577  loss_mask: 0.3042  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.1924  time: 0.6333  data_time: 0.2632  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:30:32 d2.utils.events]: \u001b[0m eta: 0:54:34  iter: 2539  total_loss: 1.528  loss_cls: 0.3394  loss_box_reg: 0.5689  loss_mask: 0.3047  loss_rpn_cls: 0.0938  loss_rpn_loc: 0.2139  time: 0.6341  data_time: 0.3082  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:30:43 d2.utils.events]: \u001b[0m eta: 0:54:21  iter: 2559  total_loss: 1.451  loss_cls: 0.3116  loss_box_reg: 0.5708  loss_mask: 0.3031  loss_rpn_cls: 0.0865  loss_rpn_loc: 0.1977  time: 0.6331  data_time: 0.1115  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:30:56 d2.utils.events]: \u001b[0m eta: 0:54:14  iter: 2579  total_loss: 1.541  loss_cls: 0.3323  loss_box_reg: 0.5725  loss_mask: 0.3187  loss_rpn_cls: 0.08584  loss_rpn_loc: 0.2089  time: 0.6336  data_time: 0.2655  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:31:07 d2.utils.events]: \u001b[0m eta: 0:53:56  iter: 2599  total_loss: 1.45  loss_cls: 0.2973  loss_box_reg: 0.5514  loss_mask: 0.2992  loss_rpn_cls: 0.07621  loss_rpn_loc: 0.1845  time: 0.6330  data_time: 0.1428  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:31:21 d2.utils.events]: \u001b[0m eta: 0:53:51  iter: 2619  total_loss: 1.55  loss_cls: 0.3339  loss_box_reg: 0.5907  loss_mask: 0.3205  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1919  time: 0.6334  data_time: 0.2709  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:31:35 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 2639  total_loss: 1.474  loss_cls: 0.3283  loss_box_reg: 0.5778  loss_mask: 0.3073  loss_rpn_cls: 0.07341  loss_rpn_loc: 0.1934  time: 0.6337  data_time: 0.2468  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:31:45 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 2659  total_loss: 1.408  loss_cls: 0.3289  loss_box_reg: 0.5507  loss_mask: 0.2849  loss_rpn_cls: 0.08099  loss_rpn_loc: 0.1899  time: 0.6329  data_time: 0.1248  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:31:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:31:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:31:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:31:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:31:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:31:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0802 s/iter. Eval: 0.0446 s/iter. Total: 0.1254 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 09:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0650 s/iter. Total: 0.1489 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0667 s/iter. Total: 0.1506 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0685 s/iter. Total: 0.1527 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:32:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.695925 (0.152551 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:32:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083340 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:32:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:32:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2672254076499916\n",
      "\u001b[32m[02/04 09:32:17 d2.utils.events]: \u001b[0m eta: 0:53:19  iter: 2679  total_loss: 1.527  loss_cls: 0.3308  loss_box_reg: 0.5872  loss_mask: 0.309  loss_rpn_cls: 0.08909  loss_rpn_loc: 0.2009  time: 0.6327  data_time: 0.1905  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:32:30 d2.utils.events]: \u001b[0m eta: 0:53:11  iter: 2699  total_loss: 1.363  loss_cls: 0.2983  loss_box_reg: 0.5227  loss_mask: 0.2863  loss_rpn_cls: 0.08387  loss_rpn_loc: 0.1787  time: 0.6329  data_time: 0.2364  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:32:42 d2.utils.events]: \u001b[0m eta: 0:52:53  iter: 2719  total_loss: 1.558  loss_cls: 0.3441  loss_box_reg: 0.5909  loss_mask: 0.3194  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.21  time: 0.6325  data_time: 0.1765  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:32:54 d2.utils.events]: \u001b[0m eta: 0:52:48  iter: 2739  total_loss: 1.512  loss_cls: 0.3449  loss_box_reg: 0.6029  loss_mask: 0.3171  loss_rpn_cls: 0.0583  loss_rpn_loc: 0.1984  time: 0.6324  data_time: 0.1858  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:33:06 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 2759  total_loss: 1.541  loss_cls: 0.3322  loss_box_reg: 0.5874  loss_mask: 0.3145  loss_rpn_cls: 0.0895  loss_rpn_loc: 0.1971  time: 0.6321  data_time: 0.1869  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:33:20 d2.utils.events]: \u001b[0m eta: 0:52:26  iter: 2779  total_loss: 1.502  loss_cls: 0.3296  loss_box_reg: 0.5777  loss_mask: 0.3258  loss_rpn_cls: 0.09305  loss_rpn_loc: 0.2008  time: 0.6326  data_time: 0.2766  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:33:32 d2.utils.events]: \u001b[0m eta: 0:52:19  iter: 2799  total_loss: 1.539  loss_cls: 0.3472  loss_box_reg: 0.5648  loss_mask: 0.3151  loss_rpn_cls: 0.09048  loss_rpn_loc: 0.2162  time: 0.6325  data_time: 0.1855  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:33:44 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 2819  total_loss: 1.534  loss_cls: 0.3526  loss_box_reg: 0.6033  loss_mask: 0.309  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.1807  time: 0.6322  data_time: 0.1438  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:33:57 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 2839  total_loss: 1.405  loss_cls: 0.3071  loss_box_reg: 0.576  loss_mask: 0.3003  loss_rpn_cls: 0.07069  loss_rpn_loc: 0.1805  time: 0.6323  data_time: 0.2222  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:34:08 d2.utils.events]: \u001b[0m eta: 0:51:56  iter: 2859  total_loss: 1.462  loss_cls: 0.3166  loss_box_reg: 0.5596  loss_mask: 0.2902  loss_rpn_cls: 0.08738  loss_rpn_loc: 0.1989  time: 0.6317  data_time: 0.1344  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:34:19 d2.utils.events]: \u001b[0m eta: 0:51:44  iter: 2879  total_loss: 1.557  loss_cls: 0.3427  loss_box_reg: 0.6083  loss_mask: 0.3026  loss_rpn_cls: 0.07283  loss_rpn_loc: 0.1925  time: 0.6310  data_time: 0.1265  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:34:30 d2.utils.events]: \u001b[0m eta: 0:51:35  iter: 2899  total_loss: 1.421  loss_cls: 0.3074  loss_box_reg: 0.5614  loss_mask: 0.3009  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.1861  time: 0.6305  data_time: 0.1281  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:34:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:34:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:34:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:34:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:34:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:34:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:34:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0805 s/iter. Eval: 0.0448 s/iter. Total: 0.1259 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 09:34:40 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0652 s/iter. Total: 0.1490 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:34:45 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0664 s/iter. Total: 0.1502 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0663 s/iter. Total: 0.1502 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:34:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.488340 (0.150762 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:34:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083098 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:34:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:34:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2630675328709559\n",
      "\u001b[32m[02/04 09:35:02 d2.utils.events]: \u001b[0m eta: 0:51:33  iter: 2919  total_loss: 1.514  loss_cls: 0.326  loss_box_reg: 0.55  loss_mask: 0.3032  loss_rpn_cls: 0.0874  loss_rpn_loc: 0.201  time: 0.6307  data_time: 0.2281  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:35:16 d2.utils.events]: \u001b[0m eta: 0:51:28  iter: 2939  total_loss: 1.443  loss_cls: 0.3336  loss_box_reg: 0.562  loss_mask: 0.3265  loss_rpn_cls: 0.07538  loss_rpn_loc: 0.186  time: 0.6313  data_time: 0.2763  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:35:27 d2.utils.events]: \u001b[0m eta: 0:51:26  iter: 2959  total_loss: 1.39  loss_cls: 0.2955  loss_box_reg: 0.5654  loss_mask: 0.2989  loss_rpn_cls: 0.05555  loss_rpn_loc: 0.1811  time: 0.6307  data_time: 0.1262  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:35:39 d2.utils.events]: \u001b[0m eta: 0:51:20  iter: 2979  total_loss: 1.349  loss_cls: 0.3026  loss_box_reg: 0.5481  loss_mask: 0.2916  loss_rpn_cls: 0.05645  loss_rpn_loc: 0.1828  time: 0.6303  data_time: 0.1518  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:35:54 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 2999  total_loss: 1.552  loss_cls: 0.3263  loss_box_reg: 0.5588  loss_mask: 0.3256  loss_rpn_cls: 0.07575  loss_rpn_loc: 0.2026  time: 0.6312  data_time: 0.3333  lr: 0.0004  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:36:05 d2.utils.events]: \u001b[0m eta: 0:50:59  iter: 3019  total_loss: 1.453  loss_cls: 0.3113  loss_box_reg: 0.5695  loss_mask: 0.3038  loss_rpn_cls: 0.06469  loss_rpn_loc: 0.205  time: 0.6307  data_time: 0.1219  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:36:16 d2.utils.events]: \u001b[0m eta: 0:50:45  iter: 3039  total_loss: 1.435  loss_cls: 0.3241  loss_box_reg: 0.5488  loss_mask: 0.2928  loss_rpn_cls: 0.07373  loss_rpn_loc: 0.1908  time: 0.6301  data_time: 0.1188  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:36:28 d2.utils.events]: \u001b[0m eta: 0:50:26  iter: 3059  total_loss: 1.428  loss_cls: 0.3125  loss_box_reg: 0.5593  loss_mask: 0.2971  loss_rpn_cls: 0.07741  loss_rpn_loc: 0.1871  time: 0.6298  data_time: 0.1741  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:36:40 d2.utils.events]: \u001b[0m eta: 0:50:18  iter: 3079  total_loss: 1.509  loss_cls: 0.3361  loss_box_reg: 0.5859  loss_mask: 0.3042  loss_rpn_cls: 0.09143  loss_rpn_loc: 0.1975  time: 0.6297  data_time: 0.1852  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:36:54 d2.utils.events]: \u001b[0m eta: 0:50:24  iter: 3099  total_loss: 1.467  loss_cls: 0.3245  loss_box_reg: 0.5425  loss_mask: 0.2955  loss_rpn_cls: 0.0764  loss_rpn_loc: 0.195  time: 0.6301  data_time: 0.2469  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:37:09 d2.utils.events]: \u001b[0m eta: 0:50:24  iter: 3119  total_loss: 1.54  loss_cls: 0.365  loss_box_reg: 0.5922  loss_mask: 0.3064  loss_rpn_cls: 0.0867  loss_rpn_loc: 0.2039  time: 0.6308  data_time: 0.3080  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:37:21 d2.utils.events]: \u001b[0m eta: 0:50:15  iter: 3139  total_loss: 1.513  loss_cls: 0.3448  loss_box_reg: 0.5923  loss_mask: 0.3091  loss_rpn_cls: 0.08638  loss_rpn_loc: 0.2091  time: 0.6308  data_time: 0.2126  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:37:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:37:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:37:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:37:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:37:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:37:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0806 s/iter. Eval: 0.0442 s/iter. Total: 0.1254 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 09:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0652 s/iter. Total: 0.1492 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0669 s/iter. Total: 0.1509 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0689 s/iter. Total: 0.1533 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:37:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.750262 (0.153019 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:37:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083468 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:37:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:37:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2610871618965398\n",
      "\u001b[32m[02/04 09:37:50 d2.utils.events]: \u001b[0m eta: 0:50:01  iter: 3159  total_loss: 1.431  loss_cls: 0.3111  loss_box_reg: 0.5766  loss_mask: 0.2941  loss_rpn_cls: 0.0801  loss_rpn_loc: 0.1915  time: 0.6299  data_time: 0.0634  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:38:00 d2.utils.events]: \u001b[0m eta: 0:49:48  iter: 3179  total_loss: 1.46  loss_cls: 0.3149  loss_box_reg: 0.5703  loss_mask: 0.3137  loss_rpn_cls: 0.06436  loss_rpn_loc: 0.1944  time: 0.6289  data_time: 0.0623  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:38:14 d2.utils.events]: \u001b[0m eta: 0:49:55  iter: 3199  total_loss: 1.476  loss_cls: 0.3404  loss_box_reg: 0.5543  loss_mask: 0.2858  loss_rpn_cls: 0.09517  loss_rpn_loc: 0.187  time: 0.6295  data_time: 0.2799  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:38:27 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 3219  total_loss: 1.417  loss_cls: 0.2977  loss_box_reg: 0.5568  loss_mask: 0.3023  loss_rpn_cls: 0.06043  loss_rpn_loc: 0.1895  time: 0.6295  data_time: 0.2108  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:38:42 d2.utils.events]: \u001b[0m eta: 0:49:44  iter: 3239  total_loss: 1.473  loss_cls: 0.3182  loss_box_reg: 0.5526  loss_mask: 0.3023  loss_rpn_cls: 0.07969  loss_rpn_loc: 0.1917  time: 0.6304  data_time: 0.3291  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:38:55 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 3259  total_loss: 1.457  loss_cls: 0.3225  loss_box_reg: 0.5685  loss_mask: 0.3005  loss_rpn_cls: 0.06157  loss_rpn_loc: 0.1774  time: 0.6306  data_time: 0.2429  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:39:08 d2.utils.events]: \u001b[0m eta: 0:49:29  iter: 3279  total_loss: 1.432  loss_cls: 0.3184  loss_box_reg: 0.564  loss_mask: 0.3093  loss_rpn_cls: 0.07502  loss_rpn_loc: 0.1992  time: 0.6306  data_time: 0.1996  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:39:21 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 3299  total_loss: 1.442  loss_cls: 0.3136  loss_box_reg: 0.5582  loss_mask: 0.2976  loss_rpn_cls: 0.06443  loss_rpn_loc: 0.1978  time: 0.6307  data_time: 0.2135  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:39:34 d2.utils.events]: \u001b[0m eta: 0:49:18  iter: 3319  total_loss: 1.556  loss_cls: 0.3256  loss_box_reg: 0.5981  loss_mask: 0.3083  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.2041  time: 0.6309  data_time: 0.2294  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:39:47 d2.utils.events]: \u001b[0m eta: 0:49:04  iter: 3339  total_loss: 1.427  loss_cls: 0.3046  loss_box_reg: 0.566  loss_mask: 0.3016  loss_rpn_cls: 0.06667  loss_rpn_loc: 0.183  time: 0.6308  data_time: 0.2029  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:39:59 d2.utils.events]: \u001b[0m eta: 0:48:54  iter: 3359  total_loss: 1.44  loss_cls: 0.3151  loss_box_reg: 0.5679  loss_mask: 0.3042  loss_rpn_cls: 0.08248  loss_rpn_loc: 0.1833  time: 0.6306  data_time: 0.1729  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:40:10 d2.utils.events]: \u001b[0m eta: 0:48:42  iter: 3379  total_loss: 1.526  loss_cls: 0.3126  loss_box_reg: 0.5947  loss_mask: 0.3081  loss_rpn_cls: 0.07766  loss_rpn_loc: 0.2101  time: 0.6304  data_time: 0.1714  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:40:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:40:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:40:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:40:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:40:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:40:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:40:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0468 s/iter. Total: 0.1282 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0656 s/iter. Total: 0.1499 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0669 s/iter. Total: 0.1511 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:40:32 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0838 s/iter. Eval: 0.0689 s/iter. Total: 0.1534 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:40:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.805142 (0.153493 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:40:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083825 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:40:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:40:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2622921266749697\n",
      "\u001b[32m[02/04 09:40:40 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 3399  total_loss: 1.469  loss_cls: 0.3338  loss_box_reg: 0.5788  loss_mask: 0.3152  loss_rpn_cls: 0.08165  loss_rpn_loc: 0.1855  time: 0.6298  data_time: 0.1138  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:40:53 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 3419  total_loss: 1.448  loss_cls: 0.3055  loss_box_reg: 0.5692  loss_mask: 0.294  loss_rpn_cls: 0.0683  loss_rpn_loc: 0.195  time: 0.6298  data_time: 0.2123  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:41:08 d2.utils.events]: \u001b[0m eta: 0:48:17  iter: 3439  total_loss: 1.45  loss_cls: 0.3293  loss_box_reg: 0.5435  loss_mask: 0.3073  loss_rpn_cls: 0.09702  loss_rpn_loc: 0.2143  time: 0.6304  data_time: 0.2995  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:41:19 d2.utils.events]: \u001b[0m eta: 0:48:06  iter: 3459  total_loss: 1.537  loss_cls: 0.3255  loss_box_reg: 0.5983  loss_mask: 0.2995  loss_rpn_cls: 0.08428  loss_rpn_loc: 0.1976  time: 0.6301  data_time: 0.1581  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:41:32 d2.utils.events]: \u001b[0m eta: 0:47:55  iter: 3479  total_loss: 1.512  loss_cls: 0.338  loss_box_reg: 0.565  loss_mask: 0.3166  loss_rpn_cls: 0.0715  loss_rpn_loc: 0.1986  time: 0.6300  data_time: 0.2034  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:41:44 d2.utils.events]: \u001b[0m eta: 0:47:47  iter: 3499  total_loss: 1.502  loss_cls: 0.3118  loss_box_reg: 0.548  loss_mask: 0.2937  loss_rpn_cls: 0.08394  loss_rpn_loc: 0.2109  time: 0.6300  data_time: 0.1987  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:41:55 d2.utils.events]: \u001b[0m eta: 0:47:33  iter: 3519  total_loss: 1.487  loss_cls: 0.3057  loss_box_reg: 0.5544  loss_mask: 0.2991  loss_rpn_cls: 0.0745  loss_rpn_loc: 0.1972  time: 0.6296  data_time: 0.1370  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:42:11 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 3539  total_loss: 1.565  loss_cls: 0.363  loss_box_reg: 0.5808  loss_mask: 0.3204  loss_rpn_cls: 0.09639  loss_rpn_loc: 0.2035  time: 0.6304  data_time: 0.3390  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:42:23 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 3559  total_loss: 1.464  loss_cls: 0.3202  loss_box_reg: 0.5522  loss_mask: 0.3094  loss_rpn_cls: 0.06081  loss_rpn_loc: 0.1905  time: 0.6302  data_time: 0.1850  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:42:33 d2.utils.events]: \u001b[0m eta: 0:47:05  iter: 3579  total_loss: 1.388  loss_cls: 0.2864  loss_box_reg: 0.54  loss_mask: 0.2917  loss_rpn_cls: 0.06992  loss_rpn_loc: 0.1845  time: 0.6297  data_time: 0.1328  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:42:45 d2.utils.events]: \u001b[0m eta: 0:47:01  iter: 3599  total_loss: 1.393  loss_cls: 0.3013  loss_box_reg: 0.5625  loss_mask: 0.2947  loss_rpn_cls: 0.06591  loss_rpn_loc: 0.1956  time: 0.6293  data_time: 0.1410  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:42:57 d2.utils.events]: \u001b[0m eta: 0:46:56  iter: 3619  total_loss: 1.561  loss_cls: 0.3113  loss_box_reg: 0.5828  loss_mask: 0.3078  loss_rpn_cls: 0.09032  loss_rpn_loc: 0.208  time: 0.6293  data_time: 0.2069  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:43:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:43:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:43:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:43:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:43:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:43:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0811 s/iter. Eval: 0.0482 s/iter. Total: 0.1299 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:43:11 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0673 s/iter. Total: 0.1515 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0007 s/iter. Inference: 0.0837 s/iter. Eval: 0.0698 s/iter. Total: 0.1543 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0007 s/iter. Inference: 0.0839 s/iter. Eval: 0.0713 s/iter. Total: 0.1560 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 09:43:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.042424 (0.155538 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:43:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083801 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:43:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:43:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26170628762675335\n",
      "\u001b[32m[02/04 09:43:30 d2.utils.events]: \u001b[0m eta: 0:46:43  iter: 3639  total_loss: 1.488  loss_cls: 0.3368  loss_box_reg: 0.5846  loss_mask: 0.3115  loss_rpn_cls: 0.0709  loss_rpn_loc: 0.1972  time: 0.6294  data_time: 0.2268  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:43:42 d2.utils.events]: \u001b[0m eta: 0:46:28  iter: 3659  total_loss: 1.417  loss_cls: 0.327  loss_box_reg: 0.5436  loss_mask: 0.2945  loss_rpn_cls: 0.08423  loss_rpn_loc: 0.1815  time: 0.6292  data_time: 0.1925  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:43:55 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 3679  total_loss: 1.529  loss_cls: 0.3404  loss_box_reg: 0.55  loss_mask: 0.2938  loss_rpn_cls: 0.09109  loss_rpn_loc: 0.1998  time: 0.6293  data_time: 0.2274  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:44:05 d2.utils.events]: \u001b[0m eta: 0:46:21  iter: 3699  total_loss: 1.552  loss_cls: 0.3482  loss_box_reg: 0.5775  loss_mask: 0.2955  loss_rpn_cls: 0.09452  loss_rpn_loc: 0.199  time: 0.6287  data_time: 0.0918  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:44:18 d2.utils.events]: \u001b[0m eta: 0:46:15  iter: 3719  total_loss: 1.588  loss_cls: 0.3649  loss_box_reg: 0.6023  loss_mask: 0.308  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.2255  time: 0.6288  data_time: 0.2120  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:44:31 d2.utils.events]: \u001b[0m eta: 0:46:07  iter: 3739  total_loss: 1.406  loss_cls: 0.2978  loss_box_reg: 0.551  loss_mask: 0.3008  loss_rpn_cls: 0.08718  loss_rpn_loc: 0.1815  time: 0.6289  data_time: 0.2139  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:44:41 d2.utils.events]: \u001b[0m eta: 0:45:58  iter: 3759  total_loss: 1.307  loss_cls: 0.3043  loss_box_reg: 0.5419  loss_mask: 0.2722  loss_rpn_cls: 0.06987  loss_rpn_loc: 0.1815  time: 0.6282  data_time: 0.0798  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:44:56 d2.utils.events]: \u001b[0m eta: 0:45:47  iter: 3779  total_loss: 1.455  loss_cls: 0.3076  loss_box_reg: 0.5744  loss_mask: 0.3139  loss_rpn_cls: 0.06959  loss_rpn_loc: 0.1852  time: 0.6287  data_time: 0.2948  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:45:12 d2.utils.events]: \u001b[0m eta: 0:45:41  iter: 3799  total_loss: 1.548  loss_cls: 0.3431  loss_box_reg: 0.5708  loss_mask: 0.3241  loss_rpn_cls: 0.08895  loss_rpn_loc: 0.2107  time: 0.6297  data_time: 0.3764  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:45:23 d2.utils.events]: \u001b[0m eta: 0:45:27  iter: 3819  total_loss: 1.417  loss_cls: 0.3142  loss_box_reg: 0.563  loss_mask: 0.3102  loss_rpn_cls: 0.06933  loss_rpn_loc: 0.2052  time: 0.6293  data_time: 0.1258  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:45:35 d2.utils.events]: \u001b[0m eta: 0:45:18  iter: 3839  total_loss: 1.392  loss_cls: 0.3129  loss_box_reg: 0.538  loss_mask: 0.2898  loss_rpn_cls: 0.06808  loss_rpn_loc: 0.1862  time: 0.6292  data_time: 0.1982  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:45:49 d2.utils.events]: \u001b[0m eta: 0:45:10  iter: 3859  total_loss: 1.476  loss_cls: 0.3097  loss_box_reg: 0.5455  loss_mask: 0.3016  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.1961  time: 0.6296  data_time: 0.2795  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:45:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:45:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:45:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:45:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:45:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:45:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0803 s/iter. Eval: 0.0433 s/iter. Total: 0.1241 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 09:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0638 s/iter. Total: 0.1478 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0657 s/iter. Total: 0.1497 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0658 s/iter. Total: 0.1498 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:46:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.460031 (0.150518 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:46:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083248 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:46:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:46:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2687795722413112\n",
      "\u001b[32m[02/04 09:46:20 d2.utils.events]: \u001b[0m eta: 0:45:01  iter: 3879  total_loss: 1.439  loss_cls: 0.2928  loss_box_reg: 0.5657  loss_mask: 0.2956  loss_rpn_cls: 0.07669  loss_rpn_loc: 0.2015  time: 0.6294  data_time: 0.1680  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:46:32 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 3899  total_loss: 1.389  loss_cls: 0.3163  loss_box_reg: 0.545  loss_mask: 0.2921  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1802  time: 0.6293  data_time: 0.1863  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:46:44 d2.utils.events]: \u001b[0m eta: 0:44:42  iter: 3919  total_loss: 1.451  loss_cls: 0.2993  loss_box_reg: 0.551  loss_mask: 0.2903  loss_rpn_cls: 0.07099  loss_rpn_loc: 0.1973  time: 0.6290  data_time: 0.1484  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:46:55 d2.utils.events]: \u001b[0m eta: 0:44:29  iter: 3939  total_loss: 1.48  loss_cls: 0.3249  loss_box_reg: 0.5768  loss_mask: 0.295  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.1866  time: 0.6286  data_time: 0.1324  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:47:06 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 3959  total_loss: 1.419  loss_cls: 0.3029  loss_box_reg: 0.5614  loss_mask: 0.3073  loss_rpn_cls: 0.07085  loss_rpn_loc: 0.1908  time: 0.6284  data_time: 0.1709  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:47:17 d2.utils.events]: \u001b[0m eta: 0:44:12  iter: 3979  total_loss: 1.501  loss_cls: 0.3313  loss_box_reg: 0.5787  loss_mask: 0.2933  loss_rpn_cls: 0.07022  loss_rpn_loc: 0.1864  time: 0.6279  data_time: 0.1122  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:47:31 d2.utils.events]: \u001b[0m eta: 0:44:03  iter: 3999  total_loss: 1.44  loss_cls: 0.3193  loss_box_reg: 0.5508  loss_mask: 0.3066  loss_rpn_cls: 0.08196  loss_rpn_loc: 0.1877  time: 0.6283  data_time: 0.2748  lr: 0.00032  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:47:46 d2.utils.events]: \u001b[0m eta: 0:43:58  iter: 4019  total_loss: 1.502  loss_cls: 0.3321  loss_box_reg: 0.5679  loss_mask: 0.3084  loss_rpn_cls: 0.08801  loss_rpn_loc: 0.2186  time: 0.6288  data_time: 0.3074  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:47:58 d2.utils.events]: \u001b[0m eta: 0:43:49  iter: 4039  total_loss: 1.379  loss_cls: 0.3007  loss_box_reg: 0.5462  loss_mask: 0.3027  loss_rpn_cls: 0.07575  loss_rpn_loc: 0.2024  time: 0.6288  data_time: 0.2124  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:48:15 d2.utils.events]: \u001b[0m eta: 0:43:44  iter: 4059  total_loss: 1.585  loss_cls: 0.3417  loss_box_reg: 0.6156  loss_mask: 0.3261  loss_rpn_cls: 0.08729  loss_rpn_loc: 0.2056  time: 0.6297  data_time: 0.3739  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:48:27 d2.utils.events]: \u001b[0m eta: 0:43:32  iter: 4079  total_loss: 1.419  loss_cls: 0.3294  loss_box_reg: 0.5522  loss_mask: 0.2947  loss_rpn_cls: 0.07434  loss_rpn_loc: 0.1873  time: 0.6297  data_time: 0.2129  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:48:39 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 4099  total_loss: 1.454  loss_cls: 0.3195  loss_box_reg: 0.571  loss_mask: 0.2993  loss_rpn_cls: 0.07974  loss_rpn_loc: 0.2005  time: 0.6296  data_time: 0.1933  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:48:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:48:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:48:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:48:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:48:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:48:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0810 s/iter. Eval: 0.0472 s/iter. Total: 0.1289 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0660 s/iter. Total: 0.1499 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0676 s/iter. Total: 0.1516 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0697 s/iter. Total: 0.1540 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:49:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.886240 (0.154192 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:49:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083595 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:49:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:49:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25843190124189913\n",
      "\u001b[32m[02/04 09:49:13 d2.utils.events]: \u001b[0m eta: 0:43:11  iter: 4119  total_loss: 1.442  loss_cls: 0.3185  loss_box_reg: 0.5638  loss_mask: 0.3124  loss_rpn_cls: 0.08471  loss_rpn_loc: 0.1902  time: 0.6300  data_time: 0.2781  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:49:26 d2.utils.events]: \u001b[0m eta: 0:43:01  iter: 4139  total_loss: 1.405  loss_cls: 0.3172  loss_box_reg: 0.5523  loss_mask: 0.2897  loss_rpn_cls: 0.06616  loss_rpn_loc: 0.1847  time: 0.6301  data_time: 0.2246  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:49:38 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 4159  total_loss: 1.408  loss_cls: 0.3196  loss_box_reg: 0.5721  loss_mask: 0.2873  loss_rpn_cls: 0.07567  loss_rpn_loc: 0.1902  time: 0.6300  data_time: 0.1829  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:49:53 d2.utils.events]: \u001b[0m eta: 0:42:48  iter: 4179  total_loss: 1.389  loss_cls: 0.3153  loss_box_reg: 0.5531  loss_mask: 0.3069  loss_rpn_cls: 0.09198  loss_rpn_loc: 0.1684  time: 0.6306  data_time: 0.3143  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:50:04 d2.utils.events]: \u001b[0m eta: 0:42:32  iter: 4199  total_loss: 1.337  loss_cls: 0.2156  loss_box_reg: 0.5584  loss_mask: 0.2931  loss_rpn_cls: 0.0495  loss_rpn_loc: 0.1851  time: 0.6301  data_time: 0.1284  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:50:13 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 4219  total_loss: 1.427  loss_cls: 0.2992  loss_box_reg: 0.5621  loss_mask: 0.2953  loss_rpn_cls: 0.06026  loss_rpn_loc: 0.1791  time: 0.6292  data_time: 0.0299  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:50:26 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 4239  total_loss: 1.439  loss_cls: 0.3273  loss_box_reg: 0.5494  loss_mask: 0.301  loss_rpn_cls: 0.09555  loss_rpn_loc: 0.1972  time: 0.6293  data_time: 0.2272  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:50:39 d2.utils.events]: \u001b[0m eta: 0:42:01  iter: 4259  total_loss: 1.476  loss_cls: 0.31  loss_box_reg: 0.5765  loss_mask: 0.313  loss_rpn_cls: 0.07822  loss_rpn_loc: 0.2002  time: 0.6295  data_time: 0.2507  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:50:51 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 4279  total_loss: 1.601  loss_cls: 0.3626  loss_box_reg: 0.6019  loss_mask: 0.3034  loss_rpn_cls: 0.08649  loss_rpn_loc: 0.2066  time: 0.6294  data_time: 0.1855  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:51:03 d2.utils.events]: \u001b[0m eta: 0:41:39  iter: 4299  total_loss: 1.37  loss_cls: 0.3045  loss_box_reg: 0.5605  loss_mask: 0.2884  loss_rpn_cls: 0.05319  loss_rpn_loc: 0.1719  time: 0.6291  data_time: 0.1567  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:51:16 d2.utils.events]: \u001b[0m eta: 0:41:29  iter: 4319  total_loss: 1.57  loss_cls: 0.3465  loss_box_reg: 0.5861  loss_mask: 0.3188  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.2116  time: 0.6291  data_time: 0.2067  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:51:28 d2.utils.events]: \u001b[0m eta: 0:41:24  iter: 4339  total_loss: 1.485  loss_cls: 0.3249  loss_box_reg: 0.5475  loss_mask: 0.3064  loss_rpn_cls: 0.09808  loss_rpn_loc: 0.1914  time: 0.6292  data_time: 0.2253  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:51:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:51:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:51:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:51:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:51:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:51:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0813 s/iter. Eval: 0.0476 s/iter. Total: 0.1295 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0658 s/iter. Total: 0.1499 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0673 s/iter. Total: 0.1515 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0837 s/iter. Eval: 0.0693 s/iter. Total: 0.1537 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:51:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.839277 (0.153787 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:51:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083683 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:51:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:51:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2656957299035717\n",
      "\u001b[32m[02/04 09:52:02 d2.utils.events]: \u001b[0m eta: 0:41:17  iter: 4359  total_loss: 1.491  loss_cls: 0.31  loss_box_reg: 0.5544  loss_mask: 0.3027  loss_rpn_cls: 0.09579  loss_rpn_loc: 0.2185  time: 0.6295  data_time: 0.2626  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:52:12 d2.utils.events]: \u001b[0m eta: 0:41:05  iter: 4379  total_loss: 1.443  loss_cls: 0.3145  loss_box_reg: 0.5689  loss_mask: 0.2987  loss_rpn_cls: 0.06791  loss_rpn_loc: 0.1881  time: 0.6290  data_time: 0.1005  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:52:26 d2.utils.events]: \u001b[0m eta: 0:40:57  iter: 4399  total_loss: 1.466  loss_cls: 0.3264  loss_box_reg: 0.5606  loss_mask: 0.317  loss_rpn_cls: 0.08226  loss_rpn_loc: 0.2002  time: 0.6293  data_time: 0.2647  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:52:39 d2.utils.events]: \u001b[0m eta: 0:40:46  iter: 4419  total_loss: 1.464  loss_cls: 0.312  loss_box_reg: 0.5676  loss_mask: 0.306  loss_rpn_cls: 0.0777  loss_rpn_loc: 0.1929  time: 0.6294  data_time: 0.2202  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:52:53 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 4439  total_loss: 1.61  loss_cls: 0.3512  loss_box_reg: 0.5959  loss_mask: 0.3029  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.2128  time: 0.6296  data_time: 0.2471  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:53:07 d2.utils.events]: \u001b[0m eta: 0:40:36  iter: 4459  total_loss: 1.397  loss_cls: 0.2917  loss_box_reg: 0.5672  loss_mask: 0.2999  loss_rpn_cls: 0.06936  loss_rpn_loc: 0.1964  time: 0.6299  data_time: 0.2596  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:53:19 d2.utils.events]: \u001b[0m eta: 0:40:28  iter: 4479  total_loss: 1.392  loss_cls: 0.2936  loss_box_reg: 0.5669  loss_mask: 0.2968  loss_rpn_cls: 0.05374  loss_rpn_loc: 0.1753  time: 0.6298  data_time: 0.1904  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:53:32 d2.utils.events]: \u001b[0m eta: 0:40:19  iter: 4499  total_loss: 1.358  loss_cls: 0.2749  loss_box_reg: 0.5313  loss_mask: 0.29  loss_rpn_cls: 0.04978  loss_rpn_loc: 0.1837  time: 0.6300  data_time: 0.2570  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:53:42 d2.utils.events]: \u001b[0m eta: 0:40:07  iter: 4519  total_loss: 1.422  loss_cls: 0.3215  loss_box_reg: 0.5798  loss_mask: 0.2952  loss_rpn_cls: 0.07191  loss_rpn_loc: 0.184  time: 0.6294  data_time: 0.0719  lr: 0.000256  max_mem: 6372M\n",
      "\u001b[32m[02/04 09:53:56 d2.utils.events]: \u001b[0m eta: 0:39:55  iter: 4539  total_loss: 1.338  loss_cls: 0.2996  loss_box_reg: 0.5326  loss_mask: 0.2886  loss_rpn_cls: 0.05039  loss_rpn_loc: 0.198  time: 0.6297  data_time: 0.2670  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:54:10 d2.utils.events]: \u001b[0m eta: 0:39:52  iter: 4559  total_loss: 1.528  loss_cls: 0.3493  loss_box_reg: 0.5804  loss_mask: 0.3039  loss_rpn_cls: 0.07383  loss_rpn_loc: 0.2027  time: 0.6299  data_time: 0.2335  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:54:21 d2.utils.events]: \u001b[0m eta: 0:39:46  iter: 4579  total_loss: 1.451  loss_cls: 0.3294  loss_box_reg: 0.5393  loss_mask: 0.3007  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.2041  time: 0.6297  data_time: 0.1616  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:54:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:54:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:54:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:54:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:54:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:54:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:54:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0466 s/iter. Total: 0.1280 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:54:39 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0654 s/iter. Total: 0.1492 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:54:44 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0667 s/iter. Total: 0.1507 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:54:49 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0834 s/iter. Eval: 0.0688 s/iter. Total: 0.1530 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:54:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.771677 (0.153204 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:54:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083582 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:54:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:54:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2696141294477152\n",
      "\u001b[32m[02/04 09:54:52 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 4599  total_loss: 1.459  loss_cls: 0.3162  loss_box_reg: 0.5779  loss_mask: 0.2975  loss_rpn_cls: 0.05651  loss_rpn_loc: 0.1778  time: 0.6294  data_time: 0.1538  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:55:04 d2.utils.events]: \u001b[0m eta: 0:39:28  iter: 4619  total_loss: 1.471  loss_cls: 0.3176  loss_box_reg: 0.5753  loss_mask: 0.307  loss_rpn_cls: 0.08202  loss_rpn_loc: 0.1898  time: 0.6293  data_time: 0.1780  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:55:16 d2.utils.events]: \u001b[0m eta: 0:39:21  iter: 4639  total_loss: 1.536  loss_cls: 0.3285  loss_box_reg: 0.5785  loss_mask: 0.3099  loss_rpn_cls: 0.08065  loss_rpn_loc: 0.1994  time: 0.6292  data_time: 0.1719  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:55:28 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 4659  total_loss: 1.511  loss_cls: 0.3286  loss_box_reg: 0.5783  loss_mask: 0.2987  loss_rpn_cls: 0.08429  loss_rpn_loc: 0.1971  time: 0.6290  data_time: 0.1767  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:55:40 d2.utils.events]: \u001b[0m eta: 0:39:05  iter: 4679  total_loss: 1.512  loss_cls: 0.3365  loss_box_reg: 0.5529  loss_mask: 0.3089  loss_rpn_cls: 0.07917  loss_rpn_loc: 0.2165  time: 0.6289  data_time: 0.1642  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:55:51 d2.utils.events]: \u001b[0m eta: 0:38:56  iter: 4699  total_loss: 1.411  loss_cls: 0.3202  loss_box_reg: 0.5429  loss_mask: 0.2796  loss_rpn_cls: 0.077  loss_rpn_loc: 0.1915  time: 0.6286  data_time: 0.1334  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:56:03 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 4719  total_loss: 1.481  loss_cls: 0.3221  loss_box_reg: 0.5673  loss_mask: 0.3054  loss_rpn_cls: 0.06428  loss_rpn_loc: 0.1886  time: 0.6284  data_time: 0.1532  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:56:13 d2.utils.events]: \u001b[0m eta: 0:38:37  iter: 4739  total_loss: 1.348  loss_cls: 0.2911  loss_box_reg: 0.5289  loss_mask: 0.2874  loss_rpn_cls: 0.05113  loss_rpn_loc: 0.185  time: 0.6279  data_time: 0.1050  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:56:25 d2.utils.events]: \u001b[0m eta: 0:38:30  iter: 4759  total_loss: 1.566  loss_cls: 0.3621  loss_box_reg: 0.5843  loss_mask: 0.3047  loss_rpn_cls: 0.09785  loss_rpn_loc: 0.1976  time: 0.6279  data_time: 0.1951  lr: 0.000256  max_mem: 6469M\n",
      "\u001b[32m[02/04 09:56:39 d2.utils.events]: \u001b[0m eta: 0:38:20  iter: 4779  total_loss: 1.305  loss_cls: 0.2243  loss_box_reg: 0.5326  loss_mask: 0.2914  loss_rpn_cls: 0.04391  loss_rpn_loc: 0.1731  time: 0.6280  data_time: 0.2540  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:56:54 d2.utils.events]: \u001b[0m eta: 0:38:10  iter: 4799  total_loss: 1.476  loss_cls: 0.3163  loss_box_reg: 0.5634  loss_mask: 0.3076  loss_rpn_cls: 0.08674  loss_rpn_loc: 0.2026  time: 0.6285  data_time: 0.3041  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:57:06 d2.utils.events]: \u001b[0m eta: 0:38:02  iter: 4819  total_loss: 1.486  loss_cls: 0.3179  loss_box_reg: 0.5655  loss_mask: 0.2975  loss_rpn_cls: 0.09182  loss_rpn_loc: 0.1927  time: 0.6286  data_time: 0.2258  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:57:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:57:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 09:57:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 09:57:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 09:57:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 09:57:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 09:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0807 s/iter. Eval: 0.0477 s/iter. Total: 0.1290 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 09:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0668 s/iter. Total: 0.1509 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 09:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0681 s/iter. Total: 0.1523 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 09:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0836 s/iter. Eval: 0.0702 s/iter. Total: 0.1546 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 09:57:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.918097 (0.154466 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:57:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083608 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 09:57:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 09:57:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2696903885820585\n",
      "\u001b[32m[02/04 09:57:39 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 4839  total_loss: 1.531  loss_cls: 0.3424  loss_box_reg: 0.567  loss_mask: 0.2992  loss_rpn_cls: 0.07374  loss_rpn_loc: 0.1832  time: 0.6287  data_time: 0.2496  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:57:52 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 4859  total_loss: 1.451  loss_cls: 0.3041  loss_box_reg: 0.5759  loss_mask: 0.3001  loss_rpn_cls: 0.09059  loss_rpn_loc: 0.1968  time: 0.6288  data_time: 0.2143  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:58:04 d2.utils.events]: \u001b[0m eta: 0:37:37  iter: 4879  total_loss: 1.458  loss_cls: 0.3228  loss_box_reg: 0.5737  loss_mask: 0.2893  loss_rpn_cls: 0.07392  loss_rpn_loc: 0.2019  time: 0.6287  data_time: 0.1749  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:58:14 d2.utils.events]: \u001b[0m eta: 0:37:28  iter: 4899  total_loss: 1.397  loss_cls: 0.3128  loss_box_reg: 0.5526  loss_mask: 0.2781  loss_rpn_cls: 0.07209  loss_rpn_loc: 0.1796  time: 0.6280  data_time: 0.0520  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:58:25 d2.utils.events]: \u001b[0m eta: 0:37:19  iter: 4919  total_loss: 1.256  loss_cls: 0.2522  loss_box_reg: 0.5174  loss_mask: 0.287  loss_rpn_cls: 0.05589  loss_rpn_loc: 0.1715  time: 0.6277  data_time: 0.1411  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:58:38 d2.utils.events]: \u001b[0m eta: 0:37:11  iter: 4939  total_loss: 1.536  loss_cls: 0.3489  loss_box_reg: 0.6093  loss_mask: 0.3076  loss_rpn_cls: 0.07536  loss_rpn_loc: 0.2046  time: 0.6279  data_time: 0.2459  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:58:52 d2.utils.events]: \u001b[0m eta: 0:37:05  iter: 4959  total_loss: 1.509  loss_cls: 0.333  loss_box_reg: 0.5548  loss_mask: 0.3108  loss_rpn_cls: 0.08486  loss_rpn_loc: 0.2122  time: 0.6281  data_time: 0.2475  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:59:02 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 4979  total_loss: 1.435  loss_cls: 0.3291  loss_box_reg: 0.5437  loss_mask: 0.3028  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.1656  time: 0.6275  data_time: 0.0763  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:59:16 d2.utils.events]: \u001b[0m eta: 0:36:48  iter: 4999  total_loss: 1.274  loss_cls: 0.2957  loss_box_reg: 0.5124  loss_mask: 0.2908  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.1798  time: 0.6279  data_time: 0.3055  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:59:28 d2.utils.events]: \u001b[0m eta: 0:36:37  iter: 5019  total_loss: 1.367  loss_cls: 0.2807  loss_box_reg: 0.5552  loss_mask: 0.3043  loss_rpn_cls: 0.07429  loss_rpn_loc: 0.1934  time: 0.6278  data_time: 0.1908  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:59:42 d2.utils.events]: \u001b[0m eta: 0:36:28  iter: 5039  total_loss: 1.435  loss_cls: 0.2968  loss_box_reg: 0.5136  loss_mask: 0.2983  loss_rpn_cls: 0.07962  loss_rpn_loc: 0.1883  time: 0.6282  data_time: 0.2832  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 09:59:55 d2.utils.events]: \u001b[0m eta: 0:36:19  iter: 5059  total_loss: 1.515  loss_cls: 0.327  loss_box_reg: 0.5594  loss_mask: 0.2904  loss_rpn_cls: 0.07695  loss_rpn_loc: 0.1914  time: 0.6282  data_time: 0.2207  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:00:06 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 5079  total_loss: 1.387  loss_cls: 0.2733  loss_box_reg: 0.5446  loss_mask: 0.3032  loss_rpn_cls: 0.07444  loss_rpn_loc: 0.1836  time: 0.6278  data_time: 0.1120  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:00:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:00:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:00:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:00:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:00:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:00:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0806 s/iter. Eval: 0.0455 s/iter. Total: 0.1266 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 10:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0656 s/iter. Total: 0.1494 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0669 s/iter. Total: 0.1507 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0691 s/iter. Total: 0.1532 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 10:00:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.770557 (0.153194 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:00:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083336 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:00:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:00:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2709522761542104\n",
      "\u001b[32m[02/04 10:00:39 d2.utils.events]: \u001b[0m eta: 0:36:02  iter: 5099  total_loss: 1.615  loss_cls: 0.3652  loss_box_reg: 0.5918  loss_mask: 0.3206  loss_rpn_cls: 0.09424  loss_rpn_loc: 0.2127  time: 0.6279  data_time: 0.2278  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:00:49 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 5119  total_loss: 1.423  loss_cls: 0.3207  loss_box_reg: 0.5499  loss_mask: 0.293  loss_rpn_cls: 0.07244  loss_rpn_loc: 0.1887  time: 0.6275  data_time: 0.1021  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:01:01 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 5139  total_loss: 1.421  loss_cls: 0.3007  loss_box_reg: 0.5476  loss_mask: 0.3017  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.1891  time: 0.6275  data_time: 0.1874  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:01:14 d2.utils.events]: \u001b[0m eta: 0:35:35  iter: 5159  total_loss: 1.511  loss_cls: 0.3292  loss_box_reg: 0.5719  loss_mask: 0.3051  loss_rpn_cls: 0.08528  loss_rpn_loc: 0.2026  time: 0.6275  data_time: 0.2068  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:01:26 d2.utils.events]: \u001b[0m eta: 0:35:24  iter: 5179  total_loss: 1.371  loss_cls: 0.2917  loss_box_reg: 0.5586  loss_mask: 0.2922  loss_rpn_cls: 0.07497  loss_rpn_loc: 0.1792  time: 0.6274  data_time: 0.1842  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:01:39 d2.utils.events]: \u001b[0m eta: 0:35:18  iter: 5199  total_loss: 1.42  loss_cls: 0.3194  loss_box_reg: 0.5555  loss_mask: 0.3002  loss_rpn_cls: 0.09393  loss_rpn_loc: 0.1991  time: 0.6275  data_time: 0.2184  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:01:50 d2.utils.events]: \u001b[0m eta: 0:35:11  iter: 5219  total_loss: 1.563  loss_cls: 0.3596  loss_box_reg: 0.5847  loss_mask: 0.311  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.2016  time: 0.6272  data_time: 0.1362  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:02:02 d2.utils.events]: \u001b[0m eta: 0:35:01  iter: 5239  total_loss: 1.439  loss_cls: 0.3195  loss_box_reg: 0.561  loss_mask: 0.3171  loss_rpn_cls: 0.08711  loss_rpn_loc: 0.1881  time: 0.6271  data_time: 0.1774  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:02:19 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 5259  total_loss: 1.518  loss_cls: 0.3463  loss_box_reg: 0.5412  loss_mask: 0.3033  loss_rpn_cls: 0.08213  loss_rpn_loc: 0.2033  time: 0.6279  data_time: 0.4126  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:02:32 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 5279  total_loss: 1.413  loss_cls: 0.2869  loss_box_reg: 0.557  loss_mask: 0.3073  loss_rpn_cls: 0.04604  loss_rpn_loc: 0.1825  time: 0.6279  data_time: 0.2064  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:02:45 d2.utils.events]: \u001b[0m eta: 0:34:37  iter: 5299  total_loss: 1.456  loss_cls: 0.3354  loss_box_reg: 0.5235  loss_mask: 0.2903  loss_rpn_cls: 0.08699  loss_rpn_loc: 0.1814  time: 0.6281  data_time: 0.2361  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:02:56 d2.utils.events]: \u001b[0m eta: 0:34:26  iter: 5319  total_loss: 1.524  loss_cls: 0.3404  loss_box_reg: 0.5525  loss_mask: 0.3172  loss_rpn_cls: 0.0876  loss_rpn_loc: 0.2097  time: 0.6278  data_time: 0.1568  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:02:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:02:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:02:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:02:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:02:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:02:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:03:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0805 s/iter. Eval: 0.0457 s/iter. Total: 0.1268 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 10:03:06 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0652 s/iter. Total: 0.1490 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:03:11 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0668 s/iter. Total: 0.1507 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0833 s/iter. Eval: 0.0687 s/iter. Total: 0.1528 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 10:03:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.718595 (0.152747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:03:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083329 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:03:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:03:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2666715632000968\n",
      "\u001b[32m[02/04 10:03:27 d2.utils.events]: \u001b[0m eta: 0:34:16  iter: 5339  total_loss: 1.41  loss_cls: 0.2856  loss_box_reg: 0.553  loss_mask: 0.3074  loss_rpn_cls: 0.05987  loss_rpn_loc: 0.1769  time: 0.6275  data_time: 0.1280  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:03:40 d2.utils.events]: \u001b[0m eta: 0:34:07  iter: 5359  total_loss: 1.423  loss_cls: 0.332  loss_box_reg: 0.5621  loss_mask: 0.3059  loss_rpn_cls: 0.06173  loss_rpn_loc: 0.1768  time: 0.6277  data_time: 0.2570  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:03:54 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 5379  total_loss: 1.32  loss_cls: 0.3026  loss_box_reg: 0.5236  loss_mask: 0.2911  loss_rpn_cls: 0.0741  loss_rpn_loc: 0.1821  time: 0.6279  data_time: 0.2679  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:04:05 d2.utils.events]: \u001b[0m eta: 0:33:52  iter: 5399  total_loss: 1.426  loss_cls: 0.3143  loss_box_reg: 0.5605  loss_mask: 0.2997  loss_rpn_cls: 0.06266  loss_rpn_loc: 0.1916  time: 0.6277  data_time: 0.1540  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:04:17 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 5419  total_loss: 1.425  loss_cls: 0.3084  loss_box_reg: 0.5566  loss_mask: 0.301  loss_rpn_cls: 0.07091  loss_rpn_loc: 0.1811  time: 0.6275  data_time: 0.1537  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:04:31 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 5439  total_loss: 1.474  loss_cls: 0.3371  loss_box_reg: 0.5719  loss_mask: 0.297  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.2031  time: 0.6278  data_time: 0.2767  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:04:43 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 5459  total_loss: 1.528  loss_cls: 0.341  loss_box_reg: 0.5936  loss_mask: 0.3093  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.2092  time: 0.6277  data_time: 0.1839  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:04:59 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 5479  total_loss: 1.49  loss_cls: 0.3508  loss_box_reg: 0.5632  loss_mask: 0.306  loss_rpn_cls: 0.08822  loss_rpn_loc: 0.1834  time: 0.6283  data_time: 0.3644  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:05:11 d2.utils.events]: \u001b[0m eta: 0:33:06  iter: 5499  total_loss: 1.453  loss_cls: 0.3358  loss_box_reg: 0.5575  loss_mask: 0.3005  loss_rpn_cls: 0.07544  loss_rpn_loc: 0.1991  time: 0.6282  data_time: 0.1599  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:05:27 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 5519  total_loss: 1.491  loss_cls: 0.3285  loss_box_reg: 0.5405  loss_mask: 0.3065  loss_rpn_cls: 0.09611  loss_rpn_loc: 0.207  time: 0.6288  data_time: 0.3738  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:05:39 d2.utils.events]: \u001b[0m eta: 0:32:51  iter: 5539  total_loss: 1.43  loss_cls: 0.2964  loss_box_reg: 0.5623  loss_mask: 0.2997  loss_rpn_cls: 0.06781  loss_rpn_loc: 0.2054  time: 0.6287  data_time: 0.1821  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:05:51 d2.utils.events]: \u001b[0m eta: 0:32:40  iter: 5559  total_loss: 1.354  loss_cls: 0.2957  loss_box_reg: 0.5295  loss_mask: 0.3003  loss_rpn_cls: 0.05847  loss_rpn_loc: 0.1817  time: 0.6287  data_time: 0.1993  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:05:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:05:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:05:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:05:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:05:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:05:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:05:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0805 s/iter. Eval: 0.0454 s/iter. Total: 0.1265 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 10:06:03 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0649 s/iter. Total: 0.1488 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0663 s/iter. Total: 0.1501 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:06:13 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0833 s/iter. Eval: 0.0687 s/iter. Total: 0.1528 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 10:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.690015 (0.152500 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083254 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:06:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:06:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2706881427054627\n",
      "\u001b[32m[02/04 10:06:26 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 5579  total_loss: 1.388  loss_cls: 0.2941  loss_box_reg: 0.5414  loss_mask: 0.3117  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.184  time: 0.6291  data_time: 0.3337  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:06:39 d2.utils.events]: \u001b[0m eta: 0:32:24  iter: 5599  total_loss: 1.366  loss_cls: 0.3023  loss_box_reg: 0.5606  loss_mask: 0.2906  loss_rpn_cls: 0.06176  loss_rpn_loc: 0.1868  time: 0.6292  data_time: 0.2253  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:06:50 d2.utils.events]: \u001b[0m eta: 0:32:13  iter: 5619  total_loss: 1.387  loss_cls: 0.3155  loss_box_reg: 0.5422  loss_mask: 0.3036  loss_rpn_cls: 0.07194  loss_rpn_loc: 0.1747  time: 0.6290  data_time: 0.1585  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:07:06 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 5639  total_loss: 1.395  loss_cls: 0.321  loss_box_reg: 0.5601  loss_mask: 0.3133  loss_rpn_cls: 0.07093  loss_rpn_loc: 0.191  time: 0.6297  data_time: 0.3671  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:07:19 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 5659  total_loss: 1.465  loss_cls: 0.3309  loss_box_reg: 0.5577  loss_mask: 0.3049  loss_rpn_cls: 0.08438  loss_rpn_loc: 0.1929  time: 0.6296  data_time: 0.1809  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:07:30 d2.utils.events]: \u001b[0m eta: 0:31:45  iter: 5679  total_loss: 1.399  loss_cls: 0.315  loss_box_reg: 0.5327  loss_mask: 0.2988  loss_rpn_cls: 0.06588  loss_rpn_loc: 0.1731  time: 0.6294  data_time: 0.1627  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:07:44 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 5699  total_loss: 1.43  loss_cls: 0.3268  loss_box_reg: 0.5556  loss_mask: 0.2919  loss_rpn_cls: 0.07815  loss_rpn_loc: 0.1917  time: 0.6295  data_time: 0.2510  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:07:56 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 5719  total_loss: 1.449  loss_cls: 0.3183  loss_box_reg: 0.5429  loss_mask: 0.2958  loss_rpn_cls: 0.08585  loss_rpn_loc: 0.1671  time: 0.6295  data_time: 0.1925  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:08:09 d2.utils.events]: \u001b[0m eta: 0:31:24  iter: 5739  total_loss: 1.494  loss_cls: 0.337  loss_box_reg: 0.5729  loss_mask: 0.3077  loss_rpn_cls: 0.08944  loss_rpn_loc: 0.1965  time: 0.6296  data_time: 0.2221  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:08:22 d2.utils.events]: \u001b[0m eta: 0:31:13  iter: 5759  total_loss: 1.469  loss_cls: 0.3275  loss_box_reg: 0.5718  loss_mask: 0.3059  loss_rpn_cls: 0.06375  loss_rpn_loc: 0.1803  time: 0.6297  data_time: 0.2598  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:08:32 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 5779  total_loss: 1.361  loss_cls: 0.2953  loss_box_reg: 0.5287  loss_mask: 0.287  loss_rpn_cls: 0.07966  loss_rpn_loc: 0.1829  time: 0.6293  data_time: 0.0794  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:08:46 d2.utils.events]: \u001b[0m eta: 0:30:52  iter: 5799  total_loss: 1.456  loss_cls: 0.3137  loss_box_reg: 0.5281  loss_mask: 0.3046  loss_rpn_cls: 0.07905  loss_rpn_loc: 0.1923  time: 0.6294  data_time: 0.2430  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:08:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:08:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:08:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:08:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:08:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:08:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0806 s/iter. Eval: 0.0465 s/iter. Total: 0.1277 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 10:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0660 s/iter. Total: 0.1499 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:09:03 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0833 s/iter. Eval: 0.0677 s/iter. Total: 0.1517 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0835 s/iter. Eval: 0.0699 s/iter. Total: 0.1542 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 10:09:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.854779 (0.153921 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:09:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083485 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:09:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:09:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2650337417449297\n",
      "\u001b[32m[02/04 10:09:18 d2.utils.events]: \u001b[0m eta: 0:30:44  iter: 5819  total_loss: 1.527  loss_cls: 0.3163  loss_box_reg: 0.5663  loss_mask: 0.3064  loss_rpn_cls: 0.09183  loss_rpn_loc: 0.2042  time: 0.6294  data_time: 0.2156  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:09:30 d2.utils.events]: \u001b[0m eta: 0:30:34  iter: 5839  total_loss: 1.317  loss_cls: 0.2939  loss_box_reg: 0.5142  loss_mask: 0.2816  loss_rpn_cls: 0.07144  loss_rpn_loc: 0.1713  time: 0.6293  data_time: 0.1867  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:09:40 d2.utils.events]: \u001b[0m eta: 0:30:21  iter: 5859  total_loss: 1.379  loss_cls: 0.2775  loss_box_reg: 0.5578  loss_mask: 0.2863  loss_rpn_cls: 0.05942  loss_rpn_loc: 0.1815  time: 0.6288  data_time: 0.0813  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:09:55 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 5879  total_loss: 1.458  loss_cls: 0.3102  loss_box_reg: 0.5656  loss_mask: 0.3129  loss_rpn_cls: 0.08521  loss_rpn_loc: 0.1978  time: 0.6292  data_time: 0.3210  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:10:08 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 5899  total_loss: 1.422  loss_cls: 0.3093  loss_box_reg: 0.5461  loss_mask: 0.2936  loss_rpn_cls: 0.07098  loss_rpn_loc: 0.1827  time: 0.6293  data_time: 0.2446  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:10:20 d2.utils.events]: \u001b[0m eta: 0:29:54  iter: 5919  total_loss: 1.464  loss_cls: 0.3032  loss_box_reg: 0.5607  loss_mask: 0.3092  loss_rpn_cls: 0.0706  loss_rpn_loc: 0.1976  time: 0.6293  data_time: 0.1919  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:10:34 d2.utils.events]: \u001b[0m eta: 0:29:44  iter: 5939  total_loss: 1.491  loss_cls: 0.3346  loss_box_reg: 0.5575  loss_mask: 0.3097  loss_rpn_cls: 0.09893  loss_rpn_loc: 0.2038  time: 0.6295  data_time: 0.2729  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:10:46 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 5959  total_loss: 1.418  loss_cls: 0.3147  loss_box_reg: 0.5546  loss_mask: 0.2987  loss_rpn_cls: 0.07372  loss_rpn_loc: 0.1802  time: 0.6294  data_time: 0.1676  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:11:00 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 5979  total_loss: 1.536  loss_cls: 0.3184  loss_box_reg: 0.5544  loss_mask: 0.3124  loss_rpn_cls: 0.08658  loss_rpn_loc: 0.2076  time: 0.6296  data_time: 0.2791  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:11:13 d2.utils.events]: \u001b[0m eta: 0:29:17  iter: 5999  total_loss: 1.504  loss_cls: 0.3212  loss_box_reg: 0.5697  loss_mask: 0.314  loss_rpn_cls: 0.09911  loss_rpn_loc: 0.1938  time: 0.6296  data_time: 0.1976  lr: 0.0002048  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:11:23 d2.utils.events]: \u001b[0m eta: 0:29:09  iter: 6019  total_loss: 1.487  loss_cls: 0.3198  loss_box_reg: 0.5475  loss_mask: 0.298  loss_rpn_cls: 0.08144  loss_rpn_loc: 0.2069  time: 0.6292  data_time: 0.0942  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:11:36 d2.utils.events]: \u001b[0m eta: 0:29:02  iter: 6039  total_loss: 1.5  loss_cls: 0.3422  loss_box_reg: 0.5794  loss_mask: 0.2958  loss_rpn_cls: 0.06913  loss_rpn_loc: 0.2124  time: 0.6293  data_time: 0.2215  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:11:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:11:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:11:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:11:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:11:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:11:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:11:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0813 s/iter. Eval: 0.0472 s/iter. Total: 0.1292 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 10:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0659 s/iter. Total: 0.1501 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0833 s/iter. Eval: 0.0673 s/iter. Total: 0.1514 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0835 s/iter. Eval: 0.0695 s/iter. Total: 0.1538 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 10:12:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.846227 (0.153847 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:12:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083548 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:12:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:12:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27129933379729876\n",
      "\u001b[32m[02/04 10:12:07 d2.utils.events]: \u001b[0m eta: 0:28:52  iter: 6059  total_loss: 1.233  loss_cls: 0.2468  loss_box_reg: 0.5204  loss_mask: 0.3019  loss_rpn_cls: 0.05273  loss_rpn_loc: 0.1614  time: 0.6291  data_time: 0.1721  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:12:23 d2.utils.events]: \u001b[0m eta: 0:28:43  iter: 6079  total_loss: 1.431  loss_cls: 0.3166  loss_box_reg: 0.5365  loss_mask: 0.2873  loss_rpn_cls: 0.05983  loss_rpn_loc: 0.1758  time: 0.6297  data_time: 0.3563  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:12:34 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 6099  total_loss: 1.406  loss_cls: 0.2976  loss_box_reg: 0.5229  loss_mask: 0.3013  loss_rpn_cls: 0.07189  loss_rpn_loc: 0.1791  time: 0.6295  data_time: 0.1715  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:12:49 d2.utils.events]: \u001b[0m eta: 0:28:27  iter: 6119  total_loss: 1.485  loss_cls: 0.3452  loss_box_reg: 0.5693  loss_mask: 0.3127  loss_rpn_cls: 0.08768  loss_rpn_loc: 0.2061  time: 0.6297  data_time: 0.2718  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:13:03 d2.utils.events]: \u001b[0m eta: 0:28:17  iter: 6139  total_loss: 1.456  loss_cls: 0.3078  loss_box_reg: 0.5593  loss_mask: 0.307  loss_rpn_cls: 0.08437  loss_rpn_loc: 0.1967  time: 0.6301  data_time: 0.3236  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:13:15 d2.utils.events]: \u001b[0m eta: 0:28:04  iter: 6159  total_loss: 1.493  loss_cls: 0.3112  loss_box_reg: 0.5925  loss_mask: 0.3181  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.1992  time: 0.6300  data_time: 0.1833  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:13:29 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 6179  total_loss: 1.413  loss_cls: 0.2857  loss_box_reg: 0.547  loss_mask: 0.3107  loss_rpn_cls: 0.059  loss_rpn_loc: 0.1871  time: 0.6301  data_time: 0.2271  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:13:39 d2.utils.events]: \u001b[0m eta: 0:27:40  iter: 6199  total_loss: 1.313  loss_cls: 0.2728  loss_box_reg: 0.5329  loss_mask: 0.2941  loss_rpn_cls: 0.05723  loss_rpn_loc: 0.1629  time: 0.6298  data_time: 0.1204  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:13:50 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 6219  total_loss: 1.46  loss_cls: 0.3157  loss_box_reg: 0.5558  loss_mask: 0.2949  loss_rpn_cls: 0.08153  loss_rpn_loc: 0.1963  time: 0.6294  data_time: 0.0997  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:14:01 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 6239  total_loss: 1.392  loss_cls: 0.2996  loss_box_reg: 0.5466  loss_mask: 0.2972  loss_rpn_cls: 0.07931  loss_rpn_loc: 0.1804  time: 0.6292  data_time: 0.1400  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:14:16 d2.utils.events]: \u001b[0m eta: 0:27:17  iter: 6259  total_loss: 1.606  loss_cls: 0.3795  loss_box_reg: 0.6059  loss_mask: 0.3179  loss_rpn_cls: 0.09148  loss_rpn_loc: 0.2162  time: 0.6296  data_time: 0.2932  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:14:28 d2.utils.events]: \u001b[0m eta: 0:27:12  iter: 6279  total_loss: 1.449  loss_cls: 0.3174  loss_box_reg: 0.5409  loss_mask: 0.2851  loss_rpn_cls: 0.08214  loss_rpn_loc: 0.197  time: 0.6295  data_time: 0.1943  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:14:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:14:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:14:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:14:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:14:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:14:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0469 s/iter. Total: 0.1283 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 10:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0656 s/iter. Total: 0.1496 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:14:48 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0832 s/iter. Eval: 0.0676 s/iter. Total: 0.1516 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:14:53 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0835 s/iter. Eval: 0.0697 s/iter. Total: 0.1540 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 10:14:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.867975 (0.154034 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:14:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083531 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:14:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:14:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.270688316937123\n",
      "\u001b[32m[02/04 10:14:58 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 6299  total_loss: 1.439  loss_cls: 0.3211  loss_box_reg: 0.5443  loss_mask: 0.3049  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.1935  time: 0.6292  data_time: 0.1207  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:15:10 d2.utils.events]: \u001b[0m eta: 0:26:52  iter: 6319  total_loss: 1.427  loss_cls: 0.3168  loss_box_reg: 0.5543  loss_mask: 0.295  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.1825  time: 0.6291  data_time: 0.1689  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:15:25 d2.utils.events]: \u001b[0m eta: 0:26:49  iter: 6339  total_loss: 1.524  loss_cls: 0.3322  loss_box_reg: 0.5695  loss_mask: 0.3149  loss_rpn_cls: 0.07876  loss_rpn_loc: 0.1911  time: 0.6295  data_time: 0.3058  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:15:35 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 6359  total_loss: 1.296  loss_cls: 0.2396  loss_box_reg: 0.5129  loss_mask: 0.2916  loss_rpn_cls: 0.05699  loss_rpn_loc: 0.1751  time: 0.6291  data_time: 0.0971  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:15:46 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 6379  total_loss: 1.396  loss_cls: 0.321  loss_box_reg: 0.5387  loss_mask: 0.2986  loss_rpn_cls: 0.05746  loss_rpn_loc: 0.187  time: 0.6288  data_time: 0.1233  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:15:58 d2.utils.events]: \u001b[0m eta: 0:26:21  iter: 6399  total_loss: 1.434  loss_cls: 0.3097  loss_box_reg: 0.5626  loss_mask: 0.2883  loss_rpn_cls: 0.07749  loss_rpn_loc: 0.189  time: 0.6287  data_time: 0.1551  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:16:10 d2.utils.events]: \u001b[0m eta: 0:26:14  iter: 6419  total_loss: 1.454  loss_cls: 0.3233  loss_box_reg: 0.5526  loss_mask: 0.29  loss_rpn_cls: 0.08298  loss_rpn_loc: 0.1876  time: 0.6287  data_time: 0.2015  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:16:22 d2.utils.events]: \u001b[0m eta: 0:26:01  iter: 6439  total_loss: 1.407  loss_cls: 0.2971  loss_box_reg: 0.5629  loss_mask: 0.3002  loss_rpn_cls: 0.05834  loss_rpn_loc: 0.1823  time: 0.6285  data_time: 0.1676  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:16:37 d2.utils.events]: \u001b[0m eta: 0:25:54  iter: 6459  total_loss: 1.478  loss_cls: 0.3063  loss_box_reg: 0.5435  loss_mask: 0.3018  loss_rpn_cls: 0.06723  loss_rpn_loc: 0.1905  time: 0.6289  data_time: 0.2983  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:16:52 d2.utils.events]: \u001b[0m eta: 0:25:46  iter: 6479  total_loss: 1.458  loss_cls: 0.3343  loss_box_reg: 0.5429  loss_mask: 0.3054  loss_rpn_cls: 0.07293  loss_rpn_loc: 0.1934  time: 0.6293  data_time: 0.3306  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:17:07 d2.utils.events]: \u001b[0m eta: 0:25:37  iter: 6499  total_loss: 1.463  loss_cls: 0.3383  loss_box_reg: 0.5607  loss_mask: 0.2979  loss_rpn_cls: 0.09325  loss_rpn_loc: 0.1827  time: 0.6297  data_time: 0.3435  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:17:17 d2.utils.events]: \u001b[0m eta: 0:25:24  iter: 6519  total_loss: 1.371  loss_cls: 0.2915  loss_box_reg: 0.5435  loss_mask: 0.2988  loss_rpn_cls: 0.05244  loss_rpn_loc: 0.1736  time: 0.6292  data_time: 0.0687  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:17:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:17:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:17:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:17:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:17:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:17:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:17:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0809 s/iter. Eval: 0.0458 s/iter. Total: 0.1273 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 10:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0832 s/iter. Eval: 0.0659 s/iter. Total: 0.1498 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0831 s/iter. Eval: 0.0672 s/iter. Total: 0.1511 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0835 s/iter. Eval: 0.0700 s/iter. Total: 0.1543 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:17:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.835975 (0.153758 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:17:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083395 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:17:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:17:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26903100660448087\n",
      "\u001b[32m[02/04 10:17:50 d2.utils.events]: \u001b[0m eta: 0:25:16  iter: 6539  total_loss: 1.469  loss_cls: 0.3129  loss_box_reg: 0.549  loss_mask: 0.2998  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.1904  time: 0.6293  data_time: 0.2252  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:18:04 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 6559  total_loss: 1.469  loss_cls: 0.3076  loss_box_reg: 0.5657  loss_mask: 0.3065  loss_rpn_cls: 0.06715  loss_rpn_loc: 0.2073  time: 0.6295  data_time: 0.2927  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:18:17 d2.utils.events]: \u001b[0m eta: 0:24:59  iter: 6579  total_loss: 1.43  loss_cls: 0.3198  loss_box_reg: 0.5446  loss_mask: 0.304  loss_rpn_cls: 0.08259  loss_rpn_loc: 0.1874  time: 0.6297  data_time: 0.2386  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:18:28 d2.utils.events]: \u001b[0m eta: 0:24:49  iter: 6599  total_loss: 1.416  loss_cls: 0.2994  loss_box_reg: 0.5635  loss_mask: 0.2958  loss_rpn_cls: 0.06618  loss_rpn_loc: 0.1946  time: 0.6294  data_time: 0.1220  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:18:45 d2.utils.events]: \u001b[0m eta: 0:24:44  iter: 6619  total_loss: 1.58  loss_cls: 0.3528  loss_box_reg: 0.5672  loss_mask: 0.3101  loss_rpn_cls: 0.09642  loss_rpn_loc: 0.2052  time: 0.6300  data_time: 0.3849  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:18:56 d2.utils.events]: \u001b[0m eta: 0:24:33  iter: 6639  total_loss: 1.467  loss_cls: 0.3435  loss_box_reg: 0.5764  loss_mask: 0.315  loss_rpn_cls: 0.08137  loss_rpn_loc: 0.1812  time: 0.6298  data_time: 0.1355  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:19:06 d2.utils.events]: \u001b[0m eta: 0:24:22  iter: 6659  total_loss: 1.292  loss_cls: 0.2624  loss_box_reg: 0.5306  loss_mask: 0.2913  loss_rpn_cls: 0.05869  loss_rpn_loc: 0.1755  time: 0.6294  data_time: 0.1162  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:19:18 d2.utils.events]: \u001b[0m eta: 0:24:12  iter: 6679  total_loss: 1.325  loss_cls: 0.2778  loss_box_reg: 0.5259  loss_mask: 0.2901  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.1743  time: 0.6294  data_time: 0.1968  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:19:30 d2.utils.events]: \u001b[0m eta: 0:24:02  iter: 6699  total_loss: 1.344  loss_cls: 0.2929  loss_box_reg: 0.5202  loss_mask: 0.2946  loss_rpn_cls: 0.06765  loss_rpn_loc: 0.1833  time: 0.6293  data_time: 0.1702  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:19:41 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 6719  total_loss: 1.421  loss_cls: 0.3076  loss_box_reg: 0.5327  loss_mask: 0.2888  loss_rpn_cls: 0.05225  loss_rpn_loc: 0.1852  time: 0.6291  data_time: 0.1458  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:19:53 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 6739  total_loss: 1.461  loss_cls: 0.3053  loss_box_reg: 0.5479  loss_mask: 0.3043  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.2032  time: 0.6289  data_time: 0.1671  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:20:05 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 6759  total_loss: 1.425  loss_cls: 0.3172  loss_box_reg: 0.5454  loss_mask: 0.3043  loss_rpn_cls: 0.08652  loss_rpn_loc: 0.1853  time: 0.6289  data_time: 0.1803  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:20:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:20:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:20:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:20:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:20:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:20:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0816 s/iter. Eval: 0.0493 s/iter. Total: 0.1316 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 10:20:24 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0835 s/iter. Eval: 0.0671 s/iter. Total: 0.1514 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0834 s/iter. Eval: 0.0680 s/iter. Total: 0.1522 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0704 s/iter. Total: 0.1551 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:20:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.935688 (0.154618 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:20:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083812 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:20:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:20:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27204836012277184\n",
      "\u001b[32m[02/04 10:20:38 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 6779  total_loss: 1.619  loss_cls: 0.3444  loss_box_reg: 0.5911  loss_mask: 0.3284  loss_rpn_cls: 0.08051  loss_rpn_loc: 0.2146  time: 0.6289  data_time: 0.1990  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:20:52 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 6799  total_loss: 1.492  loss_cls: 0.3302  loss_box_reg: 0.5796  loss_mask: 0.3033  loss_rpn_cls: 0.07678  loss_rpn_loc: 0.1874  time: 0.6291  data_time: 0.2591  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:21:03 d2.utils.events]: \u001b[0m eta: 0:23:12  iter: 6819  total_loss: 1.457  loss_cls: 0.328  loss_box_reg: 0.5519  loss_mask: 0.3108  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.1824  time: 0.6289  data_time: 0.1412  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:21:17 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 6839  total_loss: 1.427  loss_cls: 0.3068  loss_box_reg: 0.5416  loss_mask: 0.2996  loss_rpn_cls: 0.07528  loss_rpn_loc: 0.1826  time: 0.6290  data_time: 0.2663  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:21:29 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 6859  total_loss: 1.441  loss_cls: 0.3279  loss_box_reg: 0.5258  loss_mask: 0.2999  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.2006  time: 0.6290  data_time: 0.2000  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:21:40 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 6879  total_loss: 1.407  loss_cls: 0.316  loss_box_reg: 0.5596  loss_mask: 0.2917  loss_rpn_cls: 0.05768  loss_rpn_loc: 0.1829  time: 0.6289  data_time: 0.1613  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:21:53 d2.utils.events]: \u001b[0m eta: 0:22:42  iter: 6899  total_loss: 1.45  loss_cls: 0.3316  loss_box_reg: 0.5299  loss_mask: 0.2948  loss_rpn_cls: 0.0914  loss_rpn_loc: 0.1923  time: 0.6289  data_time: 0.2190  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:22:06 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 6919  total_loss: 1.397  loss_cls: 0.3089  loss_box_reg: 0.5312  loss_mask: 0.2986  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.1695  time: 0.6289  data_time: 0.2059  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:22:18 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 6939  total_loss: 1.42  loss_cls: 0.2993  loss_box_reg: 0.5529  loss_mask: 0.2888  loss_rpn_cls: 0.0753  loss_rpn_loc: 0.1852  time: 0.6288  data_time: 0.1657  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:22:30 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 6959  total_loss: 1.494  loss_cls: 0.3117  loss_box_reg: 0.5536  loss_mask: 0.2977  loss_rpn_cls: 0.07722  loss_rpn_loc: 0.1909  time: 0.6287  data_time: 0.1825  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:22:42 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 6979  total_loss: 1.533  loss_cls: 0.3391  loss_box_reg: 0.5591  loss_mask: 0.3179  loss_rpn_cls: 0.07997  loss_rpn_loc: 0.2138  time: 0.6287  data_time: 0.1897  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:22:58 d2.utils.events]: \u001b[0m eta: 0:21:58  iter: 6999  total_loss: 1.402  loss_cls: 0.2897  loss_box_reg: 0.5528  loss_mask: 0.2946  loss_rpn_cls: 0.0737  loss_rpn_loc: 0.1913  time: 0.6291  data_time: 0.3415  lr: 0.00016384  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:23:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:23:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:23:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:23:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:23:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:23:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0805 s/iter. Eval: 0.0455 s/iter. Total: 0.1266 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 10:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0656 s/iter. Total: 0.1498 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0834 s/iter. Eval: 0.0669 s/iter. Total: 0.1511 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0837 s/iter. Eval: 0.0699 s/iter. Total: 0.1545 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:23:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.864343 (0.154003 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:23:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083673 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:23:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:23:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27137001440447983\n",
      "\u001b[32m[02/04 10:23:28 d2.utils.events]: \u001b[0m eta: 0:21:50  iter: 7019  total_loss: 1.423  loss_cls: 0.3169  loss_box_reg: 0.5624  loss_mask: 0.2939  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.1831  time: 0.6288  data_time: 0.0905  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:23:41 d2.utils.events]: \u001b[0m eta: 0:21:40  iter: 7039  total_loss: 1.399  loss_cls: 0.3187  loss_box_reg: 0.5567  loss_mask: 0.3027  loss_rpn_cls: 0.07153  loss_rpn_loc: 0.1868  time: 0.6289  data_time: 0.2418  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:23:53 d2.utils.events]: \u001b[0m eta: 0:21:32  iter: 7059  total_loss: 1.41  loss_cls: 0.3088  loss_box_reg: 0.5493  loss_mask: 0.2955  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.1802  time: 0.6288  data_time: 0.1630  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:24:08 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 7079  total_loss: 1.444  loss_cls: 0.3226  loss_box_reg: 0.5638  loss_mask: 0.301  loss_rpn_cls: 0.07145  loss_rpn_loc: 0.1836  time: 0.6291  data_time: 0.3045  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:24:20 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 7099  total_loss: 1.554  loss_cls: 0.3528  loss_box_reg: 0.5835  loss_mask: 0.3137  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.1889  time: 0.6291  data_time: 0.2104  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:24:34 d2.utils.events]: \u001b[0m eta: 0:21:06  iter: 7119  total_loss: 1.53  loss_cls: 0.3209  loss_box_reg: 0.5871  loss_mask: 0.3269  loss_rpn_cls: 0.09506  loss_rpn_loc: 0.2092  time: 0.6293  data_time: 0.2516  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:24:47 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 7139  total_loss: 1.45  loss_cls: 0.3195  loss_box_reg: 0.5553  loss_mask: 0.3073  loss_rpn_cls: 0.08538  loss_rpn_loc: 0.2105  time: 0.6293  data_time: 0.2263  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:25:01 d2.utils.events]: \u001b[0m eta: 0:20:51  iter: 7159  total_loss: 1.501  loss_cls: 0.3298  loss_box_reg: 0.578  loss_mask: 0.3032  loss_rpn_cls: 0.08969  loss_rpn_loc: 0.2037  time: 0.6295  data_time: 0.2705  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:25:13 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 7179  total_loss: 1.401  loss_cls: 0.2935  loss_box_reg: 0.5307  loss_mask: 0.2869  loss_rpn_cls: 0.06302  loss_rpn_loc: 0.1809  time: 0.6294  data_time: 0.1508  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:25:23 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 7199  total_loss: 1.433  loss_cls: 0.3002  loss_box_reg: 0.5379  loss_mask: 0.3035  loss_rpn_cls: 0.07432  loss_rpn_loc: 0.1721  time: 0.6291  data_time: 0.1008  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:25:36 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 7219  total_loss: 1.329  loss_cls: 0.2759  loss_box_reg: 0.5366  loss_mask: 0.3026  loss_rpn_cls: 0.0491  loss_rpn_loc: 0.1867  time: 0.6291  data_time: 0.2312  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:25:47 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 7239  total_loss: 1.435  loss_cls: 0.2991  loss_box_reg: 0.5314  loss_mask: 0.2928  loss_rpn_cls: 0.07841  loss_rpn_loc: 0.1907  time: 0.6289  data_time: 0.1309  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:25:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:26:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:26:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:26:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:26:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:26:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0836 s/iter. Eval: 0.0503 s/iter. Total: 0.1346 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 10:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0836 s/iter. Eval: 0.0662 s/iter. Total: 0.1506 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0834 s/iter. Eval: 0.0676 s/iter. Total: 0.1518 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:26:17 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0837 s/iter. Eval: 0.0703 s/iter. Total: 0.1547 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:26:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.918315 (0.154468 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:26:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083585 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:26:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:26:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2720488724986146\n",
      "\u001b[32m[02/04 10:26:19 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 7259  total_loss: 1.36  loss_cls: 0.2997  loss_box_reg: 0.5421  loss_mask: 0.2811  loss_rpn_cls: 0.07198  loss_rpn_loc: 0.1666  time: 0.6289  data_time: 0.1989  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:26:30 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 7279  total_loss: 1.444  loss_cls: 0.3287  loss_box_reg: 0.5617  loss_mask: 0.3071  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.1908  time: 0.6287  data_time: 0.1382  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:26:41 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 7299  total_loss: 1.418  loss_cls: 0.2974  loss_box_reg: 0.5629  loss_mask: 0.293  loss_rpn_cls: 0.06272  loss_rpn_loc: 0.1899  time: 0.6284  data_time: 0.1401  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:26:52 d2.utils.events]: \u001b[0m eta: 0:19:37  iter: 7319  total_loss: 1.388  loss_cls: 0.3289  loss_box_reg: 0.5465  loss_mask: 0.2958  loss_rpn_cls: 0.06222  loss_rpn_loc: 0.1647  time: 0.6283  data_time: 0.1452  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:27:03 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 7339  total_loss: 1.478  loss_cls: 0.309  loss_box_reg: 0.5492  loss_mask: 0.3098  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.1946  time: 0.6281  data_time: 0.1328  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:27:14 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 7359  total_loss: 1.376  loss_cls: 0.3177  loss_box_reg: 0.5519  loss_mask: 0.2929  loss_rpn_cls: 0.06121  loss_rpn_loc: 0.1847  time: 0.6278  data_time: 0.1235  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:27:26 d2.utils.events]: \u001b[0m eta: 0:19:10  iter: 7379  total_loss: 1.503  loss_cls: 0.2996  loss_box_reg: 0.5783  loss_mask: 0.3156  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.172  time: 0.6277  data_time: 0.1495  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:27:39 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 7399  total_loss: 1.403  loss_cls: 0.3015  loss_box_reg: 0.5349  loss_mask: 0.2888  loss_rpn_cls: 0.05918  loss_rpn_loc: 0.1783  time: 0.6278  data_time: 0.2561  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:27:53 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 7419  total_loss: 1.411  loss_cls: 0.321  loss_box_reg: 0.5325  loss_mask: 0.2961  loss_rpn_cls: 0.08455  loss_rpn_loc: 0.1921  time: 0.6280  data_time: 0.2472  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:28:07 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 7439  total_loss: 1.372  loss_cls: 0.3105  loss_box_reg: 0.5465  loss_mask: 0.2963  loss_rpn_cls: 0.09658  loss_rpn_loc: 0.1877  time: 0.6281  data_time: 0.2629  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:28:19 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 7459  total_loss: 1.422  loss_cls: 0.3097  loss_box_reg: 0.5525  loss_mask: 0.3044  loss_rpn_cls: 0.05251  loss_rpn_loc: 0.1759  time: 0.6282  data_time: 0.2040  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:28:31 d2.utils.events]: \u001b[0m eta: 0:18:25  iter: 7479  total_loss: 1.31  loss_cls: 0.3239  loss_box_reg: 0.5263  loss_mask: 0.2891  loss_rpn_cls: 0.0451  loss_rpn_loc: 0.1619  time: 0.6280  data_time: 0.1434  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:28:46 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 7499  total_loss: 1.564  loss_cls: 0.3379  loss_box_reg: 0.5827  loss_mask: 0.3222  loss_rpn_cls: 0.09441  loss_rpn_loc: 0.2165  time: 0.6283  data_time: 0.3403  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:28:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:28:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:28:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:28:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:28:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:28:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0503 s/iter. Total: 0.1345 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 10:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0838 s/iter. Eval: 0.0672 s/iter. Total: 0.1518 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0837 s/iter. Eval: 0.0685 s/iter. Total: 0.1530 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0710 s/iter. Total: 0.1558 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:29:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.029642 (0.155428 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:29:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083844 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:29:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:29:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2692394345245574\n",
      "\u001b[32m[02/04 10:29:19 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 7519  total_loss: 1.344  loss_cls: 0.2582  loss_box_reg: 0.5308  loss_mask: 0.2958  loss_rpn_cls: 0.059  loss_rpn_loc: 0.1667  time: 0.6284  data_time: 0.2204  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:29:33 d2.utils.events]: \u001b[0m eta: 0:18:01  iter: 7539  total_loss: 1.518  loss_cls: 0.3387  loss_box_reg: 0.5609  loss_mask: 0.3002  loss_rpn_cls: 0.09823  loss_rpn_loc: 0.2017  time: 0.6286  data_time: 0.2893  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:29:46 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 7559  total_loss: 1.45  loss_cls: 0.3128  loss_box_reg: 0.5596  loss_mask: 0.2897  loss_rpn_cls: 0.08421  loss_rpn_loc: 0.1762  time: 0.6287  data_time: 0.2172  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:30:00 d2.utils.events]: \u001b[0m eta: 0:17:44  iter: 7579  total_loss: 1.466  loss_cls: 0.3163  loss_box_reg: 0.5614  loss_mask: 0.3023  loss_rpn_cls: 0.08808  loss_rpn_loc: 0.1878  time: 0.6289  data_time: 0.2682  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:30:13 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 7599  total_loss: 1.491  loss_cls: 0.305  loss_box_reg: 0.5548  loss_mask: 0.3071  loss_rpn_cls: 0.07774  loss_rpn_loc: 0.2091  time: 0.6289  data_time: 0.2390  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:30:28 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 7619  total_loss: 1.379  loss_cls: 0.306  loss_box_reg: 0.5456  loss_mask: 0.3006  loss_rpn_cls: 0.07398  loss_rpn_loc: 0.1846  time: 0.6293  data_time: 0.3198  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:30:38 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 7639  total_loss: 1.378  loss_cls: 0.2856  loss_box_reg: 0.5264  loss_mask: 0.2842  loss_rpn_cls: 0.05424  loss_rpn_loc: 0.1677  time: 0.6289  data_time: 0.0830  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:30:51 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 7659  total_loss: 1.457  loss_cls: 0.3102  loss_box_reg: 0.5736  loss_mask: 0.3084  loss_rpn_cls: 0.07783  loss_rpn_loc: 0.1855  time: 0.6290  data_time: 0.2062  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:31:03 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 7679  total_loss: 1.362  loss_cls: 0.2743  loss_box_reg: 0.5492  loss_mask: 0.2936  loss_rpn_cls: 0.06067  loss_rpn_loc: 0.1845  time: 0.6289  data_time: 0.1695  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:31:14 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 7699  total_loss: 1.367  loss_cls: 0.2834  loss_box_reg: 0.5272  loss_mask: 0.2929  loss_rpn_cls: 0.06266  loss_rpn_loc: 0.184  time: 0.6286  data_time: 0.1054  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:31:27 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 7719  total_loss: 1.441  loss_cls: 0.3223  loss_box_reg: 0.5464  loss_mask: 0.2986  loss_rpn_cls: 0.08525  loss_rpn_loc: 0.1977  time: 0.6287  data_time: 0.2427  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:31:39 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 7739  total_loss: 1.475  loss_cls: 0.3031  loss_box_reg: 0.5598  loss_mask: 0.3021  loss_rpn_cls: 0.06365  loss_rpn_loc: 0.2057  time: 0.6287  data_time: 0.1959  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:31:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:31:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:31:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:31:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:31:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:31:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0822 s/iter. Eval: 0.0549 s/iter. Total: 0.1378 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0836 s/iter. Eval: 0.0684 s/iter. Total: 0.1528 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0836 s/iter. Eval: 0.0691 s/iter. Total: 0.1535 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0838 s/iter. Eval: 0.0713 s/iter. Total: 0.1560 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:32:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.054414 (0.155642 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:32:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083862 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:32:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:32:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27107866338736\n",
      "\u001b[32m[02/04 10:32:10 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 7759  total_loss: 1.427  loss_cls: 0.2948  loss_box_reg: 0.5633  loss_mask: 0.2992  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.1908  time: 0.6285  data_time: 0.1326  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:32:21 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 7779  total_loss: 1.357  loss_cls: 0.2977  loss_box_reg: 0.5114  loss_mask: 0.2817  loss_rpn_cls: 0.0637  loss_rpn_loc: 0.165  time: 0.6283  data_time: 0.1361  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:32:33 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 7799  total_loss: 1.439  loss_cls: 0.3117  loss_box_reg: 0.5435  loss_mask: 0.3046  loss_rpn_cls: 0.04703  loss_rpn_loc: 0.1794  time: 0.6282  data_time: 0.1860  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:32:50 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 7819  total_loss: 1.462  loss_cls: 0.3403  loss_box_reg: 0.5839  loss_mask: 0.2949  loss_rpn_cls: 0.09522  loss_rpn_loc: 0.2091  time: 0.6287  data_time: 0.3792  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:33:00 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 7839  total_loss: 1.365  loss_cls: 0.2948  loss_box_reg: 0.5466  loss_mask: 0.3018  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.1782  time: 0.6285  data_time: 0.0975  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:33:15 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 7859  total_loss: 1.592  loss_cls: 0.3431  loss_box_reg: 0.5731  loss_mask: 0.3151  loss_rpn_cls: 0.09705  loss_rpn_loc: 0.2181  time: 0.6287  data_time: 0.2813  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:33:25 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 7879  total_loss: 1.391  loss_cls: 0.2618  loss_box_reg: 0.5578  loss_mask: 0.3083  loss_rpn_cls: 0.04279  loss_rpn_loc: 0.1746  time: 0.6284  data_time: 0.0955  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:33:36 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 7899  total_loss: 1.429  loss_cls: 0.3388  loss_box_reg: 0.5474  loss_mask: 0.2916  loss_rpn_cls: 0.06024  loss_rpn_loc: 0.1735  time: 0.6282  data_time: 0.1386  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:33:47 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 7919  total_loss: 1.384  loss_cls: 0.2807  loss_box_reg: 0.5401  loss_mask: 0.307  loss_rpn_cls: 0.05301  loss_rpn_loc: 0.1938  time: 0.6280  data_time: 0.1201  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:34:00 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 7939  total_loss: 1.48  loss_cls: 0.3355  loss_box_reg: 0.5654  loss_mask: 0.309  loss_rpn_cls: 0.0855  loss_rpn_loc: 0.1915  time: 0.6280  data_time: 0.2072  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:34:15 d2.utils.events]: \u001b[0m eta: 0:14:56  iter: 7959  total_loss: 1.554  loss_cls: 0.354  loss_box_reg: 0.5916  loss_mask: 0.3145  loss_rpn_cls: 0.0749  loss_rpn_loc: 0.199  time: 0.6283  data_time: 0.3304  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:34:28 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 7979  total_loss: 1.407  loss_cls: 0.2957  loss_box_reg: 0.5379  loss_mask: 0.2979  loss_rpn_cls: 0.04923  loss_rpn_loc: 0.1689  time: 0.6284  data_time: 0.2211  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:34:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:34:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:34:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:34:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:34:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:34:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0841 s/iter. Eval: 0.0532 s/iter. Total: 0.1381 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0669 s/iter. Total: 0.1518 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0837 s/iter. Eval: 0.0677 s/iter. Total: 0.1522 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0839 s/iter. Eval: 0.0698 s/iter. Total: 0.1545 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 10:34:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.933158 (0.154596 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:34:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:34:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:34:53 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26742606743012326\n",
      "\u001b[32m[02/04 10:35:03 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 7999  total_loss: 1.494  loss_cls: 0.3327  loss_box_reg: 0.5382  loss_mask: 0.3033  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.1964  time: 0.6287  data_time: 0.3085  lr: 0.00013107  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:35:13 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 8019  total_loss: 1.48  loss_cls: 0.3109  loss_box_reg: 0.5707  loss_mask: 0.295  loss_rpn_cls: 0.07929  loss_rpn_loc: 0.1823  time: 0.6284  data_time: 0.1044  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:35:27 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 8039  total_loss: 1.481  loss_cls: 0.3612  loss_box_reg: 0.5632  loss_mask: 0.2958  loss_rpn_cls: 0.09565  loss_rpn_loc: 0.2073  time: 0.6286  data_time: 0.2864  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:35:37 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 8059  total_loss: 1.416  loss_cls: 0.2868  loss_box_reg: 0.5572  loss_mask: 0.3033  loss_rpn_cls: 0.06281  loss_rpn_loc: 0.1807  time: 0.6283  data_time: 0.0842  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:35:52 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 8079  total_loss: 1.317  loss_cls: 0.2788  loss_box_reg: 0.5191  loss_mask: 0.2883  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.1887  time: 0.6285  data_time: 0.2915  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:36:05 d2.utils.events]: \u001b[0m eta: 0:13:54  iter: 8099  total_loss: 1.36  loss_cls: 0.3021  loss_box_reg: 0.5176  loss_mask: 0.2912  loss_rpn_cls: 0.04994  loss_rpn_loc: 0.1589  time: 0.6286  data_time: 0.2419  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:36:14 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 8119  total_loss: 1.265  loss_cls: 0.2708  loss_box_reg: 0.5076  loss_mask: 0.2824  loss_rpn_cls: 0.04043  loss_rpn_loc: 0.1571  time: 0.6282  data_time: 0.0898  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:36:29 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 8139  total_loss: 1.538  loss_cls: 0.347  loss_box_reg: 0.5826  loss_mask: 0.3062  loss_rpn_cls: 0.09301  loss_rpn_loc: 0.2124  time: 0.6285  data_time: 0.2972  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:36:41 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 8159  total_loss: 1.433  loss_cls: 0.3062  loss_box_reg: 0.5522  loss_mask: 0.3118  loss_rpn_cls: 0.06278  loss_rpn_loc: 0.1875  time: 0.6284  data_time: 0.1648  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:36:54 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 8179  total_loss: 1.48  loss_cls: 0.2858  loss_box_reg: 0.5795  loss_mask: 0.3156  loss_rpn_cls: 0.06522  loss_rpn_loc: 0.1988  time: 0.6284  data_time: 0.2131  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:37:07 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 8199  total_loss: 1.344  loss_cls: 0.291  loss_box_reg: 0.5352  loss_mask: 0.3032  loss_rpn_cls: 0.05875  loss_rpn_loc: 0.173  time: 0.6285  data_time: 0.2346  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:37:21 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 8219  total_loss: 1.399  loss_cls: 0.2962  loss_box_reg: 0.5361  loss_mask: 0.2893  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.1883  time: 0.6286  data_time: 0.2610  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:37:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:37:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:37:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:37:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:37:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:37:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0531 s/iter. Total: 0.1369 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0838 s/iter. Eval: 0.0665 s/iter. Total: 0.1511 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0836 s/iter. Eval: 0.0675 s/iter. Total: 0.1519 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0693 s/iter. Total: 0.1540 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 10:37:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.869612 (0.154048 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:37:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083843 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:37:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:37:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2703886410741674\n",
      "\u001b[32m[02/04 10:37:52 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 8239  total_loss: 1.368  loss_cls: 0.3037  loss_box_reg: 0.5134  loss_mask: 0.2998  loss_rpn_cls: 0.06225  loss_rpn_loc: 0.1751  time: 0.6286  data_time: 0.1874  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:38:09 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 8259  total_loss: 1.474  loss_cls: 0.3216  loss_box_reg: 0.5731  loss_mask: 0.3181  loss_rpn_cls: 0.09246  loss_rpn_loc: 0.208  time: 0.6291  data_time: 0.3813  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:38:21 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 8279  total_loss: 1.478  loss_cls: 0.3118  loss_box_reg: 0.542  loss_mask: 0.2917  loss_rpn_cls: 0.07642  loss_rpn_loc: 0.1929  time: 0.6290  data_time: 0.1837  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:38:33 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 8299  total_loss: 1.441  loss_cls: 0.3109  loss_box_reg: 0.5575  loss_mask: 0.3013  loss_rpn_cls: 0.07167  loss_rpn_loc: 0.1891  time: 0.6290  data_time: 0.1765  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:38:45 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 8319  total_loss: 1.451  loss_cls: 0.3163  loss_box_reg: 0.5397  loss_mask: 0.2897  loss_rpn_cls: 0.07112  loss_rpn_loc: 0.1942  time: 0.6289  data_time: 0.1853  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:38:58 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 8339  total_loss: 1.456  loss_cls: 0.307  loss_box_reg: 0.5654  loss_mask: 0.3078  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.1879  time: 0.6289  data_time: 0.1866  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:39:09 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 8359  total_loss: 1.393  loss_cls: 0.313  loss_box_reg: 0.5333  loss_mask: 0.2958  loss_rpn_cls: 0.0652  loss_rpn_loc: 0.1772  time: 0.6287  data_time: 0.1481  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:39:21 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 8379  total_loss: 1.315  loss_cls: 0.2921  loss_box_reg: 0.532  loss_mask: 0.2897  loss_rpn_cls: 0.06134  loss_rpn_loc: 0.169  time: 0.6287  data_time: 0.1913  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:39:33 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 8399  total_loss: 1.462  loss_cls: 0.3016  loss_box_reg: 0.5662  loss_mask: 0.304  loss_rpn_cls: 0.06887  loss_rpn_loc: 0.1807  time: 0.6286  data_time: 0.1731  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:39:44 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 8419  total_loss: 1.344  loss_cls: 0.2635  loss_box_reg: 0.5341  loss_mask: 0.3028  loss_rpn_cls: 0.05516  loss_rpn_loc: 0.1805  time: 0.6284  data_time: 0.1225  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:39:59 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 8439  total_loss: 1.412  loss_cls: 0.3065  loss_box_reg: 0.5104  loss_mask: 0.2977  loss_rpn_cls: 0.08294  loss_rpn_loc: 0.1897  time: 0.6287  data_time: 0.3451  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:40:12 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 8459  total_loss: 1.376  loss_cls: 0.2928  loss_box_reg: 0.5238  loss_mask: 0.2837  loss_rpn_cls: 0.06726  loss_rpn_loc: 0.1666  time: 0.6287  data_time: 0.1968  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:40:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:40:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:40:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:40:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:40:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:40:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0859 s/iter. Eval: 0.0714 s/iter. Total: 0.1582 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 10:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0842 s/iter. Eval: 0.0697 s/iter. Total: 0.1548 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0837 s/iter. Eval: 0.0693 s/iter. Total: 0.1538 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0713 s/iter. Total: 0.1561 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:40:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.063383 (0.155719 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:40:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083936 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:40:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:40:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27236857805487485\n",
      "\u001b[32m[02/04 10:40:43 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 8479  total_loss: 1.494  loss_cls: 0.3234  loss_box_reg: 0.546  loss_mask: 0.2995  loss_rpn_cls: 0.08549  loss_rpn_loc: 0.1969  time: 0.6286  data_time: 0.1544  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:41:00 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 8499  total_loss: 1.548  loss_cls: 0.3683  loss_box_reg: 0.5733  loss_mask: 0.3072  loss_rpn_cls: 0.09975  loss_rpn_loc: 0.2125  time: 0.6291  data_time: 0.3741  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:41:13 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 8519  total_loss: 1.423  loss_cls: 0.3044  loss_box_reg: 0.5517  loss_mask: 0.2981  loss_rpn_cls: 0.06171  loss_rpn_loc: 0.1932  time: 0.6291  data_time: 0.2332  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:41:24 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 8539  total_loss: 1.402  loss_cls: 0.31  loss_box_reg: 0.5503  loss_mask: 0.3044  loss_rpn_cls: 0.07704  loss_rpn_loc: 0.1843  time: 0.6290  data_time: 0.1352  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:41:36 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 8559  total_loss: 1.364  loss_cls: 0.3241  loss_box_reg: 0.5381  loss_mask: 0.3013  loss_rpn_cls: 0.08047  loss_rpn_loc: 0.1714  time: 0.6289  data_time: 0.1908  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:41:50 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 8579  total_loss: 1.42  loss_cls: 0.3159  loss_box_reg: 0.5772  loss_mask: 0.3  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.1957  time: 0.6290  data_time: 0.2364  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:42:01 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 8599  total_loss: 1.38  loss_cls: 0.2747  loss_box_reg: 0.5276  loss_mask: 0.2919  loss_rpn_cls: 0.04904  loss_rpn_loc: 0.1895  time: 0.6289  data_time: 0.1525  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:42:17 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 8619  total_loss: 1.407  loss_cls: 0.3072  loss_box_reg: 0.5137  loss_mask: 0.2967  loss_rpn_cls: 0.07797  loss_rpn_loc: 0.2063  time: 0.6292  data_time: 0.3343  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:42:26 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 8639  total_loss: 1.455  loss_cls: 0.3126  loss_box_reg: 0.5802  loss_mask: 0.2995  loss_rpn_cls: 0.0626  loss_rpn_loc: 0.187  time: 0.6289  data_time: 0.0617  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:42:39 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 8659  total_loss: 1.528  loss_cls: 0.3381  loss_box_reg: 0.5571  loss_mask: 0.3075  loss_rpn_cls: 0.07736  loss_rpn_loc: 0.194  time: 0.6289  data_time: 0.2038  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:42:51 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 8679  total_loss: 1.452  loss_cls: 0.3087  loss_box_reg: 0.5754  loss_mask: 0.3092  loss_rpn_cls: 0.06649  loss_rpn_loc: 0.1992  time: 0.6288  data_time: 0.1614  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:43:01 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 8699  total_loss: 1.436  loss_cls: 0.2974  loss_box_reg: 0.5554  loss_mask: 0.2909  loss_rpn_cls: 0.07084  loss_rpn_loc: 0.1836  time: 0.6285  data_time: 0.1114  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:43:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:43:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:43:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:43:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:43:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:43:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0841 s/iter. Eval: 0.0576 s/iter. Total: 0.1426 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0689 s/iter. Total: 0.1538 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0837 s/iter. Eval: 0.0696 s/iter. Total: 0.1541 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0723 s/iter. Total: 0.1571 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:43:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.151128 (0.156475 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:43:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083938 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:43:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:43:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27081260449419314\n",
      "\u001b[32m[02/04 10:43:37 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 8719  total_loss: 1.449  loss_cls: 0.3364  loss_box_reg: 0.541  loss_mask: 0.3055  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.1925  time: 0.6289  data_time: 0.3725  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:43:52 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 8739  total_loss: 1.491  loss_cls: 0.3068  loss_box_reg: 0.5449  loss_mask: 0.31  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.185  time: 0.6292  data_time: 0.3047  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:44:08 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 8759  total_loss: 1.546  loss_cls: 0.3325  loss_box_reg: 0.5603  loss_mask: 0.3115  loss_rpn_cls: 0.09334  loss_rpn_loc: 0.1844  time: 0.6295  data_time: 0.3581  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:44:19 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 8779  total_loss: 1.468  loss_cls: 0.3022  loss_box_reg: 0.5837  loss_mask: 0.3165  loss_rpn_cls: 0.07237  loss_rpn_loc: 0.1882  time: 0.6294  data_time: 0.1486  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:44:31 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 8799  total_loss: 1.371  loss_cls: 0.306  loss_box_reg: 0.5655  loss_mask: 0.305  loss_rpn_cls: 0.05968  loss_rpn_loc: 0.1904  time: 0.6293  data_time: 0.1882  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:44:46 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 8819  total_loss: 1.427  loss_cls: 0.315  loss_box_reg: 0.5289  loss_mask: 0.3014  loss_rpn_cls: 0.07781  loss_rpn_loc: 0.1851  time: 0.6296  data_time: 0.3158  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:44:58 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 8839  total_loss: 1.417  loss_cls: 0.2965  loss_box_reg: 0.5565  loss_mask: 0.3176  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.1677  time: 0.6295  data_time: 0.1673  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:45:11 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 8859  total_loss: 1.434  loss_cls: 0.3307  loss_box_reg: 0.5519  loss_mask: 0.2926  loss_rpn_cls: 0.0958  loss_rpn_loc: 0.1938  time: 0.6296  data_time: 0.2482  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:45:22 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 8879  total_loss: 1.399  loss_cls: 0.3065  loss_box_reg: 0.5327  loss_mask: 0.2899  loss_rpn_cls: 0.06591  loss_rpn_loc: 0.1741  time: 0.6294  data_time: 0.1234  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:45:34 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 8899  total_loss: 1.328  loss_cls: 0.3069  loss_box_reg: 0.5437  loss_mask: 0.2909  loss_rpn_cls: 0.0602  loss_rpn_loc: 0.17  time: 0.6293  data_time: 0.1507  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:45:46 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 8919  total_loss: 1.362  loss_cls: 0.3335  loss_box_reg: 0.5306  loss_mask: 0.2872  loss_rpn_cls: 0.05864  loss_rpn_loc: 0.1666  time: 0.6293  data_time: 0.2105  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:45:59 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 8939  total_loss: 1.41  loss_cls: 0.3204  loss_box_reg: 0.5416  loss_mask: 0.2941  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.1879  time: 0.6293  data_time: 0.2178  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:46:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:46:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:46:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:46:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:46:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:46:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0012 s/iter. Inference: 0.0837 s/iter. Eval: 0.0603 s/iter. Total: 0.1452 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0009 s/iter. Inference: 0.0839 s/iter. Eval: 0.0685 s/iter. Total: 0.1532 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0836 s/iter. Eval: 0.0692 s/iter. Total: 0.1537 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:46:25 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0838 s/iter. Eval: 0.0718 s/iter. Total: 0.1565 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:46:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.090416 (0.155952 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:46:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083755 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:46:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:46:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27080098460547103\n",
      "\u001b[32m[02/04 10:46:30 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 8959  total_loss: 1.345  loss_cls: 0.2995  loss_box_reg: 0.5488  loss_mask: 0.2977  loss_rpn_cls: 0.06243  loss_rpn_loc: 0.1704  time: 0.6291  data_time: 0.1024  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:46:41 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 8979  total_loss: 1.393  loss_cls: 0.3171  loss_box_reg: 0.5637  loss_mask: 0.2973  loss_rpn_cls: 0.07031  loss_rpn_loc: 0.1875  time: 0.6290  data_time: 0.1648  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:46:55 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 8999  total_loss: 1.433  loss_cls: 0.3155  loss_box_reg: 0.5445  loss_mask: 0.2938  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1825  time: 0.6291  data_time: 0.2663  lr: 0.00010486  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:47:08 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 9019  total_loss: 1.506  loss_cls: 0.3259  loss_box_reg: 0.5922  loss_mask: 0.31  loss_rpn_cls: 0.07631  loss_rpn_loc: 0.1974  time: 0.6292  data_time: 0.2265  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:47:20 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 9039  total_loss: 1.413  loss_cls: 0.2723  loss_box_reg: 0.5361  loss_mask: 0.2882  loss_rpn_cls: 0.06028  loss_rpn_loc: 0.1758  time: 0.6291  data_time: 0.1813  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:47:32 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 9059  total_loss: 1.45  loss_cls: 0.3295  loss_box_reg: 0.5703  loss_mask: 0.3057  loss_rpn_cls: 0.09749  loss_rpn_loc: 0.1752  time: 0.6291  data_time: 0.1810  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:47:45 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 9079  total_loss: 1.379  loss_cls: 0.2838  loss_box_reg: 0.5517  loss_mask: 0.3124  loss_rpn_cls: 0.05889  loss_rpn_loc: 0.1745  time: 0.6291  data_time: 0.2323  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:47:57 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 9099  total_loss: 1.364  loss_cls: 0.2942  loss_box_reg: 0.5404  loss_mask: 0.2835  loss_rpn_cls: 0.07607  loss_rpn_loc: 0.168  time: 0.6290  data_time: 0.1863  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:48:10 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 9119  total_loss: 1.392  loss_cls: 0.2945  loss_box_reg: 0.5496  loss_mask: 0.2954  loss_rpn_cls: 0.05968  loss_rpn_loc: 0.2003  time: 0.6291  data_time: 0.2146  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:48:23 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 9139  total_loss: 1.401  loss_cls: 0.2954  loss_box_reg: 0.5227  loss_mask: 0.2887  loss_rpn_cls: 0.09296  loss_rpn_loc: 0.1861  time: 0.6291  data_time: 0.1889  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:48:35 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 9159  total_loss: 1.523  loss_cls: 0.3482  loss_box_reg: 0.5747  loss_mask: 0.3037  loss_rpn_cls: 0.09748  loss_rpn_loc: 0.1952  time: 0.6290  data_time: 0.1844  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:48:48 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 9179  total_loss: 1.46  loss_cls: 0.3325  loss_box_reg: 0.5549  loss_mask: 0.2972  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.1933  time: 0.6291  data_time: 0.2442  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:49:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:49:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:49:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:49:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:49:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:49:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:49:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.0841 s/iter. Eval: 0.0576 s/iter. Total: 0.1427 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0681 s/iter. Total: 0.1532 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0838 s/iter. Eval: 0.0689 s/iter. Total: 0.1536 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0714 s/iter. Total: 0.1562 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:49:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.071328 (0.155787 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:49:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:49:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:49:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2708747206141469\n",
      "\u001b[32m[02/04 10:49:21 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 9199  total_loss: 1.329  loss_cls: 0.3143  loss_box_reg: 0.5208  loss_mask: 0.2892  loss_rpn_cls: 0.06349  loss_rpn_loc: 0.1802  time: 0.6292  data_time: 0.2206  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:49:32 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 9219  total_loss: 1.422  loss_cls: 0.3062  loss_box_reg: 0.5583  loss_mask: 0.3006  loss_rpn_cls: 0.06323  loss_rpn_loc: 0.193  time: 0.6289  data_time: 0.1079  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:49:42 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 9239  total_loss: 1.437  loss_cls: 0.302  loss_box_reg: 0.5521  loss_mask: 0.2948  loss_rpn_cls: 0.05951  loss_rpn_loc: 0.1752  time: 0.6287  data_time: 0.1201  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:49:54 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 9259  total_loss: 1.396  loss_cls: 0.3214  loss_box_reg: 0.5241  loss_mask: 0.2941  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.1731  time: 0.6286  data_time: 0.1485  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:50:08 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 9279  total_loss: 1.531  loss_cls: 0.3455  loss_box_reg: 0.5729  loss_mask: 0.3182  loss_rpn_cls: 0.08681  loss_rpn_loc: 0.1968  time: 0.6288  data_time: 0.2967  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:50:22 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 9299  total_loss: 1.412  loss_cls: 0.3013  loss_box_reg: 0.5366  loss_mask: 0.2962  loss_rpn_cls: 0.06164  loss_rpn_loc: 0.1763  time: 0.6290  data_time: 0.2731  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:50:35 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 9319  total_loss: 1.343  loss_cls: 0.2798  loss_box_reg: 0.5463  loss_mask: 0.2976  loss_rpn_cls: 0.04068  loss_rpn_loc: 0.1708  time: 0.6289  data_time: 0.2037  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:50:51 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 9339  total_loss: 1.463  loss_cls: 0.3218  loss_box_reg: 0.5668  loss_mask: 0.3046  loss_rpn_cls: 0.07837  loss_rpn_loc: 0.2043  time: 0.6293  data_time: 0.3620  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:51:05 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 9359  total_loss: 1.432  loss_cls: 0.3082  loss_box_reg: 0.5573  loss_mask: 0.301  loss_rpn_cls: 0.07179  loss_rpn_loc: 0.187  time: 0.6295  data_time: 0.2557  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:51:19 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 9379  total_loss: 1.507  loss_cls: 0.3303  loss_box_reg: 0.5888  loss_mask: 0.3129  loss_rpn_cls: 0.08532  loss_rpn_loc: 0.1923  time: 0.6296  data_time: 0.2540  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:51:31 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 9399  total_loss: 1.225  loss_cls: 0.2745  loss_box_reg: 0.4852  loss_mask: 0.2992  loss_rpn_cls: 0.05193  loss_rpn_loc: 0.1718  time: 0.6296  data_time: 0.2153  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:51:45 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 9419  total_loss: 1.447  loss_cls: 0.3159  loss_box_reg: 0.5379  loss_mask: 0.2969  loss_rpn_cls: 0.08528  loss_rpn_loc: 0.1826  time: 0.6298  data_time: 0.2635  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:51:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:51:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:51:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:51:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:51:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:51:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0842 s/iter. Eval: 0.0572 s/iter. Total: 0.1421 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0699 s/iter. Total: 0.1548 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0838 s/iter. Eval: 0.0701 s/iter. Total: 0.1547 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0723 s/iter. Total: 0.1571 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:52:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.152540 (0.156487 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:52:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083941 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:52:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:52:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2705612211992575\n",
      "\u001b[32m[02/04 10:52:19 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 9439  total_loss: 1.497  loss_cls: 0.3197  loss_box_reg: 0.5436  loss_mask: 0.3118  loss_rpn_cls: 0.09437  loss_rpn_loc: 0.2007  time: 0.6299  data_time: 0.2717  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:52:29 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 9459  total_loss: 1.421  loss_cls: 0.3075  loss_box_reg: 0.5584  loss_mask: 0.2891  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.1713  time: 0.6296  data_time: 0.0703  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:52:41 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 9479  total_loss: 1.311  loss_cls: 0.2765  loss_box_reg: 0.5275  loss_mask: 0.2909  loss_rpn_cls: 0.05197  loss_rpn_loc: 0.1574  time: 0.6295  data_time: 0.1473  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:52:51 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 9499  total_loss: 1.323  loss_cls: 0.2978  loss_box_reg: 0.5498  loss_mask: 0.2886  loss_rpn_cls: 0.05331  loss_rpn_loc: 0.1796  time: 0.6293  data_time: 0.1187  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:53:02 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 9519  total_loss: 1.371  loss_cls: 0.2524  loss_box_reg: 0.5298  loss_mask: 0.301  loss_rpn_cls: 0.06087  loss_rpn_loc: 0.1874  time: 0.6291  data_time: 0.1101  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:53:16 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 9539  total_loss: 1.525  loss_cls: 0.3496  loss_box_reg: 0.5503  loss_mask: 0.2957  loss_rpn_cls: 0.09018  loss_rpn_loc: 0.2118  time: 0.6292  data_time: 0.2581  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:53:32 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9559  total_loss: 1.579  loss_cls: 0.3557  loss_box_reg: 0.5866  loss_mask: 0.3196  loss_rpn_cls: 0.08938  loss_rpn_loc: 0.1974  time: 0.6296  data_time: 0.3575  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:53:46 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 9579  total_loss: 1.377  loss_cls: 0.2935  loss_box_reg: 0.5528  loss_mask: 0.3044  loss_rpn_cls: 0.05359  loss_rpn_loc: 0.1692  time: 0.6298  data_time: 0.2929  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:53:58 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 9599  total_loss: 1.398  loss_cls: 0.308  loss_box_reg: 0.5478  loss_mask: 0.3022  loss_rpn_cls: 0.06913  loss_rpn_loc: 0.1754  time: 0.6297  data_time: 0.1665  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:54:09 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 9619  total_loss: 1.375  loss_cls: 0.2989  loss_box_reg: 0.5515  loss_mask: 0.2981  loss_rpn_cls: 0.06245  loss_rpn_loc: 0.183  time: 0.6295  data_time: 0.1504  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:54:22 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 9639  total_loss: 1.411  loss_cls: 0.3044  loss_box_reg: 0.5576  loss_mask: 0.2954  loss_rpn_cls: 0.07917  loss_rpn_loc: 0.1848  time: 0.6296  data_time: 0.2286  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:54:37 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 9659  total_loss: 1.465  loss_cls: 0.3104  loss_box_reg: 0.546  loss_mask: 0.2944  loss_rpn_cls: 0.06757  loss_rpn_loc: 0.1896  time: 0.6298  data_time: 0.2835  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:54:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:54:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:54:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:54:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:54:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:54:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0847 s/iter. Eval: 0.0586 s/iter. Total: 0.1442 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0842 s/iter. Eval: 0.0699 s/iter. Total: 0.1550 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0709 s/iter. Total: 0.1557 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 10:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0725 s/iter. Total: 0.1573 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:55:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.189089 (0.156802 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:55:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084032 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:55:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:55:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27028005818750556\n",
      "\u001b[32m[02/04 10:55:08 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 9679  total_loss: 1.464  loss_cls: 0.2949  loss_box_reg: 0.5506  loss_mask: 0.3135  loss_rpn_cls: 0.05469  loss_rpn_loc: 0.1795  time: 0.6296  data_time: 0.1338  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:55:20 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 9699  total_loss: 1.457  loss_cls: 0.3263  loss_box_reg: 0.552  loss_mask: 0.301  loss_rpn_cls: 0.08492  loss_rpn_loc: 0.2059  time: 0.6295  data_time: 0.1596  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:55:31 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 9719  total_loss: 1.466  loss_cls: 0.3297  loss_box_reg: 0.5667  loss_mask: 0.3086  loss_rpn_cls: 0.07909  loss_rpn_loc: 0.1806  time: 0.6295  data_time: 0.1716  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:55:43 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 9739  total_loss: 1.429  loss_cls: 0.3089  loss_box_reg: 0.563  loss_mask: 0.3002  loss_rpn_cls: 0.06477  loss_rpn_loc: 0.1815  time: 0.6293  data_time: 0.1593  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:55:55 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 9759  total_loss: 1.371  loss_cls: 0.3159  loss_box_reg: 0.5393  loss_mask: 0.3073  loss_rpn_cls: 0.06229  loss_rpn_loc: 0.1752  time: 0.6293  data_time: 0.1644  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:56:08 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 9779  total_loss: 1.562  loss_cls: 0.3508  loss_box_reg: 0.591  loss_mask: 0.3018  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.206  time: 0.6293  data_time: 0.1851  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:56:21 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 9799  total_loss: 1.412  loss_cls: 0.2974  loss_box_reg: 0.5312  loss_mask: 0.2858  loss_rpn_cls: 0.07344  loss_rpn_loc: 0.182  time: 0.6294  data_time: 0.2643  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:56:36 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 9819  total_loss: 1.42  loss_cls: 0.3317  loss_box_reg: 0.5542  loss_mask: 0.2948  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.1811  time: 0.6296  data_time: 0.2771  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:56:46 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 9839  total_loss: 1.479  loss_cls: 0.3117  loss_box_reg: 0.5613  loss_mask: 0.306  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.2  time: 0.6293  data_time: 0.0968  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:56:59 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9859  total_loss: 1.36  loss_cls: 0.3016  loss_box_reg: 0.5461  loss_mask: 0.3055  loss_rpn_cls: 0.05349  loss_rpn_loc: 0.175  time: 0.6294  data_time: 0.2390  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:57:15 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 9879  total_loss: 1.447  loss_cls: 0.3244  loss_box_reg: 0.5391  loss_mask: 0.2938  loss_rpn_cls: 0.09197  loss_rpn_loc: 0.2033  time: 0.6297  data_time: 0.3441  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:57:27 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 9899  total_loss: 1.465  loss_cls: 0.3285  loss_box_reg: 0.5578  loss_mask: 0.3075  loss_rpn_cls: 0.08148  loss_rpn_loc: 0.1815  time: 0.6297  data_time: 0.2218  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:57:39 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 9919  total_loss: 1.485  loss_cls: 0.3094  loss_box_reg: 0.5611  loss_mask: 0.3054  loss_rpn_cls: 0.07317  loss_rpn_loc: 0.1855  time: 0.6296  data_time: 0.1744  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:57:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:57:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:57:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:57:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:57:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:57:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0850 s/iter. Eval: 0.0595 s/iter. Total: 0.1453 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 10:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0697 s/iter. Total: 0.1551 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 10:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0699 s/iter. Total: 0.1547 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 10:58:00 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0842 s/iter. Eval: 0.0720 s/iter. Total: 0.1571 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:58:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.164483 (0.156590 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:58:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:58:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:58:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2710179158261557\n",
      "\u001b[32m[02/04 10:58:13 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 9939  total_loss: 1.309  loss_cls: 0.2657  loss_box_reg: 0.5352  loss_mask: 0.2953  loss_rpn_cls: 0.04409  loss_rpn_loc: 0.1738  time: 0.6298  data_time: 0.2731  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:58:28 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 9959  total_loss: 1.394  loss_cls: 0.3112  loss_box_reg: 0.5567  loss_mask: 0.2977  loss_rpn_cls: 0.05864  loss_rpn_loc: 0.1832  time: 0.6300  data_time: 0.2788  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:58:40 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 9979  total_loss: 1.548  loss_cls: 0.3263  loss_box_reg: 0.5687  loss_mask: 0.3167  loss_rpn_cls: 0.08376  loss_rpn_loc: 0.1883  time: 0.6299  data_time: 0.1912  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:58:51 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.396  loss_cls: 0.2898  loss_box_reg: 0.5298  loss_mask: 0.2996  loss_rpn_cls: 0.05371  loss_rpn_loc: 0.1811  time: 0.6298  data_time: 0.1434  lr: 8.3886e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:58:51 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:44:56 (0.6298 s / it)\n",
      "\u001b[32m[02/04 10:58:51 d2.engine.hooks]: \u001b[0mTotal training time: 1:58:10 (0:13:13 on hooks)\n",
      "\u001b[32m[02/04 10:58:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:58:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 10:58:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:58:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 10:58:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 10:58:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 10:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0617 s/iter. Total: 0.1499 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 10:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0750 s/iter. Total: 0.1618 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 10:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0847 s/iter. Eval: 0.0726 s/iter. Total: 0.1582 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 10:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0847 s/iter. Eval: 0.0741 s/iter. Total: 0.1596 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 10:59:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.483070 (0.159337 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:59:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084490 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 10:59:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 10:59:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26683978815616904\n"
     ]
    }
   ],
   "source": [
    "# Increasing the number of top scoring RPN proposals to keep before applying NMS (15000 for train and 10000 for test) and after applying NMS (3000 for train and 2000 for test)\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b669a80f-a8a3-46ed-be9e-4f218021f1e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 10:59:12 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 10:59:13 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 10:59:14 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/04 10:59:14 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 10:59:15 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/04 10:59:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/04 10:59:15 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/04 10:59:15 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 10:59:15 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 10:59:15 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/04 10:59:29 d2.utils.events]: \u001b[0m eta: 1:09:58  iter: 19  total_loss: 3.01  loss_cls: 1.408  loss_box_reg: 0.2622  loss_mask: 0.6902  loss_rpn_cls: 0.329  loss_rpn_loc: 0.2716  time: 0.6791  data_time: 0.2939  lr: 9.9905e-06  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:59:40 d2.utils.events]: \u001b[0m eta: 1:05:52  iter: 39  total_loss: 2.906  loss_cls: 1.294  loss_box_reg: 0.3404  loss_mask: 0.6842  loss_rpn_cls: 0.3146  loss_rpn_loc: 0.2536  time: 0.6129  data_time: 0.1707  lr: 1.998e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:59:50 d2.utils.events]: \u001b[0m eta: 1:05:36  iter: 59  total_loss: 2.679  loss_cls: 1.081  loss_box_reg: 0.3684  loss_mask: 0.6678  loss_rpn_cls: 0.2654  loss_rpn_loc: 0.2777  time: 0.5834  data_time: 0.1522  lr: 2.997e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 10:59:59 d2.utils.events]: \u001b[0m eta: 1:06:43  iter: 79  total_loss: 2.475  loss_cls: 0.9116  loss_box_reg: 0.4195  loss_mask: 0.6451  loss_rpn_cls: 0.2195  loss_rpn_loc: 0.2197  time: 0.5506  data_time: 0.0586  lr: 3.9961e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:00:13 d2.utils.events]: \u001b[0m eta: 1:07:25  iter: 99  total_loss: 2.305  loss_cls: 0.7081  loss_box_reg: 0.4312  loss_mask: 0.623  loss_rpn_cls: 0.2287  loss_rpn_loc: 0.3025  time: 0.5786  data_time: 0.2783  lr: 4.9951e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:00:25 d2.utils.events]: \u001b[0m eta: 1:07:25  iter: 119  total_loss: 2.256  loss_cls: 0.7112  loss_box_reg: 0.5464  loss_mask: 0.5813  loss_rpn_cls: 0.1731  loss_rpn_loc: 0.2202  time: 0.5774  data_time: 0.1684  lr: 5.9941e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:00:42 d2.utils.events]: \u001b[0m eta: 1:08:02  iter: 139  total_loss: 2.3  loss_cls: 0.7142  loss_box_reg: 0.5328  loss_mask: 0.5602  loss_rpn_cls: 0.1957  loss_rpn_loc: 0.2405  time: 0.6194  data_time: 0.4405  lr: 6.993e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:00:57 d2.utils.events]: \u001b[0m eta: 1:09:05  iter: 159  total_loss: 2.164  loss_cls: 0.6802  loss_box_reg: 0.5517  loss_mask: 0.5278  loss_rpn_cls: 0.1825  loss_rpn_loc: 0.2336  time: 0.6370  data_time: 0.3336  lr: 7.9921e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:01:09 d2.utils.events]: \u001b[0m eta: 1:09:24  iter: 179  total_loss: 2.195  loss_cls: 0.6922  loss_box_reg: 0.5767  loss_mask: 0.5086  loss_rpn_cls: 0.153  loss_rpn_loc: 0.2112  time: 0.6343  data_time: 0.2003  lr: 8.991e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:01:25 d2.utils.events]: \u001b[0m eta: 1:09:26  iter: 199  total_loss: 2.092  loss_cls: 0.6538  loss_box_reg: 0.6195  loss_mask: 0.4726  loss_rpn_cls: 0.1282  loss_rpn_loc: 0.2153  time: 0.6465  data_time: 0.3310  lr: 9.9901e-05  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:01:39 d2.utils.events]: \u001b[0m eta: 1:09:29  iter: 219  total_loss: 2.096  loss_cls: 0.6287  loss_box_reg: 0.6316  loss_mask: 0.4502  loss_rpn_cls: 0.1177  loss_rpn_loc: 0.2233  time: 0.6526  data_time: 0.3009  lr: 0.00010989  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:01:50 d2.utils.events]: \u001b[0m eta: 1:09:43  iter: 239  total_loss: 2.017  loss_cls: 0.6173  loss_box_reg: 0.6002  loss_mask: 0.4284  loss_rpn_cls: 0.1555  loss_rpn_loc: 0.2359  time: 0.6466  data_time: 0.1701  lr: 0.00011988  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:01:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:01:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:01:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:01:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:01:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:01:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0005 s/iter. Inference: 0.0678 s/iter. Eval: 0.0000 s/iter. Total: 0.0684 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 11:01:59 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0678 s/iter. Eval: 0.0000 s/iter. Total: 0.0685 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 11:02:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.018536 (0.069125 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:02:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.067893 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:02:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:02:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.0\n",
      "\u001b[32m[02/04 11:02:14 d2.utils.events]: \u001b[0m eta: 1:09:42  iter: 259  total_loss: 1.979  loss_cls: 0.5585  loss_box_reg: 0.6238  loss_mask: 0.4161  loss_rpn_cls: 0.1265  loss_rpn_loc: 0.2378  time: 0.6528  data_time: 0.3071  lr: 0.00012987  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:02:28 d2.utils.events]: \u001b[0m eta: 1:09:49  iter: 279  total_loss: 1.931  loss_cls: 0.5771  loss_box_reg: 0.6352  loss_mask: 0.3711  loss_rpn_cls: 0.1484  loss_rpn_loc: 0.2285  time: 0.6559  data_time: 0.2623  lr: 0.00013986  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:02:38 d2.utils.events]: \u001b[0m eta: 1:09:50  iter: 299  total_loss: 1.875  loss_cls: 0.5139  loss_box_reg: 0.6486  loss_mask: 0.3647  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.2126  time: 0.6468  data_time: 0.0950  lr: 0.00014985  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:02:49 d2.utils.events]: \u001b[0m eta: 1:09:53  iter: 319  total_loss: 1.844  loss_cls: 0.4992  loss_box_reg: 0.6279  loss_mask: 0.3334  loss_rpn_cls: 0.1263  loss_rpn_loc: 0.2059  time: 0.6393  data_time: 0.1091  lr: 0.00015984  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:03:01 d2.utils.events]: \u001b[0m eta: 1:09:34  iter: 339  total_loss: 1.746  loss_cls: 0.4396  loss_box_reg: 0.6624  loss_mask: 0.3192  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.2057  time: 0.6366  data_time: 0.1810  lr: 0.00016983  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:03:16 d2.utils.events]: \u001b[0m eta: 1:09:36  iter: 359  total_loss: 1.765  loss_cls: 0.4395  loss_box_reg: 0.6184  loss_mask: 0.3335  loss_rpn_cls: 0.1297  loss_rpn_loc: 0.252  time: 0.6424  data_time: 0.3100  lr: 0.00017982  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:03:28 d2.utils.events]: \u001b[0m eta: 1:09:17  iter: 379  total_loss: 1.697  loss_cls: 0.4251  loss_box_reg: 0.6393  loss_mask: 0.3384  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.2237  time: 0.6414  data_time: 0.2218  lr: 0.00018981  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:03:44 d2.utils.events]: \u001b[0m eta: 1:09:09  iter: 399  total_loss: 1.664  loss_cls: 0.4021  loss_box_reg: 0.5987  loss_mask: 0.3349  loss_rpn_cls: 0.1217  loss_rpn_loc: 0.2294  time: 0.6486  data_time: 0.3518  lr: 0.0001998  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:03:56 d2.utils.events]: \u001b[0m eta: 1:09:09  iter: 419  total_loss: 1.743  loss_cls: 0.4257  loss_box_reg: 0.6076  loss_mask: 0.3243  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.2186  time: 0.6466  data_time: 0.1781  lr: 0.00020979  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:04:06 d2.utils.events]: \u001b[0m eta: 1:09:00  iter: 439  total_loss: 1.638  loss_cls: 0.4043  loss_box_reg: 0.5986  loss_mask: 0.3179  loss_rpn_cls: 0.08804  loss_rpn_loc: 0.2102  time: 0.6399  data_time: 0.0877  lr: 0.00021978  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:04:19 d2.utils.events]: \u001b[0m eta: 1:08:52  iter: 459  total_loss: 1.692  loss_cls: 0.4191  loss_box_reg: 0.5992  loss_mask: 0.3125  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.231  time: 0.6403  data_time: 0.2190  lr: 0.00022977  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:04:30 d2.utils.events]: \u001b[0m eta: 1:08:38  iter: 479  total_loss: 1.697  loss_cls: 0.4128  loss_box_reg: 0.6139  loss_mask: 0.3228  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.2265  time: 0.6369  data_time: 0.1526  lr: 0.00023976  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:04:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:04:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:04:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:04:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:04:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:04:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0283 s/iter. Total: 0.1026 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 11:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0756 s/iter. Eval: 0.0438 s/iter. Total: 0.1200 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 11:04:46 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0760 s/iter. Eval: 0.0468 s/iter. Total: 0.1236 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 11:04:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.050688 (0.121127 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:04:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075590 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:04:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:04:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20961589989317936\n",
      "\u001b[32m[02/04 11:04:57 d2.utils.events]: \u001b[0m eta: 1:08:30  iter: 499  total_loss: 1.574  loss_cls: 0.4066  loss_box_reg: 0.5696  loss_mask: 0.3174  loss_rpn_cls: 0.09297  loss_rpn_loc: 0.2207  time: 0.6353  data_time: 0.1867  lr: 0.00024975  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:05:08 d2.utils.events]: \u001b[0m eta: 1:08:21  iter: 519  total_loss: 1.663  loss_cls: 0.3937  loss_box_reg: 0.5695  loss_mask: 0.3239  loss_rpn_cls: 0.1276  loss_rpn_loc: 0.2306  time: 0.6314  data_time: 0.1185  lr: 0.00025974  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:05:18 d2.utils.events]: \u001b[0m eta: 1:08:10  iter: 539  total_loss: 1.631  loss_cls: 0.4017  loss_box_reg: 0.6039  loss_mask: 0.3211  loss_rpn_cls: 0.09807  loss_rpn_loc: 0.2023  time: 0.6258  data_time: 0.0680  lr: 0.00026973  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:05:33 d2.utils.events]: \u001b[0m eta: 1:08:04  iter: 559  total_loss: 1.742  loss_cls: 0.4447  loss_box_reg: 0.6029  loss_mask: 0.3314  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.2266  time: 0.6300  data_time: 0.3116  lr: 0.00027972  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:05:43 d2.utils.events]: \u001b[0m eta: 1:07:51  iter: 579  total_loss: 1.586  loss_cls: 0.3838  loss_box_reg: 0.5703  loss_mask: 0.3271  loss_rpn_cls: 0.09381  loss_rpn_loc: 0.2182  time: 0.6259  data_time: 0.1047  lr: 0.00028971  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:05:55 d2.utils.events]: \u001b[0m eta: 1:07:46  iter: 599  total_loss: 1.608  loss_cls: 0.428  loss_box_reg: 0.5645  loss_mask: 0.3142  loss_rpn_cls: 0.1167  loss_rpn_loc: 0.2177  time: 0.6258  data_time: 0.1941  lr: 0.0002997  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:06:10 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 619  total_loss: 1.559  loss_cls: 0.3815  loss_box_reg: 0.5585  loss_mask: 0.319  loss_rpn_cls: 0.07869  loss_rpn_loc: 0.2153  time: 0.6286  data_time: 0.2781  lr: 0.00030969  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:06:24 d2.utils.events]: \u001b[0m eta: 1:07:37  iter: 639  total_loss: 1.671  loss_cls: 0.3996  loss_box_reg: 0.5681  loss_mask: 0.3142  loss_rpn_cls: 0.131  loss_rpn_loc: 0.2022  time: 0.6315  data_time: 0.2943  lr: 0.00031968  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:06:37 d2.utils.events]: \u001b[0m eta: 1:07:28  iter: 659  total_loss: 1.519  loss_cls: 0.3944  loss_box_reg: 0.5278  loss_mask: 0.3077  loss_rpn_cls: 0.09512  loss_rpn_loc: 0.1963  time: 0.6327  data_time: 0.2410  lr: 0.00032967  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:06:49 d2.utils.events]: \u001b[0m eta: 1:07:21  iter: 679  total_loss: 1.715  loss_cls: 0.4273  loss_box_reg: 0.5748  loss_mask: 0.3207  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.2356  time: 0.6313  data_time: 0.1659  lr: 0.00033966  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:07:03 d2.utils.events]: \u001b[0m eta: 1:07:15  iter: 699  total_loss: 1.669  loss_cls: 0.4199  loss_box_reg: 0.5835  loss_mask: 0.329  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.2017  time: 0.6334  data_time: 0.2696  lr: 0.00034965  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:07:14 d2.utils.events]: \u001b[0m eta: 1:07:12  iter: 719  total_loss: 1.624  loss_cls: 0.3817  loss_box_reg: 0.6082  loss_mask: 0.2974  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2055  time: 0.6302  data_time: 0.0989  lr: 0.00035964  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:07:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:07:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:07:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:07:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:07:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:07:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:07:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0742 s/iter. Eval: 0.0343 s/iter. Total: 0.1091 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 55/121. Dataloading: 0.0007 s/iter. Inference: 0.0748 s/iter. Eval: 0.0394 s/iter. Total: 0.1149 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 11:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0007 s/iter. Inference: 0.0745 s/iter. Eval: 0.0382 s/iter. Total: 0.1135 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 11:07:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.166687 (0.113506 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:07:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.074490 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:07:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:07:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22638107652895292\n",
      "\u001b[32m[02/04 11:07:39 d2.utils.events]: \u001b[0m eta: 1:06:57  iter: 739  total_loss: 1.485  loss_cls: 0.3369  loss_box_reg: 0.5507  loss_mask: 0.3263  loss_rpn_cls: 0.06865  loss_rpn_loc: 0.1992  time: 0.6277  data_time: 0.1217  lr: 0.00036963  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:07:48 d2.utils.events]: \u001b[0m eta: 1:06:41  iter: 759  total_loss: 1.424  loss_cls: 0.3498  loss_box_reg: 0.5676  loss_mask: 0.2904  loss_rpn_cls: 0.07682  loss_rpn_loc: 0.1732  time: 0.6235  data_time: 0.0657  lr: 0.00037962  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:08:02 d2.utils.events]: \u001b[0m eta: 1:06:40  iter: 779  total_loss: 1.576  loss_cls: 0.3992  loss_box_reg: 0.5216  loss_mask: 0.2982  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.2178  time: 0.6250  data_time: 0.2527  lr: 0.00038961  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:08:15 d2.utils.events]: \u001b[0m eta: 1:06:32  iter: 799  total_loss: 1.667  loss_cls: 0.4129  loss_box_reg: 0.5904  loss_mask: 0.3295  loss_rpn_cls: 0.1187  loss_rpn_loc: 0.2481  time: 0.6262  data_time: 0.2507  lr: 0.0003996  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:08:26 d2.utils.events]: \u001b[0m eta: 1:06:28  iter: 819  total_loss: 1.551  loss_cls: 0.3965  loss_box_reg: 0.5622  loss_mask: 0.315  loss_rpn_cls: 0.09518  loss_rpn_loc: 0.1951  time: 0.6244  data_time: 0.1316  lr: 0.00040959  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:08:40 d2.utils.events]: \u001b[0m eta: 1:06:25  iter: 839  total_loss: 1.524  loss_cls: 0.3768  loss_box_reg: 0.5529  loss_mask: 0.3166  loss_rpn_cls: 0.08763  loss_rpn_loc: 0.1967  time: 0.6253  data_time: 0.2373  lr: 0.00041958  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:08:54 d2.utils.events]: \u001b[0m eta: 1:06:30  iter: 859  total_loss: 1.604  loss_cls: 0.4031  loss_box_reg: 0.5617  loss_mask: 0.3288  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.2258  time: 0.6274  data_time: 0.2912  lr: 0.00042957  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:09:05 d2.utils.events]: \u001b[0m eta: 1:06:13  iter: 879  total_loss: 1.586  loss_cls: 0.3745  loss_box_reg: 0.5589  loss_mask: 0.3091  loss_rpn_cls: 0.09102  loss_rpn_loc: 0.1993  time: 0.6257  data_time: 0.1400  lr: 0.00043956  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:09:16 d2.utils.events]: \u001b[0m eta: 1:06:07  iter: 899  total_loss: 1.558  loss_cls: 0.3802  loss_box_reg: 0.5497  loss_mask: 0.3001  loss_rpn_cls: 0.0776  loss_rpn_loc: 0.1913  time: 0.6235  data_time: 0.1042  lr: 0.00044955  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:09:30 d2.utils.events]: \u001b[0m eta: 1:06:06  iter: 919  total_loss: 1.567  loss_cls: 0.3706  loss_box_reg: 0.5382  loss_mask: 0.2946  loss_rpn_cls: 0.1159  loss_rpn_loc: 0.2128  time: 0.6255  data_time: 0.2955  lr: 0.00045954  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:09:43 d2.utils.events]: \u001b[0m eta: 1:05:58  iter: 939  total_loss: 1.555  loss_cls: 0.3707  loss_box_reg: 0.5672  loss_mask: 0.3114  loss_rpn_cls: 0.08095  loss_rpn_loc: 0.2019  time: 0.6259  data_time: 0.2101  lr: 0.00046953  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:09:57 d2.utils.events]: \u001b[0m eta: 1:05:53  iter: 959  total_loss: 1.739  loss_cls: 0.4756  loss_box_reg: 0.5769  loss_mask: 0.3138  loss_rpn_cls: 0.1242  loss_rpn_loc: 0.2198  time: 0.6279  data_time: 0.2812  lr: 0.00047952  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:10:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:10:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:10:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:10:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:10:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:10:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0750 s/iter. Eval: 0.0357 s/iter. Total: 0.1113 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0007 s/iter. Inference: 0.0756 s/iter. Eval: 0.0443 s/iter. Total: 0.1207 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 11:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0007 s/iter. Inference: 0.0760 s/iter. Eval: 0.0478 s/iter. Total: 0.1246 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 11:10:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.195840 (0.122378 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:10:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075644 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:10:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:10:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23596652566853776\n",
      "\u001b[32m[02/04 11:10:24 d2.utils.events]: \u001b[0m eta: 1:05:41  iter: 979  total_loss: 1.612  loss_cls: 0.4086  loss_box_reg: 0.5489  loss_mask: 0.3132  loss_rpn_cls: 0.08185  loss_rpn_loc: 0.1988  time: 0.6269  data_time: 0.1634  lr: 0.00048951  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:10:36 d2.utils.events]: \u001b[0m eta: 1:05:33  iter: 999  total_loss: 1.589  loss_cls: 0.3819  loss_box_reg: 0.5581  loss_mask: 0.32  loss_rpn_cls: 0.09815  loss_rpn_loc: 0.2092  time: 0.6262  data_time: 0.1696  lr: 0.0004995  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:10:50 d2.utils.events]: \u001b[0m eta: 1:05:26  iter: 1019  total_loss: 1.569  loss_cls: 0.3843  loss_box_reg: 0.5461  loss_mask: 0.2966  loss_rpn_cls: 0.08678  loss_rpn_loc: 0.1998  time: 0.6276  data_time: 0.2681  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:11:03 d2.utils.events]: \u001b[0m eta: 1:05:21  iter: 1039  total_loss: 1.459  loss_cls: 0.368  loss_box_reg: 0.5374  loss_mask: 0.3006  loss_rpn_cls: 0.08932  loss_rpn_loc: 0.2054  time: 0.6279  data_time: 0.2258  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:11:14 d2.utils.events]: \u001b[0m eta: 1:05:14  iter: 1059  total_loss: 1.533  loss_cls: 0.3741  loss_box_reg: 0.5599  loss_mask: 0.304  loss_rpn_cls: 0.08305  loss_rpn_loc: 0.2002  time: 0.6268  data_time: 0.1536  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:11:25 d2.utils.events]: \u001b[0m eta: 1:05:12  iter: 1079  total_loss: 1.562  loss_cls: 0.3879  loss_box_reg: 0.5699  loss_mask: 0.314  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.2026  time: 0.6247  data_time: 0.1002  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:11:38 d2.utils.events]: \u001b[0m eta: 1:05:01  iter: 1099  total_loss: 1.454  loss_cls: 0.3381  loss_box_reg: 0.534  loss_mask: 0.3004  loss_rpn_cls: 0.09257  loss_rpn_loc: 0.2073  time: 0.6249  data_time: 0.2256  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:11:52 d2.utils.events]: \u001b[0m eta: 1:04:59  iter: 1119  total_loss: 1.602  loss_cls: 0.4024  loss_box_reg: 0.5568  loss_mask: 0.3157  loss_rpn_cls: 0.07886  loss_rpn_loc: 0.2134  time: 0.6263  data_time: 0.2679  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:12:01 d2.utils.events]: \u001b[0m eta: 1:04:46  iter: 1139  total_loss: 1.444  loss_cls: 0.3769  loss_box_reg: 0.5263  loss_mask: 0.2858  loss_rpn_cls: 0.08086  loss_rpn_loc: 0.1738  time: 0.6239  data_time: 0.0745  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:12:12 d2.utils.events]: \u001b[0m eta: 1:04:37  iter: 1159  total_loss: 1.638  loss_cls: 0.3874  loss_box_reg: 0.5711  loss_mask: 0.3289  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.2242  time: 0.6220  data_time: 0.0929  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:12:27 d2.utils.events]: \u001b[0m eta: 1:04:30  iter: 1179  total_loss: 1.61  loss_cls: 0.4108  loss_box_reg: 0.5604  loss_mask: 0.3235  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2206  time: 0.6241  data_time: 0.3163  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:12:42 d2.utils.events]: \u001b[0m eta: 1:04:32  iter: 1199  total_loss: 1.698  loss_cls: 0.4471  loss_box_reg: 0.5625  loss_mask: 0.3129  loss_rpn_cls: 0.106  loss_rpn_loc: 0.2275  time: 0.6264  data_time: 0.3115  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:12:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:12:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:12:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:12:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:12:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:12:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:12:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0743 s/iter. Eval: 0.0328 s/iter. Total: 0.1077 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 11:12:55 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0762 s/iter. Eval: 0.0489 s/iter. Total: 0.1259 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 11:13:00 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0765 s/iter. Eval: 0.0510 s/iter. Total: 0.1282 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:13:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.733344 (0.127012 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:13:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076238 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:13:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:13:04 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24513188363856683\n",
      "\u001b[32m[02/04 11:13:09 d2.utils.events]: \u001b[0m eta: 1:04:23  iter: 1219  total_loss: 1.568  loss_cls: 0.3855  loss_box_reg: 0.5693  loss_mask: 0.3079  loss_rpn_cls: 0.09143  loss_rpn_loc: 0.1957  time: 0.6255  data_time: 0.1480  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:13:24 d2.utils.events]: \u001b[0m eta: 1:04:14  iter: 1239  total_loss: 1.609  loss_cls: 0.4047  loss_box_reg: 0.5557  loss_mask: 0.3093  loss_rpn_cls: 0.09433  loss_rpn_loc: 0.2122  time: 0.6269  data_time: 0.2775  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:13:37 d2.utils.events]: \u001b[0m eta: 1:04:05  iter: 1259  total_loss: 1.459  loss_cls: 0.3566  loss_box_reg: 0.5442  loss_mask: 0.3049  loss_rpn_cls: 0.08145  loss_rpn_loc: 0.1972  time: 0.6273  data_time: 0.2167  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:13:47 d2.utils.events]: \u001b[0m eta: 1:03:53  iter: 1279  total_loss: 1.614  loss_cls: 0.4155  loss_box_reg: 0.5674  loss_mask: 0.3129  loss_rpn_cls: 0.09066  loss_rpn_loc: 0.2179  time: 0.6259  data_time: 0.1196  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:14:00 d2.utils.events]: \u001b[0m eta: 1:03:47  iter: 1299  total_loss: 1.576  loss_cls: 0.3841  loss_box_reg: 0.5407  loss_mask: 0.3008  loss_rpn_cls: 0.07909  loss_rpn_loc: 0.1989  time: 0.6263  data_time: 0.2187  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:14:10 d2.utils.events]: \u001b[0m eta: 1:03:32  iter: 1319  total_loss: 1.507  loss_cls: 0.3746  loss_box_reg: 0.5404  loss_mask: 0.2943  loss_rpn_cls: 0.08128  loss_rpn_loc: 0.1977  time: 0.6242  data_time: 0.0746  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:14:26 d2.utils.events]: \u001b[0m eta: 1:03:30  iter: 1339  total_loss: 1.543  loss_cls: 0.4125  loss_box_reg: 0.5093  loss_mask: 0.3047  loss_rpn_cls: 0.111  loss_rpn_loc: 0.1963  time: 0.6264  data_time: 0.3397  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:14:37 d2.utils.events]: \u001b[0m eta: 1:03:19  iter: 1359  total_loss: 1.58  loss_cls: 0.3967  loss_box_reg: 0.5595  loss_mask: 0.3196  loss_rpn_cls: 0.07892  loss_rpn_loc: 0.2076  time: 0.6254  data_time: 0.1423  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:14:51 d2.utils.events]: \u001b[0m eta: 1:03:13  iter: 1379  total_loss: 1.579  loss_cls: 0.3862  loss_box_reg: 0.556  loss_mask: 0.3085  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2151  time: 0.6264  data_time: 0.2657  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:15:03 d2.utils.events]: \u001b[0m eta: 1:03:04  iter: 1399  total_loss: 1.571  loss_cls: 0.3895  loss_box_reg: 0.5366  loss_mask: 0.3108  loss_rpn_cls: 0.09041  loss_rpn_loc: 0.2166  time: 0.6260  data_time: 0.1754  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:15:15 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 1419  total_loss: 1.51  loss_cls: 0.3857  loss_box_reg: 0.546  loss_mask: 0.296  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1832  time: 0.6257  data_time: 0.1856  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:15:28 d2.utils.events]: \u001b[0m eta: 1:02:46  iter: 1439  total_loss: 1.595  loss_cls: 0.3778  loss_box_reg: 0.5603  loss_mask: 0.3102  loss_rpn_cls: 0.09621  loss_rpn_loc: 0.2226  time: 0.6259  data_time: 0.2191  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:15:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:15:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:15:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:15:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:15:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:15:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0345 s/iter. Total: 0.1096 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0548 s/iter. Total: 0.1325 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0578 s/iter. Total: 0.1359 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 11:15:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.578804 (0.134300 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:15:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077056 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:15:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:15:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2502587207546032\n",
      "\u001b[32m[02/04 11:15:55 d2.utils.events]: \u001b[0m eta: 1:02:38  iter: 1459  total_loss: 1.528  loss_cls: 0.3985  loss_box_reg: 0.5498  loss_mask: 0.3034  loss_rpn_cls: 0.08605  loss_rpn_loc: 0.2229  time: 0.6247  data_time: 0.1210  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:16:08 d2.utils.events]: \u001b[0m eta: 1:02:30  iter: 1479  total_loss: 1.493  loss_cls: 0.3903  loss_box_reg: 0.5392  loss_mask: 0.3011  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1912  time: 0.6245  data_time: 0.1823  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:16:21 d2.utils.events]: \u001b[0m eta: 1:02:22  iter: 1499  total_loss: 1.46  loss_cls: 0.3711  loss_box_reg: 0.5548  loss_mask: 0.2897  loss_rpn_cls: 0.07363  loss_rpn_loc: 0.1858  time: 0.6248  data_time: 0.2209  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:16:33 d2.utils.events]: \u001b[0m eta: 1:02:18  iter: 1519  total_loss: 1.671  loss_cls: 0.4089  loss_box_reg: 0.5854  loss_mask: 0.3306  loss_rpn_cls: 0.08626  loss_rpn_loc: 0.2112  time: 0.6248  data_time: 0.2022  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:16:43 d2.utils.events]: \u001b[0m eta: 1:02:03  iter: 1539  total_loss: 1.378  loss_cls: 0.3149  loss_box_reg: 0.5416  loss_mask: 0.2988  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.175  time: 0.6231  data_time: 0.0991  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:16:57 d2.utils.events]: \u001b[0m eta: 1:01:58  iter: 1559  total_loss: 1.544  loss_cls: 0.394  loss_box_reg: 0.5519  loss_mask: 0.3135  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.1986  time: 0.6244  data_time: 0.2817  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:17:11 d2.utils.events]: \u001b[0m eta: 1:01:54  iter: 1579  total_loss: 1.537  loss_cls: 0.3595  loss_box_reg: 0.5356  loss_mask: 0.2982  loss_rpn_cls: 0.07169  loss_rpn_loc: 0.2117  time: 0.6249  data_time: 0.2395  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:17:25 d2.utils.events]: \u001b[0m eta: 1:01:44  iter: 1599  total_loss: 1.632  loss_cls: 0.4032  loss_box_reg: 0.5576  loss_mask: 0.3148  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2091  time: 0.6262  data_time: 0.2934  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:17:38 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 1619  total_loss: 1.464  loss_cls: 0.3638  loss_box_reg: 0.5334  loss_mask: 0.2961  loss_rpn_cls: 0.06691  loss_rpn_loc: 0.2002  time: 0.6262  data_time: 0.1953  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:17:49 d2.utils.events]: \u001b[0m eta: 1:01:19  iter: 1639  total_loss: 1.478  loss_cls: 0.3574  loss_box_reg: 0.5281  loss_mask: 0.2892  loss_rpn_cls: 0.07465  loss_rpn_loc: 0.2308  time: 0.6252  data_time: 0.1373  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:18:00 d2.utils.events]: \u001b[0m eta: 1:01:09  iter: 1659  total_loss: 1.582  loss_cls: 0.4008  loss_box_reg: 0.5469  loss_mask: 0.3094  loss_rpn_cls: 0.09865  loss_rpn_loc: 0.2094  time: 0.6247  data_time: 0.1687  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:18:10 d2.utils.events]: \u001b[0m eta: 1:00:58  iter: 1679  total_loss: 1.558  loss_cls: 0.3785  loss_box_reg: 0.4943  loss_mask: 0.3003  loss_rpn_cls: 0.09649  loss_rpn_loc: 0.2148  time: 0.6230  data_time: 0.0823  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:18:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:18:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:18:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:18:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:18:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:18:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0332 s/iter. Total: 0.1079 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 11:18:26 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0759 s/iter. Eval: 0.0473 s/iter. Total: 0.1238 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 11:18:31 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0007 s/iter. Inference: 0.0760 s/iter. Eval: 0.0482 s/iter. Total: 0.1249 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 11:18:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.286958 (0.123163 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:18:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.075696 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:18:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:18:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24885544750495478\n",
      "\u001b[32m[02/04 11:18:41 d2.utils.events]: \u001b[0m eta: 1:00:47  iter: 1699  total_loss: 1.666  loss_cls: 0.4354  loss_box_reg: 0.5395  loss_mask: 0.3171  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.2222  time: 0.6247  data_time: 0.3248  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:18:53 d2.utils.events]: \u001b[0m eta: 1:00:38  iter: 1719  total_loss: 1.46  loss_cls: 0.3512  loss_box_reg: 0.5163  loss_mask: 0.28  loss_rpn_cls: 0.06891  loss_rpn_loc: 0.2067  time: 0.6244  data_time: 0.1834  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:19:05 d2.utils.events]: \u001b[0m eta: 1:00:34  iter: 1739  total_loss: 1.557  loss_cls: 0.369  loss_box_reg: 0.5857  loss_mask: 0.3229  loss_rpn_cls: 0.07745  loss_rpn_loc: 0.1936  time: 0.6241  data_time: 0.1774  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:19:17 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 1759  total_loss: 1.501  loss_cls: 0.3854  loss_box_reg: 0.5386  loss_mask: 0.3029  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.175  time: 0.6235  data_time: 0.1634  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:19:28 d2.utils.events]: \u001b[0m eta: 1:00:16  iter: 1779  total_loss: 1.513  loss_cls: 0.3679  loss_box_reg: 0.5414  loss_mask: 0.3138  loss_rpn_cls: 0.09777  loss_rpn_loc: 0.2027  time: 0.6230  data_time: 0.1603  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:19:43 d2.utils.events]: \u001b[0m eta: 1:00:08  iter: 1799  total_loss: 1.544  loss_cls: 0.3742  loss_box_reg: 0.5316  loss_mask: 0.305  loss_rpn_cls: 0.08325  loss_rpn_loc: 0.2088  time: 0.6242  data_time: 0.2941  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:19:56 d2.utils.events]: \u001b[0m eta: 1:00:01  iter: 1819  total_loss: 1.537  loss_cls: 0.3696  loss_box_reg: 0.5524  loss_mask: 0.3009  loss_rpn_cls: 0.09723  loss_rpn_loc: 0.2143  time: 0.6244  data_time: 0.2203  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:20:11 d2.utils.events]: \u001b[0m eta: 0:59:57  iter: 1839  total_loss: 1.561  loss_cls: 0.3945  loss_box_reg: 0.5417  loss_mask: 0.3168  loss_rpn_cls: 0.09437  loss_rpn_loc: 0.2021  time: 0.6259  data_time: 0.3131  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:20:23 d2.utils.events]: \u001b[0m eta: 0:59:41  iter: 1859  total_loss: 1.454  loss_cls: 0.3691  loss_box_reg: 0.5446  loss_mask: 0.3009  loss_rpn_cls: 0.05659  loss_rpn_loc: 0.1871  time: 0.6254  data_time: 0.1737  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:20:38 d2.utils.events]: \u001b[0m eta: 0:59:36  iter: 1879  total_loss: 1.553  loss_cls: 0.3984  loss_box_reg: 0.5533  loss_mask: 0.3084  loss_rpn_cls: 0.09002  loss_rpn_loc: 0.2168  time: 0.6269  data_time: 0.3306  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:20:48 d2.utils.events]: \u001b[0m eta: 0:59:29  iter: 1899  total_loss: 1.497  loss_cls: 0.3721  loss_box_reg: 0.5276  loss_mask: 0.2898  loss_rpn_cls: 0.09604  loss_rpn_loc: 0.2049  time: 0.6255  data_time: 0.0897  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:21:01 d2.utils.events]: \u001b[0m eta: 0:59:23  iter: 1919  total_loss: 1.513  loss_cls: 0.3718  loss_box_reg: 0.5317  loss_mask: 0.3049  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.1933  time: 0.6260  data_time: 0.2363  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:21:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:21:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:21:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:21:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:21:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:21:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0331 s/iter. Total: 0.1078 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 11:21:18 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0764 s/iter. Eval: 0.0505 s/iter. Total: 0.1276 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:21:23 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0767 s/iter. Eval: 0.0535 s/iter. Total: 0.1310 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:21:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.115447 (0.130306 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:21:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076494 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:21:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:21:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25142089363170095\n",
      "\u001b[32m[02/04 11:21:29 d2.utils.events]: \u001b[0m eta: 0:59:09  iter: 1939  total_loss: 1.51  loss_cls: 0.378  loss_box_reg: 0.5591  loss_mask: 0.3123  loss_rpn_cls: 0.08318  loss_rpn_loc: 0.2077  time: 0.6253  data_time: 0.1467  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:21:40 d2.utils.events]: \u001b[0m eta: 0:58:58  iter: 1959  total_loss: 1.535  loss_cls: 0.3904  loss_box_reg: 0.549  loss_mask: 0.2973  loss_rpn_cls: 0.0899  loss_rpn_loc: 0.195  time: 0.6245  data_time: 0.1308  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:21:51 d2.utils.events]: \u001b[0m eta: 0:58:49  iter: 1979  total_loss: 1.468  loss_cls: 0.3447  loss_box_reg: 0.5286  loss_mask: 0.3035  loss_rpn_cls: 0.06396  loss_rpn_loc: 0.1983  time: 0.6236  data_time: 0.1297  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:22:04 d2.utils.events]: \u001b[0m eta: 0:58:42  iter: 1999  total_loss: 1.595  loss_cls: 0.394  loss_box_reg: 0.5452  loss_mask: 0.3063  loss_rpn_cls: 0.07855  loss_rpn_loc: 0.1996  time: 0.6242  data_time: 0.2491  lr: 0.0005  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:22:18 d2.utils.events]: \u001b[0m eta: 0:58:33  iter: 2019  total_loss: 1.529  loss_cls: 0.3525  loss_box_reg: 0.5243  loss_mask: 0.2991  loss_rpn_cls: 0.07717  loss_rpn_loc: 0.1901  time: 0.6249  data_time: 0.2792  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:22:33 d2.utils.events]: \u001b[0m eta: 0:58:24  iter: 2039  total_loss: 1.531  loss_cls: 0.3868  loss_box_reg: 0.5195  loss_mask: 0.323  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.2186  time: 0.6262  data_time: 0.3231  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:22:46 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 2059  total_loss: 1.582  loss_cls: 0.4063  loss_box_reg: 0.5373  loss_mask: 0.3047  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.2175  time: 0.6264  data_time: 0.2254  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:22:59 d2.utils.events]: \u001b[0m eta: 0:58:11  iter: 2079  total_loss: 1.526  loss_cls: 0.3742  loss_box_reg: 0.5099  loss_mask: 0.3012  loss_rpn_cls: 0.07493  loss_rpn_loc: 0.1988  time: 0.6263  data_time: 0.1986  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:23:12 d2.utils.events]: \u001b[0m eta: 0:58:03  iter: 2099  total_loss: 1.51  loss_cls: 0.3806  loss_box_reg: 0.5478  loss_mask: 0.3078  loss_rpn_cls: 0.09722  loss_rpn_loc: 0.1898  time: 0.6267  data_time: 0.2323  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:23:22 d2.utils.events]: \u001b[0m eta: 0:57:50  iter: 2119  total_loss: 1.52  loss_cls: 0.3631  loss_box_reg: 0.5633  loss_mask: 0.3079  loss_rpn_cls: 0.07389  loss_rpn_loc: 0.1972  time: 0.6254  data_time: 0.0691  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:23:33 d2.utils.events]: \u001b[0m eta: 0:57:41  iter: 2139  total_loss: 1.48  loss_cls: 0.3728  loss_box_reg: 0.5524  loss_mask: 0.3073  loss_rpn_cls: 0.07593  loss_rpn_loc: 0.1897  time: 0.6250  data_time: 0.1574  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:23:47 d2.utils.events]: \u001b[0m eta: 0:57:31  iter: 2159  total_loss: 1.703  loss_cls: 0.4214  loss_box_reg: 0.5502  loss_mask: 0.3267  loss_rpn_cls: 0.09337  loss_rpn_loc: 0.2148  time: 0.6253  data_time: 0.2311  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:24:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:24:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:24:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:24:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:24:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:24:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0360 s/iter. Total: 0.1110 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0764 s/iter. Eval: 0.0513 s/iter. Total: 0.1286 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0767 s/iter. Eval: 0.0536 s/iter. Total: 0.1311 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:24:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.053965 (0.129776 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:24:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076458 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:24:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:24:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2562451963473163\n",
      "\u001b[32m[02/04 11:24:17 d2.utils.events]: \u001b[0m eta: 0:57:23  iter: 2179  total_loss: 1.501  loss_cls: 0.3793  loss_box_reg: 0.5108  loss_mask: 0.2862  loss_rpn_cls: 0.08078  loss_rpn_loc: 0.2099  time: 0.6258  data_time: 0.2549  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:24:31 d2.utils.events]: \u001b[0m eta: 0:57:11  iter: 2199  total_loss: 1.499  loss_cls: 0.3834  loss_box_reg: 0.514  loss_mask: 0.3063  loss_rpn_cls: 0.09631  loss_rpn_loc: 0.2118  time: 0.6265  data_time: 0.2822  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:24:43 d2.utils.events]: \u001b[0m eta: 0:57:06  iter: 2219  total_loss: 1.513  loss_cls: 0.3838  loss_box_reg: 0.5084  loss_mask: 0.2988  loss_rpn_cls: 0.07762  loss_rpn_loc: 0.1881  time: 0.6265  data_time: 0.1842  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:24:58 d2.utils.events]: \u001b[0m eta: 0:56:59  iter: 2239  total_loss: 1.476  loss_cls: 0.3596  loss_box_reg: 0.5287  loss_mask: 0.3058  loss_rpn_cls: 0.07886  loss_rpn_loc: 0.2042  time: 0.6273  data_time: 0.2829  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:25:10 d2.utils.events]: \u001b[0m eta: 0:56:54  iter: 2259  total_loss: 1.555  loss_cls: 0.4064  loss_box_reg: 0.538  loss_mask: 0.3055  loss_rpn_cls: 0.09315  loss_rpn_loc: 0.1986  time: 0.6273  data_time: 0.1862  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:25:22 d2.utils.events]: \u001b[0m eta: 0:56:45  iter: 2279  total_loss: 1.559  loss_cls: 0.4025  loss_box_reg: 0.5484  loss_mask: 0.3062  loss_rpn_cls: 0.0892  loss_rpn_loc: 0.2168  time: 0.6268  data_time: 0.1515  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:25:34 d2.utils.events]: \u001b[0m eta: 0:56:35  iter: 2299  total_loss: 1.59  loss_cls: 0.3853  loss_box_reg: 0.5327  loss_mask: 0.3065  loss_rpn_cls: 0.08787  loss_rpn_loc: 0.2017  time: 0.6267  data_time: 0.1909  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:25:45 d2.utils.events]: \u001b[0m eta: 0:56:26  iter: 2319  total_loss: 1.473  loss_cls: 0.3548  loss_box_reg: 0.5163  loss_mask: 0.3057  loss_rpn_cls: 0.07369  loss_rpn_loc: 0.2003  time: 0.6261  data_time: 0.1487  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:25:57 d2.utils.events]: \u001b[0m eta: 0:56:12  iter: 2339  total_loss: 1.482  loss_cls: 0.3539  loss_box_reg: 0.5366  loss_mask: 0.318  loss_rpn_cls: 0.08337  loss_rpn_loc: 0.1969  time: 0.6257  data_time: 0.1627  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:26:07 d2.utils.events]: \u001b[0m eta: 0:56:00  iter: 2359  total_loss: 1.462  loss_cls: 0.3782  loss_box_reg: 0.5385  loss_mask: 0.2951  loss_rpn_cls: 0.08041  loss_rpn_loc: 0.1976  time: 0.6248  data_time: 0.1072  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:26:17 d2.utils.events]: \u001b[0m eta: 0:55:49  iter: 2379  total_loss: 1.522  loss_cls: 0.3643  loss_box_reg: 0.5683  loss_mask: 0.3169  loss_rpn_cls: 0.06666  loss_rpn_loc: 0.192  time: 0.6236  data_time: 0.0651  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:26:30 d2.utils.events]: \u001b[0m eta: 0:55:41  iter: 2399  total_loss: 1.495  loss_cls: 0.3626  loss_box_reg: 0.5418  loss_mask: 0.3  loss_rpn_cls: 0.0921  loss_rpn_loc: 0.2002  time: 0.6240  data_time: 0.2322  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:26:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:26:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:26:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:26:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:26:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:26:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:26:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0335 s/iter. Total: 0.1086 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 11:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0762 s/iter. Eval: 0.0493 s/iter. Total: 0.1263 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 11:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0764 s/iter. Eval: 0.0509 s/iter. Total: 0.1280 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:26:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.705819 (0.126774 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:26:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076138 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:26:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:26:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2552590943423279\n",
      "\u001b[32m[02/04 11:26:58 d2.utils.events]: \u001b[0m eta: 0:55:32  iter: 2419  total_loss: 1.425  loss_cls: 0.3521  loss_box_reg: 0.5188  loss_mask: 0.3005  loss_rpn_cls: 0.0721  loss_rpn_loc: 0.1731  time: 0.6236  data_time: 0.1552  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:27:11 d2.utils.events]: \u001b[0m eta: 0:55:27  iter: 2439  total_loss: 1.474  loss_cls: 0.3603  loss_box_reg: 0.5378  loss_mask: 0.2951  loss_rpn_cls: 0.07131  loss_rpn_loc: 0.2089  time: 0.6238  data_time: 0.2219  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:27:25 d2.utils.events]: \u001b[0m eta: 0:55:20  iter: 2459  total_loss: 1.475  loss_cls: 0.3744  loss_box_reg: 0.5122  loss_mask: 0.303  loss_rpn_cls: 0.09153  loss_rpn_loc: 0.2201  time: 0.6244  data_time: 0.2573  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:27:39 d2.utils.events]: \u001b[0m eta: 0:55:15  iter: 2479  total_loss: 1.546  loss_cls: 0.3767  loss_box_reg: 0.5389  loss_mask: 0.3136  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.22  time: 0.6252  data_time: 0.2766  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:27:49 d2.utils.events]: \u001b[0m eta: 0:55:01  iter: 2499  total_loss: 1.446  loss_cls: 0.3569  loss_box_reg: 0.5317  loss_mask: 0.2995  loss_rpn_cls: 0.06315  loss_rpn_loc: 0.1866  time: 0.6242  data_time: 0.1052  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:28:01 d2.utils.events]: \u001b[0m eta: 0:54:48  iter: 2519  total_loss: 1.472  loss_cls: 0.3672  loss_box_reg: 0.5269  loss_mask: 0.2871  loss_rpn_cls: 0.08458  loss_rpn_loc: 0.1896  time: 0.6241  data_time: 0.1982  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:28:14 d2.utils.events]: \u001b[0m eta: 0:54:45  iter: 2539  total_loss: 1.49  loss_cls: 0.3779  loss_box_reg: 0.5356  loss_mask: 0.2946  loss_rpn_cls: 0.07855  loss_rpn_loc: 0.2005  time: 0.6242  data_time: 0.2126  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:28:27 d2.utils.events]: \u001b[0m eta: 0:54:32  iter: 2559  total_loss: 1.505  loss_cls: 0.3586  loss_box_reg: 0.5345  loss_mask: 0.3127  loss_rpn_cls: 0.09094  loss_rpn_loc: 0.2105  time: 0.6241  data_time: 0.1923  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:28:39 d2.utils.events]: \u001b[0m eta: 0:54:25  iter: 2579  total_loss: 1.512  loss_cls: 0.374  loss_box_reg: 0.5509  loss_mask: 0.2984  loss_rpn_cls: 0.08534  loss_rpn_loc: 0.2156  time: 0.6242  data_time: 0.2208  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:28:50 d2.utils.events]: \u001b[0m eta: 0:54:13  iter: 2599  total_loss: 1.461  loss_cls: 0.3443  loss_box_reg: 0.5363  loss_mask: 0.3038  loss_rpn_cls: 0.08419  loss_rpn_loc: 0.167  time: 0.6235  data_time: 0.1125  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:29:04 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 2619  total_loss: 1.528  loss_cls: 0.3809  loss_box_reg: 0.5334  loss_mask: 0.3145  loss_rpn_cls: 0.08754  loss_rpn_loc: 0.2072  time: 0.6242  data_time: 0.2794  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:29:15 d2.utils.events]: \u001b[0m eta: 0:53:59  iter: 2639  total_loss: 1.412  loss_cls: 0.3338  loss_box_reg: 0.5283  loss_mask: 0.3009  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.1795  time: 0.6236  data_time: 0.1275  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:29:26 d2.utils.events]: \u001b[0m eta: 0:53:50  iter: 2659  total_loss: 1.436  loss_cls: 0.3623  loss_box_reg: 0.5285  loss_mask: 0.2973  loss_rpn_cls: 0.08298  loss_rpn_loc: 0.19  time: 0.6229  data_time: 0.1082  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:29:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:29:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:29:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:29:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:29:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:29:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0360 s/iter. Total: 0.1110 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:29:35 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0767 s/iter. Eval: 0.0533 s/iter. Total: 0.1307 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0576 s/iter. Total: 0.1356 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:29:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.486992 (0.133509 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:29:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076934 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:29:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:29:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2653244671453106\n",
      "\u001b[32m[02/04 11:29:56 d2.utils.events]: \u001b[0m eta: 0:53:47  iter: 2679  total_loss: 1.615  loss_cls: 0.3701  loss_box_reg: 0.545  loss_mask: 0.3215  loss_rpn_cls: 0.09506  loss_rpn_loc: 0.1981  time: 0.6233  data_time: 0.2510  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:30:08 d2.utils.events]: \u001b[0m eta: 0:53:38  iter: 2699  total_loss: 1.461  loss_cls: 0.351  loss_box_reg: 0.5308  loss_mask: 0.3016  loss_rpn_cls: 0.07539  loss_rpn_loc: 0.2063  time: 0.6231  data_time: 0.1817  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:30:22 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 2719  total_loss: 1.413  loss_cls: 0.3571  loss_box_reg: 0.5219  loss_mask: 0.2913  loss_rpn_cls: 0.05773  loss_rpn_loc: 0.1739  time: 0.6237  data_time: 0.2655  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:30:32 d2.utils.events]: \u001b[0m eta: 0:53:20  iter: 2739  total_loss: 1.429  loss_cls: 0.3166  loss_box_reg: 0.5079  loss_mask: 0.307  loss_rpn_cls: 0.05314  loss_rpn_loc: 0.1725  time: 0.6227  data_time: 0.0751  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:30:47 d2.utils.events]: \u001b[0m eta: 0:53:13  iter: 2759  total_loss: 1.53  loss_cls: 0.3726  loss_box_reg: 0.558  loss_mask: 0.2982  loss_rpn_cls: 0.08257  loss_rpn_loc: 0.2061  time: 0.6235  data_time: 0.3051  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:31:00 d2.utils.events]: \u001b[0m eta: 0:53:06  iter: 2779  total_loss: 1.526  loss_cls: 0.3669  loss_box_reg: 0.5267  loss_mask: 0.3058  loss_rpn_cls: 0.09792  loss_rpn_loc: 0.2075  time: 0.6237  data_time: 0.2178  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:31:13 d2.utils.events]: \u001b[0m eta: 0:52:55  iter: 2799  total_loss: 1.452  loss_cls: 0.3467  loss_box_reg: 0.5373  loss_mask: 0.3012  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.1881  time: 0.6239  data_time: 0.2367  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:31:23 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 2819  total_loss: 1.487  loss_cls: 0.3491  loss_box_reg: 0.5369  loss_mask: 0.3083  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.1981  time: 0.6232  data_time: 0.1180  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:31:37 d2.utils.events]: \u001b[0m eta: 0:52:32  iter: 2839  total_loss: 1.565  loss_cls: 0.3797  loss_box_reg: 0.5284  loss_mask: 0.3111  loss_rpn_cls: 0.09658  loss_rpn_loc: 0.2272  time: 0.6238  data_time: 0.2690  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:31:49 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 2859  total_loss: 1.443  loss_cls: 0.3409  loss_box_reg: 0.5198  loss_mask: 0.3019  loss_rpn_cls: 0.08275  loss_rpn_loc: 0.1816  time: 0.6236  data_time: 0.1737  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:32:04 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 2879  total_loss: 1.566  loss_cls: 0.3958  loss_box_reg: 0.5235  loss_mask: 0.3058  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.2034  time: 0.6243  data_time: 0.2926  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:32:16 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 2899  total_loss: 1.494  loss_cls: 0.3831  loss_box_reg: 0.5414  loss_mask: 0.3102  loss_rpn_cls: 0.08046  loss_rpn_loc: 0.1919  time: 0.6241  data_time: 0.1633  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:32:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:32:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:32:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:32:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:32:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:32:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0748 s/iter. Eval: 0.0366 s/iter. Total: 0.1119 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0763 s/iter. Eval: 0.0494 s/iter. Total: 0.1264 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 11:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0007 s/iter. Inference: 0.0765 s/iter. Eval: 0.0507 s/iter. Total: 0.1280 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:32:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.714276 (0.126847 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:32:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076229 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:32:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:32:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2554641171320759\n",
      "\u001b[32m[02/04 11:32:44 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 2919  total_loss: 1.514  loss_cls: 0.3661  loss_box_reg: 0.5414  loss_mask: 0.2948  loss_rpn_cls: 0.0798  loss_rpn_loc: 0.2188  time: 0.6240  data_time: 0.1876  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:32:56 d2.utils.events]: \u001b[0m eta: 0:51:47  iter: 2939  total_loss: 1.484  loss_cls: 0.3653  loss_box_reg: 0.5188  loss_mask: 0.3028  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.1981  time: 0.6239  data_time: 0.1799  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:33:09 d2.utils.events]: \u001b[0m eta: 0:51:39  iter: 2959  total_loss: 1.557  loss_cls: 0.3684  loss_box_reg: 0.5392  loss_mask: 0.3189  loss_rpn_cls: 0.08284  loss_rpn_loc: 0.2056  time: 0.6241  data_time: 0.2243  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:33:21 d2.utils.events]: \u001b[0m eta: 0:51:35  iter: 2979  total_loss: 1.549  loss_cls: 0.3796  loss_box_reg: 0.535  loss_mask: 0.2995  loss_rpn_cls: 0.08476  loss_rpn_loc: 0.1841  time: 0.6239  data_time: 0.1642  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:33:33 d2.utils.events]: \u001b[0m eta: 0:51:21  iter: 2999  total_loss: 1.513  loss_cls: 0.3621  loss_box_reg: 0.5315  loss_mask: 0.3095  loss_rpn_cls: 0.08265  loss_rpn_loc: 0.198  time: 0.6237  data_time: 0.1736  lr: 0.0004  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:33:47 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 3019  total_loss: 1.51  loss_cls: 0.3833  loss_box_reg: 0.5162  loss_mask: 0.3146  loss_rpn_cls: 0.08247  loss_rpn_loc: 0.2059  time: 0.6243  data_time: 0.2933  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:33:59 d2.utils.events]: \u001b[0m eta: 0:51:05  iter: 3039  total_loss: 1.396  loss_cls: 0.3685  loss_box_reg: 0.5027  loss_mask: 0.2847  loss_rpn_cls: 0.06035  loss_rpn_loc: 0.1675  time: 0.6241  data_time: 0.1629  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:34:14 d2.utils.events]: \u001b[0m eta: 0:50:57  iter: 3059  total_loss: 1.51  loss_cls: 0.3791  loss_box_reg: 0.5094  loss_mask: 0.3216  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.2065  time: 0.6250  data_time: 0.3322  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:34:30 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 3079  total_loss: 1.399  loss_cls: 0.3668  loss_box_reg: 0.506  loss_mask: 0.3135  loss_rpn_cls: 0.07521  loss_rpn_loc: 0.2019  time: 0.6258  data_time: 0.3225  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:34:42 d2.utils.events]: \u001b[0m eta: 0:50:37  iter: 3099  total_loss: 1.38  loss_cls: 0.3139  loss_box_reg: 0.5023  loss_mask: 0.2961  loss_rpn_cls: 0.06243  loss_rpn_loc: 0.1755  time: 0.6257  data_time: 0.2077  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:34:51 d2.utils.events]: \u001b[0m eta: 0:50:28  iter: 3119  total_loss: 1.535  loss_cls: 0.3635  loss_box_reg: 0.5682  loss_mask: 0.2927  loss_rpn_cls: 0.05964  loss_rpn_loc: 0.1824  time: 0.6247  data_time: 0.0544  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:35:03 d2.utils.events]: \u001b[0m eta: 0:50:25  iter: 3139  total_loss: 1.356  loss_cls: 0.3601  loss_box_reg: 0.4902  loss_mask: 0.2933  loss_rpn_cls: 0.09183  loss_rpn_loc: 0.1872  time: 0.6246  data_time: 0.1883  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:35:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:35:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:35:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:35:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:35:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:35:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0743 s/iter. Eval: 0.0344 s/iter. Total: 0.1093 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0765 s/iter. Eval: 0.0515 s/iter. Total: 0.1288 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0771 s/iter. Eval: 0.0559 s/iter. Total: 0.1338 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:35:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.295414 (0.131857 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:35:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076790 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:35:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:35:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2601438978461844\n",
      "\u001b[32m[02/04 11:35:32 d2.utils.events]: \u001b[0m eta: 0:50:19  iter: 3159  total_loss: 1.438  loss_cls: 0.3495  loss_box_reg: 0.5346  loss_mask: 0.3019  loss_rpn_cls: 0.06103  loss_rpn_loc: 0.21  time: 0.6245  data_time: 0.1926  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:35:44 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 3179  total_loss: 1.512  loss_cls: 0.3765  loss_box_reg: 0.5403  loss_mask: 0.3045  loss_rpn_cls: 0.09454  loss_rpn_loc: 0.204  time: 0.6241  data_time: 0.1362  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:35:55 d2.utils.events]: \u001b[0m eta: 0:49:59  iter: 3199  total_loss: 1.421  loss_cls: 0.3427  loss_box_reg: 0.5222  loss_mask: 0.2884  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.1679  time: 0.6237  data_time: 0.1476  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:36:06 d2.utils.events]: \u001b[0m eta: 0:49:44  iter: 3219  total_loss: 1.454  loss_cls: 0.3577  loss_box_reg: 0.4964  loss_mask: 0.3071  loss_rpn_cls: 0.07064  loss_rpn_loc: 0.1981  time: 0.6234  data_time: 0.1562  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:36:18 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 3239  total_loss: 1.559  loss_cls: 0.3943  loss_box_reg: 0.5528  loss_mask: 0.3027  loss_rpn_cls: 0.105  loss_rpn_loc: 0.2001  time: 0.6232  data_time: 0.1456  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:36:32 d2.utils.events]: \u001b[0m eta: 0:49:24  iter: 3259  total_loss: 1.431  loss_cls: 0.3372  loss_box_reg: 0.4947  loss_mask: 0.3038  loss_rpn_cls: 0.08418  loss_rpn_loc: 0.1872  time: 0.6238  data_time: 0.2794  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:36:44 d2.utils.events]: \u001b[0m eta: 0:49:17  iter: 3279  total_loss: 1.401  loss_cls: 0.3392  loss_box_reg: 0.514  loss_mask: 0.3048  loss_rpn_cls: 0.05448  loss_rpn_loc: 0.1839  time: 0.6237  data_time: 0.1870  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:37:01 d2.utils.events]: \u001b[0m eta: 0:49:08  iter: 3299  total_loss: 1.41  loss_cls: 0.3257  loss_box_reg: 0.5101  loss_mask: 0.309  loss_rpn_cls: 0.06845  loss_rpn_loc: 0.1858  time: 0.6248  data_time: 0.3687  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:37:12 d2.utils.events]: \u001b[0m eta: 0:49:00  iter: 3319  total_loss: 1.6  loss_cls: 0.3939  loss_box_reg: 0.5476  loss_mask: 0.3235  loss_rpn_cls: 0.09975  loss_rpn_loc: 0.202  time: 0.6245  data_time: 0.1781  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:37:26 d2.utils.events]: \u001b[0m eta: 0:48:51  iter: 3339  total_loss: 1.407  loss_cls: 0.3546  loss_box_reg: 0.5107  loss_mask: 0.296  loss_rpn_cls: 0.06456  loss_rpn_loc: 0.1951  time: 0.6248  data_time: 0.2431  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:37:39 d2.utils.events]: \u001b[0m eta: 0:48:47  iter: 3359  total_loss: 1.527  loss_cls: 0.3618  loss_box_reg: 0.5189  loss_mask: 0.3204  loss_rpn_cls: 0.08609  loss_rpn_loc: 0.2121  time: 0.6250  data_time: 0.2250  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:37:51 d2.utils.events]: \u001b[0m eta: 0:48:35  iter: 3379  total_loss: 1.441  loss_cls: 0.3441  loss_box_reg: 0.5401  loss_mask: 0.2981  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.1804  time: 0.6247  data_time: 0.1673  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:37:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:37:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:37:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:37:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:37:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:37:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0746 s/iter. Eval: 0.0346 s/iter. Total: 0.1098 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0556 s/iter. Total: 0.1334 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0007 s/iter. Inference: 0.0776 s/iter. Eval: 0.0602 s/iter. Total: 0.1386 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 11:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.0775 s/iter. Eval: 0.0583 s/iter. Total: 0.1366 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 11:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.894168 (0.137019 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077484 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:38:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2678554335340999\n",
      "\u001b[32m[02/04 11:38:20 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 3399  total_loss: 1.444  loss_cls: 0.3556  loss_box_reg: 0.5214  loss_mask: 0.302  loss_rpn_cls: 0.06474  loss_rpn_loc: 0.1881  time: 0.6246  data_time: 0.1660  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:38:34 d2.utils.events]: \u001b[0m eta: 0:48:24  iter: 3419  total_loss: 1.524  loss_cls: 0.3864  loss_box_reg: 0.5274  loss_mask: 0.3054  loss_rpn_cls: 0.08596  loss_rpn_loc: 0.1888  time: 0.6250  data_time: 0.2611  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:38:47 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 3439  total_loss: 1.52  loss_cls: 0.364  loss_box_reg: 0.5157  loss_mask: 0.3148  loss_rpn_cls: 0.09699  loss_rpn_loc: 0.2063  time: 0.6253  data_time: 0.2385  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:39:00 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 3459  total_loss: 1.547  loss_cls: 0.3793  loss_box_reg: 0.5316  loss_mask: 0.3195  loss_rpn_cls: 0.08326  loss_rpn_loc: 0.2144  time: 0.6253  data_time: 0.2151  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:39:15 d2.utils.events]: \u001b[0m eta: 0:47:54  iter: 3479  total_loss: 1.495  loss_cls: 0.3608  loss_box_reg: 0.5034  loss_mask: 0.2819  loss_rpn_cls: 0.09256  loss_rpn_loc: 0.2055  time: 0.6260  data_time: 0.3142  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:39:28 d2.utils.events]: \u001b[0m eta: 0:47:49  iter: 3499  total_loss: 1.596  loss_cls: 0.3782  loss_box_reg: 0.5555  loss_mask: 0.3235  loss_rpn_cls: 0.06654  loss_rpn_loc: 0.1961  time: 0.6261  data_time: 0.2166  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:39:37 d2.utils.events]: \u001b[0m eta: 0:47:38  iter: 3519  total_loss: 1.413  loss_cls: 0.3459  loss_box_reg: 0.5122  loss_mask: 0.2907  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.1759  time: 0.6252  data_time: 0.0738  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:39:52 d2.utils.events]: \u001b[0m eta: 0:47:31  iter: 3539  total_loss: 1.531  loss_cls: 0.3709  loss_box_reg: 0.5139  loss_mask: 0.3068  loss_rpn_cls: 0.09646  loss_rpn_loc: 0.1972  time: 0.6259  data_time: 0.3081  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:40:03 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 3559  total_loss: 1.407  loss_cls: 0.3557  loss_box_reg: 0.5291  loss_mask: 0.2789  loss_rpn_cls: 0.07187  loss_rpn_loc: 0.1657  time: 0.6254  data_time: 0.1254  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:40:14 d2.utils.events]: \u001b[0m eta: 0:47:10  iter: 3579  total_loss: 1.466  loss_cls: 0.3537  loss_box_reg: 0.5405  loss_mask: 0.2955  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.1925  time: 0.6250  data_time: 0.1187  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:40:25 d2.utils.events]: \u001b[0m eta: 0:47:03  iter: 3599  total_loss: 1.455  loss_cls: 0.3308  loss_box_reg: 0.5368  loss_mask: 0.3051  loss_rpn_cls: 0.05402  loss_rpn_loc: 0.188  time: 0.6245  data_time: 0.1047  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:40:36 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 3619  total_loss: 1.482  loss_cls: 0.3615  loss_box_reg: 0.5309  loss_mask: 0.2993  loss_rpn_cls: 0.06815  loss_rpn_loc: 0.1918  time: 0.6242  data_time: 0.1632  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:40:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:40:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:40:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:40:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:40:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:40:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0749 s/iter. Eval: 0.0361 s/iter. Total: 0.1116 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0772 s/iter. Eval: 0.0547 s/iter. Total: 0.1326 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0776 s/iter. Eval: 0.0582 s/iter. Total: 0.1366 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 11:40:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.652649 (0.134937 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:40:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077359 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:40:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:40:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26396624571966676\n",
      "\u001b[32m[02/04 11:41:05 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 3639  total_loss: 1.435  loss_cls: 0.3397  loss_box_reg: 0.5089  loss_mask: 0.2937  loss_rpn_cls: 0.07454  loss_rpn_loc: 0.1921  time: 0.6240  data_time: 0.1666  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:41:18 d2.utils.events]: \u001b[0m eta: 0:46:38  iter: 3659  total_loss: 1.5  loss_cls: 0.3751  loss_box_reg: 0.5257  loss_mask: 0.3026  loss_rpn_cls: 0.07666  loss_rpn_loc: 0.1891  time: 0.6242  data_time: 0.2282  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:41:31 d2.utils.events]: \u001b[0m eta: 0:46:26  iter: 3679  total_loss: 1.464  loss_cls: 0.3651  loss_box_reg: 0.5354  loss_mask: 0.3156  loss_rpn_cls: 0.06763  loss_rpn_loc: 0.1855  time: 0.6242  data_time: 0.2228  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:41:45 d2.utils.events]: \u001b[0m eta: 0:46:18  iter: 3699  total_loss: 1.437  loss_cls: 0.3344  loss_box_reg: 0.5042  loss_mask: 0.3075  loss_rpn_cls: 0.06484  loss_rpn_loc: 0.2109  time: 0.6246  data_time: 0.2741  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:41:57 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 3719  total_loss: 1.472  loss_cls: 0.3477  loss_box_reg: 0.5149  loss_mask: 0.3056  loss_rpn_cls: 0.09062  loss_rpn_loc: 0.1917  time: 0.6244  data_time: 0.1782  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:42:11 d2.utils.events]: \u001b[0m eta: 0:46:01  iter: 3739  total_loss: 1.481  loss_cls: 0.3592  loss_box_reg: 0.5284  loss_mask: 0.299  loss_rpn_cls: 0.08657  loss_rpn_loc: 0.1951  time: 0.6249  data_time: 0.2808  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:42:21 d2.utils.events]: \u001b[0m eta: 0:45:51  iter: 3759  total_loss: 1.393  loss_cls: 0.3493  loss_box_reg: 0.5104  loss_mask: 0.2963  loss_rpn_cls: 0.05585  loss_rpn_loc: 0.1772  time: 0.6243  data_time: 0.0925  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:42:34 d2.utils.events]: \u001b[0m eta: 0:45:41  iter: 3779  total_loss: 1.479  loss_cls: 0.3515  loss_box_reg: 0.5401  loss_mask: 0.3044  loss_rpn_cls: 0.06998  loss_rpn_loc: 0.2048  time: 0.6245  data_time: 0.2606  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:42:46 d2.utils.events]: \u001b[0m eta: 0:45:32  iter: 3799  total_loss: 1.483  loss_cls: 0.3793  loss_box_reg: 0.5127  loss_mask: 0.3119  loss_rpn_cls: 0.08291  loss_rpn_loc: 0.2139  time: 0.6243  data_time: 0.1718  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:42:59 d2.utils.events]: \u001b[0m eta: 0:45:26  iter: 3819  total_loss: 1.464  loss_cls: 0.3605  loss_box_reg: 0.5288  loss_mask: 0.2964  loss_rpn_cls: 0.07358  loss_rpn_loc: 0.2069  time: 0.6243  data_time: 0.1887  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:43:10 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 3839  total_loss: 1.569  loss_cls: 0.3871  loss_box_reg: 0.5529  loss_mask: 0.3063  loss_rpn_cls: 0.08681  loss_rpn_loc: 0.2095  time: 0.6241  data_time: 0.1745  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:43:21 d2.utils.events]: \u001b[0m eta: 0:45:05  iter: 3859  total_loss: 1.416  loss_cls: 0.3555  loss_box_reg: 0.5156  loss_mask: 0.3008  loss_rpn_cls: 0.07224  loss_rpn_loc: 0.1772  time: 0.6237  data_time: 0.1147  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:43:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:43:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:43:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:43:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:43:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:43:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0753 s/iter. Eval: 0.0426 s/iter. Total: 0.1185 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 11:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0765 s/iter. Eval: 0.0511 s/iter. Total: 0.1284 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0007 s/iter. Inference: 0.0767 s/iter. Eval: 0.0530 s/iter. Total: 0.1305 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:43:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.929181 (0.128700 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:43:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076383 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:43:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:43:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2581128954646062\n",
      "\u001b[32m[02/04 11:43:50 d2.utils.events]: \u001b[0m eta: 0:45:01  iter: 3879  total_loss: 1.438  loss_cls: 0.3632  loss_box_reg: 0.508  loss_mask: 0.2923  loss_rpn_cls: 0.08799  loss_rpn_loc: 0.1844  time: 0.6237  data_time: 0.1839  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:44:03 d2.utils.events]: \u001b[0m eta: 0:44:54  iter: 3899  total_loss: 1.53  loss_cls: 0.3853  loss_box_reg: 0.5356  loss_mask: 0.2958  loss_rpn_cls: 0.09951  loss_rpn_loc: 0.2054  time: 0.6238  data_time: 0.2162  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:44:16 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 3919  total_loss: 1.395  loss_cls: 0.3592  loss_box_reg: 0.5039  loss_mask: 0.2987  loss_rpn_cls: 0.07956  loss_rpn_loc: 0.1846  time: 0.6239  data_time: 0.2232  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:44:28 d2.utils.events]: \u001b[0m eta: 0:44:34  iter: 3939  total_loss: 1.419  loss_cls: 0.3504  loss_box_reg: 0.5157  loss_mask: 0.2928  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.1782  time: 0.6238  data_time: 0.1990  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:44:43 d2.utils.events]: \u001b[0m eta: 0:44:26  iter: 3959  total_loss: 1.509  loss_cls: 0.3694  loss_box_reg: 0.5068  loss_mask: 0.3143  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.192  time: 0.6244  data_time: 0.3129  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:44:58 d2.utils.events]: \u001b[0m eta: 0:44:17  iter: 3979  total_loss: 1.472  loss_cls: 0.365  loss_box_reg: 0.5022  loss_mask: 0.2998  loss_rpn_cls: 0.08812  loss_rpn_loc: 0.193  time: 0.6250  data_time: 0.3214  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:45:10 d2.utils.events]: \u001b[0m eta: 0:44:08  iter: 3999  total_loss: 1.57  loss_cls: 0.3851  loss_box_reg: 0.5267  loss_mask: 0.3145  loss_rpn_cls: 0.08718  loss_rpn_loc: 0.1973  time: 0.6250  data_time: 0.1945  lr: 0.00032  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:45:26 d2.utils.events]: \u001b[0m eta: 0:43:59  iter: 4019  total_loss: 1.477  loss_cls: 0.3831  loss_box_reg: 0.5154  loss_mask: 0.3014  loss_rpn_cls: 0.07749  loss_rpn_loc: 0.1962  time: 0.6257  data_time: 0.3536  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:45:36 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 4039  total_loss: 1.37  loss_cls: 0.3267  loss_box_reg: 0.5043  loss_mask: 0.2958  loss_rpn_cls: 0.06908  loss_rpn_loc: 0.1757  time: 0.6252  data_time: 0.1188  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:45:49 d2.utils.events]: \u001b[0m eta: 0:43:39  iter: 4059  total_loss: 1.45  loss_cls: 0.368  loss_box_reg: 0.5273  loss_mask: 0.2976  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.1969  time: 0.6253  data_time: 0.2126  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:46:02 d2.utils.events]: \u001b[0m eta: 0:43:29  iter: 4079  total_loss: 1.589  loss_cls: 0.4067  loss_box_reg: 0.5298  loss_mask: 0.3202  loss_rpn_cls: 0.09671  loss_rpn_loc: 0.1994  time: 0.6254  data_time: 0.2212  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:46:12 d2.utils.events]: \u001b[0m eta: 0:43:20  iter: 4099  total_loss: 1.374  loss_cls: 0.3214  loss_box_reg: 0.5191  loss_mask: 0.2921  loss_rpn_cls: 0.05321  loss_rpn_loc: 0.1773  time: 0.6248  data_time: 0.1034  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:46:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:46:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:46:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:46:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:46:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:46:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0747 s/iter. Eval: 0.0354 s/iter. Total: 0.1107 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0007 s/iter. Inference: 0.0762 s/iter. Eval: 0.0491 s/iter. Total: 0.1261 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 11:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0007 s/iter. Inference: 0.0763 s/iter. Eval: 0.0500 s/iter. Total: 0.1271 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 11:46:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.591602 (0.125790 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:46:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076097 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:46:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:46:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.256823653127243\n",
      "\u001b[32m[02/04 11:46:42 d2.utils.events]: \u001b[0m eta: 0:43:15  iter: 4119  total_loss: 1.55  loss_cls: 0.3564  loss_box_reg: 0.5366  loss_mask: 0.3266  loss_rpn_cls: 0.08968  loss_rpn_loc: 0.1943  time: 0.6251  data_time: 0.2407  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:46:53 d2.utils.events]: \u001b[0m eta: 0:43:03  iter: 4139  total_loss: 1.436  loss_cls: 0.3427  loss_box_reg: 0.5233  loss_mask: 0.305  loss_rpn_cls: 0.05763  loss_rpn_loc: 0.1804  time: 0.6249  data_time: 0.1496  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:47:05 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 4159  total_loss: 1.45  loss_cls: 0.3437  loss_box_reg: 0.5316  loss_mask: 0.3167  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.2051  time: 0.6245  data_time: 0.1478  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:47:17 d2.utils.events]: \u001b[0m eta: 0:42:39  iter: 4179  total_loss: 1.467  loss_cls: 0.3511  loss_box_reg: 0.5147  loss_mask: 0.2927  loss_rpn_cls: 0.08556  loss_rpn_loc: 0.1883  time: 0.6245  data_time: 0.1984  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:47:32 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 4199  total_loss: 1.482  loss_cls: 0.3599  loss_box_reg: 0.5392  loss_mask: 0.3101  loss_rpn_cls: 0.08148  loss_rpn_loc: 0.1867  time: 0.6251  data_time: 0.3232  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:47:45 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 4219  total_loss: 1.386  loss_cls: 0.322  loss_box_reg: 0.4864  loss_mask: 0.2928  loss_rpn_cls: 0.06838  loss_rpn_loc: 0.1967  time: 0.6252  data_time: 0.2103  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:47:57 d2.utils.events]: \u001b[0m eta: 0:42:19  iter: 4239  total_loss: 1.521  loss_cls: 0.3708  loss_box_reg: 0.5491  loss_mask: 0.3142  loss_rpn_cls: 0.0866  loss_rpn_loc: 0.2026  time: 0.6252  data_time: 0.1893  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:48:08 d2.utils.events]: \u001b[0m eta: 0:42:06  iter: 4259  total_loss: 1.425  loss_cls: 0.3398  loss_box_reg: 0.5162  loss_mask: 0.2862  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.1734  time: 0.6247  data_time: 0.1146  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:48:22 d2.utils.events]: \u001b[0m eta: 0:41:57  iter: 4279  total_loss: 1.51  loss_cls: 0.3618  loss_box_reg: 0.5491  loss_mask: 0.31  loss_rpn_cls: 0.0824  loss_rpn_loc: 0.2036  time: 0.6252  data_time: 0.2833  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:48:33 d2.utils.events]: \u001b[0m eta: 0:41:49  iter: 4299  total_loss: 1.425  loss_cls: 0.3611  loss_box_reg: 0.4928  loss_mask: 0.285  loss_rpn_cls: 0.07172  loss_rpn_loc: 0.1895  time: 0.6248  data_time: 0.1278  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:48:43 d2.utils.events]: \u001b[0m eta: 0:41:38  iter: 4319  total_loss: 1.446  loss_cls: 0.3716  loss_box_reg: 0.5425  loss_mask: 0.2956  loss_rpn_cls: 0.05896  loss_rpn_loc: 0.1767  time: 0.6243  data_time: 0.1082  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:49:00 d2.utils.events]: \u001b[0m eta: 0:41:34  iter: 4339  total_loss: 1.532  loss_cls: 0.3808  loss_box_reg: 0.5176  loss_mask: 0.3115  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.1973  time: 0.6253  data_time: 0.3983  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:49:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:49:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:49:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:49:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:49:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0350 s/iter. Total: 0.1101 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0007 s/iter. Inference: 0.0765 s/iter. Eval: 0.0514 s/iter. Total: 0.1287 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0544 s/iter. Total: 0.1320 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:49:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.195706 (0.130997 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:49:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076667 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:49:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:49:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2637186817719865\n",
      "\u001b[32m[02/04 11:49:32 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 4359  total_loss: 1.465  loss_cls: 0.3591  loss_box_reg: 0.5197  loss_mask: 0.3  loss_rpn_cls: 0.08695  loss_rpn_loc: 0.1799  time: 0.6258  data_time: 0.2935  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:49:44 d2.utils.events]: \u001b[0m eta: 0:41:19  iter: 4379  total_loss: 1.455  loss_cls: 0.3598  loss_box_reg: 0.5356  loss_mask: 0.3008  loss_rpn_cls: 0.08909  loss_rpn_loc: 0.1879  time: 0.6258  data_time: 0.2201  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:49:55 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 4399  total_loss: 1.446  loss_cls: 0.3303  loss_box_reg: 0.5223  loss_mask: 0.2962  loss_rpn_cls: 0.05528  loss_rpn_loc: 0.187  time: 0.6253  data_time: 0.1214  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:50:06 d2.utils.events]: \u001b[0m eta: 0:40:51  iter: 4419  total_loss: 1.389  loss_cls: 0.3316  loss_box_reg: 0.5128  loss_mask: 0.2913  loss_rpn_cls: 0.06021  loss_rpn_loc: 0.1743  time: 0.6249  data_time: 0.1090  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:50:19 d2.utils.events]: \u001b[0m eta: 0:40:43  iter: 4439  total_loss: 1.397  loss_cls: 0.3267  loss_box_reg: 0.508  loss_mask: 0.2956  loss_rpn_cls: 0.08873  loss_rpn_loc: 0.1922  time: 0.6252  data_time: 0.2558  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:50:33 d2.utils.events]: \u001b[0m eta: 0:40:35  iter: 4459  total_loss: 1.457  loss_cls: 0.3617  loss_box_reg: 0.54  loss_mask: 0.2994  loss_rpn_cls: 0.09526  loss_rpn_loc: 0.2015  time: 0.6255  data_time: 0.2727  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:50:45 d2.utils.events]: \u001b[0m eta: 0:40:27  iter: 4479  total_loss: 1.43  loss_cls: 0.3563  loss_box_reg: 0.5384  loss_mask: 0.2985  loss_rpn_cls: 0.07984  loss_rpn_loc: 0.1845  time: 0.6253  data_time: 0.1464  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:50:54 d2.utils.events]: \u001b[0m eta: 0:40:14  iter: 4499  total_loss: 1.528  loss_cls: 0.3764  loss_box_reg: 0.5641  loss_mask: 0.3077  loss_rpn_cls: 0.06317  loss_rpn_loc: 0.1894  time: 0.6245  data_time: 0.0531  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:51:06 d2.utils.events]: \u001b[0m eta: 0:40:07  iter: 4519  total_loss: 1.46  loss_cls: 0.3612  loss_box_reg: 0.5411  loss_mask: 0.3098  loss_rpn_cls: 0.07173  loss_rpn_loc: 0.1964  time: 0.6245  data_time: 0.2074  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:51:20 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 4539  total_loss: 1.437  loss_cls: 0.3719  loss_box_reg: 0.5007  loss_mask: 0.3016  loss_rpn_cls: 0.08262  loss_rpn_loc: 0.2007  time: 0.6249  data_time: 0.2683  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:51:31 d2.utils.events]: \u001b[0m eta: 0:39:49  iter: 4559  total_loss: 1.518  loss_cls: 0.38  loss_box_reg: 0.5402  loss_mask: 0.2973  loss_rpn_cls: 0.06456  loss_rpn_loc: 0.1936  time: 0.6246  data_time: 0.1475  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:51:45 d2.utils.events]: \u001b[0m eta: 0:39:45  iter: 4579  total_loss: 1.512  loss_cls: 0.374  loss_box_reg: 0.481  loss_mask: 0.3069  loss_rpn_cls: 0.08025  loss_rpn_loc: 0.1963  time: 0.6248  data_time: 0.2411  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:51:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:51:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:51:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:51:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:51:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:51:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:51:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0746 s/iter. Eval: 0.0351 s/iter. Total: 0.1103 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0768 s/iter. Eval: 0.0520 s/iter. Total: 0.1296 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0771 s/iter. Eval: 0.0547 s/iter. Total: 0.1326 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:52:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.235611 (0.131341 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:52:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076861 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:52:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:52:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26166651357227655\n",
      "\u001b[32m[02/04 11:52:14 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 4599  total_loss: 1.518  loss_cls: 0.3643  loss_box_reg: 0.5465  loss_mask: 0.3176  loss_rpn_cls: 0.08637  loss_rpn_loc: 0.2156  time: 0.6247  data_time: 0.1758  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:52:26 d2.utils.events]: \u001b[0m eta: 0:39:28  iter: 4619  total_loss: 1.424  loss_cls: 0.3504  loss_box_reg: 0.5168  loss_mask: 0.3036  loss_rpn_cls: 0.0874  loss_rpn_loc: 0.1919  time: 0.6246  data_time: 0.1995  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:52:37 d2.utils.events]: \u001b[0m eta: 0:39:15  iter: 4639  total_loss: 1.46  loss_cls: 0.3546  loss_box_reg: 0.535  loss_mask: 0.3117  loss_rpn_cls: 0.05888  loss_rpn_loc: 0.1803  time: 0.6243  data_time: 0.1420  lr: 0.000256  max_mem: 6558M\n",
      "\u001b[32m[02/04 11:52:53 d2.utils.events]: \u001b[0m eta: 0:39:09  iter: 4659  total_loss: 1.417  loss_cls: 0.3456  loss_box_reg: 0.471  loss_mask: 0.2984  loss_rpn_cls: 0.0856  loss_rpn_loc: 0.1874  time: 0.6251  data_time: 0.3848  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:53:07 d2.utils.events]: \u001b[0m eta: 0:39:04  iter: 4679  total_loss: 1.37  loss_cls: 0.3519  loss_box_reg: 0.5035  loss_mask: 0.2812  loss_rpn_cls: 0.07962  loss_rpn_loc: 0.181  time: 0.6254  data_time: 0.2617  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:53:20 d2.utils.events]: \u001b[0m eta: 0:38:55  iter: 4699  total_loss: 1.419  loss_cls: 0.3514  loss_box_reg: 0.5168  loss_mask: 0.3008  loss_rpn_cls: 0.07084  loss_rpn_loc: 0.1896  time: 0.6256  data_time: 0.2385  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:53:34 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 4719  total_loss: 1.421  loss_cls: 0.35  loss_box_reg: 0.518  loss_mask: 0.3001  loss_rpn_cls: 0.07151  loss_rpn_loc: 0.1859  time: 0.6258  data_time: 0.2504  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:53:45 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 4739  total_loss: 1.4  loss_cls: 0.3283  loss_box_reg: 0.5254  loss_mask: 0.2964  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.1851  time: 0.6254  data_time: 0.1330  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:54:01 d2.utils.events]: \u001b[0m eta: 0:38:22  iter: 4759  total_loss: 1.523  loss_cls: 0.3556  loss_box_reg: 0.4993  loss_mask: 0.314  loss_rpn_cls: 0.09083  loss_rpn_loc: 0.2004  time: 0.6263  data_time: 0.3818  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:54:14 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 4779  total_loss: 1.511  loss_cls: 0.367  loss_box_reg: 0.5316  loss_mask: 0.3179  loss_rpn_cls: 0.07788  loss_rpn_loc: 0.2082  time: 0.6263  data_time: 0.2019  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:54:28 d2.utils.events]: \u001b[0m eta: 0:38:12  iter: 4799  total_loss: 1.653  loss_cls: 0.3753  loss_box_reg: 0.5473  loss_mask: 0.3166  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.224  time: 0.6265  data_time: 0.2464  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:54:37 d2.utils.events]: \u001b[0m eta: 0:37:57  iter: 4819  total_loss: 1.436  loss_cls: 0.3493  loss_box_reg: 0.5465  loss_mask: 0.2931  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.1857  time: 0.6259  data_time: 0.0546  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:54:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:54:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:54:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:54:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:54:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:54:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0748 s/iter. Eval: 0.0366 s/iter. Total: 0.1120 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0534 s/iter. Total: 0.1310 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0774 s/iter. Eval: 0.0567 s/iter. Total: 0.1349 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:55:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.407418 (0.132823 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:55:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077063 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:55:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:55:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2640541772321164\n",
      "\u001b[32m[02/04 11:55:05 d2.utils.events]: \u001b[0m eta: 0:37:51  iter: 4839  total_loss: 1.425  loss_cls: 0.3701  loss_box_reg: 0.5303  loss_mask: 0.2908  loss_rpn_cls: 0.06978  loss_rpn_loc: 0.1842  time: 0.6256  data_time: 0.1323  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:55:18 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 4859  total_loss: 1.529  loss_cls: 0.3701  loss_box_reg: 0.5315  loss_mask: 0.3118  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1998  time: 0.6257  data_time: 0.2183  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:55:32 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 4879  total_loss: 1.57  loss_cls: 0.3895  loss_box_reg: 0.5264  loss_mask: 0.3085  loss_rpn_cls: 0.09853  loss_rpn_loc: 0.1975  time: 0.6259  data_time: 0.2594  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:55:47 d2.utils.events]: \u001b[0m eta: 0:37:22  iter: 4899  total_loss: 1.501  loss_cls: 0.3543  loss_box_reg: 0.5097  loss_mask: 0.299  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.2088  time: 0.6264  data_time: 0.3273  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:55:56 d2.utils.events]: \u001b[0m eta: 0:37:05  iter: 4919  total_loss: 1.351  loss_cls: 0.3267  loss_box_reg: 0.5045  loss_mask: 0.2863  loss_rpn_cls: 0.05035  loss_rpn_loc: 0.1687  time: 0.6257  data_time: 0.0410  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:56:07 d2.utils.events]: \u001b[0m eta: 0:36:56  iter: 4939  total_loss: 1.436  loss_cls: 0.3589  loss_box_reg: 0.51  loss_mask: 0.3059  loss_rpn_cls: 0.06477  loss_rpn_loc: 0.1812  time: 0.6254  data_time: 0.1578  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:56:20 d2.utils.events]: \u001b[0m eta: 0:36:47  iter: 4959  total_loss: 1.492  loss_cls: 0.3587  loss_box_reg: 0.5103  loss_mask: 0.3024  loss_rpn_cls: 0.08551  loss_rpn_loc: 0.1921  time: 0.6256  data_time: 0.2300  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:56:33 d2.utils.events]: \u001b[0m eta: 0:36:40  iter: 4979  total_loss: 1.497  loss_cls: 0.3846  loss_box_reg: 0.5392  loss_mask: 0.3007  loss_rpn_cls: 0.09207  loss_rpn_loc: 0.2124  time: 0.6257  data_time: 0.2163  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:56:45 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 4999  total_loss: 1.319  loss_cls: 0.3111  loss_box_reg: 0.505  loss_mask: 0.2815  loss_rpn_cls: 0.05166  loss_rpn_loc: 0.1715  time: 0.6256  data_time: 0.1719  lr: 0.000256  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:56:57 d2.utils.events]: \u001b[0m eta: 0:36:24  iter: 5019  total_loss: 1.44  loss_cls: 0.362  loss_box_reg: 0.4997  loss_mask: 0.2982  loss_rpn_cls: 0.06969  loss_rpn_loc: 0.1913  time: 0.6254  data_time: 0.1681  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:57:11 d2.utils.events]: \u001b[0m eta: 0:36:22  iter: 5039  total_loss: 1.438  loss_cls: 0.3639  loss_box_reg: 0.5188  loss_mask: 0.2967  loss_rpn_cls: 0.08568  loss_rpn_loc: 0.1894  time: 0.6257  data_time: 0.2531  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:57:23 d2.utils.events]: \u001b[0m eta: 0:36:16  iter: 5059  total_loss: 1.451  loss_cls: 0.3672  loss_box_reg: 0.5073  loss_mask: 0.3027  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1914  time: 0.6256  data_time: 0.1713  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:57:35 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 5079  total_loss: 1.413  loss_cls: 0.3438  loss_box_reg: 0.5394  loss_mask: 0.3149  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.1804  time: 0.6254  data_time: 0.1576  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:57:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:57:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 11:57:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 11:57:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 11:57:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 11:57:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 11:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0748 s/iter. Eval: 0.0357 s/iter. Total: 0.1111 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 11:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0529 s/iter. Total: 0.1307 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 11:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0774 s/iter. Eval: 0.0564 s/iter. Total: 0.1346 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 11:57:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.472280 (0.133382 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:57:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077231 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 11:57:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 11:57:53 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26429059159726914\n",
      "\u001b[32m[02/04 11:58:02 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 5099  total_loss: 1.437  loss_cls: 0.3532  loss_box_reg: 0.5029  loss_mask: 0.2962  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.1746  time: 0.6251  data_time: 0.1184  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:58:13 d2.utils.events]: \u001b[0m eta: 0:35:47  iter: 5119  total_loss: 1.422  loss_cls: 0.3474  loss_box_reg: 0.5334  loss_mask: 0.3024  loss_rpn_cls: 0.08736  loss_rpn_loc: 0.1891  time: 0.6247  data_time: 0.1139  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:58:26 d2.utils.events]: \u001b[0m eta: 0:35:40  iter: 5139  total_loss: 1.524  loss_cls: 0.3804  loss_box_reg: 0.5192  loss_mask: 0.3019  loss_rpn_cls: 0.07793  loss_rpn_loc: 0.1851  time: 0.6248  data_time: 0.2299  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:58:37 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 5159  total_loss: 1.365  loss_cls: 0.3407  loss_box_reg: 0.5129  loss_mask: 0.2917  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.1863  time: 0.6246  data_time: 0.1593  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:58:51 d2.utils.events]: \u001b[0m eta: 0:35:24  iter: 5179  total_loss: 1.455  loss_cls: 0.3707  loss_box_reg: 0.513  loss_mask: 0.2969  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.1998  time: 0.6248  data_time: 0.2340  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:59:04 d2.utils.events]: \u001b[0m eta: 0:35:18  iter: 5199  total_loss: 1.543  loss_cls: 0.3631  loss_box_reg: 0.5237  loss_mask: 0.3204  loss_rpn_cls: 0.08364  loss_rpn_loc: 0.214  time: 0.6248  data_time: 0.2047  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:59:16 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 5219  total_loss: 1.475  loss_cls: 0.3626  loss_box_reg: 0.5428  loss_mask: 0.2948  loss_rpn_cls: 0.06672  loss_rpn_loc: 0.183  time: 0.6248  data_time: 0.2032  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:59:27 d2.utils.events]: \u001b[0m eta: 0:34:55  iter: 5239  total_loss: 1.514  loss_cls: 0.3706  loss_box_reg: 0.534  loss_mask: 0.312  loss_rpn_cls: 0.05972  loss_rpn_loc: 0.1949  time: 0.6245  data_time: 0.1216  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:59:42 d2.utils.events]: \u001b[0m eta: 0:34:49  iter: 5259  total_loss: 1.494  loss_cls: 0.3682  loss_box_reg: 0.5109  loss_mask: 0.2988  loss_rpn_cls: 0.0802  loss_rpn_loc: 0.2131  time: 0.6250  data_time: 0.2949  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 11:59:54 d2.utils.events]: \u001b[0m eta: 0:34:37  iter: 5279  total_loss: 1.502  loss_cls: 0.3729  loss_box_reg: 0.5466  loss_mask: 0.2995  loss_rpn_cls: 0.07065  loss_rpn_loc: 0.1855  time: 0.6249  data_time: 0.2140  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 12:00:06 d2.utils.events]: \u001b[0m eta: 0:34:28  iter: 5299  total_loss: 1.455  loss_cls: 0.3497  loss_box_reg: 0.5219  loss_mask: 0.2917  loss_rpn_cls: 0.07807  loss_rpn_loc: 0.187  time: 0.6249  data_time: 0.1854  lr: 0.0002048  max_mem: 6661M\n",
      "\u001b[32m[02/04 12:00:20 d2.utils.events]: \u001b[0m eta: 0:34:22  iter: 5319  total_loss: 1.418  loss_cls: 0.3335  loss_box_reg: 0.4995  loss_mask: 0.2931  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.1847  time: 0.6252  data_time: 0.2738  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:00:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:00:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:00:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:00:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:00:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:00:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0743 s/iter. Eval: 0.0343 s/iter. Total: 0.1092 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 12:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0767 s/iter. Eval: 0.0514 s/iter. Total: 0.1288 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0547 s/iter. Total: 0.1325 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 12:00:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.192451 (0.130969 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:00:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076764 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:00:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:00:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25830142946905815\n",
      "\u001b[32m[02/04 12:00:49 d2.utils.events]: \u001b[0m eta: 0:34:11  iter: 5339  total_loss: 1.388  loss_cls: 0.3281  loss_box_reg: 0.5013  loss_mask: 0.2861  loss_rpn_cls: 0.0575  loss_rpn_loc: 0.1788  time: 0.6251  data_time: 0.1694  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:01:00 d2.utils.events]: \u001b[0m eta: 0:33:57  iter: 5359  total_loss: 1.372  loss_cls: 0.3324  loss_box_reg: 0.5316  loss_mask: 0.2977  loss_rpn_cls: 0.08707  loss_rpn_loc: 0.1836  time: 0.6247  data_time: 0.1150  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:01:14 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 5379  total_loss: 1.5  loss_cls: 0.3677  loss_box_reg: 0.5067  loss_mask: 0.3058  loss_rpn_cls: 0.08419  loss_rpn_loc: 0.2023  time: 0.6250  data_time: 0.2821  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:01:28 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 5399  total_loss: 1.422  loss_cls: 0.3563  loss_box_reg: 0.5047  loss_mask: 0.3014  loss_rpn_cls: 0.07663  loss_rpn_loc: 0.1881  time: 0.6253  data_time: 0.2628  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:01:39 d2.utils.events]: \u001b[0m eta: 0:33:38  iter: 5419  total_loss: 1.38  loss_cls: 0.3391  loss_box_reg: 0.5115  loss_mask: 0.2924  loss_rpn_cls: 0.05958  loss_rpn_loc: 0.1791  time: 0.6250  data_time: 0.1360  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:01:51 d2.utils.events]: \u001b[0m eta: 0:33:24  iter: 5439  total_loss: 1.489  loss_cls: 0.3432  loss_box_reg: 0.5374  loss_mask: 0.325  loss_rpn_cls: 0.05675  loss_rpn_loc: 0.1908  time: 0.6249  data_time: 0.1789  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:02:02 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 5459  total_loss: 1.422  loss_cls: 0.3601  loss_box_reg: 0.5244  loss_mask: 0.2862  loss_rpn_cls: 0.06624  loss_rpn_loc: 0.1959  time: 0.6246  data_time: 0.1181  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:02:13 d2.utils.events]: \u001b[0m eta: 0:33:06  iter: 5479  total_loss: 1.592  loss_cls: 0.3975  loss_box_reg: 0.5339  loss_mask: 0.3093  loss_rpn_cls: 0.06431  loss_rpn_loc: 0.1947  time: 0.6243  data_time: 0.1277  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:02:26 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 5499  total_loss: 1.438  loss_cls: 0.3723  loss_box_reg: 0.5191  loss_mask: 0.3074  loss_rpn_cls: 0.09245  loss_rpn_loc: 0.193  time: 0.6245  data_time: 0.2405  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:02:37 d2.utils.events]: \u001b[0m eta: 0:32:59  iter: 5519  total_loss: 1.48  loss_cls: 0.3615  loss_box_reg: 0.55  loss_mask: 0.3099  loss_rpn_cls: 0.07579  loss_rpn_loc: 0.1928  time: 0.6243  data_time: 0.1538  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:02:49 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 5539  total_loss: 1.539  loss_cls: 0.3719  loss_box_reg: 0.5366  loss_mask: 0.3113  loss_rpn_cls: 0.07338  loss_rpn_loc: 0.1975  time: 0.6242  data_time: 0.1639  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:03:02 d2.utils.events]: \u001b[0m eta: 0:32:35  iter: 5559  total_loss: 1.342  loss_cls: 0.3275  loss_box_reg: 0.488  loss_mask: 0.2825  loss_rpn_cls: 0.07168  loss_rpn_loc: 0.1707  time: 0.6243  data_time: 0.2263  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:03:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:03:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:03:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:03:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:03:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:03:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0757 s/iter. Eval: 0.0410 s/iter. Total: 0.1173 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 12:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0551 s/iter. Total: 0.1328 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0008 s/iter. Inference: 0.0775 s/iter. Eval: 0.0580 s/iter. Total: 0.1362 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:03:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.652193 (0.134933 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:03:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077154 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:03:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:03:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26530056688501863\n",
      "\u001b[32m[02/04 12:03:33 d2.utils.events]: \u001b[0m eta: 0:32:24  iter: 5579  total_loss: 1.473  loss_cls: 0.3458  loss_box_reg: 0.4895  loss_mask: 0.3056  loss_rpn_cls: 0.08942  loss_rpn_loc: 0.2003  time: 0.6244  data_time: 0.2241  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:03:46 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 5599  total_loss: 1.384  loss_cls: 0.3237  loss_box_reg: 0.5053  loss_mask: 0.2984  loss_rpn_cls: 0.05583  loss_rpn_loc: 0.1699  time: 0.6245  data_time: 0.2333  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:03:59 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 5619  total_loss: 1.443  loss_cls: 0.3564  loss_box_reg: 0.5268  loss_mask: 0.2981  loss_rpn_cls: 0.07204  loss_rpn_loc: 0.1877  time: 0.6246  data_time: 0.2459  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:04:12 d2.utils.events]: \u001b[0m eta: 0:31:59  iter: 5639  total_loss: 1.387  loss_cls: 0.3307  loss_box_reg: 0.4808  loss_mask: 0.2939  loss_rpn_cls: 0.07225  loss_rpn_loc: 0.1811  time: 0.6247  data_time: 0.2345  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:04:24 d2.utils.events]: \u001b[0m eta: 0:31:50  iter: 5659  total_loss: 1.414  loss_cls: 0.3541  loss_box_reg: 0.4959  loss_mask: 0.2877  loss_rpn_cls: 0.05687  loss_rpn_loc: 0.1846  time: 0.6246  data_time: 0.1748  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:04:38 d2.utils.events]: \u001b[0m eta: 0:31:42  iter: 5679  total_loss: 1.503  loss_cls: 0.3758  loss_box_reg: 0.5195  loss_mask: 0.3124  loss_rpn_cls: 0.08019  loss_rpn_loc: 0.2072  time: 0.6249  data_time: 0.2778  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:04:53 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 5699  total_loss: 1.449  loss_cls: 0.3444  loss_box_reg: 0.5272  loss_mask: 0.3139  loss_rpn_cls: 0.05902  loss_rpn_loc: 0.2025  time: 0.6253  data_time: 0.3057  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:05:06 d2.utils.events]: \u001b[0m eta: 0:31:23  iter: 5719  total_loss: 1.505  loss_cls: 0.3678  loss_box_reg: 0.5305  loss_mask: 0.3235  loss_rpn_cls: 0.07815  loss_rpn_loc: 0.201  time: 0.6254  data_time: 0.2374  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:05:19 d2.utils.events]: \u001b[0m eta: 0:31:16  iter: 5739  total_loss: 1.56  loss_cls: 0.3912  loss_box_reg: 0.531  loss_mask: 0.2975  loss_rpn_cls: 0.103  loss_rpn_loc: 0.2182  time: 0.6255  data_time: 0.2296  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:05:30 d2.utils.events]: \u001b[0m eta: 0:31:03  iter: 5759  total_loss: 1.364  loss_cls: 0.3287  loss_box_reg: 0.5054  loss_mask: 0.2928  loss_rpn_cls: 0.05715  loss_rpn_loc: 0.166  time: 0.6252  data_time: 0.1239  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:05:40 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 5779  total_loss: 1.449  loss_cls: 0.3558  loss_box_reg: 0.5238  loss_mask: 0.2937  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.1916  time: 0.6248  data_time: 0.0969  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:05:52 d2.utils.events]: \u001b[0m eta: 0:30:42  iter: 5799  total_loss: 1.494  loss_cls: 0.3374  loss_box_reg: 0.51  loss_mask: 0.3018  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.1941  time: 0.6247  data_time: 0.1958  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:05:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:05:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:05:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:05:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:05:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:05:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0748 s/iter. Eval: 0.0384 s/iter. Total: 0.1139 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 12:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0548 s/iter. Total: 0.1326 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0578 s/iter. Total: 0.1359 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.555387 (0.134098 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077030 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:06:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:06:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26552672356947304\n",
      "\u001b[32m[02/04 12:06:22 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 5819  total_loss: 1.551  loss_cls: 0.3886  loss_box_reg: 0.5233  loss_mask: 0.3133  loss_rpn_cls: 0.07947  loss_rpn_loc: 0.195  time: 0.6247  data_time: 0.1775  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:06:33 d2.utils.events]: \u001b[0m eta: 0:30:29  iter: 5839  total_loss: 1.566  loss_cls: 0.4074  loss_box_reg: 0.5585  loss_mask: 0.3071  loss_rpn_cls: 0.09358  loss_rpn_loc: 0.1963  time: 0.6245  data_time: 0.1269  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:06:47 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 5859  total_loss: 1.511  loss_cls: 0.3803  loss_box_reg: 0.5232  loss_mask: 0.3111  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.222  time: 0.6248  data_time: 0.2581  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:06:58 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 5879  total_loss: 1.374  loss_cls: 0.3429  loss_box_reg: 0.5196  loss_mask: 0.2914  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.1784  time: 0.6245  data_time: 0.1291  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:07:12 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 5899  total_loss: 1.449  loss_cls: 0.3601  loss_box_reg: 0.5122  loss_mask: 0.3081  loss_rpn_cls: 0.06771  loss_rpn_loc: 0.1907  time: 0.6247  data_time: 0.2624  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:07:25 d2.utils.events]: \u001b[0m eta: 0:29:55  iter: 5919  total_loss: 1.344  loss_cls: 0.317  loss_box_reg: 0.502  loss_mask: 0.2898  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.1778  time: 0.6249  data_time: 0.2408  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:07:41 d2.utils.events]: \u001b[0m eta: 0:29:49  iter: 5939  total_loss: 1.513  loss_cls: 0.3647  loss_box_reg: 0.5024  loss_mask: 0.3011  loss_rpn_cls: 0.09082  loss_rpn_loc: 0.2023  time: 0.6255  data_time: 0.3665  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:07:54 d2.utils.events]: \u001b[0m eta: 0:29:38  iter: 5959  total_loss: 1.361  loss_cls: 0.3161  loss_box_reg: 0.5049  loss_mask: 0.3069  loss_rpn_cls: 0.05833  loss_rpn_loc: 0.1866  time: 0.6255  data_time: 0.2142  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:08:05 d2.utils.events]: \u001b[0m eta: 0:29:29  iter: 5979  total_loss: 1.479  loss_cls: 0.3574  loss_box_reg: 0.5014  loss_mask: 0.2998  loss_rpn_cls: 0.06974  loss_rpn_loc: 0.1914  time: 0.6252  data_time: 0.1377  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:08:18 d2.utils.events]: \u001b[0m eta: 0:29:20  iter: 5999  total_loss: 1.366  loss_cls: 0.3401  loss_box_reg: 0.4968  loss_mask: 0.2945  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1774  time: 0.6253  data_time: 0.2154  lr: 0.0002048  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:08:30 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 6019  total_loss: 1.493  loss_cls: 0.3447  loss_box_reg: 0.5236  loss_mask: 0.3122  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.1811  time: 0.6253  data_time: 0.1844  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:08:42 d2.utils.events]: \u001b[0m eta: 0:29:03  iter: 6039  total_loss: 1.47  loss_cls: 0.368  loss_box_reg: 0.5379  loss_mask: 0.2915  loss_rpn_cls: 0.08712  loss_rpn_loc: 0.1832  time: 0.6251  data_time: 0.1434  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:08:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:08:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:08:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:08:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:08:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:08:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0746 s/iter. Eval: 0.0355 s/iter. Total: 0.1107 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 12:08:54 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0769 s/iter. Eval: 0.0533 s/iter. Total: 0.1310 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0573 s/iter. Total: 0.1354 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 12:09:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.488211 (0.133519 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:09:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077067 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:09:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:09:04 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2619822170317832\n",
      "\u001b[32m[02/04 12:09:10 d2.utils.events]: \u001b[0m eta: 0:28:53  iter: 6059  total_loss: 1.441  loss_cls: 0.3449  loss_box_reg: 0.5112  loss_mask: 0.2949  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.1853  time: 0.6249  data_time: 0.1310  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:09:24 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 6079  total_loss: 1.469  loss_cls: 0.3652  loss_box_reg: 0.5075  loss_mask: 0.3011  loss_rpn_cls: 0.09164  loss_rpn_loc: 0.185  time: 0.6250  data_time: 0.2415  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:09:36 d2.utils.events]: \u001b[0m eta: 0:28:38  iter: 6099  total_loss: 1.398  loss_cls: 0.3607  loss_box_reg: 0.4886  loss_mask: 0.276  loss_rpn_cls: 0.08984  loss_rpn_loc: 0.1874  time: 0.6251  data_time: 0.2189  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:09:52 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 6119  total_loss: 1.472  loss_cls: 0.3551  loss_box_reg: 0.4992  loss_mask: 0.3061  loss_rpn_cls: 0.0789  loss_rpn_loc: 0.188  time: 0.6257  data_time: 0.3577  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:10:05 d2.utils.events]: \u001b[0m eta: 0:28:19  iter: 6139  total_loss: 1.41  loss_cls: 0.3321  loss_box_reg: 0.5285  loss_mask: 0.2973  loss_rpn_cls: 0.07923  loss_rpn_loc: 0.2011  time: 0.6256  data_time: 0.1985  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:10:16 d2.utils.events]: \u001b[0m eta: 0:28:11  iter: 6159  total_loss: 1.433  loss_cls: 0.3654  loss_box_reg: 0.5219  loss_mask: 0.2953  loss_rpn_cls: 0.055  loss_rpn_loc: 0.1916  time: 0.6254  data_time: 0.1341  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:10:28 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 6179  total_loss: 1.413  loss_cls: 0.3399  loss_box_reg: 0.5189  loss_mask: 0.2989  loss_rpn_cls: 0.06057  loss_rpn_loc: 0.1731  time: 0.6253  data_time: 0.1890  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:10:39 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 6199  total_loss: 1.568  loss_cls: 0.3943  loss_box_reg: 0.5338  loss_mask: 0.3065  loss_rpn_cls: 0.08793  loss_rpn_loc: 0.2097  time: 0.6252  data_time: 0.1587  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:10:51 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 6219  total_loss: 1.318  loss_cls: 0.3047  loss_box_reg: 0.5129  loss_mask: 0.2948  loss_rpn_cls: 0.04014  loss_rpn_loc: 0.1575  time: 0.6251  data_time: 0.1714  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:11:03 d2.utils.events]: \u001b[0m eta: 0:27:34  iter: 6239  total_loss: 1.468  loss_cls: 0.3513  loss_box_reg: 0.504  loss_mask: 0.315  loss_rpn_cls: 0.07111  loss_rpn_loc: 0.1985  time: 0.6250  data_time: 0.1793  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:11:16 d2.utils.events]: \u001b[0m eta: 0:27:25  iter: 6259  total_loss: 1.486  loss_cls: 0.3664  loss_box_reg: 0.498  loss_mask: 0.307  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.2118  time: 0.6250  data_time: 0.1942  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:11:27 d2.utils.events]: \u001b[0m eta: 0:27:17  iter: 6279  total_loss: 1.437  loss_cls: 0.3433  loss_box_reg: 0.5476  loss_mask: 0.3076  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.1819  time: 0.6248  data_time: 0.1396  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:11:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:11:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:11:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:11:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:11:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:11:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:11:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0371 s/iter. Total: 0.1123 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 12:11:42 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0770 s/iter. Eval: 0.0547 s/iter. Total: 0.1325 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:11:47 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0007 s/iter. Inference: 0.0774 s/iter. Eval: 0.0577 s/iter. Total: 0.1360 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 12:11:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.533810 (0.133912 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:11:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:11:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:11:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2673323018627986\n",
      "\u001b[32m[02/04 12:11:57 d2.utils.events]: \u001b[0m eta: 0:27:09  iter: 6299  total_loss: 1.49  loss_cls: 0.3852  loss_box_reg: 0.5242  loss_mask: 0.3049  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1993  time: 0.6248  data_time: 0.2085  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:12:09 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 6319  total_loss: 1.436  loss_cls: 0.3371  loss_box_reg: 0.5081  loss_mask: 0.3017  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.1919  time: 0.6248  data_time: 0.2018  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:12:20 d2.utils.events]: \u001b[0m eta: 0:26:51  iter: 6339  total_loss: 1.358  loss_cls: 0.3304  loss_box_reg: 0.5032  loss_mask: 0.2842  loss_rpn_cls: 0.05538  loss_rpn_loc: 0.1691  time: 0.6246  data_time: 0.1429  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:12:31 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 6359  total_loss: 1.481  loss_cls: 0.361  loss_box_reg: 0.5273  loss_mask: 0.3111  loss_rpn_cls: 0.06987  loss_rpn_loc: 0.2069  time: 0.6242  data_time: 0.1070  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:12:43 d2.utils.events]: \u001b[0m eta: 0:26:33  iter: 6379  total_loss: 1.376  loss_cls: 0.3333  loss_box_reg: 0.5155  loss_mask: 0.2984  loss_rpn_cls: 0.06661  loss_rpn_loc: 0.1641  time: 0.6242  data_time: 0.1873  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:12:57 d2.utils.events]: \u001b[0m eta: 0:26:23  iter: 6399  total_loss: 1.537  loss_cls: 0.3761  loss_box_reg: 0.5241  loss_mask: 0.3212  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.1843  time: 0.6244  data_time: 0.2568  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:13:12 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 6419  total_loss: 1.462  loss_cls: 0.3616  loss_box_reg: 0.4989  loss_mask: 0.3106  loss_rpn_cls: 0.09058  loss_rpn_loc: 0.2029  time: 0.6249  data_time: 0.3283  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:13:25 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 6439  total_loss: 1.391  loss_cls: 0.3385  loss_box_reg: 0.5026  loss_mask: 0.2971  loss_rpn_cls: 0.04788  loss_rpn_loc: 0.1901  time: 0.6249  data_time: 0.2180  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:13:38 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 6459  total_loss: 1.506  loss_cls: 0.3613  loss_box_reg: 0.5299  loss_mask: 0.315  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.1944  time: 0.6250  data_time: 0.2296  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:13:52 d2.utils.events]: \u001b[0m eta: 0:25:50  iter: 6479  total_loss: 1.49  loss_cls: 0.3738  loss_box_reg: 0.5233  loss_mask: 0.301  loss_rpn_cls: 0.08755  loss_rpn_loc: 0.2114  time: 0.6252  data_time: 0.2620  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:14:04 d2.utils.events]: \u001b[0m eta: 0:25:40  iter: 6499  total_loss: 1.426  loss_cls: 0.3426  loss_box_reg: 0.5249  loss_mask: 0.3031  loss_rpn_cls: 0.07648  loss_rpn_loc: 0.18  time: 0.6251  data_time: 0.1733  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:14:15 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 6519  total_loss: 1.367  loss_cls: 0.3324  loss_box_reg: 0.5029  loss_mask: 0.2871  loss_rpn_cls: 0.07281  loss_rpn_loc: 0.1886  time: 0.6250  data_time: 0.1602  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:14:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:14:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:14:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:14:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:14:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:14:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:14:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0746 s/iter. Eval: 0.0352 s/iter. Total: 0.1104 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 12:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0772 s/iter. Eval: 0.0542 s/iter. Total: 0.1321 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0774 s/iter. Eval: 0.0571 s/iter. Total: 0.1352 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:14:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.561691 (0.134153 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:14:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077128 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:14:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:14:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2654286479209506\n",
      "\u001b[32m[02/04 12:14:44 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 6539  total_loss: 1.458  loss_cls: 0.3688  loss_box_reg: 0.5083  loss_mask: 0.2856  loss_rpn_cls: 0.07244  loss_rpn_loc: 0.1843  time: 0.6248  data_time: 0.1657  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:14:58 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 6559  total_loss: 1.358  loss_cls: 0.3425  loss_box_reg: 0.4742  loss_mask: 0.2817  loss_rpn_cls: 0.07614  loss_rpn_loc: 0.1762  time: 0.6251  data_time: 0.2781  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:15:10 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 6579  total_loss: 1.423  loss_cls: 0.3365  loss_box_reg: 0.5224  loss_mask: 0.3007  loss_rpn_cls: 0.06174  loss_rpn_loc: 0.1753  time: 0.6249  data_time: 0.1418  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:15:21 d2.utils.events]: \u001b[0m eta: 0:24:57  iter: 6599  total_loss: 1.421  loss_cls: 0.3389  loss_box_reg: 0.5032  loss_mask: 0.2956  loss_rpn_cls: 0.05746  loss_rpn_loc: 0.1792  time: 0.6248  data_time: 0.1741  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:15:32 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 6619  total_loss: 1.375  loss_cls: 0.3408  loss_box_reg: 0.4996  loss_mask: 0.2923  loss_rpn_cls: 0.06683  loss_rpn_loc: 0.1879  time: 0.6244  data_time: 0.1053  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:15:45 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 6639  total_loss: 1.453  loss_cls: 0.3357  loss_box_reg: 0.5146  loss_mask: 0.2988  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.199  time: 0.6245  data_time: 0.2261  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:15:58 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 6659  total_loss: 1.449  loss_cls: 0.3366  loss_box_reg: 0.5238  loss_mask: 0.2948  loss_rpn_cls: 0.06065  loss_rpn_loc: 0.1784  time: 0.6247  data_time: 0.2498  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:16:11 d2.utils.events]: \u001b[0m eta: 0:24:21  iter: 6679  total_loss: 1.39  loss_cls: 0.3346  loss_box_reg: 0.4835  loss_mask: 0.3002  loss_rpn_cls: 0.06653  loss_rpn_loc: 0.1882  time: 0.6247  data_time: 0.2168  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:16:24 d2.utils.events]: \u001b[0m eta: 0:24:12  iter: 6699  total_loss: 1.384  loss_cls: 0.3525  loss_box_reg: 0.5174  loss_mask: 0.2957  loss_rpn_cls: 0.06208  loss_rpn_loc: 0.1857  time: 0.6248  data_time: 0.2409  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:16:35 d2.utils.events]: \u001b[0m eta: 0:24:03  iter: 6719  total_loss: 1.443  loss_cls: 0.3616  loss_box_reg: 0.5129  loss_mask: 0.2937  loss_rpn_cls: 0.06784  loss_rpn_loc: 0.1769  time: 0.6246  data_time: 0.1216  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:16:47 d2.utils.events]: \u001b[0m eta: 0:23:54  iter: 6739  total_loss: 1.461  loss_cls: 0.3579  loss_box_reg: 0.4992  loss_mask: 0.2897  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.1903  time: 0.6245  data_time: 0.1725  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:17:01 d2.utils.events]: \u001b[0m eta: 0:23:47  iter: 6759  total_loss: 1.49  loss_cls: 0.3628  loss_box_reg: 0.5261  loss_mask: 0.313  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.1904  time: 0.6247  data_time: 0.2622  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:17:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:17:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:17:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:17:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:17:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:17:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:17:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0757 s/iter. Eval: 0.0389 s/iter. Total: 0.1154 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 12:17:21 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.0771 s/iter. Eval: 0.0549 s/iter. Total: 0.1328 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.0774 s/iter. Eval: 0.0579 s/iter. Total: 0.1361 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 12:17:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.569707 (0.134222 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:17:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077084 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:17:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:17:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26493057700479095\n",
      "\u001b[32m[02/04 12:17:32 d2.utils.events]: \u001b[0m eta: 0:23:40  iter: 6779  total_loss: 1.531  loss_cls: 0.3777  loss_box_reg: 0.5534  loss_mask: 0.3156  loss_rpn_cls: 0.08569  loss_rpn_loc: 0.1907  time: 0.6249  data_time: 0.2685  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:17:47 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 6799  total_loss: 1.427  loss_cls: 0.354  loss_box_reg: 0.5253  loss_mask: 0.3066  loss_rpn_cls: 0.08256  loss_rpn_loc: 0.2027  time: 0.6253  data_time: 0.3083  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:17:59 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 6819  total_loss: 1.391  loss_cls: 0.3387  loss_box_reg: 0.5076  loss_mask: 0.3061  loss_rpn_cls: 0.0585  loss_rpn_loc: 0.1922  time: 0.6252  data_time: 0.1604  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:18:15 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 6839  total_loss: 1.418  loss_cls: 0.3295  loss_box_reg: 0.4971  loss_mask: 0.2922  loss_rpn_cls: 0.06789  loss_rpn_loc: 0.1768  time: 0.6256  data_time: 0.3579  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:18:28 d2.utils.events]: \u001b[0m eta: 0:23:03  iter: 6859  total_loss: 1.421  loss_cls: 0.3482  loss_box_reg: 0.495  loss_mask: 0.2947  loss_rpn_cls: 0.07226  loss_rpn_loc: 0.1933  time: 0.6258  data_time: 0.2672  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:18:43 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 6879  total_loss: 1.484  loss_cls: 0.3642  loss_box_reg: 0.5057  loss_mask: 0.3131  loss_rpn_cls: 0.09287  loss_rpn_loc: 0.1985  time: 0.6261  data_time: 0.2983  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:18:55 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 6899  total_loss: 1.429  loss_cls: 0.3718  loss_box_reg: 0.4986  loss_mask: 0.2977  loss_rpn_cls: 0.09359  loss_rpn_loc: 0.1932  time: 0.6261  data_time: 0.1787  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:19:07 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 6919  total_loss: 1.454  loss_cls: 0.3448  loss_box_reg: 0.5131  loss_mask: 0.2934  loss_rpn_cls: 0.07582  loss_rpn_loc: 0.1999  time: 0.6259  data_time: 0.1562  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:19:17 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 6939  total_loss: 1.356  loss_cls: 0.3303  loss_box_reg: 0.5078  loss_mask: 0.2861  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.1755  time: 0.6256  data_time: 0.0901  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:19:28 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 6959  total_loss: 1.525  loss_cls: 0.3987  loss_box_reg: 0.5346  loss_mask: 0.3072  loss_rpn_cls: 0.08429  loss_rpn_loc: 0.1867  time: 0.6255  data_time: 0.1567  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:19:39 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 6979  total_loss: 1.346  loss_cls: 0.3166  loss_box_reg: 0.4999  loss_mask: 0.289  loss_rpn_cls: 0.04929  loss_rpn_loc: 0.182  time: 0.6252  data_time: 0.1319  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:19:52 d2.utils.events]: \u001b[0m eta: 0:22:03  iter: 6999  total_loss: 1.304  loss_cls: 0.2991  loss_box_reg: 0.4865  loss_mask: 0.2825  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.1741  time: 0.6253  data_time: 0.2089  lr: 0.00016384  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:20:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:20:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:20:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:20:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:20:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:20:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0765 s/iter. Eval: 0.0417 s/iter. Total: 0.1189 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 12:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0771 s/iter. Eval: 0.0536 s/iter. Total: 0.1315 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0773 s/iter. Eval: 0.0562 s/iter. Total: 0.1343 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 12:20:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.403290 (0.132787 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:20:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077055 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:20:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:20:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26531823052744175\n",
      "\u001b[32m[02/04 12:20:22 d2.utils.events]: \u001b[0m eta: 0:21:54  iter: 7019  total_loss: 1.435  loss_cls: 0.3469  loss_box_reg: 0.5101  loss_mask: 0.3058  loss_rpn_cls: 0.0813  loss_rpn_loc: 0.1941  time: 0.6253  data_time: 0.1946  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:20:34 d2.utils.events]: \u001b[0m eta: 0:21:45  iter: 7039  total_loss: 1.543  loss_cls: 0.3751  loss_box_reg: 0.5423  loss_mask: 0.3129  loss_rpn_cls: 0.07252  loss_rpn_loc: 0.1863  time: 0.6252  data_time: 0.2026  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:20:46 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 7059  total_loss: 1.387  loss_cls: 0.3393  loss_box_reg: 0.5157  loss_mask: 0.3023  loss_rpn_cls: 0.05447  loss_rpn_loc: 0.1684  time: 0.6252  data_time: 0.1866  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:20:59 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 7079  total_loss: 1.433  loss_cls: 0.3595  loss_box_reg: 0.5189  loss_mask: 0.2954  loss_rpn_cls: 0.07642  loss_rpn_loc: 0.1935  time: 0.6252  data_time: 0.1823  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:21:14 d2.utils.events]: \u001b[0m eta: 0:21:18  iter: 7099  total_loss: 1.498  loss_cls: 0.3763  loss_box_reg: 0.512  loss_mask: 0.3148  loss_rpn_cls: 0.07192  loss_rpn_loc: 0.1949  time: 0.6256  data_time: 0.3201  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:21:26 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 7119  total_loss: 1.476  loss_cls: 0.3377  loss_box_reg: 0.5003  loss_mask: 0.3181  loss_rpn_cls: 0.05419  loss_rpn_loc: 0.1926  time: 0.6256  data_time: 0.2117  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:21:44 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 7139  total_loss: 1.407  loss_cls: 0.3492  loss_box_reg: 0.4994  loss_mask: 0.2997  loss_rpn_cls: 0.07811  loss_rpn_loc: 0.1903  time: 0.6263  data_time: 0.4540  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:21:57 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 7159  total_loss: 1.402  loss_cls: 0.3385  loss_box_reg: 0.5229  loss_mask: 0.2971  loss_rpn_cls: 0.05589  loss_rpn_loc: 0.1807  time: 0.6263  data_time: 0.2058  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:22:06 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 7179  total_loss: 1.47  loss_cls: 0.3436  loss_box_reg: 0.5411  loss_mask: 0.313  loss_rpn_cls: 0.05359  loss_rpn_loc: 0.1763  time: 0.6259  data_time: 0.0683  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:22:18 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 7199  total_loss: 1.469  loss_cls: 0.3716  loss_box_reg: 0.533  loss_mask: 0.2914  loss_rpn_cls: 0.07607  loss_rpn_loc: 0.1874  time: 0.6258  data_time: 0.1419  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:22:33 d2.utils.events]: \u001b[0m eta: 0:20:26  iter: 7219  total_loss: 1.529  loss_cls: 0.3725  loss_box_reg: 0.5149  loss_mask: 0.3058  loss_rpn_cls: 0.09567  loss_rpn_loc: 0.2231  time: 0.6261  data_time: 0.3327  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:22:42 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 7239  total_loss: 1.395  loss_cls: 0.339  loss_box_reg: 0.5036  loss_mask: 0.2882  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.1874  time: 0.6257  data_time: 0.0563  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:22:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:22:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:22:56 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:22:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:22:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:22:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0763 s/iter. Eval: 0.0376 s/iter. Total: 0.1146 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 12:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0548 s/iter. Total: 0.1329 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0007 s/iter. Inference: 0.0776 s/iter. Eval: 0.0580 s/iter. Total: 0.1363 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:23:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.655662 (0.134963 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:23:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077205 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:23:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:23:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2675728283183669\n",
      "\u001b[32m[02/04 12:23:13 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 7259  total_loss: 1.401  loss_cls: 0.3661  loss_box_reg: 0.5163  loss_mask: 0.2926  loss_rpn_cls: 0.07863  loss_rpn_loc: 0.1732  time: 0.6257  data_time: 0.2206  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:23:23 d2.utils.events]: \u001b[0m eta: 0:19:59  iter: 7279  total_loss: 1.482  loss_cls: 0.3588  loss_box_reg: 0.5274  loss_mask: 0.2924  loss_rpn_cls: 0.0764  loss_rpn_loc: 0.2051  time: 0.6255  data_time: 0.1185  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:23:39 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 7299  total_loss: 1.473  loss_cls: 0.3614  loss_box_reg: 0.5021  loss_mask: 0.3194  loss_rpn_cls: 0.08272  loss_rpn_loc: 0.1979  time: 0.6260  data_time: 0.3655  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:23:50 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 7319  total_loss: 1.392  loss_cls: 0.3275  loss_box_reg: 0.504  loss_mask: 0.2939  loss_rpn_cls: 0.04321  loss_rpn_loc: 0.1849  time: 0.6257  data_time: 0.1022  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:23:59 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 7339  total_loss: 1.348  loss_cls: 0.294  loss_box_reg: 0.5252  loss_mask: 0.301  loss_rpn_cls: 0.04828  loss_rpn_loc: 0.1737  time: 0.6253  data_time: 0.0649  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:24:11 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 7359  total_loss: 1.387  loss_cls: 0.3385  loss_box_reg: 0.5218  loss_mask: 0.3001  loss_rpn_cls: 0.0653  loss_rpn_loc: 0.1744  time: 0.6252  data_time: 0.1732  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:24:25 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 7379  total_loss: 1.409  loss_cls: 0.3402  loss_box_reg: 0.4992  loss_mask: 0.2908  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.1855  time: 0.6253  data_time: 0.2178  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:24:38 d2.utils.events]: \u001b[0m eta: 0:19:10  iter: 7399  total_loss: 1.488  loss_cls: 0.3838  loss_box_reg: 0.5034  loss_mask: 0.2932  loss_rpn_cls: 0.08097  loss_rpn_loc: 0.1938  time: 0.6254  data_time: 0.1900  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:24:48 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 7419  total_loss: 1.486  loss_cls: 0.3413  loss_box_reg: 0.558  loss_mask: 0.3063  loss_rpn_cls: 0.07687  loss_rpn_loc: 0.1895  time: 0.6251  data_time: 0.0898  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:25:01 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 7439  total_loss: 1.471  loss_cls: 0.3605  loss_box_reg: 0.5234  loss_mask: 0.3059  loss_rpn_cls: 0.07448  loss_rpn_loc: 0.1983  time: 0.6252  data_time: 0.2276  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:25:15 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 7459  total_loss: 1.408  loss_cls: 0.3461  loss_box_reg: 0.494  loss_mask: 0.2915  loss_rpn_cls: 0.07926  loss_rpn_loc: 0.1925  time: 0.6254  data_time: 0.2457  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:25:26 d2.utils.events]: \u001b[0m eta: 0:18:40  iter: 7479  total_loss: 1.359  loss_cls: 0.3189  loss_box_reg: 0.5094  loss_mask: 0.2961  loss_rpn_cls: 0.04818  loss_rpn_loc: 0.1846  time: 0.6252  data_time: 0.1033  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:25:41 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 7499  total_loss: 1.426  loss_cls: 0.3579  loss_box_reg: 0.4991  loss_mask: 0.3049  loss_rpn_cls: 0.0821  loss_rpn_loc: 0.2015  time: 0.6255  data_time: 0.2632  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:25:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:25:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:25:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:25:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:25:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:25:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:25:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0828 s/iter. Eval: 0.0413 s/iter. Total: 0.1248 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 12:25:51 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0575 s/iter. Total: 0.1416 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 12:25:56 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.0835 s/iter. Eval: 0.0594 s/iter. Total: 0.1437 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:26:01 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.0830 s/iter. Eval: 0.0580 s/iter. Total: 0.1418 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 12:26:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.549181 (0.142665 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:26:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.082961 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:26:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:26:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26476474693031726\n",
      "\u001b[32m[02/04 12:26:13 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 7519  total_loss: 1.399  loss_cls: 0.333  loss_box_reg: 0.4875  loss_mask: 0.2959  loss_rpn_cls: 0.06636  loss_rpn_loc: 0.182  time: 0.6256  data_time: 0.1915  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:26:26 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 7539  total_loss: 1.516  loss_cls: 0.3893  loss_box_reg: 0.5174  loss_mask: 0.3034  loss_rpn_cls: 0.0902  loss_rpn_loc: 0.1909  time: 0.6258  data_time: 0.2300  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:26:40 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 7559  total_loss: 1.443  loss_cls: 0.3342  loss_box_reg: 0.5041  loss_mask: 0.294  loss_rpn_cls: 0.07317  loss_rpn_loc: 0.1988  time: 0.6259  data_time: 0.2215  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:26:52 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 7579  total_loss: 1.433  loss_cls: 0.3413  loss_box_reg: 0.5078  loss_mask: 0.3101  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.1813  time: 0.6259  data_time: 0.1739  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:27:06 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 7599  total_loss: 1.516  loss_cls: 0.3914  loss_box_reg: 0.5181  loss_mask: 0.3148  loss_rpn_cls: 0.07435  loss_rpn_loc: 0.1966  time: 0.6261  data_time: 0.2327  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:27:18 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 7619  total_loss: 1.405  loss_cls: 0.3342  loss_box_reg: 0.5063  loss_mask: 0.2982  loss_rpn_cls: 0.06292  loss_rpn_loc: 0.1685  time: 0.6260  data_time: 0.1360  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:27:32 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 7639  total_loss: 1.413  loss_cls: 0.336  loss_box_reg: 0.5009  loss_mask: 0.3025  loss_rpn_cls: 0.06561  loss_rpn_loc: 0.1857  time: 0.6262  data_time: 0.2559  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:27:48 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 7659  total_loss: 1.446  loss_cls: 0.3301  loss_box_reg: 0.4921  loss_mask: 0.3011  loss_rpn_cls: 0.09046  loss_rpn_loc: 0.2001  time: 0.6266  data_time: 0.3502  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:27:59 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 7679  total_loss: 1.337  loss_cls: 0.3159  loss_box_reg: 0.5238  loss_mask: 0.2838  loss_rpn_cls: 0.05105  loss_rpn_loc: 0.1624  time: 0.6265  data_time: 0.1296  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:28:14 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 7699  total_loss: 1.447  loss_cls: 0.363  loss_box_reg: 0.4756  loss_mask: 0.3008  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.1934  time: 0.6267  data_time: 0.2646  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:28:24 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 7719  total_loss: 1.337  loss_cls: 0.3118  loss_box_reg: 0.4886  loss_mask: 0.2924  loss_rpn_cls: 0.05862  loss_rpn_loc: 0.1708  time: 0.6263  data_time: 0.0472  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:28:35 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 7739  total_loss: 1.496  loss_cls: 0.3682  loss_box_reg: 0.5261  loss_mask: 0.3081  loss_rpn_cls: 0.06985  loss_rpn_loc: 0.1829  time: 0.6262  data_time: 0.1137  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:28:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:28:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:28:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:28:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:28:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:28:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0824 s/iter. Eval: 0.0435 s/iter. Total: 0.1267 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 12:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0007 s/iter. Inference: 0.0803 s/iter. Eval: 0.0564 s/iter. Total: 0.1374 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 12:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0011 s/iter. Inference: 0.0809 s/iter. Eval: 0.0591 s/iter. Total: 0.1411 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0010 s/iter. Inference: 0.0801 s/iter. Eval: 0.0566 s/iter. Total: 0.1378 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 12:28:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.041325 (0.138287 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:28:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.080138 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:28:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:28:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2650936143315773\n",
      "\u001b[32m[02/04 12:29:07 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 7759  total_loss: 1.57  loss_cls: 0.3765  loss_box_reg: 0.5222  loss_mask: 0.3213  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2151  time: 0.6264  data_time: 0.2642  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:29:18 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 7779  total_loss: 1.39  loss_cls: 0.3404  loss_box_reg: 0.4976  loss_mask: 0.2933  loss_rpn_cls: 0.06384  loss_rpn_loc: 0.1866  time: 0.6263  data_time: 0.1349  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:29:29 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 7799  total_loss: 1.432  loss_cls: 0.3602  loss_box_reg: 0.4841  loss_mask: 0.2893  loss_rpn_cls: 0.06812  loss_rpn_loc: 0.1893  time: 0.6261  data_time: 0.1180  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:29:42 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 7819  total_loss: 1.463  loss_cls: 0.3177  loss_box_reg: 0.4895  loss_mask: 0.2967  loss_rpn_cls: 0.0715  loss_rpn_loc: 0.1921  time: 0.6261  data_time: 0.1987  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:29:53 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 7839  total_loss: 1.464  loss_cls: 0.3504  loss_box_reg: 0.5408  loss_mask: 0.3084  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.1992  time: 0.6259  data_time: 0.0908  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:30:06 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 7859  total_loss: 1.477  loss_cls: 0.3554  loss_box_reg: 0.5135  loss_mask: 0.315  loss_rpn_cls: 0.06989  loss_rpn_loc: 0.1864  time: 0.6259  data_time: 0.2058  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:30:19 d2.utils.events]: \u001b[0m eta: 0:16:04  iter: 7879  total_loss: 1.381  loss_cls: 0.3179  loss_box_reg: 0.4996  loss_mask: 0.3013  loss_rpn_cls: 0.06078  loss_rpn_loc: 0.174  time: 0.6260  data_time: 0.2272  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:30:31 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 7899  total_loss: 1.402  loss_cls: 0.3119  loss_box_reg: 0.532  loss_mask: 0.3086  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1731  time: 0.6259  data_time: 0.1600  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:30:47 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 7919  total_loss: 1.542  loss_cls: 0.3887  loss_box_reg: 0.5029  loss_mask: 0.3077  loss_rpn_cls: 0.09125  loss_rpn_loc: 0.1934  time: 0.6264  data_time: 0.3405  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:31:00 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 7939  total_loss: 1.426  loss_cls: 0.3707  loss_box_reg: 0.4941  loss_mask: 0.2798  loss_rpn_cls: 0.06146  loss_rpn_loc: 0.1906  time: 0.6264  data_time: 0.1844  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:31:16 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 7959  total_loss: 1.498  loss_cls: 0.3614  loss_box_reg: 0.5025  loss_mask: 0.3025  loss_rpn_cls: 0.08542  loss_rpn_loc: 0.1811  time: 0.6269  data_time: 0.3406  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:31:26 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 7979  total_loss: 1.383  loss_cls: 0.3299  loss_box_reg: 0.5084  loss_mask: 0.2763  loss_rpn_cls: 0.07035  loss_rpn_loc: 0.1729  time: 0.6266  data_time: 0.0747  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:31:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:31:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:31:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:31:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:31:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:31:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0819 s/iter. Eval: 0.0426 s/iter. Total: 0.1252 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 12:31:37 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0807 s/iter. Eval: 0.0573 s/iter. Total: 0.1388 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 12:31:42 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0808 s/iter. Eval: 0.0603 s/iter. Total: 0.1419 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:31:47 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0803 s/iter. Eval: 0.0576 s/iter. Total: 0.1388 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 12:31:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.220876 (0.139835 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:31:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.080433 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:31:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:31:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26643532217952315\n",
      "\u001b[32m[02/04 12:31:58 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 7999  total_loss: 1.453  loss_cls: 0.3429  loss_box_reg: 0.5034  loss_mask: 0.3066  loss_rpn_cls: 0.07544  loss_rpn_loc: 0.2013  time: 0.6267  data_time: 0.2354  lr: 0.00013107  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:32:09 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 8019  total_loss: 1.405  loss_cls: 0.3392  loss_box_reg: 0.4891  loss_mask: 0.2956  loss_rpn_cls: 0.06595  loss_rpn_loc: 0.1769  time: 0.6265  data_time: 0.1391  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:32:24 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 8039  total_loss: 1.408  loss_cls: 0.3528  loss_box_reg: 0.5096  loss_mask: 0.2847  loss_rpn_cls: 0.07539  loss_rpn_loc: 0.1733  time: 0.6269  data_time: 0.3057  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:32:36 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 8059  total_loss: 1.475  loss_cls: 0.3569  loss_box_reg: 0.5268  loss_mask: 0.3072  loss_rpn_cls: 0.06808  loss_rpn_loc: 0.1877  time: 0.6268  data_time: 0.1570  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:32:48 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 8079  total_loss: 1.444  loss_cls: 0.3515  loss_box_reg: 0.4963  loss_mask: 0.3085  loss_rpn_cls: 0.07491  loss_rpn_loc: 0.2091  time: 0.6267  data_time: 0.1719  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:33:00 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 8099  total_loss: 1.495  loss_cls: 0.3517  loss_box_reg: 0.5394  loss_mask: 0.313  loss_rpn_cls: 0.07354  loss_rpn_loc: 0.1903  time: 0.6266  data_time: 0.1644  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:33:12 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 8119  total_loss: 1.303  loss_cls: 0.3119  loss_box_reg: 0.5029  loss_mask: 0.2946  loss_rpn_cls: 0.05792  loss_rpn_loc: 0.1741  time: 0.6266  data_time: 0.1824  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:33:23 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 8139  total_loss: 1.464  loss_cls: 0.3683  loss_box_reg: 0.5425  loss_mask: 0.3118  loss_rpn_cls: 0.05159  loss_rpn_loc: 0.1974  time: 0.6263  data_time: 0.1142  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:33:36 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 8159  total_loss: 1.421  loss_cls: 0.3528  loss_box_reg: 0.5107  loss_mask: 0.2959  loss_rpn_cls: 0.07466  loss_rpn_loc: 0.1804  time: 0.6264  data_time: 0.2254  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:33:48 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 8179  total_loss: 1.361  loss_cls: 0.3371  loss_box_reg: 0.5017  loss_mask: 0.2875  loss_rpn_cls: 0.05603  loss_rpn_loc: 0.1722  time: 0.6264  data_time: 0.2193  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:34:00 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 8199  total_loss: 1.422  loss_cls: 0.3639  loss_box_reg: 0.5169  loss_mask: 0.2955  loss_rpn_cls: 0.07037  loss_rpn_loc: 0.1962  time: 0.6264  data_time: 0.1758  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:34:14 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 8219  total_loss: 1.35  loss_cls: 0.3277  loss_box_reg: 0.4876  loss_mask: 0.2899  loss_rpn_cls: 0.06134  loss_rpn_loc: 0.1816  time: 0.6265  data_time: 0.2401  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:34:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:34:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:34:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:34:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:34:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:34:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0769 s/iter. Eval: 0.0457 s/iter. Total: 0.1234 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 12:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0007 s/iter. Inference: 0.0772 s/iter. Eval: 0.0533 s/iter. Total: 0.1313 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0007 s/iter. Inference: 0.0772 s/iter. Eval: 0.0553 s/iter. Total: 0.1333 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 12:34:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.250324 (0.131468 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:34:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076897 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:34:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:34:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2626570981170038\n",
      "\u001b[32m[02/04 12:34:45 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 8239  total_loss: 1.5  loss_cls: 0.358  loss_box_reg: 0.5028  loss_mask: 0.3061  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.2227  time: 0.6267  data_time: 0.2643  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:34:57 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 8259  total_loss: 1.296  loss_cls: 0.2974  loss_box_reg: 0.4992  loss_mask: 0.2854  loss_rpn_cls: 0.05161  loss_rpn_loc: 0.171  time: 0.6266  data_time: 0.1698  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:35:09 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 8279  total_loss: 1.413  loss_cls: 0.3359  loss_box_reg: 0.4859  loss_mask: 0.3112  loss_rpn_cls: 0.06014  loss_rpn_loc: 0.1985  time: 0.6266  data_time: 0.2113  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:35:22 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 8299  total_loss: 1.402  loss_cls: 0.3515  loss_box_reg: 0.5016  loss_mask: 0.2952  loss_rpn_cls: 0.05128  loss_rpn_loc: 0.1813  time: 0.6266  data_time: 0.2154  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:35:34 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 8319  total_loss: 1.401  loss_cls: 0.3469  loss_box_reg: 0.5221  loss_mask: 0.2913  loss_rpn_cls: 0.074  loss_rpn_loc: 0.1933  time: 0.6266  data_time: 0.1722  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:35:47 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 8339  total_loss: 1.472  loss_cls: 0.348  loss_box_reg: 0.5296  loss_mask: 0.3138  loss_rpn_cls: 0.06921  loss_rpn_loc: 0.19  time: 0.6266  data_time: 0.2080  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:36:00 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 8359  total_loss: 1.377  loss_cls: 0.3347  loss_box_reg: 0.4622  loss_mask: 0.2999  loss_rpn_cls: 0.06117  loss_rpn_loc: 0.1776  time: 0.6267  data_time: 0.2471  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:36:15 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 8379  total_loss: 1.513  loss_cls: 0.3805  loss_box_reg: 0.5391  loss_mask: 0.3131  loss_rpn_cls: 0.09777  loss_rpn_loc: 0.2151  time: 0.6270  data_time: 0.3112  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:36:31 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 8399  total_loss: 1.486  loss_cls: 0.3259  loss_box_reg: 0.5284  loss_mask: 0.308  loss_rpn_cls: 0.06892  loss_rpn_loc: 0.1858  time: 0.6273  data_time: 0.3224  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:36:41 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 8419  total_loss: 1.395  loss_cls: 0.3256  loss_box_reg: 0.512  loss_mask: 0.2835  loss_rpn_cls: 0.05827  loss_rpn_loc: 0.173  time: 0.6271  data_time: 0.1334  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:36:53 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 8439  total_loss: 1.366  loss_cls: 0.3491  loss_box_reg: 0.516  loss_mask: 0.2702  loss_rpn_cls: 0.07705  loss_rpn_loc: 0.1782  time: 0.6270  data_time: 0.1513  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:37:03 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 8459  total_loss: 1.495  loss_cls: 0.3558  loss_box_reg: 0.534  loss_mask: 0.305  loss_rpn_cls: 0.07269  loss_rpn_loc: 0.1903  time: 0.6267  data_time: 0.1005  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:37:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:37:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:37:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:37:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:37:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:37:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0775 s/iter. Eval: 0.0480 s/iter. Total: 0.1263 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 12:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0588 s/iter. Total: 0.1376 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 12:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0783 s/iter. Eval: 0.0618 s/iter. Total: 0.1409 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0778 s/iter. Eval: 0.0593 s/iter. Total: 0.1379 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 12:37:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.073645 (0.138566 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:37:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077812 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:37:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:37:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2659460440404608\n",
      "\u001b[32m[02/04 12:37:35 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 8479  total_loss: 1.445  loss_cls: 0.3546  loss_box_reg: 0.5018  loss_mask: 0.2946  loss_rpn_cls: 0.0915  loss_rpn_loc: 0.1918  time: 0.6268  data_time: 0.2365  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:37:47 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 8499  total_loss: 1.344  loss_cls: 0.3206  loss_box_reg: 0.5101  loss_mask: 0.2836  loss_rpn_cls: 0.06741  loss_rpn_loc: 0.1656  time: 0.6268  data_time: 0.1988  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:38:01 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 8519  total_loss: 1.364  loss_cls: 0.3262  loss_box_reg: 0.4841  loss_mask: 0.2929  loss_rpn_cls: 0.08169  loss_rpn_loc: 0.1862  time: 0.6270  data_time: 0.2590  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:38:15 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 8539  total_loss: 1.494  loss_cls: 0.3754  loss_box_reg: 0.5204  loss_mask: 0.312  loss_rpn_cls: 0.07672  loss_rpn_loc: 0.1842  time: 0.6271  data_time: 0.2493  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:38:28 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 8559  total_loss: 1.46  loss_cls: 0.3384  loss_box_reg: 0.5023  loss_mask: 0.2994  loss_rpn_cls: 0.07431  loss_rpn_loc: 0.197  time: 0.6272  data_time: 0.2295  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:38:40 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 8579  total_loss: 1.51  loss_cls: 0.363  loss_box_reg: 0.5119  loss_mask: 0.307  loss_rpn_cls: 0.08144  loss_rpn_loc: 0.1879  time: 0.6271  data_time: 0.1753  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:38:52 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 8599  total_loss: 1.416  loss_cls: 0.3666  loss_box_reg: 0.5128  loss_mask: 0.2997  loss_rpn_cls: 0.07302  loss_rpn_loc: 0.181  time: 0.6271  data_time: 0.1958  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:39:05 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 8619  total_loss: 1.27  loss_cls: 0.3057  loss_box_reg: 0.4717  loss_mask: 0.2793  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.1776  time: 0.6271  data_time: 0.2093  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:39:16 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 8639  total_loss: 1.435  loss_cls: 0.3428  loss_box_reg: 0.5265  loss_mask: 0.2986  loss_rpn_cls: 0.06956  loss_rpn_loc: 0.1844  time: 0.6270  data_time: 0.1550  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:39:27 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 8659  total_loss: 1.403  loss_cls: 0.3656  loss_box_reg: 0.4914  loss_mask: 0.2905  loss_rpn_cls: 0.05737  loss_rpn_loc: 0.1754  time: 0.6268  data_time: 0.1261  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:39:38 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 8679  total_loss: 1.441  loss_cls: 0.345  loss_box_reg: 0.5176  loss_mask: 0.305  loss_rpn_cls: 0.08043  loss_rpn_loc: 0.1968  time: 0.6267  data_time: 0.1504  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:39:54 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 8699  total_loss: 1.524  loss_cls: 0.3767  loss_box_reg: 0.5327  loss_mask: 0.3108  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.2079  time: 0.6270  data_time: 0.3245  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:40:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:40:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:40:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:40:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:40:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:40:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0779 s/iter. Eval: 0.0488 s/iter. Total: 0.1275 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 12:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 49/121. Dataloading: 0.0008 s/iter. Inference: 0.0773 s/iter. Eval: 0.0550 s/iter. Total: 0.1331 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0008 s/iter. Inference: 0.0774 s/iter. Eval: 0.0567 s/iter. Total: 0.1349 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 12:40:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.446484 (0.133159 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:40:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077088 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:40:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:40:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25844939200084716\n",
      "\u001b[32m[02/04 12:40:21 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 8719  total_loss: 1.332  loss_cls: 0.3306  loss_box_reg: 0.4963  loss_mask: 0.2793  loss_rpn_cls: 0.05964  loss_rpn_loc: 0.1784  time: 0.6267  data_time: 0.0998  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:40:31 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 8739  total_loss: 1.386  loss_cls: 0.3428  loss_box_reg: 0.5089  loss_mask: 0.2868  loss_rpn_cls: 0.05073  loss_rpn_loc: 0.1638  time: 0.6263  data_time: 0.0527  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:40:45 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 8759  total_loss: 1.446  loss_cls: 0.365  loss_box_reg: 0.4947  loss_mask: 0.295  loss_rpn_cls: 0.07635  loss_rpn_loc: 0.1939  time: 0.6266  data_time: 0.2732  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:40:55 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 8779  total_loss: 1.418  loss_cls: 0.3386  loss_box_reg: 0.511  loss_mask: 0.3036  loss_rpn_cls: 0.06124  loss_rpn_loc: 0.1762  time: 0.6263  data_time: 0.0945  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:41:08 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 8799  total_loss: 1.523  loss_cls: 0.3929  loss_box_reg: 0.5324  loss_mask: 0.2914  loss_rpn_cls: 0.0753  loss_rpn_loc: 0.1874  time: 0.6263  data_time: 0.2109  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:41:22 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 8819  total_loss: 1.541  loss_cls: 0.4131  loss_box_reg: 0.5245  loss_mask: 0.2968  loss_rpn_cls: 0.09725  loss_rpn_loc: 0.1978  time: 0.6265  data_time: 0.2569  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:41:33 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 8839  total_loss: 1.43  loss_cls: 0.3102  loss_box_reg: 0.5248  loss_mask: 0.2977  loss_rpn_cls: 0.06661  loss_rpn_loc: 0.1868  time: 0.6263  data_time: 0.1431  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:41:46 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 8859  total_loss: 1.449  loss_cls: 0.3521  loss_box_reg: 0.525  loss_mask: 0.3035  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.201  time: 0.6264  data_time: 0.2312  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:41:59 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 8879  total_loss: 1.469  loss_cls: 0.3428  loss_box_reg: 0.53  loss_mask: 0.3099  loss_rpn_cls: 0.06449  loss_rpn_loc: 0.1956  time: 0.6264  data_time: 0.2123  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:42:13 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 8899  total_loss: 1.392  loss_cls: 0.3589  loss_box_reg: 0.4864  loss_mask: 0.2938  loss_rpn_cls: 0.06671  loss_rpn_loc: 0.1778  time: 0.6266  data_time: 0.2714  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:42:25 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 8919  total_loss: 1.411  loss_cls: 0.3481  loss_box_reg: 0.5096  loss_mask: 0.2977  loss_rpn_cls: 0.07  loss_rpn_loc: 0.2017  time: 0.6266  data_time: 0.1788  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:42:39 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 8939  total_loss: 1.531  loss_cls: 0.3907  loss_box_reg: 0.5357  loss_mask: 0.3058  loss_rpn_cls: 0.07409  loss_rpn_loc: 0.1959  time: 0.6267  data_time: 0.2447  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:42:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:42:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:42:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:42:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:42:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:42:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0778 s/iter. Eval: 0.0493 s/iter. Total: 0.1278 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 12:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0598 s/iter. Total: 0.1386 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 12:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.0783 s/iter. Eval: 0.0617 s/iter. Total: 0.1409 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0778 s/iter. Eval: 0.0589 s/iter. Total: 0.1375 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 12:43:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.007066 (0.137992 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:43:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077777 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:43:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:43:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26683140905028785\n",
      "\u001b[32m[02/04 12:43:09 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 8959  total_loss: 1.404  loss_cls: 0.3292  loss_box_reg: 0.4734  loss_mask: 0.3092  loss_rpn_cls: 0.06873  loss_rpn_loc: 0.1886  time: 0.6266  data_time: 0.1950  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:43:22 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 8979  total_loss: 1.389  loss_cls: 0.3491  loss_box_reg: 0.4884  loss_mask: 0.2902  loss_rpn_cls: 0.04901  loss_rpn_loc: 0.1863  time: 0.6267  data_time: 0.2330  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:43:34 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 8999  total_loss: 1.356  loss_cls: 0.3259  loss_box_reg: 0.5019  loss_mask: 0.2827  loss_rpn_cls: 0.05359  loss_rpn_loc: 0.1697  time: 0.6266  data_time: 0.1858  lr: 0.00010486  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:43:45 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 9019  total_loss: 1.404  loss_cls: 0.3385  loss_box_reg: 0.4957  loss_mask: 0.3009  loss_rpn_cls: 0.06212  loss_rpn_loc: 0.1794  time: 0.6265  data_time: 0.1534  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:44:01 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 9039  total_loss: 1.516  loss_cls: 0.3554  loss_box_reg: 0.506  loss_mask: 0.3268  loss_rpn_cls: 0.093  loss_rpn_loc: 0.2191  time: 0.6269  data_time: 0.3625  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:44:15 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 9059  total_loss: 1.572  loss_cls: 0.381  loss_box_reg: 0.5478  loss_mask: 0.3227  loss_rpn_cls: 0.09334  loss_rpn_loc: 0.2059  time: 0.6270  data_time: 0.2560  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:44:30 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 9079  total_loss: 1.507  loss_cls: 0.363  loss_box_reg: 0.4968  loss_mask: 0.3053  loss_rpn_cls: 0.09655  loss_rpn_loc: 0.22  time: 0.6273  data_time: 0.3089  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:44:42 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 9099  total_loss: 1.306  loss_cls: 0.3217  loss_box_reg: 0.4804  loss_mask: 0.2845  loss_rpn_cls: 0.06028  loss_rpn_loc: 0.1751  time: 0.6272  data_time: 0.1787  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:44:53 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 9119  total_loss: 1.448  loss_cls: 0.3655  loss_box_reg: 0.5179  loss_mask: 0.3028  loss_rpn_cls: 0.06592  loss_rpn_loc: 0.1934  time: 0.6271  data_time: 0.1347  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:45:05 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 9139  total_loss: 1.383  loss_cls: 0.3153  loss_box_reg: 0.5206  loss_mask: 0.2965  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.1655  time: 0.6270  data_time: 0.1647  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:45:16 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 9159  total_loss: 1.407  loss_cls: 0.3478  loss_box_reg: 0.5101  loss_mask: 0.2907  loss_rpn_cls: 0.06361  loss_rpn_loc: 0.1785  time: 0.6268  data_time: 0.1230  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:45:30 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 9179  total_loss: 1.337  loss_cls: 0.3258  loss_box_reg: 0.4967  loss_mask: 0.281  loss_rpn_cls: 0.04843  loss_rpn_loc: 0.174  time: 0.6270  data_time: 0.2795  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:45:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:45:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:45:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:45:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:45:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:45:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:45:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0785 s/iter. Eval: 0.0452 s/iter. Total: 0.1245 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 12:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0780 s/iter. Eval: 0.0581 s/iter. Total: 0.1370 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 12:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0779 s/iter. Eval: 0.0593 s/iter. Total: 0.1380 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:45:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.759389 (0.135857 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:45:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077537 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:45:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:45:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26550460709745005\n",
      "\u001b[32m[02/04 12:45:58 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 9199  total_loss: 1.473  loss_cls: 0.3343  loss_box_reg: 0.525  loss_mask: 0.2896  loss_rpn_cls: 0.06899  loss_rpn_loc: 0.1887  time: 0.6267  data_time: 0.1018  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:46:08 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 9219  total_loss: 1.437  loss_cls: 0.3696  loss_box_reg: 0.4904  loss_mask: 0.3154  loss_rpn_cls: 0.0604  loss_rpn_loc: 0.1725  time: 0.6265  data_time: 0.1101  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:46:19 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 9239  total_loss: 1.374  loss_cls: 0.3193  loss_box_reg: 0.5072  loss_mask: 0.2884  loss_rpn_cls: 0.05922  loss_rpn_loc: 0.1745  time: 0.6263  data_time: 0.1199  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:46:29 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 9259  total_loss: 1.32  loss_cls: 0.3197  loss_box_reg: 0.4894  loss_mask: 0.2882  loss_rpn_cls: 0.03871  loss_rpn_loc: 0.1722  time: 0.6261  data_time: 0.1086  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:46:42 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 9279  total_loss: 1.389  loss_cls: 0.335  loss_box_reg: 0.5079  loss_mask: 0.2999  loss_rpn_cls: 0.05237  loss_rpn_loc: 0.1822  time: 0.6261  data_time: 0.2579  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:46:55 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 9299  total_loss: 1.43  loss_cls: 0.3645  loss_box_reg: 0.512  loss_mask: 0.2973  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.1779  time: 0.6262  data_time: 0.2005  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:47:08 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 9319  total_loss: 1.49  loss_cls: 0.3617  loss_box_reg: 0.5175  loss_mask: 0.2905  loss_rpn_cls: 0.07144  loss_rpn_loc: 0.1847  time: 0.6261  data_time: 0.1984  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:47:20 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 9339  total_loss: 1.527  loss_cls: 0.3749  loss_box_reg: 0.5226  loss_mask: 0.3158  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.1965  time: 0.6261  data_time: 0.1974  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:47:33 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 9359  total_loss: 1.479  loss_cls: 0.3561  loss_box_reg: 0.5028  loss_mask: 0.2942  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.1928  time: 0.6262  data_time: 0.2070  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:47:47 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 9379  total_loss: 1.364  loss_cls: 0.3198  loss_box_reg: 0.5009  loss_mask: 0.2937  loss_rpn_cls: 0.05929  loss_rpn_loc: 0.1956  time: 0.6263  data_time: 0.2614  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:48:00 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 9399  total_loss: 1.403  loss_cls: 0.3478  loss_box_reg: 0.4981  loss_mask: 0.2991  loss_rpn_cls: 0.09231  loss_rpn_loc: 0.1916  time: 0.6264  data_time: 0.2310  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:48:12 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9419  total_loss: 1.387  loss_cls: 0.3415  loss_box_reg: 0.5021  loss_mask: 0.287  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.1728  time: 0.6264  data_time: 0.1895  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:48:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:48:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:48:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:48:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:48:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:48:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0786 s/iter. Eval: 0.0497 s/iter. Total: 0.1291 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 12:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.0783 s/iter. Eval: 0.0588 s/iter. Total: 0.1380 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 12:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.0782 s/iter. Eval: 0.0603 s/iter. Total: 0.1393 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0778 s/iter. Eval: 0.0582 s/iter. Total: 0.1368 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 12:48:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.940472 (0.137418 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:48:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077832 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:48:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:48:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2673708530737044\n",
      "\u001b[32m[02/04 12:48:42 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 9439  total_loss: 1.384  loss_cls: 0.335  loss_box_reg: 0.5024  loss_mask: 0.2923  loss_rpn_cls: 0.05425  loss_rpn_loc: 0.1719  time: 0.6264  data_time: 0.1975  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:48:56 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 9459  total_loss: 1.471  loss_cls: 0.3798  loss_box_reg: 0.5249  loss_mask: 0.315  loss_rpn_cls: 0.07799  loss_rpn_loc: 0.2036  time: 0.6264  data_time: 0.2306  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:49:09 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 9479  total_loss: 1.528  loss_cls: 0.3576  loss_box_reg: 0.5222  loss_mask: 0.3093  loss_rpn_cls: 0.07856  loss_rpn_loc: 0.1833  time: 0.6266  data_time: 0.2544  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:49:23 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 9499  total_loss: 1.476  loss_cls: 0.3504  loss_box_reg: 0.5263  loss_mask: 0.3069  loss_rpn_cls: 0.09204  loss_rpn_loc: 0.1987  time: 0.6267  data_time: 0.2555  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:49:33 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 9519  total_loss: 1.403  loss_cls: 0.3454  loss_box_reg: 0.5223  loss_mask: 0.2804  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.1809  time: 0.6265  data_time: 0.1225  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:49:45 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 9539  total_loss: 1.474  loss_cls: 0.3609  loss_box_reg: 0.5131  loss_mask: 0.303  loss_rpn_cls: 0.08802  loss_rpn_loc: 0.1878  time: 0.6264  data_time: 0.1911  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:50:01 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9559  total_loss: 1.47  loss_cls: 0.3668  loss_box_reg: 0.4945  loss_mask: 0.2954  loss_rpn_cls: 0.08698  loss_rpn_loc: 0.2011  time: 0.6267  data_time: 0.3537  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:50:13 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 9579  total_loss: 1.366  loss_cls: 0.3401  loss_box_reg: 0.4992  loss_mask: 0.2829  loss_rpn_cls: 0.06174  loss_rpn_loc: 0.173  time: 0.6266  data_time: 0.1529  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:50:23 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 9599  total_loss: 1.254  loss_cls: 0.2943  loss_box_reg: 0.4878  loss_mask: 0.2835  loss_rpn_cls: 0.04597  loss_rpn_loc: 0.1594  time: 0.6264  data_time: 0.1170  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:50:34 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 9619  total_loss: 1.343  loss_cls: 0.3235  loss_box_reg: 0.4818  loss_mask: 0.3052  loss_rpn_cls: 0.05264  loss_rpn_loc: 0.1779  time: 0.6263  data_time: 0.1470  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:50:50 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 9639  total_loss: 1.433  loss_cls: 0.3456  loss_box_reg: 0.5127  loss_mask: 0.3106  loss_rpn_cls: 0.07653  loss_rpn_loc: 0.1909  time: 0.6266  data_time: 0.3431  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:51:05 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 9659  total_loss: 1.478  loss_cls: 0.3572  loss_box_reg: 0.4969  loss_mask: 0.3059  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.2035  time: 0.6268  data_time: 0.2890  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:51:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:51:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:51:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:51:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:51:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:51:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0781 s/iter. Eval: 0.0492 s/iter. Total: 0.1280 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 12:51:24 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0012 s/iter. Inference: 0.0784 s/iter. Eval: 0.0613 s/iter. Total: 0.1410 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 12:51:29 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0010 s/iter. Inference: 0.0784 s/iter. Eval: 0.0624 s/iter. Total: 0.1418 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:51:34 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0009 s/iter. Inference: 0.0779 s/iter. Eval: 0.0597 s/iter. Total: 0.1386 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 12:51:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.127654 (0.139031 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:51:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077935 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:51:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:51:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.267427550391284\n",
      "\u001b[32m[02/04 12:51:34 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 9679  total_loss: 1.518  loss_cls: 0.3727  loss_box_reg: 0.5245  loss_mask: 0.3107  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.2044  time: 0.6267  data_time: 0.1567  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:51:46 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 9699  total_loss: 1.448  loss_cls: 0.3516  loss_box_reg: 0.4986  loss_mask: 0.2999  loss_rpn_cls: 0.0634  loss_rpn_loc: 0.1908  time: 0.6267  data_time: 0.1728  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:51:58 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 9719  total_loss: 1.383  loss_cls: 0.3299  loss_box_reg: 0.4935  loss_mask: 0.2872  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.1752  time: 0.6266  data_time: 0.1782  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:52:12 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 9739  total_loss: 1.398  loss_cls: 0.3392  loss_box_reg: 0.4767  loss_mask: 0.2915  loss_rpn_cls: 0.09275  loss_rpn_loc: 0.1922  time: 0.6268  data_time: 0.2706  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:52:26 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 9759  total_loss: 1.405  loss_cls: 0.3503  loss_box_reg: 0.4955  loss_mask: 0.2947  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.1857  time: 0.6269  data_time: 0.2580  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:52:36 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 9779  total_loss: 1.319  loss_cls: 0.3194  loss_box_reg: 0.4887  loss_mask: 0.2908  loss_rpn_cls: 0.06006  loss_rpn_loc: 0.1763  time: 0.6266  data_time: 0.0937  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:52:50 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 9799  total_loss: 1.451  loss_cls: 0.348  loss_box_reg: 0.5267  loss_mask: 0.3195  loss_rpn_cls: 0.08179  loss_rpn_loc: 0.1979  time: 0.6267  data_time: 0.2573  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:53:01 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 9819  total_loss: 1.499  loss_cls: 0.3684  loss_box_reg: 0.5228  loss_mask: 0.3104  loss_rpn_cls: 0.06446  loss_rpn_loc: 0.1955  time: 0.6267  data_time: 0.1630  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:53:14 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 9839  total_loss: 1.401  loss_cls: 0.3459  loss_box_reg: 0.5031  loss_mask: 0.293  loss_rpn_cls: 0.06322  loss_rpn_loc: 0.1866  time: 0.6267  data_time: 0.2216  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:53:26 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 9859  total_loss: 1.378  loss_cls: 0.3677  loss_box_reg: 0.5086  loss_mask: 0.2858  loss_rpn_cls: 0.05107  loss_rpn_loc: 0.1948  time: 0.6266  data_time: 0.1694  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:53:40 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 9879  total_loss: 1.38  loss_cls: 0.3397  loss_box_reg: 0.5291  loss_mask: 0.2991  loss_rpn_cls: 0.05647  loss_rpn_loc: 0.1766  time: 0.6268  data_time: 0.2593  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:53:53 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 9899  total_loss: 1.431  loss_cls: 0.3438  loss_box_reg: 0.5025  loss_mask: 0.3026  loss_rpn_cls: 0.08428  loss_rpn_loc: 0.1937  time: 0.6269  data_time: 0.2428  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:54:05 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 9919  total_loss: 1.395  loss_cls: 0.3471  loss_box_reg: 0.499  loss_mask: 0.305  loss_rpn_cls: 0.06812  loss_rpn_loc: 0.1765  time: 0.6267  data_time: 0.1632  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:54:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:54:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:54:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:54:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:54:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:54:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:54:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0034 s/iter. Inference: 0.0778 s/iter. Eval: 0.0445 s/iter. Total: 0.1256 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 12:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0011 s/iter. Inference: 0.0779 s/iter. Eval: 0.0562 s/iter. Total: 0.1352 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 12:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0010 s/iter. Inference: 0.0779 s/iter. Eval: 0.0584 s/iter. Total: 0.1373 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 12:54:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.605051 (0.134526 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:54:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.077540 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:54:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:54:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26349702216731197\n",
      "\u001b[32m[02/04 12:54:33 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 9939  total_loss: 1.459  loss_cls: 0.3507  loss_box_reg: 0.5053  loss_mask: 0.3071  loss_rpn_cls: 0.07601  loss_rpn_loc: 0.1875  time: 0.6266  data_time: 0.1447  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:54:47 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 9959  total_loss: 1.491  loss_cls: 0.3567  loss_box_reg: 0.514  loss_mask: 0.3103  loss_rpn_cls: 0.08083  loss_rpn_loc: 0.2128  time: 0.6267  data_time: 0.2244  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:54:59 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 9979  total_loss: 1.531  loss_cls: 0.3524  loss_box_reg: 0.5116  loss_mask: 0.3001  loss_rpn_cls: 0.06889  loss_rpn_loc: 0.1817  time: 0.6267  data_time: 0.1894  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:55:12 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.318  loss_cls: 0.3371  loss_box_reg: 0.486  loss_mask: 0.2759  loss_rpn_cls: 0.04508  loss_rpn_loc: 0.157  time: 0.6266  data_time: 0.1968  lr: 8.3886e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 12:55:12 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:44:25 (0.6267 s / it)\n",
      "\u001b[32m[02/04 12:55:12 d2.engine.hooks]: \u001b[0mTotal training time: 1:55:55 (0:11:29 on hooks)\n",
      "\u001b[32m[02/04 12:55:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:55:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 12:55:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 12:55:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 12:55:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 12:55:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 12:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0782 s/iter. Eval: 0.0488 s/iter. Total: 0.1278 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 12:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0010 s/iter. Inference: 0.0788 s/iter. Eval: 0.0653 s/iter. Total: 0.1452 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 12:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0009 s/iter. Inference: 0.0784 s/iter. Eval: 0.0636 s/iter. Total: 0.1429 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 12:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0009 s/iter. Inference: 0.0778 s/iter. Eval: 0.0602 s/iter. Total: 0.1390 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 12:55:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.233533 (0.139944 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:55:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.077917 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 12:55:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 12:55:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2653801700653902\n"
     ]
    }
   ],
   "source": [
    "# Increasing the number of top scoring RPN proposals to keep only before applying NMS\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ec849b1-ed38-4635-a1a4-e08b739862e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.96482685978931"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean pixel values in the training dataset\n",
    "from PIL import Image\n",
    "_, _, filenames = next(os.walk(\"../train/\"), (None, None, []))\n",
    "s=0.\n",
    "for filename in filenames:\n",
    "    imtest = Image.open(f'../train/{filename}')\n",
    "    imtest = np.asarray(imtest)\n",
    "    s+=np.mean(imtest)\n",
    "s/len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c5da9b-c186-4d3d-bbfe-2debffebfdf3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 13:49:58 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 13:49:59 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 13:50:00 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/04 13:50:00 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 13:50:01 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/04 13:50:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/04 13:50:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/04 13:50:01 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 13:50:01 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 13:50:01 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 13:50:13 d2.utils.events]: \u001b[0m eta: 1:16:43  iter: 19  total_loss: 3.2  loss_cls: 1.368  loss_box_reg: 0.4795  loss_mask: 0.6948  loss_rpn_cls: 0.3864  loss_rpn_loc: 0.2618  time: 0.6026  data_time: 0.1502  lr: 9.9905e-06  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:50:25 d2.utils.events]: \u001b[0m eta: 1:17:49  iter: 39  total_loss: 3.111  loss_cls: 1.296  loss_box_reg: 0.5804  loss_mask: 0.6872  loss_rpn_cls: 0.3017  loss_rpn_loc: 0.2378  time: 0.6167  data_time: 0.1657  lr: 1.998e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:50:36 d2.utils.events]: \u001b[0m eta: 1:17:01  iter: 59  total_loss: 2.9  loss_cls: 1.121  loss_box_reg: 0.6241  loss_mask: 0.6702  loss_rpn_cls: 0.2519  loss_rpn_loc: 0.2299  time: 0.5797  data_time: 0.0699  lr: 2.997e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:50:49 d2.utils.events]: \u001b[0m eta: 1:17:19  iter: 79  total_loss: 2.726  loss_cls: 0.9239  loss_box_reg: 0.6438  loss_mask: 0.6529  loss_rpn_cls: 0.232  loss_rpn_loc: 0.2218  time: 0.6061  data_time: 0.2224  lr: 3.9961e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:51:01 d2.utils.events]: \u001b[0m eta: 1:18:37  iter: 99  total_loss: 2.641  loss_cls: 0.7833  loss_box_reg: 0.7463  loss_mask: 0.6125  loss_rpn_cls: 0.2203  loss_rpn_loc: 0.2544  time: 0.5987  data_time: 0.0960  lr: 4.9951e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:51:17 d2.utils.events]: \u001b[0m eta: 1:18:36  iter: 119  total_loss: 2.556  loss_cls: 0.7675  loss_box_reg: 0.7237  loss_mask: 0.6036  loss_rpn_cls: 0.2275  loss_rpn_loc: 0.2569  time: 0.6393  data_time: 0.3666  lr: 5.9941e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:51:35 d2.utils.events]: \u001b[0m eta: 1:19:19  iter: 139  total_loss: 2.442  loss_cls: 0.7163  loss_box_reg: 0.7342  loss_mask: 0.5786  loss_rpn_cls: 0.1724  loss_rpn_loc: 0.2372  time: 0.6752  data_time: 0.3968  lr: 6.993e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:51:51 d2.utils.events]: \u001b[0m eta: 1:19:44  iter: 159  total_loss: 2.375  loss_cls: 0.7069  loss_box_reg: 0.7643  loss_mask: 0.5343  loss_rpn_cls: 0.1457  loss_rpn_loc: 0.2264  time: 0.6888  data_time: 0.2878  lr: 7.9921e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:52:04 d2.utils.events]: \u001b[0m eta: 1:19:53  iter: 179  total_loss: 2.309  loss_cls: 0.6759  loss_box_reg: 0.7645  loss_mask: 0.4996  loss_rpn_cls: 0.1405  loss_rpn_loc: 0.2147  time: 0.6865  data_time: 0.1912  lr: 8.991e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:52:23 d2.utils.events]: \u001b[0m eta: 1:20:01  iter: 199  total_loss: 2.27  loss_cls: 0.6567  loss_box_reg: 0.7182  loss_mask: 0.4966  loss_rpn_cls: 0.1596  loss_rpn_loc: 0.2388  time: 0.7099  data_time: 0.4336  lr: 9.9901e-05  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:52:35 d2.utils.events]: \u001b[0m eta: 1:20:02  iter: 219  total_loss: 2.192  loss_cls: 0.6096  loss_box_reg: 0.7681  loss_mask: 0.4565  loss_rpn_cls: 0.1365  loss_rpn_loc: 0.2434  time: 0.7018  data_time: 0.1377  lr: 0.00010989  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:52:46 d2.utils.events]: \u001b[0m eta: 1:19:37  iter: 239  total_loss: 2.084  loss_cls: 0.5211  loss_box_reg: 0.7613  loss_mask: 0.4151  loss_rpn_cls: 0.1369  loss_rpn_loc: 0.2247  time: 0.6884  data_time: 0.0878  lr: 0.00011988  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:52:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 13:52:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 13:52:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 13:52:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 13:52:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 13:52:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 13:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0760 s/iter. Eval: 0.0091 s/iter. Total: 0.0856 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 13:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0007 s/iter. Inference: 0.0767 s/iter. Eval: 0.0110 s/iter. Total: 0.0885 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 13:52:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.041724 (0.086567 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 13:52:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076144 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 13:52:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 13:52:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.08001589686752118\n",
      "\u001b[32m[02/04 13:53:09 d2.utils.events]: \u001b[0m eta: 1:19:27  iter: 259  total_loss: 1.999  loss_cls: 0.4943  loss_box_reg: 0.7487  loss_mask: 0.399  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.2317  time: 0.6824  data_time: 0.1503  lr: 0.00012987  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:53:21 d2.utils.events]: \u001b[0m eta: 1:19:06  iter: 279  total_loss: 1.949  loss_cls: 0.5014  loss_box_reg: 0.7261  loss_mask: 0.3605  loss_rpn_cls: 0.09426  loss_rpn_loc: 0.1993  time: 0.6746  data_time: 0.1254  lr: 0.00013986  max_mem: 6670M\n",
      "\u001b[32m[02/04 13:53:35 d2.utils.events]: \u001b[0m eta: 1:18:58  iter: 299  total_loss: 1.946  loss_cls: 0.4775  loss_box_reg: 0.7131  loss_mask: 0.3616  loss_rpn_cls: 0.1385  loss_rpn_loc: 0.2305  time: 0.6780  data_time: 0.2527  lr: 0.00014985  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:53:46 d2.utils.events]: \u001b[0m eta: 1:18:51  iter: 319  total_loss: 1.836  loss_cls: 0.4235  loss_box_reg: 0.7059  loss_mask: 0.329  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2187  time: 0.6696  data_time: 0.0903  lr: 0.00015984  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:54:00 d2.utils.events]: \u001b[0m eta: 1:18:41  iter: 339  total_loss: 1.658  loss_cls: 0.3859  loss_box_reg: 0.6559  loss_mask: 0.3058  loss_rpn_cls: 0.09444  loss_rpn_loc: 0.1962  time: 0.6693  data_time: 0.1840  lr: 0.00016983  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:54:13 d2.utils.events]: \u001b[0m eta: 1:18:29  iter: 359  total_loss: 1.844  loss_cls: 0.4085  loss_box_reg: 0.6944  loss_mask: 0.3136  loss_rpn_cls: 0.1472  loss_rpn_loc: 0.2061  time: 0.6708  data_time: 0.2099  lr: 0.00017982  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:54:29 d2.utils.events]: \u001b[0m eta: 1:18:19  iter: 379  total_loss: 1.818  loss_cls: 0.404  loss_box_reg: 0.6637  loss_mask: 0.3409  loss_rpn_cls: 0.144  loss_rpn_loc: 0.2135  time: 0.6758  data_time: 0.2864  lr: 0.00018981  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:54:44 d2.utils.events]: \u001b[0m eta: 1:18:15  iter: 399  total_loss: 1.783  loss_cls: 0.3895  loss_box_reg: 0.6943  loss_mask: 0.3418  loss_rpn_cls: 0.1308  loss_rpn_loc: 0.2455  time: 0.6805  data_time: 0.2793  lr: 0.0001998  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:54:56 d2.utils.events]: \u001b[0m eta: 1:18:09  iter: 419  total_loss: 1.635  loss_cls: 0.3702  loss_box_reg: 0.6672  loss_mask: 0.3161  loss_rpn_cls: 0.1213  loss_rpn_loc: 0.2198  time: 0.6770  data_time: 0.1140  lr: 0.00020979  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:55:10 d2.utils.events]: \u001b[0m eta: 1:17:48  iter: 439  total_loss: 1.762  loss_cls: 0.3704  loss_box_reg: 0.6721  loss_mask: 0.3349  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.2427  time: 0.6770  data_time: 0.2163  lr: 0.00021978  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:55:23 d2.utils.events]: \u001b[0m eta: 1:17:40  iter: 459  total_loss: 1.77  loss_cls: 0.4046  loss_box_reg: 0.6519  loss_mask: 0.3221  loss_rpn_cls: 0.1433  loss_rpn_loc: 0.2339  time: 0.6750  data_time: 0.1571  lr: 0.00022977  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:55:36 d2.utils.events]: \u001b[0m eta: 1:17:33  iter: 479  total_loss: 1.753  loss_cls: 0.4146  loss_box_reg: 0.6406  loss_mask: 0.3189  loss_rpn_cls: 0.1245  loss_rpn_loc: 0.2168  time: 0.6751  data_time: 0.1897  lr: 0.00023976  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:55:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 13:55:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 13:55:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 13:55:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 13:55:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 13:55:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 13:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0820 s/iter. Eval: 0.0428 s/iter. Total: 0.1255 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 13:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0625 s/iter. Total: 0.1475 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 13:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0647 s/iter. Total: 0.1522 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 13:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0644 s/iter. Total: 0.1520 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 13:55:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.610928 (0.151818 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 13:55:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087006 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 13:55:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 13:55:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21476369924666308\n",
      "\u001b[32m[02/04 13:56:07 d2.utils.events]: \u001b[0m eta: 1:17:30  iter: 499  total_loss: 1.672  loss_cls: 0.3752  loss_box_reg: 0.6589  loss_mask: 0.314  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.2154  time: 0.6715  data_time: 0.0996  lr: 0.00024975  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:56:19 d2.utils.events]: \u001b[0m eta: 1:17:16  iter: 519  total_loss: 1.58  loss_cls: 0.3569  loss_box_reg: 0.6175  loss_mask: 0.3133  loss_rpn_cls: 0.08962  loss_rpn_loc: 0.2005  time: 0.6696  data_time: 0.1257  lr: 0.00025974  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:56:34 d2.utils.events]: \u001b[0m eta: 1:17:15  iter: 539  total_loss: 1.688  loss_cls: 0.3845  loss_box_reg: 0.6623  loss_mask: 0.3154  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.2105  time: 0.6724  data_time: 0.2557  lr: 0.00026973  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:56:46 d2.utils.events]: \u001b[0m eta: 1:17:05  iter: 559  total_loss: 1.724  loss_cls: 0.3948  loss_box_reg: 0.6646  loss_mask: 0.3358  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.2291  time: 0.6697  data_time: 0.1241  lr: 0.00027972  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:57:03 d2.utils.events]: \u001b[0m eta: 1:16:58  iter: 579  total_loss: 1.672  loss_cls: 0.3606  loss_box_reg: 0.6347  loss_mask: 0.3265  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.2317  time: 0.6750  data_time: 0.3549  lr: 0.00028971  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:57:20 d2.utils.events]: \u001b[0m eta: 1:16:47  iter: 599  total_loss: 1.62  loss_cls: 0.3534  loss_box_reg: 0.6025  loss_mask: 0.3176  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.209  time: 0.6810  data_time: 0.3788  lr: 0.0002997  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:57:33 d2.utils.events]: \u001b[0m eta: 1:16:36  iter: 619  total_loss: 1.639  loss_cls: 0.3646  loss_box_reg: 0.6146  loss_mask: 0.3066  loss_rpn_cls: 0.09077  loss_rpn_loc: 0.2072  time: 0.6796  data_time: 0.1696  lr: 0.00030969  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:57:44 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 639  total_loss: 1.596  loss_cls: 0.3742  loss_box_reg: 0.6211  loss_mask: 0.3111  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2043  time: 0.6756  data_time: 0.0944  lr: 0.00031968  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:57:59 d2.utils.events]: \u001b[0m eta: 1:16:08  iter: 659  total_loss: 1.757  loss_cls: 0.3933  loss_box_reg: 0.644  loss_mask: 0.3319  loss_rpn_cls: 0.132  loss_rpn_loc: 0.2286  time: 0.6781  data_time: 0.2892  lr: 0.00032967  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:58:12 d2.utils.events]: \u001b[0m eta: 1:15:58  iter: 679  total_loss: 1.601  loss_cls: 0.3557  loss_box_reg: 0.6209  loss_mask: 0.3127  loss_rpn_cls: 0.104  loss_rpn_loc: 0.1969  time: 0.6774  data_time: 0.1990  lr: 0.00033966  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:58:23 d2.utils.events]: \u001b[0m eta: 1:15:41  iter: 699  total_loss: 1.542  loss_cls: 0.3375  loss_box_reg: 0.6072  loss_mask: 0.3205  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.2131  time: 0.6736  data_time: 0.1165  lr: 0.00034965  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:58:35 d2.utils.events]: \u001b[0m eta: 1:15:29  iter: 719  total_loss: 1.642  loss_cls: 0.3715  loss_box_reg: 0.6084  loss_mask: 0.3125  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.2028  time: 0.6713  data_time: 0.1294  lr: 0.00035964  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:58:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 13:58:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 13:58:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 13:58:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 13:58:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 13:58:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 13:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0813 s/iter. Eval: 0.0449 s/iter. Total: 0.1268 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 13:58:47 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0845 s/iter. Eval: 0.0628 s/iter. Total: 0.1481 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 13:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0841 s/iter. Eval: 0.0655 s/iter. Total: 0.1504 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 13:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0007 s/iter. Inference: 0.0839 s/iter. Eval: 0.0641 s/iter. Total: 0.1488 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 13:58:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.266756 (0.148851 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 13:58:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083881 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 13:58:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 13:58:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21240330738417268\n",
      "\u001b[32m[02/04 13:59:06 d2.utils.events]: \u001b[0m eta: 1:15:16  iter: 739  total_loss: 1.562  loss_cls: 0.3292  loss_box_reg: 0.6282  loss_mask: 0.3108  loss_rpn_cls: 0.09451  loss_rpn_loc: 0.2168  time: 0.6703  data_time: 0.1812  lr: 0.00036963  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:59:21 d2.utils.events]: \u001b[0m eta: 1:15:10  iter: 759  total_loss: 1.696  loss_cls: 0.3929  loss_box_reg: 0.6052  loss_mask: 0.3341  loss_rpn_cls: 0.133  loss_rpn_loc: 0.226  time: 0.6726  data_time: 0.2831  lr: 0.00037962  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:59:35 d2.utils.events]: \u001b[0m eta: 1:15:03  iter: 779  total_loss: 1.656  loss_cls: 0.365  loss_box_reg: 0.5978  loss_mask: 0.3214  loss_rpn_cls: 0.1198  loss_rpn_loc: 0.2406  time: 0.6725  data_time: 0.2063  lr: 0.00038961  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:59:47 d2.utils.events]: \u001b[0m eta: 1:14:47  iter: 799  total_loss: 1.463  loss_cls: 0.3127  loss_box_reg: 0.5786  loss_mask: 0.2927  loss_rpn_cls: 0.08653  loss_rpn_loc: 0.2006  time: 0.6712  data_time: 0.1744  lr: 0.0003996  max_mem: 6722M\n",
      "\u001b[32m[02/04 13:59:57 d2.utils.events]: \u001b[0m eta: 1:14:29  iter: 819  total_loss: 1.609  loss_cls: 0.3486  loss_box_reg: 0.6238  loss_mask: 0.3088  loss_rpn_cls: 0.09443  loss_rpn_loc: 0.218  time: 0.6673  data_time: 0.0708  lr: 0.00040959  max_mem: 6722M\n",
      "\u001b[32m[02/04 14:00:12 d2.utils.events]: \u001b[0m eta: 1:14:21  iter: 839  total_loss: 1.532  loss_cls: 0.348  loss_box_reg: 0.5596  loss_mask: 0.2975  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.1892  time: 0.6684  data_time: 0.2406  lr: 0.00041958  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:00:25 d2.utils.events]: \u001b[0m eta: 1:14:11  iter: 859  total_loss: 1.693  loss_cls: 0.3526  loss_box_reg: 0.6181  loss_mask: 0.3168  loss_rpn_cls: 0.1281  loss_rpn_loc: 0.2075  time: 0.6685  data_time: 0.2135  lr: 0.00042957  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:00:39 d2.utils.events]: \u001b[0m eta: 1:13:56  iter: 879  total_loss: 1.559  loss_cls: 0.3349  loss_box_reg: 0.5836  loss_mask: 0.3133  loss_rpn_cls: 0.08914  loss_rpn_loc: 0.2057  time: 0.6691  data_time: 0.2377  lr: 0.00043956  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:00:51 d2.utils.events]: \u001b[0m eta: 1:13:42  iter: 899  total_loss: 1.642  loss_cls: 0.3707  loss_box_reg: 0.6329  loss_mask: 0.3117  loss_rpn_cls: 0.14  loss_rpn_loc: 0.2257  time: 0.6678  data_time: 0.1625  lr: 0.00044955  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:01:02 d2.utils.events]: \u001b[0m eta: 1:13:30  iter: 919  total_loss: 1.558  loss_cls: 0.3457  loss_box_reg: 0.5864  loss_mask: 0.3003  loss_rpn_cls: 0.09209  loss_rpn_loc: 0.2066  time: 0.6652  data_time: 0.1015  lr: 0.00045954  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:01:14 d2.utils.events]: \u001b[0m eta: 1:13:16  iter: 939  total_loss: 1.518  loss_cls: 0.3457  loss_box_reg: 0.5865  loss_mask: 0.3199  loss_rpn_cls: 0.07959  loss_rpn_loc: 0.2009  time: 0.6631  data_time: 0.1166  lr: 0.00046953  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:01:28 d2.utils.events]: \u001b[0m eta: 1:13:02  iter: 959  total_loss: 1.847  loss_cls: 0.4768  loss_box_reg: 0.6422  loss_mask: 0.3362  loss_rpn_cls: 0.119  loss_rpn_loc: 0.2247  time: 0.6639  data_time: 0.2351  lr: 0.00047952  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:01:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:01:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:01:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:01:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:01:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:01:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:01:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0472 s/iter. Total: 0.1285 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:01:42 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.0846 s/iter. Eval: 0.0639 s/iter. Total: 0.1494 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0664 s/iter. Total: 0.1518 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0008 s/iter. Inference: 0.0849 s/iter. Eval: 0.0676 s/iter. Total: 0.1534 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:01:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.712914 (0.152698 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:01:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084974 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:01:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:01:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23100208234476413\n",
      "\u001b[32m[02/04 14:02:01 d2.utils.events]: \u001b[0m eta: 1:12:53  iter: 979  total_loss: 1.587  loss_cls: 0.364  loss_box_reg: 0.6072  loss_mask: 0.3102  loss_rpn_cls: 0.08355  loss_rpn_loc: 0.2091  time: 0.6649  data_time: 0.2448  lr: 0.00048951  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:02:13 d2.utils.events]: \u001b[0m eta: 1:12:40  iter: 999  total_loss: 1.419  loss_cls: 0.2716  loss_box_reg: 0.5567  loss_mask: 0.3154  loss_rpn_cls: 0.07185  loss_rpn_loc: 0.1934  time: 0.6637  data_time: 0.1338  lr: 0.0004995  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:02:28 d2.utils.events]: \u001b[0m eta: 1:12:35  iter: 1019  total_loss: 1.524  loss_cls: 0.337  loss_box_reg: 0.6047  loss_mask: 0.3123  loss_rpn_cls: 0.101  loss_rpn_loc: 0.1995  time: 0.6650  data_time: 0.2579  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:02:42 d2.utils.events]: \u001b[0m eta: 1:12:28  iter: 1039  total_loss: 1.527  loss_cls: 0.3541  loss_box_reg: 0.592  loss_mask: 0.2845  loss_rpn_cls: 0.09327  loss_rpn_loc: 0.194  time: 0.6655  data_time: 0.2192  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:02:53 d2.utils.events]: \u001b[0m eta: 1:12:24  iter: 1059  total_loss: 1.628  loss_cls: 0.3804  loss_box_reg: 0.6183  loss_mask: 0.3208  loss_rpn_cls: 0.134  loss_rpn_loc: 0.2133  time: 0.6634  data_time: 0.0751  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:03:05 d2.utils.events]: \u001b[0m eta: 1:12:18  iter: 1079  total_loss: 1.565  loss_cls: 0.3319  loss_box_reg: 0.6076  loss_mask: 0.3224  loss_rpn_cls: 0.09536  loss_rpn_loc: 0.2104  time: 0.6629  data_time: 0.1525  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:03:22 d2.utils.events]: \u001b[0m eta: 1:12:11  iter: 1099  total_loss: 1.601  loss_cls: 0.3787  loss_box_reg: 0.5942  loss_mask: 0.3068  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.2203  time: 0.6662  data_time: 0.3598  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:03:37 d2.utils.events]: \u001b[0m eta: 1:12:01  iter: 1119  total_loss: 1.52  loss_cls: 0.3502  loss_box_reg: 0.5837  loss_mask: 0.3095  loss_rpn_cls: 0.09918  loss_rpn_loc: 0.1939  time: 0.6670  data_time: 0.2462  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:03:49 d2.utils.events]: \u001b[0m eta: 1:11:44  iter: 1139  total_loss: 1.576  loss_cls: 0.3465  loss_box_reg: 0.5996  loss_mask: 0.3127  loss_rpn_cls: 0.08339  loss_rpn_loc: 0.2045  time: 0.6662  data_time: 0.1457  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:04:02 d2.utils.events]: \u001b[0m eta: 1:11:27  iter: 1159  total_loss: 1.536  loss_cls: 0.3466  loss_box_reg: 0.5971  loss_mask: 0.3075  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.2068  time: 0.6662  data_time: 0.2013  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:04:16 d2.utils.events]: \u001b[0m eta: 1:11:10  iter: 1179  total_loss: 1.552  loss_cls: 0.335  loss_box_reg: 0.6077  loss_mask: 0.3225  loss_rpn_cls: 0.08638  loss_rpn_loc: 0.2085  time: 0.6669  data_time: 0.2503  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:04:29 d2.utils.events]: \u001b[0m eta: 1:10:57  iter: 1199  total_loss: 1.617  loss_cls: 0.3647  loss_box_reg: 0.6019  loss_mask: 0.3057  loss_rpn_cls: 0.09923  loss_rpn_loc: 0.1983  time: 0.6664  data_time: 0.1727  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:04:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:04:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:04:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:04:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:04:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:04:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0790 s/iter. Eval: 0.0341 s/iter. Total: 0.1137 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 14:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0007 s/iter. Inference: 0.0814 s/iter. Eval: 0.0541 s/iter. Total: 0.1363 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 14:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0007 s/iter. Inference: 0.0819 s/iter. Eval: 0.0579 s/iter. Total: 0.1406 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 14:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0007 s/iter. Inference: 0.0816 s/iter. Eval: 0.0557 s/iter. Total: 0.1380 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 14:04:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.057492 (0.138427 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:04:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.081571 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:04:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:04:53 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24592430932856266\n",
      "\u001b[32m[02/04 14:05:01 d2.utils.events]: \u001b[0m eta: 1:10:45  iter: 1219  total_loss: 1.502  loss_cls: 0.3104  loss_box_reg: 0.5449  loss_mask: 0.3043  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.2025  time: 0.6675  data_time: 0.2744  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:05:16 d2.utils.events]: \u001b[0m eta: 1:10:36  iter: 1239  total_loss: 1.517  loss_cls: 0.3485  loss_box_reg: 0.5689  loss_mask: 0.3099  loss_rpn_cls: 0.07073  loss_rpn_loc: 0.2171  time: 0.6682  data_time: 0.2586  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:05:28 d2.utils.events]: \u001b[0m eta: 1:10:23  iter: 1259  total_loss: 1.528  loss_cls: 0.3446  loss_box_reg: 0.5794  loss_mask: 0.3145  loss_rpn_cls: 0.09909  loss_rpn_loc: 0.1959  time: 0.6671  data_time: 0.1568  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:05:38 d2.utils.events]: \u001b[0m eta: 1:10:13  iter: 1279  total_loss: 1.513  loss_cls: 0.3379  loss_box_reg: 0.5736  loss_mask: 0.3113  loss_rpn_cls: 0.08633  loss_rpn_loc: 0.2067  time: 0.6652  data_time: 0.0916  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:05:53 d2.utils.events]: \u001b[0m eta: 1:09:57  iter: 1299  total_loss: 1.563  loss_cls: 0.3385  loss_box_reg: 0.5823  loss_mask: 0.2937  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.2239  time: 0.6658  data_time: 0.2381  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:06:04 d2.utils.events]: \u001b[0m eta: 1:09:40  iter: 1319  total_loss: 1.529  loss_cls: 0.3143  loss_box_reg: 0.5982  loss_mask: 0.32  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.2152  time: 0.6645  data_time: 0.1356  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:06:19 d2.utils.events]: \u001b[0m eta: 1:09:35  iter: 1339  total_loss: 1.554  loss_cls: 0.342  loss_box_reg: 0.5842  loss_mask: 0.3069  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.2056  time: 0.6658  data_time: 0.2920  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:06:32 d2.utils.events]: \u001b[0m eta: 1:09:20  iter: 1359  total_loss: 1.498  loss_cls: 0.3422  loss_box_reg: 0.5793  loss_mask: 0.3056  loss_rpn_cls: 0.06878  loss_rpn_loc: 0.1871  time: 0.6653  data_time: 0.1643  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:06:44 d2.utils.events]: \u001b[0m eta: 1:09:09  iter: 1379  total_loss: 1.506  loss_cls: 0.3338  loss_box_reg: 0.5774  loss_mask: 0.3131  loss_rpn_cls: 0.07065  loss_rpn_loc: 0.1931  time: 0.6643  data_time: 0.1373  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:06:58 d2.utils.events]: \u001b[0m eta: 1:08:58  iter: 1399  total_loss: 1.58  loss_cls: 0.3384  loss_box_reg: 0.6002  loss_mask: 0.3068  loss_rpn_cls: 0.08581  loss_rpn_loc: 0.2174  time: 0.6649  data_time: 0.2257  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:07:09 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 1419  total_loss: 1.66  loss_cls: 0.3815  loss_box_reg: 0.6185  loss_mask: 0.3168  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.2174  time: 0.6631  data_time: 0.0787  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:07:26 d2.utils.events]: \u001b[0m eta: 1:08:40  iter: 1439  total_loss: 1.549  loss_cls: 0.3555  loss_box_reg: 0.5893  loss_mask: 0.3091  loss_rpn_cls: 0.08963  loss_rpn_loc: 0.1905  time: 0.6661  data_time: 0.4019  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:07:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:07:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:07:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:07:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:07:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:07:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0821 s/iter. Eval: 0.0483 s/iter. Total: 0.1311 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:07:40 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0637 s/iter. Total: 0.1475 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0653 s/iter. Total: 0.1491 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0649 s/iter. Total: 0.1491 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:07:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.309292 (0.149218 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:07:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083384 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:07:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:07:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2583013967249015\n",
      "\u001b[32m[02/04 14:07:56 d2.utils.events]: \u001b[0m eta: 1:08:28  iter: 1459  total_loss: 1.532  loss_cls: 0.3298  loss_box_reg: 0.5649  loss_mask: 0.294  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.2026  time: 0.6643  data_time: 0.0762  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:08:09 d2.utils.events]: \u001b[0m eta: 1:08:17  iter: 1479  total_loss: 1.56  loss_cls: 0.3602  loss_box_reg: 0.5834  loss_mask: 0.3124  loss_rpn_cls: 0.07781  loss_rpn_loc: 0.1963  time: 0.6645  data_time: 0.2038  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:08:24 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 1499  total_loss: 1.566  loss_cls: 0.3661  loss_box_reg: 0.5888  loss_mask: 0.3156  loss_rpn_cls: 0.09605  loss_rpn_loc: 0.2246  time: 0.6652  data_time: 0.2597  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:08:33 d2.utils.events]: \u001b[0m eta: 1:07:42  iter: 1519  total_loss: 1.475  loss_cls: 0.3236  loss_box_reg: 0.5684  loss_mask: 0.2934  loss_rpn_cls: 0.07622  loss_rpn_loc: 0.1904  time: 0.6626  data_time: 0.0331  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:08:45 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 1539  total_loss: 1.556  loss_cls: 0.3642  loss_box_reg: 0.5983  loss_mask: 0.3113  loss_rpn_cls: 0.07017  loss_rpn_loc: 0.2048  time: 0.6614  data_time: 0.1143  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:08:57 d2.utils.events]: \u001b[0m eta: 1:07:08  iter: 1559  total_loss: 1.465  loss_cls: 0.3042  loss_box_reg: 0.5379  loss_mask: 0.3045  loss_rpn_cls: 0.08749  loss_rpn_loc: 0.1855  time: 0.6610  data_time: 0.1674  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:09:12 d2.utils.events]: \u001b[0m eta: 1:06:58  iter: 1579  total_loss: 1.633  loss_cls: 0.3662  loss_box_reg: 0.6098  loss_mask: 0.3236  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.2293  time: 0.6622  data_time: 0.3001  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:09:26 d2.utils.events]: \u001b[0m eta: 1:06:54  iter: 1599  total_loss: 1.586  loss_cls: 0.3344  loss_box_reg: 0.5726  loss_mask: 0.3141  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2153  time: 0.6626  data_time: 0.2263  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:09:39 d2.utils.events]: \u001b[0m eta: 1:06:42  iter: 1619  total_loss: 1.539  loss_cls: 0.3639  loss_box_reg: 0.588  loss_mask: 0.3165  loss_rpn_cls: 0.08115  loss_rpn_loc: 0.1965  time: 0.6625  data_time: 0.1914  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:09:55 d2.utils.events]: \u001b[0m eta: 1:06:46  iter: 1639  total_loss: 1.658  loss_cls: 0.3812  loss_box_reg: 0.6099  loss_mask: 0.3155  loss_rpn_cls: 0.09582  loss_rpn_loc: 0.2274  time: 0.6637  data_time: 0.2739  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:10:07 d2.utils.events]: \u001b[0m eta: 1:06:40  iter: 1659  total_loss: 1.488  loss_cls: 0.331  loss_box_reg: 0.5581  loss_mask: 0.2932  loss_rpn_cls: 0.07818  loss_rpn_loc: 0.2109  time: 0.6631  data_time: 0.1270  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:10:19 d2.utils.events]: \u001b[0m eta: 1:06:31  iter: 1679  total_loss: 1.416  loss_cls: 0.2922  loss_box_reg: 0.5708  loss_mask: 0.2919  loss_rpn_cls: 0.06211  loss_rpn_loc: 0.1812  time: 0.6625  data_time: 0.1368  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:10:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:10:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:10:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:10:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:10:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:10:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0904 s/iter. Eval: 0.0524 s/iter. Total: 0.1435 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 14:10:37 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0868 s/iter. Eval: 0.0670 s/iter. Total: 0.1545 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:10:42 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0677 s/iter. Total: 0.1540 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0695 s/iter. Total: 0.1558 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:10:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.042545 (0.155539 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:10:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085641 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:10:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:10:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24971158645707794\n",
      "\u001b[32m[02/04 14:10:53 d2.utils.events]: \u001b[0m eta: 1:06:34  iter: 1699  total_loss: 1.599  loss_cls: 0.3803  loss_box_reg: 0.5881  loss_mask: 0.2987  loss_rpn_cls: 0.129  loss_rpn_loc: 0.2129  time: 0.6630  data_time: 0.2212  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:11:07 d2.utils.events]: \u001b[0m eta: 1:06:26  iter: 1719  total_loss: 1.46  loss_cls: 0.3106  loss_box_reg: 0.5401  loss_mask: 0.298  loss_rpn_cls: 0.09315  loss_rpn_loc: 0.1926  time: 0.6633  data_time: 0.2037  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:11:20 d2.utils.events]: \u001b[0m eta: 1:06:15  iter: 1739  total_loss: 1.532  loss_cls: 0.3297  loss_box_reg: 0.5888  loss_mask: 0.3091  loss_rpn_cls: 0.08273  loss_rpn_loc: 0.2005  time: 0.6630  data_time: 0.1769  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:11:32 d2.utils.events]: \u001b[0m eta: 1:06:04  iter: 1759  total_loss: 1.52  loss_cls: 0.3449  loss_box_reg: 0.5893  loss_mask: 0.3219  loss_rpn_cls: 0.08816  loss_rpn_loc: 0.2004  time: 0.6624  data_time: 0.1329  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:11:45 d2.utils.events]: \u001b[0m eta: 1:05:54  iter: 1779  total_loss: 1.56  loss_cls: 0.3367  loss_box_reg: 0.6074  loss_mask: 0.3006  loss_rpn_cls: 0.07896  loss_rpn_loc: 0.2029  time: 0.6623  data_time: 0.1791  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:11:58 d2.utils.events]: \u001b[0m eta: 1:05:44  iter: 1799  total_loss: 1.527  loss_cls: 0.3507  loss_box_reg: 0.6038  loss_mask: 0.3087  loss_rpn_cls: 0.08117  loss_rpn_loc: 0.2007  time: 0.6622  data_time: 0.1781  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:12:09 d2.utils.events]: \u001b[0m eta: 1:05:38  iter: 1819  total_loss: 1.645  loss_cls: 0.3645  loss_box_reg: 0.6095  loss_mask: 0.3046  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.2154  time: 0.6610  data_time: 0.0987  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:12:26 d2.utils.events]: \u001b[0m eta: 1:05:31  iter: 1839  total_loss: 1.461  loss_cls: 0.3245  loss_box_reg: 0.5492  loss_mask: 0.2993  loss_rpn_cls: 0.08379  loss_rpn_loc: 0.1944  time: 0.6632  data_time: 0.3770  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:12:41 d2.utils.events]: \u001b[0m eta: 1:05:23  iter: 1859  total_loss: 1.54  loss_cls: 0.3423  loss_box_reg: 0.5918  loss_mask: 0.3284  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.1898  time: 0.6639  data_time: 0.2369  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:12:55 d2.utils.events]: \u001b[0m eta: 1:05:19  iter: 1879  total_loss: 1.539  loss_cls: 0.3571  loss_box_reg: 0.5816  loss_mask: 0.3007  loss_rpn_cls: 0.08827  loss_rpn_loc: 0.1952  time: 0.6643  data_time: 0.2153  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:13:09 d2.utils.events]: \u001b[0m eta: 1:05:12  iter: 1899  total_loss: 1.441  loss_cls: 0.3101  loss_box_reg: 0.572  loss_mask: 0.3022  loss_rpn_cls: 0.0666  loss_rpn_loc: 0.1786  time: 0.6647  data_time: 0.2261  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:13:22 d2.utils.events]: \u001b[0m eta: 1:05:07  iter: 1919  total_loss: 1.528  loss_cls: 0.3168  loss_box_reg: 0.5749  loss_mask: 0.3118  loss_rpn_cls: 0.08551  loss_rpn_loc: 0.1933  time: 0.6645  data_time: 0.1730  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:13:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:13:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:13:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:13:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:13:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:13:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0465 s/iter. Total: 0.1279 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0644 s/iter. Total: 0.1483 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0663 s/iter. Total: 0.1505 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0836 s/iter. Eval: 0.0683 s/iter. Total: 0.1528 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:13:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.823613 (0.153652 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:13:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084233 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:13:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:13:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25430526600830483\n",
      "\u001b[32m[02/04 14:13:54 d2.utils.events]: \u001b[0m eta: 1:04:59  iter: 1939  total_loss: 1.477  loss_cls: 0.2948  loss_box_reg: 0.5798  loss_mask: 0.3086  loss_rpn_cls: 0.07538  loss_rpn_loc: 0.1921  time: 0.6642  data_time: 0.1737  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:14:07 d2.utils.events]: \u001b[0m eta: 1:04:51  iter: 1959  total_loss: 1.626  loss_cls: 0.3849  loss_box_reg: 0.6008  loss_mask: 0.3128  loss_rpn_cls: 0.09023  loss_rpn_loc: 0.2157  time: 0.6640  data_time: 0.1774  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:14:20 d2.utils.events]: \u001b[0m eta: 1:04:35  iter: 1979  total_loss: 1.506  loss_cls: 0.3381  loss_box_reg: 0.578  loss_mask: 0.3283  loss_rpn_cls: 0.08082  loss_rpn_loc: 0.1985  time: 0.6640  data_time: 0.2108  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:14:34 d2.utils.events]: \u001b[0m eta: 1:04:31  iter: 1999  total_loss: 1.484  loss_cls: 0.3319  loss_box_reg: 0.565  loss_mask: 0.2986  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.204  time: 0.6642  data_time: 0.2060  lr: 0.0005  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:14:46 d2.utils.events]: \u001b[0m eta: 1:04:19  iter: 2019  total_loss: 1.45  loss_cls: 0.3115  loss_box_reg: 0.5638  loss_mask: 0.3008  loss_rpn_cls: 0.07993  loss_rpn_loc: 0.2031  time: 0.6639  data_time: 0.1689  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:15:00 d2.utils.events]: \u001b[0m eta: 1:04:06  iter: 2039  total_loss: 1.65  loss_cls: 0.3705  loss_box_reg: 0.6023  loss_mask: 0.3217  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2267  time: 0.6642  data_time: 0.2303  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:15:13 d2.utils.events]: \u001b[0m eta: 1:03:56  iter: 2059  total_loss: 1.491  loss_cls: 0.3432  loss_box_reg: 0.5682  loss_mask: 0.3049  loss_rpn_cls: 0.08676  loss_rpn_loc: 0.1979  time: 0.6638  data_time: 0.1665  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:15:29 d2.utils.events]: \u001b[0m eta: 1:03:50  iter: 2079  total_loss: 1.53  loss_cls: 0.3511  loss_box_reg: 0.5689  loss_mask: 0.3191  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.1974  time: 0.6652  data_time: 0.3251  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:15:43 d2.utils.events]: \u001b[0m eta: 1:03:36  iter: 2099  total_loss: 1.47  loss_cls: 0.3199  loss_box_reg: 0.5547  loss_mask: 0.2961  loss_rpn_cls: 0.0892  loss_rpn_loc: 0.1796  time: 0.6657  data_time: 0.2477  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:15:56 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 2119  total_loss: 1.498  loss_cls: 0.3592  loss_box_reg: 0.5555  loss_mask: 0.3004  loss_rpn_cls: 0.07646  loss_rpn_loc: 0.1921  time: 0.6654  data_time: 0.1615  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:16:07 d2.utils.events]: \u001b[0m eta: 1:03:16  iter: 2139  total_loss: 1.483  loss_cls: 0.3113  loss_box_reg: 0.5695  loss_mask: 0.3041  loss_rpn_cls: 0.09376  loss_rpn_loc: 0.1997  time: 0.6645  data_time: 0.1205  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:16:21 d2.utils.events]: \u001b[0m eta: 1:03:08  iter: 2159  total_loss: 1.47  loss_cls: 0.3252  loss_box_reg: 0.5556  loss_mask: 0.3112  loss_rpn_cls: 0.07998  loss_rpn_loc: 0.204  time: 0.6645  data_time: 0.1743  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:16:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:16:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:16:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:16:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:16:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:16:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:16:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0826 s/iter. Eval: 0.0446 s/iter. Total: 0.1278 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:16:39 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0851 s/iter. Eval: 0.0639 s/iter. Total: 0.1498 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0654 s/iter. Total: 0.1510 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0666 s/iter. Total: 0.1519 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:16:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.597808 (0.151705 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:16:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084335 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:16:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:16:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26238505454642164\n",
      "\u001b[32m[02/04 14:16:52 d2.utils.events]: \u001b[0m eta: 1:02:58  iter: 2179  total_loss: 1.409  loss_cls: 0.315  loss_box_reg: 0.5851  loss_mask: 0.2878  loss_rpn_cls: 0.08224  loss_rpn_loc: 0.1791  time: 0.6638  data_time: 0.1227  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:17:07 d2.utils.events]: \u001b[0m eta: 1:02:56  iter: 2199  total_loss: 1.607  loss_cls: 0.3457  loss_box_reg: 0.5825  loss_mask: 0.3059  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.2113  time: 0.6649  data_time: 0.2944  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:17:22 d2.utils.events]: \u001b[0m eta: 1:02:51  iter: 2219  total_loss: 1.493  loss_cls: 0.3515  loss_box_reg: 0.5741  loss_mask: 0.2908  loss_rpn_cls: 0.08981  loss_rpn_loc: 0.1953  time: 0.6654  data_time: 0.2348  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:17:37 d2.utils.events]: \u001b[0m eta: 1:02:43  iter: 2239  total_loss: 1.484  loss_cls: 0.3111  loss_box_reg: 0.5628  loss_mask: 0.285  loss_rpn_cls: 0.08541  loss_rpn_loc: 0.1897  time: 0.6664  data_time: 0.2955  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:17:50 d2.utils.events]: \u001b[0m eta: 1:02:37  iter: 2259  total_loss: 1.533  loss_cls: 0.3263  loss_box_reg: 0.5791  loss_mask: 0.3012  loss_rpn_cls: 0.08543  loss_rpn_loc: 0.2035  time: 0.6661  data_time: 0.1667  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:18:04 d2.utils.events]: \u001b[0m eta: 1:02:43  iter: 2279  total_loss: 1.528  loss_cls: 0.3239  loss_box_reg: 0.5693  loss_mask: 0.3117  loss_rpn_cls: 0.09449  loss_rpn_loc: 0.2043  time: 0.6662  data_time: 0.2133  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:18:17 d2.utils.events]: \u001b[0m eta: 1:02:40  iter: 2299  total_loss: 1.518  loss_cls: 0.3316  loss_box_reg: 0.5748  loss_mask: 0.308  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.2091  time: 0.6661  data_time: 0.1562  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:18:31 d2.utils.events]: \u001b[0m eta: 1:02:35  iter: 2319  total_loss: 1.561  loss_cls: 0.3246  loss_box_reg: 0.5764  loss_mask: 0.3194  loss_rpn_cls: 0.08838  loss_rpn_loc: 0.2056  time: 0.6665  data_time: 0.2376  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:18:42 d2.utils.events]: \u001b[0m eta: 1:02:23  iter: 2339  total_loss: 1.303  loss_cls: 0.2615  loss_box_reg: 0.5216  loss_mask: 0.2984  loss_rpn_cls: 0.05364  loss_rpn_loc: 0.1679  time: 0.6657  data_time: 0.1117  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:18:54 d2.utils.events]: \u001b[0m eta: 1:02:16  iter: 2359  total_loss: 1.537  loss_cls: 0.3145  loss_box_reg: 0.6073  loss_mask: 0.3018  loss_rpn_cls: 0.07814  loss_rpn_loc: 0.1831  time: 0.6652  data_time: 0.1420  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:19:07 d2.utils.events]: \u001b[0m eta: 1:02:15  iter: 2379  total_loss: 1.5  loss_cls: 0.3367  loss_box_reg: 0.5811  loss_mask: 0.3049  loss_rpn_cls: 0.09877  loss_rpn_loc: 0.1999  time: 0.6650  data_time: 0.1658  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:19:19 d2.utils.events]: \u001b[0m eta: 1:01:59  iter: 2399  total_loss: 1.405  loss_cls: 0.3199  loss_box_reg: 0.5507  loss_mask: 0.2998  loss_rpn_cls: 0.07623  loss_rpn_loc: 0.1899  time: 0.6642  data_time: 0.1133  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:19:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:19:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:19:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:19:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:19:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:19:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:19:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0455 s/iter. Total: 0.1269 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 14:19:40 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0868 s/iter. Eval: 0.0654 s/iter. Total: 0.1530 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:19:45 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0679 s/iter. Total: 0.1550 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:19:50 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0703 s/iter. Total: 0.1588 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:19:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.405063 (0.158664 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:19:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087699 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:19:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:19:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2577425981966983\n",
      "\u001b[32m[02/04 14:19:52 d2.utils.events]: \u001b[0m eta: 1:01:52  iter: 2419  total_loss: 1.482  loss_cls: 0.3208  loss_box_reg: 0.5791  loss_mask: 0.3059  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.1997  time: 0.6644  data_time: 0.2168  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:20:03 d2.utils.events]: \u001b[0m eta: 1:01:42  iter: 2439  total_loss: 1.431  loss_cls: 0.3141  loss_box_reg: 0.5709  loss_mask: 0.3091  loss_rpn_cls: 0.0631  loss_rpn_loc: 0.1691  time: 0.6634  data_time: 0.0778  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:20:19 d2.utils.events]: \u001b[0m eta: 1:01:37  iter: 2459  total_loss: 1.413  loss_cls: 0.3182  loss_box_reg: 0.5395  loss_mask: 0.3015  loss_rpn_cls: 0.06477  loss_rpn_loc: 0.2008  time: 0.6645  data_time: 0.3079  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:20:32 d2.utils.events]: \u001b[0m eta: 1:01:25  iter: 2479  total_loss: 1.548  loss_cls: 0.3627  loss_box_reg: 0.5889  loss_mask: 0.304  loss_rpn_cls: 0.08087  loss_rpn_loc: 0.1888  time: 0.6641  data_time: 0.1635  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:20:48 d2.utils.events]: \u001b[0m eta: 1:01:18  iter: 2499  total_loss: 1.47  loss_cls: 0.3145  loss_box_reg: 0.5521  loss_mask: 0.3177  loss_rpn_cls: 0.08382  loss_rpn_loc: 0.1826  time: 0.6652  data_time: 0.3270  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:20:59 d2.utils.events]: \u001b[0m eta: 1:01:21  iter: 2519  total_loss: 1.448  loss_cls: 0.327  loss_box_reg: 0.5544  loss_mask: 0.2961  loss_rpn_cls: 0.07029  loss_rpn_loc: 0.1819  time: 0.6646  data_time: 0.1104  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:21:13 d2.utils.events]: \u001b[0m eta: 1:01:19  iter: 2539  total_loss: 1.602  loss_cls: 0.3846  loss_box_reg: 0.5976  loss_mask: 0.3052  loss_rpn_cls: 0.098  loss_rpn_loc: 0.2276  time: 0.6649  data_time: 0.2263  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:21:25 d2.utils.events]: \u001b[0m eta: 1:01:09  iter: 2559  total_loss: 1.574  loss_cls: 0.3632  loss_box_reg: 0.5787  loss_mask: 0.3027  loss_rpn_cls: 0.09811  loss_rpn_loc: 0.1949  time: 0.6643  data_time: 0.1204  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:21:39 d2.utils.events]: \u001b[0m eta: 1:01:00  iter: 2579  total_loss: 1.497  loss_cls: 0.3319  loss_box_reg: 0.5754  loss_mask: 0.3067  loss_rpn_cls: 0.07305  loss_rpn_loc: 0.2105  time: 0.6646  data_time: 0.2168  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:21:53 d2.utils.events]: \u001b[0m eta: 1:00:44  iter: 2599  total_loss: 1.434  loss_cls: 0.2584  loss_box_reg: 0.5862  loss_mask: 0.3134  loss_rpn_cls: 0.07272  loss_rpn_loc: 0.1956  time: 0.6646  data_time: 0.2029  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:22:04 d2.utils.events]: \u001b[0m eta: 1:00:34  iter: 2619  total_loss: 1.414  loss_cls: 0.2946  loss_box_reg: 0.58  loss_mask: 0.2996  loss_rpn_cls: 0.07336  loss_rpn_loc: 0.1922  time: 0.6640  data_time: 0.1189  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:22:17 d2.utils.events]: \u001b[0m eta: 1:00:20  iter: 2639  total_loss: 1.445  loss_cls: 0.3151  loss_box_reg: 0.5514  loss_mask: 0.2928  loss_rpn_cls: 0.08317  loss_rpn_loc: 0.2003  time: 0.6637  data_time: 0.1508  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:22:29 d2.utils.events]: \u001b[0m eta: 1:00:01  iter: 2659  total_loss: 1.549  loss_cls: 0.3175  loss_box_reg: 0.5521  loss_mask: 0.3136  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.2141  time: 0.6634  data_time: 0.1882  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:22:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:22:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:22:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:22:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:22:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:22:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:22:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0807 s/iter. Eval: 0.0441 s/iter. Total: 0.1255 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 14:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0638 s/iter. Total: 0.1478 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:22:44 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0659 s/iter. Total: 0.1501 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:22:49 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0660 s/iter. Total: 0.1507 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:22:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.572595 (0.151488 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:22:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083915 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:22:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:22:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.259351171733308\n",
      "\u001b[32m[02/04 14:23:02 d2.utils.events]: \u001b[0m eta: 0:59:55  iter: 2679  total_loss: 1.544  loss_cls: 0.3413  loss_box_reg: 0.5769  loss_mask: 0.3186  loss_rpn_cls: 0.06497  loss_rpn_loc: 0.2116  time: 0.6634  data_time: 0.1848  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:23:14 d2.utils.events]: \u001b[0m eta: 0:59:40  iter: 2699  total_loss: 1.505  loss_cls: 0.3476  loss_box_reg: 0.5731  loss_mask: 0.3037  loss_rpn_cls: 0.0875  loss_rpn_loc: 0.2011  time: 0.6630  data_time: 0.1330  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:23:28 d2.utils.events]: \u001b[0m eta: 0:59:28  iter: 2719  total_loss: 1.417  loss_cls: 0.3043  loss_box_reg: 0.5679  loss_mask: 0.2998  loss_rpn_cls: 0.0746  loss_rpn_loc: 0.1944  time: 0.6633  data_time: 0.2549  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:23:40 d2.utils.events]: \u001b[0m eta: 0:59:20  iter: 2739  total_loss: 1.479  loss_cls: 0.3254  loss_box_reg: 0.5582  loss_mask: 0.3032  loss_rpn_cls: 0.08282  loss_rpn_loc: 0.1935  time: 0.6630  data_time: 0.1479  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:23:51 d2.utils.events]: \u001b[0m eta: 0:59:10  iter: 2759  total_loss: 1.59  loss_cls: 0.3651  loss_box_reg: 0.5834  loss_mask: 0.3102  loss_rpn_cls: 0.08525  loss_rpn_loc: 0.204  time: 0.6620  data_time: 0.0589  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:24:03 d2.utils.events]: \u001b[0m eta: 0:58:58  iter: 2779  total_loss: 1.452  loss_cls: 0.3214  loss_box_reg: 0.564  loss_mask: 0.2941  loss_rpn_cls: 0.06535  loss_rpn_loc: 0.1781  time: 0.6617  data_time: 0.1709  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:24:17 d2.utils.events]: \u001b[0m eta: 0:58:51  iter: 2799  total_loss: 1.573  loss_cls: 0.3382  loss_box_reg: 0.5838  loss_mask: 0.3053  loss_rpn_cls: 0.09279  loss_rpn_loc: 0.2105  time: 0.6617  data_time: 0.1974  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:24:30 d2.utils.events]: \u001b[0m eta: 0:58:49  iter: 2819  total_loss: 1.367  loss_cls: 0.2928  loss_box_reg: 0.5436  loss_mask: 0.2811  loss_rpn_cls: 0.07957  loss_rpn_loc: 0.1824  time: 0.6617  data_time: 0.1679  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:24:45 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 2839  total_loss: 1.548  loss_cls: 0.3511  loss_box_reg: 0.5753  loss_mask: 0.2972  loss_rpn_cls: 0.07831  loss_rpn_loc: 0.2155  time: 0.6624  data_time: 0.2797  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:24:59 d2.utils.events]: \u001b[0m eta: 0:58:26  iter: 2859  total_loss: 1.487  loss_cls: 0.3187  loss_box_reg: 0.5738  loss_mask: 0.3101  loss_rpn_cls: 0.09396  loss_rpn_loc: 0.2014  time: 0.6625  data_time: 0.2056  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:25:09 d2.utils.events]: \u001b[0m eta: 0:58:08  iter: 2879  total_loss: 1.453  loss_cls: 0.3319  loss_box_reg: 0.5752  loss_mask: 0.3094  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.1996  time: 0.6616  data_time: 0.0922  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:25:25 d2.utils.events]: \u001b[0m eta: 0:57:58  iter: 2899  total_loss: 1.541  loss_cls: 0.3391  loss_box_reg: 0.5996  loss_mask: 0.3114  loss_rpn_cls: 0.08242  loss_rpn_loc: 0.212  time: 0.6623  data_time: 0.2712  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:25:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:25:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:25:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:25:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:25:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:25:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:25:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0813 s/iter. Eval: 0.0473 s/iter. Total: 0.1292 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:25:37 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0848 s/iter. Eval: 0.0658 s/iter. Total: 0.1514 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:25:42 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0847 s/iter. Eval: 0.0666 s/iter. Total: 0.1521 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:25:47 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0007 s/iter. Inference: 0.0854 s/iter. Eval: 0.0690 s/iter. Total: 0.1552 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:25:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.882365 (0.154158 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:25:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085128 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:25:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:25:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2602693174382008\n",
      "\u001b[32m[02/04 14:25:59 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 2919  total_loss: 1.45  loss_cls: 0.3323  loss_box_reg: 0.5381  loss_mask: 0.3001  loss_rpn_cls: 0.07231  loss_rpn_loc: 0.1941  time: 0.6630  data_time: 0.2683  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:26:12 d2.utils.events]: \u001b[0m eta: 0:57:42  iter: 2939  total_loss: 1.466  loss_cls: 0.3164  loss_box_reg: 0.5589  loss_mask: 0.2985  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.1974  time: 0.6629  data_time: 0.1657  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:26:23 d2.utils.events]: \u001b[0m eta: 0:57:29  iter: 2959  total_loss: 1.322  loss_cls: 0.2913  loss_box_reg: 0.5395  loss_mask: 0.2728  loss_rpn_cls: 0.05296  loss_rpn_loc: 0.1743  time: 0.6620  data_time: 0.0807  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:26:36 d2.utils.events]: \u001b[0m eta: 0:57:26  iter: 2979  total_loss: 1.545  loss_cls: 0.3476  loss_box_reg: 0.5478  loss_mask: 0.312  loss_rpn_cls: 0.08426  loss_rpn_loc: 0.201  time: 0.6620  data_time: 0.1958  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:26:50 d2.utils.events]: \u001b[0m eta: 0:57:13  iter: 2999  total_loss: 1.596  loss_cls: 0.3427  loss_box_reg: 0.5842  loss_mask: 0.3112  loss_rpn_cls: 0.09634  loss_rpn_loc: 0.2182  time: 0.6620  data_time: 0.2017  lr: 0.0004  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:27:03 d2.utils.events]: \u001b[0m eta: 0:57:05  iter: 3019  total_loss: 1.495  loss_cls: 0.3218  loss_box_reg: 0.5611  loss_mask: 0.3098  loss_rpn_cls: 0.09011  loss_rpn_loc: 0.2037  time: 0.6622  data_time: 0.2111  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:27:18 d2.utils.events]: \u001b[0m eta: 0:56:58  iter: 3039  total_loss: 1.527  loss_cls: 0.3295  loss_box_reg: 0.5868  loss_mask: 0.3105  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2044  time: 0.6626  data_time: 0.2410  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:27:32 d2.utils.events]: \u001b[0m eta: 0:56:48  iter: 3059  total_loss: 1.606  loss_cls: 0.3755  loss_box_reg: 0.5847  loss_mask: 0.325  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.2201  time: 0.6630  data_time: 0.2407  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:27:44 d2.utils.events]: \u001b[0m eta: 0:56:36  iter: 3079  total_loss: 1.369  loss_cls: 0.3077  loss_box_reg: 0.5271  loss_mask: 0.2983  loss_rpn_cls: 0.06972  loss_rpn_loc: 0.1772  time: 0.6623  data_time: 0.1000  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:27:56 d2.utils.events]: \u001b[0m eta: 0:56:28  iter: 3099  total_loss: 1.427  loss_cls: 0.3278  loss_box_reg: 0.5586  loss_mask: 0.2909  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1822  time: 0.6620  data_time: 0.1468  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:28:08 d2.utils.events]: \u001b[0m eta: 0:56:17  iter: 3119  total_loss: 1.438  loss_cls: 0.3065  loss_box_reg: 0.5858  loss_mask: 0.2976  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1934  time: 0.6618  data_time: 0.1619  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:28:19 d2.utils.events]: \u001b[0m eta: 0:56:09  iter: 3139  total_loss: 1.523  loss_cls: 0.3216  loss_box_reg: 0.5686  loss_mask: 0.2873  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.1897  time: 0.6611  data_time: 0.0900  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:28:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:28:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:28:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:28:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:28:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:28:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0811 s/iter. Eval: 0.0487 s/iter. Total: 0.1305 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0840 s/iter. Eval: 0.0658 s/iter. Total: 0.1506 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0670 s/iter. Total: 0.1517 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0691 s/iter. Total: 0.1539 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:28:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.866369 (0.154020 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:28:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084070 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:28:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:28:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.259251264674245\n",
      "\u001b[32m[02/04 14:28:51 d2.utils.events]: \u001b[0m eta: 0:56:02  iter: 3159  total_loss: 1.567  loss_cls: 0.3358  loss_box_reg: 0.6064  loss_mask: 0.313  loss_rpn_cls: 0.09219  loss_rpn_loc: 0.2026  time: 0.6608  data_time: 0.1364  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:29:08 d2.utils.events]: \u001b[0m eta: 0:55:55  iter: 3179  total_loss: 1.503  loss_cls: 0.3372  loss_box_reg: 0.5746  loss_mask: 0.3215  loss_rpn_cls: 0.08053  loss_rpn_loc: 0.2043  time: 0.6619  data_time: 0.3498  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:29:19 d2.utils.events]: \u001b[0m eta: 0:55:47  iter: 3199  total_loss: 1.512  loss_cls: 0.3673  loss_box_reg: 0.6166  loss_mask: 0.2918  loss_rpn_cls: 0.06568  loss_rpn_loc: 0.181  time: 0.6613  data_time: 0.0809  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:29:31 d2.utils.events]: \u001b[0m eta: 0:55:32  iter: 3219  total_loss: 1.386  loss_cls: 0.2957  loss_box_reg: 0.5559  loss_mask: 0.2842  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.1827  time: 0.6609  data_time: 0.1245  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:29:45 d2.utils.events]: \u001b[0m eta: 0:55:25  iter: 3239  total_loss: 1.635  loss_cls: 0.3726  loss_box_reg: 0.595  loss_mask: 0.3212  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2185  time: 0.6612  data_time: 0.2418  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:29:59 d2.utils.events]: \u001b[0m eta: 0:55:17  iter: 3259  total_loss: 1.468  loss_cls: 0.3408  loss_box_reg: 0.5561  loss_mask: 0.2974  loss_rpn_cls: 0.08514  loss_rpn_loc: 0.1862  time: 0.6613  data_time: 0.2056  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:30:11 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 3279  total_loss: 1.411  loss_cls: 0.2999  loss_box_reg: 0.5527  loss_mask: 0.3024  loss_rpn_cls: 0.07141  loss_rpn_loc: 0.1928  time: 0.6610  data_time: 0.1519  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:30:26 d2.utils.events]: \u001b[0m eta: 0:54:51  iter: 3299  total_loss: 1.508  loss_cls: 0.3226  loss_box_reg: 0.5728  loss_mask: 0.3167  loss_rpn_cls: 0.09625  loss_rpn_loc: 0.2087  time: 0.6614  data_time: 0.2618  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:30:40 d2.utils.events]: \u001b[0m eta: 0:54:40  iter: 3319  total_loss: 1.45  loss_cls: 0.3021  loss_box_reg: 0.5622  loss_mask: 0.2988  loss_rpn_cls: 0.07045  loss_rpn_loc: 0.2013  time: 0.6616  data_time: 0.2071  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:30:53 d2.utils.events]: \u001b[0m eta: 0:54:31  iter: 3339  total_loss: 1.404  loss_cls: 0.3158  loss_box_reg: 0.5457  loss_mask: 0.2898  loss_rpn_cls: 0.06962  loss_rpn_loc: 0.1928  time: 0.6615  data_time: 0.1926  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:31:03 d2.utils.events]: \u001b[0m eta: 0:54:19  iter: 3359  total_loss: 1.443  loss_cls: 0.3141  loss_box_reg: 0.5587  loss_mask: 0.2952  loss_rpn_cls: 0.09109  loss_rpn_loc: 0.1875  time: 0.6607  data_time: 0.0723  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:31:17 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 3379  total_loss: 1.406  loss_cls: 0.3111  loss_box_reg: 0.5587  loss_mask: 0.3091  loss_rpn_cls: 0.07258  loss_rpn_loc: 0.1921  time: 0.6608  data_time: 0.2109  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:31:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:31:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:31:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:31:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:31:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:31:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:31:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0810 s/iter. Eval: 0.0478 s/iter. Total: 0.1294 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:31:29 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0663 s/iter. Total: 0.1533 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:31:34 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0690 s/iter. Total: 0.1562 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 14:31:39 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0719 s/iter. Total: 0.1597 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:31:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.459068 (0.159130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:31:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086569 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:31:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:31:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.264870958197342\n",
      "\u001b[32m[02/04 14:31:52 d2.utils.events]: \u001b[0m eta: 0:54:01  iter: 3399  total_loss: 1.433  loss_cls: 0.3465  loss_box_reg: 0.5605  loss_mask: 0.2975  loss_rpn_cls: 0.08269  loss_rpn_loc: 0.1887  time: 0.6613  data_time: 0.2580  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:32:03 d2.utils.events]: \u001b[0m eta: 0:53:51  iter: 3419  total_loss: 1.586  loss_cls: 0.3328  loss_box_reg: 0.6059  loss_mask: 0.3042  loss_rpn_cls: 0.09618  loss_rpn_loc: 0.2101  time: 0.6608  data_time: 0.1228  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:32:16 d2.utils.events]: \u001b[0m eta: 0:53:40  iter: 3439  total_loss: 1.361  loss_cls: 0.3045  loss_box_reg: 0.5553  loss_mask: 0.3025  loss_rpn_cls: 0.09062  loss_rpn_loc: 0.2003  time: 0.6607  data_time: 0.1624  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:32:27 d2.utils.events]: \u001b[0m eta: 0:53:26  iter: 3459  total_loss: 1.398  loss_cls: 0.2798  loss_box_reg: 0.563  loss_mask: 0.2819  loss_rpn_cls: 0.05007  loss_rpn_loc: 0.1821  time: 0.6600  data_time: 0.0765  lr: 0.00032  max_mem: 6867M\n",
      "\u001b[32m[02/04 14:32:43 d2.utils.events]: \u001b[0m eta: 0:53:18  iter: 3479  total_loss: 1.517  loss_cls: 0.349  loss_box_reg: 0.6077  loss_mask: 0.3145  loss_rpn_cls: 0.07544  loss_rpn_loc: 0.2015  time: 0.6607  data_time: 0.2985  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:32:58 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 3499  total_loss: 1.461  loss_cls: 0.2988  loss_box_reg: 0.5645  loss_mask: 0.3122  loss_rpn_cls: 0.07757  loss_rpn_loc: 0.184  time: 0.6613  data_time: 0.2651  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:33:11 d2.utils.events]: \u001b[0m eta: 0:52:57  iter: 3519  total_loss: 1.439  loss_cls: 0.3327  loss_box_reg: 0.5641  loss_mask: 0.2922  loss_rpn_cls: 0.08276  loss_rpn_loc: 0.2  time: 0.6611  data_time: 0.1618  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:33:24 d2.utils.events]: \u001b[0m eta: 0:52:45  iter: 3539  total_loss: 1.501  loss_cls: 0.3115  loss_box_reg: 0.5855  loss_mask: 0.3022  loss_rpn_cls: 0.07771  loss_rpn_loc: 0.1975  time: 0.6612  data_time: 0.2146  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:33:37 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 3559  total_loss: 1.413  loss_cls: 0.3195  loss_box_reg: 0.5445  loss_mask: 0.2978  loss_rpn_cls: 0.07987  loss_rpn_loc: 0.1788  time: 0.6610  data_time: 0.1435  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:33:49 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 3579  total_loss: 1.556  loss_cls: 0.3293  loss_box_reg: 0.5842  loss_mask: 0.3152  loss_rpn_cls: 0.08642  loss_rpn_loc: 0.208  time: 0.6608  data_time: 0.1422  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:34:02 d2.utils.events]: \u001b[0m eta: 0:52:19  iter: 3599  total_loss: 1.426  loss_cls: 0.3071  loss_box_reg: 0.5433  loss_mask: 0.2972  loss_rpn_cls: 0.0802  loss_rpn_loc: 0.2026  time: 0.6607  data_time: 0.1903  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:34:16 d2.utils.events]: \u001b[0m eta: 0:52:12  iter: 3619  total_loss: 1.426  loss_cls: 0.3046  loss_box_reg: 0.5444  loss_mask: 0.2938  loss_rpn_cls: 0.08292  loss_rpn_loc: 0.1808  time: 0.6610  data_time: 0.2497  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:34:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:34:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:34:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:34:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:34:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:34:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:34:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0846 s/iter. Eval: 0.0501 s/iter. Total: 0.1354 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0850 s/iter. Eval: 0.0677 s/iter. Total: 0.1535 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0845 s/iter. Eval: 0.0678 s/iter. Total: 0.1531 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0845 s/iter. Eval: 0.0698 s/iter. Total: 0.1551 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:34:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.996291 (0.155140 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:34:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084506 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:34:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:34:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26493831766325415\n",
      "\u001b[32m[02/04 14:34:50 d2.utils.events]: \u001b[0m eta: 0:52:04  iter: 3639  total_loss: 1.584  loss_cls: 0.37  loss_box_reg: 0.5839  loss_mask: 0.3161  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.2027  time: 0.6612  data_time: 0.2235  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:35:05 d2.utils.events]: \u001b[0m eta: 0:51:59  iter: 3659  total_loss: 1.445  loss_cls: 0.3213  loss_box_reg: 0.5557  loss_mask: 0.2962  loss_rpn_cls: 0.07505  loss_rpn_loc: 0.199  time: 0.6616  data_time: 0.2417  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:35:18 d2.utils.events]: \u001b[0m eta: 0:51:48  iter: 3679  total_loss: 1.366  loss_cls: 0.2884  loss_box_reg: 0.5398  loss_mask: 0.3083  loss_rpn_cls: 0.07516  loss_rpn_loc: 0.1817  time: 0.6617  data_time: 0.2086  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:35:32 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 3699  total_loss: 1.543  loss_cls: 0.3471  loss_box_reg: 0.5579  loss_mask: 0.291  loss_rpn_cls: 0.0977  loss_rpn_loc: 0.2279  time: 0.6618  data_time: 0.2114  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:35:44 d2.utils.events]: \u001b[0m eta: 0:51:24  iter: 3719  total_loss: 1.339  loss_cls: 0.2963  loss_box_reg: 0.5362  loss_mask: 0.2959  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.1546  time: 0.6615  data_time: 0.1466  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:35:58 d2.utils.events]: \u001b[0m eta: 0:51:15  iter: 3739  total_loss: 1.493  loss_cls: 0.3333  loss_box_reg: 0.5736  loss_mask: 0.3004  loss_rpn_cls: 0.08846  loss_rpn_loc: 0.2159  time: 0.6616  data_time: 0.2207  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:36:10 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 3759  total_loss: 1.437  loss_cls: 0.2973  loss_box_reg: 0.5644  loss_mask: 0.3164  loss_rpn_cls: 0.07832  loss_rpn_loc: 0.1883  time: 0.6613  data_time: 0.1387  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:36:24 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 3779  total_loss: 1.485  loss_cls: 0.3247  loss_box_reg: 0.5843  loss_mask: 0.2939  loss_rpn_cls: 0.07482  loss_rpn_loc: 0.2136  time: 0.6615  data_time: 0.2148  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:36:34 d2.utils.events]: \u001b[0m eta: 0:50:45  iter: 3799  total_loss: 1.375  loss_cls: 0.2959  loss_box_reg: 0.5506  loss_mask: 0.2845  loss_rpn_cls: 0.06013  loss_rpn_loc: 0.1792  time: 0.6607  data_time: 0.0872  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:36:48 d2.utils.events]: \u001b[0m eta: 0:50:33  iter: 3819  total_loss: 1.487  loss_cls: 0.3166  loss_box_reg: 0.5727  loss_mask: 0.3118  loss_rpn_cls: 0.06338  loss_rpn_loc: 0.2107  time: 0.6610  data_time: 0.2327  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:37:02 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 3839  total_loss: 1.427  loss_cls: 0.3099  loss_box_reg: 0.5324  loss_mask: 0.2935  loss_rpn_cls: 0.08094  loss_rpn_loc: 0.1988  time: 0.6611  data_time: 0.2095  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:37:14 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 3859  total_loss: 1.454  loss_cls: 0.3039  loss_box_reg: 0.5783  loss_mask: 0.3103  loss_rpn_cls: 0.08218  loss_rpn_loc: 0.1903  time: 0.6609  data_time: 0.1633  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:37:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:37:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:37:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:37:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:37:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:37:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0810 s/iter. Eval: 0.0472 s/iter. Total: 0.1288 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0847 s/iter. Eval: 0.0664 s/iter. Total: 0.1519 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0843 s/iter. Eval: 0.0680 s/iter. Total: 0.1531 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0007 s/iter. Inference: 0.0848 s/iter. Eval: 0.0711 s/iter. Total: 0.1567 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:37:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.148738 (0.156455 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:37:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084722 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:37:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:37:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26405566236927863\n",
      "\u001b[32m[02/04 14:37:44 d2.utils.events]: \u001b[0m eta: 0:49:59  iter: 3879  total_loss: 1.552  loss_cls: 0.3612  loss_box_reg: 0.5902  loss_mask: 0.3114  loss_rpn_cls: 0.07918  loss_rpn_loc: 0.193  time: 0.6601  data_time: 0.0575  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:37:54 d2.utils.events]: \u001b[0m eta: 0:49:44  iter: 3899  total_loss: 1.359  loss_cls: 0.301  loss_box_reg: 0.5483  loss_mask: 0.2802  loss_rpn_cls: 0.05732  loss_rpn_loc: 0.1676  time: 0.6593  data_time: 0.0563  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:38:08 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 3919  total_loss: 1.537  loss_cls: 0.3485  loss_box_reg: 0.5645  loss_mask: 0.2902  loss_rpn_cls: 0.0866  loss_rpn_loc: 0.205  time: 0.6594  data_time: 0.2204  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:38:25 d2.utils.events]: \u001b[0m eta: 0:49:25  iter: 3939  total_loss: 1.434  loss_cls: 0.3116  loss_box_reg: 0.5612  loss_mask: 0.3109  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.1981  time: 0.6603  data_time: 0.3498  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:38:36 d2.utils.events]: \u001b[0m eta: 0:49:16  iter: 3959  total_loss: 1.329  loss_cls: 0.2855  loss_box_reg: 0.5551  loss_mask: 0.291  loss_rpn_cls: 0.05267  loss_rpn_loc: 0.1914  time: 0.6597  data_time: 0.1006  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:38:51 d2.utils.events]: \u001b[0m eta: 0:49:04  iter: 3979  total_loss: 1.463  loss_cls: 0.3233  loss_box_reg: 0.5375  loss_mask: 0.3012  loss_rpn_cls: 0.08965  loss_rpn_loc: 0.2089  time: 0.6602  data_time: 0.2856  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:39:04 d2.utils.events]: \u001b[0m eta: 0:48:58  iter: 3999  total_loss: 1.397  loss_cls: 0.32  loss_box_reg: 0.5456  loss_mask: 0.2836  loss_rpn_cls: 0.07668  loss_rpn_loc: 0.1768  time: 0.6602  data_time: 0.1889  lr: 0.00032  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:39:16 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 4019  total_loss: 1.375  loss_cls: 0.3017  loss_box_reg: 0.5598  loss_mask: 0.2964  loss_rpn_cls: 0.05438  loss_rpn_loc: 0.1789  time: 0.6600  data_time: 0.1537  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:39:31 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 4039  total_loss: 1.524  loss_cls: 0.3438  loss_box_reg: 0.5684  loss_mask: 0.3104  loss_rpn_cls: 0.09088  loss_rpn_loc: 0.2167  time: 0.6603  data_time: 0.2620  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:39:45 d2.utils.events]: \u001b[0m eta: 0:48:18  iter: 4059  total_loss: 1.444  loss_cls: 0.3182  loss_box_reg: 0.5523  loss_mask: 0.3024  loss_rpn_cls: 0.08703  loss_rpn_loc: 0.1813  time: 0.6605  data_time: 0.2399  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:39:59 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 4079  total_loss: 1.673  loss_cls: 0.4063  loss_box_reg: 0.6083  loss_mask: 0.3192  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.2283  time: 0.6607  data_time: 0.2068  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:40:10 d2.utils.events]: \u001b[0m eta: 0:48:01  iter: 4099  total_loss: 1.551  loss_cls: 0.319  loss_box_reg: 0.5884  loss_mask: 0.3159  loss_rpn_cls: 0.0867  loss_rpn_loc: 0.2077  time: 0.6602  data_time: 0.1122  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:40:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:40:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:40:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:40:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:40:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:40:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0810 s/iter. Eval: 0.0438 s/iter. Total: 0.1254 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 14:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0839 s/iter. Eval: 0.0640 s/iter. Total: 0.1486 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:40:32 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0654 s/iter. Total: 0.1503 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:40:37 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0678 s/iter. Total: 0.1531 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 14:40:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.811224 (0.153545 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:40:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084781 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:40:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:40:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27149514942120484\n",
      "\u001b[32m[02/04 14:40:43 d2.utils.events]: \u001b[0m eta: 0:47:55  iter: 4119  total_loss: 1.357  loss_cls: 0.2905  loss_box_reg: 0.5133  loss_mask: 0.2769  loss_rpn_cls: 0.07976  loss_rpn_loc: 0.1847  time: 0.6602  data_time: 0.1735  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:40:54 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 4139  total_loss: 1.386  loss_cls: 0.295  loss_box_reg: 0.5405  loss_mask: 0.293  loss_rpn_cls: 0.06277  loss_rpn_loc: 0.1807  time: 0.6598  data_time: 0.1179  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:41:06 d2.utils.events]: \u001b[0m eta: 0:47:28  iter: 4159  total_loss: 1.371  loss_cls: 0.2715  loss_box_reg: 0.5732  loss_mask: 0.3022  loss_rpn_cls: 0.05138  loss_rpn_loc: 0.1891  time: 0.6593  data_time: 0.1066  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:41:20 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 4179  total_loss: 1.461  loss_cls: 0.3129  loss_box_reg: 0.5558  loss_mask: 0.3062  loss_rpn_cls: 0.07781  loss_rpn_loc: 0.2015  time: 0.6596  data_time: 0.2359  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:41:32 d2.utils.events]: \u001b[0m eta: 0:47:06  iter: 4199  total_loss: 1.296  loss_cls: 0.2967  loss_box_reg: 0.5273  loss_mask: 0.2821  loss_rpn_cls: 0.06249  loss_rpn_loc: 0.1744  time: 0.6593  data_time: 0.1248  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:41:44 d2.utils.events]: \u001b[0m eta: 0:46:55  iter: 4219  total_loss: 1.487  loss_cls: 0.3418  loss_box_reg: 0.5614  loss_mask: 0.301  loss_rpn_cls: 0.0765  loss_rpn_loc: 0.1911  time: 0.6591  data_time: 0.1641  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:41:59 d2.utils.events]: \u001b[0m eta: 0:46:48  iter: 4239  total_loss: 1.575  loss_cls: 0.3529  loss_box_reg: 0.5814  loss_mask: 0.3146  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.2131  time: 0.6596  data_time: 0.2687  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:42:12 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 4259  total_loss: 1.551  loss_cls: 0.344  loss_box_reg: 0.5837  loss_mask: 0.3038  loss_rpn_cls: 0.08645  loss_rpn_loc: 0.2141  time: 0.6595  data_time: 0.1641  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:42:24 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 4279  total_loss: 1.343  loss_cls: 0.2922  loss_box_reg: 0.563  loss_mask: 0.29  loss_rpn_cls: 0.04747  loss_rpn_loc: 0.1669  time: 0.6593  data_time: 0.1449  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:42:38 d2.utils.events]: \u001b[0m eta: 0:46:19  iter: 4299  total_loss: 1.547  loss_cls: 0.3279  loss_box_reg: 0.5597  loss_mask: 0.3108  loss_rpn_cls: 0.07901  loss_rpn_loc: 0.1926  time: 0.6594  data_time: 0.2178  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:42:51 d2.utils.events]: \u001b[0m eta: 0:46:08  iter: 4319  total_loss: 1.525  loss_cls: 0.3144  loss_box_reg: 0.5545  loss_mask: 0.2946  loss_rpn_cls: 0.05146  loss_rpn_loc: 0.2059  time: 0.6594  data_time: 0.1882  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:43:06 d2.utils.events]: \u001b[0m eta: 0:46:02  iter: 4339  total_loss: 1.444  loss_cls: 0.3226  loss_box_reg: 0.5602  loss_mask: 0.3062  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1858  time: 0.6598  data_time: 0.2872  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:43:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:43:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:43:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:43:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:43:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:43:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0813 s/iter. Eval: 0.0481 s/iter. Total: 0.1301 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0833 s/iter. Eval: 0.0659 s/iter. Total: 0.1501 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0680 s/iter. Total: 0.1529 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0698 s/iter. Total: 0.1551 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:43:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.001346 (0.155184 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:43:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084680 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:43:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:43:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2711865324500442\n",
      "\u001b[32m[02/04 14:43:39 d2.utils.events]: \u001b[0m eta: 0:45:58  iter: 4359  total_loss: 1.375  loss_cls: 0.3214  loss_box_reg: 0.5402  loss_mask: 0.2809  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.1789  time: 0.6598  data_time: 0.1724  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:43:54 d2.utils.events]: \u001b[0m eta: 0:45:53  iter: 4379  total_loss: 1.454  loss_cls: 0.316  loss_box_reg: 0.5593  loss_mask: 0.31  loss_rpn_cls: 0.08905  loss_rpn_loc: 0.1869  time: 0.6602  data_time: 0.2774  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:44:08 d2.utils.events]: \u001b[0m eta: 0:45:44  iter: 4399  total_loss: 1.423  loss_cls: 0.308  loss_box_reg: 0.5603  loss_mask: 0.2994  loss_rpn_cls: 0.07989  loss_rpn_loc: 0.1976  time: 0.6604  data_time: 0.2194  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:44:19 d2.utils.events]: \u001b[0m eta: 0:45:32  iter: 4419  total_loss: 1.427  loss_cls: 0.3119  loss_box_reg: 0.5607  loss_mask: 0.2934  loss_rpn_cls: 0.06358  loss_rpn_loc: 0.181  time: 0.6599  data_time: 0.0827  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:44:29 d2.utils.events]: \u001b[0m eta: 0:45:18  iter: 4439  total_loss: 1.402  loss_cls: 0.2945  loss_box_reg: 0.5521  loss_mask: 0.2746  loss_rpn_cls: 0.0501  loss_rpn_loc: 0.1897  time: 0.6592  data_time: 0.0620  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:44:44 d2.utils.events]: \u001b[0m eta: 0:45:10  iter: 4459  total_loss: 1.387  loss_cls: 0.3095  loss_box_reg: 0.5277  loss_mask: 0.3  loss_rpn_cls: 0.09872  loss_rpn_loc: 0.2012  time: 0.6595  data_time: 0.2359  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:45:01 d2.utils.events]: \u001b[0m eta: 0:45:00  iter: 4479  total_loss: 1.552  loss_cls: 0.381  loss_box_reg: 0.5831  loss_mask: 0.3111  loss_rpn_cls: 0.09024  loss_rpn_loc: 0.2188  time: 0.6605  data_time: 0.3857  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:45:14 d2.utils.events]: \u001b[0m eta: 0:44:49  iter: 4499  total_loss: 1.478  loss_cls: 0.3109  loss_box_reg: 0.5675  loss_mask: 0.2957  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.1865  time: 0.6604  data_time: 0.1823  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:45:28 d2.utils.events]: \u001b[0m eta: 0:44:40  iter: 4519  total_loss: 1.501  loss_cls: 0.3439  loss_box_reg: 0.5898  loss_mask: 0.3152  loss_rpn_cls: 0.09092  loss_rpn_loc: 0.2035  time: 0.6605  data_time: 0.1916  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:45:39 d2.utils.events]: \u001b[0m eta: 0:44:32  iter: 4539  total_loss: 1.401  loss_cls: 0.3152  loss_box_reg: 0.5556  loss_mask: 0.3047  loss_rpn_cls: 0.0756  loss_rpn_loc: 0.1778  time: 0.6601  data_time: 0.1045  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:45:52 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 4559  total_loss: 1.436  loss_cls: 0.3094  loss_box_reg: 0.5383  loss_mask: 0.3039  loss_rpn_cls: 0.07188  loss_rpn_loc: 0.1904  time: 0.6600  data_time: 0.1729  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:46:03 d2.utils.events]: \u001b[0m eta: 0:44:03  iter: 4579  total_loss: 1.359  loss_cls: 0.2986  loss_box_reg: 0.5416  loss_mask: 0.2883  loss_rpn_cls: 0.07256  loss_rpn_loc: 0.187  time: 0.6595  data_time: 0.1037  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:46:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:46:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:46:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:46:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:46:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:46:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0835 s/iter. Eval: 0.0478 s/iter. Total: 0.1319 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0854 s/iter. Eval: 0.0665 s/iter. Total: 0.1527 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0685 s/iter. Total: 0.1553 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0701 s/iter. Total: 0.1567 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:46:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.124807 (0.156248 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:46:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085664 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:46:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:46:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2698909097030425\n",
      "\u001b[32m[02/04 14:46:36 d2.utils.events]: \u001b[0m eta: 0:43:53  iter: 4599  total_loss: 1.381  loss_cls: 0.3128  loss_box_reg: 0.5246  loss_mask: 0.2948  loss_rpn_cls: 0.07698  loss_rpn_loc: 0.1822  time: 0.6594  data_time: 0.1689  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:46:51 d2.utils.events]: \u001b[0m eta: 0:43:49  iter: 4619  total_loss: 1.575  loss_cls: 0.3473  loss_box_reg: 0.5694  loss_mask: 0.3168  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.2135  time: 0.6599  data_time: 0.2924  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:47:05 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 4639  total_loss: 1.477  loss_cls: 0.3153  loss_box_reg: 0.5698  loss_mask: 0.3048  loss_rpn_cls: 0.09055  loss_rpn_loc: 0.1955  time: 0.6600  data_time: 0.1922  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:47:20 d2.utils.events]: \u001b[0m eta: 0:43:26  iter: 4659  total_loss: 1.505  loss_cls: 0.3379  loss_box_reg: 0.5401  loss_mask: 0.2978  loss_rpn_cls: 0.08219  loss_rpn_loc: 0.1946  time: 0.6603  data_time: 0.2540  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:47:35 d2.utils.events]: \u001b[0m eta: 0:43:21  iter: 4679  total_loss: 1.458  loss_cls: 0.309  loss_box_reg: 0.5682  loss_mask: 0.2866  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.1885  time: 0.6607  data_time: 0.2663  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:47:45 d2.utils.events]: \u001b[0m eta: 0:43:11  iter: 4699  total_loss: 1.33  loss_cls: 0.297  loss_box_reg: 0.5192  loss_mask: 0.2806  loss_rpn_cls: 0.06  loss_rpn_loc: 0.1766  time: 0.6601  data_time: 0.0637  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:47:58 d2.utils.events]: \u001b[0m eta: 0:43:02  iter: 4719  total_loss: 1.436  loss_cls: 0.3208  loss_box_reg: 0.5467  loss_mask: 0.2961  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.1948  time: 0.6601  data_time: 0.2063  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:48:08 d2.utils.events]: \u001b[0m eta: 0:42:49  iter: 4739  total_loss: 1.402  loss_cls: 0.2848  loss_box_reg: 0.5339  loss_mask: 0.2832  loss_rpn_cls: 0.07094  loss_rpn_loc: 0.1987  time: 0.6595  data_time: 0.0555  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:48:26 d2.utils.events]: \u001b[0m eta: 0:42:42  iter: 4759  total_loss: 1.466  loss_cls: 0.3497  loss_box_reg: 0.5633  loss_mask: 0.2963  loss_rpn_cls: 0.07369  loss_rpn_loc: 0.1886  time: 0.6605  data_time: 0.4127  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:48:42 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 4779  total_loss: 1.409  loss_cls: 0.2975  loss_box_reg: 0.5469  loss_mask: 0.3056  loss_rpn_cls: 0.08232  loss_rpn_loc: 0.1935  time: 0.6610  data_time: 0.3200  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:48:54 d2.utils.events]: \u001b[0m eta: 0:42:23  iter: 4799  total_loss: 1.345  loss_cls: 0.2935  loss_box_reg: 0.5481  loss_mask: 0.2847  loss_rpn_cls: 0.05979  loss_rpn_loc: 0.1643  time: 0.6607  data_time: 0.1205  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:49:07 d2.utils.events]: \u001b[0m eta: 0:42:13  iter: 4819  total_loss: 1.539  loss_cls: 0.3532  loss_box_reg: 0.5859  loss_mask: 0.3102  loss_rpn_cls: 0.08233  loss_rpn_loc: 0.2165  time: 0.6608  data_time: 0.2169  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:49:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:49:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:49:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:49:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:49:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:49:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0814 s/iter. Eval: 0.0465 s/iter. Total: 0.1285 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0662 s/iter. Total: 0.1515 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0846 s/iter. Eval: 0.0683 s/iter. Total: 0.1537 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0849 s/iter. Eval: 0.0704 s/iter. Total: 0.1562 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:49:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.132861 (0.156318 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:49:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085011 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:49:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:49:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.263330980007393\n",
      "\u001b[32m[02/04 14:49:40 d2.utils.events]: \u001b[0m eta: 0:41:59  iter: 4839  total_loss: 1.348  loss_cls: 0.2849  loss_box_reg: 0.563  loss_mask: 0.2966  loss_rpn_cls: 0.06126  loss_rpn_loc: 0.1797  time: 0.6608  data_time: 0.2011  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:49:52 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 4859  total_loss: 1.516  loss_cls: 0.3158  loss_box_reg: 0.5778  loss_mask: 0.3115  loss_rpn_cls: 0.09061  loss_rpn_loc: 0.1972  time: 0.6604  data_time: 0.1233  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:50:04 d2.utils.events]: \u001b[0m eta: 0:41:43  iter: 4879  total_loss: 1.468  loss_cls: 0.3368  loss_box_reg: 0.5494  loss_mask: 0.2867  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.1891  time: 0.6601  data_time: 0.1144  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:50:17 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 4899  total_loss: 1.348  loss_cls: 0.2888  loss_box_reg: 0.5312  loss_mask: 0.302  loss_rpn_cls: 0.0548  loss_rpn_loc: 0.1761  time: 0.6601  data_time: 0.1871  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:50:30 d2.utils.events]: \u001b[0m eta: 0:41:20  iter: 4919  total_loss: 1.369  loss_cls: 0.2856  loss_box_reg: 0.5398  loss_mask: 0.2927  loss_rpn_cls: 0.05752  loss_rpn_loc: 0.1854  time: 0.6600  data_time: 0.1766  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:50:45 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 4939  total_loss: 1.399  loss_cls: 0.3278  loss_box_reg: 0.5506  loss_mask: 0.3026  loss_rpn_cls: 0.0616  loss_rpn_loc: 0.1819  time: 0.6605  data_time: 0.3006  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:50:58 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 4959  total_loss: 1.497  loss_cls: 0.319  loss_box_reg: 0.5801  loss_mask: 0.3061  loss_rpn_cls: 0.08426  loss_rpn_loc: 0.1846  time: 0.6604  data_time: 0.1803  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:51:10 d2.utils.events]: \u001b[0m eta: 0:40:51  iter: 4979  total_loss: 1.476  loss_cls: 0.3043  loss_box_reg: 0.5656  loss_mask: 0.3039  loss_rpn_cls: 0.085  loss_rpn_loc: 0.2016  time: 0.6602  data_time: 0.1493  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:51:26 d2.utils.events]: \u001b[0m eta: 0:40:42  iter: 4999  total_loss: 1.542  loss_cls: 0.354  loss_box_reg: 0.5804  loss_mask: 0.3247  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.207  time: 0.6608  data_time: 0.3147  lr: 0.000256  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:51:40 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 5019  total_loss: 1.425  loss_cls: 0.3024  loss_box_reg: 0.5638  loss_mask: 0.2971  loss_rpn_cls: 0.07443  loss_rpn_loc: 0.196  time: 0.6610  data_time: 0.2415  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:51:51 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 5039  total_loss: 1.447  loss_cls: 0.3183  loss_box_reg: 0.5777  loss_mask: 0.3078  loss_rpn_cls: 0.07254  loss_rpn_loc: 0.1915  time: 0.6605  data_time: 0.0575  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:52:06 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 5059  total_loss: 1.421  loss_cls: 0.3439  loss_box_reg: 0.5372  loss_mask: 0.2932  loss_rpn_cls: 0.07733  loss_rpn_loc: 0.1858  time: 0.6608  data_time: 0.2931  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:52:20 d2.utils.events]: \u001b[0m eta: 0:40:05  iter: 5079  total_loss: 1.468  loss_cls: 0.3224  loss_box_reg: 0.5617  loss_mask: 0.301  loss_rpn_cls: 0.09148  loss_rpn_loc: 0.1993  time: 0.6609  data_time: 0.2117  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:52:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:52:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:52:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:52:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:52:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:52:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:52:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0810 s/iter. Eval: 0.0448 s/iter. Total: 0.1264 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 14:52:28 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0843 s/iter. Eval: 0.0646 s/iter. Total: 0.1497 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:52:33 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0843 s/iter. Eval: 0.0656 s/iter. Total: 0.1507 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:52:38 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0687 s/iter. Total: 0.1543 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:52:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.852658 (0.153902 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:52:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084671 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:52:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:52:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27164686446519637\n",
      "\u001b[32m[02/04 14:52:51 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 5099  total_loss: 1.379  loss_cls: 0.3034  loss_box_reg: 0.559  loss_mask: 0.2976  loss_rpn_cls: 0.06839  loss_rpn_loc: 0.1873  time: 0.6606  data_time: 0.1105  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:53:02 d2.utils.events]: \u001b[0m eta: 0:39:43  iter: 5119  total_loss: 1.468  loss_cls: 0.2965  loss_box_reg: 0.5578  loss_mask: 0.3093  loss_rpn_cls: 0.06817  loss_rpn_loc: 0.1846  time: 0.6602  data_time: 0.1156  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:53:17 d2.utils.events]: \u001b[0m eta: 0:39:40  iter: 5139  total_loss: 1.513  loss_cls: 0.3339  loss_box_reg: 0.5629  loss_mask: 0.2965  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1994  time: 0.6605  data_time: 0.2389  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:53:30 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 5159  total_loss: 1.479  loss_cls: 0.3207  loss_box_reg: 0.5512  loss_mask: 0.3052  loss_rpn_cls: 0.07525  loss_rpn_loc: 0.1926  time: 0.6606  data_time: 0.2001  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:53:42 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 5179  total_loss: 1.473  loss_cls: 0.3308  loss_box_reg: 0.5665  loss_mask: 0.3177  loss_rpn_cls: 0.07806  loss_rpn_loc: 0.1981  time: 0.6602  data_time: 0.1004  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:53:54 d2.utils.events]: \u001b[0m eta: 0:39:14  iter: 5199  total_loss: 1.44  loss_cls: 0.3196  loss_box_reg: 0.5546  loss_mask: 0.2942  loss_rpn_cls: 0.08075  loss_rpn_loc: 0.1951  time: 0.6601  data_time: 0.1378  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:54:06 d2.utils.events]: \u001b[0m eta: 0:39:05  iter: 5219  total_loss: 1.416  loss_cls: 0.3334  loss_box_reg: 0.5449  loss_mask: 0.2891  loss_rpn_cls: 0.08039  loss_rpn_loc: 0.1848  time: 0.6598  data_time: 0.1337  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:54:19 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 5239  total_loss: 1.398  loss_cls: 0.3011  loss_box_reg: 0.5417  loss_mask: 0.3059  loss_rpn_cls: 0.07203  loss_rpn_loc: 0.1792  time: 0.6598  data_time: 0.1877  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:54:33 d2.utils.events]: \u001b[0m eta: 0:38:42  iter: 5259  total_loss: 1.372  loss_cls: 0.333  loss_box_reg: 0.5469  loss_mask: 0.3028  loss_rpn_cls: 0.07627  loss_rpn_loc: 0.1855  time: 0.6599  data_time: 0.1953  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:54:46 d2.utils.events]: \u001b[0m eta: 0:38:34  iter: 5279  total_loss: 1.432  loss_cls: 0.2934  loss_box_reg: 0.5411  loss_mask: 0.3067  loss_rpn_cls: 0.06272  loss_rpn_loc: 0.1936  time: 0.6598  data_time: 0.1630  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:55:00 d2.utils.events]: \u001b[0m eta: 0:38:25  iter: 5299  total_loss: 1.389  loss_cls: 0.3137  loss_box_reg: 0.5466  loss_mask: 0.2845  loss_rpn_cls: 0.06818  loss_rpn_loc: 0.1768  time: 0.6600  data_time: 0.2312  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:55:14 d2.utils.events]: \u001b[0m eta: 0:38:16  iter: 5319  total_loss: 1.586  loss_cls: 0.3444  loss_box_reg: 0.5876  loss_mask: 0.3164  loss_rpn_cls: 0.09156  loss_rpn_loc: 0.216  time: 0.6602  data_time: 0.2281  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:55:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:55:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:55:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:55:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:55:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:55:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0814 s/iter. Eval: 0.0469 s/iter. Total: 0.1289 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0666 s/iter. Total: 0.1516 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0849 s/iter. Eval: 0.0688 s/iter. Total: 0.1546 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0852 s/iter. Eval: 0.0705 s/iter. Total: 0.1565 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:55:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.193195 (0.156838 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:55:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085486 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:55:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:55:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27019454289934375\n",
      "\u001b[32m[02/04 14:55:45 d2.utils.events]: \u001b[0m eta: 0:38:05  iter: 5339  total_loss: 1.413  loss_cls: 0.3222  loss_box_reg: 0.5562  loss_mask: 0.2951  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.1781  time: 0.6597  data_time: 0.0637  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:55:59 d2.utils.events]: \u001b[0m eta: 0:37:55  iter: 5359  total_loss: 1.436  loss_cls: 0.3219  loss_box_reg: 0.558  loss_mask: 0.2913  loss_rpn_cls: 0.08067  loss_rpn_loc: 0.2044  time: 0.6599  data_time: 0.2434  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:56:12 d2.utils.events]: \u001b[0m eta: 0:37:44  iter: 5379  total_loss: 1.486  loss_cls: 0.3391  loss_box_reg: 0.5493  loss_mask: 0.3049  loss_rpn_cls: 0.07838  loss_rpn_loc: 0.1874  time: 0.6599  data_time: 0.1672  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:56:25 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 5399  total_loss: 1.438  loss_cls: 0.3007  loss_box_reg: 0.5519  loss_mask: 0.2857  loss_rpn_cls: 0.0866  loss_rpn_loc: 0.1918  time: 0.6598  data_time: 0.1717  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:56:39 d2.utils.events]: \u001b[0m eta: 0:37:24  iter: 5419  total_loss: 1.457  loss_cls: 0.3175  loss_box_reg: 0.5366  loss_mask: 0.3027  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.1834  time: 0.6600  data_time: 0.2489  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:56:53 d2.utils.events]: \u001b[0m eta: 0:37:17  iter: 5439  total_loss: 1.512  loss_cls: 0.2979  loss_box_reg: 0.553  loss_mask: 0.3139  loss_rpn_cls: 0.07005  loss_rpn_loc: 0.2128  time: 0.6602  data_time: 0.2432  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:57:06 d2.utils.events]: \u001b[0m eta: 0:37:07  iter: 5459  total_loss: 1.375  loss_cls: 0.2824  loss_box_reg: 0.5419  loss_mask: 0.3113  loss_rpn_cls: 0.0479  loss_rpn_loc: 0.1779  time: 0.6601  data_time: 0.1817  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:57:19 d2.utils.events]: \u001b[0m eta: 0:36:56  iter: 5479  total_loss: 1.396  loss_cls: 0.3078  loss_box_reg: 0.5653  loss_mask: 0.3089  loss_rpn_cls: 0.04926  loss_rpn_loc: 0.1832  time: 0.6600  data_time: 0.1438  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:57:33 d2.utils.events]: \u001b[0m eta: 0:36:45  iter: 5499  total_loss: 1.464  loss_cls: 0.3191  loss_box_reg: 0.5507  loss_mask: 0.3033  loss_rpn_cls: 0.08016  loss_rpn_loc: 0.2009  time: 0.6602  data_time: 0.2478  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:57:46 d2.utils.events]: \u001b[0m eta: 0:36:34  iter: 5519  total_loss: 1.324  loss_cls: 0.2726  loss_box_reg: 0.5488  loss_mask: 0.3091  loss_rpn_cls: 0.06066  loss_rpn_loc: 0.1804  time: 0.6602  data_time: 0.2238  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:57:56 d2.utils.events]: \u001b[0m eta: 0:36:19  iter: 5539  total_loss: 1.363  loss_cls: 0.3104  loss_box_reg: 0.5328  loss_mask: 0.2768  loss_rpn_cls: 0.06497  loss_rpn_loc: 0.1751  time: 0.6596  data_time: 0.0465  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:58:09 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 5559  total_loss: 1.492  loss_cls: 0.3296  loss_box_reg: 0.553  loss_mask: 0.3092  loss_rpn_cls: 0.09382  loss_rpn_loc: 0.1957  time: 0.6596  data_time: 0.1902  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:58:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 14:58:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 14:58:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 14:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 14:58:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 14:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0812 s/iter. Eval: 0.0483 s/iter. Total: 0.1302 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 14:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0836 s/iter. Eval: 0.0666 s/iter. Total: 0.1510 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 14:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0007 s/iter. Inference: 0.0841 s/iter. Eval: 0.0690 s/iter. Total: 0.1538 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 14:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0706 s/iter. Total: 0.1558 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 14:58:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.027281 (0.155408 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:58:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084305 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 14:58:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 14:58:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26500550798719424\n",
      "\u001b[32m[02/04 14:58:41 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 5579  total_loss: 1.435  loss_cls: 0.3175  loss_box_reg: 0.5549  loss_mask: 0.3031  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.1838  time: 0.6593  data_time: 0.1330  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:58:53 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 5599  total_loss: 1.362  loss_cls: 0.2754  loss_box_reg: 0.5206  loss_mask: 0.2874  loss_rpn_cls: 0.04361  loss_rpn_loc: 0.1727  time: 0.6592  data_time: 0.1518  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:59:10 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 5619  total_loss: 1.449  loss_cls: 0.3315  loss_box_reg: 0.558  loss_mask: 0.3075  loss_rpn_cls: 0.07764  loss_rpn_loc: 0.1902  time: 0.6598  data_time: 0.3384  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:59:24 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 5639  total_loss: 1.44  loss_cls: 0.3281  loss_box_reg: 0.5282  loss_mask: 0.2933  loss_rpn_cls: 0.07253  loss_rpn_loc: 0.1978  time: 0.6600  data_time: 0.2334  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:59:39 d2.utils.events]: \u001b[0m eta: 0:35:18  iter: 5659  total_loss: 1.413  loss_cls: 0.3109  loss_box_reg: 0.5476  loss_mask: 0.305  loss_rpn_cls: 0.07462  loss_rpn_loc: 0.1891  time: 0.6603  data_time: 0.2669  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 14:59:52 d2.utils.events]: \u001b[0m eta: 0:35:05  iter: 5679  total_loss: 1.424  loss_cls: 0.3314  loss_box_reg: 0.5379  loss_mask: 0.2901  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.1743  time: 0.6602  data_time: 0.1684  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:00:08 d2.utils.events]: \u001b[0m eta: 0:35:02  iter: 5699  total_loss: 1.516  loss_cls: 0.3356  loss_box_reg: 0.5823  loss_mask: 0.3226  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.1895  time: 0.6607  data_time: 0.2868  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:00:21 d2.utils.events]: \u001b[0m eta: 0:34:55  iter: 5719  total_loss: 1.487  loss_cls: 0.3298  loss_box_reg: 0.5608  loss_mask: 0.3042  loss_rpn_cls: 0.08028  loss_rpn_loc: 0.1863  time: 0.6607  data_time: 0.1953  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:00:35 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 5739  total_loss: 1.324  loss_cls: 0.2968  loss_box_reg: 0.5204  loss_mask: 0.2849  loss_rpn_cls: 0.06064  loss_rpn_loc: 0.1873  time: 0.6609  data_time: 0.2506  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:00:46 d2.utils.events]: \u001b[0m eta: 0:34:32  iter: 5759  total_loss: 1.379  loss_cls: 0.2874  loss_box_reg: 0.5342  loss_mask: 0.2951  loss_rpn_cls: 0.05365  loss_rpn_loc: 0.1801  time: 0.6604  data_time: 0.0524  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:00:57 d2.utils.events]: \u001b[0m eta: 0:34:22  iter: 5779  total_loss: 1.414  loss_cls: 0.3115  loss_box_reg: 0.5635  loss_mask: 0.3135  loss_rpn_cls: 0.05476  loss_rpn_loc: 0.1936  time: 0.6600  data_time: 0.1050  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:01:09 d2.utils.events]: \u001b[0m eta: 0:34:12  iter: 5799  total_loss: 1.429  loss_cls: 0.3018  loss_box_reg: 0.5673  loss_mask: 0.2932  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.1849  time: 0.6598  data_time: 0.1351  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:01:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:01:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:01:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:01:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:01:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:01:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0825 s/iter. Eval: 0.0448 s/iter. Total: 0.1279 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 15:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0666 s/iter. Total: 0.1539 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0694 s/iter. Total: 0.1567 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:01:32 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0712 s/iter. Total: 0.1583 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:01:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.315136 (0.157889 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:01:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.086187 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:01:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:01:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27025879534374636\n",
      "\u001b[32m[02/04 15:01:41 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 5819  total_loss: 1.417  loss_cls: 0.2921  loss_box_reg: 0.5465  loss_mask: 0.2957  loss_rpn_cls: 0.08741  loss_rpn_loc: 0.1957  time: 0.6597  data_time: 0.1542  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:01:55 d2.utils.events]: \u001b[0m eta: 0:33:52  iter: 5839  total_loss: 1.406  loss_cls: 0.3156  loss_box_reg: 0.5609  loss_mask: 0.2828  loss_rpn_cls: 0.06467  loss_rpn_loc: 0.1815  time: 0.6597  data_time: 0.1951  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:02:07 d2.utils.events]: \u001b[0m eta: 0:33:43  iter: 5859  total_loss: 1.385  loss_cls: 0.3074  loss_box_reg: 0.5477  loss_mask: 0.2965  loss_rpn_cls: 0.07968  loss_rpn_loc: 0.185  time: 0.6596  data_time: 0.1730  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:02:24 d2.utils.events]: \u001b[0m eta: 0:33:36  iter: 5879  total_loss: 1.537  loss_cls: 0.3419  loss_box_reg: 0.5554  loss_mask: 0.3008  loss_rpn_cls: 0.0888  loss_rpn_loc: 0.2024  time: 0.6601  data_time: 0.3086  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:02:38 d2.utils.events]: \u001b[0m eta: 0:33:31  iter: 5899  total_loss: 1.371  loss_cls: 0.3058  loss_box_reg: 0.4982  loss_mask: 0.2948  loss_rpn_cls: 0.07846  loss_rpn_loc: 0.1862  time: 0.6604  data_time: 0.2672  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:02:52 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 5919  total_loss: 1.47  loss_cls: 0.3141  loss_box_reg: 0.5583  loss_mask: 0.3016  loss_rpn_cls: 0.08451  loss_rpn_loc: 0.2137  time: 0.6605  data_time: 0.2082  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:03:06 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 5939  total_loss: 1.426  loss_cls: 0.3022  loss_box_reg: 0.5477  loss_mask: 0.302  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.1912  time: 0.6606  data_time: 0.2411  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:03:18 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 5959  total_loss: 1.39  loss_cls: 0.3189  loss_box_reg: 0.5397  loss_mask: 0.2939  loss_rpn_cls: 0.06258  loss_rpn_loc: 0.1883  time: 0.6603  data_time: 0.1220  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:03:28 d2.utils.events]: \u001b[0m eta: 0:32:53  iter: 5979  total_loss: 1.464  loss_cls: 0.3068  loss_box_reg: 0.5646  loss_mask: 0.3054  loss_rpn_cls: 0.06752  loss_rpn_loc: 0.192  time: 0.6599  data_time: 0.0753  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:03:40 d2.utils.events]: \u001b[0m eta: 0:32:41  iter: 5999  total_loss: 1.408  loss_cls: 0.2996  loss_box_reg: 0.5531  loss_mask: 0.3021  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.1961  time: 0.6597  data_time: 0.1498  lr: 0.0002048  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:03:53 d2.utils.events]: \u001b[0m eta: 0:32:29  iter: 6019  total_loss: 1.479  loss_cls: 0.3204  loss_box_reg: 0.5681  loss_mask: 0.3027  loss_rpn_cls: 0.06786  loss_rpn_loc: 0.1925  time: 0.6597  data_time: 0.2041  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:04:05 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 6039  total_loss: 1.387  loss_cls: 0.3141  loss_box_reg: 0.5491  loss_mask: 0.2822  loss_rpn_cls: 0.05191  loss_rpn_loc: 0.1792  time: 0.6594  data_time: 0.1240  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:04:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:04:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:04:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:04:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:04:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:04:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0814 s/iter. Eval: 0.0497 s/iter. Total: 0.1317 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 15:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0010 s/iter. Inference: 0.0837 s/iter. Eval: 0.0676 s/iter. Total: 0.1523 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0009 s/iter. Inference: 0.0836 s/iter. Eval: 0.0688 s/iter. Total: 0.1533 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0715 s/iter. Total: 0.1563 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:04:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.119964 (0.156207 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:04:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083936 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:04:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:04:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2695249082096839\n",
      "\u001b[32m[02/04 15:04:36 d2.utils.events]: \u001b[0m eta: 0:32:03  iter: 6059  total_loss: 1.493  loss_cls: 0.318  loss_box_reg: 0.5673  loss_mask: 0.3041  loss_rpn_cls: 0.07922  loss_rpn_loc: 0.2213  time: 0.6591  data_time: 0.1199  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:04:50 d2.utils.events]: \u001b[0m eta: 0:31:56  iter: 6079  total_loss: 1.453  loss_cls: 0.319  loss_box_reg: 0.5623  loss_mask: 0.2941  loss_rpn_cls: 0.07477  loss_rpn_loc: 0.1895  time: 0.6592  data_time: 0.1904  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:04:59 d2.utils.events]: \u001b[0m eta: 0:31:41  iter: 6099  total_loss: 1.414  loss_cls: 0.2869  loss_box_reg: 0.5491  loss_mask: 0.2956  loss_rpn_cls: 0.04577  loss_rpn_loc: 0.1851  time: 0.6586  data_time: 0.0431  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:05:12 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 6119  total_loss: 1.35  loss_cls: 0.2893  loss_box_reg: 0.5245  loss_mask: 0.2839  loss_rpn_cls: 0.05974  loss_rpn_loc: 0.1762  time: 0.6585  data_time: 0.1884  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:05:28 d2.utils.events]: \u001b[0m eta: 0:31:20  iter: 6139  total_loss: 1.547  loss_cls: 0.3592  loss_box_reg: 0.5785  loss_mask: 0.3134  loss_rpn_cls: 0.08545  loss_rpn_loc: 0.1937  time: 0.6590  data_time: 0.3088  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:05:41 d2.utils.events]: \u001b[0m eta: 0:31:09  iter: 6159  total_loss: 1.375  loss_cls: 0.2995  loss_box_reg: 0.5162  loss_mask: 0.2992  loss_rpn_cls: 0.07043  loss_rpn_loc: 0.1818  time: 0.6589  data_time: 0.1853  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:05:54 d2.utils.events]: \u001b[0m eta: 0:31:00  iter: 6179  total_loss: 1.412  loss_cls: 0.3079  loss_box_reg: 0.5482  loss_mask: 0.3082  loss_rpn_cls: 0.07159  loss_rpn_loc: 0.191  time: 0.6588  data_time: 0.1587  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:06:08 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 6199  total_loss: 1.473  loss_cls: 0.3271  loss_box_reg: 0.5422  loss_mask: 0.3059  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.1899  time: 0.6590  data_time: 0.2461  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:06:20 d2.utils.events]: \u001b[0m eta: 0:30:40  iter: 6219  total_loss: 1.413  loss_cls: 0.3146  loss_box_reg: 0.5201  loss_mask: 0.2868  loss_rpn_cls: 0.09105  loss_rpn_loc: 0.1857  time: 0.6589  data_time: 0.1559  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:06:35 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 6239  total_loss: 1.425  loss_cls: 0.3118  loss_box_reg: 0.5372  loss_mask: 0.3031  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1953  time: 0.6591  data_time: 0.2426  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:06:48 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 6259  total_loss: 1.421  loss_cls: 0.3254  loss_box_reg: 0.5561  loss_mask: 0.3087  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.1903  time: 0.6590  data_time: 0.1925  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:07:00 d2.utils.events]: \u001b[0m eta: 0:30:09  iter: 6279  total_loss: 1.448  loss_cls: 0.3146  loss_box_reg: 0.552  loss_mask: 0.3004  loss_rpn_cls: 0.06787  loss_rpn_loc: 0.1889  time: 0.6589  data_time: 0.1560  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:07:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:07:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:07:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:07:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:07:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:07:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0897 s/iter. Eval: 0.0512 s/iter. Total: 0.1416 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 15:07:14 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0871 s/iter. Eval: 0.0661 s/iter. Total: 0.1540 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:07:19 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0685 s/iter. Total: 0.1552 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0700 s/iter. Total: 0.1564 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:07:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.090084 (0.155949 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:07:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085367 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:07:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:07:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2729620333677678\n",
      "\u001b[32m[02/04 15:07:32 d2.utils.events]: \u001b[0m eta: 0:29:58  iter: 6299  total_loss: 1.446  loss_cls: 0.3308  loss_box_reg: 0.5388  loss_mask: 0.3008  loss_rpn_cls: 0.07157  loss_rpn_loc: 0.2027  time: 0.6587  data_time: 0.0967  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:07:43 d2.utils.events]: \u001b[0m eta: 0:29:49  iter: 6319  total_loss: 1.384  loss_cls: 0.3085  loss_box_reg: 0.5328  loss_mask: 0.2983  loss_rpn_cls: 0.06963  loss_rpn_loc: 0.1854  time: 0.6584  data_time: 0.1063  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:07:59 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 6339  total_loss: 1.546  loss_cls: 0.3245  loss_box_reg: 0.5725  loss_mask: 0.306  loss_rpn_cls: 0.09333  loss_rpn_loc: 0.2015  time: 0.6589  data_time: 0.3293  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:08:12 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 6359  total_loss: 1.425  loss_cls: 0.2961  loss_box_reg: 0.5676  loss_mask: 0.321  loss_rpn_cls: 0.06435  loss_rpn_loc: 0.1807  time: 0.6588  data_time: 0.1641  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:08:25 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 6379  total_loss: 1.333  loss_cls: 0.3112  loss_box_reg: 0.538  loss_mask: 0.2938  loss_rpn_cls: 0.06298  loss_rpn_loc: 0.1803  time: 0.6588  data_time: 0.1898  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:08:39 d2.utils.events]: \u001b[0m eta: 0:29:08  iter: 6399  total_loss: 1.462  loss_cls: 0.3169  loss_box_reg: 0.5413  loss_mask: 0.2944  loss_rpn_cls: 0.0838  loss_rpn_loc: 0.1981  time: 0.6589  data_time: 0.2331  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:08:51 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 6419  total_loss: 1.381  loss_cls: 0.3052  loss_box_reg: 0.5542  loss_mask: 0.2918  loss_rpn_cls: 0.06299  loss_rpn_loc: 0.1705  time: 0.6587  data_time: 0.1201  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:09:02 d2.utils.events]: \u001b[0m eta: 0:28:47  iter: 6439  total_loss: 1.388  loss_cls: 0.3022  loss_box_reg: 0.5471  loss_mask: 0.2917  loss_rpn_cls: 0.06988  loss_rpn_loc: 0.1732  time: 0.6584  data_time: 0.0873  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:09:15 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 6459  total_loss: 1.409  loss_cls: 0.2833  loss_box_reg: 0.5294  loss_mask: 0.2932  loss_rpn_cls: 0.06874  loss_rpn_loc: 0.18  time: 0.6583  data_time: 0.1616  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:09:30 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 6479  total_loss: 1.491  loss_cls: 0.3228  loss_box_reg: 0.551  loss_mask: 0.2971  loss_rpn_cls: 0.08812  loss_rpn_loc: 0.1853  time: 0.6587  data_time: 0.2959  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:09:43 d2.utils.events]: \u001b[0m eta: 0:28:19  iter: 6499  total_loss: 1.554  loss_cls: 0.3766  loss_box_reg: 0.5537  loss_mask: 0.3076  loss_rpn_cls: 0.09303  loss_rpn_loc: 0.1944  time: 0.6586  data_time: 0.1721  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:09:56 d2.utils.events]: \u001b[0m eta: 0:28:10  iter: 6519  total_loss: 1.427  loss_cls: 0.2959  loss_box_reg: 0.5503  loss_mask: 0.312  loss_rpn_cls: 0.06857  loss_rpn_loc: 0.1903  time: 0.6586  data_time: 0.2005  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:10:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:10:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:10:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:10:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:10:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:10:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0819 s/iter. Eval: 0.0486 s/iter. Total: 0.1311 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 15:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0840 s/iter. Eval: 0.0670 s/iter. Total: 0.1517 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0682 s/iter. Total: 0.1531 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0710 s/iter. Total: 0.1563 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:10:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.144936 (0.156422 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:10:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084640 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:10:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:10:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2682215297944182\n",
      "\u001b[32m[02/04 15:10:29 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 6539  total_loss: 1.428  loss_cls: 0.3122  loss_box_reg: 0.5577  loss_mask: 0.296  loss_rpn_cls: 0.06882  loss_rpn_loc: 0.1873  time: 0.6586  data_time: 0.1804  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:10:44 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 6559  total_loss: 1.528  loss_cls: 0.3379  loss_box_reg: 0.5631  loss_mask: 0.3156  loss_rpn_cls: 0.09075  loss_rpn_loc: 0.2178  time: 0.6589  data_time: 0.2736  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:10:57 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 6579  total_loss: 1.398  loss_cls: 0.3078  loss_box_reg: 0.5245  loss_mask: 0.2926  loss_rpn_cls: 0.08734  loss_rpn_loc: 0.1837  time: 0.6589  data_time: 0.1801  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:11:10 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 6599  total_loss: 1.405  loss_cls: 0.3215  loss_box_reg: 0.5571  loss_mask: 0.2924  loss_rpn_cls: 0.0676  loss_rpn_loc: 0.1732  time: 0.6587  data_time: 0.1714  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:11:20 d2.utils.events]: \u001b[0m eta: 0:27:23  iter: 6619  total_loss: 1.38  loss_cls: 0.3116  loss_box_reg: 0.5543  loss_mask: 0.2908  loss_rpn_cls: 0.05757  loss_rpn_loc: 0.178  time: 0.6582  data_time: 0.0470  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:11:32 d2.utils.events]: \u001b[0m eta: 0:27:11  iter: 6639  total_loss: 1.471  loss_cls: 0.3029  loss_box_reg: 0.5491  loss_mask: 0.3127  loss_rpn_cls: 0.08046  loss_rpn_loc: 0.1864  time: 0.6581  data_time: 0.1704  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:11:46 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 6659  total_loss: 1.471  loss_cls: 0.3244  loss_box_reg: 0.5676  loss_mask: 0.3047  loss_rpn_cls: 0.09397  loss_rpn_loc: 0.1992  time: 0.6583  data_time: 0.2356  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:11:59 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 6679  total_loss: 1.405  loss_cls: 0.3193  loss_box_reg: 0.5371  loss_mask: 0.2918  loss_rpn_cls: 0.06472  loss_rpn_loc: 0.1845  time: 0.6582  data_time: 0.1644  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:12:12 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 6699  total_loss: 1.402  loss_cls: 0.3118  loss_box_reg: 0.5391  loss_mask: 0.3028  loss_rpn_cls: 0.06414  loss_rpn_loc: 0.1829  time: 0.6582  data_time: 0.1606  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:12:25 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 6719  total_loss: 1.469  loss_cls: 0.3155  loss_box_reg: 0.5644  loss_mask: 0.3019  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.2021  time: 0.6582  data_time: 0.1770  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:12:38 d2.utils.events]: \u001b[0m eta: 0:26:22  iter: 6739  total_loss: 1.449  loss_cls: 0.2982  loss_box_reg: 0.5442  loss_mask: 0.2966  loss_rpn_cls: 0.08454  loss_rpn_loc: 0.1984  time: 0.6582  data_time: 0.1908  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:12:53 d2.utils.events]: \u001b[0m eta: 0:26:13  iter: 6759  total_loss: 1.472  loss_cls: 0.3311  loss_box_reg: 0.5631  loss_mask: 0.3018  loss_rpn_cls: 0.08419  loss_rpn_loc: 0.1954  time: 0.6585  data_time: 0.2770  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:13:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:13:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:13:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:13:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:13:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:13:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0556 s/iter. Total: 0.1397 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 15:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0851 s/iter. Eval: 0.0691 s/iter. Total: 0.1550 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0850 s/iter. Eval: 0.0711 s/iter. Total: 0.1569 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0853 s/iter. Eval: 0.0738 s/iter. Total: 0.1599 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:13:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.617308 (0.160494 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:13:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085786 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:13:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:13:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2676109822226298\n",
      "\u001b[32m[02/04 15:13:27 d2.utils.events]: \u001b[0m eta: 0:26:04  iter: 6779  total_loss: 1.39  loss_cls: 0.2978  loss_box_reg: 0.5137  loss_mask: 0.3008  loss_rpn_cls: 0.08411  loss_rpn_loc: 0.1672  time: 0.6584  data_time: 0.1709  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:13:38 d2.utils.events]: \u001b[0m eta: 0:25:53  iter: 6799  total_loss: 1.42  loss_cls: 0.324  loss_box_reg: 0.5186  loss_mask: 0.2984  loss_rpn_cls: 0.08066  loss_rpn_loc: 0.1869  time: 0.6582  data_time: 0.1341  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:13:50 d2.utils.events]: \u001b[0m eta: 0:25:43  iter: 6819  total_loss: 1.398  loss_cls: 0.3106  loss_box_reg: 0.5084  loss_mask: 0.2935  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.1791  time: 0.6580  data_time: 0.1257  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:14:03 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 6839  total_loss: 1.45  loss_cls: 0.3295  loss_box_reg: 0.5398  loss_mask: 0.2888  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1862  time: 0.6580  data_time: 0.1879  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:14:17 d2.utils.events]: \u001b[0m eta: 0:25:24  iter: 6859  total_loss: 1.376  loss_cls: 0.3074  loss_box_reg: 0.5284  loss_mask: 0.2879  loss_rpn_cls: 0.07997  loss_rpn_loc: 0.1828  time: 0.6581  data_time: 0.2404  lr: 0.00016384  max_mem: 6885M\n",
      "\u001b[32m[02/04 15:14:30 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 6879  total_loss: 1.457  loss_cls: 0.266  loss_box_reg: 0.5535  loss_mask: 0.3144  loss_rpn_cls: 0.04601  loss_rpn_loc: 0.1969  time: 0.6581  data_time: 0.1903  lr: 0.00016384  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:14:42 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 6899  total_loss: 1.448  loss_cls: 0.3151  loss_box_reg: 0.5617  loss_mask: 0.2981  loss_rpn_cls: 0.07682  loss_rpn_loc: 0.2024  time: 0.6579  data_time: 0.1378  lr: 0.00016384  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:14:54 d2.utils.events]: \u001b[0m eta: 0:24:51  iter: 6919  total_loss: 1.429  loss_cls: 0.3152  loss_box_reg: 0.563  loss_mask: 0.2978  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.1813  time: 0.6578  data_time: 0.1492  lr: 0.00016384  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:15:09 d2.utils.events]: \u001b[0m eta: 0:24:42  iter: 6939  total_loss: 1.395  loss_cls: 0.3014  loss_box_reg: 0.5152  loss_mask: 0.3  loss_rpn_cls: 0.06402  loss_rpn_loc: 0.1838  time: 0.6579  data_time: 0.2450  lr: 0.00016384  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:15:19 d2.utils.events]: \u001b[0m eta: 0:24:32  iter: 6959  total_loss: 1.356  loss_cls: 0.2617  loss_box_reg: 0.5694  loss_mask: 0.293  loss_rpn_cls: 0.05836  loss_rpn_loc: 0.1755  time: 0.6575  data_time: 0.0617  lr: 0.00016384  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:15:36 d2.utils.events]: \u001b[0m eta: 0:24:24  iter: 6979  total_loss: 1.495  loss_cls: 0.3469  loss_box_reg: 0.5617  loss_mask: 0.3172  loss_rpn_cls: 0.08287  loss_rpn_loc: 0.202  time: 0.6581  data_time: 0.3782  lr: 0.00016384  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:15:49 d2.utils.events]: \u001b[0m eta: 0:24:15  iter: 6999  total_loss: 1.411  loss_cls: 0.3218  loss_box_reg: 0.5241  loss_mask: 0.3086  loss_rpn_cls: 0.08796  loss_rpn_loc: 0.2011  time: 0.6581  data_time: 0.1758  lr: 0.00016384  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:16:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:16:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:16:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:16:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:16:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:16:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0821 s/iter. Eval: 0.0548 s/iter. Total: 0.1377 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 15:16:08 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0676 s/iter. Total: 0.1525 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0695 s/iter. Total: 0.1543 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0717 s/iter. Total: 0.1567 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:16:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.149885 (0.156465 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:16:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084223 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:16:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:16:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2681432388413758\n",
      "\u001b[32m[02/04 15:16:21 d2.utils.events]: \u001b[0m eta: 0:24:06  iter: 7019  total_loss: 1.478  loss_cls: 0.2872  loss_box_reg: 0.5586  loss_mask: 0.3139  loss_rpn_cls: 0.09613  loss_rpn_loc: 0.1914  time: 0.6579  data_time: 0.1336  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:16:36 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 7039  total_loss: 1.588  loss_cls: 0.3617  loss_box_reg: 0.5905  loss_mask: 0.3305  loss_rpn_cls: 0.09036  loss_rpn_loc: 0.2119  time: 0.6581  data_time: 0.2634  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:16:53 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 7059  total_loss: 1.516  loss_cls: 0.3336  loss_box_reg: 0.5734  loss_mask: 0.3149  loss_rpn_cls: 0.0927  loss_rpn_loc: 0.213  time: 0.6587  data_time: 0.3979  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:17:07 d2.utils.events]: \u001b[0m eta: 0:23:40  iter: 7079  total_loss: 1.416  loss_cls: 0.2838  loss_box_reg: 0.5549  loss_mask: 0.3045  loss_rpn_cls: 0.04825  loss_rpn_loc: 0.1852  time: 0.6588  data_time: 0.2074  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:17:18 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 7099  total_loss: 1.431  loss_cls: 0.2951  loss_box_reg: 0.5348  loss_mask: 0.2931  loss_rpn_cls: 0.05942  loss_rpn_loc: 0.1853  time: 0.6585  data_time: 0.1026  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:17:31 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 7119  total_loss: 1.481  loss_cls: 0.33  loss_box_reg: 0.5593  loss_mask: 0.3048  loss_rpn_cls: 0.08415  loss_rpn_loc: 0.196  time: 0.6585  data_time: 0.1796  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:17:44 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 7139  total_loss: 1.375  loss_cls: 0.2977  loss_box_reg: 0.5148  loss_mask: 0.2963  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.1789  time: 0.6585  data_time: 0.2205  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:17:59 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 7159  total_loss: 1.35  loss_cls: 0.3092  loss_box_reg: 0.5285  loss_mask: 0.2851  loss_rpn_cls: 0.072  loss_rpn_loc: 0.1769  time: 0.6587  data_time: 0.2117  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:18:10 d2.utils.events]: \u001b[0m eta: 0:22:53  iter: 7179  total_loss: 1.398  loss_cls: 0.302  loss_box_reg: 0.5576  loss_mask: 0.2987  loss_rpn_cls: 0.06982  loss_rpn_loc: 0.1838  time: 0.6584  data_time: 0.0920  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:18:23 d2.utils.events]: \u001b[0m eta: 0:22:44  iter: 7199  total_loss: 1.329  loss_cls: 0.2949  loss_box_reg: 0.5208  loss_mask: 0.2917  loss_rpn_cls: 0.04909  loss_rpn_loc: 0.1848  time: 0.6584  data_time: 0.2022  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:18:35 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 7219  total_loss: 1.38  loss_cls: 0.3127  loss_box_reg: 0.5361  loss_mask: 0.2896  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.1732  time: 0.6582  data_time: 0.1208  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:18:50 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 7239  total_loss: 1.535  loss_cls: 0.342  loss_box_reg: 0.5539  loss_mask: 0.3008  loss_rpn_cls: 0.09264  loss_rpn_loc: 0.1889  time: 0.6584  data_time: 0.2750  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:19:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:19:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:19:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:19:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:19:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:19:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0822 s/iter. Eval: 0.0506 s/iter. Total: 0.1336 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 15:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0673 s/iter. Total: 0.1521 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0690 s/iter. Total: 0.1543 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0847 s/iter. Eval: 0.0711 s/iter. Total: 0.1566 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:19:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.155743 (0.156515 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:19:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084648 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:19:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:19:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27476035245853675\n",
      "\u001b[32m[02/04 15:19:22 d2.utils.events]: \u001b[0m eta: 0:22:14  iter: 7259  total_loss: 1.424  loss_cls: 0.3146  loss_box_reg: 0.5456  loss_mask: 0.2863  loss_rpn_cls: 0.07387  loss_rpn_loc: 0.2027  time: 0.6583  data_time: 0.1773  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:19:36 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 7279  total_loss: 1.36  loss_cls: 0.2906  loss_box_reg: 0.5418  loss_mask: 0.2904  loss_rpn_cls: 0.0693  loss_rpn_loc: 0.1778  time: 0.6584  data_time: 0.1949  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:19:51 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 7299  total_loss: 1.523  loss_cls: 0.3518  loss_box_reg: 0.5487  loss_mask: 0.3039  loss_rpn_cls: 0.0847  loss_rpn_loc: 0.2002  time: 0.6586  data_time: 0.2755  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:20:06 d2.utils.events]: \u001b[0m eta: 0:21:49  iter: 7319  total_loss: 1.553  loss_cls: 0.328  loss_box_reg: 0.5593  loss_mask: 0.3198  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.2073  time: 0.6589  data_time: 0.2903  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:20:22 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 7339  total_loss: 1.58  loss_cls: 0.3764  loss_box_reg: 0.5715  loss_mask: 0.3188  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2106  time: 0.6594  data_time: 0.3344  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:20:33 d2.utils.events]: \u001b[0m eta: 0:21:32  iter: 7359  total_loss: 1.307  loss_cls: 0.2658  loss_box_reg: 0.5282  loss_mask: 0.2783  loss_rpn_cls: 0.05505  loss_rpn_loc: 0.1663  time: 0.6591  data_time: 0.0856  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:20:47 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 7379  total_loss: 1.316  loss_cls: 0.2695  loss_box_reg: 0.5246  loss_mask: 0.3022  loss_rpn_cls: 0.0614  loss_rpn_loc: 0.1819  time: 0.6591  data_time: 0.2177  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:20:59 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 7399  total_loss: 1.465  loss_cls: 0.3171  loss_box_reg: 0.5716  loss_mask: 0.3085  loss_rpn_cls: 0.07632  loss_rpn_loc: 0.1879  time: 0.6590  data_time: 0.1645  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:21:10 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 7419  total_loss: 1.401  loss_cls: 0.2873  loss_box_reg: 0.5649  loss_mask: 0.3134  loss_rpn_cls: 0.06152  loss_rpn_loc: 0.1788  time: 0.6587  data_time: 0.1193  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:21:24 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 7439  total_loss: 1.338  loss_cls: 0.3018  loss_box_reg: 0.5369  loss_mask: 0.2941  loss_rpn_cls: 0.06705  loss_rpn_loc: 0.1712  time: 0.6588  data_time: 0.2028  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:21:34 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 7459  total_loss: 1.436  loss_cls: 0.3052  loss_box_reg: 0.5573  loss_mask: 0.2947  loss_rpn_cls: 0.07766  loss_rpn_loc: 0.1837  time: 0.6584  data_time: 0.0320  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:21:46 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 7479  total_loss: 1.45  loss_cls: 0.3334  loss_box_reg: 0.5668  loss_mask: 0.3144  loss_rpn_cls: 0.05951  loss_rpn_loc: 0.1971  time: 0.6583  data_time: 0.1498  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:21:57 d2.utils.events]: \u001b[0m eta: 0:20:19  iter: 7499  total_loss: 1.349  loss_cls: 0.3155  loss_box_reg: 0.5244  loss_mask: 0.294  loss_rpn_cls: 0.06535  loss_rpn_loc: 0.1784  time: 0.6579  data_time: 0.0728  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:22:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:22:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:22:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:22:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:22:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:22:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0582 s/iter. Total: 0.1457 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0673 s/iter. Total: 0.1547 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0689 s/iter. Total: 0.1557 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0008 s/iter. Inference: 0.0854 s/iter. Eval: 0.0706 s/iter. Total: 0.1569 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:22:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.225419 (0.157116 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:22:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085272 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:22:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:22:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2729566358916704\n",
      "\u001b[32m[02/04 15:22:31 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 7519  total_loss: 1.376  loss_cls: 0.2908  loss_box_reg: 0.5514  loss_mask: 0.296  loss_rpn_cls: 0.0577  loss_rpn_loc: 0.189  time: 0.6580  data_time: 0.2080  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:22:46 d2.utils.events]: \u001b[0m eta: 0:20:01  iter: 7539  total_loss: 1.458  loss_cls: 0.3107  loss_box_reg: 0.5346  loss_mask: 0.2882  loss_rpn_cls: 0.0729  loss_rpn_loc: 0.1998  time: 0.6582  data_time: 0.2532  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:23:03 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 7559  total_loss: 1.427  loss_cls: 0.3077  loss_box_reg: 0.5285  loss_mask: 0.3056  loss_rpn_cls: 0.07299  loss_rpn_loc: 0.176  time: 0.6587  data_time: 0.3671  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:23:17 d2.utils.events]: \u001b[0m eta: 0:19:40  iter: 7579  total_loss: 1.589  loss_cls: 0.3515  loss_box_reg: 0.5661  loss_mask: 0.312  loss_rpn_cls: 0.08746  loss_rpn_loc: 0.2069  time: 0.6588  data_time: 0.2071  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:23:30 d2.utils.events]: \u001b[0m eta: 0:19:32  iter: 7599  total_loss: 1.414  loss_cls: 0.301  loss_box_reg: 0.5516  loss_mask: 0.3007  loss_rpn_cls: 0.06062  loss_rpn_loc: 0.1597  time: 0.6588  data_time: 0.1850  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:23:43 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 7619  total_loss: 1.428  loss_cls: 0.3001  loss_box_reg: 0.5467  loss_mask: 0.31  loss_rpn_cls: 0.07504  loss_rpn_loc: 0.2004  time: 0.6588  data_time: 0.2023  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:23:54 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 7639  total_loss: 1.391  loss_cls: 0.317  loss_box_reg: 0.5292  loss_mask: 0.2834  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.1686  time: 0.6585  data_time: 0.0814  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:24:07 d2.utils.events]: \u001b[0m eta: 0:19:04  iter: 7659  total_loss: 1.457  loss_cls: 0.333  loss_box_reg: 0.5658  loss_mask: 0.2984  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.1737  time: 0.6585  data_time: 0.2057  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:24:20 d2.utils.events]: \u001b[0m eta: 0:18:54  iter: 7679  total_loss: 1.35  loss_cls: 0.2992  loss_box_reg: 0.5345  loss_mask: 0.2982  loss_rpn_cls: 0.05893  loss_rpn_loc: 0.1692  time: 0.6585  data_time: 0.1818  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:24:32 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 7699  total_loss: 1.371  loss_cls: 0.2788  loss_box_reg: 0.5353  loss_mask: 0.2939  loss_rpn_cls: 0.0687  loss_rpn_loc: 0.1847  time: 0.6584  data_time: 0.1456  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:24:45 d2.utils.events]: \u001b[0m eta: 0:18:33  iter: 7719  total_loss: 1.423  loss_cls: 0.3149  loss_box_reg: 0.5538  loss_mask: 0.2986  loss_rpn_cls: 0.06783  loss_rpn_loc: 0.1988  time: 0.6583  data_time: 0.1378  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:24:56 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 7739  total_loss: 1.404  loss_cls: 0.2991  loss_box_reg: 0.5507  loss_mask: 0.2935  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.1916  time: 0.6581  data_time: 0.1222  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:24:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:24:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:24:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:24:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:24:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:24:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0595 s/iter. Total: 0.1451 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 15:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0684 s/iter. Total: 0.1537 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0691 s/iter. Total: 0.1542 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0716 s/iter. Total: 0.1570 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:25:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.183355 (0.156753 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:25:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084508 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:25:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:25:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.273501144222286\n",
      "\u001b[32m[02/04 15:25:30 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 7759  total_loss: 1.373  loss_cls: 0.2958  loss_box_reg: 0.5346  loss_mask: 0.285  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.1767  time: 0.6581  data_time: 0.2116  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:25:44 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 7779  total_loss: 1.424  loss_cls: 0.3328  loss_box_reg: 0.5526  loss_mask: 0.304  loss_rpn_cls: 0.06815  loss_rpn_loc: 0.1962  time: 0.6583  data_time: 0.2598  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:25:55 d2.utils.events]: \u001b[0m eta: 0:17:52  iter: 7799  total_loss: 1.352  loss_cls: 0.2809  loss_box_reg: 0.5477  loss_mask: 0.2955  loss_rpn_cls: 0.04289  loss_rpn_loc: 0.1754  time: 0.6579  data_time: 0.0577  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:26:07 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 7819  total_loss: 1.363  loss_cls: 0.2875  loss_box_reg: 0.5347  loss_mask: 0.2941  loss_rpn_cls: 0.07122  loss_rpn_loc: 0.1838  time: 0.6579  data_time: 0.1439  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:26:20 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 7839  total_loss: 1.284  loss_cls: 0.2827  loss_box_reg: 0.5308  loss_mask: 0.2863  loss_rpn_cls: 0.06298  loss_rpn_loc: 0.1707  time: 0.6578  data_time: 0.1518  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:26:34 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 7859  total_loss: 1.459  loss_cls: 0.3294  loss_box_reg: 0.5691  loss_mask: 0.311  loss_rpn_cls: 0.07479  loss_rpn_loc: 0.1836  time: 0.6579  data_time: 0.2306  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:26:52 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 7879  total_loss: 1.471  loss_cls: 0.3445  loss_box_reg: 0.5496  loss_mask: 0.2977  loss_rpn_cls: 0.09547  loss_rpn_loc: 0.1915  time: 0.6586  data_time: 0.4131  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:27:08 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 7899  total_loss: 1.448  loss_cls: 0.3167  loss_box_reg: 0.5664  loss_mask: 0.3015  loss_rpn_cls: 0.07602  loss_rpn_loc: 0.187  time: 0.6589  data_time: 0.2795  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:27:21 d2.utils.events]: \u001b[0m eta: 0:17:00  iter: 7919  total_loss: 1.374  loss_cls: 0.3137  loss_box_reg: 0.5285  loss_mask: 0.2856  loss_rpn_cls: 0.07608  loss_rpn_loc: 0.1775  time: 0.6589  data_time: 0.1870  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:27:34 d2.utils.events]: \u001b[0m eta: 0:16:51  iter: 7939  total_loss: 1.455  loss_cls: 0.3098  loss_box_reg: 0.5537  loss_mask: 0.3039  loss_rpn_cls: 0.06833  loss_rpn_loc: 0.1955  time: 0.6588  data_time: 0.1697  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:27:49 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 7959  total_loss: 1.502  loss_cls: 0.321  loss_box_reg: 0.5543  loss_mask: 0.301  loss_rpn_cls: 0.09673  loss_rpn_loc: 0.2058  time: 0.6591  data_time: 0.3097  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:28:01 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 7979  total_loss: 1.344  loss_cls: 0.2771  loss_box_reg: 0.5517  loss_mask: 0.2856  loss_rpn_cls: 0.03878  loss_rpn_loc: 0.1744  time: 0.6590  data_time: 0.1366  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:28:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:28:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:28:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:28:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:28:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:28:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0842 s/iter. Eval: 0.0664 s/iter. Total: 0.1516 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0698 s/iter. Total: 0.1555 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0846 s/iter. Eval: 0.0705 s/iter. Total: 0.1560 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0846 s/iter. Eval: 0.0722 s/iter. Total: 0.1576 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:28:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.293024 (0.157698 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:28:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084620 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:28:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:28:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2731344930892286\n",
      "\u001b[32m[02/04 15:28:33 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 7999  total_loss: 1.427  loss_cls: 0.3038  loss_box_reg: 0.535  loss_mask: 0.3001  loss_rpn_cls: 0.06897  loss_rpn_loc: 0.1732  time: 0.6588  data_time: 0.1290  lr: 0.00013107  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:28:50 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 8019  total_loss: 1.395  loss_cls: 0.3185  loss_box_reg: 0.5419  loss_mask: 0.2923  loss_rpn_cls: 0.0885  loss_rpn_loc: 0.192  time: 0.6593  data_time: 0.3870  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:29:04 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 8039  total_loss: 1.489  loss_cls: 0.3213  loss_box_reg: 0.5611  loss_mask: 0.2999  loss_rpn_cls: 0.0761  loss_rpn_loc: 0.2008  time: 0.6593  data_time: 0.2115  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:29:14 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 8059  total_loss: 1.367  loss_cls: 0.2991  loss_box_reg: 0.533  loss_mask: 0.2875  loss_rpn_cls: 0.07331  loss_rpn_loc: 0.1784  time: 0.6590  data_time: 0.0919  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:29:28 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 8079  total_loss: 1.492  loss_cls: 0.325  loss_box_reg: 0.5473  loss_mask: 0.3146  loss_rpn_cls: 0.0766  loss_rpn_loc: 0.1853  time: 0.6590  data_time: 0.2261  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:29:42 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 8099  total_loss: 1.436  loss_cls: 0.3202  loss_box_reg: 0.5466  loss_mask: 0.3044  loss_rpn_cls: 0.07638  loss_rpn_loc: 0.1809  time: 0.6592  data_time: 0.2356  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:29:55 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 8119  total_loss: 1.481  loss_cls: 0.3219  loss_box_reg: 0.5452  loss_mask: 0.2946  loss_rpn_cls: 0.06996  loss_rpn_loc: 0.1927  time: 0.6591  data_time: 0.1589  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:30:08 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 8139  total_loss: 1.358  loss_cls: 0.288  loss_box_reg: 0.5199  loss_mask: 0.2824  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.1702  time: 0.6591  data_time: 0.1661  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:30:22 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 8159  total_loss: 1.448  loss_cls: 0.3017  loss_box_reg: 0.5389  loss_mask: 0.3141  loss_rpn_cls: 0.07255  loss_rpn_loc: 0.1953  time: 0.6592  data_time: 0.2299  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:30:32 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 8179  total_loss: 1.415  loss_cls: 0.3131  loss_box_reg: 0.5537  loss_mask: 0.2955  loss_rpn_cls: 0.07207  loss_rpn_loc: 0.1874  time: 0.6588  data_time: 0.0586  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:30:44 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 8199  total_loss: 1.391  loss_cls: 0.2577  loss_box_reg: 0.5129  loss_mask: 0.3066  loss_rpn_cls: 0.08143  loss_rpn_loc: 0.1687  time: 0.6587  data_time: 0.1430  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:30:59 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 8219  total_loss: 1.499  loss_cls: 0.3428  loss_box_reg: 0.5843  loss_mask: 0.3053  loss_rpn_cls: 0.07085  loss_rpn_loc: 0.2018  time: 0.6589  data_time: 0.2729  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:31:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:31:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:31:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:31:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:31:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:31:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:31:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0033 s/iter. Inference: 0.0836 s/iter. Eval: 0.0648 s/iter. Total: 0.1516 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0012 s/iter. Inference: 0.0848 s/iter. Eval: 0.0707 s/iter. Total: 0.1567 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0010 s/iter. Inference: 0.0846 s/iter. Eval: 0.0702 s/iter. Total: 0.1559 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:31:21 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0010 s/iter. Inference: 0.0848 s/iter. Eval: 0.0724 s/iter. Total: 0.1582 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:31:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.337528 (0.158082 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:31:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084838 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:31:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:31:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27126775765068484\n",
      "\u001b[32m[02/04 15:31:29 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 8239  total_loss: 1.292  loss_cls: 0.2555  loss_box_reg: 0.5194  loss_mask: 0.2859  loss_rpn_cls: 0.04816  loss_rpn_loc: 0.1748  time: 0.6585  data_time: 0.0261  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:31:43 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 8259  total_loss: 1.513  loss_cls: 0.3241  loss_box_reg: 0.5717  loss_mask: 0.3105  loss_rpn_cls: 0.0712  loss_rpn_loc: 0.1983  time: 0.6585  data_time: 0.2214  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:31:55 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 8279  total_loss: 1.437  loss_cls: 0.3073  loss_box_reg: 0.5607  loss_mask: 0.2896  loss_rpn_cls: 0.06658  loss_rpn_loc: 0.1692  time: 0.6584  data_time: 0.1384  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:32:13 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 8299  total_loss: 1.569  loss_cls: 0.3528  loss_box_reg: 0.5596  loss_mask: 0.3267  loss_rpn_cls: 0.0991  loss_rpn_loc: 0.2173  time: 0.6590  data_time: 0.4248  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:32:26 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 8319  total_loss: 1.35  loss_cls: 0.2988  loss_box_reg: 0.566  loss_mask: 0.2892  loss_rpn_cls: 0.05657  loss_rpn_loc: 0.1755  time: 0.6590  data_time: 0.1494  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:32:39 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 8339  total_loss: 1.419  loss_cls: 0.3126  loss_box_reg: 0.5803  loss_mask: 0.3063  loss_rpn_cls: 0.06125  loss_rpn_loc: 0.196  time: 0.6589  data_time: 0.1714  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:32:51 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 8359  total_loss: 1.422  loss_cls: 0.3023  loss_box_reg: 0.557  loss_mask: 0.287  loss_rpn_cls: 0.05955  loss_rpn_loc: 0.1781  time: 0.6588  data_time: 0.1306  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:33:04 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 8379  total_loss: 1.533  loss_cls: 0.3249  loss_box_reg: 0.5513  loss_mask: 0.3123  loss_rpn_cls: 0.07761  loss_rpn_loc: 0.1906  time: 0.6588  data_time: 0.1952  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:33:18 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 8399  total_loss: 1.297  loss_cls: 0.2836  loss_box_reg: 0.5239  loss_mask: 0.2953  loss_rpn_cls: 0.05703  loss_rpn_loc: 0.1651  time: 0.6589  data_time: 0.2138  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:33:31 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 8419  total_loss: 1.521  loss_cls: 0.3277  loss_box_reg: 0.5576  loss_mask: 0.3177  loss_rpn_cls: 0.08054  loss_rpn_loc: 0.2099  time: 0.6589  data_time: 0.1807  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:33:46 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 8439  total_loss: 1.483  loss_cls: 0.345  loss_box_reg: 0.5856  loss_mask: 0.2983  loss_rpn_cls: 0.08099  loss_rpn_loc: 0.1745  time: 0.6591  data_time: 0.2574  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:33:58 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 8459  total_loss: 1.389  loss_cls: 0.3  loss_box_reg: 0.5489  loss_mask: 0.294  loss_rpn_cls: 0.0519  loss_rpn_loc: 0.1786  time: 0.6589  data_time: 0.1293  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:34:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:34:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:34:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:34:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:34:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:34:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0898 s/iter. Eval: 0.0609 s/iter. Total: 0.1517 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0691 s/iter. Total: 0.1554 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:34:17 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0850 s/iter. Eval: 0.0693 s/iter. Total: 0.1551 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:34:22 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0852 s/iter. Eval: 0.0722 s/iter. Total: 0.1582 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:34:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.319171 (0.157924 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:34:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085070 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:34:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:34:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27332712672794224\n",
      "\u001b[32m[02/04 15:34:30 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 8479  total_loss: 1.337  loss_cls: 0.2994  loss_box_reg: 0.5194  loss_mask: 0.2961  loss_rpn_cls: 0.06272  loss_rpn_loc: 0.1835  time: 0.6587  data_time: 0.1296  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:34:42 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 8499  total_loss: 1.492  loss_cls: 0.3297  loss_box_reg: 0.5602  loss_mask: 0.3208  loss_rpn_cls: 0.069  loss_rpn_loc: 0.2045  time: 0.6587  data_time: 0.1790  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:34:57 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 8519  total_loss: 1.413  loss_cls: 0.3107  loss_box_reg: 0.5514  loss_mask: 0.2988  loss_rpn_cls: 0.06201  loss_rpn_loc: 0.1767  time: 0.6589  data_time: 0.2438  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:35:10 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 8539  total_loss: 1.349  loss_cls: 0.2768  loss_box_reg: 0.5233  loss_mask: 0.2861  loss_rpn_cls: 0.04646  loss_rpn_loc: 0.1695  time: 0.6589  data_time: 0.2199  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:35:21 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 8559  total_loss: 1.363  loss_cls: 0.3016  loss_box_reg: 0.5324  loss_mask: 0.2928  loss_rpn_cls: 0.07521  loss_rpn_loc: 0.1834  time: 0.6587  data_time: 0.0977  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:35:37 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 8579  total_loss: 1.383  loss_cls: 0.3138  loss_box_reg: 0.5284  loss_mask: 0.2898  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.1978  time: 0.6589  data_time: 0.2937  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:35:52 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 8599  total_loss: 1.525  loss_cls: 0.3226  loss_box_reg: 0.5752  loss_mask: 0.3231  loss_rpn_cls: 0.08917  loss_rpn_loc: 0.193  time: 0.6591  data_time: 0.2876  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:36:05 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 8619  total_loss: 1.376  loss_cls: 0.2975  loss_box_reg: 0.5342  loss_mask: 0.2964  loss_rpn_cls: 0.06188  loss_rpn_loc: 0.1792  time: 0.6592  data_time: 0.2150  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:36:17 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 8639  total_loss: 1.249  loss_cls: 0.2407  loss_box_reg: 0.4875  loss_mask: 0.2845  loss_rpn_cls: 0.05952  loss_rpn_loc: 0.1624  time: 0.6590  data_time: 0.1388  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:36:30 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 8659  total_loss: 1.406  loss_cls: 0.2954  loss_box_reg: 0.5677  loss_mask: 0.3081  loss_rpn_cls: 0.06028  loss_rpn_loc: 0.1629  time: 0.6590  data_time: 0.1868  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:36:40 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 8679  total_loss: 1.48  loss_cls: 0.2927  loss_box_reg: 0.5756  loss_mask: 0.3051  loss_rpn_cls: 0.06424  loss_rpn_loc: 0.1844  time: 0.6586  data_time: 0.0720  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:36:55 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 8699  total_loss: 1.516  loss_cls: 0.335  loss_box_reg: 0.5555  loss_mask: 0.3068  loss_rpn_cls: 0.09654  loss_rpn_loc: 0.1992  time: 0.6588  data_time: 0.2559  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:37:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:37:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:37:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:37:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:37:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:37:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0616 s/iter. Total: 0.1463 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0846 s/iter. Eval: 0.0686 s/iter. Total: 0.1541 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 15:37:15 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0692 s/iter. Total: 0.1541 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:37:20 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0716 s/iter. Total: 0.1567 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:37:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.140289 (0.156382 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:37:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084262 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:37:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:37:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27364412718756187\n",
      "\u001b[32m[02/04 15:37:28 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 8719  total_loss: 1.306  loss_cls: 0.2925  loss_box_reg: 0.5292  loss_mask: 0.2818  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.1794  time: 0.6588  data_time: 0.1840  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:37:43 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 8739  total_loss: 1.416  loss_cls: 0.3082  loss_box_reg: 0.545  loss_mask: 0.3046  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.1825  time: 0.6590  data_time: 0.2992  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:37:56 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 8759  total_loss: 1.374  loss_cls: 0.28  loss_box_reg: 0.5484  loss_mask: 0.3065  loss_rpn_cls: 0.06013  loss_rpn_loc: 0.18  time: 0.6590  data_time: 0.1917  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:38:09 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 8779  total_loss: 1.436  loss_cls: 0.3123  loss_box_reg: 0.5562  loss_mask: 0.3024  loss_rpn_cls: 0.08409  loss_rpn_loc: 0.1988  time: 0.6590  data_time: 0.1733  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:38:21 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 8799  total_loss: 1.435  loss_cls: 0.3234  loss_box_reg: 0.5651  loss_mask: 0.3036  loss_rpn_cls: 0.06399  loss_rpn_loc: 0.1766  time: 0.6588  data_time: 0.1165  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:38:34 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 8819  total_loss: 1.419  loss_cls: 0.3113  loss_box_reg: 0.549  loss_mask: 0.2965  loss_rpn_cls: 0.07855  loss_rpn_loc: 0.1926  time: 0.6588  data_time: 0.2249  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:38:48 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 8839  total_loss: 1.435  loss_cls: 0.303  loss_box_reg: 0.5268  loss_mask: 0.3088  loss_rpn_cls: 0.06799  loss_rpn_loc: 0.1963  time: 0.6589  data_time: 0.2203  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:39:01 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 8859  total_loss: 1.379  loss_cls: 0.2891  loss_box_reg: 0.5197  loss_mask: 0.2935  loss_rpn_cls: 0.07526  loss_rpn_loc: 0.1715  time: 0.6589  data_time: 0.2148  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:39:14 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 8879  total_loss: 1.37  loss_cls: 0.2974  loss_box_reg: 0.5447  loss_mask: 0.2983  loss_rpn_cls: 0.05657  loss_rpn_loc: 0.175  time: 0.6589  data_time: 0.1877  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:39:26 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 8899  total_loss: 1.361  loss_cls: 0.3131  loss_box_reg: 0.527  loss_mask: 0.2915  loss_rpn_cls: 0.07553  loss_rpn_loc: 0.183  time: 0.6588  data_time: 0.1258  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:39:38 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 8919  total_loss: 1.519  loss_cls: 0.3435  loss_box_reg: 0.5743  loss_mask: 0.3224  loss_rpn_cls: 0.09697  loss_rpn_loc: 0.191  time: 0.6585  data_time: 0.0962  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:39:51 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 8939  total_loss: 1.34  loss_cls: 0.2793  loss_box_reg: 0.5218  loss_mask: 0.2875  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.1821  time: 0.6585  data_time: 0.1762  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:39:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:39:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:39:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:39:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:40:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:40:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0876 s/iter. Eval: 0.0640 s/iter. Total: 0.1524 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0697 s/iter. Total: 0.1569 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:40:12 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0709 s/iter. Total: 0.1578 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:40:17 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0729 s/iter. Total: 0.1597 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:40:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.541141 (0.159837 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:40:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085745 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:40:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:40:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2696280148252962\n",
      "\u001b[32m[02/04 15:40:23 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 8959  total_loss: 1.42  loss_cls: 0.3109  loss_box_reg: 0.5359  loss_mask: 0.2806  loss_rpn_cls: 0.06363  loss_rpn_loc: 0.191  time: 0.6584  data_time: 0.1301  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:40:42 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 8979  total_loss: 1.446  loss_cls: 0.3187  loss_box_reg: 0.55  loss_mask: 0.3006  loss_rpn_cls: 0.07685  loss_rpn_loc: 0.2067  time: 0.6591  data_time: 0.4539  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:40:54 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 8999  total_loss: 1.371  loss_cls: 0.2964  loss_box_reg: 0.533  loss_mask: 0.2932  loss_rpn_cls: 0.068  loss_rpn_loc: 0.1743  time: 0.6589  data_time: 0.1057  lr: 0.00010486  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:41:10 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 9019  total_loss: 1.456  loss_cls: 0.3367  loss_box_reg: 0.561  loss_mask: 0.3105  loss_rpn_cls: 0.09463  loss_rpn_loc: 0.1947  time: 0.6593  data_time: 0.3624  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:41:24 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 9039  total_loss: 1.47  loss_cls: 0.3291  loss_box_reg: 0.5758  loss_mask: 0.3003  loss_rpn_cls: 0.07018  loss_rpn_loc: 0.1951  time: 0.6593  data_time: 0.1795  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:41:33 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 9059  total_loss: 1.403  loss_cls: 0.2867  loss_box_reg: 0.5424  loss_mask: 0.2891  loss_rpn_cls: 0.05294  loss_rpn_loc: 0.1876  time: 0.6589  data_time: 0.0246  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:41:46 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 9079  total_loss: 1.294  loss_cls: 0.2928  loss_box_reg: 0.5228  loss_mask: 0.2893  loss_rpn_cls: 0.04332  loss_rpn_loc: 0.1668  time: 0.6588  data_time: 0.1855  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:41:59 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 9099  total_loss: 1.465  loss_cls: 0.3274  loss_box_reg: 0.5772  loss_mask: 0.2968  loss_rpn_cls: 0.08957  loss_rpn_loc: 0.1896  time: 0.6588  data_time: 0.1714  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:42:14 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 9119  total_loss: 1.449  loss_cls: 0.319  loss_box_reg: 0.5521  loss_mask: 0.3062  loss_rpn_cls: 0.07996  loss_rpn_loc: 0.2043  time: 0.6591  data_time: 0.3280  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:42:29 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 9139  total_loss: 1.466  loss_cls: 0.315  loss_box_reg: 0.5537  loss_mask: 0.3095  loss_rpn_cls: 0.08089  loss_rpn_loc: 0.1913  time: 0.6592  data_time: 0.2549  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:42:42 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 9159  total_loss: 1.416  loss_cls: 0.3093  loss_box_reg: 0.5391  loss_mask: 0.3143  loss_rpn_cls: 0.08579  loss_rpn_loc: 0.1917  time: 0.6591  data_time: 0.1677  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:42:54 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 9179  total_loss: 1.32  loss_cls: 0.2922  loss_box_reg: 0.5514  loss_mask: 0.2868  loss_rpn_cls: 0.05372  loss_rpn_loc: 0.1761  time: 0.6590  data_time: 0.1487  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:43:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:43:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:43:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:43:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:43:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:43:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.0849 s/iter. Eval: 0.0636 s/iter. Total: 0.1501 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0009 s/iter. Inference: 0.0851 s/iter. Eval: 0.0697 s/iter. Total: 0.1558 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0009 s/iter. Inference: 0.0849 s/iter. Eval: 0.0703 s/iter. Total: 0.1561 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0726 s/iter. Total: 0.1594 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:43:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.555854 (0.159964 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:43:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085824 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:43:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:43:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27475346325882966\n",
      "\u001b[32m[02/04 15:43:25 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 9199  total_loss: 1.356  loss_cls: 0.2813  loss_box_reg: 0.5281  loss_mask: 0.2933  loss_rpn_cls: 0.0631  loss_rpn_loc: 0.1742  time: 0.6588  data_time: 0.0910  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:43:37 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 9219  total_loss: 1.39  loss_cls: 0.3012  loss_box_reg: 0.5332  loss_mask: 0.2948  loss_rpn_cls: 0.07862  loss_rpn_loc: 0.1685  time: 0.6587  data_time: 0.1359  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:43:49 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 9239  total_loss: 1.406  loss_cls: 0.2982  loss_box_reg: 0.5246  loss_mask: 0.2912  loss_rpn_cls: 0.05017  loss_rpn_loc: 0.1755  time: 0.6585  data_time: 0.1151  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:44:04 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 9259  total_loss: 1.472  loss_cls: 0.3071  loss_box_reg: 0.5422  loss_mask: 0.2942  loss_rpn_cls: 0.08468  loss_rpn_loc: 0.177  time: 0.6587  data_time: 0.2772  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:44:16 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 9279  total_loss: 1.386  loss_cls: 0.3074  loss_box_reg: 0.5395  loss_mask: 0.2975  loss_rpn_cls: 0.05915  loss_rpn_loc: 0.1791  time: 0.6586  data_time: 0.1320  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:44:28 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 9299  total_loss: 1.434  loss_cls: 0.2974  loss_box_reg: 0.5683  loss_mask: 0.2998  loss_rpn_cls: 0.06027  loss_rpn_loc: 0.1954  time: 0.6585  data_time: 0.1351  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:44:40 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 9319  total_loss: 1.327  loss_cls: 0.2992  loss_box_reg: 0.5311  loss_mask: 0.2754  loss_rpn_cls: 0.05788  loss_rpn_loc: 0.1709  time: 0.6583  data_time: 0.1580  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:44:53 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 9339  total_loss: 1.369  loss_cls: 0.3087  loss_box_reg: 0.5407  loss_mask: 0.3036  loss_rpn_cls: 0.07356  loss_rpn_loc: 0.1738  time: 0.6583  data_time: 0.1783  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:45:04 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 9359  total_loss: 1.461  loss_cls: 0.3277  loss_box_reg: 0.5669  loss_mask: 0.2993  loss_rpn_cls: 0.05829  loss_rpn_loc: 0.1874  time: 0.6581  data_time: 0.0750  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:45:17 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 9379  total_loss: 1.497  loss_cls: 0.3227  loss_box_reg: 0.5565  loss_mask: 0.2906  loss_rpn_cls: 0.08351  loss_rpn_loc: 0.1854  time: 0.6580  data_time: 0.1902  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:45:31 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 9399  total_loss: 1.353  loss_cls: 0.2952  loss_box_reg: 0.5359  loss_mask: 0.2949  loss_rpn_cls: 0.06841  loss_rpn_loc: 0.1899  time: 0.6582  data_time: 0.2725  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:45:44 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 9419  total_loss: 1.42  loss_cls: 0.2977  loss_box_reg: 0.5552  loss_mask: 0.304  loss_rpn_cls: 0.06411  loss_rpn_loc: 0.1865  time: 0.6582  data_time: 0.1924  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:45:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:45:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:45:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:45:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:45:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:45:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0840 s/iter. Eval: 0.0660 s/iter. Total: 0.1509 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0715 s/iter. Total: 0.1565 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:46:11 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0708 s/iter. Total: 0.1554 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 15:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0842 s/iter. Eval: 0.0730 s/iter. Total: 0.1580 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:46:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.300003 (0.157759 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:46:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084234 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:46:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:46:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2708185001042997\n",
      "\u001b[32m[02/04 15:46:19 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 9439  total_loss: 1.378  loss_cls: 0.3083  loss_box_reg: 0.5402  loss_mask: 0.3133  loss_rpn_cls: 0.05846  loss_rpn_loc: 0.1951  time: 0.6583  data_time: 0.2450  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:46:33 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 9459  total_loss: 1.46  loss_cls: 0.3271  loss_box_reg: 0.535  loss_mask: 0.3015  loss_rpn_cls: 0.08416  loss_rpn_loc: 0.2017  time: 0.6584  data_time: 0.2484  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:46:46 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 9479  total_loss: 1.423  loss_cls: 0.3083  loss_box_reg: 0.541  loss_mask: 0.2939  loss_rpn_cls: 0.07956  loss_rpn_loc: 0.1941  time: 0.6584  data_time: 0.1635  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:47:01 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 9499  total_loss: 1.513  loss_cls: 0.3292  loss_box_reg: 0.5657  loss_mask: 0.3166  loss_rpn_cls: 0.09064  loss_rpn_loc: 0.2063  time: 0.6586  data_time: 0.2856  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:47:15 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 9519  total_loss: 1.414  loss_cls: 0.3159  loss_box_reg: 0.5499  loss_mask: 0.2965  loss_rpn_cls: 0.06446  loss_rpn_loc: 0.1804  time: 0.6587  data_time: 0.2280  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:47:30 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 9539  total_loss: 1.381  loss_cls: 0.3024  loss_box_reg: 0.533  loss_mask: 0.2778  loss_rpn_cls: 0.06623  loss_rpn_loc: 0.1812  time: 0.6588  data_time: 0.2498  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:47:41 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 9559  total_loss: 1.396  loss_cls: 0.3004  loss_box_reg: 0.5509  loss_mask: 0.306  loss_rpn_cls: 0.05009  loss_rpn_loc: 0.168  time: 0.6586  data_time: 0.0917  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:47:53 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 9579  total_loss: 1.391  loss_cls: 0.3113  loss_box_reg: 0.5426  loss_mask: 0.2909  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.1737  time: 0.6585  data_time: 0.1419  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:48:06 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 9599  total_loss: 1.256  loss_cls: 0.2637  loss_box_reg: 0.4969  loss_mask: 0.2804  loss_rpn_cls: 0.03434  loss_rpn_loc: 0.159  time: 0.6584  data_time: 0.1444  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:48:21 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 9619  total_loss: 1.435  loss_cls: 0.2997  loss_box_reg: 0.5533  loss_mask: 0.3063  loss_rpn_cls: 0.0932  loss_rpn_loc: 0.1902  time: 0.6586  data_time: 0.2722  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:48:34 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 9639  total_loss: 1.517  loss_cls: 0.3267  loss_box_reg: 0.5811  loss_mask: 0.3097  loss_rpn_cls: 0.07554  loss_rpn_loc: 0.1809  time: 0.6587  data_time: 0.2052  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:48:47 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 9659  total_loss: 1.435  loss_cls: 0.3183  loss_box_reg: 0.551  loss_mask: 0.3011  loss_rpn_cls: 0.07649  loss_rpn_loc: 0.2  time: 0.6586  data_time: 0.1573  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:49:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:49:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:49:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:49:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:49:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:49:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0850 s/iter. Eval: 0.0601 s/iter. Total: 0.1459 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0851 s/iter. Eval: 0.0710 s/iter. Total: 0.1569 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0719 s/iter. Total: 0.1590 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0737 s/iter. Total: 0.1604 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:49:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.736699 (0.161523 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:49:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085978 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:49:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:49:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27309442060163197\n",
      "\u001b[32m[02/04 15:49:22 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9679  total_loss: 1.413  loss_cls: 0.3176  loss_box_reg: 0.5472  loss_mask: 0.2989  loss_rpn_cls: 0.07448  loss_rpn_loc: 0.1838  time: 0.6588  data_time: 0.2698  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:49:35 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9699  total_loss: 1.333  loss_cls: 0.3015  loss_box_reg: 0.5361  loss_mask: 0.2987  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.1785  time: 0.6587  data_time: 0.1593  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:49:48 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 9719  total_loss: 1.459  loss_cls: 0.3313  loss_box_reg: 0.5669  loss_mask: 0.3017  loss_rpn_cls: 0.07455  loss_rpn_loc: 0.1744  time: 0.6587  data_time: 0.1951  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:50:02 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 9739  total_loss: 1.427  loss_cls: 0.3233  loss_box_reg: 0.5581  loss_mask: 0.2948  loss_rpn_cls: 0.05918  loss_rpn_loc: 0.1922  time: 0.6588  data_time: 0.2346  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:50:17 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9759  total_loss: 1.424  loss_cls: 0.3166  loss_box_reg: 0.5505  loss_mask: 0.2939  loss_rpn_cls: 0.05986  loss_rpn_loc: 0.1911  time: 0.6590  data_time: 0.2616  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:50:29 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 9779  total_loss: 1.474  loss_cls: 0.3153  loss_box_reg: 0.5763  loss_mask: 0.2974  loss_rpn_cls: 0.07901  loss_rpn_loc: 0.1875  time: 0.6589  data_time: 0.1736  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:50:44 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 9799  total_loss: 1.399  loss_cls: 0.3099  loss_box_reg: 0.5414  loss_mask: 0.298  loss_rpn_cls: 0.06678  loss_rpn_loc: 0.179  time: 0.6591  data_time: 0.2568  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:50:57 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 9819  total_loss: 1.424  loss_cls: 0.2976  loss_box_reg: 0.5392  loss_mask: 0.3092  loss_rpn_cls: 0.06071  loss_rpn_loc: 0.1892  time: 0.6590  data_time: 0.1678  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:51:10 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 9839  total_loss: 1.426  loss_cls: 0.321  loss_box_reg: 0.5585  loss_mask: 0.2976  loss_rpn_cls: 0.08263  loss_rpn_loc: 0.167  time: 0.6590  data_time: 0.1848  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:51:22 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 9859  total_loss: 1.315  loss_cls: 0.2845  loss_box_reg: 0.5253  loss_mask: 0.2958  loss_rpn_cls: 0.0334  loss_rpn_loc: 0.1956  time: 0.6590  data_time: 0.1610  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:51:35 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 9879  total_loss: 1.337  loss_cls: 0.2985  loss_box_reg: 0.5515  loss_mask: 0.3041  loss_rpn_cls: 0.06203  loss_rpn_loc: 0.186  time: 0.6589  data_time: 0.1763  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:51:52 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 9899  total_loss: 1.476  loss_cls: 0.3276  loss_box_reg: 0.5475  loss_mask: 0.2872  loss_rpn_cls: 0.06697  loss_rpn_loc: 0.196  time: 0.6593  data_time: 0.3565  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:52:04 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 9919  total_loss: 1.339  loss_cls: 0.2948  loss_box_reg: 0.541  loss_mask: 0.2864  loss_rpn_cls: 0.07214  loss_rpn_loc: 0.1666  time: 0.6591  data_time: 0.1386  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:52:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:52:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:52:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:52:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:52:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:52:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0846 s/iter. Eval: 0.0686 s/iter. Total: 0.1539 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0853 s/iter. Eval: 0.0724 s/iter. Total: 0.1585 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 15:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0851 s/iter. Eval: 0.0719 s/iter. Total: 0.1578 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:52:23 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0744 s/iter. Total: 0.1609 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:52:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.742190 (0.161571 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:52:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085812 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:52:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:52:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27169146172036557\n",
      "\u001b[32m[02/04 15:52:38 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 9939  total_loss: 1.316  loss_cls: 0.2879  loss_box_reg: 0.5315  loss_mask: 0.2737  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.1735  time: 0.6592  data_time: 0.2225  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:52:50 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9959  total_loss: 1.353  loss_cls: 0.3004  loss_box_reg: 0.5113  loss_mask: 0.3002  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.1931  time: 0.6590  data_time: 0.1274  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:53:01 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 9979  total_loss: 1.311  loss_cls: 0.2872  loss_box_reg: 0.5174  loss_mask: 0.3025  loss_rpn_cls: 0.04867  loss_rpn_loc: 0.1797  time: 0.6589  data_time: 0.1206  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:53:15 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.513  loss_cls: 0.338  loss_box_reg: 0.5818  loss_mask: 0.3133  loss_rpn_cls: 0.09227  loss_rpn_loc: 0.2106  time: 0.6590  data_time: 0.2285  lr: 8.3886e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:53:15 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:49:48 (0.6590 s / it)\n",
      "\u001b[32m[02/04 15:53:15 d2.engine.hooks]: \u001b[0mTotal training time: 2:03:13 (0:13:25 on hooks)\n",
      "\u001b[32m[02/04 15:53:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:53:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:53:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:53:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:53:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:53:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0594 s/iter. Total: 0.1456 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 15:53:23 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.0863 s/iter. Eval: 0.0770 s/iter. Total: 0.1642 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 15:53:28 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0849 s/iter. Eval: 0.0730 s/iter. Total: 0.1588 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 15:53:33 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0746 s/iter. Total: 0.1613 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 15:53:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.894144 (0.162881 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:53:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085971 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:53:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:53:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27388707875508017\n"
     ]
    }
   ],
   "source": [
    "# correcting the mean pixel values used for normalisation and unfreezing the second layer of the backbone (making it trainable)\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af8b594-6c84-46e1-b9b6-d873d678548f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 15:55:49 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 15:55:50 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 15:55:51 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/04 15:55:51 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 15:55:52 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/04 15:55:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/04 15:55:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/04 15:55:52 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:55:52 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 15:55:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 15:56:10 d2.utils.events]: \u001b[0m eta: 1:28:48  iter: 19  total_loss: 3.332  loss_cls: 1.386  loss_box_reg: 0.5705  loss_mask: 0.6899  loss_rpn_cls: 0.3127  loss_rpn_loc: 0.2975  time: 0.9220  data_time: 0.4318  lr: 9.9905e-06  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:56:24 d2.utils.events]: \u001b[0m eta: 1:26:04  iter: 39  total_loss: 3.177  loss_cls: 1.312  loss_box_reg: 0.5733  loss_mask: 0.6848  loss_rpn_cls: 0.3146  loss_rpn_loc: 0.2766  time: 0.8035  data_time: 0.2189  lr: 1.998e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:56:36 d2.utils.events]: \u001b[0m eta: 1:22:54  iter: 59  total_loss: 2.993  loss_cls: 1.143  loss_box_reg: 0.6084  loss_mask: 0.6706  loss_rpn_cls: 0.2776  loss_rpn_loc: 0.2583  time: 0.7205  data_time: 0.1268  lr: 2.997e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:56:48 d2.utils.events]: \u001b[0m eta: 1:22:44  iter: 79  total_loss: 2.725  loss_cls: 0.9296  loss_box_reg: 0.6844  loss_mask: 0.6465  loss_rpn_cls: 0.2357  loss_rpn_loc: 0.2403  time: 0.6950  data_time: 0.1549  lr: 3.9961e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:57:02 d2.utils.events]: \u001b[0m eta: 1:22:34  iter: 99  total_loss: 2.636  loss_cls: 0.7914  loss_box_reg: 0.7514  loss_mask: 0.6263  loss_rpn_cls: 0.1959  loss_rpn_loc: 0.2416  time: 0.6915  data_time: 0.2179  lr: 4.9951e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:57:15 d2.utils.events]: \u001b[0m eta: 1:22:29  iter: 119  total_loss: 2.519  loss_cls: 0.73  loss_box_reg: 0.7263  loss_mask: 0.599  loss_rpn_cls: 0.1894  loss_rpn_loc: 0.2458  time: 0.6886  data_time: 0.2020  lr: 5.9941e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:57:27 d2.utils.events]: \u001b[0m eta: 1:20:09  iter: 139  total_loss: 2.325  loss_cls: 0.6748  loss_box_reg: 0.7583  loss_mask: 0.5385  loss_rpn_cls: 0.1488  loss_rpn_loc: 0.2236  time: 0.6732  data_time: 0.1207  lr: 6.993e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:57:37 d2.utils.events]: \u001b[0m eta: 1:19:33  iter: 159  total_loss: 2.229  loss_cls: 0.6202  loss_box_reg: 0.7659  loss_mask: 0.5161  loss_rpn_cls: 0.1471  loss_rpn_loc: 0.2253  time: 0.6528  data_time: 0.0535  lr: 7.9921e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:57:50 d2.utils.events]: \u001b[0m eta: 1:19:49  iter: 179  total_loss: 2.299  loss_cls: 0.6333  loss_box_reg: 0.7913  loss_mask: 0.5111  loss_rpn_cls: 0.1563  loss_rpn_loc: 0.2291  time: 0.6532  data_time: 0.1874  lr: 8.991e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:58:06 d2.utils.events]: \u001b[0m eta: 1:21:16  iter: 199  total_loss: 2.191  loss_cls: 0.6091  loss_box_reg: 0.7238  loss_mask: 0.4875  loss_rpn_cls: 0.1892  loss_rpn_loc: 0.2311  time: 0.6693  data_time: 0.3094  lr: 9.9901e-05  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:58:22 d2.utils.events]: \u001b[0m eta: 1:21:23  iter: 219  total_loss: 2.112  loss_cls: 0.5527  loss_box_reg: 0.7554  loss_mask: 0.4621  loss_rpn_cls: 0.1354  loss_rpn_loc: 0.2338  time: 0.6787  data_time: 0.2780  lr: 0.00010989  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:58:32 d2.utils.events]: \u001b[0m eta: 1:19:53  iter: 239  total_loss: 1.997  loss_cls: 0.507  loss_box_reg: 0.78  loss_mask: 0.3937  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.1962  time: 0.6657  data_time: 0.0665  lr: 0.00011988  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:58:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:58:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 15:58:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 15:58:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 15:58:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 15:58:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 15:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0780 s/iter. Eval: 0.0187 s/iter. Total: 0.0973 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 15:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0007 s/iter. Inference: 0.0773 s/iter. Eval: 0.0188 s/iter. Total: 0.0968 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 15:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0768 s/iter. Eval: 0.0162 s/iter. Total: 0.0937 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 15:58:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.922025 (0.094155 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:58:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.076792 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 15:58:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 15:58:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.13083013106973154\n",
      "\u001b[32m[02/04 15:58:58 d2.utils.events]: \u001b[0m eta: 1:19:43  iter: 259  total_loss: 1.954  loss_cls: 0.4701  loss_box_reg: 0.7264  loss_mask: 0.4003  loss_rpn_cls: 0.1245  loss_rpn_loc: 0.2225  time: 0.6676  data_time: 0.2141  lr: 0.00012987  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:59:11 d2.utils.events]: \u001b[0m eta: 1:19:00  iter: 279  total_loss: 1.849  loss_cls: 0.4528  loss_box_reg: 0.7152  loss_mask: 0.361  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.2103  time: 0.6655  data_time: 0.1853  lr: 0.00013986  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:59:24 d2.utils.events]: \u001b[0m eta: 1:18:58  iter: 299  total_loss: 1.806  loss_cls: 0.4221  loss_box_reg: 0.7127  loss_mask: 0.3483  loss_rpn_cls: 0.1241  loss_rpn_loc: 0.2061  time: 0.6641  data_time: 0.1762  lr: 0.00014985  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:59:35 d2.utils.events]: \u001b[0m eta: 1:18:30  iter: 319  total_loss: 1.81  loss_cls: 0.3785  loss_box_reg: 0.7111  loss_mask: 0.3398  loss_rpn_cls: 0.1243  loss_rpn_loc: 0.2046  time: 0.6558  data_time: 0.0720  lr: 0.00015984  max_mem: 7043M\n",
      "\u001b[32m[02/04 15:59:51 d2.utils.events]: \u001b[0m eta: 1:18:21  iter: 339  total_loss: 1.87  loss_cls: 0.4206  loss_box_reg: 0.6794  loss_mask: 0.3314  loss_rpn_cls: 0.1291  loss_rpn_loc: 0.2287  time: 0.6661  data_time: 0.3542  lr: 0.00016983  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:00:05 d2.utils.events]: \u001b[0m eta: 1:18:30  iter: 359  total_loss: 1.898  loss_cls: 0.4011  loss_box_reg: 0.6889  loss_mask: 0.3393  loss_rpn_cls: 0.139  loss_rpn_loc: 0.2524  time: 0.6676  data_time: 0.2236  lr: 0.00017982  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:00:19 d2.utils.events]: \u001b[0m eta: 1:18:39  iter: 379  total_loss: 1.785  loss_cls: 0.4412  loss_box_reg: 0.6875  loss_mask: 0.314  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.2344  time: 0.6685  data_time: 0.2100  lr: 0.00018981  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:00:32 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 399  total_loss: 1.672  loss_cls: 0.3552  loss_box_reg: 0.6646  loss_mask: 0.2975  loss_rpn_cls: 0.09354  loss_rpn_loc: 0.2103  time: 0.6678  data_time: 0.2018  lr: 0.0001998  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:00:45 d2.utils.events]: \u001b[0m eta: 1:18:00  iter: 419  total_loss: 1.67  loss_cls: 0.3625  loss_box_reg: 0.6836  loss_mask: 0.3361  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.2174  time: 0.6664  data_time: 0.1658  lr: 0.00020979  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:01:00 d2.utils.events]: \u001b[0m eta: 1:18:11  iter: 439  total_loss: 1.701  loss_cls: 0.3847  loss_box_reg: 0.6573  loss_mask: 0.3254  loss_rpn_cls: 0.1261  loss_rpn_loc: 0.228  time: 0.6711  data_time: 0.2918  lr: 0.00021978  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:01:10 d2.utils.events]: \u001b[0m eta: 1:17:36  iter: 459  total_loss: 1.545  loss_cls: 0.3312  loss_box_reg: 0.633  loss_mask: 0.3064  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2077  time: 0.6624  data_time: 0.0272  lr: 0.00022977  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:01:23 d2.utils.events]: \u001b[0m eta: 1:17:31  iter: 479  total_loss: 1.74  loss_cls: 0.3748  loss_box_reg: 0.6576  loss_mask: 0.32  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.2171  time: 0.6626  data_time: 0.1941  lr: 0.00023976  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:01:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:01:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:01:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:01:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:01:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:01:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:01:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0451 s/iter. Total: 0.1264 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:01:33 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0601 s/iter. Total: 0.1438 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 16:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0626 s/iter. Total: 0.1466 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:01:43 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0605 s/iter. Total: 0.1444 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 16:01:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.745402 (0.144357 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:01:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.082984 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:01:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:01:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21463216895908244\n",
      "\u001b[32m[02/04 16:01:53 d2.utils.events]: \u001b[0m eta: 1:17:34  iter: 499  total_loss: 1.82  loss_cls: 0.4213  loss_box_reg: 0.6851  loss_mask: 0.3269  loss_rpn_cls: 0.1319  loss_rpn_loc: 0.2384  time: 0.6606  data_time: 0.1433  lr: 0.00024975  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:02:06 d2.utils.events]: \u001b[0m eta: 1:17:30  iter: 519  total_loss: 1.666  loss_cls: 0.3728  loss_box_reg: 0.6304  loss_mask: 0.3154  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.2084  time: 0.6597  data_time: 0.1667  lr: 0.00025974  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:02:19 d2.utils.events]: \u001b[0m eta: 1:17:15  iter: 539  total_loss: 1.516  loss_cls: 0.3377  loss_box_reg: 0.6136  loss_mask: 0.3066  loss_rpn_cls: 0.08909  loss_rpn_loc: 0.1976  time: 0.6584  data_time: 0.1581  lr: 0.00026973  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:02:31 d2.utils.events]: \u001b[0m eta: 1:16:52  iter: 559  total_loss: 1.633  loss_cls: 0.3449  loss_box_reg: 0.627  loss_mask: 0.3273  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.2344  time: 0.6574  data_time: 0.1677  lr: 0.00027972  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:02:43 d2.utils.events]: \u001b[0m eta: 1:16:42  iter: 579  total_loss: 1.742  loss_cls: 0.3613  loss_box_reg: 0.6433  loss_mask: 0.3237  loss_rpn_cls: 0.1233  loss_rpn_loc: 0.2331  time: 0.6555  data_time: 0.1390  lr: 0.00028971  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:03:00 d2.utils.events]: \u001b[0m eta: 1:16:32  iter: 599  total_loss: 1.67  loss_cls: 0.3612  loss_box_reg: 0.6139  loss_mask: 0.3149  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.2175  time: 0.6619  data_time: 0.3726  lr: 0.0002997  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:03:13 d2.utils.events]: \u001b[0m eta: 1:16:22  iter: 619  total_loss: 1.636  loss_cls: 0.3632  loss_box_reg: 0.6339  loss_mask: 0.3122  loss_rpn_cls: 0.09448  loss_rpn_loc: 0.2003  time: 0.6611  data_time: 0.1757  lr: 0.00030969  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:03:26 d2.utils.events]: \u001b[0m eta: 1:16:11  iter: 639  total_loss: 1.735  loss_cls: 0.3715  loss_box_reg: 0.6419  loss_mask: 0.3351  loss_rpn_cls: 0.1214  loss_rpn_loc: 0.2313  time: 0.6601  data_time: 0.1742  lr: 0.00031968  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:03:37 d2.utils.events]: \u001b[0m eta: 1:15:50  iter: 659  total_loss: 1.63  loss_cls: 0.372  loss_box_reg: 0.6351  loss_mask: 0.3236  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.2185  time: 0.6578  data_time: 0.1232  lr: 0.00032967  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:03:50 d2.utils.events]: \u001b[0m eta: 1:15:37  iter: 679  total_loss: 1.588  loss_cls: 0.341  loss_box_reg: 0.6106  loss_mask: 0.313  loss_rpn_cls: 0.09337  loss_rpn_loc: 0.2087  time: 0.6568  data_time: 0.1597  lr: 0.00033966  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:04:02 d2.utils.events]: \u001b[0m eta: 1:15:25  iter: 699  total_loss: 1.73  loss_cls: 0.4033  loss_box_reg: 0.6244  loss_mask: 0.3248  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.2166  time: 0.6549  data_time: 0.1215  lr: 0.00034965  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:04:16 d2.utils.events]: \u001b[0m eta: 1:15:17  iter: 719  total_loss: 1.696  loss_cls: 0.3649  loss_box_reg: 0.6263  loss_mask: 0.3184  loss_rpn_cls: 0.106  loss_rpn_loc: 0.2251  time: 0.6571  data_time: 0.2512  lr: 0.00035964  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:04:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:04:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:04:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:04:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:04:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:04:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0800 s/iter. Eval: 0.0395 s/iter. Total: 0.1201 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0007 s/iter. Inference: 0.0824 s/iter. Eval: 0.0587 s/iter. Total: 0.1418 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 16:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0007 s/iter. Inference: 0.0829 s/iter. Eval: 0.0619 s/iter. Total: 0.1455 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 16:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0007 s/iter. Inference: 0.0826 s/iter. Eval: 0.0607 s/iter. Total: 0.1441 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 16:04:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.774224 (0.144605 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:04:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.082638 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:04:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:04:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23790505977358958\n",
      "\u001b[32m[02/04 16:04:49 d2.utils.events]: \u001b[0m eta: 1:15:07  iter: 739  total_loss: 1.634  loss_cls: 0.3722  loss_box_reg: 0.6145  loss_mask: 0.3155  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.2255  time: 0.6587  data_time: 0.2353  lr: 0.00036963  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:05:02 d2.utils.events]: \u001b[0m eta: 1:14:50  iter: 759  total_loss: 1.642  loss_cls: 0.3413  loss_box_reg: 0.595  loss_mask: 0.3236  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.2086  time: 0.6585  data_time: 0.1978  lr: 0.00037962  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:05:14 d2.utils.events]: \u001b[0m eta: 1:14:30  iter: 779  total_loss: 1.553  loss_cls: 0.308  loss_box_reg: 0.6164  loss_mask: 0.3038  loss_rpn_cls: 0.06607  loss_rpn_loc: 0.185  time: 0.6570  data_time: 0.1417  lr: 0.00038961  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:05:29 d2.utils.events]: \u001b[0m eta: 1:14:37  iter: 799  total_loss: 1.651  loss_cls: 0.3582  loss_box_reg: 0.6309  loss_mask: 0.3184  loss_rpn_cls: 0.121  loss_rpn_loc: 0.2187  time: 0.6599  data_time: 0.2765  lr: 0.0003996  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:05:42 d2.utils.events]: \u001b[0m eta: 1:14:18  iter: 819  total_loss: 1.465  loss_cls: 0.3428  loss_box_reg: 0.5987  loss_mask: 0.301  loss_rpn_cls: 0.08027  loss_rpn_loc: 0.1985  time: 0.6594  data_time: 0.1710  lr: 0.00040959  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:05:54 d2.utils.events]: \u001b[0m eta: 1:14:15  iter: 839  total_loss: 1.732  loss_cls: 0.3963  loss_box_reg: 0.6157  loss_mask: 0.3264  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2239  time: 0.6581  data_time: 0.1419  lr: 0.00041958  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:06:08 d2.utils.events]: \u001b[0m eta: 1:14:11  iter: 859  total_loss: 1.841  loss_cls: 0.3897  loss_box_reg: 0.6316  loss_mask: 0.3427  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.2372  time: 0.6588  data_time: 0.1963  lr: 0.00042957  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:06:21 d2.utils.events]: \u001b[0m eta: 1:14:13  iter: 879  total_loss: 1.613  loss_cls: 0.3642  loss_box_reg: 0.5987  loss_mask: 0.3122  loss_rpn_cls: 0.1228  loss_rpn_loc: 0.2134  time: 0.6589  data_time: 0.1584  lr: 0.00043956  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:06:37 d2.utils.events]: \u001b[0m eta: 1:14:08  iter: 899  total_loss: 1.63  loss_cls: 0.3806  loss_box_reg: 0.6261  loss_mask: 0.326  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2211  time: 0.6613  data_time: 0.2585  lr: 0.00044955  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:06:49 d2.utils.events]: \u001b[0m eta: 1:14:03  iter: 919  total_loss: 1.519  loss_cls: 0.359  loss_box_reg: 0.5786  loss_mask: 0.3068  loss_rpn_cls: 0.07425  loss_rpn_loc: 0.1731  time: 0.6603  data_time: 0.1282  lr: 0.00045954  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:07:02 d2.utils.events]: \u001b[0m eta: 1:14:07  iter: 939  total_loss: 1.61  loss_cls: 0.3801  loss_box_reg: 0.6154  loss_mask: 0.302  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.2096  time: 0.6602  data_time: 0.1670  lr: 0.00046953  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:07:14 d2.utils.events]: \u001b[0m eta: 1:13:59  iter: 959  total_loss: 1.491  loss_cls: 0.3254  loss_box_reg: 0.5486  loss_mask: 0.2997  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.1923  time: 0.6591  data_time: 0.1193  lr: 0.00047952  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:07:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:07:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:07:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:07:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:07:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:07:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0835 s/iter. Eval: 0.0462 s/iter. Total: 0.1303 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0838 s/iter. Eval: 0.0652 s/iter. Total: 0.1498 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0007 s/iter. Inference: 0.0847 s/iter. Eval: 0.0681 s/iter. Total: 0.1536 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0007 s/iter. Inference: 0.0849 s/iter. Eval: 0.0701 s/iter. Total: 0.1558 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 16:07:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.995610 (0.155135 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:07:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084818 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:07:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:07:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2389212321221183\n",
      "\u001b[32m[02/04 16:07:47 d2.utils.events]: \u001b[0m eta: 1:13:49  iter: 979  total_loss: 1.614  loss_cls: 0.3468  loss_box_reg: 0.5963  loss_mask: 0.3272  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.218  time: 0.6587  data_time: 0.1642  lr: 0.00048951  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:07:58 d2.utils.events]: \u001b[0m eta: 1:13:36  iter: 999  total_loss: 1.415  loss_cls: 0.3114  loss_box_reg: 0.5657  loss_mask: 0.2898  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.1991  time: 0.6567  data_time: 0.0941  lr: 0.0004995  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:08:10 d2.utils.events]: \u001b[0m eta: 1:13:13  iter: 1019  total_loss: 1.602  loss_cls: 0.3444  loss_box_reg: 0.5844  loss_mask: 0.3268  loss_rpn_cls: 0.09021  loss_rpn_loc: 0.2005  time: 0.6561  data_time: 0.1640  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:08:23 d2.utils.events]: \u001b[0m eta: 1:13:01  iter: 1039  total_loss: 1.626  loss_cls: 0.3674  loss_box_reg: 0.6034  loss_mask: 0.3152  loss_rpn_cls: 0.09465  loss_rpn_loc: 0.2136  time: 0.6554  data_time: 0.1567  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:08:36 d2.utils.events]: \u001b[0m eta: 1:12:53  iter: 1059  total_loss: 1.531  loss_cls: 0.3213  loss_box_reg: 0.592  loss_mask: 0.306  loss_rpn_cls: 0.09587  loss_rpn_loc: 0.2154  time: 0.6553  data_time: 0.1896  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:08:52 d2.utils.events]: \u001b[0m eta: 1:12:57  iter: 1079  total_loss: 1.59  loss_cls: 0.3467  loss_box_reg: 0.5815  loss_mask: 0.3293  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.2168  time: 0.6583  data_time: 0.3235  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:09:06 d2.utils.events]: \u001b[0m eta: 1:12:47  iter: 1099  total_loss: 1.657  loss_cls: 0.3706  loss_box_reg: 0.6274  loss_mask: 0.3001  loss_rpn_cls: 0.106  loss_rpn_loc: 0.2139  time: 0.6586  data_time: 0.1942  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:09:18 d2.utils.events]: \u001b[0m eta: 1:12:34  iter: 1119  total_loss: 1.423  loss_cls: 0.3211  loss_box_reg: 0.5443  loss_mask: 0.2845  loss_rpn_cls: 0.07225  loss_rpn_loc: 0.1915  time: 0.6582  data_time: 0.1754  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:09:29 d2.utils.events]: \u001b[0m eta: 1:12:26  iter: 1139  total_loss: 1.666  loss_cls: 0.3439  loss_box_reg: 0.6286  loss_mask: 0.3099  loss_rpn_cls: 0.08179  loss_rpn_loc: 0.2202  time: 0.6561  data_time: 0.0845  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:09:47 d2.utils.events]: \u001b[0m eta: 1:12:21  iter: 1159  total_loss: 1.517  loss_cls: 0.3513  loss_box_reg: 0.5881  loss_mask: 0.3062  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2128  time: 0.6602  data_time: 0.4117  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:09:59 d2.utils.events]: \u001b[0m eta: 1:12:10  iter: 1179  total_loss: 1.645  loss_cls: 0.3857  loss_box_reg: 0.5807  loss_mask: 0.3281  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.2298  time: 0.6593  data_time: 0.1525  lr: 0.0005  max_mem: 7043M\n",
      "\u001b[32m[02/04 16:10:13 d2.utils.events]: \u001b[0m eta: 1:11:55  iter: 1199  total_loss: 1.515  loss_cls: 0.3402  loss_box_reg: 0.5749  loss_mask: 0.3097  loss_rpn_cls: 0.08441  loss_rpn_loc: 0.1992  time: 0.6602  data_time: 0.2394  lr: 0.0005  max_mem: 7081M\n",
      "\u001b[32m[02/04 16:10:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:10:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:10:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:10:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:10:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:10:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0805 s/iter. Eval: 0.0455 s/iter. Total: 0.1266 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0647 s/iter. Total: 0.1484 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0007 s/iter. Inference: 0.0831 s/iter. Eval: 0.0660 s/iter. Total: 0.1498 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:10:37 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0663 s/iter. Total: 0.1503 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:10:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.515552 (0.150996 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:10:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083239 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:10:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:10:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25402712157568497\n",
      "\u001b[32m[02/04 16:10:44 d2.utils.events]: \u001b[0m eta: 1:11:36  iter: 1219  total_loss: 1.566  loss_cls: 0.3569  loss_box_reg: 0.6053  loss_mask: 0.3227  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.2085  time: 0.6591  data_time: 0.1190  lr: 0.0005  max_mem: 7081M\n",
      "\u001b[32m[02/04 16:10:57 d2.utils.events]: \u001b[0m eta: 1:11:36  iter: 1239  total_loss: 1.676  loss_cls: 0.3984  loss_box_reg: 0.6074  loss_mask: 0.3307  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.2181  time: 0.6584  data_time: 0.1424  lr: 0.0005  max_mem: 7081M\n",
      "\u001b[32m[02/04 16:11:10 d2.utils.events]: \u001b[0m eta: 1:11:26  iter: 1259  total_loss: 1.549  loss_cls: 0.3701  loss_box_reg: 0.5923  loss_mask: 0.3147  loss_rpn_cls: 0.09273  loss_rpn_loc: 0.2167  time: 0.6585  data_time: 0.1918  lr: 0.0005  max_mem: 7081M\n",
      "\u001b[32m[02/04 16:11:21 d2.utils.events]: \u001b[0m eta: 1:11:16  iter: 1279  total_loss: 1.577  loss_cls: 0.362  loss_box_reg: 0.5968  loss_mask: 0.3145  loss_rpn_cls: 0.09863  loss_rpn_loc: 0.1976  time: 0.6566  data_time: 0.0908  lr: 0.0005  max_mem: 7081M\n",
      "\u001b[32m[02/04 16:11:32 d2.utils.events]: \u001b[0m eta: 1:10:57  iter: 1299  total_loss: 1.585  loss_cls: 0.3391  loss_box_reg: 0.6176  loss_mask: 0.3052  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.1984  time: 0.6555  data_time: 0.1280  lr: 0.0005  max_mem: 7081M\n",
      "\u001b[32m[02/04 16:11:48 d2.utils.events]: \u001b[0m eta: 1:11:01  iter: 1319  total_loss: 1.63  loss_cls: 0.37  loss_box_reg: 0.6065  loss_mask: 0.3145  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.2232  time: 0.6570  data_time: 0.2748  lr: 0.0005  max_mem: 7081M\n",
      "\u001b[32m[02/04 16:12:04 d2.utils.events]: \u001b[0m eta: 1:10:51  iter: 1339  total_loss: 1.549  loss_cls: 0.3164  loss_box_reg: 0.5785  loss_mask: 0.3271  loss_rpn_cls: 0.08909  loss_rpn_loc: 0.2436  time: 0.6593  data_time: 0.3335  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:12:17 d2.utils.events]: \u001b[0m eta: 1:10:38  iter: 1359  total_loss: 1.534  loss_cls: 0.3332  loss_box_reg: 0.5927  loss_mask: 0.3064  loss_rpn_cls: 0.1316  loss_rpn_loc: 0.2254  time: 0.6595  data_time: 0.1977  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:12:29 d2.utils.events]: \u001b[0m eta: 1:10:17  iter: 1379  total_loss: 1.409  loss_cls: 0.2785  loss_box_reg: 0.551  loss_mask: 0.2942  loss_rpn_cls: 0.06298  loss_rpn_loc: 0.1904  time: 0.6582  data_time: 0.1139  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:12:39 d2.utils.events]: \u001b[0m eta: 1:10:05  iter: 1399  total_loss: 1.543  loss_cls: 0.3017  loss_box_reg: 0.5969  loss_mask: 0.2986  loss_rpn_cls: 0.09499  loss_rpn_loc: 0.1989  time: 0.6564  data_time: 0.0803  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:12:53 d2.utils.events]: \u001b[0m eta: 1:09:54  iter: 1419  total_loss: 1.473  loss_cls: 0.3445  loss_box_reg: 0.5576  loss_mask: 0.3055  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.2059  time: 0.6566  data_time: 0.1964  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:13:04 d2.utils.events]: \u001b[0m eta: 1:09:38  iter: 1439  total_loss: 1.564  loss_cls: 0.3533  loss_box_reg: 0.6029  loss_mask: 0.3016  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.2113  time: 0.6553  data_time: 0.0940  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:13:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:13:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:13:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:13:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:13:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:13:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0813 s/iter. Eval: 0.0433 s/iter. Total: 0.1252 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.0831 s/iter. Eval: 0.0624 s/iter. Total: 0.1463 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.0832 s/iter. Eval: 0.0642 s/iter. Total: 0.1482 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0830 s/iter. Eval: 0.0630 s/iter. Total: 0.1469 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:13:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.104558 (0.147453 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:13:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083057 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:13:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:13:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24708862206335516\n",
      "\u001b[32m[02/04 16:13:34 d2.utils.events]: \u001b[0m eta: 1:09:34  iter: 1459  total_loss: 1.6  loss_cls: 0.3315  loss_box_reg: 0.5799  loss_mask: 0.311  loss_rpn_cls: 0.09984  loss_rpn_loc: 0.1889  time: 0.6538  data_time: 0.0877  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:13:49 d2.utils.events]: \u001b[0m eta: 1:09:19  iter: 1479  total_loss: 1.521  loss_cls: 0.3378  loss_box_reg: 0.5816  loss_mask: 0.3113  loss_rpn_cls: 0.09081  loss_rpn_loc: 0.1971  time: 0.6553  data_time: 0.2990  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:14:04 d2.utils.events]: \u001b[0m eta: 1:09:16  iter: 1499  total_loss: 1.711  loss_cls: 0.3719  loss_box_reg: 0.6284  loss_mask: 0.3185  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.2287  time: 0.6568  data_time: 0.2815  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:14:17 d2.utils.events]: \u001b[0m eta: 1:09:12  iter: 1519  total_loss: 1.658  loss_cls: 0.3734  loss_box_reg: 0.5922  loss_mask: 0.3241  loss_rpn_cls: 0.1159  loss_rpn_loc: 0.2134  time: 0.6564  data_time: 0.1512  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:14:27 d2.utils.events]: \u001b[0m eta: 1:08:59  iter: 1539  total_loss: 1.35  loss_cls: 0.2848  loss_box_reg: 0.551  loss_mask: 0.2835  loss_rpn_cls: 0.06393  loss_rpn_loc: 0.1725  time: 0.6548  data_time: 0.0742  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:14:43 d2.utils.events]: \u001b[0m eta: 1:09:00  iter: 1559  total_loss: 1.467  loss_cls: 0.3179  loss_box_reg: 0.555  loss_mask: 0.2996  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1903  time: 0.6566  data_time: 0.3148  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:14:57 d2.utils.events]: \u001b[0m eta: 1:08:50  iter: 1579  total_loss: 1.529  loss_cls: 0.3373  loss_box_reg: 0.5843  loss_mask: 0.3196  loss_rpn_cls: 0.09333  loss_rpn_loc: 0.2147  time: 0.6571  data_time: 0.2281  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:15:09 d2.utils.events]: \u001b[0m eta: 1:08:39  iter: 1599  total_loss: 1.512  loss_cls: 0.3231  loss_box_reg: 0.5862  loss_mask: 0.3056  loss_rpn_cls: 0.09594  loss_rpn_loc: 0.2023  time: 0.6562  data_time: 0.1276  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:15:23 d2.utils.events]: \u001b[0m eta: 1:08:30  iter: 1619  total_loss: 1.544  loss_cls: 0.3563  loss_box_reg: 0.5935  loss_mask: 0.3145  loss_rpn_cls: 0.08075  loss_rpn_loc: 0.2129  time: 0.6567  data_time: 0.2273  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:15:34 d2.utils.events]: \u001b[0m eta: 1:08:24  iter: 1639  total_loss: 1.612  loss_cls: 0.3604  loss_box_reg: 0.6086  loss_mask: 0.3106  loss_rpn_cls: 0.09436  loss_rpn_loc: 0.228  time: 0.6557  data_time: 0.1154  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:15:47 d2.utils.events]: \u001b[0m eta: 1:08:15  iter: 1659  total_loss: 1.451  loss_cls: 0.3409  loss_box_reg: 0.5776  loss_mask: 0.289  loss_rpn_cls: 0.08079  loss_rpn_loc: 0.1851  time: 0.6554  data_time: 0.1632  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:16:00 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 1679  total_loss: 1.423  loss_cls: 0.2961  loss_box_reg: 0.5633  loss_mask: 0.2999  loss_rpn_cls: 0.0696  loss_rpn_loc: 0.1938  time: 0.6552  data_time: 0.1678  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:16:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:16:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:16:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:16:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:16:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:16:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:16:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0802 s/iter. Eval: 0.0442 s/iter. Total: 0.1250 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0827 s/iter. Eval: 0.0632 s/iter. Total: 0.1467 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0657 s/iter. Total: 0.1495 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0661 s/iter. Total: 0.1499 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:16:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.514281 (0.150985 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:16:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083090 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:16:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:16:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2504019992786292\n",
      "\u001b[32m[02/04 16:16:31 d2.utils.events]: \u001b[0m eta: 1:07:58  iter: 1699  total_loss: 1.719  loss_cls: 0.3758  loss_box_reg: 0.5989  loss_mask: 0.3159  loss_rpn_cls: 0.09471  loss_rpn_loc: 0.2231  time: 0.6544  data_time: 0.1261  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:16:45 d2.utils.events]: \u001b[0m eta: 1:07:46  iter: 1719  total_loss: 1.484  loss_cls: 0.3423  loss_box_reg: 0.5509  loss_mask: 0.3021  loss_rpn_cls: 0.08427  loss_rpn_loc: 0.2031  time: 0.6549  data_time: 0.2247  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:17:00 d2.utils.events]: \u001b[0m eta: 1:07:37  iter: 1739  total_loss: 1.491  loss_cls: 0.3318  loss_box_reg: 0.5604  loss_mask: 0.3103  loss_rpn_cls: 0.08071  loss_rpn_loc: 0.2005  time: 0.6562  data_time: 0.2901  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:17:10 d2.utils.events]: \u001b[0m eta: 1:07:27  iter: 1759  total_loss: 1.542  loss_cls: 0.3231  loss_box_reg: 0.5764  loss_mask: 0.3145  loss_rpn_cls: 0.08773  loss_rpn_loc: 0.2067  time: 0.6545  data_time: 0.0563  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:17:23 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 1779  total_loss: 1.495  loss_cls: 0.3366  loss_box_reg: 0.5682  loss_mask: 0.3011  loss_rpn_cls: 0.104  loss_rpn_loc: 0.2129  time: 0.6544  data_time: 0.1708  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:17:39 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 1799  total_loss: 1.448  loss_cls: 0.2955  loss_box_reg: 0.5918  loss_mask: 0.3237  loss_rpn_cls: 0.089  loss_rpn_loc: 0.1984  time: 0.6561  data_time: 0.3324  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:17:53 d2.utils.events]: \u001b[0m eta: 1:07:02  iter: 1819  total_loss: 1.49  loss_cls: 0.3298  loss_box_reg: 0.5511  loss_mask: 0.3014  loss_rpn_cls: 0.0923  loss_rpn_loc: 0.2012  time: 0.6563  data_time: 0.2099  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:18:10 d2.utils.events]: \u001b[0m eta: 1:06:56  iter: 1839  total_loss: 1.566  loss_cls: 0.3507  loss_box_reg: 0.5872  loss_mask: 0.317  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.1998  time: 0.6585  data_time: 0.3379  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:18:22 d2.utils.events]: \u001b[0m eta: 1:06:48  iter: 1859  total_loss: 1.617  loss_cls: 0.3497  loss_box_reg: 0.6188  loss_mask: 0.3249  loss_rpn_cls: 0.08974  loss_rpn_loc: 0.2108  time: 0.6581  data_time: 0.1488  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:18:33 d2.utils.events]: \u001b[0m eta: 1:06:31  iter: 1879  total_loss: 1.474  loss_cls: 0.3307  loss_box_reg: 0.5807  loss_mask: 0.2987  loss_rpn_cls: 0.0813  loss_rpn_loc: 0.1988  time: 0.6568  data_time: 0.0717  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:18:46 d2.utils.events]: \u001b[0m eta: 1:06:17  iter: 1899  total_loss: 1.64  loss_cls: 0.3634  loss_box_reg: 0.6113  loss_mask: 0.3142  loss_rpn_cls: 0.09299  loss_rpn_loc: 0.2068  time: 0.6567  data_time: 0.1727  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:18:59 d2.utils.events]: \u001b[0m eta: 1:06:07  iter: 1919  total_loss: 1.569  loss_cls: 0.3438  loss_box_reg: 0.5807  loss_mask: 0.2962  loss_rpn_cls: 0.0965  loss_rpn_loc: 0.2058  time: 0.6567  data_time: 0.1891  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:19:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:19:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:19:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:19:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:19:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:19:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0817 s/iter. Eval: 0.0490 s/iter. Total: 0.1313 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0842 s/iter. Eval: 0.0667 s/iter. Total: 0.1516 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0843 s/iter. Eval: 0.0675 s/iter. Total: 0.1525 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0007 s/iter. Inference: 0.0848 s/iter. Eval: 0.0699 s/iter. Total: 0.1555 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 16:19:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.999329 (0.155167 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:19:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084795 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:19:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:19:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2519274269431155\n",
      "\u001b[32m[02/04 16:19:29 d2.utils.events]: \u001b[0m eta: 1:05:45  iter: 1939  total_loss: 1.443  loss_cls: 0.3373  loss_box_reg: 0.5743  loss_mask: 0.2943  loss_rpn_cls: 0.07805  loss_rpn_loc: 0.1917  time: 0.6555  data_time: 0.0735  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:19:43 d2.utils.events]: \u001b[0m eta: 1:05:34  iter: 1959  total_loss: 1.419  loss_cls: 0.306  loss_box_reg: 0.5482  loss_mask: 0.2864  loss_rpn_cls: 0.05001  loss_rpn_loc: 0.1853  time: 0.6555  data_time: 0.1916  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:19:55 d2.utils.events]: \u001b[0m eta: 1:05:24  iter: 1979  total_loss: 1.5  loss_cls: 0.3251  loss_box_reg: 0.5604  loss_mask: 0.2962  loss_rpn_cls: 0.08593  loss_rpn_loc: 0.2074  time: 0.6549  data_time: 0.1294  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:20:07 d2.utils.events]: \u001b[0m eta: 1:05:18  iter: 1999  total_loss: 1.538  loss_cls: 0.3299  loss_box_reg: 0.5953  loss_mask: 0.306  loss_rpn_cls: 0.07053  loss_rpn_loc: 0.2076  time: 0.6547  data_time: 0.1681  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:20:18 d2.utils.events]: \u001b[0m eta: 1:05:08  iter: 2019  total_loss: 1.445  loss_cls: 0.3075  loss_box_reg: 0.542  loss_mask: 0.301  loss_rpn_cls: 0.0841  loss_rpn_loc: 0.1834  time: 0.6537  data_time: 0.0856  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:20:32 d2.utils.events]: \u001b[0m eta: 1:04:59  iter: 2039  total_loss: 1.618  loss_cls: 0.3573  loss_box_reg: 0.5914  loss_mask: 0.3204  loss_rpn_cls: 0.08621  loss_rpn_loc: 0.1919  time: 0.6538  data_time: 0.1873  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:20:42 d2.utils.events]: \u001b[0m eta: 1:04:45  iter: 2059  total_loss: 1.335  loss_cls: 0.2695  loss_box_reg: 0.5648  loss_mask: 0.3153  loss_rpn_cls: 0.06501  loss_rpn_loc: 0.1909  time: 0.6527  data_time: 0.0832  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:20:58 d2.utils.events]: \u001b[0m eta: 1:04:34  iter: 2079  total_loss: 1.645  loss_cls: 0.3724  loss_box_reg: 0.5946  loss_mask: 0.3067  loss_rpn_cls: 0.09936  loss_rpn_loc: 0.2189  time: 0.6538  data_time: 0.2865  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:21:12 d2.utils.events]: \u001b[0m eta: 1:04:20  iter: 2099  total_loss: 1.465  loss_cls: 0.3179  loss_box_reg: 0.5898  loss_mask: 0.3014  loss_rpn_cls: 0.06685  loss_rpn_loc: 0.1967  time: 0.6543  data_time: 0.2254  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:21:23 d2.utils.events]: \u001b[0m eta: 1:04:11  iter: 2119  total_loss: 1.405  loss_cls: 0.2977  loss_box_reg: 0.5649  loss_mask: 0.2791  loss_rpn_cls: 0.07119  loss_rpn_loc: 0.1919  time: 0.6533  data_time: 0.0829  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:21:36 d2.utils.events]: \u001b[0m eta: 1:04:11  iter: 2139  total_loss: 1.533  loss_cls: 0.3517  loss_box_reg: 0.5956  loss_mask: 0.3007  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.2183  time: 0.6531  data_time: 0.1434  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:21:49 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 2159  total_loss: 1.533  loss_cls: 0.3369  loss_box_reg: 0.5731  loss_mask: 0.3254  loss_rpn_cls: 0.0952  loss_rpn_loc: 0.2102  time: 0.6533  data_time: 0.1884  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:22:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:22:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:22:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:22:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:22:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:22:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0801 s/iter. Eval: 0.0435 s/iter. Total: 0.1242 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.0827 s/iter. Eval: 0.0619 s/iter. Total: 0.1455 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:22:17 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.0830 s/iter. Eval: 0.0639 s/iter. Total: 0.1477 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:22:22 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0831 s/iter. Eval: 0.0630 s/iter. Total: 0.1469 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:22:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.116917 (0.147560 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:22:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083238 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:22:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:22:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25856852161309474\n",
      "\u001b[32m[02/04 16:22:24 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 2179  total_loss: 1.646  loss_cls: 0.3579  loss_box_reg: 0.6017  loss_mask: 0.3321  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.2257  time: 0.6549  data_time: 0.3200  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:22:36 d2.utils.events]: \u001b[0m eta: 1:03:47  iter: 2199  total_loss: 1.513  loss_cls: 0.3246  loss_box_reg: 0.5602  loss_mask: 0.2867  loss_rpn_cls: 0.07922  loss_rpn_loc: 0.1912  time: 0.6542  data_time: 0.1067  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:22:51 d2.utils.events]: \u001b[0m eta: 1:03:39  iter: 2219  total_loss: 1.498  loss_cls: 0.3269  loss_box_reg: 0.5569  loss_mask: 0.3061  loss_rpn_cls: 0.06652  loss_rpn_loc: 0.1995  time: 0.6551  data_time: 0.2747  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:23:02 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 2239  total_loss: 1.38  loss_cls: 0.2692  loss_box_reg: 0.555  loss_mask: 0.3024  loss_rpn_cls: 0.08482  loss_rpn_loc: 0.1987  time: 0.6541  data_time: 0.0901  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:23:14 d2.utils.events]: \u001b[0m eta: 1:03:18  iter: 2259  total_loss: 1.448  loss_cls: 0.3101  loss_box_reg: 0.5405  loss_mask: 0.2846  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.2002  time: 0.6536  data_time: 0.1177  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:23:28 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 2279  total_loss: 1.53  loss_cls: 0.3683  loss_box_reg: 0.5791  loss_mask: 0.3081  loss_rpn_cls: 0.07566  loss_rpn_loc: 0.2109  time: 0.6540  data_time: 0.2118  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:23:40 d2.utils.events]: \u001b[0m eta: 1:03:11  iter: 2299  total_loss: 1.383  loss_cls: 0.3211  loss_box_reg: 0.5504  loss_mask: 0.3025  loss_rpn_cls: 0.07394  loss_rpn_loc: 0.1726  time: 0.6536  data_time: 0.1371  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:23:52 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 2319  total_loss: 1.412  loss_cls: 0.3048  loss_box_reg: 0.5559  loss_mask: 0.294  loss_rpn_cls: 0.06789  loss_rpn_loc: 0.1977  time: 0.6531  data_time: 0.1182  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:24:05 d2.utils.events]: \u001b[0m eta: 1:02:44  iter: 2339  total_loss: 1.424  loss_cls: 0.3158  loss_box_reg: 0.5485  loss_mask: 0.2963  loss_rpn_cls: 0.07711  loss_rpn_loc: 0.1743  time: 0.6531  data_time: 0.1884  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:24:19 d2.utils.events]: \u001b[0m eta: 1:02:34  iter: 2359  total_loss: 1.545  loss_cls: 0.3329  loss_box_reg: 0.5892  loss_mask: 0.3173  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.2007  time: 0.6534  data_time: 0.2060  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:24:35 d2.utils.events]: \u001b[0m eta: 1:02:33  iter: 2379  total_loss: 1.55  loss_cls: 0.366  loss_box_reg: 0.5742  loss_mask: 0.3118  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.2016  time: 0.6549  data_time: 0.3403  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:24:47 d2.utils.events]: \u001b[0m eta: 1:02:28  iter: 2399  total_loss: 1.64  loss_cls: 0.3752  loss_box_reg: 0.6124  loss_mask: 0.3159  loss_rpn_cls: 0.0933  loss_rpn_loc: 0.2052  time: 0.6541  data_time: 0.0966  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:25:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:25:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:25:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:25:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:25:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:25:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0805 s/iter. Eval: 0.0446 s/iter. Total: 0.1257 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0830 s/iter. Eval: 0.0639 s/iter. Total: 0.1477 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0659 s/iter. Total: 0.1499 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0654 s/iter. Total: 0.1493 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:25:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.375871 (0.149792 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:25:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083192 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:25:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:25:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26447131541764807\n",
      "\u001b[32m[02/04 16:25:20 d2.utils.events]: \u001b[0m eta: 1:02:23  iter: 2419  total_loss: 1.506  loss_cls: 0.3415  loss_box_reg: 0.6056  loss_mask: 0.3046  loss_rpn_cls: 0.08303  loss_rpn_loc: 0.1975  time: 0.6548  data_time: 0.2442  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:25:33 d2.utils.events]: \u001b[0m eta: 1:02:13  iter: 2439  total_loss: 1.552  loss_cls: 0.3703  loss_box_reg: 0.584  loss_mask: 0.318  loss_rpn_cls: 0.0954  loss_rpn_loc: 0.2126  time: 0.6545  data_time: 0.1548  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:25:45 d2.utils.events]: \u001b[0m eta: 1:02:04  iter: 2459  total_loss: 1.396  loss_cls: 0.2991  loss_box_reg: 0.5373  loss_mask: 0.2924  loss_rpn_cls: 0.06757  loss_rpn_loc: 0.178  time: 0.6540  data_time: 0.1321  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:25:58 d2.utils.events]: \u001b[0m eta: 1:01:54  iter: 2479  total_loss: 1.63  loss_cls: 0.367  loss_box_reg: 0.5835  loss_mask: 0.3094  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.2307  time: 0.6541  data_time: 0.1846  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:26:09 d2.utils.events]: \u001b[0m eta: 1:01:38  iter: 2499  total_loss: 1.448  loss_cls: 0.3059  loss_box_reg: 0.5741  loss_mask: 0.2895  loss_rpn_cls: 0.06743  loss_rpn_loc: 0.1761  time: 0.6534  data_time: 0.1127  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:26:23 d2.utils.events]: \u001b[0m eta: 1:01:19  iter: 2519  total_loss: 1.451  loss_cls: 0.3114  loss_box_reg: 0.5467  loss_mask: 0.2908  loss_rpn_cls: 0.08664  loss_rpn_loc: 0.1929  time: 0.6537  data_time: 0.2218  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:26:37 d2.utils.events]: \u001b[0m eta: 1:01:13  iter: 2539  total_loss: 1.494  loss_cls: 0.3336  loss_box_reg: 0.5623  loss_mask: 0.2984  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.21  time: 0.6540  data_time: 0.2083  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:26:48 d2.utils.events]: \u001b[0m eta: 1:00:56  iter: 2559  total_loss: 1.505  loss_cls: 0.3365  loss_box_reg: 0.5482  loss_mask: 0.3007  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.1815  time: 0.6531  data_time: 0.0757  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:27:01 d2.utils.events]: \u001b[0m eta: 1:00:46  iter: 2579  total_loss: 1.578  loss_cls: 0.3337  loss_box_reg: 0.5704  loss_mask: 0.3191  loss_rpn_cls: 0.08646  loss_rpn_loc: 0.2095  time: 0.6532  data_time: 0.1990  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:27:16 d2.utils.events]: \u001b[0m eta: 1:00:42  iter: 2599  total_loss: 1.541  loss_cls: 0.3387  loss_box_reg: 0.5796  loss_mask: 0.312  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2068  time: 0.6540  data_time: 0.2533  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:27:28 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 2619  total_loss: 1.445  loss_cls: 0.3112  loss_box_reg: 0.5532  loss_mask: 0.3046  loss_rpn_cls: 0.07651  loss_rpn_loc: 0.1695  time: 0.6533  data_time: 0.1103  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:27:42 d2.utils.events]: \u001b[0m eta: 1:00:18  iter: 2639  total_loss: 1.572  loss_cls: 0.3278  loss_box_reg: 0.5853  loss_mask: 0.3053  loss_rpn_cls: 0.09704  loss_rpn_loc: 0.2071  time: 0.6537  data_time: 0.2204  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:27:55 d2.utils.events]: \u001b[0m eta: 1:00:09  iter: 2659  total_loss: 1.581  loss_cls: 0.3325  loss_box_reg: 0.5623  loss_mask: 0.3026  loss_rpn_cls: 0.112  loss_rpn_loc: 0.1989  time: 0.6540  data_time: 0.2142  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:27:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:27:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:27:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:27:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:27:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:27:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0815 s/iter. Eval: 0.0466 s/iter. Total: 0.1288 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0847 s/iter. Eval: 0.0658 s/iter. Total: 0.1514 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:28:10 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0664 s/iter. Total: 0.1518 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0682 s/iter. Total: 0.1538 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:28:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.819471 (0.153616 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:28:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084739 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:28:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:28:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2590076217602011\n",
      "\u001b[32m[02/04 16:28:27 d2.utils.events]: \u001b[0m eta: 1:00:03  iter: 2679  total_loss: 1.451  loss_cls: 0.3193  loss_box_reg: 0.5488  loss_mask: 0.3058  loss_rpn_cls: 0.06602  loss_rpn_loc: 0.181  time: 0.6537  data_time: 0.1415  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:28:37 d2.utils.events]: \u001b[0m eta: 0:59:49  iter: 2699  total_loss: 1.437  loss_cls: 0.2935  loss_box_reg: 0.5691  loss_mask: 0.3063  loss_rpn_cls: 0.06486  loss_rpn_loc: 0.1983  time: 0.6526  data_time: 0.0441  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:28:50 d2.utils.events]: \u001b[0m eta: 0:59:40  iter: 2719  total_loss: 1.451  loss_cls: 0.3048  loss_box_reg: 0.5703  loss_mask: 0.2958  loss_rpn_cls: 0.07529  loss_rpn_loc: 0.1884  time: 0.6526  data_time: 0.1773  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:29:03 d2.utils.events]: \u001b[0m eta: 0:59:29  iter: 2739  total_loss: 1.525  loss_cls: 0.3286  loss_box_reg: 0.5612  loss_mask: 0.3017  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.2128  time: 0.6525  data_time: 0.1644  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:29:17 d2.utils.events]: \u001b[0m eta: 0:59:27  iter: 2759  total_loss: 1.445  loss_cls: 0.321  loss_box_reg: 0.5548  loss_mask: 0.3018  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.1913  time: 0.6529  data_time: 0.2184  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:29:30 d2.utils.events]: \u001b[0m eta: 0:59:19  iter: 2779  total_loss: 1.538  loss_cls: 0.3277  loss_box_reg: 0.5713  loss_mask: 0.3086  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.2217  time: 0.6528  data_time: 0.1783  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:29:43 d2.utils.events]: \u001b[0m eta: 0:59:05  iter: 2799  total_loss: 1.434  loss_cls: 0.3265  loss_box_reg: 0.5554  loss_mask: 0.2873  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.1773  time: 0.6529  data_time: 0.1836  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:29:54 d2.utils.events]: \u001b[0m eta: 0:58:52  iter: 2819  total_loss: 1.311  loss_cls: 0.2325  loss_box_reg: 0.521  loss_mask: 0.2834  loss_rpn_cls: 0.06135  loss_rpn_loc: 0.1883  time: 0.6519  data_time: 0.0479  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:30:08 d2.utils.events]: \u001b[0m eta: 0:58:41  iter: 2839  total_loss: 1.571  loss_cls: 0.3324  loss_box_reg: 0.5994  loss_mask: 0.3083  loss_rpn_cls: 0.09679  loss_rpn_loc: 0.2114  time: 0.6523  data_time: 0.2487  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:30:21 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 2859  total_loss: 1.506  loss_cls: 0.324  loss_box_reg: 0.5667  loss_mask: 0.2886  loss_rpn_cls: 0.07617  loss_rpn_loc: 0.1766  time: 0.6524  data_time: 0.1733  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:30:38 d2.utils.events]: \u001b[0m eta: 0:58:26  iter: 2879  total_loss: 1.683  loss_cls: 0.3711  loss_box_reg: 0.6084  loss_mask: 0.3327  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.2126  time: 0.6536  data_time: 0.3232  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:30:52 d2.utils.events]: \u001b[0m eta: 0:58:20  iter: 2899  total_loss: 1.486  loss_cls: 0.3173  loss_box_reg: 0.5681  loss_mask: 0.3059  loss_rpn_cls: 0.08447  loss_rpn_loc: 0.2139  time: 0.6539  data_time: 0.2202  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:30:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:30:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:30:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:30:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:30:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:30:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0855 s/iter. Eval: 0.0480 s/iter. Total: 0.1341 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0856 s/iter. Eval: 0.0663 s/iter. Total: 0.1527 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0849 s/iter. Eval: 0.0678 s/iter. Total: 0.1535 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:31:12 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0007 s/iter. Inference: 0.0855 s/iter. Eval: 0.0707 s/iter. Total: 0.1570 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 16:31:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.167207 (0.156614 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:31:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085486 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:31:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:31:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2670732779481329\n",
      "\u001b[32m[02/04 16:31:23 d2.utils.events]: \u001b[0m eta: 0:58:10  iter: 2919  total_loss: 1.605  loss_cls: 0.3631  loss_box_reg: 0.6048  loss_mask: 0.3075  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.1911  time: 0.6533  data_time: 0.0853  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:31:36 d2.utils.events]: \u001b[0m eta: 0:58:07  iter: 2939  total_loss: 1.473  loss_cls: 0.3251  loss_box_reg: 0.5211  loss_mask: 0.2975  loss_rpn_cls: 0.07361  loss_rpn_loc: 0.1952  time: 0.6532  data_time: 0.1650  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:31:47 d2.utils.events]: \u001b[0m eta: 0:57:55  iter: 2959  total_loss: 1.586  loss_cls: 0.3422  loss_box_reg: 0.5839  loss_mask: 0.3175  loss_rpn_cls: 0.07811  loss_rpn_loc: 0.2032  time: 0.6526  data_time: 0.1009  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:31:58 d2.utils.events]: \u001b[0m eta: 0:57:41  iter: 2979  total_loss: 1.459  loss_cls: 0.2781  loss_box_reg: 0.5935  loss_mask: 0.3046  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.1996  time: 0.6518  data_time: 0.0745  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:32:14 d2.utils.events]: \u001b[0m eta: 0:57:37  iter: 2999  total_loss: 1.498  loss_cls: 0.3334  loss_box_reg: 0.5779  loss_mask: 0.3015  loss_rpn_cls: 0.08692  loss_rpn_loc: 0.1846  time: 0.6530  data_time: 0.3325  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:32:30 d2.utils.events]: \u001b[0m eta: 0:57:27  iter: 3019  total_loss: 1.449  loss_cls: 0.2981  loss_box_reg: 0.5798  loss_mask: 0.3119  loss_rpn_cls: 0.08241  loss_rpn_loc: 0.2021  time: 0.6538  data_time: 0.2861  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:32:42 d2.utils.events]: \u001b[0m eta: 0:57:20  iter: 3039  total_loss: 1.507  loss_cls: 0.3318  loss_box_reg: 0.5652  loss_mask: 0.308  loss_rpn_cls: 0.09999  loss_rpn_loc: 0.1882  time: 0.6535  data_time: 0.1290  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:32:57 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 3059  total_loss: 1.556  loss_cls: 0.3412  loss_box_reg: 0.566  loss_mask: 0.3071  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2214  time: 0.6540  data_time: 0.2446  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:33:10 d2.utils.events]: \u001b[0m eta: 0:57:02  iter: 3079  total_loss: 1.419  loss_cls: 0.3029  loss_box_reg: 0.5331  loss_mask: 0.3025  loss_rpn_cls: 0.0749  loss_rpn_loc: 0.1952  time: 0.6543  data_time: 0.2118  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:33:23 d2.utils.events]: \u001b[0m eta: 0:56:52  iter: 3099  total_loss: 1.54  loss_cls: 0.3308  loss_box_reg: 0.5394  loss_mask: 0.2929  loss_rpn_cls: 0.08202  loss_rpn_loc: 0.2027  time: 0.6542  data_time: 0.1648  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:33:38 d2.utils.events]: \u001b[0m eta: 0:56:45  iter: 3119  total_loss: 1.489  loss_cls: 0.3254  loss_box_reg: 0.5509  loss_mask: 0.3089  loss_rpn_cls: 0.09594  loss_rpn_loc: 0.2001  time: 0.6545  data_time: 0.2338  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:33:50 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 3139  total_loss: 1.397  loss_cls: 0.3054  loss_box_reg: 0.5479  loss_mask: 0.2874  loss_rpn_cls: 0.07576  loss_rpn_loc: 0.1713  time: 0.6543  data_time: 0.1449  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:33:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:33:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:33:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:33:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:33:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:33:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:33:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0811 s/iter. Eval: 0.0439 s/iter. Total: 0.1257 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0631 s/iter. Total: 0.1478 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:34:05 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.0837 s/iter. Eval: 0.0650 s/iter. Total: 0.1495 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0658 s/iter. Total: 0.1505 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:34:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.548457 (0.151280 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:34:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084019 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:34:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:34:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26313430685055417\n",
      "\u001b[32m[02/04 16:34:20 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 3159  total_loss: 1.454  loss_cls: 0.3208  loss_box_reg: 0.5375  loss_mask: 0.2934  loss_rpn_cls: 0.06529  loss_rpn_loc: 0.1852  time: 0.6536  data_time: 0.0766  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:34:34 d2.utils.events]: \u001b[0m eta: 0:56:09  iter: 3179  total_loss: 1.416  loss_cls: 0.3049  loss_box_reg: 0.5407  loss_mask: 0.303  loss_rpn_cls: 0.07073  loss_rpn_loc: 0.1839  time: 0.6540  data_time: 0.2349  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:34:45 d2.utils.events]: \u001b[0m eta: 0:56:01  iter: 3199  total_loss: 1.465  loss_cls: 0.3323  loss_box_reg: 0.5526  loss_mask: 0.2852  loss_rpn_cls: 0.07976  loss_rpn_loc: 0.191  time: 0.6534  data_time: 0.0777  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:34:58 d2.utils.events]: \u001b[0m eta: 0:55:52  iter: 3219  total_loss: 1.538  loss_cls: 0.3299  loss_box_reg: 0.5736  loss_mask: 0.3135  loss_rpn_cls: 0.0892  loss_rpn_loc: 0.2124  time: 0.6534  data_time: 0.1940  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:35:11 d2.utils.events]: \u001b[0m eta: 0:55:43  iter: 3239  total_loss: 1.442  loss_cls: 0.3155  loss_box_reg: 0.5755  loss_mask: 0.2868  loss_rpn_cls: 0.07057  loss_rpn_loc: 0.1871  time: 0.6532  data_time: 0.1354  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:35:22 d2.utils.events]: \u001b[0m eta: 0:55:29  iter: 3259  total_loss: 1.302  loss_cls: 0.2524  loss_box_reg: 0.5349  loss_mask: 0.2873  loss_rpn_cls: 0.06586  loss_rpn_loc: 0.1755  time: 0.6526  data_time: 0.1036  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:35:37 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 3279  total_loss: 1.495  loss_cls: 0.3277  loss_box_reg: 0.5569  loss_mask: 0.3147  loss_rpn_cls: 0.08794  loss_rpn_loc: 0.2068  time: 0.6533  data_time: 0.2912  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:35:53 d2.utils.events]: \u001b[0m eta: 0:55:10  iter: 3299  total_loss: 1.482  loss_cls: 0.3302  loss_box_reg: 0.576  loss_mask: 0.3014  loss_rpn_cls: 0.08739  loss_rpn_loc: 0.1985  time: 0.6542  data_time: 0.3136  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:36:08 d2.utils.events]: \u001b[0m eta: 0:55:01  iter: 3319  total_loss: 1.454  loss_cls: 0.3418  loss_box_reg: 0.5715  loss_mask: 0.3045  loss_rpn_cls: 0.07243  loss_rpn_loc: 0.1931  time: 0.6545  data_time: 0.2320  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:36:20 d2.utils.events]: \u001b[0m eta: 0:54:49  iter: 3339  total_loss: 1.415  loss_cls: 0.2891  loss_box_reg: 0.5076  loss_mask: 0.2827  loss_rpn_cls: 0.05072  loss_rpn_loc: 0.1817  time: 0.6543  data_time: 0.1364  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:36:34 d2.utils.events]: \u001b[0m eta: 0:54:36  iter: 3359  total_loss: 1.519  loss_cls: 0.3328  loss_box_reg: 0.557  loss_mask: 0.306  loss_rpn_cls: 0.08966  loss_rpn_loc: 0.2052  time: 0.6545  data_time: 0.2274  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:36:48 d2.utils.events]: \u001b[0m eta: 0:54:27  iter: 3379  total_loss: 1.603  loss_cls: 0.3459  loss_box_reg: 0.5809  loss_mask: 0.323  loss_rpn_cls: 0.08549  loss_rpn_loc: 0.204  time: 0.6548  data_time: 0.2277  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:36:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:36:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:36:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:36:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:36:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:36:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0808 s/iter. Eval: 0.0468 s/iter. Total: 0.1283 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0840 s/iter. Eval: 0.0656 s/iter. Total: 0.1504 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0836 s/iter. Eval: 0.0666 s/iter. Total: 0.1510 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0842 s/iter. Eval: 0.0693 s/iter. Total: 0.1543 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 16:37:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.868171 (0.154036 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:37:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084114 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:37:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:37:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2662598305439984\n",
      "\u001b[32m[02/04 16:37:21 d2.utils.events]: \u001b[0m eta: 0:54:14  iter: 3399  total_loss: 1.484  loss_cls: 0.3413  loss_box_reg: 0.5611  loss_mask: 0.3101  loss_rpn_cls: 0.07079  loss_rpn_loc: 0.199  time: 0.6550  data_time: 0.2026  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:37:34 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 3419  total_loss: 1.463  loss_cls: 0.3221  loss_box_reg: 0.5569  loss_mask: 0.3023  loss_rpn_cls: 0.06878  loss_rpn_loc: 0.1798  time: 0.6548  data_time: 0.1522  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:37:45 d2.utils.events]: \u001b[0m eta: 0:53:50  iter: 3439  total_loss: 1.386  loss_cls: 0.2913  loss_box_reg: 0.555  loss_mask: 0.2782  loss_rpn_cls: 0.06171  loss_rpn_loc: 0.1944  time: 0.6544  data_time: 0.1166  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:37:59 d2.utils.events]: \u001b[0m eta: 0:53:41  iter: 3459  total_loss: 1.542  loss_cls: 0.3298  loss_box_reg: 0.5886  loss_mask: 0.3051  loss_rpn_cls: 0.09559  loss_rpn_loc: 0.2018  time: 0.6545  data_time: 0.1883  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:38:11 d2.utils.events]: \u001b[0m eta: 0:53:29  iter: 3479  total_loss: 1.462  loss_cls: 0.3173  loss_box_reg: 0.5548  loss_mask: 0.3116  loss_rpn_cls: 0.07844  loss_rpn_loc: 0.1888  time: 0.6542  data_time: 0.1448  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:38:25 d2.utils.events]: \u001b[0m eta: 0:53:23  iter: 3499  total_loss: 1.464  loss_cls: 0.3126  loss_box_reg: 0.5777  loss_mask: 0.3011  loss_rpn_cls: 0.07876  loss_rpn_loc: 0.2044  time: 0.6545  data_time: 0.2251  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:38:37 d2.utils.events]: \u001b[0m eta: 0:53:15  iter: 3519  total_loss: 1.415  loss_cls: 0.3057  loss_box_reg: 0.5394  loss_mask: 0.2994  loss_rpn_cls: 0.07015  loss_rpn_loc: 0.1909  time: 0.6542  data_time: 0.1489  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:38:48 d2.utils.events]: \u001b[0m eta: 0:52:58  iter: 3539  total_loss: 1.356  loss_cls: 0.2805  loss_box_reg: 0.5355  loss_mask: 0.2875  loss_rpn_cls: 0.05027  loss_rpn_loc: 0.1804  time: 0.6537  data_time: 0.1031  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:39:04 d2.utils.events]: \u001b[0m eta: 0:52:56  iter: 3559  total_loss: 1.671  loss_cls: 0.3821  loss_box_reg: 0.5888  loss_mask: 0.3029  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.2018  time: 0.6543  data_time: 0.2849  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:39:17 d2.utils.events]: \u001b[0m eta: 0:52:47  iter: 3579  total_loss: 1.478  loss_cls: 0.3196  loss_box_reg: 0.5529  loss_mask: 0.304  loss_rpn_cls: 0.0828  loss_rpn_loc: 0.21  time: 0.6544  data_time: 0.2022  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:39:28 d2.utils.events]: \u001b[0m eta: 0:52:32  iter: 3599  total_loss: 1.382  loss_cls: 0.3043  loss_box_reg: 0.5428  loss_mask: 0.3005  loss_rpn_cls: 0.06982  loss_rpn_loc: 0.1859  time: 0.6538  data_time: 0.0913  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:39:44 d2.utils.events]: \u001b[0m eta: 0:52:25  iter: 3619  total_loss: 1.475  loss_cls: 0.3397  loss_box_reg: 0.5607  loss_mask: 0.3143  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.1834  time: 0.6547  data_time: 0.3441  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:39:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:39:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:39:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:39:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:39:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:39:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0805 s/iter. Eval: 0.0443 s/iter. Total: 0.1255 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 16:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0638 s/iter. Total: 0.1478 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.0839 s/iter. Eval: 0.0648 s/iter. Total: 0.1496 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0655 s/iter. Total: 0.1506 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:40:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.550462 (0.151297 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:40:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084320 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:40:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:40:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26772920049329124\n",
      "\u001b[32m[02/04 16:40:14 d2.utils.events]: \u001b[0m eta: 0:52:11  iter: 3639  total_loss: 1.447  loss_cls: 0.3164  loss_box_reg: 0.5351  loss_mask: 0.2948  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.1879  time: 0.6541  data_time: 0.0933  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:40:27 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 3659  total_loss: 1.418  loss_cls: 0.2922  loss_box_reg: 0.5553  loss_mask: 0.3014  loss_rpn_cls: 0.06472  loss_rpn_loc: 0.1743  time: 0.6541  data_time: 0.1897  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:40:41 d2.utils.events]: \u001b[0m eta: 0:51:50  iter: 3679  total_loss: 1.448  loss_cls: 0.3098  loss_box_reg: 0.5362  loss_mask: 0.2926  loss_rpn_cls: 0.08117  loss_rpn_loc: 0.1809  time: 0.6541  data_time: 0.1865  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:40:52 d2.utils.events]: \u001b[0m eta: 0:51:46  iter: 3699  total_loss: 1.445  loss_cls: 0.3302  loss_box_reg: 0.5787  loss_mask: 0.3034  loss_rpn_cls: 0.05914  loss_rpn_loc: 0.1918  time: 0.6536  data_time: 0.0753  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:41:05 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 3719  total_loss: 1.422  loss_cls: 0.3153  loss_box_reg: 0.5433  loss_mask: 0.2961  loss_rpn_cls: 0.09499  loss_rpn_loc: 0.2134  time: 0.6537  data_time: 0.1912  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:41:21 d2.utils.events]: \u001b[0m eta: 0:51:29  iter: 3739  total_loss: 1.515  loss_cls: 0.3301  loss_box_reg: 0.5809  loss_mask: 0.3105  loss_rpn_cls: 0.08327  loss_rpn_loc: 0.2012  time: 0.6544  data_time: 0.3087  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:41:34 d2.utils.events]: \u001b[0m eta: 0:51:17  iter: 3759  total_loss: 1.436  loss_cls: 0.3207  loss_box_reg: 0.5398  loss_mask: 0.2971  loss_rpn_cls: 0.07006  loss_rpn_loc: 0.2045  time: 0.6545  data_time: 0.2197  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:41:50 d2.utils.events]: \u001b[0m eta: 0:51:07  iter: 3779  total_loss: 1.465  loss_cls: 0.3259  loss_box_reg: 0.574  loss_mask: 0.3121  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.1909  time: 0.6551  data_time: 0.2869  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:42:01 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 3799  total_loss: 1.343  loss_cls: 0.2868  loss_box_reg: 0.5415  loss_mask: 0.2829  loss_rpn_cls: 0.06876  loss_rpn_loc: 0.1763  time: 0.6547  data_time: 0.1074  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:42:17 d2.utils.events]: \u001b[0m eta: 0:50:59  iter: 3819  total_loss: 1.527  loss_cls: 0.35  loss_box_reg: 0.5826  loss_mask: 0.3072  loss_rpn_cls: 0.09402  loss_rpn_loc: 0.1961  time: 0.6554  data_time: 0.2865  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:42:31 d2.utils.events]: \u001b[0m eta: 0:50:52  iter: 3839  total_loss: 1.368  loss_cls: 0.312  loss_box_reg: 0.5396  loss_mask: 0.2821  loss_rpn_cls: 0.0646  loss_rpn_loc: 0.1837  time: 0.6557  data_time: 0.2247  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:42:45 d2.utils.events]: \u001b[0m eta: 0:50:36  iter: 3859  total_loss: 1.399  loss_cls: 0.2945  loss_box_reg: 0.5411  loss_mask: 0.2947  loss_rpn_cls: 0.08422  loss_rpn_loc: 0.1918  time: 0.6558  data_time: 0.2134  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:42:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:42:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:42:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:42:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:42:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:42:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0816 s/iter. Eval: 0.0490 s/iter. Total: 0.1312 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0674 s/iter. Total: 0.1538 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0692 s/iter. Total: 0.1556 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 16:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0724 s/iter. Total: 0.1594 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 16:43:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.555143 (0.159958 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:43:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086475 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:43:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:43:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2657969364318982\n",
      "\u001b[32m[02/04 16:43:16 d2.utils.events]: \u001b[0m eta: 0:50:17  iter: 3879  total_loss: 1.42  loss_cls: 0.3069  loss_box_reg: 0.5706  loss_mask: 0.3045  loss_rpn_cls: 0.07682  loss_rpn_loc: 0.1903  time: 0.6552  data_time: 0.0809  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:43:28 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 3899  total_loss: 1.519  loss_cls: 0.3183  loss_box_reg: 0.5779  loss_mask: 0.3172  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.2037  time: 0.6548  data_time: 0.1031  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:43:42 d2.utils.events]: \u001b[0m eta: 0:49:59  iter: 3919  total_loss: 1.581  loss_cls: 0.3872  loss_box_reg: 0.5881  loss_mask: 0.3166  loss_rpn_cls: 0.09339  loss_rpn_loc: 0.2174  time: 0.6553  data_time: 0.2497  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:43:55 d2.utils.events]: \u001b[0m eta: 0:49:48  iter: 3939  total_loss: 1.444  loss_cls: 0.3279  loss_box_reg: 0.5631  loss_mask: 0.3043  loss_rpn_cls: 0.09003  loss_rpn_loc: 0.1799  time: 0.6552  data_time: 0.1690  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:44:09 d2.utils.events]: \u001b[0m eta: 0:49:40  iter: 3959  total_loss: 1.407  loss_cls: 0.3072  loss_box_reg: 0.5553  loss_mask: 0.2891  loss_rpn_cls: 0.06527  loss_rpn_loc: 0.1827  time: 0.6554  data_time: 0.2189  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:44:21 d2.utils.events]: \u001b[0m eta: 0:49:32  iter: 3979  total_loss: 1.419  loss_cls: 0.3171  loss_box_reg: 0.5645  loss_mask: 0.3058  loss_rpn_cls: 0.07505  loss_rpn_loc: 0.1872  time: 0.6552  data_time: 0.1428  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:44:34 d2.utils.events]: \u001b[0m eta: 0:49:18  iter: 3999  total_loss: 1.378  loss_cls: 0.285  loss_box_reg: 0.5319  loss_mask: 0.2897  loss_rpn_cls: 0.07622  loss_rpn_loc: 0.1807  time: 0.6552  data_time: 0.1824  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:44:49 d2.utils.events]: \u001b[0m eta: 0:49:10  iter: 4019  total_loss: 1.449  loss_cls: 0.3108  loss_box_reg: 0.5332  loss_mask: 0.3008  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.2029  time: 0.6555  data_time: 0.2617  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:45:01 d2.utils.events]: \u001b[0m eta: 0:48:56  iter: 4039  total_loss: 1.425  loss_cls: 0.2881  loss_box_reg: 0.5699  loss_mask: 0.3131  loss_rpn_cls: 0.07379  loss_rpn_loc: 0.1819  time: 0.6552  data_time: 0.1375  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:45:14 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 4059  total_loss: 1.441  loss_cls: 0.3279  loss_box_reg: 0.5755  loss_mask: 0.3028  loss_rpn_cls: 0.06498  loss_rpn_loc: 0.1983  time: 0.6552  data_time: 0.1779  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:45:31 d2.utils.events]: \u001b[0m eta: 0:48:39  iter: 4079  total_loss: 1.447  loss_cls: 0.3288  loss_box_reg: 0.5516  loss_mask: 0.3048  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.1938  time: 0.6561  data_time: 0.3581  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:45:43 d2.utils.events]: \u001b[0m eta: 0:48:29  iter: 4099  total_loss: 1.404  loss_cls: 0.312  loss_box_reg: 0.5343  loss_mask: 0.2903  loss_rpn_cls: 0.07763  loss_rpn_loc: 0.167  time: 0.6560  data_time: 0.1487  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:45:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:45:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:45:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:45:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:45:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:45:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0809 s/iter. Eval: 0.0471 s/iter. Total: 0.1286 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0652 s/iter. Total: 0.1492 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0671 s/iter. Total: 0.1513 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0007 s/iter. Inference: 0.0836 s/iter. Eval: 0.0692 s/iter. Total: 0.1536 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:46:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.822773 (0.153645 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:46:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083675 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:46:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:46:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2684920152612817\n",
      "\u001b[32m[02/04 16:46:15 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 4119  total_loss: 1.479  loss_cls: 0.3326  loss_box_reg: 0.5629  loss_mask: 0.2875  loss_rpn_cls: 0.08378  loss_rpn_loc: 0.1878  time: 0.6557  data_time: 0.1231  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:46:29 d2.utils.events]: \u001b[0m eta: 0:48:06  iter: 4139  total_loss: 1.407  loss_cls: 0.3027  loss_box_reg: 0.5495  loss_mask: 0.2985  loss_rpn_cls: 0.09242  loss_rpn_loc: 0.1898  time: 0.6559  data_time: 0.2478  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:46:43 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 4159  total_loss: 1.562  loss_cls: 0.3479  loss_box_reg: 0.582  loss_mask: 0.3219  loss_rpn_cls: 0.09845  loss_rpn_loc: 0.1995  time: 0.6561  data_time: 0.2430  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:46:56 d2.utils.events]: \u001b[0m eta: 0:47:46  iter: 4179  total_loss: 1.421  loss_cls: 0.3156  loss_box_reg: 0.5445  loss_mask: 0.2847  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1788  time: 0.6562  data_time: 0.1981  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:47:06 d2.utils.events]: \u001b[0m eta: 0:47:33  iter: 4199  total_loss: 1.495  loss_cls: 0.324  loss_box_reg: 0.5856  loss_mask: 0.3006  loss_rpn_cls: 0.07324  loss_rpn_loc: 0.1845  time: 0.6555  data_time: 0.0349  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:47:19 d2.utils.events]: \u001b[0m eta: 0:47:22  iter: 4219  total_loss: 1.427  loss_cls: 0.3183  loss_box_reg: 0.5771  loss_mask: 0.3022  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.2018  time: 0.6554  data_time: 0.1672  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:47:34 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 4239  total_loss: 1.448  loss_cls: 0.3144  loss_box_reg: 0.5582  loss_mask: 0.3059  loss_rpn_cls: 0.08164  loss_rpn_loc: 0.1979  time: 0.6558  data_time: 0.2455  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:47:47 d2.utils.events]: \u001b[0m eta: 0:47:04  iter: 4259  total_loss: 1.451  loss_cls: 0.3263  loss_box_reg: 0.5526  loss_mask: 0.2998  loss_rpn_cls: 0.07276  loss_rpn_loc: 0.1943  time: 0.6558  data_time: 0.1914  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:48:00 d2.utils.events]: \u001b[0m eta: 0:46:56  iter: 4279  total_loss: 1.407  loss_cls: 0.318  loss_box_reg: 0.5372  loss_mask: 0.3048  loss_rpn_cls: 0.0788  loss_rpn_loc: 0.1855  time: 0.6557  data_time: 0.1686  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:48:15 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 4299  total_loss: 1.511  loss_cls: 0.3325  loss_box_reg: 0.5807  loss_mask: 0.3058  loss_rpn_cls: 0.08513  loss_rpn_loc: 0.2098  time: 0.6562  data_time: 0.2705  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:48:26 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 4319  total_loss: 1.439  loss_cls: 0.3264  loss_box_reg: 0.5449  loss_mask: 0.2941  loss_rpn_cls: 0.07766  loss_rpn_loc: 0.1991  time: 0.6558  data_time: 0.1122  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:48:40 d2.utils.events]: \u001b[0m eta: 0:46:27  iter: 4339  total_loss: 1.427  loss_cls: 0.3024  loss_box_reg: 0.5447  loss_mask: 0.3033  loss_rpn_cls: 0.06553  loss_rpn_loc: 0.1939  time: 0.6559  data_time: 0.2035  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:48:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:48:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:48:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:48:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:48:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:48:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0813 s/iter. Eval: 0.0471 s/iter. Total: 0.1290 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0845 s/iter. Eval: 0.0673 s/iter. Total: 0.1526 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0842 s/iter. Eval: 0.0695 s/iter. Total: 0.1546 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0847 s/iter. Eval: 0.0716 s/iter. Total: 0.1571 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 16:49:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.172031 (0.156655 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:49:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084712 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:49:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:49:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2665064468391706\n",
      "\u001b[32m[02/04 16:49:10 d2.utils.events]: \u001b[0m eta: 0:46:13  iter: 4359  total_loss: 1.296  loss_cls: 0.2607  loss_box_reg: 0.5386  loss_mask: 0.2838  loss_rpn_cls: 0.05141  loss_rpn_loc: 0.1747  time: 0.6553  data_time: 0.0580  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:49:23 d2.utils.events]: \u001b[0m eta: 0:46:02  iter: 4379  total_loss: 1.385  loss_cls: 0.3196  loss_box_reg: 0.581  loss_mask: 0.2896  loss_rpn_cls: 0.07218  loss_rpn_loc: 0.1986  time: 0.6553  data_time: 0.1655  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:49:36 d2.utils.events]: \u001b[0m eta: 0:45:58  iter: 4399  total_loss: 1.405  loss_cls: 0.3216  loss_box_reg: 0.5538  loss_mask: 0.2934  loss_rpn_cls: 0.0738  loss_rpn_loc: 0.1844  time: 0.6552  data_time: 0.1707  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:49:48 d2.utils.events]: \u001b[0m eta: 0:45:45  iter: 4419  total_loss: 1.423  loss_cls: 0.2762  loss_box_reg: 0.5575  loss_mask: 0.3062  loss_rpn_cls: 0.05987  loss_rpn_loc: 0.1896  time: 0.6549  data_time: 0.1206  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:50:00 d2.utils.events]: \u001b[0m eta: 0:45:38  iter: 4439  total_loss: 1.281  loss_cls: 0.2776  loss_box_reg: 0.5144  loss_mask: 0.2869  loss_rpn_cls: 0.05926  loss_rpn_loc: 0.1652  time: 0.6546  data_time: 0.1245  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:50:12 d2.utils.events]: \u001b[0m eta: 0:45:28  iter: 4459  total_loss: 1.556  loss_cls: 0.3566  loss_box_reg: 0.593  loss_mask: 0.3114  loss_rpn_cls: 0.08724  loss_rpn_loc: 0.196  time: 0.6545  data_time: 0.1486  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:50:24 d2.utils.events]: \u001b[0m eta: 0:45:19  iter: 4479  total_loss: 1.34  loss_cls: 0.2967  loss_box_reg: 0.5214  loss_mask: 0.2871  loss_rpn_cls: 0.07628  loss_rpn_loc: 0.1784  time: 0.6543  data_time: 0.1410  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:50:38 d2.utils.events]: \u001b[0m eta: 0:45:10  iter: 4499  total_loss: 1.505  loss_cls: 0.3396  loss_box_reg: 0.5783  loss_mask: 0.3122  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.1994  time: 0.6543  data_time: 0.1709  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:50:52 d2.utils.events]: \u001b[0m eta: 0:45:00  iter: 4519  total_loss: 1.496  loss_cls: 0.3325  loss_box_reg: 0.5559  loss_mask: 0.3095  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.2068  time: 0.6545  data_time: 0.2367  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:51:06 d2.utils.events]: \u001b[0m eta: 0:44:54  iter: 4539  total_loss: 1.456  loss_cls: 0.3202  loss_box_reg: 0.5668  loss_mask: 0.3172  loss_rpn_cls: 0.07532  loss_rpn_loc: 0.1926  time: 0.6547  data_time: 0.2330  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:51:23 d2.utils.events]: \u001b[0m eta: 0:44:42  iter: 4559  total_loss: 1.506  loss_cls: 0.3305  loss_box_reg: 0.5634  loss_mask: 0.3075  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1949  time: 0.6556  data_time: 0.3635  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:51:38 d2.utils.events]: \u001b[0m eta: 0:44:32  iter: 4579  total_loss: 1.484  loss_cls: 0.3177  loss_box_reg: 0.5422  loss_mask: 0.2911  loss_rpn_cls: 0.08017  loss_rpn_loc: 0.1929  time: 0.6560  data_time: 0.2496  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:51:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:51:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:51:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:51:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:51:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:51:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:51:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0857 s/iter. Eval: 0.0493 s/iter. Total: 0.1357 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:51:58 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0853 s/iter. Eval: 0.0664 s/iter. Total: 0.1525 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0007 s/iter. Inference: 0.0843 s/iter. Eval: 0.0675 s/iter. Total: 0.1526 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0008 s/iter. Inference: 0.0843 s/iter. Eval: 0.0690 s/iter. Total: 0.1541 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 16:52:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.937087 (0.154630 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:52:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084467 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:52:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:52:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27231771357096196\n",
      "\u001b[32m[02/04 16:52:11 d2.utils.events]: \u001b[0m eta: 0:44:31  iter: 4599  total_loss: 1.426  loss_cls: 0.3144  loss_box_reg: 0.5467  loss_mask: 0.2914  loss_rpn_cls: 0.07147  loss_rpn_loc: 0.1877  time: 0.6562  data_time: 0.2124  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:52:25 d2.utils.events]: \u001b[0m eta: 0:44:25  iter: 4619  total_loss: 1.505  loss_cls: 0.3309  loss_box_reg: 0.5917  loss_mask: 0.3192  loss_rpn_cls: 0.08287  loss_rpn_loc: 0.1999  time: 0.6562  data_time: 0.1906  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:52:36 d2.utils.events]: \u001b[0m eta: 0:44:15  iter: 4639  total_loss: 1.283  loss_cls: 0.2794  loss_box_reg: 0.5337  loss_mask: 0.2878  loss_rpn_cls: 0.05694  loss_rpn_loc: 0.1812  time: 0.6559  data_time: 0.1085  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:52:49 d2.utils.events]: \u001b[0m eta: 0:44:05  iter: 4659  total_loss: 1.427  loss_cls: 0.2902  loss_box_reg: 0.552  loss_mask: 0.2874  loss_rpn_cls: 0.0695  loss_rpn_loc: 0.1825  time: 0.6557  data_time: 0.1502  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:53:00 d2.utils.events]: \u001b[0m eta: 0:43:54  iter: 4679  total_loss: 1.391  loss_cls: 0.2697  loss_box_reg: 0.5473  loss_mask: 0.3084  loss_rpn_cls: 0.07294  loss_rpn_loc: 0.1871  time: 0.6553  data_time: 0.0946  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:53:17 d2.utils.events]: \u001b[0m eta: 0:43:45  iter: 4699  total_loss: 1.5  loss_cls: 0.335  loss_box_reg: 0.5643  loss_mask: 0.2913  loss_rpn_cls: 0.08578  loss_rpn_loc: 0.1927  time: 0.6560  data_time: 0.3346  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:53:31 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 4719  total_loss: 1.361  loss_cls: 0.3253  loss_box_reg: 0.5357  loss_mask: 0.2924  loss_rpn_cls: 0.07793  loss_rpn_loc: 0.1702  time: 0.6564  data_time: 0.2620  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:53:44 d2.utils.events]: \u001b[0m eta: 0:43:25  iter: 4739  total_loss: 1.571  loss_cls: 0.3494  loss_box_reg: 0.5879  loss_mask: 0.3103  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.204  time: 0.6563  data_time: 0.1612  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:53:58 d2.utils.events]: \u001b[0m eta: 0:43:15  iter: 4759  total_loss: 1.362  loss_cls: 0.3056  loss_box_reg: 0.5214  loss_mask: 0.2928  loss_rpn_cls: 0.06635  loss_rpn_loc: 0.1783  time: 0.6565  data_time: 0.2093  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:54:11 d2.utils.events]: \u001b[0m eta: 0:43:01  iter: 4779  total_loss: 1.389  loss_cls: 0.3026  loss_box_reg: 0.5529  loss_mask: 0.2942  loss_rpn_cls: 0.0586  loss_rpn_loc: 0.1805  time: 0.6564  data_time: 0.1712  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:54:23 d2.utils.events]: \u001b[0m eta: 0:42:49  iter: 4799  total_loss: 1.398  loss_cls: 0.2995  loss_box_reg: 0.5565  loss_mask: 0.2939  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.1863  time: 0.6562  data_time: 0.1537  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:54:38 d2.utils.events]: \u001b[0m eta: 0:42:39  iter: 4819  total_loss: 1.537  loss_cls: 0.3827  loss_box_reg: 0.5951  loss_mask: 0.3074  loss_rpn_cls: 0.08797  loss_rpn_loc: 0.1827  time: 0.6565  data_time: 0.2282  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:54:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:54:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:54:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:54:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:54:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:54:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0810 s/iter. Eval: 0.0461 s/iter. Total: 0.1277 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0842 s/iter. Eval: 0.0668 s/iter. Total: 0.1518 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0846 s/iter. Eval: 0.0687 s/iter. Total: 0.1541 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:55:10 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0847 s/iter. Eval: 0.0706 s/iter. Total: 0.1561 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 16:55:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.082194 (0.155881 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:55:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084555 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:55:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:55:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26735072155158857\n",
      "\u001b[32m[02/04 16:55:12 d2.utils.events]: \u001b[0m eta: 0:42:25  iter: 4839  total_loss: 1.521  loss_cls: 0.3303  loss_box_reg: 0.584  loss_mask: 0.3212  loss_rpn_cls: 0.08031  loss_rpn_loc: 0.1984  time: 0.6568  data_time: 0.2488  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:55:22 d2.utils.events]: \u001b[0m eta: 0:42:13  iter: 4859  total_loss: 1.295  loss_cls: 0.2722  loss_box_reg: 0.499  loss_mask: 0.2709  loss_rpn_cls: 0.05457  loss_rpn_loc: 0.1686  time: 0.6562  data_time: 0.0414  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:55:36 d2.utils.events]: \u001b[0m eta: 0:42:09  iter: 4879  total_loss: 1.372  loss_cls: 0.328  loss_box_reg: 0.5389  loss_mask: 0.2948  loss_rpn_cls: 0.07788  loss_rpn_loc: 0.1842  time: 0.6563  data_time: 0.2133  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:55:50 d2.utils.events]: \u001b[0m eta: 0:41:57  iter: 4899  total_loss: 1.523  loss_cls: 0.3628  loss_box_reg: 0.5804  loss_mask: 0.3075  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2018  time: 0.6565  data_time: 0.2002  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:56:03 d2.utils.events]: \u001b[0m eta: 0:41:42  iter: 4919  total_loss: 1.364  loss_cls: 0.2889  loss_box_reg: 0.5369  loss_mask: 0.2983  loss_rpn_cls: 0.06172  loss_rpn_loc: 0.1806  time: 0.6564  data_time: 0.1952  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:56:15 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 4939  total_loss: 1.389  loss_cls: 0.2929  loss_box_reg: 0.5463  loss_mask: 0.2967  loss_rpn_cls: 0.0607  loss_rpn_loc: 0.1828  time: 0.6563  data_time: 0.1442  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:56:27 d2.utils.events]: \u001b[0m eta: 0:41:22  iter: 4959  total_loss: 1.409  loss_cls: 0.3128  loss_box_reg: 0.5515  loss_mask: 0.2898  loss_rpn_cls: 0.07813  loss_rpn_loc: 0.186  time: 0.6561  data_time: 0.1589  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:56:41 d2.utils.events]: \u001b[0m eta: 0:41:12  iter: 4979  total_loss: 1.441  loss_cls: 0.3126  loss_box_reg: 0.5583  loss_mask: 0.316  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.2046  time: 0.6562  data_time: 0.1731  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:56:54 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 4999  total_loss: 1.524  loss_cls: 0.3371  loss_box_reg: 0.5613  loss_mask: 0.2952  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2114  time: 0.6562  data_time: 0.1903  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:57:10 d2.utils.events]: \u001b[0m eta: 0:40:57  iter: 5019  total_loss: 1.512  loss_cls: 0.3427  loss_box_reg: 0.5782  loss_mask: 0.3033  loss_rpn_cls: 0.08351  loss_rpn_loc: 0.2087  time: 0.6567  data_time: 0.2947  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:57:22 d2.utils.events]: \u001b[0m eta: 0:40:48  iter: 5039  total_loss: 1.466  loss_cls: 0.3197  loss_box_reg: 0.5777  loss_mask: 0.2983  loss_rpn_cls: 0.06995  loss_rpn_loc: 0.181  time: 0.6565  data_time: 0.1107  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:57:37 d2.utils.events]: \u001b[0m eta: 0:40:42  iter: 5059  total_loss: 1.464  loss_cls: 0.3181  loss_box_reg: 0.5702  loss_mask: 0.3031  loss_rpn_cls: 0.08438  loss_rpn_loc: 0.1778  time: 0.6569  data_time: 0.2710  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:57:50 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 5079  total_loss: 1.416  loss_cls: 0.3062  loss_box_reg: 0.555  loss_mask: 0.3048  loss_rpn_cls: 0.06466  loss_rpn_loc: 0.179  time: 0.6568  data_time: 0.1463  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:57:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:57:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 16:57:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 16:57:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 16:57:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 16:57:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 16:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0809 s/iter. Eval: 0.0486 s/iter. Total: 0.1301 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 16:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0670 s/iter. Total: 0.1518 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 16:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0844 s/iter. Eval: 0.0689 s/iter. Total: 0.1542 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 16:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0844 s/iter. Eval: 0.0707 s/iter. Total: 0.1559 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 16:58:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.012430 (0.155280 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:58:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084236 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 16:58:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 16:58:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2681800989807813\n",
      "\u001b[32m[02/04 16:58:24 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 5099  total_loss: 1.441  loss_cls: 0.3212  loss_box_reg: 0.5563  loss_mask: 0.3062  loss_rpn_cls: 0.08668  loss_rpn_loc: 0.1984  time: 0.6570  data_time: 0.2321  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:58:37 d2.utils.events]: \u001b[0m eta: 0:40:10  iter: 5119  total_loss: 1.435  loss_cls: 0.3206  loss_box_reg: 0.5595  loss_mask: 0.307  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.192  time: 0.6570  data_time: 0.1898  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:58:48 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 5139  total_loss: 1.413  loss_cls: 0.2973  loss_box_reg: 0.5639  loss_mask: 0.294  loss_rpn_cls: 0.0616  loss_rpn_loc: 0.1751  time: 0.6567  data_time: 0.1164  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:59:03 d2.utils.events]: \u001b[0m eta: 0:39:53  iter: 5159  total_loss: 1.527  loss_cls: 0.3418  loss_box_reg: 0.561  loss_mask: 0.3057  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2196  time: 0.6570  data_time: 0.2497  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:59:16 d2.utils.events]: \u001b[0m eta: 0:39:43  iter: 5179  total_loss: 1.437  loss_cls: 0.3263  loss_box_reg: 0.5449  loss_mask: 0.2947  loss_rpn_cls: 0.08995  loss_rpn_loc: 0.1932  time: 0.6570  data_time: 0.1715  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:59:28 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 5199  total_loss: 1.385  loss_cls: 0.2994  loss_box_reg: 0.5419  loss_mask: 0.3034  loss_rpn_cls: 0.05621  loss_rpn_loc: 0.1934  time: 0.6567  data_time: 0.1359  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:59:41 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 5219  total_loss: 1.382  loss_cls: 0.2954  loss_box_reg: 0.5292  loss_mask: 0.2882  loss_rpn_cls: 0.06566  loss_rpn_loc: 0.1854  time: 0.6568  data_time: 0.2144  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 16:59:56 d2.utils.events]: \u001b[0m eta: 0:39:15  iter: 5239  total_loss: 1.547  loss_cls: 0.3462  loss_box_reg: 0.5632  loss_mask: 0.3083  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.2066  time: 0.6571  data_time: 0.2504  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:00:09 d2.utils.events]: \u001b[0m eta: 0:39:04  iter: 5259  total_loss: 1.322  loss_cls: 0.2899  loss_box_reg: 0.5403  loss_mask: 0.2958  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.1711  time: 0.6571  data_time: 0.1998  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:00:22 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 5279  total_loss: 1.333  loss_cls: 0.281  loss_box_reg: 0.5211  loss_mask: 0.2889  loss_rpn_cls: 0.05788  loss_rpn_loc: 0.1712  time: 0.6570  data_time: 0.1598  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:00:37 d2.utils.events]: \u001b[0m eta: 0:38:41  iter: 5299  total_loss: 1.503  loss_cls: 0.3045  loss_box_reg: 0.5403  loss_mask: 0.305  loss_rpn_cls: 0.08911  loss_rpn_loc: 0.2059  time: 0.6574  data_time: 0.2746  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:00:49 d2.utils.events]: \u001b[0m eta: 0:38:33  iter: 5319  total_loss: 1.479  loss_cls: 0.3421  loss_box_reg: 0.5752  loss_mask: 0.2976  loss_rpn_cls: 0.08184  loss_rpn_loc: 0.1911  time: 0.6572  data_time: 0.1412  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:00:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:00:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:00:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:00:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:00:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:00:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0810 s/iter. Eval: 0.0470 s/iter. Total: 0.1287 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 17:00:59 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0669 s/iter. Total: 0.1510 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 17:01:04 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0834 s/iter. Eval: 0.0679 s/iter. Total: 0.1521 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 17:01:09 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0838 s/iter. Eval: 0.0707 s/iter. Total: 0.1553 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:01:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.992562 (0.155108 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:01:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083751 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:01:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:01:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26954951632664553\n",
      "\u001b[32m[02/04 17:01:18 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 5339  total_loss: 1.426  loss_cls: 0.2973  loss_box_reg: 0.5688  loss_mask: 0.2964  loss_rpn_cls: 0.06541  loss_rpn_loc: 0.1896  time: 0.6565  data_time: 0.0143  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:01:28 d2.utils.events]: \u001b[0m eta: 0:38:09  iter: 5359  total_loss: 1.381  loss_cls: 0.3018  loss_box_reg: 0.531  loss_mask: 0.2816  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.1844  time: 0.6559  data_time: 0.0463  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:01:42 d2.utils.events]: \u001b[0m eta: 0:37:58  iter: 5379  total_loss: 1.475  loss_cls: 0.3283  loss_box_reg: 0.5679  loss_mask: 0.3117  loss_rpn_cls: 0.05555  loss_rpn_loc: 0.1885  time: 0.6561  data_time: 0.2173  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:01:56 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 5399  total_loss: 1.491  loss_cls: 0.33  loss_box_reg: 0.5747  loss_mask: 0.2964  loss_rpn_cls: 0.07504  loss_rpn_loc: 0.1947  time: 0.6562  data_time: 0.2004  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:02:10 d2.utils.events]: \u001b[0m eta: 0:37:40  iter: 5419  total_loss: 1.554  loss_cls: 0.3531  loss_box_reg: 0.5864  loss_mask: 0.3148  loss_rpn_cls: 0.09674  loss_rpn_loc: 0.202  time: 0.6563  data_time: 0.2139  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:02:25 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 5439  total_loss: 1.518  loss_cls: 0.3343  loss_box_reg: 0.5731  loss_mask: 0.3078  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1927  time: 0.6567  data_time: 0.3008  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:02:39 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 5459  total_loss: 1.515  loss_cls: 0.3449  loss_box_reg: 0.5755  loss_mask: 0.3061  loss_rpn_cls: 0.08411  loss_rpn_loc: 0.1999  time: 0.6568  data_time: 0.1946  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:02:53 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 5479  total_loss: 1.373  loss_cls: 0.3008  loss_box_reg: 0.549  loss_mask: 0.294  loss_rpn_cls: 0.068  loss_rpn_loc: 0.184  time: 0.6570  data_time: 0.2654  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:03:05 d2.utils.events]: \u001b[0m eta: 0:36:53  iter: 5499  total_loss: 1.403  loss_cls: 0.2939  loss_box_reg: 0.5586  loss_mask: 0.2959  loss_rpn_cls: 0.05725  loss_rpn_loc: 0.1984  time: 0.6567  data_time: 0.1140  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:03:19 d2.utils.events]: \u001b[0m eta: 0:36:47  iter: 5519  total_loss: 1.408  loss_cls: 0.2947  loss_box_reg: 0.5517  loss_mask: 0.3024  loss_rpn_cls: 0.07643  loss_rpn_loc: 0.1889  time: 0.6569  data_time: 0.2396  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:03:32 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 5539  total_loss: 1.441  loss_cls: 0.3052  loss_box_reg: 0.5317  loss_mask: 0.2999  loss_rpn_cls: 0.06579  loss_rpn_loc: 0.1771  time: 0.6570  data_time: 0.2104  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:03:43 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 5559  total_loss: 1.427  loss_cls: 0.2866  loss_box_reg: 0.5335  loss_mask: 0.302  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.1838  time: 0.6566  data_time: 0.0987  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:03:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:03:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:03:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:03:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:03:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:03:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0824 s/iter. Eval: 0.0480 s/iter. Total: 0.1310 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 17:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0839 s/iter. Eval: 0.0662 s/iter. Total: 0.1509 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 17:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0837 s/iter. Eval: 0.0679 s/iter. Total: 0.1524 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 17:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0840 s/iter. Eval: 0.0708 s/iter. Total: 0.1556 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:04:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.977963 (0.154982 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:04:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083877 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:04:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:04:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2721852976100146\n",
      "\u001b[32m[02/04 17:04:16 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 5579  total_loss: 1.463  loss_cls: 0.3139  loss_box_reg: 0.5426  loss_mask: 0.3036  loss_rpn_cls: 0.0902  loss_rpn_loc: 0.1951  time: 0.6565  data_time: 0.1571  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:04:29 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 5599  total_loss: 1.414  loss_cls: 0.3273  loss_box_reg: 0.5934  loss_mask: 0.3036  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.1847  time: 0.6565  data_time: 0.1638  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:04:41 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 5619  total_loss: 1.405  loss_cls: 0.3049  loss_box_reg: 0.5576  loss_mask: 0.2951  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.1865  time: 0.6563  data_time: 0.1413  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:04:54 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 5639  total_loss: 1.441  loss_cls: 0.3122  loss_box_reg: 0.5656  loss_mask: 0.3105  loss_rpn_cls: 0.07475  loss_rpn_loc: 0.1985  time: 0.6564  data_time: 0.2101  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:05:07 d2.utils.events]: \u001b[0m eta: 0:35:29  iter: 5659  total_loss: 1.332  loss_cls: 0.3005  loss_box_reg: 0.4954  loss_mask: 0.2867  loss_rpn_cls: 0.07201  loss_rpn_loc: 0.1963  time: 0.6564  data_time: 0.1957  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:05:19 d2.utils.events]: \u001b[0m eta: 0:35:15  iter: 5679  total_loss: 1.343  loss_cls: 0.2916  loss_box_reg: 0.5485  loss_mask: 0.297  loss_rpn_cls: 0.05003  loss_rpn_loc: 0.1678  time: 0.6560  data_time: 0.1055  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:05:32 d2.utils.events]: \u001b[0m eta: 0:35:03  iter: 5699  total_loss: 1.415  loss_cls: 0.2989  loss_box_reg: 0.549  loss_mask: 0.2933  loss_rpn_cls: 0.07078  loss_rpn_loc: 0.1831  time: 0.6561  data_time: 0.2173  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:05:43 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 5719  total_loss: 1.31  loss_cls: 0.2718  loss_box_reg: 0.5187  loss_mask: 0.2977  loss_rpn_cls: 0.0558  loss_rpn_loc: 0.18  time: 0.6557  data_time: 0.0641  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:06:00 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 5739  total_loss: 1.467  loss_cls: 0.3341  loss_box_reg: 0.5406  loss_mask: 0.3047  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.1938  time: 0.6563  data_time: 0.3430  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:06:14 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 5759  total_loss: 1.413  loss_cls: 0.3128  loss_box_reg: 0.5545  loss_mask: 0.2945  loss_rpn_cls: 0.07289  loss_rpn_loc: 0.1814  time: 0.6566  data_time: 0.2563  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:06:26 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 5779  total_loss: 1.453  loss_cls: 0.3371  loss_box_reg: 0.5669  loss_mask: 0.3205  loss_rpn_cls: 0.06417  loss_rpn_loc: 0.1971  time: 0.6563  data_time: 0.1251  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:06:38 d2.utils.events]: \u001b[0m eta: 0:34:11  iter: 5799  total_loss: 1.403  loss_cls: 0.2899  loss_box_reg: 0.5463  loss_mask: 0.2972  loss_rpn_cls: 0.05821  loss_rpn_loc: 0.1902  time: 0.6562  data_time: 0.1758  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:06:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:06:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:06:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:06:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:06:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:06:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0810 s/iter. Eval: 0.0469 s/iter. Total: 0.1285 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 17:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0839 s/iter. Eval: 0.0656 s/iter. Total: 0.1503 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 17:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0007 s/iter. Inference: 0.0838 s/iter. Eval: 0.0671 s/iter. Total: 0.1517 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 17:07:05 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0007 s/iter. Inference: 0.0846 s/iter. Eval: 0.0698 s/iter. Total: 0.1551 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:07:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.945643 (0.154704 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:07:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084529 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:07:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:07:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26937595548135007\n",
      "\u001b[32m[02/04 17:07:16 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 5819  total_loss: 1.513  loss_cls: 0.3627  loss_box_reg: 0.5753  loss_mask: 0.3171  loss_rpn_cls: 0.08783  loss_rpn_loc: 0.2097  time: 0.6570  data_time: 0.3838  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:07:30 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 5839  total_loss: 1.564  loss_cls: 0.3401  loss_box_reg: 0.5686  loss_mask: 0.3053  loss_rpn_cls: 0.09284  loss_rpn_loc: 0.1853  time: 0.6572  data_time: 0.2167  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:07:42 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 5859  total_loss: 1.474  loss_cls: 0.3331  loss_box_reg: 0.5688  loss_mask: 0.3199  loss_rpn_cls: 0.06882  loss_rpn_loc: 0.1935  time: 0.6570  data_time: 0.1012  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:07:56 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 5879  total_loss: 1.388  loss_cls: 0.3038  loss_box_reg: 0.5477  loss_mask: 0.2897  loss_rpn_cls: 0.07202  loss_rpn_loc: 0.1782  time: 0.6572  data_time: 0.2316  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:08:08 d2.utils.events]: \u001b[0m eta: 0:33:27  iter: 5899  total_loss: 1.271  loss_cls: 0.2442  loss_box_reg: 0.5024  loss_mask: 0.2718  loss_rpn_cls: 0.05588  loss_rpn_loc: 0.1724  time: 0.6569  data_time: 0.0939  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:08:23 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 5919  total_loss: 1.352  loss_cls: 0.2895  loss_box_reg: 0.5332  loss_mask: 0.2999  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.1763  time: 0.6572  data_time: 0.2604  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:08:39 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 5939  total_loss: 1.412  loss_cls: 0.3193  loss_box_reg: 0.5435  loss_mask: 0.2904  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.1893  time: 0.6577  data_time: 0.3098  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:08:50 d2.utils.events]: \u001b[0m eta: 0:33:05  iter: 5959  total_loss: 1.461  loss_cls: 0.3145  loss_box_reg: 0.5381  loss_mask: 0.3081  loss_rpn_cls: 0.07972  loss_rpn_loc: 0.2029  time: 0.6574  data_time: 0.1041  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:09:04 d2.utils.events]: \u001b[0m eta: 0:32:55  iter: 5979  total_loss: 1.523  loss_cls: 0.3115  loss_box_reg: 0.5754  loss_mask: 0.3115  loss_rpn_cls: 0.08888  loss_rpn_loc: 0.2173  time: 0.6575  data_time: 0.2293  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:09:17 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 5999  total_loss: 1.425  loss_cls: 0.3157  loss_box_reg: 0.5388  loss_mask: 0.3029  loss_rpn_cls: 0.06806  loss_rpn_loc: 0.1899  time: 0.6575  data_time: 0.1687  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:09:33 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 6019  total_loss: 1.475  loss_cls: 0.3229  loss_box_reg: 0.5759  loss_mask: 0.3  loss_rpn_cls: 0.07969  loss_rpn_loc: 0.1973  time: 0.6580  data_time: 0.3153  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:09:43 d2.utils.events]: \u001b[0m eta: 0:32:18  iter: 6039  total_loss: 1.394  loss_cls: 0.3125  loss_box_reg: 0.5635  loss_mask: 0.2952  loss_rpn_cls: 0.07636  loss_rpn_loc: 0.1666  time: 0.6575  data_time: 0.0444  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:09:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:09:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:09:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:09:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:09:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:09:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:09:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0857 s/iter. Eval: 0.0518 s/iter. Total: 0.1381 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 17:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0678 s/iter. Total: 0.1562 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0704 s/iter. Total: 0.1585 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0736 s/iter. Total: 0.1620 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:10:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.693411 (0.161150 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:10:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087087 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:10:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:10:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26979935564388113\n",
      "\u001b[32m[02/04 17:10:17 d2.utils.events]: \u001b[0m eta: 0:32:08  iter: 6059  total_loss: 1.407  loss_cls: 0.3243  loss_box_reg: 0.5602  loss_mask: 0.3069  loss_rpn_cls: 0.08227  loss_rpn_loc: 0.1762  time: 0.6575  data_time: 0.1595  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:10:28 d2.utils.events]: \u001b[0m eta: 0:31:56  iter: 6079  total_loss: 1.287  loss_cls: 0.2939  loss_box_reg: 0.5224  loss_mask: 0.2847  loss_rpn_cls: 0.05743  loss_rpn_loc: 0.1637  time: 0.6571  data_time: 0.0828  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:10:45 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 6099  total_loss: 1.428  loss_cls: 0.2995  loss_box_reg: 0.5457  loss_mask: 0.3002  loss_rpn_cls: 0.08825  loss_rpn_loc: 0.1891  time: 0.6577  data_time: 0.3428  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:10:56 d2.utils.events]: \u001b[0m eta: 0:31:37  iter: 6119  total_loss: 1.4  loss_cls: 0.3128  loss_box_reg: 0.5652  loss_mask: 0.2983  loss_rpn_cls: 0.04667  loss_rpn_loc: 0.1773  time: 0.6573  data_time: 0.0761  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:11:10 d2.utils.events]: \u001b[0m eta: 0:31:30  iter: 6139  total_loss: 1.453  loss_cls: 0.2974  loss_box_reg: 0.5418  loss_mask: 0.3038  loss_rpn_cls: 0.07853  loss_rpn_loc: 0.211  time: 0.6575  data_time: 0.2287  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:11:24 d2.utils.events]: \u001b[0m eta: 0:31:24  iter: 6159  total_loss: 1.512  loss_cls: 0.3262  loss_box_reg: 0.5739  loss_mask: 0.3216  loss_rpn_cls: 0.07516  loss_rpn_loc: 0.1975  time: 0.6577  data_time: 0.2055  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:11:39 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 6179  total_loss: 1.478  loss_cls: 0.3258  loss_box_reg: 0.5501  loss_mask: 0.2967  loss_rpn_cls: 0.0787  loss_rpn_loc: 0.1854  time: 0.6580  data_time: 0.2467  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:11:53 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 6199  total_loss: 1.542  loss_cls: 0.3454  loss_box_reg: 0.5988  loss_mask: 0.3239  loss_rpn_cls: 0.08975  loss_rpn_loc: 0.1979  time: 0.6581  data_time: 0.1935  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:12:07 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 6219  total_loss: 1.441  loss_cls: 0.316  loss_box_reg: 0.56  loss_mask: 0.2933  loss_rpn_cls: 0.06486  loss_rpn_loc: 0.1866  time: 0.6583  data_time: 0.2108  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:12:20 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 6239  total_loss: 1.338  loss_cls: 0.3007  loss_box_reg: 0.5418  loss_mask: 0.2924  loss_rpn_cls: 0.0457  loss_rpn_loc: 0.1689  time: 0.6582  data_time: 0.1526  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:12:36 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 6259  total_loss: 1.555  loss_cls: 0.3389  loss_box_reg: 0.5903  loss_mask: 0.3055  loss_rpn_cls: 0.09187  loss_rpn_loc: 0.2034  time: 0.6586  data_time: 0.2680  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:12:49 d2.utils.events]: \u001b[0m eta: 0:30:44  iter: 6279  total_loss: 1.294  loss_cls: 0.2717  loss_box_reg: 0.5105  loss_mask: 0.2885  loss_rpn_cls: 0.06137  loss_rpn_loc: 0.1706  time: 0.6587  data_time: 0.1854  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:13:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:13:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:13:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:13:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:13:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:13:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:13:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0852 s/iter. Eval: 0.0495 s/iter. Total: 0.1354 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 17:13:07 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0662 s/iter. Total: 0.1545 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0694 s/iter. Total: 0.1578 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0725 s/iter. Total: 0.1616 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:13:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.926748 (0.163162 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:13:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088771 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:13:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:13:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27257785946206897\n",
      "\u001b[32m[02/04 17:13:25 d2.utils.events]: \u001b[0m eta: 0:30:35  iter: 6299  total_loss: 1.611  loss_cls: 0.3407  loss_box_reg: 0.5559  loss_mask: 0.3085  loss_rpn_cls: 0.08149  loss_rpn_loc: 0.1969  time: 0.6589  data_time: 0.2307  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:13:38 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 6319  total_loss: 1.312  loss_cls: 0.2569  loss_box_reg: 0.516  loss_mask: 0.2794  loss_rpn_cls: 0.04243  loss_rpn_loc: 0.1624  time: 0.6589  data_time: 0.1799  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:13:51 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 6339  total_loss: 1.431  loss_cls: 0.2784  loss_box_reg: 0.5524  loss_mask: 0.3083  loss_rpn_cls: 0.05538  loss_rpn_loc: 0.1921  time: 0.6589  data_time: 0.1660  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:14:06 d2.utils.events]: \u001b[0m eta: 0:30:17  iter: 6359  total_loss: 1.426  loss_cls: 0.3158  loss_box_reg: 0.5603  loss_mask: 0.2994  loss_rpn_cls: 0.09033  loss_rpn_loc: 0.1944  time: 0.6591  data_time: 0.2206  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:14:20 d2.utils.events]: \u001b[0m eta: 0:30:09  iter: 6379  total_loss: 1.482  loss_cls: 0.3267  loss_box_reg: 0.5327  loss_mask: 0.3071  loss_rpn_cls: 0.07981  loss_rpn_loc: 0.1977  time: 0.6593  data_time: 0.2296  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:14:32 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 6399  total_loss: 1.354  loss_cls: 0.2866  loss_box_reg: 0.5414  loss_mask: 0.2961  loss_rpn_cls: 0.05535  loss_rpn_loc: 0.1764  time: 0.6590  data_time: 0.0654  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:14:47 d2.utils.events]: \u001b[0m eta: 0:29:54  iter: 6419  total_loss: 1.507  loss_cls: 0.3383  loss_box_reg: 0.5419  loss_mask: 0.2965  loss_rpn_cls: 0.08169  loss_rpn_loc: 0.1882  time: 0.6593  data_time: 0.2484  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:14:58 d2.utils.events]: \u001b[0m eta: 0:29:45  iter: 6439  total_loss: 1.432  loss_cls: 0.348  loss_box_reg: 0.5488  loss_mask: 0.2942  loss_rpn_cls: 0.0676  loss_rpn_loc: 0.1826  time: 0.6590  data_time: 0.0761  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:15:11 d2.utils.events]: \u001b[0m eta: 0:29:34  iter: 6459  total_loss: 1.4  loss_cls: 0.317  loss_box_reg: 0.5569  loss_mask: 0.3016  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.1795  time: 0.6590  data_time: 0.1747  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:15:26 d2.utils.events]: \u001b[0m eta: 0:29:25  iter: 6479  total_loss: 1.497  loss_cls: 0.3222  loss_box_reg: 0.5475  loss_mask: 0.3101  loss_rpn_cls: 0.0809  loss_rpn_loc: 0.1977  time: 0.6593  data_time: 0.2183  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:15:40 d2.utils.events]: \u001b[0m eta: 0:29:19  iter: 6499  total_loss: 1.491  loss_cls: 0.3279  loss_box_reg: 0.5519  loss_mask: 0.2963  loss_rpn_cls: 0.09335  loss_rpn_loc: 0.2057  time: 0.6594  data_time: 0.2063  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:15:53 d2.utils.events]: \u001b[0m eta: 0:29:08  iter: 6519  total_loss: 1.299  loss_cls: 0.2786  loss_box_reg: 0.5424  loss_mask: 0.3012  loss_rpn_cls: 0.07127  loss_rpn_loc: 0.182  time: 0.6593  data_time: 0.1595  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:16:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:16:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:16:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:16:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:16:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:16:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:16:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0857 s/iter. Eval: 0.0498 s/iter. Total: 0.1361 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 17:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0689 s/iter. Total: 0.1576 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0695 s/iter. Total: 0.1580 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0733 s/iter. Total: 0.1623 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:16:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.763597 (0.161755 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:16:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088042 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:16:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:16:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27006304311423945\n",
      "\u001b[32m[02/04 17:16:26 d2.utils.events]: \u001b[0m eta: 0:28:59  iter: 6539  total_loss: 1.436  loss_cls: 0.3307  loss_box_reg: 0.5407  loss_mask: 0.286  loss_rpn_cls: 0.07978  loss_rpn_loc: 0.1784  time: 0.6592  data_time: 0.1469  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:16:41 d2.utils.events]: \u001b[0m eta: 0:28:52  iter: 6559  total_loss: 1.412  loss_cls: 0.3093  loss_box_reg: 0.5156  loss_mask: 0.3015  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1948  time: 0.6595  data_time: 0.2739  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:16:53 d2.utils.events]: \u001b[0m eta: 0:28:43  iter: 6579  total_loss: 1.378  loss_cls: 0.2819  loss_box_reg: 0.5425  loss_mask: 0.2969  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.1817  time: 0.6593  data_time: 0.1088  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:17:09 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 6599  total_loss: 1.443  loss_cls: 0.3121  loss_box_reg: 0.5464  loss_mask: 0.294  loss_rpn_cls: 0.07422  loss_rpn_loc: 0.1879  time: 0.6597  data_time: 0.2907  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:17:20 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 6619  total_loss: 1.452  loss_cls: 0.312  loss_box_reg: 0.5563  loss_mask: 0.2976  loss_rpn_cls: 0.08398  loss_rpn_loc: 0.1767  time: 0.6595  data_time: 0.1118  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:17:34 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 6639  total_loss: 1.468  loss_cls: 0.3187  loss_box_reg: 0.5404  loss_mask: 0.3015  loss_rpn_cls: 0.088  loss_rpn_loc: 0.2062  time: 0.6595  data_time: 0.1705  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:17:48 d2.utils.events]: \u001b[0m eta: 0:28:05  iter: 6659  total_loss: 1.541  loss_cls: 0.362  loss_box_reg: 0.5823  loss_mask: 0.3067  loss_rpn_cls: 0.08236  loss_rpn_loc: 0.2003  time: 0.6597  data_time: 0.2167  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:18:00 d2.utils.events]: \u001b[0m eta: 0:27:56  iter: 6679  total_loss: 1.345  loss_cls: 0.3007  loss_box_reg: 0.5319  loss_mask: 0.2915  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.1804  time: 0.6595  data_time: 0.1339  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:18:13 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 6699  total_loss: 1.362  loss_cls: 0.3036  loss_box_reg: 0.5478  loss_mask: 0.2988  loss_rpn_cls: 0.06471  loss_rpn_loc: 0.1757  time: 0.6594  data_time: 0.1541  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:18:24 d2.utils.events]: \u001b[0m eta: 0:27:36  iter: 6719  total_loss: 1.405  loss_cls: 0.2817  loss_box_reg: 0.5497  loss_mask: 0.284  loss_rpn_cls: 0.05258  loss_rpn_loc: 0.1626  time: 0.6591  data_time: 0.0996  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:18:38 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 6739  total_loss: 1.536  loss_cls: 0.3347  loss_box_reg: 0.5537  loss_mask: 0.3178  loss_rpn_cls: 0.08927  loss_rpn_loc: 0.2034  time: 0.6593  data_time: 0.2363  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:18:52 d2.utils.events]: \u001b[0m eta: 0:27:18  iter: 6759  total_loss: 1.526  loss_cls: 0.3368  loss_box_reg: 0.5613  loss_mask: 0.3112  loss_rpn_cls: 0.06597  loss_rpn_loc: 0.2118  time: 0.6593  data_time: 0.1981  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:19:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:19:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:19:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:19:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:19:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:19:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:19:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0859 s/iter. Eval: 0.0571 s/iter. Total: 0.1436 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 17:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0755 s/iter. Total: 0.1646 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 17:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0737 s/iter. Total: 0.1610 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0761 s/iter. Total: 0.1634 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:19:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.902219 (0.162950 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:19:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.086147 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:19:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:19:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2664666243577498\n",
      "\u001b[32m[02/04 17:19:29 d2.utils.events]: \u001b[0m eta: 0:27:12  iter: 6779  total_loss: 1.406  loss_cls: 0.3125  loss_box_reg: 0.551  loss_mask: 0.2939  loss_rpn_cls: 0.0869  loss_rpn_loc: 0.1902  time: 0.6599  data_time: 0.3411  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:19:46 d2.utils.events]: \u001b[0m eta: 0:27:04  iter: 6799  total_loss: 1.544  loss_cls: 0.3401  loss_box_reg: 0.5534  loss_mask: 0.3213  loss_rpn_cls: 0.08521  loss_rpn_loc: 0.1804  time: 0.6604  data_time: 0.3549  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:20:01 d2.utils.events]: \u001b[0m eta: 0:26:53  iter: 6819  total_loss: 1.492  loss_cls: 0.3448  loss_box_reg: 0.5762  loss_mask: 0.3057  loss_rpn_cls: 0.08572  loss_rpn_loc: 0.1888  time: 0.6607  data_time: 0.2467  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:20:16 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 6839  total_loss: 1.425  loss_cls: 0.3176  loss_box_reg: 0.5451  loss_mask: 0.2868  loss_rpn_cls: 0.07073  loss_rpn_loc: 0.1892  time: 0.6609  data_time: 0.2477  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:20:30 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 6859  total_loss: 1.385  loss_cls: 0.2999  loss_box_reg: 0.5431  loss_mask: 0.2927  loss_rpn_cls: 0.07003  loss_rpn_loc: 0.1799  time: 0.6610  data_time: 0.1898  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:20:42 d2.utils.events]: \u001b[0m eta: 0:26:21  iter: 6879  total_loss: 1.508  loss_cls: 0.3216  loss_box_reg: 0.545  loss_mask: 0.3043  loss_rpn_cls: 0.08508  loss_rpn_loc: 0.212  time: 0.6609  data_time: 0.1392  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:20:55 d2.utils.events]: \u001b[0m eta: 0:26:14  iter: 6899  total_loss: 1.348  loss_cls: 0.2823  loss_box_reg: 0.5284  loss_mask: 0.2841  loss_rpn_cls: 0.07575  loss_rpn_loc: 0.1916  time: 0.6608  data_time: 0.1422  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:21:07 d2.utils.events]: \u001b[0m eta: 0:26:02  iter: 6919  total_loss: 1.394  loss_cls: 0.3106  loss_box_reg: 0.5541  loss_mask: 0.3101  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.1851  time: 0.6607  data_time: 0.1546  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:21:20 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 6939  total_loss: 1.41  loss_cls: 0.3099  loss_box_reg: 0.5385  loss_mask: 0.2905  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.195  time: 0.6606  data_time: 0.1337  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:21:32 d2.utils.events]: \u001b[0m eta: 0:25:43  iter: 6959  total_loss: 1.342  loss_cls: 0.289  loss_box_reg: 0.531  loss_mask: 0.2919  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.1752  time: 0.6604  data_time: 0.1148  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:21:44 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 6979  total_loss: 1.325  loss_cls: 0.2858  loss_box_reg: 0.5382  loss_mask: 0.2836  loss_rpn_cls: 0.05415  loss_rpn_loc: 0.1688  time: 0.6602  data_time: 0.1135  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:21:59 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 6999  total_loss: 1.445  loss_cls: 0.3237  loss_box_reg: 0.5573  loss_mask: 0.3084  loss_rpn_cls: 0.0783  loss_rpn_loc: 0.196  time: 0.6605  data_time: 0.2572  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:22:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:22:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:22:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:22:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:22:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:22:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0854 s/iter. Eval: 0.0490 s/iter. Total: 0.1350 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 17:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0011 s/iter. Inference: 0.0906 s/iter. Eval: 0.0669 s/iter. Total: 0.1588 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0010 s/iter. Inference: 0.0905 s/iter. Eval: 0.0682 s/iter. Total: 0.1598 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0009 s/iter. Inference: 0.0907 s/iter. Eval: 0.0722 s/iter. Total: 0.1639 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:22:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.983531 (0.163651 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:22:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090739 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:22:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:22:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27576023091553903\n",
      "\u001b[32m[02/04 17:22:33 d2.utils.events]: \u001b[0m eta: 0:25:22  iter: 7019  total_loss: 1.38  loss_cls: 0.3153  loss_box_reg: 0.5423  loss_mask: 0.2875  loss_rpn_cls: 0.0766  loss_rpn_loc: 0.1896  time: 0.6605  data_time: 0.1468  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:22:48 d2.utils.events]: \u001b[0m eta: 0:25:14  iter: 7039  total_loss: 1.42  loss_cls: 0.3114  loss_box_reg: 0.5505  loss_mask: 0.3036  loss_rpn_cls: 0.0688  loss_rpn_loc: 0.202  time: 0.6608  data_time: 0.2572  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:23:03 d2.utils.events]: \u001b[0m eta: 0:25:04  iter: 7059  total_loss: 1.541  loss_cls: 0.3089  loss_box_reg: 0.5704  loss_mask: 0.3101  loss_rpn_cls: 0.09514  loss_rpn_loc: 0.2006  time: 0.6610  data_time: 0.2160  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:23:14 d2.utils.events]: \u001b[0m eta: 0:24:55  iter: 7079  total_loss: 1.39  loss_cls: 0.2886  loss_box_reg: 0.5517  loss_mask: 0.3033  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.1843  time: 0.6607  data_time: 0.0800  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:23:28 d2.utils.events]: \u001b[0m eta: 0:24:43  iter: 7099  total_loss: 1.386  loss_cls: 0.301  loss_box_reg: 0.5391  loss_mask: 0.2959  loss_rpn_cls: 0.07618  loss_rpn_loc: 0.1921  time: 0.6607  data_time: 0.2039  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:23:39 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 7119  total_loss: 1.37  loss_cls: 0.2964  loss_box_reg: 0.5234  loss_mask: 0.2764  loss_rpn_cls: 0.07273  loss_rpn_loc: 0.1719  time: 0.6605  data_time: 0.0702  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:23:51 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 7139  total_loss: 1.393  loss_cls: 0.2883  loss_box_reg: 0.531  loss_mask: 0.2999  loss_rpn_cls: 0.07946  loss_rpn_loc: 0.1763  time: 0.6603  data_time: 0.0951  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:24:01 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 7159  total_loss: 1.206  loss_cls: 0.2291  loss_box_reg: 0.5145  loss_mask: 0.2828  loss_rpn_cls: 0.05434  loss_rpn_loc: 0.1718  time: 0.6598  data_time: 0.0353  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:24:16 d2.utils.events]: \u001b[0m eta: 0:24:03  iter: 7179  total_loss: 1.403  loss_cls: 0.3366  loss_box_reg: 0.5301  loss_mask: 0.2846  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.1943  time: 0.6602  data_time: 0.2589  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:24:30 d2.utils.events]: \u001b[0m eta: 0:23:51  iter: 7199  total_loss: 1.451  loss_cls: 0.3468  loss_box_reg: 0.5563  loss_mask: 0.2953  loss_rpn_cls: 0.09575  loss_rpn_loc: 0.1994  time: 0.6603  data_time: 0.2019  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:24:45 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 7219  total_loss: 1.443  loss_cls: 0.3251  loss_box_reg: 0.5485  loss_mask: 0.3096  loss_rpn_cls: 0.07956  loss_rpn_loc: 0.1808  time: 0.6605  data_time: 0.2025  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:25:00 d2.utils.events]: \u001b[0m eta: 0:23:35  iter: 7239  total_loss: 1.407  loss_cls: 0.324  loss_box_reg: 0.5626  loss_mask: 0.3039  loss_rpn_cls: 0.07057  loss_rpn_loc: 0.1806  time: 0.6607  data_time: 0.2184  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:25:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:25:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:25:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:25:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:25:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:25:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0898 s/iter. Eval: 0.0588 s/iter. Total: 0.1493 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 17:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0708 s/iter. Total: 0.1603 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0866 s/iter. Eval: 0.0721 s/iter. Total: 0.1596 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:25:31 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0747 s/iter. Total: 0.1619 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:25:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.805653 (0.162118 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:25:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086417 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:25:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:25:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26814406591446494\n",
      "\u001b[32m[02/04 17:25:34 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 7259  total_loss: 1.483  loss_cls: 0.3315  loss_box_reg: 0.5599  loss_mask: 0.3059  loss_rpn_cls: 0.0891  loss_rpn_loc: 0.209  time: 0.6607  data_time: 0.2012  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:25:46 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 7279  total_loss: 1.26  loss_cls: 0.2356  loss_box_reg: 0.5377  loss_mask: 0.2932  loss_rpn_cls: 0.04563  loss_rpn_loc: 0.1729  time: 0.6605  data_time: 0.1092  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:25:57 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 7299  total_loss: 1.346  loss_cls: 0.3101  loss_box_reg: 0.5395  loss_mask: 0.2895  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.1613  time: 0.6603  data_time: 0.1232  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:26:09 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 7319  total_loss: 1.438  loss_cls: 0.3054  loss_box_reg: 0.5478  loss_mask: 0.3154  loss_rpn_cls: 0.06121  loss_rpn_loc: 0.184  time: 0.6600  data_time: 0.1125  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:26:23 d2.utils.events]: \u001b[0m eta: 0:22:38  iter: 7339  total_loss: 1.4  loss_cls: 0.297  loss_box_reg: 0.5402  loss_mask: 0.3004  loss_rpn_cls: 0.09253  loss_rpn_loc: 0.1777  time: 0.6602  data_time: 0.2425  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:26:38 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 7359  total_loss: 1.389  loss_cls: 0.3123  loss_box_reg: 0.5431  loss_mask: 0.3004  loss_rpn_cls: 0.06761  loss_rpn_loc: 0.2084  time: 0.6605  data_time: 0.2883  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:26:50 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 7379  total_loss: 1.354  loss_cls: 0.2876  loss_box_reg: 0.5422  loss_mask: 0.3053  loss_rpn_cls: 0.06109  loss_rpn_loc: 0.1747  time: 0.6603  data_time: 0.1464  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:27:02 d2.utils.events]: \u001b[0m eta: 0:22:01  iter: 7399  total_loss: 1.348  loss_cls: 0.2954  loss_box_reg: 0.5481  loss_mask: 0.3016  loss_rpn_cls: 0.06038  loss_rpn_loc: 0.1783  time: 0.6601  data_time: 0.1060  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:27:16 d2.utils.events]: \u001b[0m eta: 0:21:50  iter: 7419  total_loss: 1.43  loss_cls: 0.3214  loss_box_reg: 0.5513  loss_mask: 0.2813  loss_rpn_cls: 0.06353  loss_rpn_loc: 0.1829  time: 0.6602  data_time: 0.1933  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:27:29 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 7439  total_loss: 1.413  loss_cls: 0.3273  loss_box_reg: 0.5466  loss_mask: 0.286  loss_rpn_cls: 0.08007  loss_rpn_loc: 0.1771  time: 0.6603  data_time: 0.1939  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:27:46 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 7459  total_loss: 1.475  loss_cls: 0.3262  loss_box_reg: 0.5652  loss_mask: 0.3131  loss_rpn_cls: 0.08896  loss_rpn_loc: 0.1957  time: 0.6607  data_time: 0.3231  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:27:59 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 7479  total_loss: 1.534  loss_cls: 0.3298  loss_box_reg: 0.5772  loss_mask: 0.3133  loss_rpn_cls: 0.08227  loss_rpn_loc: 0.1979  time: 0.6606  data_time: 0.1503  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:28:15 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 7499  total_loss: 1.49  loss_cls: 0.3189  loss_box_reg: 0.5609  loss_mask: 0.3099  loss_rpn_cls: 0.09034  loss_rpn_loc: 0.2021  time: 0.6611  data_time: 0.3102  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:28:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:28:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:28:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:28:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:28:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:28:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0577 s/iter. Total: 0.1461 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 17:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0012 s/iter. Inference: 0.0879 s/iter. Eval: 0.0711 s/iter. Total: 0.1602 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0010 s/iter. Inference: 0.0882 s/iter. Eval: 0.0719 s/iter. Total: 0.1612 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0010 s/iter. Inference: 0.0885 s/iter. Eval: 0.0755 s/iter. Total: 0.1650 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:28:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.112595 (0.164764 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:28:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088389 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:28:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:28:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2699689577889346\n",
      "\u001b[32m[02/04 17:28:49 d2.utils.events]: \u001b[0m eta: 0:21:05  iter: 7519  total_loss: 1.411  loss_cls: 0.2992  loss_box_reg: 0.5437  loss_mask: 0.3023  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.1875  time: 0.6610  data_time: 0.1405  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:29:04 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 7539  total_loss: 1.403  loss_cls: 0.3268  loss_box_reg: 0.5487  loss_mask: 0.2954  loss_rpn_cls: 0.07515  loss_rpn_loc: 0.1896  time: 0.6613  data_time: 0.2735  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:29:17 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 7559  total_loss: 1.422  loss_cls: 0.3326  loss_box_reg: 0.5279  loss_mask: 0.2942  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.1833  time: 0.6613  data_time: 0.1579  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:29:32 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 7579  total_loss: 1.397  loss_cls: 0.2965  loss_box_reg: 0.5267  loss_mask: 0.2895  loss_rpn_cls: 0.07448  loss_rpn_loc: 0.1915  time: 0.6614  data_time: 0.2046  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:29:44 d2.utils.events]: \u001b[0m eta: 0:20:26  iter: 7599  total_loss: 1.381  loss_cls: 0.2933  loss_box_reg: 0.5553  loss_mask: 0.2939  loss_rpn_cls: 0.05602  loss_rpn_loc: 0.193  time: 0.6613  data_time: 0.1425  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:29:55 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 7619  total_loss: 1.356  loss_cls: 0.3024  loss_box_reg: 0.5376  loss_mask: 0.2885  loss_rpn_cls: 0.05986  loss_rpn_loc: 0.168  time: 0.6610  data_time: 0.0531  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:30:07 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 7639  total_loss: 1.41  loss_cls: 0.3172  loss_box_reg: 0.5415  loss_mask: 0.2957  loss_rpn_cls: 0.07837  loss_rpn_loc: 0.1806  time: 0.6609  data_time: 0.1315  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:30:22 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 7659  total_loss: 1.39  loss_cls: 0.3041  loss_box_reg: 0.5431  loss_mask: 0.3106  loss_rpn_cls: 0.06019  loss_rpn_loc: 0.1837  time: 0.6611  data_time: 0.2405  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:30:38 d2.utils.events]: \u001b[0m eta: 0:19:47  iter: 7679  total_loss: 1.481  loss_cls: 0.3228  loss_box_reg: 0.568  loss_mask: 0.3169  loss_rpn_cls: 0.07404  loss_rpn_loc: 0.1932  time: 0.6614  data_time: 0.2673  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:30:51 d2.utils.events]: \u001b[0m eta: 0:19:37  iter: 7699  total_loss: 1.408  loss_cls: 0.2865  loss_box_reg: 0.5396  loss_mask: 0.3082  loss_rpn_cls: 0.07934  loss_rpn_loc: 0.2  time: 0.6615  data_time: 0.1755  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:31:06 d2.utils.events]: \u001b[0m eta: 0:19:30  iter: 7719  total_loss: 1.427  loss_cls: 0.3165  loss_box_reg: 0.5154  loss_mask: 0.2907  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.1759  time: 0.6616  data_time: 0.2175  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:31:20 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 7739  total_loss: 1.461  loss_cls: 0.3158  loss_box_reg: 0.5845  loss_mask: 0.3058  loss_rpn_cls: 0.07122  loss_rpn_loc: 0.1884  time: 0.6618  data_time: 0.2135  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:31:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:31:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:31:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:31:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:31:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:31:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0011 s/iter. Inference: 0.0910 s/iter. Eval: 0.0646 s/iter. Total: 0.1568 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 17:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0009 s/iter. Inference: 0.0889 s/iter. Eval: 0.0717 s/iter. Total: 0.1616 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0009 s/iter. Inference: 0.0883 s/iter. Eval: 0.0723 s/iter. Total: 0.1615 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0761 s/iter. Total: 0.1657 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:31:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.182059 (0.165363 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:31:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088579 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:31:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:31:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.268553620133326\n",
      "\u001b[32m[02/04 17:31:54 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 7759  total_loss: 1.32  loss_cls: 0.2783  loss_box_reg: 0.5341  loss_mask: 0.2927  loss_rpn_cls: 0.06807  loss_rpn_loc: 0.1699  time: 0.6617  data_time: 0.1444  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:32:10 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 7779  total_loss: 1.433  loss_cls: 0.3022  loss_box_reg: 0.5254  loss_mask: 0.3003  loss_rpn_cls: 0.08002  loss_rpn_loc: 0.1926  time: 0.6621  data_time: 0.3151  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:32:25 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 7799  total_loss: 1.452  loss_cls: 0.3133  loss_box_reg: 0.5706  loss_mask: 0.2876  loss_rpn_cls: 0.07123  loss_rpn_loc: 0.1877  time: 0.6623  data_time: 0.2505  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:32:38 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 7819  total_loss: 1.445  loss_cls: 0.3126  loss_box_reg: 0.5414  loss_mask: 0.2985  loss_rpn_cls: 0.08661  loss_rpn_loc: 0.2015  time: 0.6623  data_time: 0.1607  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:32:53 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 7839  total_loss: 1.437  loss_cls: 0.3047  loss_box_reg: 0.534  loss_mask: 0.2942  loss_rpn_cls: 0.05986  loss_rpn_loc: 0.1984  time: 0.6624  data_time: 0.2230  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:33:07 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 7859  total_loss: 1.246  loss_cls: 0.2656  loss_box_reg: 0.5009  loss_mask: 0.2853  loss_rpn_cls: 0.06248  loss_rpn_loc: 0.1689  time: 0.6626  data_time: 0.2304  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:33:19 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 7879  total_loss: 1.379  loss_cls: 0.3063  loss_box_reg: 0.5421  loss_mask: 0.307  loss_rpn_cls: 0.06705  loss_rpn_loc: 0.1801  time: 0.6624  data_time: 0.1216  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:33:31 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 7899  total_loss: 1.213  loss_cls: 0.2525  loss_box_reg: 0.5151  loss_mask: 0.2808  loss_rpn_cls: 0.05879  loss_rpn_loc: 0.1568  time: 0.6622  data_time: 0.0864  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:33:46 d2.utils.events]: \u001b[0m eta: 0:17:44  iter: 7919  total_loss: 1.519  loss_cls: 0.3258  loss_box_reg: 0.5626  loss_mask: 0.3201  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.208  time: 0.6624  data_time: 0.2693  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:34:01 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 7939  total_loss: 1.52  loss_cls: 0.3291  loss_box_reg: 0.5584  loss_mask: 0.3031  loss_rpn_cls: 0.07942  loss_rpn_loc: 0.1937  time: 0.6626  data_time: 0.2525  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:34:13 d2.utils.events]: \u001b[0m eta: 0:17:24  iter: 7959  total_loss: 1.448  loss_cls: 0.3131  loss_box_reg: 0.5494  loss_mask: 0.2869  loss_rpn_cls: 0.0911  loss_rpn_loc: 0.1941  time: 0.6625  data_time: 0.1306  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:34:27 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 7979  total_loss: 1.449  loss_cls: 0.3223  loss_box_reg: 0.5707  loss_mask: 0.3074  loss_rpn_cls: 0.06053  loss_rpn_loc: 0.182  time: 0.6626  data_time: 0.1808  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:34:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:34:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:34:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:34:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:34:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:34:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0920 s/iter. Eval: 0.0668 s/iter. Total: 0.1596 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 17:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0901 s/iter. Eval: 0.0756 s/iter. Total: 0.1666 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 17:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0727 s/iter. Total: 0.1626 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0772 s/iter. Total: 0.1674 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 17:34:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.307400 (0.166443 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:34:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089234 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:34:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:34:53 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26963592213611187\n",
      "\u001b[32m[02/04 17:35:01 d2.utils.events]: \u001b[0m eta: 0:17:03  iter: 7999  total_loss: 1.429  loss_cls: 0.3241  loss_box_reg: 0.5609  loss_mask: 0.3066  loss_rpn_cls: 0.07192  loss_rpn_loc: 0.2062  time: 0.6625  data_time: 0.1578  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:35:14 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 8019  total_loss: 1.361  loss_cls: 0.3035  loss_box_reg: 0.5341  loss_mask: 0.2882  loss_rpn_cls: 0.06652  loss_rpn_loc: 0.1902  time: 0.6626  data_time: 0.1853  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:35:27 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 8039  total_loss: 1.383  loss_cls: 0.3019  loss_box_reg: 0.5326  loss_mask: 0.2925  loss_rpn_cls: 0.06254  loss_rpn_loc: 0.1799  time: 0.6625  data_time: 0.1545  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:35:42 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 8059  total_loss: 1.444  loss_cls: 0.3287  loss_box_reg: 0.5422  loss_mask: 0.3037  loss_rpn_cls: 0.07769  loss_rpn_loc: 0.1805  time: 0.6627  data_time: 0.2224  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:35:54 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 8079  total_loss: 1.377  loss_cls: 0.3161  loss_box_reg: 0.5583  loss_mask: 0.2899  loss_rpn_cls: 0.05641  loss_rpn_loc: 0.1839  time: 0.6625  data_time: 0.1065  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:36:08 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 8099  total_loss: 1.444  loss_cls: 0.3447  loss_box_reg: 0.547  loss_mask: 0.2913  loss_rpn_cls: 0.08433  loss_rpn_loc: 0.1921  time: 0.6626  data_time: 0.2047  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:36:18 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 8119  total_loss: 1.351  loss_cls: 0.2861  loss_box_reg: 0.5549  loss_mask: 0.2916  loss_rpn_cls: 0.0498  loss_rpn_loc: 0.1754  time: 0.6622  data_time: 0.0192  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:36:33 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 8139  total_loss: 1.382  loss_cls: 0.3135  loss_box_reg: 0.5397  loss_mask: 0.3118  loss_rpn_cls: 0.07607  loss_rpn_loc: 0.1951  time: 0.6625  data_time: 0.2603  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:36:46 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 8159  total_loss: 1.497  loss_cls: 0.3222  loss_box_reg: 0.5617  loss_mask: 0.2985  loss_rpn_cls: 0.06813  loss_rpn_loc: 0.1848  time: 0.6624  data_time: 0.1418  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:37:00 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 8179  total_loss: 1.422  loss_cls: 0.3152  loss_box_reg: 0.5382  loss_mask: 0.2927  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.1844  time: 0.6625  data_time: 0.1938  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:37:12 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 8199  total_loss: 1.415  loss_cls: 0.3206  loss_box_reg: 0.5392  loss_mask: 0.3005  loss_rpn_cls: 0.06728  loss_rpn_loc: 0.1901  time: 0.6624  data_time: 0.1368  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:37:26 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 8219  total_loss: 1.317  loss_cls: 0.2742  loss_box_reg: 0.5245  loss_mask: 0.2949  loss_rpn_cls: 0.05672  loss_rpn_loc: 0.1535  time: 0.6624  data_time: 0.1938  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:37:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:37:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:37:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:37:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:37:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:37:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0636 s/iter. Total: 0.1539 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 17:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0692 s/iter. Total: 0.1584 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0710 s/iter. Total: 0.1601 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0890 s/iter. Eval: 0.0754 s/iter. Total: 0.1652 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:37:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.062559 (0.164332 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:37:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088903 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:37:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:37:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2734621259987561\n",
      "\u001b[32m[02/04 17:38:02 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 8239  total_loss: 1.471  loss_cls: 0.329  loss_box_reg: 0.5549  loss_mask: 0.3007  loss_rpn_cls: 0.08798  loss_rpn_loc: 0.2009  time: 0.6626  data_time: 0.2134  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:38:15 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 8259  total_loss: 1.385  loss_cls: 0.3108  loss_box_reg: 0.5571  loss_mask: 0.2983  loss_rpn_cls: 0.06394  loss_rpn_loc: 0.1922  time: 0.6627  data_time: 0.1786  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:38:27 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 8279  total_loss: 1.355  loss_cls: 0.3248  loss_box_reg: 0.4973  loss_mask: 0.2663  loss_rpn_cls: 0.07373  loss_rpn_loc: 0.1887  time: 0.6625  data_time: 0.1039  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:38:42 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 8299  total_loss: 1.398  loss_cls: 0.3265  loss_box_reg: 0.5215  loss_mask: 0.2952  loss_rpn_cls: 0.09136  loss_rpn_loc: 0.1858  time: 0.6627  data_time: 0.2487  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:38:58 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 8319  total_loss: 1.49  loss_cls: 0.3301  loss_box_reg: 0.5734  loss_mask: 0.3101  loss_rpn_cls: 0.09349  loss_rpn_loc: 0.1993  time: 0.6630  data_time: 0.2824  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:39:13 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 8339  total_loss: 1.43  loss_cls: 0.3265  loss_box_reg: 0.562  loss_mask: 0.3101  loss_rpn_cls: 0.07461  loss_rpn_loc: 0.1754  time: 0.6632  data_time: 0.2296  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:39:28 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 8359  total_loss: 1.386  loss_cls: 0.2878  loss_box_reg: 0.5447  loss_mask: 0.296  loss_rpn_cls: 0.07457  loss_rpn_loc: 0.1871  time: 0.6634  data_time: 0.2509  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:39:40 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 8379  total_loss: 1.435  loss_cls: 0.3119  loss_box_reg: 0.5282  loss_mask: 0.3003  loss_rpn_cls: 0.06588  loss_rpn_loc: 0.1804  time: 0.6633  data_time: 0.1137  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:39:52 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 8399  total_loss: 1.356  loss_cls: 0.2657  loss_box_reg: 0.5297  loss_mask: 0.2886  loss_rpn_cls: 0.03763  loss_rpn_loc: 0.1916  time: 0.6631  data_time: 0.1185  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:40:06 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 8419  total_loss: 1.433  loss_cls: 0.3051  loss_box_reg: 0.5386  loss_mask: 0.3026  loss_rpn_cls: 0.06083  loss_rpn_loc: 0.1838  time: 0.6633  data_time: 0.2368  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:40:19 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 8439  total_loss: 1.337  loss_cls: 0.2654  loss_box_reg: 0.5365  loss_mask: 0.2983  loss_rpn_cls: 0.06295  loss_rpn_loc: 0.1794  time: 0.6632  data_time: 0.1262  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:40:33 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 8459  total_loss: 1.278  loss_cls: 0.2698  loss_box_reg: 0.5163  loss_mask: 0.29  loss_rpn_cls: 0.05381  loss_rpn_loc: 0.1791  time: 0.6633  data_time: 0.2253  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:40:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:40:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:40:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:40:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:40:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:40:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:40:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0903 s/iter. Eval: 0.0627 s/iter. Total: 0.1538 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 17:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0712 s/iter. Total: 0.1610 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0009 s/iter. Inference: 0.0883 s/iter. Eval: 0.0715 s/iter. Total: 0.1608 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0009 s/iter. Inference: 0.0887 s/iter. Eval: 0.0754 s/iter. Total: 0.1651 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:41:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.077974 (0.164465 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:41:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088564 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:41:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:41:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2704914012923237\n",
      "\u001b[32m[02/04 17:41:07 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 8479  total_loss: 1.364  loss_cls: 0.2915  loss_box_reg: 0.5379  loss_mask: 0.2965  loss_rpn_cls: 0.06501  loss_rpn_loc: 0.1713  time: 0.6632  data_time: 0.1380  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:41:23 d2.utils.events]: \u001b[0m eta: 0:12:54  iter: 8499  total_loss: 1.514  loss_cls: 0.3201  loss_box_reg: 0.558  loss_mask: 0.3039  loss_rpn_cls: 0.08306  loss_rpn_loc: 0.2104  time: 0.6636  data_time: 0.3170  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:41:38 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 8519  total_loss: 1.473  loss_cls: 0.326  loss_box_reg: 0.5628  loss_mask: 0.3008  loss_rpn_cls: 0.06503  loss_rpn_loc: 0.1847  time: 0.6637  data_time: 0.2290  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:41:53 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 8539  total_loss: 1.345  loss_cls: 0.298  loss_box_reg: 0.5166  loss_mask: 0.2927  loss_rpn_cls: 0.05347  loss_rpn_loc: 0.1814  time: 0.6640  data_time: 0.2820  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:42:05 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 8559  total_loss: 1.271  loss_cls: 0.2819  loss_box_reg: 0.5114  loss_mask: 0.2816  loss_rpn_cls: 0.03723  loss_rpn_loc: 0.1557  time: 0.6638  data_time: 0.1335  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:42:20 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 8579  total_loss: 1.54  loss_cls: 0.3361  loss_box_reg: 0.5745  loss_mask: 0.3127  loss_rpn_cls: 0.08223  loss_rpn_loc: 0.2109  time: 0.6640  data_time: 0.2326  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:42:33 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 8599  total_loss: 1.416  loss_cls: 0.2949  loss_box_reg: 0.5446  loss_mask: 0.2887  loss_rpn_cls: 0.06049  loss_rpn_loc: 0.1861  time: 0.6640  data_time: 0.1674  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:42:45 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 8619  total_loss: 1.425  loss_cls: 0.3365  loss_box_reg: 0.5338  loss_mask: 0.2949  loss_rpn_cls: 0.05079  loss_rpn_loc: 0.1682  time: 0.6638  data_time: 0.1161  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:42:58 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 8639  total_loss: 1.427  loss_cls: 0.3134  loss_box_reg: 0.5408  loss_mask: 0.2945  loss_rpn_cls: 0.07447  loss_rpn_loc: 0.1911  time: 0.6638  data_time: 0.1710  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:43:10 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 8659  total_loss: 1.259  loss_cls: 0.2778  loss_box_reg: 0.5308  loss_mask: 0.2787  loss_rpn_cls: 0.05894  loss_rpn_loc: 0.1842  time: 0.6637  data_time: 0.1040  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:43:23 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 8679  total_loss: 1.352  loss_cls: 0.3127  loss_box_reg: 0.5129  loss_mask: 0.2701  loss_rpn_cls: 0.08047  loss_rpn_loc: 0.1852  time: 0.6636  data_time: 0.1624  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:43:40 d2.utils.events]: \u001b[0m eta: 0:11:09  iter: 8699  total_loss: 1.479  loss_cls: 0.3542  loss_box_reg: 0.5747  loss_mask: 0.3008  loss_rpn_cls: 0.09095  loss_rpn_loc: 0.178  time: 0.6641  data_time: 0.3346  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:43:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:43:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:43:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:43:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:43:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:43:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0889 s/iter. Eval: 0.0635 s/iter. Total: 0.1533 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 17:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0749 s/iter. Total: 0.1652 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 17:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0725 s/iter. Total: 0.1620 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0768 s/iter. Total: 0.1666 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 17:44:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.266748 (0.166093 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:44:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088915 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:44:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:44:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26939698865212836\n",
      "\u001b[32m[02/04 17:44:16 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 8719  total_loss: 1.502  loss_cls: 0.3148  loss_box_reg: 0.5644  loss_mask: 0.3143  loss_rpn_cls: 0.08654  loss_rpn_loc: 0.2092  time: 0.6642  data_time: 0.2192  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:44:28 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 8739  total_loss: 1.375  loss_cls: 0.2643  loss_box_reg: 0.5488  loss_mask: 0.303  loss_rpn_cls: 0.0533  loss_rpn_loc: 0.1878  time: 0.6641  data_time: 0.1334  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:44:39 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 8759  total_loss: 1.397  loss_cls: 0.3068  loss_box_reg: 0.5308  loss_mask: 0.2871  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.1742  time: 0.6639  data_time: 0.0820  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:44:52 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 8779  total_loss: 1.465  loss_cls: 0.3117  loss_box_reg: 0.5652  loss_mask: 0.3179  loss_rpn_cls: 0.06896  loss_rpn_loc: 0.1988  time: 0.6638  data_time: 0.1494  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:45:08 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 8799  total_loss: 1.327  loss_cls: 0.3204  loss_box_reg: 0.5203  loss_mask: 0.2806  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.176  time: 0.6641  data_time: 0.2789  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:45:22 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 8819  total_loss: 1.567  loss_cls: 0.3583  loss_box_reg: 0.5646  loss_mask: 0.3011  loss_rpn_cls: 0.07984  loss_rpn_loc: 0.2014  time: 0.6642  data_time: 0.2379  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:45:34 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 8839  total_loss: 1.408  loss_cls: 0.3245  loss_box_reg: 0.5522  loss_mask: 0.2983  loss_rpn_cls: 0.058  loss_rpn_loc: 0.1769  time: 0.6641  data_time: 0.1087  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:45:50 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 8859  total_loss: 1.407  loss_cls: 0.3069  loss_box_reg: 0.5368  loss_mask: 0.3021  loss_rpn_cls: 0.08998  loss_rpn_loc: 0.1828  time: 0.6643  data_time: 0.2600  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:46:05 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 8879  total_loss: 1.458  loss_cls: 0.3275  loss_box_reg: 0.5555  loss_mask: 0.3135  loss_rpn_cls: 0.06816  loss_rpn_loc: 0.1876  time: 0.6645  data_time: 0.2532  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:46:17 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 8899  total_loss: 1.459  loss_cls: 0.3135  loss_box_reg: 0.5529  loss_mask: 0.29  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.1866  time: 0.6644  data_time: 0.1268  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:46:31 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 8919  total_loss: 1.448  loss_cls: 0.3038  loss_box_reg: 0.5487  loss_mask: 0.3096  loss_rpn_cls: 0.06396  loss_rpn_loc: 0.2003  time: 0.6644  data_time: 0.1623  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:46:46 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 8939  total_loss: 1.454  loss_cls: 0.3423  loss_box_reg: 0.565  loss_mask: 0.2971  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.1892  time: 0.6646  data_time: 0.2313  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:46:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:46:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:46:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:46:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:46:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:46:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0946 s/iter. Eval: 0.0671 s/iter. Total: 0.1625 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 17:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0788 s/iter. Total: 0.1706 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 17:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0757 s/iter. Total: 0.1654 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0795 s/iter. Total: 0.1700 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 17:47:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.614202 (0.169088 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:47:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089575 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:47:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:47:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2721966676233822\n",
      "\u001b[32m[02/04 17:47:23 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 8959  total_loss: 1.378  loss_cls: 0.2927  loss_box_reg: 0.5531  loss_mask: 0.3122  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.1865  time: 0.6649  data_time: 0.3134  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:47:37 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 8979  total_loss: 1.437  loss_cls: 0.3122  loss_box_reg: 0.5504  loss_mask: 0.2945  loss_rpn_cls: 0.07293  loss_rpn_loc: 0.1756  time: 0.6650  data_time: 0.1909  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:47:52 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 8999  total_loss: 1.397  loss_cls: 0.3233  loss_box_reg: 0.5038  loss_mask: 0.2821  loss_rpn_cls: 0.05449  loss_rpn_loc: 0.1962  time: 0.6651  data_time: 0.2290  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:48:05 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 9019  total_loss: 1.381  loss_cls: 0.3164  loss_box_reg: 0.529  loss_mask: 0.3018  loss_rpn_cls: 0.07416  loss_rpn_loc: 0.1833  time: 0.6652  data_time: 0.1782  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:48:18 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 9039  total_loss: 1.396  loss_cls: 0.28  loss_box_reg: 0.5472  loss_mask: 0.3033  loss_rpn_cls: 0.06899  loss_rpn_loc: 0.1884  time: 0.6651  data_time: 0.1346  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:48:31 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 9059  total_loss: 1.393  loss_cls: 0.3066  loss_box_reg: 0.5475  loss_mask: 0.2993  loss_rpn_cls: 0.06439  loss_rpn_loc: 0.1706  time: 0.6650  data_time: 0.1568  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:48:44 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 9079  total_loss: 1.558  loss_cls: 0.3435  loss_box_reg: 0.5617  loss_mask: 0.3166  loss_rpn_cls: 0.08841  loss_rpn_loc: 0.2051  time: 0.6650  data_time: 0.1696  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:48:59 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 9099  total_loss: 1.557  loss_cls: 0.3691  loss_box_reg: 0.5724  loss_mask: 0.3101  loss_rpn_cls: 0.1172  loss_rpn_loc: 0.2043  time: 0.6652  data_time: 0.2487  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:49:10 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 9119  total_loss: 1.348  loss_cls: 0.2881  loss_box_reg: 0.5466  loss_mask: 0.2945  loss_rpn_cls: 0.05807  loss_rpn_loc: 0.1599  time: 0.6649  data_time: 0.0722  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:49:22 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 9139  total_loss: 1.345  loss_cls: 0.2901  loss_box_reg: 0.5236  loss_mask: 0.2739  loss_rpn_cls: 0.06567  loss_rpn_loc: 0.1865  time: 0.6648  data_time: 0.1343  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:49:36 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 9159  total_loss: 1.401  loss_cls: 0.3291  loss_box_reg: 0.5294  loss_mask: 0.2915  loss_rpn_cls: 0.05734  loss_rpn_loc: 0.1684  time: 0.6648  data_time: 0.1757  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:49:51 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 9179  total_loss: 1.464  loss_cls: 0.3347  loss_box_reg: 0.5729  loss_mask: 0.3122  loss_rpn_cls: 0.0681  loss_rpn_loc: 0.1948  time: 0.6651  data_time: 0.2931  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:50:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:50:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:50:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:50:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:50:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:50:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0014 s/iter. Inference: 0.0891 s/iter. Eval: 0.0625 s/iter. Total: 0.1531 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 17:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.0895 s/iter. Eval: 0.0745 s/iter. Total: 0.1650 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 17:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0009 s/iter. Inference: 0.0887 s/iter. Eval: 0.0721 s/iter. Total: 0.1617 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0009 s/iter. Inference: 0.0891 s/iter. Eval: 0.0768 s/iter. Total: 0.1669 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 17:50:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.306048 (0.166431 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:50:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089131 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:50:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:50:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2727042126931741\n",
      "\u001b[32m[02/04 17:50:27 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 9199  total_loss: 1.431  loss_cls: 0.318  loss_box_reg: 0.5522  loss_mask: 0.2922  loss_rpn_cls: 0.07647  loss_rpn_loc: 0.186  time: 0.6652  data_time: 0.2062  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:50:40 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 9219  total_loss: 1.333  loss_cls: 0.2841  loss_box_reg: 0.5429  loss_mask: 0.2835  loss_rpn_cls: 0.05547  loss_rpn_loc: 0.173  time: 0.6652  data_time: 0.1751  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:50:54 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 9239  total_loss: 1.465  loss_cls: 0.3265  loss_box_reg: 0.5412  loss_mask: 0.3011  loss_rpn_cls: 0.08646  loss_rpn_loc: 0.187  time: 0.6653  data_time: 0.2242  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:51:08 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 9259  total_loss: 1.398  loss_cls: 0.294  loss_box_reg: 0.545  loss_mask: 0.2919  loss_rpn_cls: 0.06206  loss_rpn_loc: 0.1797  time: 0.6653  data_time: 0.1966  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:51:19 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 9279  total_loss: 1.385  loss_cls: 0.3023  loss_box_reg: 0.5343  loss_mask: 0.2915  loss_rpn_cls: 0.05796  loss_rpn_loc: 0.1666  time: 0.6651  data_time: 0.0824  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:51:30 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 9299  total_loss: 1.426  loss_cls: 0.3189  loss_box_reg: 0.5554  loss_mask: 0.2928  loss_rpn_cls: 0.07007  loss_rpn_loc: 0.1683  time: 0.6648  data_time: 0.0651  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:51:47 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 9319  total_loss: 1.532  loss_cls: 0.3746  loss_box_reg: 0.5699  loss_mask: 0.3058  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.1986  time: 0.6652  data_time: 0.3280  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:52:01 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 9339  total_loss: 1.576  loss_cls: 0.3437  loss_box_reg: 0.5865  loss_mask: 0.3081  loss_rpn_cls: 0.09527  loss_rpn_loc: 0.2044  time: 0.6653  data_time: 0.2026  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:52:16 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 9359  total_loss: 1.435  loss_cls: 0.3243  loss_box_reg: 0.5437  loss_mask: 0.2964  loss_rpn_cls: 0.06996  loss_rpn_loc: 0.2008  time: 0.6655  data_time: 0.2535  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:52:29 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 9379  total_loss: 1.426  loss_cls: 0.322  loss_box_reg: 0.5482  loss_mask: 0.3035  loss_rpn_cls: 0.0662  loss_rpn_loc: 0.1845  time: 0.6655  data_time: 0.1839  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:52:47 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 9399  total_loss: 1.552  loss_cls: 0.3487  loss_box_reg: 0.5635  loss_mask: 0.3124  loss_rpn_cls: 0.08574  loss_rpn_loc: 0.1996  time: 0.6660  data_time: 0.3907  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:52:58 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 9419  total_loss: 1.296  loss_cls: 0.2973  loss_box_reg: 0.5391  loss_mask: 0.2839  loss_rpn_cls: 0.05045  loss_rpn_loc: 0.179  time: 0.6657  data_time: 0.0331  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:53:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:53:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:53:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:53:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:53:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:53:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0035 s/iter. Inference: 0.0900 s/iter. Eval: 0.0686 s/iter. Total: 0.1622 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 17:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0013 s/iter. Inference: 0.0888 s/iter. Eval: 0.0744 s/iter. Total: 0.1645 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 17:53:25 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0010 s/iter. Inference: 0.0883 s/iter. Eval: 0.0728 s/iter. Total: 0.1623 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0010 s/iter. Inference: 0.0887 s/iter. Eval: 0.0761 s/iter. Total: 0.1658 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 17:53:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.135915 (0.164965 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:53:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088594 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:53:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:53:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2684413755841257\n",
      "\u001b[32m[02/04 17:53:34 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 9439  total_loss: 1.348  loss_cls: 0.2858  loss_box_reg: 0.5256  loss_mask: 0.2937  loss_rpn_cls: 0.0471  loss_rpn_loc: 0.1542  time: 0.6658  data_time: 0.2285  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:53:46 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 9459  total_loss: 1.441  loss_cls: 0.3212  loss_box_reg: 0.5552  loss_mask: 0.2892  loss_rpn_cls: 0.09115  loss_rpn_loc: 0.1942  time: 0.6658  data_time: 0.1669  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:54:01 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 9479  total_loss: 1.46  loss_cls: 0.3094  loss_box_reg: 0.5647  loss_mask: 0.305  loss_rpn_cls: 0.06555  loss_rpn_loc: 0.1953  time: 0.6659  data_time: 0.2344  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:54:17 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9499  total_loss: 1.337  loss_cls: 0.2861  loss_box_reg: 0.5364  loss_mask: 0.2938  loss_rpn_cls: 0.05238  loss_rpn_loc: 0.1615  time: 0.6662  data_time: 0.3120  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:54:30 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 9519  total_loss: 1.421  loss_cls: 0.3049  loss_box_reg: 0.5476  loss_mask: 0.2905  loss_rpn_cls: 0.0627  loss_rpn_loc: 0.1856  time: 0.6662  data_time: 0.1411  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:54:43 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 9539  total_loss: 1.371  loss_cls: 0.2982  loss_box_reg: 0.5423  loss_mask: 0.2818  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1757  time: 0.6661  data_time: 0.1459  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:54:55 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 9559  total_loss: 1.429  loss_cls: 0.3007  loss_box_reg: 0.5588  loss_mask: 0.2987  loss_rpn_cls: 0.07601  loss_rpn_loc: 0.1843  time: 0.6660  data_time: 0.1325  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:55:07 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 9579  total_loss: 1.428  loss_cls: 0.3063  loss_box_reg: 0.5595  loss_mask: 0.303  loss_rpn_cls: 0.07732  loss_rpn_loc: 0.1932  time: 0.6659  data_time: 0.1233  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:55:21 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 9599  total_loss: 1.334  loss_cls: 0.3001  loss_box_reg: 0.5013  loss_mask: 0.2917  loss_rpn_cls: 0.08772  loss_rpn_loc: 0.1762  time: 0.6660  data_time: 0.2138  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:55:35 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 9619  total_loss: 1.382  loss_cls: 0.3157  loss_box_reg: 0.5233  loss_mask: 0.2979  loss_rpn_cls: 0.06383  loss_rpn_loc: 0.1841  time: 0.6660  data_time: 0.1999  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:55:49 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 9639  total_loss: 1.473  loss_cls: 0.3197  loss_box_reg: 0.5467  loss_mask: 0.3048  loss_rpn_cls: 0.07053  loss_rpn_loc: 0.1902  time: 0.6661  data_time: 0.2052  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:56:04 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 9659  total_loss: 1.496  loss_cls: 0.3204  loss_box_reg: 0.5731  loss_mask: 0.3061  loss_rpn_cls: 0.07491  loss_rpn_loc: 0.1922  time: 0.6663  data_time: 0.2172  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:56:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:56:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:56:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:56:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:56:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:56:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:56:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0627 s/iter. Total: 0.1528 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 17:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.0896 s/iter. Eval: 0.0761 s/iter. Total: 0.1666 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 17:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0730 s/iter. Total: 0.1625 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0774 s/iter. Total: 0.1676 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 17:56:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.375674 (0.167032 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:56:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089186 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:56:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:56:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27200677584567123\n",
      "\u001b[32m[02/04 17:56:37 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 9679  total_loss: 1.457  loss_cls: 0.3176  loss_box_reg: 0.5579  loss_mask: 0.3077  loss_rpn_cls: 0.06335  loss_rpn_loc: 0.1895  time: 0.6661  data_time: 0.0953  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:56:48 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 9699  total_loss: 1.368  loss_cls: 0.2795  loss_box_reg: 0.5468  loss_mask: 0.3103  loss_rpn_cls: 0.05029  loss_rpn_loc: 0.1801  time: 0.6658  data_time: 0.0492  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:57:05 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 9719  total_loss: 1.417  loss_cls: 0.3183  loss_box_reg: 0.5399  loss_mask: 0.2948  loss_rpn_cls: 0.07505  loss_rpn_loc: 0.1928  time: 0.6662  data_time: 0.3537  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:57:19 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 9739  total_loss: 1.269  loss_cls: 0.2658  loss_box_reg: 0.491  loss_mask: 0.2863  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.1801  time: 0.6663  data_time: 0.2204  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:57:33 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 9759  total_loss: 1.391  loss_cls: 0.2903  loss_box_reg: 0.5382  loss_mask: 0.2898  loss_rpn_cls: 0.05326  loss_rpn_loc: 0.1782  time: 0.6664  data_time: 0.2079  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:57:46 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 9779  total_loss: 1.315  loss_cls: 0.2614  loss_box_reg: 0.5109  loss_mask: 0.2763  loss_rpn_cls: 0.05866  loss_rpn_loc: 0.1772  time: 0.6663  data_time: 0.1475  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:57:57 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 9799  total_loss: 1.343  loss_cls: 0.294  loss_box_reg: 0.5225  loss_mask: 0.2852  loss_rpn_cls: 0.07873  loss_rpn_loc: 0.17  time: 0.6661  data_time: 0.0879  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:58:10 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 9819  total_loss: 1.393  loss_cls: 0.3114  loss_box_reg: 0.5421  loss_mask: 0.3081  loss_rpn_cls: 0.06322  loss_rpn_loc: 0.1791  time: 0.6661  data_time: 0.1838  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:58:24 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 9839  total_loss: 1.389  loss_cls: 0.3099  loss_box_reg: 0.5262  loss_mask: 0.3034  loss_rpn_cls: 0.08418  loss_rpn_loc: 0.1811  time: 0.6661  data_time: 0.1846  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:58:41 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 9859  total_loss: 1.468  loss_cls: 0.3112  loss_box_reg: 0.5674  loss_mask: 0.3075  loss_rpn_cls: 0.0798  loss_rpn_loc: 0.1937  time: 0.6665  data_time: 0.3385  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:58:54 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 9879  total_loss: 1.465  loss_cls: 0.339  loss_box_reg: 0.5775  loss_mask: 0.3038  loss_rpn_cls: 0.05838  loss_rpn_loc: 0.1718  time: 0.6665  data_time: 0.1826  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:59:09 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 9899  total_loss: 1.422  loss_cls: 0.3223  loss_box_reg: 0.5458  loss_mask: 0.3191  loss_rpn_cls: 0.07542  loss_rpn_loc: 0.1828  time: 0.6666  data_time: 0.2257  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:59:22 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 9919  total_loss: 1.395  loss_cls: 0.2972  loss_box_reg: 0.5372  loss_mask: 0.2911  loss_rpn_cls: 0.05486  loss_rpn_loc: 0.1791  time: 0.6666  data_time: 0.1444  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 17:59:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:59:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 17:59:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 17:59:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 17:59:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 17:59:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 17:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0727 s/iter. Total: 0.1630 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 17:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.0897 s/iter. Eval: 0.0769 s/iter. Total: 0.1677 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 17:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0009 s/iter. Inference: 0.0887 s/iter. Eval: 0.0732 s/iter. Total: 0.1629 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 17:59:42 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0009 s/iter. Inference: 0.0892 s/iter. Eval: 0.0772 s/iter. Total: 0.1673 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 17:59:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.321924 (0.166568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:59:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089165 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 17:59:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 17:59:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27079418541039013\n",
      "\u001b[32m[02/04 17:59:55 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 9939  total_loss: 1.403  loss_cls: 0.2916  loss_box_reg: 0.5608  loss_mask: 0.2951  loss_rpn_cls: 0.07318  loss_rpn_loc: 0.1837  time: 0.6664  data_time: 0.1170  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 18:00:11 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 9959  total_loss: 1.462  loss_cls: 0.3128  loss_box_reg: 0.5263  loss_mask: 0.3037  loss_rpn_cls: 0.06848  loss_rpn_loc: 0.1952  time: 0.6667  data_time: 0.2758  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 18:00:24 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 9979  total_loss: 1.349  loss_cls: 0.2523  loss_box_reg: 0.5433  loss_mask: 0.2955  loss_rpn_cls: 0.05512  loss_rpn_loc: 0.178  time: 0.6667  data_time: 0.1944  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 18:00:39 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.521  loss_cls: 0.3301  loss_box_reg: 0.5632  loss_mask: 0.3112  loss_rpn_cls: 0.08946  loss_rpn_loc: 0.1964  time: 0.6668  data_time: 0.2020  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 18:00:39 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:51:06 (0.6668 s / it)\n",
      "\u001b[32m[02/04 18:00:39 d2.engine.hooks]: \u001b[0mTotal training time: 2:04:45 (0:13:38 on hooks)\n",
      "\u001b[32m[02/04 18:00:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 18:00:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 18:00:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 18:00:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 18:00:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 18:00:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 18:00:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0901 s/iter. Eval: 0.0665 s/iter. Total: 0.1574 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 18:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0818 s/iter. Total: 0.1736 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 18:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0892 s/iter. Eval: 0.0753 s/iter. Total: 0.1655 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 18:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0793 s/iter. Total: 0.1697 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 18:01:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.513279 (0.168218 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 18:01:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089275 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 18:01:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 18:01:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27229031892934896\n"
     ]
    }
   ],
   "source": [
    "# unfreezing the first layer of the backbone\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 0\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04de8c84-3a74-42b1-a207-85fb5d96288d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 19:02:28 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 19:02:29 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 19:02:30 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/04 19:02:30 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 19:02:30 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/04 19:02:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/04 19:02:30 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/04 19:02:30 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:02:30 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 19:02:31 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 19:02:46 d2.utils.events]: \u001b[0m eta: 1:17:16  iter: 19  total_loss: 3.095  loss_cls: 1.284  loss_box_reg: 0.529  loss_mask: 0.6923  loss_rpn_cls: 0.3269  loss_rpn_loc: 0.2261  time: 0.7143  data_time: 0.3056  lr: 9.9905e-06  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:03:00 d2.utils.events]: \u001b[0m eta: 1:26:30  iter: 39  total_loss: 3.001  loss_cls: 1.221  loss_box_reg: 0.5494  loss_mask: 0.686  loss_rpn_cls: 0.3178  loss_rpn_loc: 0.2218  time: 0.7154  data_time: 0.2364  lr: 1.998e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:03:15 d2.utils.events]: \u001b[0m eta: 1:21:49  iter: 59  total_loss: 2.856  loss_cls: 1.069  loss_box_reg: 0.653  loss_mask: 0.6751  loss_rpn_cls: 0.2841  loss_rpn_loc: 0.2426  time: 0.7175  data_time: 0.2398  lr: 2.997e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:03:26 d2.utils.events]: \u001b[0m eta: 1:22:58  iter: 79  total_loss: 2.631  loss_cls: 0.8948  loss_box_reg: 0.6729  loss_mask: 0.6469  loss_rpn_cls: 0.2247  loss_rpn_loc: 0.1936  time: 0.6800  data_time: 0.0878  lr: 3.9961e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:03:39 d2.utils.events]: \u001b[0m eta: 1:22:50  iter: 99  total_loss: 2.571  loss_cls: 0.758  loss_box_reg: 0.7075  loss_mask: 0.6256  loss_rpn_cls: 0.2062  loss_rpn_loc: 0.2156  time: 0.6741  data_time: 0.1756  lr: 4.9951e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:03:54 d2.utils.events]: \u001b[0m eta: 1:22:40  iter: 119  total_loss: 2.435  loss_cls: 0.7236  loss_box_reg: 0.7214  loss_mask: 0.5961  loss_rpn_cls: 0.182  loss_rpn_loc: 0.1918  time: 0.6834  data_time: 0.2400  lr: 5.9941e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:04:08 d2.utils.events]: \u001b[0m eta: 1:22:30  iter: 139  total_loss: 2.37  loss_cls: 0.7036  loss_box_reg: 0.7578  loss_mask: 0.5549  loss_rpn_cls: 0.1715  loss_rpn_loc: 0.2086  time: 0.6904  data_time: 0.2594  lr: 6.993e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:04:21 d2.utils.events]: \u001b[0m eta: 1:21:40  iter: 159  total_loss: 2.286  loss_cls: 0.658  loss_box_reg: 0.7391  loss_mask: 0.5179  loss_rpn_cls: 0.1557  loss_rpn_loc: 0.1711  time: 0.6826  data_time: 0.1705  lr: 7.9921e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:04:32 d2.utils.events]: \u001b[0m eta: 1:20:27  iter: 179  total_loss: 2.282  loss_cls: 0.6403  loss_box_reg: 0.8092  loss_mask: 0.5132  loss_rpn_cls: 0.1545  loss_rpn_loc: 0.2175  time: 0.6664  data_time: 0.0860  lr: 8.991e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:04:46 d2.utils.events]: \u001b[0m eta: 1:21:12  iter: 199  total_loss: 2.206  loss_cls: 0.6056  loss_box_reg: 0.7709  loss_mask: 0.4733  loss_rpn_cls: 0.1446  loss_rpn_loc: 0.2178  time: 0.6694  data_time: 0.2136  lr: 9.9901e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:04:59 d2.utils.events]: \u001b[0m eta: 1:20:29  iter: 219  total_loss: 2.076  loss_cls: 0.5352  loss_box_reg: 0.7902  loss_mask: 0.4391  loss_rpn_cls: 0.1476  loss_rpn_loc: 0.1936  time: 0.6680  data_time: 0.1859  lr: 0.00010989  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:05:12 d2.utils.events]: \u001b[0m eta: 1:19:51  iter: 239  total_loss: 1.889  loss_cls: 0.4345  loss_box_reg: 0.7293  loss_mask: 0.4072  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.1658  time: 0.6684  data_time: 0.2182  lr: 0.00011988  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:05:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:05:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:05:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:05:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:05:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:05:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:05:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0840 s/iter. Eval: 0.0153 s/iter. Total: 0.1000 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/04 19:05:21 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0008 s/iter. Inference: 0.0841 s/iter. Eval: 0.0168 s/iter. Total: 0.1017 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 19:05:26 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.0827 s/iter. Eval: 0.0148 s/iter. Total: 0.0983 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/04 19:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.377993 (0.098086 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.082503 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:05:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:05:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.11828339195691194\n",
      "\u001b[32m[02/04 19:05:37 d2.utils.events]: \u001b[0m eta: 1:19:31  iter: 259  total_loss: 1.917  loss_cls: 0.4693  loss_box_reg: 0.7338  loss_mask: 0.3783  loss_rpn_cls: 0.1132  loss_rpn_loc: 0.1957  time: 0.6654  data_time: 0.1493  lr: 0.00012987  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:05:50 d2.utils.events]: \u001b[0m eta: 1:19:02  iter: 279  total_loss: 1.728  loss_cls: 0.3899  loss_box_reg: 0.7212  loss_mask: 0.3519  loss_rpn_cls: 0.08812  loss_rpn_loc: 0.1647  time: 0.6616  data_time: 0.1619  lr: 0.00013986  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:06:04 d2.utils.events]: \u001b[0m eta: 1:18:49  iter: 299  total_loss: 1.857  loss_cls: 0.4213  loss_box_reg: 0.735  loss_mask: 0.3485  loss_rpn_cls: 0.1363  loss_rpn_loc: 0.2242  time: 0.6648  data_time: 0.2439  lr: 0.00014985  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:06:16 d2.utils.events]: \u001b[0m eta: 1:18:37  iter: 319  total_loss: 1.822  loss_cls: 0.3963  loss_box_reg: 0.7062  loss_mask: 0.344  loss_rpn_cls: 0.1368  loss_rpn_loc: 0.2115  time: 0.6622  data_time: 0.1703  lr: 0.00015984  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:06:28 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 339  total_loss: 1.739  loss_cls: 0.3789  loss_box_reg: 0.6852  loss_mask: 0.3338  loss_rpn_cls: 0.1187  loss_rpn_loc: 0.2141  time: 0.6558  data_time: 0.1078  lr: 0.00016983  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:06:41 d2.utils.events]: \u001b[0m eta: 1:17:53  iter: 359  total_loss: 1.666  loss_cls: 0.3884  loss_box_reg: 0.6649  loss_mask: 0.3226  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.1754  time: 0.6572  data_time: 0.2128  lr: 0.00017982  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:06:54 d2.utils.events]: \u001b[0m eta: 1:17:50  iter: 379  total_loss: 1.642  loss_cls: 0.3569  loss_box_reg: 0.6656  loss_mask: 0.3225  loss_rpn_cls: 0.08418  loss_rpn_loc: 0.1853  time: 0.6554  data_time: 0.1481  lr: 0.00018981  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:07:07 d2.utils.events]: \u001b[0m eta: 1:17:58  iter: 399  total_loss: 1.784  loss_cls: 0.4036  loss_box_reg: 0.7074  loss_mask: 0.3254  loss_rpn_cls: 0.1303  loss_rpn_loc: 0.195  time: 0.6561  data_time: 0.1847  lr: 0.0001998  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:07:20 d2.utils.events]: \u001b[0m eta: 1:17:50  iter: 419  total_loss: 1.768  loss_cls: 0.3701  loss_box_reg: 0.6776  loss_mask: 0.3344  loss_rpn_cls: 0.1196  loss_rpn_loc: 0.1766  time: 0.6550  data_time: 0.1496  lr: 0.00020979  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:07:32 d2.utils.events]: \u001b[0m eta: 1:17:47  iter: 439  total_loss: 1.705  loss_cls: 0.3814  loss_box_reg: 0.6815  loss_mask: 0.3215  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2026  time: 0.6529  data_time: 0.1279  lr: 0.00021978  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:07:48 d2.utils.events]: \u001b[0m eta: 1:18:01  iter: 459  total_loss: 1.712  loss_cls: 0.3962  loss_box_reg: 0.6709  loss_mask: 0.326  loss_rpn_cls: 0.1289  loss_rpn_loc: 0.1964  time: 0.6587  data_time: 0.2909  lr: 0.00022977  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:08:02 d2.utils.events]: \u001b[0m eta: 1:17:54  iter: 479  total_loss: 1.854  loss_cls: 0.4223  loss_box_reg: 0.6521  loss_mask: 0.3237  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.2014  time: 0.6623  data_time: 0.2533  lr: 0.00023976  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:08:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:08:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:08:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:08:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:08:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:08:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0904 s/iter. Eval: 0.0637 s/iter. Total: 0.1548 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 19:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0777 s/iter. Total: 0.1696 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 19:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0770 s/iter. Total: 0.1687 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 19:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0835 s/iter. Total: 0.1756 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 19:08:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.279766 (0.174826 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:08:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091235 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:08:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:08:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21877154781266112\n",
      "\u001b[32m[02/04 19:08:39 d2.utils.events]: \u001b[0m eta: 1:18:11  iter: 499  total_loss: 1.787  loss_cls: 0.4043  loss_box_reg: 0.653  loss_mask: 0.3307  loss_rpn_cls: 0.1217  loss_rpn_loc: 0.2259  time: 0.6646  data_time: 0.2165  lr: 0.00024975  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:08:52 d2.utils.events]: \u001b[0m eta: 1:17:59  iter: 519  total_loss: 1.663  loss_cls: 0.3822  loss_box_reg: 0.6711  loss_mask: 0.3234  loss_rpn_cls: 0.1205  loss_rpn_loc: 0.1954  time: 0.6651  data_time: 0.1975  lr: 0.00025974  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:09:05 d2.utils.events]: \u001b[0m eta: 1:18:06  iter: 539  total_loss: 1.86  loss_cls: 0.4831  loss_box_reg: 0.6848  loss_mask: 0.3318  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.2159  time: 0.6646  data_time: 0.1457  lr: 0.00026973  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:09:18 d2.utils.events]: \u001b[0m eta: 1:18:07  iter: 559  total_loss: 1.667  loss_cls: 0.3648  loss_box_reg: 0.6529  loss_mask: 0.313  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.1877  time: 0.6640  data_time: 0.1618  lr: 0.00027972  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:09:30 d2.utils.events]: \u001b[0m eta: 1:17:54  iter: 579  total_loss: 1.609  loss_cls: 0.3543  loss_box_reg: 0.6011  loss_mask: 0.3053  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2052  time: 0.6609  data_time: 0.1102  lr: 0.00028971  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:09:42 d2.utils.events]: \u001b[0m eta: 1:17:28  iter: 599  total_loss: 1.459  loss_cls: 0.309  loss_box_reg: 0.6084  loss_mask: 0.318  loss_rpn_cls: 0.08059  loss_rpn_loc: 0.1565  time: 0.6595  data_time: 0.1584  lr: 0.0002997  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:09:56 d2.utils.events]: \u001b[0m eta: 1:17:21  iter: 619  total_loss: 1.66  loss_cls: 0.3551  loss_box_reg: 0.6362  loss_mask: 0.3287  loss_rpn_cls: 0.1258  loss_rpn_loc: 0.1756  time: 0.6605  data_time: 0.1987  lr: 0.00030969  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:10:08 d2.utils.events]: \u001b[0m eta: 1:17:09  iter: 639  total_loss: 1.654  loss_cls: 0.3568  loss_box_reg: 0.6491  loss_mask: 0.3252  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.1984  time: 0.6589  data_time: 0.1399  lr: 0.00031968  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:10:21 d2.utils.events]: \u001b[0m eta: 1:16:53  iter: 659  total_loss: 1.511  loss_cls: 0.3105  loss_box_reg: 0.6197  loss_mask: 0.3117  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.1877  time: 0.6589  data_time: 0.1878  lr: 0.00032967  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:10:34 d2.utils.events]: \u001b[0m eta: 1:16:42  iter: 679  total_loss: 1.583  loss_cls: 0.3557  loss_box_reg: 0.6209  loss_mask: 0.305  loss_rpn_cls: 0.09813  loss_rpn_loc: 0.1816  time: 0.6585  data_time: 0.1871  lr: 0.00033966  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:10:50 d2.utils.events]: \u001b[0m eta: 1:16:33  iter: 699  total_loss: 1.63  loss_cls: 0.3828  loss_box_reg: 0.6173  loss_mask: 0.3144  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.2019  time: 0.6613  data_time: 0.2834  lr: 0.00034965  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:11:04 d2.utils.events]: \u001b[0m eta: 1:16:21  iter: 719  total_loss: 1.479  loss_cls: 0.3383  loss_box_reg: 0.5996  loss_mask: 0.3087  loss_rpn_cls: 0.0978  loss_rpn_loc: 0.1797  time: 0.6633  data_time: 0.2584  lr: 0.00035964  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:11:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:11:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:11:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:11:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:11:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:11:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:11:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0843 s/iter. Eval: 0.0521 s/iter. Total: 0.1370 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:11:16 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0856 s/iter. Eval: 0.0688 s/iter. Total: 0.1553 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:11:21 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0007 s/iter. Inference: 0.0865 s/iter. Eval: 0.0713 s/iter. Total: 0.1586 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:11:26 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0007 s/iter. Inference: 0.0872 s/iter. Eval: 0.0767 s/iter. Total: 0.1647 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 19:11:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.994679 (0.163747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:11:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086945 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:11:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:11:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23233457284234652\n",
      "\u001b[32m[02/04 19:11:35 d2.utils.events]: \u001b[0m eta: 1:15:59  iter: 739  total_loss: 1.602  loss_cls: 0.3742  loss_box_reg: 0.6232  loss_mask: 0.3183  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.1912  time: 0.6597  data_time: 0.0733  lr: 0.00036963  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:11:47 d2.utils.events]: \u001b[0m eta: 1:15:48  iter: 759  total_loss: 1.477  loss_cls: 0.346  loss_box_reg: 0.5763  loss_mask: 0.3195  loss_rpn_cls: 0.07708  loss_rpn_loc: 0.1802  time: 0.6580  data_time: 0.1377  lr: 0.00037962  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:12:01 d2.utils.events]: \u001b[0m eta: 1:15:40  iter: 779  total_loss: 1.564  loss_cls: 0.3566  loss_box_reg: 0.5971  loss_mask: 0.323  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.1701  time: 0.6585  data_time: 0.2036  lr: 0.00038961  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:12:11 d2.utils.events]: \u001b[0m eta: 1:15:24  iter: 799  total_loss: 1.373  loss_cls: 0.3181  loss_box_reg: 0.5872  loss_mask: 0.3016  loss_rpn_cls: 0.05963  loss_rpn_loc: 0.1371  time: 0.6552  data_time: 0.0741  lr: 0.0003996  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:12:25 d2.utils.events]: \u001b[0m eta: 1:15:15  iter: 819  total_loss: 1.61  loss_cls: 0.3793  loss_box_reg: 0.631  loss_mask: 0.3078  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.2057  time: 0.6559  data_time: 0.2190  lr: 0.00040959  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:12:38 d2.utils.events]: \u001b[0m eta: 1:15:06  iter: 839  total_loss: 1.458  loss_cls: 0.3444  loss_box_reg: 0.5783  loss_mask: 0.3126  loss_rpn_cls: 0.09996  loss_rpn_loc: 0.1797  time: 0.6561  data_time: 0.1863  lr: 0.00041958  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:12:51 d2.utils.events]: \u001b[0m eta: 1:15:00  iter: 859  total_loss: 1.547  loss_cls: 0.3317  loss_box_reg: 0.5905  loss_mask: 0.3146  loss_rpn_cls: 0.09613  loss_rpn_loc: 0.1817  time: 0.6560  data_time: 0.1544  lr: 0.00042957  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:13:05 d2.utils.events]: \u001b[0m eta: 1:14:58  iter: 879  total_loss: 1.622  loss_cls: 0.3509  loss_box_reg: 0.6385  loss_mask: 0.3071  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.1914  time: 0.6568  data_time: 0.1995  lr: 0.00043956  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:13:17 d2.utils.events]: \u001b[0m eta: 1:14:43  iter: 899  total_loss: 1.587  loss_cls: 0.3629  loss_box_reg: 0.6341  loss_mask: 0.3208  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.1899  time: 0.6549  data_time: 0.1075  lr: 0.00044955  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:13:31 d2.utils.events]: \u001b[0m eta: 1:14:33  iter: 919  total_loss: 1.581  loss_cls: 0.3368  loss_box_reg: 0.6125  loss_mask: 0.3155  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.1936  time: 0.6564  data_time: 0.2600  lr: 0.00045954  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:13:46 d2.utils.events]: \u001b[0m eta: 1:14:25  iter: 939  total_loss: 1.669  loss_cls: 0.3783  loss_box_reg: 0.6088  loss_mask: 0.3198  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.2097  time: 0.6581  data_time: 0.2589  lr: 0.00046953  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:14:03 d2.utils.events]: \u001b[0m eta: 1:14:13  iter: 959  total_loss: 1.573  loss_cls: 0.3723  loss_box_reg: 0.5707  loss_mask: 0.3126  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.2022  time: 0.6622  data_time: 0.3955  lr: 0.00047952  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:14:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:14:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:14:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:14:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:14:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:14:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:14:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0873 s/iter. Eval: 0.0640 s/iter. Total: 0.1518 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 19:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0890 s/iter. Eval: 0.0797 s/iter. Total: 0.1695 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 19:14:20 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0009 s/iter. Inference: 0.0890 s/iter. Eval: 0.0789 s/iter. Total: 0.1688 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 19:14:25 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0831 s/iter. Total: 0.1729 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:14:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.929168 (0.171803 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:14:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088730 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:14:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:14:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2281458969304561\n",
      "\u001b[32m[02/04 19:14:35 d2.utils.events]: \u001b[0m eta: 1:13:59  iter: 979  total_loss: 1.484  loss_cls: 0.2961  loss_box_reg: 0.5739  loss_mask: 0.3051  loss_rpn_cls: 0.08413  loss_rpn_loc: 0.1618  time: 0.6595  data_time: 0.0837  lr: 0.00048951  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:14:50 d2.utils.events]: \u001b[0m eta: 1:13:51  iter: 999  total_loss: 1.638  loss_cls: 0.3861  loss_box_reg: 0.6151  loss_mask: 0.3143  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.1935  time: 0.6611  data_time: 0.2473  lr: 0.0004995  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:15:01 d2.utils.events]: \u001b[0m eta: 1:13:38  iter: 1019  total_loss: 1.462  loss_cls: 0.3244  loss_box_reg: 0.5631  loss_mask: 0.3186  loss_rpn_cls: 0.07427  loss_rpn_loc: 0.1829  time: 0.6592  data_time: 0.1139  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:15:17 d2.utils.events]: \u001b[0m eta: 1:13:27  iter: 1039  total_loss: 1.615  loss_cls: 0.3619  loss_box_reg: 0.5969  loss_mask: 0.3177  loss_rpn_cls: 0.1341  loss_rpn_loc: 0.206  time: 0.6617  data_time: 0.3292  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:15:30 d2.utils.events]: \u001b[0m eta: 1:13:14  iter: 1059  total_loss: 1.442  loss_cls: 0.3233  loss_box_reg: 0.554  loss_mask: 0.2951  loss_rpn_cls: 0.08363  loss_rpn_loc: 0.1615  time: 0.6610  data_time: 0.1542  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:15:40 d2.utils.events]: \u001b[0m eta: 1:12:54  iter: 1079  total_loss: 1.269  loss_cls: 0.25  loss_box_reg: 0.5659  loss_mask: 0.2843  loss_rpn_cls: 0.07806  loss_rpn_loc: 0.1529  time: 0.6584  data_time: 0.0754  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:15:51 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 1099  total_loss: 1.469  loss_cls: 0.3484  loss_box_reg: 0.5923  loss_mask: 0.2938  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.1624  time: 0.6568  data_time: 0.0966  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:16:02 d2.utils.events]: \u001b[0m eta: 1:12:28  iter: 1119  total_loss: 1.539  loss_cls: 0.3424  loss_box_reg: 0.6079  loss_mask: 0.3017  loss_rpn_cls: 0.09138  loss_rpn_loc: 0.2002  time: 0.6544  data_time: 0.0554  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:16:16 d2.utils.events]: \u001b[0m eta: 1:12:18  iter: 1139  total_loss: 1.455  loss_cls: 0.3276  loss_box_reg: 0.5844  loss_mask: 0.3151  loss_rpn_cls: 0.09516  loss_rpn_loc: 0.1763  time: 0.6554  data_time: 0.2338  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:16:33 d2.utils.events]: \u001b[0m eta: 1:12:19  iter: 1159  total_loss: 1.695  loss_cls: 0.3831  loss_box_reg: 0.622  loss_mask: 0.3302  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.218  time: 0.6583  data_time: 0.3242  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:16:47 d2.utils.events]: \u001b[0m eta: 1:12:12  iter: 1179  total_loss: 1.511  loss_cls: 0.3506  loss_box_reg: 0.5862  loss_mask: 0.3159  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.1887  time: 0.6592  data_time: 0.2358  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:17:01 d2.utils.events]: \u001b[0m eta: 1:12:04  iter: 1199  total_loss: 1.684  loss_cls: 0.3906  loss_box_reg: 0.6286  loss_mask: 0.3224  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.2149  time: 0.6602  data_time: 0.2443  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:17:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:17:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:17:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:17:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:17:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:17:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0839 s/iter. Eval: 0.0579 s/iter. Total: 0.1425 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0852 s/iter. Eval: 0.0734 s/iter. Total: 0.1594 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:17:20 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0739 s/iter. Total: 0.1603 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:17:25 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0780 s/iter. Total: 0.1647 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:17:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.027423 (0.164030 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:17:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085835 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:17:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:17:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25737415320766394\n",
      "\u001b[32m[02/04 19:17:34 d2.utils.events]: \u001b[0m eta: 1:11:56  iter: 1219  total_loss: 1.611  loss_cls: 0.3519  loss_box_reg: 0.6234  loss_mask: 0.3175  loss_rpn_cls: 0.09341  loss_rpn_loc: 0.1882  time: 0.6596  data_time: 0.1499  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:17:47 d2.utils.events]: \u001b[0m eta: 1:11:49  iter: 1239  total_loss: 1.525  loss_cls: 0.3484  loss_box_reg: 0.577  loss_mask: 0.2999  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2031  time: 0.6596  data_time: 0.1852  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:18:03 d2.utils.events]: \u001b[0m eta: 1:11:43  iter: 1259  total_loss: 1.466  loss_cls: 0.3287  loss_box_reg: 0.5729  loss_mask: 0.2957  loss_rpn_cls: 0.09353  loss_rpn_loc: 0.1765  time: 0.6614  data_time: 0.2766  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:18:20 d2.utils.events]: \u001b[0m eta: 1:11:50  iter: 1279  total_loss: 1.533  loss_cls: 0.3568  loss_box_reg: 0.5814  loss_mask: 0.3092  loss_rpn_cls: 0.111  loss_rpn_loc: 0.1863  time: 0.6644  data_time: 0.3414  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:18:33 d2.utils.events]: \u001b[0m eta: 1:11:40  iter: 1299  total_loss: 1.598  loss_cls: 0.3559  loss_box_reg: 0.6063  loss_mask: 0.2999  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.1764  time: 0.6642  data_time: 0.1797  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:18:46 d2.utils.events]: \u001b[0m eta: 1:11:31  iter: 1319  total_loss: 1.499  loss_cls: 0.3384  loss_box_reg: 0.569  loss_mask: 0.3008  loss_rpn_cls: 0.08612  loss_rpn_loc: 0.1449  time: 0.6638  data_time: 0.1794  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:18:59 d2.utils.events]: \u001b[0m eta: 1:11:21  iter: 1339  total_loss: 1.487  loss_cls: 0.3584  loss_box_reg: 0.5716  loss_mask: 0.2949  loss_rpn_cls: 0.08522  loss_rpn_loc: 0.1773  time: 0.6639  data_time: 0.2169  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:19:13 d2.utils.events]: \u001b[0m eta: 1:11:15  iter: 1359  total_loss: 1.547  loss_cls: 0.3577  loss_box_reg: 0.6074  loss_mask: 0.3166  loss_rpn_cls: 0.09479  loss_rpn_loc: 0.1938  time: 0.6641  data_time: 0.2041  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:19:28 d2.utils.events]: \u001b[0m eta: 1:11:02  iter: 1379  total_loss: 1.565  loss_cls: 0.3653  loss_box_reg: 0.6047  loss_mask: 0.3149  loss_rpn_cls: 0.08593  loss_rpn_loc: 0.1686  time: 0.6655  data_time: 0.2760  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:19:41 d2.utils.events]: \u001b[0m eta: 1:10:50  iter: 1399  total_loss: 1.588  loss_cls: 0.3433  loss_box_reg: 0.6222  loss_mask: 0.3192  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.1906  time: 0.6652  data_time: 0.1818  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:19:53 d2.utils.events]: \u001b[0m eta: 1:10:38  iter: 1419  total_loss: 1.491  loss_cls: 0.3459  loss_box_reg: 0.5626  loss_mask: 0.2916  loss_rpn_cls: 0.08476  loss_rpn_loc: 0.1687  time: 0.6642  data_time: 0.1353  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:20:04 d2.utils.events]: \u001b[0m eta: 1:10:15  iter: 1439  total_loss: 1.515  loss_cls: 0.3361  loss_box_reg: 0.5883  loss_mask: 0.2958  loss_rpn_cls: 0.09006  loss_rpn_loc: 0.1634  time: 0.6627  data_time: 0.0951  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:20:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:20:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:20:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:20:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:20:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:20:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0859 s/iter. Eval: 0.0569 s/iter. Total: 0.1435 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0870 s/iter. Eval: 0.0708 s/iter. Total: 0.1586 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0717 s/iter. Total: 0.1588 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0759 s/iter. Total: 0.1631 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 19:20:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.838044 (0.162397 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:20:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086259 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:20:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:20:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2453424762742896\n",
      "\u001b[32m[02/04 19:20:38 d2.utils.events]: \u001b[0m eta: 1:10:01  iter: 1459  total_loss: 1.487  loss_cls: 0.3562  loss_box_reg: 0.604  loss_mask: 0.306  loss_rpn_cls: 0.09797  loss_rpn_loc: 0.1777  time: 0.6629  data_time: 0.1954  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:20:49 d2.utils.events]: \u001b[0m eta: 1:09:48  iter: 1479  total_loss: 1.558  loss_cls: 0.3354  loss_box_reg: 0.581  loss_mask: 0.3046  loss_rpn_cls: 0.0969  loss_rpn_loc: 0.1869  time: 0.6613  data_time: 0.0933  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:21:00 d2.utils.events]: \u001b[0m eta: 1:09:25  iter: 1499  total_loss: 1.412  loss_cls: 0.3098  loss_box_reg: 0.548  loss_mask: 0.2961  loss_rpn_cls: 0.08471  loss_rpn_loc: 0.1606  time: 0.6600  data_time: 0.1033  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:21:13 d2.utils.events]: \u001b[0m eta: 1:09:13  iter: 1519  total_loss: 1.509  loss_cls: 0.3169  loss_box_reg: 0.6007  loss_mask: 0.3172  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.1756  time: 0.6596  data_time: 0.1786  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:21:28 d2.utils.events]: \u001b[0m eta: 1:08:59  iter: 1539  total_loss: 1.511  loss_cls: 0.3361  loss_box_reg: 0.5746  loss_mask: 0.3167  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.1977  time: 0.6611  data_time: 0.2832  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:21:41 d2.utils.events]: \u001b[0m eta: 1:08:42  iter: 1559  total_loss: 1.405  loss_cls: 0.3218  loss_box_reg: 0.572  loss_mask: 0.3059  loss_rpn_cls: 0.07637  loss_rpn_loc: 0.1617  time: 0.6607  data_time: 0.1686  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:21:52 d2.utils.events]: \u001b[0m eta: 1:08:26  iter: 1579  total_loss: 1.42  loss_cls: 0.3121  loss_box_reg: 0.5743  loss_mask: 0.3108  loss_rpn_cls: 0.06538  loss_rpn_loc: 0.1448  time: 0.6591  data_time: 0.0886  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:22:05 d2.utils.events]: \u001b[0m eta: 1:08:20  iter: 1599  total_loss: 1.457  loss_cls: 0.3334  loss_box_reg: 0.5715  loss_mask: 0.305  loss_rpn_cls: 0.08939  loss_rpn_loc: 0.1766  time: 0.6592  data_time: 0.2014  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:22:17 d2.utils.events]: \u001b[0m eta: 1:08:01  iter: 1619  total_loss: 1.52  loss_cls: 0.3172  loss_box_reg: 0.5959  loss_mask: 0.316  loss_rpn_cls: 0.08905  loss_rpn_loc: 0.1714  time: 0.6588  data_time: 0.1613  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:22:29 d2.utils.events]: \u001b[0m eta: 1:07:53  iter: 1639  total_loss: 1.532  loss_cls: 0.3455  loss_box_reg: 0.6081  loss_mask: 0.3088  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.1808  time: 0.6580  data_time: 0.1187  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:22:43 d2.utils.events]: \u001b[0m eta: 1:07:51  iter: 1659  total_loss: 1.508  loss_cls: 0.339  loss_box_reg: 0.5743  loss_mask: 0.312  loss_rpn_cls: 0.0922  loss_rpn_loc: 0.1882  time: 0.6583  data_time: 0.2014  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:22:58 d2.utils.events]: \u001b[0m eta: 1:07:48  iter: 1679  total_loss: 1.585  loss_cls: 0.3376  loss_box_reg: 0.5976  loss_mask: 0.3039  loss_rpn_cls: 0.08983  loss_rpn_loc: 0.1914  time: 0.6592  data_time: 0.2371  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:23:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:23:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:23:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:23:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:23:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:23:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0851 s/iter. Eval: 0.0645 s/iter. Total: 0.1503 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 19:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0776 s/iter. Total: 0.1669 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 19:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0740 s/iter. Total: 0.1623 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0781 s/iter. Total: 0.1673 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:23:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.221663 (0.165704 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:23:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088066 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:23:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22956562686718796\n",
      "\u001b[32m[02/04 19:23:36 d2.utils.events]: \u001b[0m eta: 1:07:39  iter: 1699  total_loss: 1.593  loss_cls: 0.372  loss_box_reg: 0.5852  loss_mask: 0.3273  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.1946  time: 0.6615  data_time: 0.3603  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:23:50 d2.utils.events]: \u001b[0m eta: 1:07:34  iter: 1719  total_loss: 1.666  loss_cls: 0.3712  loss_box_reg: 0.5974  loss_mask: 0.3218  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1941  time: 0.6620  data_time: 0.2259  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:24:05 d2.utils.events]: \u001b[0m eta: 1:07:31  iter: 1739  total_loss: 1.517  loss_cls: 0.3575  loss_box_reg: 0.5685  loss_mask: 0.2905  loss_rpn_cls: 0.08854  loss_rpn_loc: 0.1739  time: 0.6634  data_time: 0.2858  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:24:20 d2.utils.events]: \u001b[0m eta: 1:07:27  iter: 1759  total_loss: 1.571  loss_cls: 0.3417  loss_box_reg: 0.5744  loss_mask: 0.3257  loss_rpn_cls: 0.09625  loss_rpn_loc: 0.2013  time: 0.6644  data_time: 0.2539  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:24:31 d2.utils.events]: \u001b[0m eta: 1:07:12  iter: 1779  total_loss: 1.384  loss_cls: 0.2963  loss_box_reg: 0.5569  loss_mask: 0.3038  loss_rpn_cls: 0.06199  loss_rpn_loc: 0.1462  time: 0.6631  data_time: 0.0818  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:24:43 d2.utils.events]: \u001b[0m eta: 1:07:07  iter: 1799  total_loss: 1.455  loss_cls: 0.3226  loss_box_reg: 0.5558  loss_mask: 0.2987  loss_rpn_cls: 0.09383  loss_rpn_loc: 0.1819  time: 0.6620  data_time: 0.0922  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:24:57 d2.utils.events]: \u001b[0m eta: 1:06:55  iter: 1819  total_loss: 1.627  loss_cls: 0.3548  loss_box_reg: 0.5957  loss_mask: 0.3178  loss_rpn_cls: 0.09248  loss_rpn_loc: 0.1813  time: 0.6625  data_time: 0.2373  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:25:12 d2.utils.events]: \u001b[0m eta: 1:06:45  iter: 1839  total_loss: 1.509  loss_cls: 0.3465  loss_box_reg: 0.5787  loss_mask: 0.2987  loss_rpn_cls: 0.09068  loss_rpn_loc: 0.1761  time: 0.6635  data_time: 0.2716  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:25:24 d2.utils.events]: \u001b[0m eta: 1:06:33  iter: 1859  total_loss: 1.481  loss_cls: 0.3285  loss_box_reg: 0.6087  loss_mask: 0.3138  loss_rpn_cls: 0.08083  loss_rpn_loc: 0.1514  time: 0.6631  data_time: 0.1643  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:25:40 d2.utils.events]: \u001b[0m eta: 1:06:17  iter: 1879  total_loss: 1.456  loss_cls: 0.35  loss_box_reg: 0.5712  loss_mask: 0.2943  loss_rpn_cls: 0.07297  loss_rpn_loc: 0.1685  time: 0.6641  data_time: 0.2945  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:25:52 d2.utils.events]: \u001b[0m eta: 1:06:09  iter: 1899  total_loss: 1.53  loss_cls: 0.3552  loss_box_reg: 0.5902  loss_mask: 0.3088  loss_rpn_cls: 0.08067  loss_rpn_loc: 0.1704  time: 0.6638  data_time: 0.1606  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:26:06 d2.utils.events]: \u001b[0m eta: 1:05:59  iter: 1919  total_loss: 1.47  loss_cls: 0.3177  loss_box_reg: 0.5648  loss_mask: 0.2901  loss_rpn_cls: 0.08426  loss_rpn_loc: 0.1763  time: 0.6640  data_time: 0.1983  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:26:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:26:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:26:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:26:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:26:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:26:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0860 s/iter. Eval: 0.0567 s/iter. Total: 0.1433 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0728 s/iter. Total: 0.1593 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0739 s/iter. Total: 0.1609 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0789 s/iter. Total: 0.1666 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:26:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.208993 (0.165595 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:26:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086663 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:26:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:26:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25422957016507464\n",
      "\u001b[32m[02/04 19:26:40 d2.utils.events]: \u001b[0m eta: 1:05:49  iter: 1939  total_loss: 1.496  loss_cls: 0.3348  loss_box_reg: 0.5706  loss_mask: 0.3133  loss_rpn_cls: 0.07429  loss_rpn_loc: 0.1797  time: 0.6641  data_time: 0.2033  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:26:54 d2.utils.events]: \u001b[0m eta: 1:05:44  iter: 1959  total_loss: 1.483  loss_cls: 0.3468  loss_box_reg: 0.5671  loss_mask: 0.306  loss_rpn_cls: 0.09089  loss_rpn_loc: 0.1682  time: 0.6645  data_time: 0.2319  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:27:10 d2.utils.events]: \u001b[0m eta: 1:05:38  iter: 1979  total_loss: 1.502  loss_cls: 0.3569  loss_box_reg: 0.5817  loss_mask: 0.3147  loss_rpn_cls: 0.08412  loss_rpn_loc: 0.1802  time: 0.6658  data_time: 0.3244  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:27:22 d2.utils.events]: \u001b[0m eta: 1:05:26  iter: 1999  total_loss: 1.462  loss_cls: 0.3269  loss_box_reg: 0.5816  loss_mask: 0.3102  loss_rpn_cls: 0.07732  loss_rpn_loc: 0.1834  time: 0.6650  data_time: 0.1158  lr: 0.0005  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:27:36 d2.utils.events]: \u001b[0m eta: 1:05:17  iter: 2019  total_loss: 1.436  loss_cls: 0.3333  loss_box_reg: 0.5526  loss_mask: 0.2921  loss_rpn_cls: 0.07935  loss_rpn_loc: 0.1764  time: 0.6651  data_time: 0.2157  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:27:50 d2.utils.events]: \u001b[0m eta: 1:05:09  iter: 2039  total_loss: 1.567  loss_cls: 0.3403  loss_box_reg: 0.6108  loss_mask: 0.3186  loss_rpn_cls: 0.09041  loss_rpn_loc: 0.1705  time: 0.6656  data_time: 0.2361  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:28:01 d2.utils.events]: \u001b[0m eta: 1:05:02  iter: 2059  total_loss: 1.446  loss_cls: 0.334  loss_box_reg: 0.5563  loss_mask: 0.2915  loss_rpn_cls: 0.08667  loss_rpn_loc: 0.1607  time: 0.6647  data_time: 0.1150  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:28:16 d2.utils.events]: \u001b[0m eta: 1:04:54  iter: 2079  total_loss: 1.561  loss_cls: 0.3364  loss_box_reg: 0.5912  loss_mask: 0.3213  loss_rpn_cls: 0.08562  loss_rpn_loc: 0.1742  time: 0.6652  data_time: 0.2424  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:28:28 d2.utils.events]: \u001b[0m eta: 1:04:49  iter: 2099  total_loss: 1.523  loss_cls: 0.3646  loss_box_reg: 0.6055  loss_mask: 0.3068  loss_rpn_cls: 0.09472  loss_rpn_loc: 0.1701  time: 0.6646  data_time: 0.1375  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:28:40 d2.utils.events]: \u001b[0m eta: 1:04:40  iter: 2119  total_loss: 1.567  loss_cls: 0.3387  loss_box_reg: 0.6073  loss_mask: 0.3187  loss_rpn_cls: 0.08035  loss_rpn_loc: 0.1823  time: 0.6642  data_time: 0.1660  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:28:53 d2.utils.events]: \u001b[0m eta: 1:04:24  iter: 2139  total_loss: 1.417  loss_cls: 0.3064  loss_box_reg: 0.5574  loss_mask: 0.3078  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.1555  time: 0.6638  data_time: 0.1671  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:29:03 d2.utils.events]: \u001b[0m eta: 1:04:05  iter: 2159  total_loss: 1.554  loss_cls: 0.3486  loss_box_reg: 0.5908  loss_mask: 0.3079  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.2048  time: 0.6626  data_time: 0.0715  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:29:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:29:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:29:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:29:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:29:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:29:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0850 s/iter. Eval: 0.0614 s/iter. Total: 0.1471 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 19:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0742 s/iter. Total: 0.1610 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0748 s/iter. Total: 0.1639 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 19:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0799 s/iter. Total: 0.1690 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:29:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.514225 (0.168226 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:29:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088227 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:29:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:29:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2556524258201606\n",
      "\u001b[32m[02/04 19:29:36 d2.utils.events]: \u001b[0m eta: 1:03:55  iter: 2179  total_loss: 1.423  loss_cls: 0.3259  loss_box_reg: 0.555  loss_mask: 0.3024  loss_rpn_cls: 0.0913  loss_rpn_loc: 0.1756  time: 0.6618  data_time: 0.1019  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:29:52 d2.utils.events]: \u001b[0m eta: 1:03:46  iter: 2199  total_loss: 1.396  loss_cls: 0.328  loss_box_reg: 0.5649  loss_mask: 0.3063  loss_rpn_cls: 0.09615  loss_rpn_loc: 0.1782  time: 0.6631  data_time: 0.3107  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:30:02 d2.utils.events]: \u001b[0m eta: 1:03:31  iter: 2219  total_loss: 1.485  loss_cls: 0.3324  loss_box_reg: 0.5661  loss_mask: 0.3182  loss_rpn_cls: 0.08131  loss_rpn_loc: 0.1853  time: 0.6617  data_time: 0.0601  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:30:16 d2.utils.events]: \u001b[0m eta: 1:03:21  iter: 2239  total_loss: 1.423  loss_cls: 0.3293  loss_box_reg: 0.5489  loss_mask: 0.2905  loss_rpn_cls: 0.08589  loss_rpn_loc: 0.1718  time: 0.6618  data_time: 0.1987  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:30:29 d2.utils.events]: \u001b[0m eta: 1:03:12  iter: 2259  total_loss: 1.485  loss_cls: 0.3437  loss_box_reg: 0.5651  loss_mask: 0.3054  loss_rpn_cls: 0.0932  loss_rpn_loc: 0.1747  time: 0.6620  data_time: 0.2024  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:30:45 d2.utils.events]: \u001b[0m eta: 1:03:01  iter: 2279  total_loss: 1.649  loss_cls: 0.3887  loss_box_reg: 0.6126  loss_mask: 0.3235  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2042  time: 0.6631  data_time: 0.3047  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:30:57 d2.utils.events]: \u001b[0m eta: 1:02:44  iter: 2299  total_loss: 1.409  loss_cls: 0.2987  loss_box_reg: 0.572  loss_mask: 0.311  loss_rpn_cls: 0.04963  loss_rpn_loc: 0.1696  time: 0.6626  data_time: 0.1616  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:31:11 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 2319  total_loss: 1.389  loss_cls: 0.3206  loss_box_reg: 0.5523  loss_mask: 0.302  loss_rpn_cls: 0.06743  loss_rpn_loc: 0.1555  time: 0.6628  data_time: 0.2169  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:31:25 d2.utils.events]: \u001b[0m eta: 1:02:28  iter: 2339  total_loss: 1.576  loss_cls: 0.359  loss_box_reg: 0.5906  loss_mask: 0.3138  loss_rpn_cls: 0.09807  loss_rpn_loc: 0.1802  time: 0.6629  data_time: 0.2198  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:31:36 d2.utils.events]: \u001b[0m eta: 1:02:06  iter: 2359  total_loss: 1.568  loss_cls: 0.3364  loss_box_reg: 0.5945  loss_mask: 0.315  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.1782  time: 0.6624  data_time: 0.1536  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:31:48 d2.utils.events]: \u001b[0m eta: 1:01:53  iter: 2379  total_loss: 1.492  loss_cls: 0.3306  loss_box_reg: 0.5647  loss_mask: 0.2979  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.1695  time: 0.6618  data_time: 0.1338  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:32:03 d2.utils.events]: \u001b[0m eta: 1:01:43  iter: 2399  total_loss: 1.481  loss_cls: 0.3467  loss_box_reg: 0.5809  loss_mask: 0.2981  loss_rpn_cls: 0.09212  loss_rpn_loc: 0.1869  time: 0.6623  data_time: 0.2534  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:32:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:32:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:32:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:32:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:32:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:32:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:32:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0833 s/iter. Eval: 0.0540 s/iter. Total: 0.1379 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:32:22 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0851 s/iter. Eval: 0.0721 s/iter. Total: 0.1580 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0851 s/iter. Eval: 0.0728 s/iter. Total: 0.1587 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0772 s/iter. Total: 0.1636 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 19:32:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.872743 (0.162696 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:32:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085398 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:32:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:32:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2647931275227615\n",
      "\u001b[32m[02/04 19:32:35 d2.utils.events]: \u001b[0m eta: 1:01:37  iter: 2419  total_loss: 1.509  loss_cls: 0.3393  loss_box_reg: 0.5726  loss_mask: 0.3104  loss_rpn_cls: 0.09547  loss_rpn_loc: 0.188  time: 0.6618  data_time: 0.1449  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:32:49 d2.utils.events]: \u001b[0m eta: 1:01:33  iter: 2439  total_loss: 1.492  loss_cls: 0.349  loss_box_reg: 0.5719  loss_mask: 0.3005  loss_rpn_cls: 0.09001  loss_rpn_loc: 0.1622  time: 0.6617  data_time: 0.1709  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:33:00 d2.utils.events]: \u001b[0m eta: 1:01:19  iter: 2459  total_loss: 1.443  loss_cls: 0.3127  loss_box_reg: 0.5481  loss_mask: 0.2883  loss_rpn_cls: 0.09294  loss_rpn_loc: 0.1714  time: 0.6608  data_time: 0.0836  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:33:12 d2.utils.events]: \u001b[0m eta: 1:01:18  iter: 2479  total_loss: 1.444  loss_cls: 0.3429  loss_box_reg: 0.5714  loss_mask: 0.2906  loss_rpn_cls: 0.07466  loss_rpn_loc: 0.1553  time: 0.6604  data_time: 0.1256  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:33:23 d2.utils.events]: \u001b[0m eta: 1:01:03  iter: 2499  total_loss: 1.425  loss_cls: 0.3013  loss_box_reg: 0.5437  loss_mask: 0.3071  loss_rpn_cls: 0.06699  loss_rpn_loc: 0.1804  time: 0.6595  data_time: 0.0959  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:33:40 d2.utils.events]: \u001b[0m eta: 1:01:06  iter: 2519  total_loss: 1.474  loss_cls: 0.3423  loss_box_reg: 0.5608  loss_mask: 0.2901  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.1828  time: 0.6610  data_time: 0.3602  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:33:52 d2.utils.events]: \u001b[0m eta: 1:00:49  iter: 2539  total_loss: 1.388  loss_cls: 0.3305  loss_box_reg: 0.5628  loss_mask: 0.3157  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.1591  time: 0.6607  data_time: 0.1567  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:34:04 d2.utils.events]: \u001b[0m eta: 1:00:36  iter: 2559  total_loss: 1.53  loss_cls: 0.3411  loss_box_reg: 0.5941  loss_mask: 0.3058  loss_rpn_cls: 0.07947  loss_rpn_loc: 0.1757  time: 0.6601  data_time: 0.1102  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:34:16 d2.utils.events]: \u001b[0m eta: 1:00:32  iter: 2579  total_loss: 1.263  loss_cls: 0.2855  loss_box_reg: 0.5173  loss_mask: 0.2828  loss_rpn_cls: 0.06018  loss_rpn_loc: 0.1347  time: 0.6598  data_time: 0.1590  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:34:30 d2.utils.events]: \u001b[0m eta: 1:00:26  iter: 2599  total_loss: 1.477  loss_cls: 0.3349  loss_box_reg: 0.5998  loss_mask: 0.3167  loss_rpn_cls: 0.08356  loss_rpn_loc: 0.155  time: 0.6602  data_time: 0.2351  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:34:45 d2.utils.events]: \u001b[0m eta: 1:00:22  iter: 2619  total_loss: 1.591  loss_cls: 0.352  loss_box_reg: 0.584  loss_mask: 0.313  loss_rpn_cls: 0.09571  loss_rpn_loc: 0.2111  time: 0.6608  data_time: 0.2666  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:34:56 d2.utils.events]: \u001b[0m eta: 1:00:04  iter: 2639  total_loss: 1.445  loss_cls: 0.2934  loss_box_reg: 0.5924  loss_mask: 0.3155  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.1712  time: 0.6600  data_time: 0.0979  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:35:10 d2.utils.events]: \u001b[0m eta: 1:00:02  iter: 2659  total_loss: 1.46  loss_cls: 0.3321  loss_box_reg: 0.5715  loss_mask: 0.3034  loss_rpn_cls: 0.08169  loss_rpn_loc: 0.1765  time: 0.6602  data_time: 0.1953  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:35:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:35:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:35:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:35:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:35:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:35:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0871 s/iter. Eval: 0.0567 s/iter. Total: 0.1445 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0861 s/iter. Eval: 0.0700 s/iter. Total: 0.1569 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0007 s/iter. Inference: 0.0865 s/iter. Eval: 0.0722 s/iter. Total: 0.1595 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:35:31 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0780 s/iter. Total: 0.1668 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:35:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.260326 (0.166037 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:35:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087802 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:35:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:35:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26072794797313625\n",
      "\u001b[32m[02/04 19:35:44 d2.utils.events]: \u001b[0m eta: 0:59:37  iter: 2679  total_loss: 1.466  loss_cls: 0.3615  loss_box_reg: 0.5806  loss_mask: 0.2991  loss_rpn_cls: 0.07288  loss_rpn_loc: 0.1805  time: 0.6601  data_time: 0.1884  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:35:59 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 2699  total_loss: 1.554  loss_cls: 0.3613  loss_box_reg: 0.6062  loss_mask: 0.3139  loss_rpn_cls: 0.09815  loss_rpn_loc: 0.1698  time: 0.6607  data_time: 0.2753  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:36:12 d2.utils.events]: \u001b[0m eta: 0:59:12  iter: 2719  total_loss: 1.446  loss_cls: 0.3125  loss_box_reg: 0.5561  loss_mask: 0.2926  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1824  time: 0.6609  data_time: 0.2114  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:36:25 d2.utils.events]: \u001b[0m eta: 0:58:56  iter: 2739  total_loss: 1.509  loss_cls: 0.3086  loss_box_reg: 0.5722  loss_mask: 0.3149  loss_rpn_cls: 0.06699  loss_rpn_loc: 0.1834  time: 0.6605  data_time: 0.1407  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:36:43 d2.utils.events]: \u001b[0m eta: 0:58:46  iter: 2759  total_loss: 1.371  loss_cls: 0.3136  loss_box_reg: 0.5422  loss_mask: 0.2903  loss_rpn_cls: 0.08877  loss_rpn_loc: 0.1601  time: 0.6622  data_time: 0.4147  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:36:54 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 2779  total_loss: 1.413  loss_cls: 0.3065  loss_box_reg: 0.547  loss_mask: 0.3009  loss_rpn_cls: 0.0957  loss_rpn_loc: 0.1516  time: 0.6617  data_time: 0.1333  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:37:10 d2.utils.events]: \u001b[0m eta: 0:58:28  iter: 2799  total_loss: 1.585  loss_cls: 0.3967  loss_box_reg: 0.6203  loss_mask: 0.3129  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.1989  time: 0.6625  data_time: 0.2909  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:37:21 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 2819  total_loss: 1.51  loss_cls: 0.327  loss_box_reg: 0.5758  loss_mask: 0.3093  loss_rpn_cls: 0.08148  loss_rpn_loc: 0.1584  time: 0.6619  data_time: 0.1147  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:37:33 d2.utils.events]: \u001b[0m eta: 0:58:06  iter: 2839  total_loss: 1.464  loss_cls: 0.3217  loss_box_reg: 0.5686  loss_mask: 0.311  loss_rpn_cls: 0.0926  loss_rpn_loc: 0.168  time: 0.6614  data_time: 0.1395  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:37:43 d2.utils.events]: \u001b[0m eta: 0:57:52  iter: 2859  total_loss: 1.416  loss_cls: 0.332  loss_box_reg: 0.5758  loss_mask: 0.2915  loss_rpn_cls: 0.07277  loss_rpn_loc: 0.1444  time: 0.6601  data_time: 0.0361  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:37:57 d2.utils.events]: \u001b[0m eta: 0:57:44  iter: 2879  total_loss: 1.511  loss_cls: 0.321  loss_box_reg: 0.5887  loss_mask: 0.3194  loss_rpn_cls: 0.07664  loss_rpn_loc: 0.1938  time: 0.6605  data_time: 0.2381  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:38:10 d2.utils.events]: \u001b[0m eta: 0:57:31  iter: 2899  total_loss: 1.423  loss_cls: 0.349  loss_box_reg: 0.5625  loss_mask: 0.2984  loss_rpn_cls: 0.08235  loss_rpn_loc: 0.1733  time: 0.6605  data_time: 0.2150  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:38:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:38:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:38:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:38:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:38:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:38:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0838 s/iter. Eval: 0.0552 s/iter. Total: 0.1395 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0755 s/iter. Total: 0.1639 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 19:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0740 s/iter. Total: 0.1613 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0866 s/iter. Eval: 0.0785 s/iter. Total: 0.1659 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:38:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.159915 (0.165172 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:38:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086371 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:38:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:38:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2657666356582056\n",
      "\u001b[32m[02/04 19:38:44 d2.utils.events]: \u001b[0m eta: 0:57:21  iter: 2919  total_loss: 1.458  loss_cls: 0.3562  loss_box_reg: 0.5786  loss_mask: 0.2932  loss_rpn_cls: 0.07879  loss_rpn_loc: 0.1688  time: 0.6602  data_time: 0.1390  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:38:56 d2.utils.events]: \u001b[0m eta: 0:57:08  iter: 2939  total_loss: 1.329  loss_cls: 0.2793  loss_box_reg: 0.555  loss_mask: 0.2901  loss_rpn_cls: 0.06643  loss_rpn_loc: 0.1317  time: 0.6601  data_time: 0.1885  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:39:11 d2.utils.events]: \u001b[0m eta: 0:56:59  iter: 2959  total_loss: 1.511  loss_cls: 0.3366  loss_box_reg: 0.5879  loss_mask: 0.3248  loss_rpn_cls: 0.08292  loss_rpn_loc: 0.1812  time: 0.6604  data_time: 0.2080  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:39:24 d2.utils.events]: \u001b[0m eta: 0:56:50  iter: 2979  total_loss: 1.414  loss_cls: 0.2981  loss_box_reg: 0.559  loss_mask: 0.3113  loss_rpn_cls: 0.09519  loss_rpn_loc: 0.1646  time: 0.6604  data_time: 0.1795  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:39:37 d2.utils.events]: \u001b[0m eta: 0:56:41  iter: 2999  total_loss: 1.435  loss_cls: 0.3409  loss_box_reg: 0.552  loss_mask: 0.2946  loss_rpn_cls: 0.08552  loss_rpn_loc: 0.1652  time: 0.6604  data_time: 0.1916  lr: 0.0004  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:39:52 d2.utils.events]: \u001b[0m eta: 0:56:38  iter: 3019  total_loss: 1.46  loss_cls: 0.3255  loss_box_reg: 0.5859  loss_mask: 0.2981  loss_rpn_cls: 0.09515  loss_rpn_loc: 0.1917  time: 0.6611  data_time: 0.2839  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:40:05 d2.utils.events]: \u001b[0m eta: 0:56:24  iter: 3039  total_loss: 1.43  loss_cls: 0.3256  loss_box_reg: 0.5639  loss_mask: 0.3008  loss_rpn_cls: 0.08994  loss_rpn_loc: 0.1721  time: 0.6609  data_time: 0.1580  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:40:16 d2.utils.events]: \u001b[0m eta: 0:56:17  iter: 3059  total_loss: 1.55  loss_cls: 0.338  loss_box_reg: 0.6021  loss_mask: 0.3104  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.1717  time: 0.6602  data_time: 0.0897  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:40:30 d2.utils.events]: \u001b[0m eta: 0:56:02  iter: 3079  total_loss: 1.475  loss_cls: 0.3409  loss_box_reg: 0.5779  loss_mask: 0.3002  loss_rpn_cls: 0.08235  loss_rpn_loc: 0.1821  time: 0.6606  data_time: 0.2632  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:40:45 d2.utils.events]: \u001b[0m eta: 0:55:49  iter: 3099  total_loss: 1.42  loss_cls: 0.3127  loss_box_reg: 0.5625  loss_mask: 0.2934  loss_rpn_cls: 0.08162  loss_rpn_loc: 0.1632  time: 0.6612  data_time: 0.2786  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:40:57 d2.utils.events]: \u001b[0m eta: 0:55:38  iter: 3119  total_loss: 1.364  loss_cls: 0.3079  loss_box_reg: 0.5695  loss_mask: 0.2916  loss_rpn_cls: 0.0573  loss_rpn_loc: 0.1404  time: 0.6605  data_time: 0.0923  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:41:11 d2.utils.events]: \u001b[0m eta: 0:55:30  iter: 3139  total_loss: 1.447  loss_cls: 0.3306  loss_box_reg: 0.5625  loss_mask: 0.2903  loss_rpn_cls: 0.08662  loss_rpn_loc: 0.1562  time: 0.6610  data_time: 0.2737  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:41:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:41:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:41:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:41:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:41:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:41:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:41:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0840 s/iter. Eval: 0.0588 s/iter. Total: 0.1434 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0737 s/iter. Total: 0.1609 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0746 s/iter. Total: 0.1629 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0796 s/iter. Total: 0.1687 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:41:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.628677 (0.169213 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:41:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088614 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:41:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:41:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25829401523253315\n",
      "\u001b[32m[02/04 19:41:44 d2.utils.events]: \u001b[0m eta: 0:55:24  iter: 3159  total_loss: 1.374  loss_cls: 0.3018  loss_box_reg: 0.5521  loss_mask: 0.2937  loss_rpn_cls: 0.06557  loss_rpn_loc: 0.1517  time: 0.6605  data_time: 0.1096  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:41:59 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 3179  total_loss: 1.491  loss_cls: 0.3272  loss_box_reg: 0.5526  loss_mask: 0.3137  loss_rpn_cls: 0.08806  loss_rpn_loc: 0.1782  time: 0.6611  data_time: 0.2872  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:42:12 d2.utils.events]: \u001b[0m eta: 0:55:03  iter: 3199  total_loss: 1.398  loss_cls: 0.3097  loss_box_reg: 0.5576  loss_mask: 0.3046  loss_rpn_cls: 0.05756  loss_rpn_loc: 0.1667  time: 0.6610  data_time: 0.1900  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:42:27 d2.utils.events]: \u001b[0m eta: 0:54:58  iter: 3219  total_loss: 1.495  loss_cls: 0.3163  loss_box_reg: 0.5913  loss_mask: 0.3155  loss_rpn_cls: 0.08464  loss_rpn_loc: 0.1912  time: 0.6615  data_time: 0.2718  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:42:40 d2.utils.events]: \u001b[0m eta: 0:54:45  iter: 3239  total_loss: 1.445  loss_cls: 0.3314  loss_box_reg: 0.589  loss_mask: 0.3021  loss_rpn_cls: 0.08466  loss_rpn_loc: 0.1524  time: 0.6613  data_time: 0.1582  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:42:55 d2.utils.events]: \u001b[0m eta: 0:54:32  iter: 3259  total_loss: 1.465  loss_cls: 0.331  loss_box_reg: 0.5674  loss_mask: 0.3083  loss_rpn_cls: 0.08807  loss_rpn_loc: 0.1841  time: 0.6620  data_time: 0.3139  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:43:09 d2.utils.events]: \u001b[0m eta: 0:54:20  iter: 3279  total_loss: 1.463  loss_cls: 0.3315  loss_box_reg: 0.5743  loss_mask: 0.319  loss_rpn_cls: 0.07649  loss_rpn_loc: 0.1752  time: 0.6622  data_time: 0.2158  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:43:21 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 3299  total_loss: 1.32  loss_cls: 0.3009  loss_box_reg: 0.5531  loss_mask: 0.29  loss_rpn_cls: 0.0668  loss_rpn_loc: 0.154  time: 0.6619  data_time: 0.1603  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:43:38 d2.utils.events]: \u001b[0m eta: 0:54:11  iter: 3319  total_loss: 1.572  loss_cls: 0.3527  loss_box_reg: 0.5752  loss_mask: 0.3157  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.2129  time: 0.6628  data_time: 0.3338  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:43:52 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 3339  total_loss: 1.455  loss_cls: 0.3178  loss_box_reg: 0.569  loss_mask: 0.2988  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.1695  time: 0.6630  data_time: 0.2301  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:44:02 d2.utils.events]: \u001b[0m eta: 0:53:54  iter: 3359  total_loss: 1.338  loss_cls: 0.2982  loss_box_reg: 0.5393  loss_mask: 0.291  loss_rpn_cls: 0.06484  loss_rpn_loc: 0.1402  time: 0.6622  data_time: 0.0835  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:44:14 d2.utils.events]: \u001b[0m eta: 0:53:43  iter: 3379  total_loss: 1.357  loss_cls: 0.3009  loss_box_reg: 0.553  loss_mask: 0.2916  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.1655  time: 0.6618  data_time: 0.1443  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:44:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:44:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:44:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:44:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:44:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:44:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0839 s/iter. Eval: 0.0585 s/iter. Total: 0.1431 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0855 s/iter. Eval: 0.0735 s/iter. Total: 0.1598 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0754 s/iter. Total: 0.1629 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0815 s/iter. Total: 0.1704 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:44:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.704522 (0.169867 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:44:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088220 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:44:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:44:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26709776031712446\n",
      "\u001b[32m[02/04 19:44:47 d2.utils.events]: \u001b[0m eta: 0:53:29  iter: 3399  total_loss: 1.422  loss_cls: 0.3217  loss_box_reg: 0.5532  loss_mask: 0.3026  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.176  time: 0.6614  data_time: 0.1323  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:45:01 d2.utils.events]: \u001b[0m eta: 0:53:18  iter: 3419  total_loss: 1.395  loss_cls: 0.3232  loss_box_reg: 0.579  loss_mask: 0.3004  loss_rpn_cls: 0.06188  loss_rpn_loc: 0.1577  time: 0.6614  data_time: 0.1821  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:45:12 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 3439  total_loss: 1.451  loss_cls: 0.3199  loss_box_reg: 0.561  loss_mask: 0.3124  loss_rpn_cls: 0.0752  loss_rpn_loc: 0.1742  time: 0.6608  data_time: 0.1034  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:45:24 d2.utils.events]: \u001b[0m eta: 0:52:51  iter: 3459  total_loss: 1.439  loss_cls: 0.3083  loss_box_reg: 0.5679  loss_mask: 0.2953  loss_rpn_cls: 0.08837  loss_rpn_loc: 0.1804  time: 0.6605  data_time: 0.1558  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:45:37 d2.utils.events]: \u001b[0m eta: 0:52:42  iter: 3479  total_loss: 1.448  loss_cls: 0.3319  loss_box_reg: 0.5807  loss_mask: 0.3083  loss_rpn_cls: 0.07113  loss_rpn_loc: 0.1516  time: 0.6603  data_time: 0.1546  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:45:48 d2.utils.events]: \u001b[0m eta: 0:52:38  iter: 3499  total_loss: 1.479  loss_cls: 0.3073  loss_box_reg: 0.5809  loss_mask: 0.302  loss_rpn_cls: 0.09115  loss_rpn_loc: 0.1701  time: 0.6599  data_time: 0.1143  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:46:02 d2.utils.events]: \u001b[0m eta: 0:52:24  iter: 3519  total_loss: 1.467  loss_cls: 0.3273  loss_box_reg: 0.5853  loss_mask: 0.2961  loss_rpn_cls: 0.07809  loss_rpn_loc: 0.1818  time: 0.6601  data_time: 0.2228  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:46:16 d2.utils.events]: \u001b[0m eta: 0:52:15  iter: 3539  total_loss: 1.545  loss_cls: 0.3492  loss_box_reg: 0.5638  loss_mask: 0.3016  loss_rpn_cls: 0.09374  loss_rpn_loc: 0.1619  time: 0.6602  data_time: 0.2229  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:46:30 d2.utils.events]: \u001b[0m eta: 0:52:07  iter: 3559  total_loss: 1.42  loss_cls: 0.344  loss_box_reg: 0.5494  loss_mask: 0.292  loss_rpn_cls: 0.08911  loss_rpn_loc: 0.1768  time: 0.6606  data_time: 0.2394  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:46:43 d2.utils.events]: \u001b[0m eta: 0:52:03  iter: 3579  total_loss: 1.436  loss_cls: 0.3247  loss_box_reg: 0.5753  loss_mask: 0.3103  loss_rpn_cls: 0.06933  loss_rpn_loc: 0.1709  time: 0.6604  data_time: 0.1681  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:47:01 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 3599  total_loss: 1.37  loss_cls: 0.3131  loss_box_reg: 0.5287  loss_mask: 0.2986  loss_rpn_cls: 0.08788  loss_rpn_loc: 0.1707  time: 0.6618  data_time: 0.4145  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:47:13 d2.utils.events]: \u001b[0m eta: 0:51:37  iter: 3619  total_loss: 1.393  loss_cls: 0.3179  loss_box_reg: 0.5406  loss_mask: 0.2872  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.177  time: 0.6614  data_time: 0.1143  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:47:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:47:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:47:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:47:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:47:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:47:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0835 s/iter. Eval: 0.0527 s/iter. Total: 0.1368 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0853 s/iter. Eval: 0.0701 s/iter. Total: 0.1561 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0853 s/iter. Eval: 0.0720 s/iter. Total: 0.1581 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0752 s/iter. Total: 0.1615 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 19:47:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.777736 (0.161877 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:47:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085484 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:47:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:47:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26755921077015404\n",
      "\u001b[32m[02/04 19:47:45 d2.utils.events]: \u001b[0m eta: 0:51:27  iter: 3639  total_loss: 1.432  loss_cls: 0.3159  loss_box_reg: 0.5529  loss_mask: 0.3082  loss_rpn_cls: 0.07211  loss_rpn_loc: 0.188  time: 0.6610  data_time: 0.1290  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:47:57 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 3659  total_loss: 1.362  loss_cls: 0.3022  loss_box_reg: 0.5591  loss_mask: 0.2858  loss_rpn_cls: 0.06013  loss_rpn_loc: 0.162  time: 0.6606  data_time: 0.1493  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:48:11 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 3679  total_loss: 1.375  loss_cls: 0.3047  loss_box_reg: 0.5452  loss_mask: 0.2945  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.1844  time: 0.6608  data_time: 0.2247  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:48:23 d2.utils.events]: \u001b[0m eta: 0:50:54  iter: 3699  total_loss: 1.453  loss_cls: 0.3238  loss_box_reg: 0.5577  loss_mask: 0.3117  loss_rpn_cls: 0.07806  loss_rpn_loc: 0.1632  time: 0.6604  data_time: 0.1229  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:48:35 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 3719  total_loss: 1.601  loss_cls: 0.3748  loss_box_reg: 0.6059  loss_mask: 0.3071  loss_rpn_cls: 0.09992  loss_rpn_loc: 0.1936  time: 0.6603  data_time: 0.1597  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:48:49 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 3739  total_loss: 1.405  loss_cls: 0.3367  loss_box_reg: 0.5411  loss_mask: 0.2983  loss_rpn_cls: 0.07856  loss_rpn_loc: 0.1526  time: 0.6605  data_time: 0.2121  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:49:02 d2.utils.events]: \u001b[0m eta: 0:50:27  iter: 3759  total_loss: 1.429  loss_cls: 0.309  loss_box_reg: 0.5465  loss_mask: 0.2876  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.1694  time: 0.6602  data_time: 0.1330  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:49:15 d2.utils.events]: \u001b[0m eta: 0:50:21  iter: 3779  total_loss: 1.431  loss_cls: 0.3267  loss_box_reg: 0.5524  loss_mask: 0.3104  loss_rpn_cls: 0.07358  loss_rpn_loc: 0.1671  time: 0.6603  data_time: 0.1782  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:49:26 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 3799  total_loss: 1.355  loss_cls: 0.2841  loss_box_reg: 0.5516  loss_mask: 0.2882  loss_rpn_cls: 0.07211  loss_rpn_loc: 0.1524  time: 0.6597  data_time: 0.0978  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:49:41 d2.utils.events]: \u001b[0m eta: 0:49:57  iter: 3819  total_loss: 1.499  loss_cls: 0.3364  loss_box_reg: 0.5869  loss_mask: 0.3134  loss_rpn_cls: 0.09177  loss_rpn_loc: 0.1933  time: 0.6601  data_time: 0.2563  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:49:54 d2.utils.events]: \u001b[0m eta: 0:49:50  iter: 3839  total_loss: 1.411  loss_cls: 0.2885  loss_box_reg: 0.575  loss_mask: 0.3003  loss_rpn_cls: 0.07735  loss_rpn_loc: 0.1946  time: 0.6600  data_time: 0.1864  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:50:06 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 3859  total_loss: 1.447  loss_cls: 0.306  loss_box_reg: 0.5464  loss_mask: 0.3151  loss_rpn_cls: 0.07595  loss_rpn_loc: 0.1549  time: 0.6597  data_time: 0.1307  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:50:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:50:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:50:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:50:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:50:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:50:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0827 s/iter. Eval: 0.0510 s/iter. Total: 0.1344 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 19:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0845 s/iter. Eval: 0.0686 s/iter. Total: 0.1539 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0716 s/iter. Total: 0.1572 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:50:30 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0851 s/iter. Eval: 0.0746 s/iter. Total: 0.1605 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 19:50:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.651029 (0.160785 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:50:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085073 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:50:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:50:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27033819138647086\n",
      "\u001b[32m[02/04 19:50:39 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 3879  total_loss: 1.467  loss_cls: 0.3279  loss_box_reg: 0.5785  loss_mask: 0.3041  loss_rpn_cls: 0.08331  loss_rpn_loc: 0.1653  time: 0.6596  data_time: 0.1839  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:50:53 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 3899  total_loss: 1.376  loss_cls: 0.2915  loss_box_reg: 0.5466  loss_mask: 0.2927  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.1786  time: 0.6599  data_time: 0.2553  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:51:04 d2.utils.events]: \u001b[0m eta: 0:49:07  iter: 3919  total_loss: 1.321  loss_cls: 0.2816  loss_box_reg: 0.5504  loss_mask: 0.2857  loss_rpn_cls: 0.0412  loss_rpn_loc: 0.1325  time: 0.6592  data_time: 0.0694  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:51:18 d2.utils.events]: \u001b[0m eta: 0:48:59  iter: 3939  total_loss: 1.441  loss_cls: 0.3366  loss_box_reg: 0.5534  loss_mask: 0.2988  loss_rpn_cls: 0.0839  loss_rpn_loc: 0.1728  time: 0.6595  data_time: 0.2417  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:51:31 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 3959  total_loss: 1.448  loss_cls: 0.3158  loss_box_reg: 0.55  loss_mask: 0.2918  loss_rpn_cls: 0.08062  loss_rpn_loc: 0.1707  time: 0.6593  data_time: 0.1696  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:51:43 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 3979  total_loss: 1.511  loss_cls: 0.3398  loss_box_reg: 0.5865  loss_mask: 0.3109  loss_rpn_cls: 0.09202  loss_rpn_loc: 0.1883  time: 0.6592  data_time: 0.1746  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:51:56 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 3999  total_loss: 1.442  loss_cls: 0.3198  loss_box_reg: 0.5525  loss_mask: 0.2947  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.1806  time: 0.6591  data_time: 0.2014  lr: 0.00032  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:52:06 d2.utils.events]: \u001b[0m eta: 0:48:11  iter: 4019  total_loss: 1.506  loss_cls: 0.3253  loss_box_reg: 0.5874  loss_mask: 0.3007  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.1719  time: 0.6583  data_time: 0.0405  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:52:21 d2.utils.events]: \u001b[0m eta: 0:48:02  iter: 4039  total_loss: 1.295  loss_cls: 0.2636  loss_box_reg: 0.5569  loss_mask: 0.3058  loss_rpn_cls: 0.06526  loss_rpn_loc: 0.1608  time: 0.6588  data_time: 0.2598  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:52:36 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 4059  total_loss: 1.439  loss_cls: 0.3471  loss_box_reg: 0.566  loss_mask: 0.3097  loss_rpn_cls: 0.08952  loss_rpn_loc: 0.1783  time: 0.6592  data_time: 0.2451  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:52:50 d2.utils.events]: \u001b[0m eta: 0:47:47  iter: 4079  total_loss: 1.397  loss_cls: 0.306  loss_box_reg: 0.5511  loss_mask: 0.3011  loss_rpn_cls: 0.07067  loss_rpn_loc: 0.1515  time: 0.6592  data_time: 0.1935  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:53:01 d2.utils.events]: \u001b[0m eta: 0:47:36  iter: 4099  total_loss: 1.504  loss_cls: 0.3423  loss_box_reg: 0.5761  loss_mask: 0.3032  loss_rpn_cls: 0.07992  loss_rpn_loc: 0.1817  time: 0.6588  data_time: 0.1266  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:53:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:53:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:53:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:53:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:53:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:53:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0839 s/iter. Eval: 0.0593 s/iter. Total: 0.1438 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0010 s/iter. Inference: 0.0856 s/iter. Eval: 0.0739 s/iter. Total: 0.1605 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:53:23 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0009 s/iter. Inference: 0.0855 s/iter. Eval: 0.0745 s/iter. Total: 0.1609 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:53:28 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0791 s/iter. Total: 0.1659 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 19:53:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.144500 (0.165039 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:53:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085697 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:53:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:53:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26448978460543743\n",
      "\u001b[32m[02/04 19:53:34 d2.utils.events]: \u001b[0m eta: 0:47:28  iter: 4119  total_loss: 1.345  loss_cls: 0.3067  loss_box_reg: 0.5205  loss_mask: 0.2949  loss_rpn_cls: 0.07981  loss_rpn_loc: 0.1758  time: 0.6586  data_time: 0.1446  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:53:47 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 4139  total_loss: 1.427  loss_cls: 0.3171  loss_box_reg: 0.5606  loss_mask: 0.2914  loss_rpn_cls: 0.08997  loss_rpn_loc: 0.1681  time: 0.6584  data_time: 0.1624  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:53:58 d2.utils.events]: \u001b[0m eta: 0:47:10  iter: 4159  total_loss: 1.441  loss_cls: 0.324  loss_box_reg: 0.5704  loss_mask: 0.3013  loss_rpn_cls: 0.08152  loss_rpn_loc: 0.1695  time: 0.6580  data_time: 0.1081  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:54:11 d2.utils.events]: \u001b[0m eta: 0:46:58  iter: 4179  total_loss: 1.414  loss_cls: 0.3118  loss_box_reg: 0.566  loss_mask: 0.3104  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.1603  time: 0.6580  data_time: 0.1821  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:54:27 d2.utils.events]: \u001b[0m eta: 0:46:51  iter: 4199  total_loss: 1.483  loss_cls: 0.3459  loss_box_reg: 0.5579  loss_mask: 0.309  loss_rpn_cls: 0.08969  loss_rpn_loc: 0.175  time: 0.6586  data_time: 0.3060  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:54:39 d2.utils.events]: \u001b[0m eta: 0:46:44  iter: 4219  total_loss: 1.517  loss_cls: 0.3434  loss_box_reg: 0.564  loss_mask: 0.3018  loss_rpn_cls: 0.08682  loss_rpn_loc: 0.1694  time: 0.6585  data_time: 0.1500  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:54:51 d2.utils.events]: \u001b[0m eta: 0:46:32  iter: 4239  total_loss: 1.213  loss_cls: 0.263  loss_box_reg: 0.5246  loss_mask: 0.2812  loss_rpn_cls: 0.05855  loss_rpn_loc: 0.128  time: 0.6580  data_time: 0.1029  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:55:02 d2.utils.events]: \u001b[0m eta: 0:46:21  iter: 4259  total_loss: 1.372  loss_cls: 0.2837  loss_box_reg: 0.5452  loss_mask: 0.2912  loss_rpn_cls: 0.05929  loss_rpn_loc: 0.1456  time: 0.6576  data_time: 0.1149  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:55:19 d2.utils.events]: \u001b[0m eta: 0:46:13  iter: 4279  total_loss: 1.478  loss_cls: 0.3403  loss_box_reg: 0.5554  loss_mask: 0.3005  loss_rpn_cls: 0.08711  loss_rpn_loc: 0.1887  time: 0.6584  data_time: 0.3423  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:55:32 d2.utils.events]: \u001b[0m eta: 0:46:03  iter: 4299  total_loss: 1.38  loss_cls: 0.3058  loss_box_reg: 0.5268  loss_mask: 0.2912  loss_rpn_cls: 0.07402  loss_rpn_loc: 0.1639  time: 0.6585  data_time: 0.2228  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:55:46 d2.utils.events]: \u001b[0m eta: 0:45:55  iter: 4319  total_loss: 1.499  loss_cls: 0.34  loss_box_reg: 0.5787  loss_mask: 0.3095  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.1807  time: 0.6586  data_time: 0.1848  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:55:56 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 4339  total_loss: 1.307  loss_cls: 0.2816  loss_box_reg: 0.5634  loss_mask: 0.2941  loss_rpn_cls: 0.0477  loss_rpn_loc: 0.151  time: 0.6580  data_time: 0.0754  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:56:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:56:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:56:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:56:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:56:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:56:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0845 s/iter. Eval: 0.0559 s/iter. Total: 0.1410 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0754 s/iter. Total: 0.1624 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0742 s/iter. Total: 0.1616 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0793 s/iter. Total: 0.1668 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 19:56:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.304991 (0.166422 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:56:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086526 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:56:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:56:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2682270621193041\n",
      "\u001b[32m[02/04 19:56:30 d2.utils.events]: \u001b[0m eta: 0:45:33  iter: 4359  total_loss: 1.391  loss_cls: 0.3216  loss_box_reg: 0.561  loss_mask: 0.3017  loss_rpn_cls: 0.06618  loss_rpn_loc: 0.1724  time: 0.6579  data_time: 0.1748  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:56:43 d2.utils.events]: \u001b[0m eta: 0:45:24  iter: 4379  total_loss: 1.389  loss_cls: 0.3138  loss_box_reg: 0.5674  loss_mask: 0.2992  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.1617  time: 0.6579  data_time: 0.1888  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:56:55 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 4399  total_loss: 1.388  loss_cls: 0.3314  loss_box_reg: 0.5607  loss_mask: 0.2893  loss_rpn_cls: 0.07077  loss_rpn_loc: 0.1577  time: 0.6575  data_time: 0.1226  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:57:07 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 4419  total_loss: 1.341  loss_cls: 0.2999  loss_box_reg: 0.5403  loss_mask: 0.3014  loss_rpn_cls: 0.07377  loss_rpn_loc: 0.1562  time: 0.6573  data_time: 0.1576  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:57:19 d2.utils.events]: \u001b[0m eta: 0:44:57  iter: 4439  total_loss: 1.391  loss_cls: 0.3228  loss_box_reg: 0.5585  loss_mask: 0.293  loss_rpn_cls: 0.07345  loss_rpn_loc: 0.1715  time: 0.6570  data_time: 0.1318  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:57:34 d2.utils.events]: \u001b[0m eta: 0:44:56  iter: 4459  total_loss: 1.51  loss_cls: 0.3434  loss_box_reg: 0.5623  loss_mask: 0.3074  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1891  time: 0.6574  data_time: 0.2481  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:57:46 d2.utils.events]: \u001b[0m eta: 0:44:42  iter: 4479  total_loss: 1.422  loss_cls: 0.3258  loss_box_reg: 0.561  loss_mask: 0.296  loss_rpn_cls: 0.08565  loss_rpn_loc: 0.1637  time: 0.6573  data_time: 0.1739  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:57:58 d2.utils.events]: \u001b[0m eta: 0:44:28  iter: 4499  total_loss: 1.349  loss_cls: 0.3002  loss_box_reg: 0.5294  loss_mask: 0.2893  loss_rpn_cls: 0.05017  loss_rpn_loc: 0.1509  time: 0.6569  data_time: 0.1347  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:58:15 d2.utils.events]: \u001b[0m eta: 0:44:19  iter: 4519  total_loss: 1.528  loss_cls: 0.3455  loss_box_reg: 0.595  loss_mask: 0.3164  loss_rpn_cls: 0.07545  loss_rpn_loc: 0.1801  time: 0.6577  data_time: 0.3438  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:58:27 d2.utils.events]: \u001b[0m eta: 0:44:09  iter: 4539  total_loss: 1.289  loss_cls: 0.2431  loss_box_reg: 0.5285  loss_mask: 0.307  loss_rpn_cls: 0.05699  loss_rpn_loc: 0.166  time: 0.6576  data_time: 0.1784  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:58:42 d2.utils.events]: \u001b[0m eta: 0:44:01  iter: 4559  total_loss: 1.558  loss_cls: 0.3467  loss_box_reg: 0.5931  loss_mask: 0.3123  loss_rpn_cls: 0.08767  loss_rpn_loc: 0.1913  time: 0.6580  data_time: 0.2631  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:58:56 d2.utils.events]: \u001b[0m eta: 0:43:54  iter: 4579  total_loss: 1.461  loss_cls: 0.3314  loss_box_reg: 0.5344  loss_mask: 0.3017  loss_rpn_cls: 0.09431  loss_rpn_loc: 0.1785  time: 0.6580  data_time: 0.1913  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:59:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:59:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 19:59:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 19:59:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 19:59:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 19:59:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 19:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0831 s/iter. Eval: 0.0529 s/iter. Total: 0.1367 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 19:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0851 s/iter. Eval: 0.0718 s/iter. Total: 0.1577 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 19:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0850 s/iter. Eval: 0.0718 s/iter. Total: 0.1576 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 19:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0763 s/iter. Total: 0.1626 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 19:59:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.758807 (0.161714 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:59:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085348 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 19:59:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 19:59:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2702884987165921\n",
      "\u001b[32m[02/04 19:59:26 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 4599  total_loss: 1.386  loss_cls: 0.2902  loss_box_reg: 0.5565  loss_mask: 0.3004  loss_rpn_cls: 0.05723  loss_rpn_loc: 0.1743  time: 0.6574  data_time: 0.0550  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:59:40 d2.utils.events]: \u001b[0m eta: 0:43:28  iter: 4619  total_loss: 1.366  loss_cls: 0.3078  loss_box_reg: 0.5581  loss_mask: 0.2868  loss_rpn_cls: 0.07347  loss_rpn_loc: 0.158  time: 0.6574  data_time: 0.2140  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 19:59:55 d2.utils.events]: \u001b[0m eta: 0:43:21  iter: 4639  total_loss: 1.381  loss_cls: 0.327  loss_box_reg: 0.522  loss_mask: 0.2924  loss_rpn_cls: 0.07634  loss_rpn_loc: 0.153  time: 0.6579  data_time: 0.3032  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:00:08 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 4659  total_loss: 1.542  loss_cls: 0.3433  loss_box_reg: 0.5876  loss_mask: 0.3182  loss_rpn_cls: 0.08625  loss_rpn_loc: 0.1855  time: 0.6577  data_time: 0.1422  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:00:20 d2.utils.events]: \u001b[0m eta: 0:43:10  iter: 4679  total_loss: 1.408  loss_cls: 0.318  loss_box_reg: 0.5654  loss_mask: 0.3158  loss_rpn_cls: 0.0876  loss_rpn_loc: 0.1466  time: 0.6576  data_time: 0.1618  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:00:36 d2.utils.events]: \u001b[0m eta: 0:43:00  iter: 4699  total_loss: 1.258  loss_cls: 0.2781  loss_box_reg: 0.5311  loss_mask: 0.3099  loss_rpn_cls: 0.04307  loss_rpn_loc: 0.1412  time: 0.6582  data_time: 0.3154  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:00:49 d2.utils.events]: \u001b[0m eta: 0:42:48  iter: 4719  total_loss: 1.358  loss_cls: 0.3056  loss_box_reg: 0.546  loss_mask: 0.2831  loss_rpn_cls: 0.07104  loss_rpn_loc: 0.1636  time: 0.6582  data_time: 0.1871  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:01:00 d2.utils.events]: \u001b[0m eta: 0:42:32  iter: 4739  total_loss: 1.406  loss_cls: 0.3172  loss_box_reg: 0.549  loss_mask: 0.3018  loss_rpn_cls: 0.06849  loss_rpn_loc: 0.1692  time: 0.6577  data_time: 0.0771  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:01:14 d2.utils.events]: \u001b[0m eta: 0:42:22  iter: 4759  total_loss: 1.451  loss_cls: 0.3154  loss_box_reg: 0.5821  loss_mask: 0.2996  loss_rpn_cls: 0.08508  loss_rpn_loc: 0.1864  time: 0.6579  data_time: 0.2404  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:01:27 d2.utils.events]: \u001b[0m eta: 0:42:08  iter: 4779  total_loss: 1.31  loss_cls: 0.2967  loss_box_reg: 0.5377  loss_mask: 0.2959  loss_rpn_cls: 0.091  loss_rpn_loc: 0.1464  time: 0.6579  data_time: 0.1926  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:01:40 d2.utils.events]: \u001b[0m eta: 0:42:01  iter: 4799  total_loss: 1.498  loss_cls: 0.3286  loss_box_reg: 0.5664  loss_mask: 0.3247  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.1929  time: 0.6579  data_time: 0.1655  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:01:51 d2.utils.events]: \u001b[0m eta: 0:41:52  iter: 4819  total_loss: 1.535  loss_cls: 0.3581  loss_box_reg: 0.6053  loss_mask: 0.3046  loss_rpn_cls: 0.09989  loss_rpn_loc: 0.198  time: 0.6575  data_time: 0.0997  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:02:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:02:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:02:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:02:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:02:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:02:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:02:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0838 s/iter. Eval: 0.0577 s/iter. Total: 0.1421 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 20:02:12 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0854 s/iter. Eval: 0.0731 s/iter. Total: 0.1594 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0853 s/iter. Eval: 0.0730 s/iter. Total: 0.1591 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0775 s/iter. Total: 0.1640 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 20:02:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.918136 (0.163087 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:02:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085528 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:02:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:02:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27040772118623996\n",
      "\u001b[32m[02/04 20:02:25 d2.utils.events]: \u001b[0m eta: 0:41:44  iter: 4839  total_loss: 1.386  loss_cls: 0.3177  loss_box_reg: 0.5256  loss_mask: 0.2863  loss_rpn_cls: 0.07406  loss_rpn_loc: 0.1554  time: 0.6574  data_time: 0.1988  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:02:40 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 4859  total_loss: 1.459  loss_cls: 0.3402  loss_box_reg: 0.577  loss_mask: 0.3034  loss_rpn_cls: 0.09262  loss_rpn_loc: 0.1856  time: 0.6577  data_time: 0.2357  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:02:53 d2.utils.events]: \u001b[0m eta: 0:41:27  iter: 4879  total_loss: 1.526  loss_cls: 0.3416  loss_box_reg: 0.576  loss_mask: 0.3241  loss_rpn_cls: 0.07831  loss_rpn_loc: 0.191  time: 0.6579  data_time: 0.2273  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:03:06 d2.utils.events]: \u001b[0m eta: 0:41:16  iter: 4899  total_loss: 1.451  loss_cls: 0.3299  loss_box_reg: 0.5889  loss_mask: 0.2954  loss_rpn_cls: 0.08561  loss_rpn_loc: 0.1708  time: 0.6578  data_time: 0.1887  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:03:18 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 4919  total_loss: 1.382  loss_cls: 0.3149  loss_box_reg: 0.5537  loss_mask: 0.3011  loss_rpn_cls: 0.05714  loss_rpn_loc: 0.1559  time: 0.6574  data_time: 0.1122  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:03:28 d2.utils.events]: \u001b[0m eta: 0:40:55  iter: 4939  total_loss: 1.37  loss_cls: 0.2928  loss_box_reg: 0.5529  loss_mask: 0.2879  loss_rpn_cls: 0.0635  loss_rpn_loc: 0.1654  time: 0.6569  data_time: 0.0769  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:03:42 d2.utils.events]: \u001b[0m eta: 0:40:52  iter: 4959  total_loss: 1.517  loss_cls: 0.3447  loss_box_reg: 0.5762  loss_mask: 0.3027  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1979  time: 0.6570  data_time: 0.2001  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:03:55 d2.utils.events]: \u001b[0m eta: 0:40:45  iter: 4979  total_loss: 1.262  loss_cls: 0.2793  loss_box_reg: 0.5106  loss_mask: 0.2917  loss_rpn_cls: 0.0795  loss_rpn_loc: 0.1576  time: 0.6570  data_time: 0.1941  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:04:08 d2.utils.events]: \u001b[0m eta: 0:40:35  iter: 4999  total_loss: 1.351  loss_cls: 0.3003  loss_box_reg: 0.549  loss_mask: 0.3006  loss_rpn_cls: 0.06865  loss_rpn_loc: 0.1688  time: 0.6569  data_time: 0.1622  lr: 0.000256  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:04:23 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 5019  total_loss: 1.492  loss_cls: 0.3285  loss_box_reg: 0.5789  loss_mask: 0.3164  loss_rpn_cls: 0.09043  loss_rpn_loc: 0.1822  time: 0.6573  data_time: 0.2687  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:04:36 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 5039  total_loss: 1.487  loss_cls: 0.344  loss_box_reg: 0.5857  loss_mask: 0.3121  loss_rpn_cls: 0.08028  loss_rpn_loc: 0.1831  time: 0.6572  data_time: 0.1616  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:04:51 d2.utils.events]: \u001b[0m eta: 0:40:05  iter: 5059  total_loss: 1.45  loss_cls: 0.3074  loss_box_reg: 0.5678  loss_mask: 0.298  loss_rpn_cls: 0.07628  loss_rpn_loc: 0.1678  time: 0.6576  data_time: 0.2767  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:05:05 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 5079  total_loss: 1.326  loss_cls: 0.2636  loss_box_reg: 0.5105  loss_mask: 0.293  loss_rpn_cls: 0.0555  loss_rpn_loc: 0.1387  time: 0.6578  data_time: 0.2265  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:05:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:05:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:05:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:05:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:05:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:05:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0843 s/iter. Eval: 0.0544 s/iter. Total: 0.1394 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 20:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0731 s/iter. Total: 0.1595 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0734 s/iter. Total: 0.1600 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0782 s/iter. Total: 0.1658 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.173326 (0.165287 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086464 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:05:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:05:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2729076017313342\n",
      "\u001b[32m[02/04 20:05:41 d2.utils.events]: \u001b[0m eta: 0:39:53  iter: 5099  total_loss: 1.425  loss_cls: 0.3058  loss_box_reg: 0.5474  loss_mask: 0.293  loss_rpn_cls: 0.07304  loss_rpn_loc: 0.1753  time: 0.6582  data_time: 0.2702  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:05:54 d2.utils.events]: \u001b[0m eta: 0:39:40  iter: 5119  total_loss: 1.452  loss_cls: 0.3308  loss_box_reg: 0.556  loss_mask: 0.2921  loss_rpn_cls: 0.07559  loss_rpn_loc: 0.1748  time: 0.6581  data_time: 0.1819  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:06:08 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 5139  total_loss: 1.434  loss_cls: 0.3175  loss_box_reg: 0.5741  loss_mask: 0.3078  loss_rpn_cls: 0.07364  loss_rpn_loc: 0.1758  time: 0.6583  data_time: 0.2295  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:06:18 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 5159  total_loss: 1.3  loss_cls: 0.2748  loss_box_reg: 0.5367  loss_mask: 0.289  loss_rpn_cls: 0.05403  loss_rpn_loc: 0.1566  time: 0.6576  data_time: 0.0438  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:06:32 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 5179  total_loss: 1.394  loss_cls: 0.309  loss_box_reg: 0.544  loss_mask: 0.3054  loss_rpn_cls: 0.07683  loss_rpn_loc: 0.1621  time: 0.6578  data_time: 0.2308  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:06:44 d2.utils.events]: \u001b[0m eta: 0:38:55  iter: 5199  total_loss: 1.526  loss_cls: 0.338  loss_box_reg: 0.5791  loss_mask: 0.306  loss_rpn_cls: 0.08227  loss_rpn_loc: 0.1753  time: 0.6576  data_time: 0.1293  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:06:56 d2.utils.events]: \u001b[0m eta: 0:38:42  iter: 5219  total_loss: 1.405  loss_cls: 0.3262  loss_box_reg: 0.5552  loss_mask: 0.3093  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.1618  time: 0.6575  data_time: 0.1565  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:07:07 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 5239  total_loss: 1.464  loss_cls: 0.3363  loss_box_reg: 0.5455  loss_mask: 0.2964  loss_rpn_cls: 0.0876  loss_rpn_loc: 0.1523  time: 0.6570  data_time: 0.0757  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:07:22 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 5259  total_loss: 1.428  loss_cls: 0.3153  loss_box_reg: 0.5554  loss_mask: 0.2996  loss_rpn_cls: 0.06586  loss_rpn_loc: 0.1768  time: 0.6573  data_time: 0.2404  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:07:34 d2.utils.events]: \u001b[0m eta: 0:38:11  iter: 5279  total_loss: 1.254  loss_cls: 0.2898  loss_box_reg: 0.504  loss_mask: 0.2899  loss_rpn_cls: 0.05299  loss_rpn_loc: 0.1556  time: 0.6571  data_time: 0.1603  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:07:47 d2.utils.events]: \u001b[0m eta: 0:38:04  iter: 5299  total_loss: 1.431  loss_cls: 0.3189  loss_box_reg: 0.5542  loss_mask: 0.3034  loss_rpn_cls: 0.09195  loss_rpn_loc: 0.1593  time: 0.6571  data_time: 0.1576  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:08:01 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 5319  total_loss: 1.436  loss_cls: 0.3203  loss_box_reg: 0.5645  loss_mask: 0.2989  loss_rpn_cls: 0.07768  loss_rpn_loc: 0.1663  time: 0.6572  data_time: 0.2262  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:08:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:08:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:08:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:08:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:08:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:08:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0932 s/iter. Eval: 0.0639 s/iter. Total: 0.1578 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 20:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0899 s/iter. Eval: 0.0777 s/iter. Total: 0.1684 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0885 s/iter. Eval: 0.0751 s/iter. Total: 0.1645 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0885 s/iter. Eval: 0.0797 s/iter. Total: 0.1690 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:08:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.513975 (0.168224 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:08:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087904 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:08:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:08:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26694523130692654\n",
      "\u001b[32m[02/04 20:08:37 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 5339  total_loss: 1.436  loss_cls: 0.3229  loss_box_reg: 0.5425  loss_mask: 0.3027  loss_rpn_cls: 0.0828  loss_rpn_loc: 0.1897  time: 0.6576  data_time: 0.2579  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:08:52 d2.utils.events]: \u001b[0m eta: 0:37:39  iter: 5359  total_loss: 1.484  loss_cls: 0.3384  loss_box_reg: 0.5571  loss_mask: 0.3089  loss_rpn_cls: 0.08819  loss_rpn_loc: 0.1713  time: 0.6578  data_time: 0.2523  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:09:04 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 5379  total_loss: 1.371  loss_cls: 0.3014  loss_box_reg: 0.5427  loss_mask: 0.2971  loss_rpn_cls: 0.08437  loss_rpn_loc: 0.1525  time: 0.6577  data_time: 0.1671  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:09:18 d2.utils.events]: \u001b[0m eta: 0:37:21  iter: 5399  total_loss: 1.497  loss_cls: 0.3335  loss_box_reg: 0.5653  loss_mask: 0.3108  loss_rpn_cls: 0.0727  loss_rpn_loc: 0.1691  time: 0.6578  data_time: 0.2317  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:09:29 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 5419  total_loss: 1.342  loss_cls: 0.2778  loss_box_reg: 0.5508  loss_mask: 0.2897  loss_rpn_cls: 0.05038  loss_rpn_loc: 0.1498  time: 0.6574  data_time: 0.0978  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:09:39 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 5439  total_loss: 1.404  loss_cls: 0.302  loss_box_reg: 0.5681  loss_mask: 0.2923  loss_rpn_cls: 0.05783  loss_rpn_loc: 0.1457  time: 0.6569  data_time: 0.0636  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:09:51 d2.utils.events]: \u001b[0m eta: 0:36:45  iter: 5459  total_loss: 1.338  loss_cls: 0.2993  loss_box_reg: 0.5352  loss_mask: 0.2844  loss_rpn_cls: 0.06545  loss_rpn_loc: 0.1581  time: 0.6567  data_time: 0.1011  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:10:05 d2.utils.events]: \u001b[0m eta: 0:36:36  iter: 5479  total_loss: 1.416  loss_cls: 0.2971  loss_box_reg: 0.5286  loss_mask: 0.2876  loss_rpn_cls: 0.06918  loss_rpn_loc: 0.1742  time: 0.6568  data_time: 0.2210  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:10:19 d2.utils.events]: \u001b[0m eta: 0:36:31  iter: 5499  total_loss: 1.463  loss_cls: 0.3213  loss_box_reg: 0.5768  loss_mask: 0.3142  loss_rpn_cls: 0.09579  loss_rpn_loc: 0.1982  time: 0.6569  data_time: 0.2170  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:10:34 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 5519  total_loss: 1.485  loss_cls: 0.3265  loss_box_reg: 0.5657  loss_mask: 0.3019  loss_rpn_cls: 0.08374  loss_rpn_loc: 0.1722  time: 0.6573  data_time: 0.2689  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:10:44 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 5539  total_loss: 1.458  loss_cls: 0.3  loss_box_reg: 0.5842  loss_mask: 0.2949  loss_rpn_cls: 0.06151  loss_rpn_loc: 0.1605  time: 0.6567  data_time: 0.0401  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:10:57 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 5559  total_loss: 1.443  loss_cls: 0.3135  loss_box_reg: 0.5562  loss_mask: 0.298  loss_rpn_cls: 0.08096  loss_rpn_loc: 0.195  time: 0.6566  data_time: 0.1745  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:11:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:11:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:11:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:11:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:11:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:11:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0835 s/iter. Eval: 0.0579 s/iter. Total: 0.1420 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 20:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0853 s/iter. Eval: 0.0741 s/iter. Total: 0.1603 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:11:14 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0007 s/iter. Inference: 0.0852 s/iter. Eval: 0.0740 s/iter. Total: 0.1600 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:11:19 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0785 s/iter. Total: 0.1650 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 20:11:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.045123 (0.164182 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:11:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085540 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:11:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:11:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26759178508995607\n",
      "\u001b[32m[02/04 20:11:31 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 5579  total_loss: 1.371  loss_cls: 0.3133  loss_box_reg: 0.5603  loss_mask: 0.2892  loss_rpn_cls: 0.08016  loss_rpn_loc: 0.1511  time: 0.6567  data_time: 0.2130  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:11:44 d2.utils.events]: \u001b[0m eta: 0:35:39  iter: 5599  total_loss: 1.354  loss_cls: 0.303  loss_box_reg: 0.5419  loss_mask: 0.2999  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.1573  time: 0.6566  data_time: 0.1809  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:11:58 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 5619  total_loss: 1.419  loss_cls: 0.3156  loss_box_reg: 0.5661  loss_mask: 0.3034  loss_rpn_cls: 0.06498  loss_rpn_loc: 0.1667  time: 0.6567  data_time: 0.2286  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:12:12 d2.utils.events]: \u001b[0m eta: 0:35:25  iter: 5639  total_loss: 1.561  loss_cls: 0.36  loss_box_reg: 0.5887  loss_mask: 0.2906  loss_rpn_cls: 0.089  loss_rpn_loc: 0.1916  time: 0.6570  data_time: 0.2531  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:12:23 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 5659  total_loss: 1.572  loss_cls: 0.3527  loss_box_reg: 0.5918  loss_mask: 0.3309  loss_rpn_cls: 0.09337  loss_rpn_loc: 0.1776  time: 0.6566  data_time: 0.0936  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:12:38 d2.utils.events]: \u001b[0m eta: 0:35:03  iter: 5679  total_loss: 1.388  loss_cls: 0.3285  loss_box_reg: 0.5499  loss_mask: 0.2955  loss_rpn_cls: 0.09044  loss_rpn_loc: 0.1577  time: 0.6569  data_time: 0.2677  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:12:49 d2.utils.events]: \u001b[0m eta: 0:34:51  iter: 5699  total_loss: 1.425  loss_cls: 0.3158  loss_box_reg: 0.5669  loss_mask: 0.2795  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.1805  time: 0.6566  data_time: 0.1202  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:13:02 d2.utils.events]: \u001b[0m eta: 0:34:38  iter: 5719  total_loss: 1.359  loss_cls: 0.2866  loss_box_reg: 0.5192  loss_mask: 0.3033  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.1593  time: 0.6565  data_time: 0.1733  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:13:13 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 5739  total_loss: 1.391  loss_cls: 0.2971  loss_box_reg: 0.5427  loss_mask: 0.2973  loss_rpn_cls: 0.06623  loss_rpn_loc: 0.1694  time: 0.6562  data_time: 0.0970  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:13:25 d2.utils.events]: \u001b[0m eta: 0:34:18  iter: 5759  total_loss: 1.443  loss_cls: 0.332  loss_box_reg: 0.5401  loss_mask: 0.2869  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.1603  time: 0.6559  data_time: 0.1349  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:13:37 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 5779  total_loss: 1.288  loss_cls: 0.2559  loss_box_reg: 0.5127  loss_mask: 0.2905  loss_rpn_cls: 0.06273  loss_rpn_loc: 0.1342  time: 0.6557  data_time: 0.1248  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:13:55 d2.utils.events]: \u001b[0m eta: 0:33:59  iter: 5799  total_loss: 1.59  loss_cls: 0.3686  loss_box_reg: 0.5911  loss_mask: 0.321  loss_rpn_cls: 0.09507  loss_rpn_loc: 0.1829  time: 0.6565  data_time: 0.4065  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:13:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:13:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:13:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:13:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:13:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:13:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0842 s/iter. Eval: 0.0568 s/iter. Total: 0.1417 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 20:14:07 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0753 s/iter. Total: 0.1635 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:14:12 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0740 s/iter. Total: 0.1611 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:14:17 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0792 s/iter. Total: 0.1667 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:14:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.265805 (0.166085 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:14:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086480 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:14:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:14:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27180893333681044\n",
      "\u001b[32m[02/04 20:14:29 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 5819  total_loss: 1.431  loss_cls: 0.3104  loss_box_reg: 0.5636  loss_mask: 0.2987  loss_rpn_cls: 0.07193  loss_rpn_loc: 0.1762  time: 0.6566  data_time: 0.1947  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:14:40 d2.utils.events]: \u001b[0m eta: 0:33:40  iter: 5839  total_loss: 1.275  loss_cls: 0.2911  loss_box_reg: 0.5315  loss_mask: 0.2886  loss_rpn_cls: 0.0527  loss_rpn_loc: 0.1494  time: 0.6562  data_time: 0.1010  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:14:54 d2.utils.events]: \u001b[0m eta: 0:33:28  iter: 5859  total_loss: 1.386  loss_cls: 0.3007  loss_box_reg: 0.53  loss_mask: 0.2916  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.1535  time: 0.6563  data_time: 0.1970  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:15:07 d2.utils.events]: \u001b[0m eta: 0:33:19  iter: 5879  total_loss: 1.493  loss_cls: 0.3233  loss_box_reg: 0.5588  loss_mask: 0.3008  loss_rpn_cls: 0.07537  loss_rpn_loc: 0.18  time: 0.6562  data_time: 0.1890  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:15:18 d2.utils.events]: \u001b[0m eta: 0:33:10  iter: 5899  total_loss: 1.346  loss_cls: 0.2895  loss_box_reg: 0.5329  loss_mask: 0.2918  loss_rpn_cls: 0.06874  loss_rpn_loc: 0.1639  time: 0.6560  data_time: 0.1408  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:15:34 d2.utils.events]: \u001b[0m eta: 0:33:05  iter: 5919  total_loss: 1.447  loss_cls: 0.337  loss_box_reg: 0.5724  loss_mask: 0.3083  loss_rpn_cls: 0.07144  loss_rpn_loc: 0.1714  time: 0.6564  data_time: 0.2986  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:15:47 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 5939  total_loss: 1.435  loss_cls: 0.3488  loss_box_reg: 0.5439  loss_mask: 0.2944  loss_rpn_cls: 0.06996  loss_rpn_loc: 0.1683  time: 0.6564  data_time: 0.1549  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:15:59 d2.utils.events]: \u001b[0m eta: 0:32:46  iter: 5959  total_loss: 1.343  loss_cls: 0.28  loss_box_reg: 0.5448  loss_mask: 0.2969  loss_rpn_cls: 0.0665  loss_rpn_loc: 0.1452  time: 0.6562  data_time: 0.1629  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:16:14 d2.utils.events]: \u001b[0m eta: 0:32:37  iter: 5979  total_loss: 1.42  loss_cls: 0.3164  loss_box_reg: 0.5616  loss_mask: 0.3009  loss_rpn_cls: 0.07752  loss_rpn_loc: 0.1873  time: 0.6566  data_time: 0.2763  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:16:27 d2.utils.events]: \u001b[0m eta: 0:32:30  iter: 5999  total_loss: 1.412  loss_cls: 0.311  loss_box_reg: 0.5495  loss_mask: 0.292  loss_rpn_cls: 0.08957  loss_rpn_loc: 0.1669  time: 0.6565  data_time: 0.1722  lr: 0.0002048  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:16:40 d2.utils.events]: \u001b[0m eta: 0:32:17  iter: 6019  total_loss: 1.428  loss_cls: 0.3093  loss_box_reg: 0.5664  loss_mask: 0.3017  loss_rpn_cls: 0.08345  loss_rpn_loc: 0.1848  time: 0.6565  data_time: 0.1772  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:16:56 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 6039  total_loss: 1.397  loss_cls: 0.3483  loss_box_reg: 0.5387  loss_mask: 0.2912  loss_rpn_cls: 0.08153  loss_rpn_loc: 0.1995  time: 0.6570  data_time: 0.3349  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:17:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:17:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:17:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:17:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:17:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:17:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:17:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0832 s/iter. Eval: 0.0540 s/iter. Total: 0.1378 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 20:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0853 s/iter. Eval: 0.0717 s/iter. Total: 0.1578 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0851 s/iter. Eval: 0.0725 s/iter. Total: 0.1584 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:17:20 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0854 s/iter. Eval: 0.0772 s/iter. Total: 0.1634 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 20:17:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.874097 (0.162708 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:17:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085450 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:17:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:17:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27181438444925926\n",
      "\u001b[32m[02/04 20:17:31 d2.utils.events]: \u001b[0m eta: 0:31:59  iter: 6059  total_loss: 1.436  loss_cls: 0.3253  loss_box_reg: 0.554  loss_mask: 0.302  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.1669  time: 0.6572  data_time: 0.2203  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:17:44 d2.utils.events]: \u001b[0m eta: 0:31:48  iter: 6079  total_loss: 1.417  loss_cls: 0.3198  loss_box_reg: 0.5728  loss_mask: 0.3091  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.1637  time: 0.6571  data_time: 0.1811  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:17:56 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 6099  total_loss: 1.423  loss_cls: 0.324  loss_box_reg: 0.5546  loss_mask: 0.3081  loss_rpn_cls: 0.06476  loss_rpn_loc: 0.1631  time: 0.6570  data_time: 0.1498  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:18:11 d2.utils.events]: \u001b[0m eta: 0:31:29  iter: 6119  total_loss: 1.339  loss_cls: 0.3029  loss_box_reg: 0.5313  loss_mask: 0.2986  loss_rpn_cls: 0.0806  loss_rpn_loc: 0.1617  time: 0.6572  data_time: 0.2509  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:18:23 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 6139  total_loss: 1.35  loss_cls: 0.2894  loss_box_reg: 0.5343  loss_mask: 0.2827  loss_rpn_cls: 0.0645  loss_rpn_loc: 0.1392  time: 0.6570  data_time: 0.1400  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:18:35 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 6159  total_loss: 1.396  loss_cls: 0.3103  loss_box_reg: 0.5446  loss_mask: 0.3149  loss_rpn_cls: 0.08291  loss_rpn_loc: 0.1754  time: 0.6569  data_time: 0.1384  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:18:50 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 6179  total_loss: 1.382  loss_cls: 0.2943  loss_box_reg: 0.5358  loss_mask: 0.3027  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.1883  time: 0.6572  data_time: 0.2849  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:19:00 d2.utils.events]: \u001b[0m eta: 0:30:49  iter: 6199  total_loss: 1.244  loss_cls: 0.2503  loss_box_reg: 0.5098  loss_mask: 0.2765  loss_rpn_cls: 0.05507  loss_rpn_loc: 0.1426  time: 0.6566  data_time: 0.0407  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:19:16 d2.utils.events]: \u001b[0m eta: 0:30:40  iter: 6219  total_loss: 1.629  loss_cls: 0.3769  loss_box_reg: 0.5854  loss_mask: 0.3256  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2111  time: 0.6572  data_time: 0.3417  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:19:32 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 6239  total_loss: 1.424  loss_cls: 0.3131  loss_box_reg: 0.583  loss_mask: 0.3012  loss_rpn_cls: 0.07307  loss_rpn_loc: 0.1689  time: 0.6575  data_time: 0.2871  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:19:45 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 6259  total_loss: 1.373  loss_cls: 0.3067  loss_box_reg: 0.547  loss_mask: 0.2969  loss_rpn_cls: 0.06643  loss_rpn_loc: 0.1584  time: 0.6575  data_time: 0.1900  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:19:56 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 6279  total_loss: 1.278  loss_cls: 0.2785  loss_box_reg: 0.5403  loss_mask: 0.2897  loss_rpn_cls: 0.06388  loss_rpn_loc: 0.1419  time: 0.6572  data_time: 0.0878  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:20:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:20:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:20:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:20:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:20:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:20:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0837 s/iter. Eval: 0.0572 s/iter. Total: 0.1415 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 20:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0865 s/iter. Eval: 0.0755 s/iter. Total: 0.1628 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0749 s/iter. Total: 0.1625 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0814 s/iter. Total: 0.1699 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:20:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.647096 (0.169372 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:20:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087844 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:20:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:20:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.271555754561081\n",
      "\u001b[32m[02/04 20:20:28 d2.utils.events]: \u001b[0m eta: 0:30:00  iter: 6299  total_loss: 1.432  loss_cls: 0.334  loss_box_reg: 0.5761  loss_mask: 0.3035  loss_rpn_cls: 0.05709  loss_rpn_loc: 0.1693  time: 0.6568  data_time: 0.0764  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:20:40 d2.utils.events]: \u001b[0m eta: 0:29:51  iter: 6319  total_loss: 1.406  loss_cls: 0.3191  loss_box_reg: 0.5571  loss_mask: 0.2918  loss_rpn_cls: 0.08098  loss_rpn_loc: 0.1472  time: 0.6566  data_time: 0.1193  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:20:54 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 6339  total_loss: 1.454  loss_cls: 0.3441  loss_box_reg: 0.5536  loss_mask: 0.3087  loss_rpn_cls: 0.07751  loss_rpn_loc: 0.1758  time: 0.6566  data_time: 0.2137  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:21:05 d2.utils.events]: \u001b[0m eta: 0:29:31  iter: 6359  total_loss: 1.299  loss_cls: 0.2692  loss_box_reg: 0.5154  loss_mask: 0.2824  loss_rpn_cls: 0.05116  loss_rpn_loc: 0.1503  time: 0.6564  data_time: 0.1036  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:21:21 d2.utils.events]: \u001b[0m eta: 0:29:23  iter: 6379  total_loss: 1.357  loss_cls: 0.3194  loss_box_reg: 0.5363  loss_mask: 0.2907  loss_rpn_cls: 0.07549  loss_rpn_loc: 0.1571  time: 0.6568  data_time: 0.3113  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:21:33 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 6399  total_loss: 1.498  loss_cls: 0.3559  loss_box_reg: 0.5689  loss_mask: 0.3154  loss_rpn_cls: 0.09044  loss_rpn_loc: 0.1922  time: 0.6566  data_time: 0.1282  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:21:46 d2.utils.events]: \u001b[0m eta: 0:29:06  iter: 6419  total_loss: 1.417  loss_cls: 0.2973  loss_box_reg: 0.555  loss_mask: 0.3025  loss_rpn_cls: 0.09985  loss_rpn_loc: 0.1755  time: 0.6566  data_time: 0.2034  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:21:58 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 6439  total_loss: 1.233  loss_cls: 0.2652  loss_box_reg: 0.5252  loss_mask: 0.2754  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.1427  time: 0.6564  data_time: 0.1264  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:22:09 d2.utils.events]: \u001b[0m eta: 0:28:46  iter: 6459  total_loss: 1.291  loss_cls: 0.262  loss_box_reg: 0.4954  loss_mask: 0.2811  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.1507  time: 0.6561  data_time: 0.0967  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:22:23 d2.utils.events]: \u001b[0m eta: 0:28:37  iter: 6479  total_loss: 1.439  loss_cls: 0.3132  loss_box_reg: 0.5492  loss_mask: 0.3035  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.1786  time: 0.6563  data_time: 0.2383  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:22:40 d2.utils.events]: \u001b[0m eta: 0:28:28  iter: 6499  total_loss: 1.535  loss_cls: 0.3316  loss_box_reg: 0.5885  loss_mask: 0.3078  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.1936  time: 0.6568  data_time: 0.3297  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:22:51 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 6519  total_loss: 1.435  loss_cls: 0.3169  loss_box_reg: 0.5761  loss_mask: 0.3091  loss_rpn_cls: 0.07936  loss_rpn_loc: 0.1682  time: 0.6566  data_time: 0.1136  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:23:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:23:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:23:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:23:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:23:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:23:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0853 s/iter. Eval: 0.0566 s/iter. Total: 0.1426 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 20:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0729 s/iter. Total: 0.1594 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:23:14 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0745 s/iter. Total: 0.1609 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0796 s/iter. Total: 0.1668 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:23:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.373438 (0.167012 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:23:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086685 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:23:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:23:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2738152314083189\n",
      "\u001b[32m[02/04 20:23:26 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 6539  total_loss: 1.493  loss_cls: 0.3291  loss_box_reg: 0.5593  loss_mask: 0.3039  loss_rpn_cls: 0.08203  loss_rpn_loc: 0.1844  time: 0.6566  data_time: 0.1912  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:23:38 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 6559  total_loss: 1.415  loss_cls: 0.3014  loss_box_reg: 0.5523  loss_mask: 0.3024  loss_rpn_cls: 0.07434  loss_rpn_loc: 0.1754  time: 0.6565  data_time: 0.1679  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:23:51 d2.utils.events]: \u001b[0m eta: 0:27:48  iter: 6579  total_loss: 1.413  loss_cls: 0.3247  loss_box_reg: 0.5276  loss_mask: 0.2957  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.1612  time: 0.6564  data_time: 0.1467  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:24:03 d2.utils.events]: \u001b[0m eta: 0:27:41  iter: 6599  total_loss: 1.419  loss_cls: 0.3444  loss_box_reg: 0.5638  loss_mask: 0.3144  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.1774  time: 0.6562  data_time: 0.1449  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:24:14 d2.utils.events]: \u001b[0m eta: 0:27:31  iter: 6619  total_loss: 1.456  loss_cls: 0.3184  loss_box_reg: 0.5634  loss_mask: 0.2937  loss_rpn_cls: 0.078  loss_rpn_loc: 0.177  time: 0.6560  data_time: 0.1016  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:24:29 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 6639  total_loss: 1.482  loss_cls: 0.3402  loss_box_reg: 0.5563  loss_mask: 0.3016  loss_rpn_cls: 0.09169  loss_rpn_loc: 0.1729  time: 0.6561  data_time: 0.2480  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:24:39 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 6659  total_loss: 1.3  loss_cls: 0.2937  loss_box_reg: 0.5327  loss_mask: 0.2879  loss_rpn_cls: 0.05902  loss_rpn_loc: 0.1372  time: 0.6557  data_time: 0.0431  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:24:52 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 6679  total_loss: 1.409  loss_cls: 0.3245  loss_box_reg: 0.551  loss_mask: 0.3053  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.1646  time: 0.6557  data_time: 0.2065  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:25:03 d2.utils.events]: \u001b[0m eta: 0:26:49  iter: 6699  total_loss: 1.31  loss_cls: 0.2701  loss_box_reg: 0.5278  loss_mask: 0.2852  loss_rpn_cls: 0.05531  loss_rpn_loc: 0.1379  time: 0.6553  data_time: 0.0659  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:25:16 d2.utils.events]: \u001b[0m eta: 0:26:40  iter: 6719  total_loss: 1.372  loss_cls: 0.299  loss_box_reg: 0.5482  loss_mask: 0.3028  loss_rpn_cls: 0.06235  loss_rpn_loc: 0.1699  time: 0.6554  data_time: 0.2173  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:25:28 d2.utils.events]: \u001b[0m eta: 0:26:30  iter: 6739  total_loss: 1.339  loss_cls: 0.287  loss_box_reg: 0.5052  loss_mask: 0.2916  loss_rpn_cls: 0.05623  loss_rpn_loc: 0.1527  time: 0.6552  data_time: 0.1215  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:25:46 d2.utils.events]: \u001b[0m eta: 0:26:23  iter: 6759  total_loss: 1.483  loss_cls: 0.3466  loss_box_reg: 0.5711  loss_mask: 0.3153  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.1797  time: 0.6559  data_time: 0.4247  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:25:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:25:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:25:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:25:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:25:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:25:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0849 s/iter. Eval: 0.0567 s/iter. Total: 0.1423 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 20:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0861 s/iter. Eval: 0.0757 s/iter. Total: 0.1626 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0747 s/iter. Total: 0.1618 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0798 s/iter. Total: 0.1671 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:26:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.312468 (0.166487 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:26:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086291 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:26:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:26:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26880632556165235\n",
      "\u001b[32m[02/04 20:26:20 d2.utils.events]: \u001b[0m eta: 0:26:17  iter: 6779  total_loss: 1.432  loss_cls: 0.3081  loss_box_reg: 0.5567  loss_mask: 0.2919  loss_rpn_cls: 0.0783  loss_rpn_loc: 0.1676  time: 0.6559  data_time: 0.1782  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:26:32 d2.utils.events]: \u001b[0m eta: 0:26:03  iter: 6799  total_loss: 1.317  loss_cls: 0.3106  loss_box_reg: 0.537  loss_mask: 0.3032  loss_rpn_cls: 0.05824  loss_rpn_loc: 0.1502  time: 0.6558  data_time: 0.1406  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:26:44 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 6819  total_loss: 1.445  loss_cls: 0.3385  loss_box_reg: 0.5548  loss_mask: 0.2952  loss_rpn_cls: 0.08007  loss_rpn_loc: 0.1629  time: 0.6556  data_time: 0.1467  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:27:01 d2.utils.events]: \u001b[0m eta: 0:25:43  iter: 6839  total_loss: 1.435  loss_cls: 0.3202  loss_box_reg: 0.552  loss_mask: 0.3037  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1875  time: 0.6561  data_time: 0.3376  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:27:13 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 6859  total_loss: 1.53  loss_cls: 0.3069  loss_box_reg: 0.6077  loss_mask: 0.3088  loss_rpn_cls: 0.0743  loss_rpn_loc: 0.1806  time: 0.6560  data_time: 0.1637  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:27:26 d2.utils.events]: \u001b[0m eta: 0:25:22  iter: 6879  total_loss: 1.318  loss_cls: 0.2896  loss_box_reg: 0.5427  loss_mask: 0.3006  loss_rpn_cls: 0.05293  loss_rpn_loc: 0.1522  time: 0.6559  data_time: 0.1807  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:27:37 d2.utils.events]: \u001b[0m eta: 0:25:14  iter: 6899  total_loss: 1.381  loss_cls: 0.3333  loss_box_reg: 0.5405  loss_mask: 0.2917  loss_rpn_cls: 0.07317  loss_rpn_loc: 0.1539  time: 0.6557  data_time: 0.1180  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:27:50 d2.utils.events]: \u001b[0m eta: 0:24:59  iter: 6919  total_loss: 1.415  loss_cls: 0.3187  loss_box_reg: 0.5275  loss_mask: 0.3042  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.1484  time: 0.6556  data_time: 0.1798  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:28:04 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 6939  total_loss: 1.425  loss_cls: 0.3208  loss_box_reg: 0.5383  loss_mask: 0.311  loss_rpn_cls: 0.0743  loss_rpn_loc: 0.1981  time: 0.6557  data_time: 0.2331  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:28:16 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 6959  total_loss: 1.32  loss_cls: 0.2872  loss_box_reg: 0.5415  loss_mask: 0.2796  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.1493  time: 0.6555  data_time: 0.1309  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:28:34 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 6979  total_loss: 1.574  loss_cls: 0.3656  loss_box_reg: 0.5851  loss_mask: 0.3185  loss_rpn_cls: 0.09783  loss_rpn_loc: 0.215  time: 0.6563  data_time: 0.3967  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:28:46 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 6999  total_loss: 1.446  loss_cls: 0.3201  loss_box_reg: 0.5629  loss_mask: 0.3082  loss_rpn_cls: 0.06909  loss_rpn_loc: 0.175  time: 0.6562  data_time: 0.1387  lr: 0.00016384  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:28:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:28:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:28:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:28:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:28:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:28:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0862 s/iter. Eval: 0.0590 s/iter. Total: 0.1458 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 20:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0861 s/iter. Eval: 0.0736 s/iter. Total: 0.1605 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0742 s/iter. Total: 0.1612 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0791 s/iter. Total: 0.1664 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 20:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.190852 (0.165438 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086239 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:29:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:29:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2700183884549027\n",
      "\u001b[32m[02/04 20:29:19 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 7019  total_loss: 1.495  loss_cls: 0.3133  loss_box_reg: 0.5811  loss_mask: 0.2919  loss_rpn_cls: 0.07952  loss_rpn_loc: 0.1672  time: 0.6560  data_time: 0.1306  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:29:32 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 7039  total_loss: 1.33  loss_cls: 0.2917  loss_box_reg: 0.5503  loss_mask: 0.3008  loss_rpn_cls: 0.04595  loss_rpn_loc: 0.1668  time: 0.6559  data_time: 0.1774  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:29:46 d2.utils.events]: \u001b[0m eta: 0:23:45  iter: 7059  total_loss: 1.35  loss_cls: 0.2822  loss_box_reg: 0.5373  loss_mask: 0.2984  loss_rpn_cls: 0.06884  loss_rpn_loc: 0.1476  time: 0.6560  data_time: 0.2358  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:30:00 d2.utils.events]: \u001b[0m eta: 0:23:39  iter: 7079  total_loss: 1.502  loss_cls: 0.3298  loss_box_reg: 0.5858  loss_mask: 0.315  loss_rpn_cls: 0.09018  loss_rpn_loc: 0.2022  time: 0.6562  data_time: 0.2184  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:30:10 d2.utils.events]: \u001b[0m eta: 0:23:27  iter: 7099  total_loss: 1.346  loss_cls: 0.3011  loss_box_reg: 0.5424  loss_mask: 0.3014  loss_rpn_cls: 0.0585  loss_rpn_loc: 0.1431  time: 0.6557  data_time: 0.0476  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:30:23 d2.utils.events]: \u001b[0m eta: 0:23:16  iter: 7119  total_loss: 1.424  loss_cls: 0.3345  loss_box_reg: 0.5659  loss_mask: 0.2928  loss_rpn_cls: 0.0794  loss_rpn_loc: 0.1615  time: 0.6557  data_time: 0.1689  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:30:38 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 7139  total_loss: 1.368  loss_cls: 0.2823  loss_box_reg: 0.5664  loss_mask: 0.311  loss_rpn_cls: 0.05875  loss_rpn_loc: 0.177  time: 0.6560  data_time: 0.3080  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:30:52 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 7159  total_loss: 1.349  loss_cls: 0.3031  loss_box_reg: 0.5353  loss_mask: 0.2903  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.1566  time: 0.6561  data_time: 0.2139  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:31:08 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 7179  total_loss: 1.439  loss_cls: 0.3386  loss_box_reg: 0.5543  loss_mask: 0.301  loss_rpn_cls: 0.08792  loss_rpn_loc: 0.1901  time: 0.6565  data_time: 0.3036  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:31:19 d2.utils.events]: \u001b[0m eta: 0:22:41  iter: 7199  total_loss: 1.435  loss_cls: 0.3065  loss_box_reg: 0.587  loss_mask: 0.2971  loss_rpn_cls: 0.05787  loss_rpn_loc: 0.1692  time: 0.6561  data_time: 0.0922  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:31:32 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 7219  total_loss: 1.362  loss_cls: 0.2827  loss_box_reg: 0.5401  loss_mask: 0.3002  loss_rpn_cls: 0.0552  loss_rpn_loc: 0.1812  time: 0.6561  data_time: 0.1956  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:31:45 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 7239  total_loss: 1.5  loss_cls: 0.3423  loss_box_reg: 0.5659  loss_mask: 0.3123  loss_rpn_cls: 0.08729  loss_rpn_loc: 0.1681  time: 0.6561  data_time: 0.1910  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:31:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:31:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:31:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:31:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:31:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:31:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:32:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0858 s/iter. Eval: 0.0618 s/iter. Total: 0.1484 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 20:32:05 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0731 s/iter. Total: 0.1598 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:32:10 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0733 s/iter. Total: 0.1597 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:32:15 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0782 s/iter. Total: 0.1651 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 20:32:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.029058 (0.164044 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:32:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085869 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:32:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:32:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2725304948925796\n",
      "\u001b[32m[02/04 20:32:18 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 7259  total_loss: 1.235  loss_cls: 0.2565  loss_box_reg: 0.5058  loss_mask: 0.2749  loss_rpn_cls: 0.045  loss_rpn_loc: 0.137  time: 0.6560  data_time: 0.1526  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:32:32 d2.utils.events]: \u001b[0m eta: 0:21:57  iter: 7279  total_loss: 1.399  loss_cls: 0.3185  loss_box_reg: 0.5496  loss_mask: 0.3038  loss_rpn_cls: 0.08239  loss_rpn_loc: 0.1727  time: 0.6561  data_time: 0.2239  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:32:44 d2.utils.events]: \u001b[0m eta: 0:21:50  iter: 7299  total_loss: 1.305  loss_cls: 0.2742  loss_box_reg: 0.5435  loss_mask: 0.2971  loss_rpn_cls: 0.05704  loss_rpn_loc: 0.1512  time: 0.6559  data_time: 0.1318  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:32:59 d2.utils.events]: \u001b[0m eta: 0:21:39  iter: 7319  total_loss: 1.463  loss_cls: 0.3221  loss_box_reg: 0.5615  loss_mask: 0.3002  loss_rpn_cls: 0.08539  loss_rpn_loc: 0.1753  time: 0.6563  data_time: 0.3086  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:33:13 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 7339  total_loss: 1.4  loss_cls: 0.3064  loss_box_reg: 0.5635  loss_mask: 0.2832  loss_rpn_cls: 0.07203  loss_rpn_loc: 0.1812  time: 0.6564  data_time: 0.2117  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:33:23 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 7359  total_loss: 1.284  loss_cls: 0.2883  loss_box_reg: 0.5136  loss_mask: 0.2905  loss_rpn_cls: 0.05793  loss_rpn_loc: 0.14  time: 0.6560  data_time: 0.0681  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:33:35 d2.utils.events]: \u001b[0m eta: 0:21:05  iter: 7379  total_loss: 1.358  loss_cls: 0.2971  loss_box_reg: 0.549  loss_mask: 0.2956  loss_rpn_cls: 0.05695  loss_rpn_loc: 0.1721  time: 0.6558  data_time: 0.1301  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:33:50 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 7399  total_loss: 1.401  loss_cls: 0.3019  loss_box_reg: 0.5393  loss_mask: 0.287  loss_rpn_cls: 0.07968  loss_rpn_loc: 0.1729  time: 0.6560  data_time: 0.2626  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:34:02 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 7419  total_loss: 1.365  loss_cls: 0.2887  loss_box_reg: 0.5554  loss_mask: 0.2972  loss_rpn_cls: 0.07479  loss_rpn_loc: 0.155  time: 0.6559  data_time: 0.1507  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:34:13 d2.utils.events]: \u001b[0m eta: 0:20:33  iter: 7439  total_loss: 1.377  loss_cls: 0.3172  loss_box_reg: 0.5231  loss_mask: 0.2943  loss_rpn_cls: 0.08405  loss_rpn_loc: 0.1575  time: 0.6556  data_time: 0.1068  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:34:26 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 7459  total_loss: 1.428  loss_cls: 0.3341  loss_box_reg: 0.5541  loss_mask: 0.3099  loss_rpn_cls: 0.08219  loss_rpn_loc: 0.1832  time: 0.6556  data_time: 0.1855  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:34:41 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 7479  total_loss: 1.43  loss_cls: 0.3173  loss_box_reg: 0.5906  loss_mask: 0.309  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.1787  time: 0.6558  data_time: 0.2559  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:34:55 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 7499  total_loss: 1.399  loss_cls: 0.3012  loss_box_reg: 0.5402  loss_mask: 0.2932  loss_rpn_cls: 0.07529  loss_rpn_loc: 0.1725  time: 0.6559  data_time: 0.2264  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:34:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:34:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:34:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:34:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:34:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:34:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0647 s/iter. Total: 0.1527 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 20:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0749 s/iter. Total: 0.1617 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0755 s/iter. Total: 0.1621 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0861 s/iter. Eval: 0.0800 s/iter. Total: 0.1670 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:35:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.245145 (0.165906 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:35:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085988 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:35:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2688329937560305\n",
      "\u001b[32m[02/04 20:35:30 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 7519  total_loss: 1.47  loss_cls: 0.3125  loss_box_reg: 0.5531  loss_mask: 0.314  loss_rpn_cls: 0.09504  loss_rpn_loc: 0.1859  time: 0.6561  data_time: 0.2495  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:35:43 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 7539  total_loss: 1.325  loss_cls: 0.3239  loss_box_reg: 0.5355  loss_mask: 0.3029  loss_rpn_cls: 0.06529  loss_rpn_loc: 0.146  time: 0.6561  data_time: 0.1876  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:35:59 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 7559  total_loss: 1.402  loss_cls: 0.3077  loss_box_reg: 0.572  loss_mask: 0.3026  loss_rpn_cls: 0.07444  loss_rpn_loc: 0.1719  time: 0.6564  data_time: 0.3050  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:36:11 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 7579  total_loss: 1.33  loss_cls: 0.3011  loss_box_reg: 0.5493  loss_mask: 0.2985  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.1409  time: 0.6563  data_time: 0.1477  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:36:24 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 7599  total_loss: 1.443  loss_cls: 0.3179  loss_box_reg: 0.5776  loss_mask: 0.3205  loss_rpn_cls: 0.08603  loss_rpn_loc: 0.1764  time: 0.6562  data_time: 0.1693  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:36:33 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 7619  total_loss: 1.336  loss_cls: 0.3013  loss_box_reg: 0.555  loss_mask: 0.2859  loss_rpn_cls: 0.06201  loss_rpn_loc: 0.1609  time: 0.6558  data_time: 0.0266  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:36:45 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 7639  total_loss: 1.372  loss_cls: 0.3235  loss_box_reg: 0.532  loss_mask: 0.2968  loss_rpn_cls: 0.07087  loss_rpn_loc: 0.1493  time: 0.6556  data_time: 0.1195  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:36:58 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 7659  total_loss: 1.336  loss_cls: 0.3115  loss_box_reg: 0.5555  loss_mask: 0.2974  loss_rpn_cls: 0.06826  loss_rpn_loc: 0.1681  time: 0.6556  data_time: 0.1932  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:37:12 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 7679  total_loss: 1.518  loss_cls: 0.3305  loss_box_reg: 0.5902  loss_mask: 0.3087  loss_rpn_cls: 0.07858  loss_rpn_loc: 0.1805  time: 0.6557  data_time: 0.2343  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:37:27 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 7699  total_loss: 1.443  loss_cls: 0.319  loss_box_reg: 0.5513  loss_mask: 0.2977  loss_rpn_cls: 0.08668  loss_rpn_loc: 0.1653  time: 0.6559  data_time: 0.2658  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:37:42 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 7719  total_loss: 1.44  loss_cls: 0.326  loss_box_reg: 0.5541  loss_mask: 0.3071  loss_rpn_cls: 0.0874  loss_rpn_loc: 0.1684  time: 0.6562  data_time: 0.2886  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:37:54 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 7739  total_loss: 1.293  loss_cls: 0.2779  loss_box_reg: 0.5047  loss_mask: 0.2759  loss_rpn_cls: 0.05157  loss_rpn_loc: 0.1419  time: 0.6561  data_time: 0.1639  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:37:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:37:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:37:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:37:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:37:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:37:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0868 s/iter. Eval: 0.0634 s/iter. Total: 0.1509 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 20:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0010 s/iter. Inference: 0.0865 s/iter. Eval: 0.0750 s/iter. Total: 0.1626 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0009 s/iter. Inference: 0.0860 s/iter. Eval: 0.0746 s/iter. Total: 0.1616 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0009 s/iter. Inference: 0.0862 s/iter. Eval: 0.0793 s/iter. Total: 0.1664 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 20:38:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.178228 (0.165330 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:38:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085962 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:38:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:38:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27055448124304815\n",
      "\u001b[32m[02/04 20:38:28 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 7759  total_loss: 1.343  loss_cls: 0.2997  loss_box_reg: 0.53  loss_mask: 0.2938  loss_rpn_cls: 0.05544  loss_rpn_loc: 0.1537  time: 0.6559  data_time: 0.1501  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:38:42 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 7779  total_loss: 1.399  loss_cls: 0.3045  loss_box_reg: 0.5302  loss_mask: 0.2958  loss_rpn_cls: 0.06723  loss_rpn_loc: 0.1516  time: 0.6562  data_time: 0.2743  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:38:55 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 7799  total_loss: 1.431  loss_cls: 0.3233  loss_box_reg: 0.5645  loss_mask: 0.3043  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.163  time: 0.6561  data_time: 0.1525  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:39:08 d2.utils.events]: \u001b[0m eta: 0:17:32  iter: 7819  total_loss: 1.436  loss_cls: 0.3274  loss_box_reg: 0.5828  loss_mask: 0.296  loss_rpn_cls: 0.06457  loss_rpn_loc: 0.1921  time: 0.6561  data_time: 0.2148  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:39:19 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 7839  total_loss: 1.389  loss_cls: 0.2635  loss_box_reg: 0.5567  loss_mask: 0.2996  loss_rpn_cls: 0.04839  loss_rpn_loc: 0.1448  time: 0.6558  data_time: 0.0586  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:39:29 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 7859  total_loss: 1.43  loss_cls: 0.3194  loss_box_reg: 0.5604  loss_mask: 0.298  loss_rpn_cls: 0.06307  loss_rpn_loc: 0.1876  time: 0.6554  data_time: 0.0920  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:39:43 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 7879  total_loss: 1.4  loss_cls: 0.291  loss_box_reg: 0.5442  loss_mask: 0.3022  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.1632  time: 0.6555  data_time: 0.2296  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:39:57 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 7899  total_loss: 1.406  loss_cls: 0.3131  loss_box_reg: 0.5251  loss_mask: 0.2942  loss_rpn_cls: 0.07935  loss_rpn_loc: 0.1921  time: 0.6557  data_time: 0.2397  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:40:09 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 7919  total_loss: 1.379  loss_cls: 0.297  loss_box_reg: 0.5234  loss_mask: 0.2954  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.1714  time: 0.6555  data_time: 0.1651  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:40:21 d2.utils.events]: \u001b[0m eta: 0:16:33  iter: 7939  total_loss: 1.52  loss_cls: 0.3611  loss_box_reg: 0.5856  loss_mask: 0.2919  loss_rpn_cls: 0.09441  loss_rpn_loc: 0.1895  time: 0.6553  data_time: 0.0992  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:40:35 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 7959  total_loss: 1.361  loss_cls: 0.2955  loss_box_reg: 0.5327  loss_mask: 0.3004  loss_rpn_cls: 0.05726  loss_rpn_loc: 0.1612  time: 0.6555  data_time: 0.2469  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:40:47 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 7979  total_loss: 1.382  loss_cls: 0.3117  loss_box_reg: 0.5632  loss_mask: 0.2841  loss_rpn_cls: 0.07606  loss_rpn_loc: 0.1502  time: 0.6553  data_time: 0.1433  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:40:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:40:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:40:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:40:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:40:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:40:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0865 s/iter. Eval: 0.0679 s/iter. Total: 0.1551 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 20:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0751 s/iter. Total: 0.1621 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0746 s/iter. Total: 0.1611 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:41:09 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0792 s/iter. Total: 0.1660 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 20:41:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.124032 (0.164862 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:41:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085783 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:41:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:41:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27374968976669156\n",
      "\u001b[32m[02/04 20:41:23 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 7999  total_loss: 1.291  loss_cls: 0.2827  loss_box_reg: 0.5273  loss_mask: 0.2946  loss_rpn_cls: 0.05802  loss_rpn_loc: 0.1679  time: 0.6556  data_time: 0.2912  lr: 0.00013107  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:41:38 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 8019  total_loss: 1.378  loss_cls: 0.303  loss_box_reg: 0.5443  loss_mask: 0.2998  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.1589  time: 0.6558  data_time: 0.2784  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:41:51 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 8039  total_loss: 1.374  loss_cls: 0.2947  loss_box_reg: 0.5569  loss_mask: 0.2948  loss_rpn_cls: 0.05543  loss_rpn_loc: 0.1642  time: 0.6557  data_time: 0.1536  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:42:06 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 8059  total_loss: 1.45  loss_cls: 0.3268  loss_box_reg: 0.5546  loss_mask: 0.2928  loss_rpn_cls: 0.07025  loss_rpn_loc: 0.1754  time: 0.6560  data_time: 0.2781  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:42:20 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 8079  total_loss: 1.424  loss_cls: 0.3209  loss_box_reg: 0.5868  loss_mask: 0.3063  loss_rpn_cls: 0.08091  loss_rpn_loc: 0.1567  time: 0.6561  data_time: 0.2164  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:42:35 d2.utils.events]: \u001b[0m eta: 0:15:16  iter: 8099  total_loss: 1.356  loss_cls: 0.3246  loss_box_reg: 0.5366  loss_mask: 0.2941  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.1647  time: 0.6563  data_time: 0.2800  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:42:49 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 8119  total_loss: 1.466  loss_cls: 0.3234  loss_box_reg: 0.5598  loss_mask: 0.3055  loss_rpn_cls: 0.08913  loss_rpn_loc: 0.1909  time: 0.6564  data_time: 0.2481  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:43:03 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 8139  total_loss: 1.384  loss_cls: 0.3097  loss_box_reg: 0.5496  loss_mask: 0.2946  loss_rpn_cls: 0.07156  loss_rpn_loc: 0.1623  time: 0.6566  data_time: 0.2405  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:43:14 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 8159  total_loss: 1.343  loss_cls: 0.2969  loss_box_reg: 0.5244  loss_mask: 0.2904  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.1543  time: 0.6563  data_time: 0.1269  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:43:28 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 8179  total_loss: 1.374  loss_cls: 0.3086  loss_box_reg: 0.5376  loss_mask: 0.3132  loss_rpn_cls: 0.08058  loss_rpn_loc: 0.1545  time: 0.6564  data_time: 0.2144  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:43:40 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 8199  total_loss: 1.289  loss_cls: 0.3068  loss_box_reg: 0.5252  loss_mask: 0.287  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.1446  time: 0.6563  data_time: 0.1499  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:43:52 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 8219  total_loss: 1.414  loss_cls: 0.317  loss_box_reg: 0.5522  loss_mask: 0.2959  loss_rpn_cls: 0.08308  loss_rpn_loc: 0.1573  time: 0.6561  data_time: 0.1372  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:43:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:43:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:43:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:43:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:43:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:43:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0863 s/iter. Eval: 0.0708 s/iter. Total: 0.1579 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 20:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0756 s/iter. Total: 0.1625 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/04 20:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0757 s/iter. Total: 0.1622 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0795 s/iter. Total: 0.1661 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/04 20:44:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.205858 (0.165568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:44:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085710 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:44:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:44:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2744283274807822\n",
      "\u001b[32m[02/04 20:44:25 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 8239  total_loss: 1.402  loss_cls: 0.3109  loss_box_reg: 0.5536  loss_mask: 0.3021  loss_rpn_cls: 0.06065  loss_rpn_loc: 0.1788  time: 0.6559  data_time: 0.1195  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:44:36 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 8259  total_loss: 1.375  loss_cls: 0.3114  loss_box_reg: 0.5524  loss_mask: 0.2917  loss_rpn_cls: 0.07691  loss_rpn_loc: 0.1744  time: 0.6557  data_time: 0.0980  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:44:47 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 8279  total_loss: 1.442  loss_cls: 0.3004  loss_box_reg: 0.5597  loss_mask: 0.3051  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.1654  time: 0.6555  data_time: 0.1140  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:45:01 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 8299  total_loss: 1.461  loss_cls: 0.3185  loss_box_reg: 0.582  loss_mask: 0.3183  loss_rpn_cls: 0.08291  loss_rpn_loc: 0.1846  time: 0.6555  data_time: 0.1860  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:45:13 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 8319  total_loss: 1.436  loss_cls: 0.3041  loss_box_reg: 0.5576  loss_mask: 0.2931  loss_rpn_cls: 0.07339  loss_rpn_loc: 0.1794  time: 0.6555  data_time: 0.1771  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:45:26 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 8339  total_loss: 1.344  loss_cls: 0.3068  loss_box_reg: 0.5313  loss_mask: 0.2827  loss_rpn_cls: 0.06466  loss_rpn_loc: 0.1756  time: 0.6555  data_time: 0.2065  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:45:39 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 8359  total_loss: 1.453  loss_cls: 0.3308  loss_box_reg: 0.5564  loss_mask: 0.301  loss_rpn_cls: 0.09609  loss_rpn_loc: 0.1748  time: 0.6554  data_time: 0.1762  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:45:53 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 8379  total_loss: 1.399  loss_cls: 0.3158  loss_box_reg: 0.5471  loss_mask: 0.3027  loss_rpn_cls: 0.07025  loss_rpn_loc: 0.1674  time: 0.6555  data_time: 0.2517  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:46:06 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 8399  total_loss: 1.299  loss_cls: 0.2851  loss_box_reg: 0.5352  loss_mask: 0.2923  loss_rpn_cls: 0.05256  loss_rpn_loc: 0.1532  time: 0.6555  data_time: 0.1757  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:46:22 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 8419  total_loss: 1.366  loss_cls: 0.3174  loss_box_reg: 0.5352  loss_mask: 0.2982  loss_rpn_cls: 0.07269  loss_rpn_loc: 0.1622  time: 0.6558  data_time: 0.3065  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:46:35 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 8439  total_loss: 1.29  loss_cls: 0.2762  loss_box_reg: 0.5115  loss_mask: 0.2896  loss_rpn_cls: 0.05932  loss_rpn_loc: 0.152  time: 0.6558  data_time: 0.1922  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:46:49 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 8459  total_loss: 1.384  loss_cls: 0.3155  loss_box_reg: 0.5313  loss_mask: 0.3128  loss_rpn_cls: 0.06859  loss_rpn_loc: 0.1588  time: 0.6560  data_time: 0.2540  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:46:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:46:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:46:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:46:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:46:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:46:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0903 s/iter. Eval: 0.0718 s/iter. Total: 0.1628 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 20:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0783 s/iter. Total: 0.1660 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0861 s/iter. Eval: 0.0762 s/iter. Total: 0.1631 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0809 s/iter. Total: 0.1680 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:47:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.409207 (0.167321 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:47:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.086060 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:47:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:47:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2626182914451382\n",
      "\u001b[32m[02/04 20:47:27 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 8479  total_loss: 1.402  loss_cls: 0.3115  loss_box_reg: 0.536  loss_mask: 0.2845  loss_rpn_cls: 0.07268  loss_rpn_loc: 0.1626  time: 0.6564  data_time: 0.3381  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:47:40 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 8499  total_loss: 1.538  loss_cls: 0.355  loss_box_reg: 0.5896  loss_mask: 0.313  loss_rpn_cls: 0.09207  loss_rpn_loc: 0.1837  time: 0.6564  data_time: 0.1886  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:47:57 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 8519  total_loss: 1.369  loss_cls: 0.3085  loss_box_reg: 0.541  loss_mask: 0.3158  loss_rpn_cls: 0.06201  loss_rpn_loc: 0.1795  time: 0.6568  data_time: 0.3371  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:48:10 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 8539  total_loss: 1.401  loss_cls: 0.3121  loss_box_reg: 0.5579  loss_mask: 0.3156  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.1612  time: 0.6567  data_time: 0.1822  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:48:20 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 8559  total_loss: 1.345  loss_cls: 0.267  loss_box_reg: 0.5638  loss_mask: 0.3032  loss_rpn_cls: 0.06217  loss_rpn_loc: 0.1637  time: 0.6564  data_time: 0.0813  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:48:33 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 8579  total_loss: 1.302  loss_cls: 0.2787  loss_box_reg: 0.5208  loss_mask: 0.298  loss_rpn_cls: 0.06478  loss_rpn_loc: 0.157  time: 0.6564  data_time: 0.1900  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:48:47 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 8599  total_loss: 1.39  loss_cls: 0.3082  loss_box_reg: 0.5519  loss_mask: 0.2964  loss_rpn_cls: 0.0722  loss_rpn_loc: 0.1635  time: 0.6565  data_time: 0.2456  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:49:01 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 8619  total_loss: 1.32  loss_cls: 0.299  loss_box_reg: 0.5437  loss_mask: 0.3065  loss_rpn_cls: 0.06702  loss_rpn_loc: 0.1463  time: 0.6566  data_time: 0.2543  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:49:14 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 8639  total_loss: 1.365  loss_cls: 0.3189  loss_box_reg: 0.5479  loss_mask: 0.2919  loss_rpn_cls: 0.07554  loss_rpn_loc: 0.1507  time: 0.6566  data_time: 0.1794  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:49:26 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 8659  total_loss: 1.262  loss_cls: 0.2972  loss_box_reg: 0.5132  loss_mask: 0.2727  loss_rpn_cls: 0.05333  loss_rpn_loc: 0.152  time: 0.6565  data_time: 0.1400  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:49:38 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 8679  total_loss: 1.286  loss_cls: 0.2755  loss_box_reg: 0.5284  loss_mask: 0.2774  loss_rpn_cls: 0.05326  loss_rpn_loc: 0.1385  time: 0.6563  data_time: 0.1428  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:49:52 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 8699  total_loss: 1.461  loss_cls: 0.3137  loss_box_reg: 0.5584  loss_mask: 0.3054  loss_rpn_cls: 0.07916  loss_rpn_loc: 0.1769  time: 0.6564  data_time: 0.2151  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:50:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:50:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:50:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:50:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:50:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:50:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:50:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0716 s/iter. Total: 0.1590 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 20:50:10 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0800 s/iter. Total: 0.1672 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:50:15 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0767 s/iter. Total: 0.1632 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:50:20 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0815 s/iter. Total: 0.1682 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:50:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.448689 (0.167661 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:50:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085853 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:50:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:50:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27339108877056073\n",
      "\u001b[32m[02/04 20:50:27 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 8719  total_loss: 1.358  loss_cls: 0.2992  loss_box_reg: 0.5207  loss_mask: 0.2875  loss_rpn_cls: 0.06909  loss_rpn_loc: 0.1635  time: 0.6565  data_time: 0.2171  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:50:41 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 8739  total_loss: 1.374  loss_cls: 0.3294  loss_box_reg: 0.5476  loss_mask: 0.3043  loss_rpn_cls: 0.0725  loss_rpn_loc: 0.1791  time: 0.6565  data_time: 0.2224  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:50:56 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 8759  total_loss: 1.389  loss_cls: 0.3073  loss_box_reg: 0.5356  loss_mask: 0.3052  loss_rpn_cls: 0.06446  loss_rpn_loc: 0.1507  time: 0.6568  data_time: 0.3188  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:51:12 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 8779  total_loss: 1.352  loss_cls: 0.2895  loss_box_reg: 0.5314  loss_mask: 0.2949  loss_rpn_cls: 0.05983  loss_rpn_loc: 0.1574  time: 0.6571  data_time: 0.3154  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:51:26 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 8799  total_loss: 1.53  loss_cls: 0.3791  loss_box_reg: 0.5929  loss_mask: 0.3125  loss_rpn_cls: 0.08809  loss_rpn_loc: 0.187  time: 0.6572  data_time: 0.2069  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:51:40 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 8819  total_loss: 1.361  loss_cls: 0.3245  loss_box_reg: 0.5257  loss_mask: 0.2924  loss_rpn_cls: 0.0758  loss_rpn_loc: 0.1562  time: 0.6574  data_time: 0.2751  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:51:53 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 8839  total_loss: 1.442  loss_cls: 0.3072  loss_box_reg: 0.5719  loss_mask: 0.3063  loss_rpn_cls: 0.07705  loss_rpn_loc: 0.1801  time: 0.6573  data_time: 0.1625  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:52:06 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 8859  total_loss: 1.362  loss_cls: 0.2914  loss_box_reg: 0.5376  loss_mask: 0.2946  loss_rpn_cls: 0.06576  loss_rpn_loc: 0.1742  time: 0.6573  data_time: 0.1965  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:52:18 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 8879  total_loss: 1.235  loss_cls: 0.2484  loss_box_reg: 0.5252  loss_mask: 0.2891  loss_rpn_cls: 0.04928  loss_rpn_loc: 0.1353  time: 0.6571  data_time: 0.1286  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:52:30 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 8899  total_loss: 1.366  loss_cls: 0.3035  loss_box_reg: 0.5466  loss_mask: 0.2829  loss_rpn_cls: 0.06045  loss_rpn_loc: 0.1572  time: 0.6570  data_time: 0.1475  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:52:40 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 8919  total_loss: 1.317  loss_cls: 0.2781  loss_box_reg: 0.5323  loss_mask: 0.2943  loss_rpn_cls: 0.05527  loss_rpn_loc: 0.1473  time: 0.6567  data_time: 0.0584  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:52:53 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 8939  total_loss: 1.45  loss_cls: 0.3314  loss_box_reg: 0.5523  loss_mask: 0.2929  loss_rpn_cls: 0.09375  loss_rpn_loc: 0.1726  time: 0.6566  data_time: 0.1665  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:53:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:53:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:53:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:53:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:53:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:53:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:53:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0740 s/iter. Total: 0.1644 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/04 20:53:09 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0816 s/iter. Total: 0.1692 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0780 s/iter. Total: 0.1648 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0825 s/iter. Total: 0.1696 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:53:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.588890 (0.168870 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:53:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.086187 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:53:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:53:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27080700614611086\n",
      "\u001b[32m[02/04 20:53:27 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 8959  total_loss: 1.461  loss_cls: 0.3241  loss_box_reg: 0.5555  loss_mask: 0.3109  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.1876  time: 0.6566  data_time: 0.1685  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:53:43 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 8979  total_loss: 1.415  loss_cls: 0.3085  loss_box_reg: 0.5644  loss_mask: 0.3088  loss_rpn_cls: 0.0743  loss_rpn_loc: 0.156  time: 0.6569  data_time: 0.3190  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:53:54 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 8999  total_loss: 1.38  loss_cls: 0.2966  loss_box_reg: 0.5438  loss_mask: 0.2817  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1566  time: 0.6566  data_time: 0.0972  lr: 0.00010486  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:54:13 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 9019  total_loss: 1.549  loss_cls: 0.3638  loss_box_reg: 0.5704  loss_mask: 0.3165  loss_rpn_cls: 0.08799  loss_rpn_loc: 0.1665  time: 0.6573  data_time: 0.4480  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:54:22 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 9039  total_loss: 1.371  loss_cls: 0.3131  loss_box_reg: 0.5313  loss_mask: 0.298  loss_rpn_cls: 0.07122  loss_rpn_loc: 0.1484  time: 0.6569  data_time: 0.0428  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:54:35 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 9059  total_loss: 1.348  loss_cls: 0.3044  loss_box_reg: 0.5235  loss_mask: 0.2927  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.1489  time: 0.6569  data_time: 0.1647  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:54:52 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 9079  total_loss: 1.436  loss_cls: 0.3144  loss_box_reg: 0.5426  loss_mask: 0.2936  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1694  time: 0.6572  data_time: 0.3469  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:55:03 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 9099  total_loss: 1.371  loss_cls: 0.3179  loss_box_reg: 0.5471  loss_mask: 0.2982  loss_rpn_cls: 0.06332  loss_rpn_loc: 0.1576  time: 0.6570  data_time: 0.1339  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:55:15 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 9119  total_loss: 1.383  loss_cls: 0.2992  loss_box_reg: 0.5558  loss_mask: 0.3058  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.1711  time: 0.6569  data_time: 0.1088  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:55:26 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 9139  total_loss: 1.304  loss_cls: 0.3001  loss_box_reg: 0.5069  loss_mask: 0.2644  loss_rpn_cls: 0.05789  loss_rpn_loc: 0.1551  time: 0.6567  data_time: 0.1284  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:55:41 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 9159  total_loss: 1.46  loss_cls: 0.3373  loss_box_reg: 0.5583  loss_mask: 0.3032  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.173  time: 0.6568  data_time: 0.2505  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:55:58 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 9179  total_loss: 1.547  loss_cls: 0.3443  loss_box_reg: 0.562  loss_mask: 0.3333  loss_rpn_cls: 0.08731  loss_rpn_loc: 0.1993  time: 0.6573  data_time: 0.3704  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:56:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:56:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:56:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:56:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:56:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:56:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0722 s/iter. Total: 0.1625 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 20:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0788 s/iter. Total: 0.1666 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0011 s/iter. Inference: 0.0859 s/iter. Eval: 0.0760 s/iter. Total: 0.1630 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 20:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0010 s/iter. Inference: 0.0860 s/iter. Eval: 0.0806 s/iter. Total: 0.1677 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:56:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.430784 (0.167507 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:56:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085955 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:56:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:56:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27280193033473793\n",
      "\u001b[32m[02/04 20:56:31 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 9199  total_loss: 1.368  loss_cls: 0.3246  loss_box_reg: 0.561  loss_mask: 0.2881  loss_rpn_cls: 0.05439  loss_rpn_loc: 0.1472  time: 0.6571  data_time: 0.1236  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:56:43 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 9219  total_loss: 1.316  loss_cls: 0.2856  loss_box_reg: 0.5361  loss_mask: 0.2966  loss_rpn_cls: 0.04899  loss_rpn_loc: 0.1567  time: 0.6570  data_time: 0.1670  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:56:58 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 9239  total_loss: 1.416  loss_cls: 0.3023  loss_box_reg: 0.5274  loss_mask: 0.2887  loss_rpn_cls: 0.0552  loss_rpn_loc: 0.1565  time: 0.6572  data_time: 0.2634  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:57:09 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 9259  total_loss: 1.32  loss_cls: 0.2605  loss_box_reg: 0.5181  loss_mask: 0.2984  loss_rpn_cls: 0.04633  loss_rpn_loc: 0.167  time: 0.6570  data_time: 0.0912  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:57:21 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 9279  total_loss: 1.4  loss_cls: 0.3149  loss_box_reg: 0.5441  loss_mask: 0.2895  loss_rpn_cls: 0.06773  loss_rpn_loc: 0.1675  time: 0.6569  data_time: 0.1326  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:57:33 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 9299  total_loss: 1.449  loss_cls: 0.3277  loss_box_reg: 0.5647  loss_mask: 0.3172  loss_rpn_cls: 0.08724  loss_rpn_loc: 0.1649  time: 0.6567  data_time: 0.1278  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:57:46 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 9319  total_loss: 1.385  loss_cls: 0.3094  loss_box_reg: 0.5277  loss_mask: 0.2898  loss_rpn_cls: 0.08625  loss_rpn_loc: 0.1735  time: 0.6567  data_time: 0.1963  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:57:57 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 9339  total_loss: 1.317  loss_cls: 0.2902  loss_box_reg: 0.5398  loss_mask: 0.2893  loss_rpn_cls: 0.04486  loss_rpn_loc: 0.159  time: 0.6565  data_time: 0.1069  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:58:11 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 9359  total_loss: 1.379  loss_cls: 0.302  loss_box_reg: 0.5296  loss_mask: 0.2922  loss_rpn_cls: 0.05527  loss_rpn_loc: 0.1647  time: 0.6566  data_time: 0.1946  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:58:25 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 9379  total_loss: 1.42  loss_cls: 0.326  loss_box_reg: 0.544  loss_mask: 0.2905  loss_rpn_cls: 0.08616  loss_rpn_loc: 0.1494  time: 0.6567  data_time: 0.2295  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:58:37 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 9399  total_loss: 1.415  loss_cls: 0.3178  loss_box_reg: 0.5488  loss_mask: 0.3041  loss_rpn_cls: 0.08468  loss_rpn_loc: 0.1588  time: 0.6565  data_time: 0.1158  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:58:52 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 9419  total_loss: 1.398  loss_cls: 0.3095  loss_box_reg: 0.5273  loss_mask: 0.2932  loss_rpn_cls: 0.06933  loss_rpn_loc: 0.1625  time: 0.6567  data_time: 0.2747  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:59:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:59:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 20:59:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 20:59:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 20:59:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 20:59:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 20:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0924 s/iter. Eval: 0.0754 s/iter. Total: 0.1686 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/04 20:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0010 s/iter. Inference: 0.0893 s/iter. Eval: 0.0823 s/iter. Total: 0.1727 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 20:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0009 s/iter. Inference: 0.0879 s/iter. Eval: 0.0793 s/iter. Total: 0.1681 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 20:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0009 s/iter. Inference: 0.0881 s/iter. Eval: 0.0844 s/iter. Total: 0.1735 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 20:59:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.826996 (0.170922 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:59:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087740 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 20:59:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 20:59:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26999626737397325\n",
      "\u001b[32m[02/04 20:59:27 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 9439  total_loss: 1.346  loss_cls: 0.2907  loss_box_reg: 0.5201  loss_mask: 0.2883  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.1398  time: 0.6567  data_time: 0.1689  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:59:39 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 9459  total_loss: 1.41  loss_cls: 0.2885  loss_box_reg: 0.5611  loss_mask: 0.2942  loss_rpn_cls: 0.07208  loss_rpn_loc: 0.1712  time: 0.6566  data_time: 0.1469  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 20:59:52 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 9479  total_loss: 1.356  loss_cls: 0.3083  loss_box_reg: 0.5413  loss_mask: 0.3023  loss_rpn_cls: 0.06224  loss_rpn_loc: 0.1748  time: 0.6566  data_time: 0.1948  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:00:06 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 9499  total_loss: 1.421  loss_cls: 0.3102  loss_box_reg: 0.5654  loss_mask: 0.3021  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.1863  time: 0.6567  data_time: 0.1984  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:00:18 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 9519  total_loss: 1.338  loss_cls: 0.3013  loss_box_reg: 0.5259  loss_mask: 0.2905  loss_rpn_cls: 0.07343  loss_rpn_loc: 0.1517  time: 0.6566  data_time: 0.1482  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:00:32 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 9539  total_loss: 1.384  loss_cls: 0.2962  loss_box_reg: 0.5328  loss_mask: 0.2868  loss_rpn_cls: 0.09113  loss_rpn_loc: 0.1773  time: 0.6567  data_time: 0.2344  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:00:45 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 9559  total_loss: 1.175  loss_cls: 0.2752  loss_box_reg: 0.4828  loss_mask: 0.2699  loss_rpn_cls: 0.05021  loss_rpn_loc: 0.1286  time: 0.6567  data_time: 0.1668  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:01:00 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 9579  total_loss: 1.542  loss_cls: 0.3189  loss_box_reg: 0.5809  loss_mask: 0.3114  loss_rpn_cls: 0.08496  loss_rpn_loc: 0.1981  time: 0.6568  data_time: 0.2329  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:01:13 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9599  total_loss: 1.411  loss_cls: 0.3189  loss_box_reg: 0.5766  loss_mask: 0.3119  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.1693  time: 0.6568  data_time: 0.1679  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:01:27 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 9619  total_loss: 1.422  loss_cls: 0.2951  loss_box_reg: 0.5276  loss_mask: 0.2945  loss_rpn_cls: 0.06113  loss_rpn_loc: 0.1805  time: 0.6569  data_time: 0.2225  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:01:40 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 9639  total_loss: 1.399  loss_cls: 0.3291  loss_box_reg: 0.5463  loss_mask: 0.2997  loss_rpn_cls: 0.06927  loss_rpn_loc: 0.1598  time: 0.6569  data_time: 0.1864  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:01:52 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 9659  total_loss: 1.371  loss_cls: 0.2946  loss_box_reg: 0.5374  loss_mask: 0.2934  loss_rpn_cls: 0.07023  loss_rpn_loc: 0.1727  time: 0.6569  data_time: 0.1621  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:02:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 21:02:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 21:02:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 21:02:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 21:02:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 21:02:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 21:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0725 s/iter. Total: 0.1645 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/04 21:02:13 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0806 s/iter. Total: 0.1711 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 21:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0764 s/iter. Total: 0.1646 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 21:02:23 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0805 s/iter. Total: 0.1684 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 21:02:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.427695 (0.167480 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 21:02:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086768 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 21:02:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 21:02:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27591636520876156\n",
      "\u001b[32m[02/04 21:02:26 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9679  total_loss: 1.324  loss_cls: 0.3043  loss_box_reg: 0.5262  loss_mask: 0.2914  loss_rpn_cls: 0.07619  loss_rpn_loc: 0.1496  time: 0.6568  data_time: 0.1567  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:02:41 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 9699  total_loss: 1.451  loss_cls: 0.3145  loss_box_reg: 0.5584  loss_mask: 0.2944  loss_rpn_cls: 0.07129  loss_rpn_loc: 0.1681  time: 0.6569  data_time: 0.2367  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:02:53 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 9719  total_loss: 1.372  loss_cls: 0.3097  loss_box_reg: 0.5182  loss_mask: 0.2869  loss_rpn_cls: 0.07735  loss_rpn_loc: 0.1556  time: 0.6569  data_time: 0.1703  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:03:06 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 9739  total_loss: 1.407  loss_cls: 0.3319  loss_box_reg: 0.5544  loss_mask: 0.2962  loss_rpn_cls: 0.08521  loss_rpn_loc: 0.171  time: 0.6568  data_time: 0.1392  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:03:17 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9759  total_loss: 1.319  loss_cls: 0.2769  loss_box_reg: 0.544  loss_mask: 0.3038  loss_rpn_cls: 0.05416  loss_rpn_loc: 0.145  time: 0.6566  data_time: 0.0931  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:03:30 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 9779  total_loss: 1.407  loss_cls: 0.3055  loss_box_reg: 0.5574  loss_mask: 0.296  loss_rpn_cls: 0.06125  loss_rpn_loc: 0.1643  time: 0.6566  data_time: 0.2214  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:03:45 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 9799  total_loss: 1.507  loss_cls: 0.3409  loss_box_reg: 0.5422  loss_mask: 0.3168  loss_rpn_cls: 0.06173  loss_rpn_loc: 0.1539  time: 0.6568  data_time: 0.2820  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:03:56 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 9819  total_loss: 1.287  loss_cls: 0.2772  loss_box_reg: 0.543  loss_mask: 0.2874  loss_rpn_cls: 0.05247  loss_rpn_loc: 0.1729  time: 0.6566  data_time: 0.0886  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:04:10 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 9839  total_loss: 1.43  loss_cls: 0.3101  loss_box_reg: 0.5551  loss_mask: 0.3274  loss_rpn_cls: 0.07375  loss_rpn_loc: 0.159  time: 0.6566  data_time: 0.2071  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:04:27 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 9859  total_loss: 1.512  loss_cls: 0.3446  loss_box_reg: 0.5635  loss_mask: 0.3037  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2  time: 0.6570  data_time: 0.3441  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:04:37 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 9879  total_loss: 1.384  loss_cls: 0.3071  loss_box_reg: 0.5626  loss_mask: 0.2977  loss_rpn_cls: 0.0661  loss_rpn_loc: 0.1716  time: 0.6568  data_time: 0.0658  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:04:51 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 9899  total_loss: 1.3  loss_cls: 0.287  loss_box_reg: 0.5149  loss_mask: 0.2876  loss_rpn_cls: 0.05936  loss_rpn_loc: 0.1531  time: 0.6568  data_time: 0.1773  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:05:03 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9919  total_loss: 1.383  loss_cls: 0.3005  loss_box_reg: 0.5476  loss_mask: 0.2932  loss_rpn_cls: 0.07017  loss_rpn_loc: 0.1739  time: 0.6567  data_time: 0.1400  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:05:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 21:05:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 21:05:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 21:05:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 21:05:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 21:05:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 21:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.0925 s/iter. Eval: 0.0713 s/iter. Total: 0.1648 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/04 21:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0009 s/iter. Inference: 0.0904 s/iter. Eval: 0.0822 s/iter. Total: 0.1736 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 21:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0009 s/iter. Inference: 0.0895 s/iter. Eval: 0.0799 s/iter. Total: 0.1703 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 21:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0848 s/iter. Total: 0.1761 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 21:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.094382 (0.173227 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 21:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089834 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 21:05:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 21:05:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27236546829825303\n",
      "\u001b[32m[02/04 21:05:39 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 9939  total_loss: 1.348  loss_cls: 0.2795  loss_box_reg: 0.5453  loss_mask: 0.2934  loss_rpn_cls: 0.07175  loss_rpn_loc: 0.1729  time: 0.6567  data_time: 0.2175  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:05:55 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9959  total_loss: 1.441  loss_cls: 0.3085  loss_box_reg: 0.5406  loss_mask: 0.3085  loss_rpn_cls: 0.08282  loss_rpn_loc: 0.1891  time: 0.6570  data_time: 0.2995  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:06:08 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 9979  total_loss: 1.327  loss_cls: 0.2964  loss_box_reg: 0.507  loss_mask: 0.2808  loss_rpn_cls: 0.07682  loss_rpn_loc: 0.1619  time: 0.6570  data_time: 0.1799  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:06:23 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.43  loss_cls: 0.3258  loss_box_reg: 0.5561  loss_mask: 0.2895  loss_rpn_cls: 0.07735  loss_rpn_loc: 0.1686  time: 0.6572  data_time: 0.3112  lr: 8.3886e-05  max_mem: 7240M\n",
      "\u001b[32m[02/04 21:06:23 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:49:31 (0.6572 s / it)\n",
      "\u001b[32m[02/04 21:06:23 d2.engine.hooks]: \u001b[0mTotal training time: 2:03:50 (0:14:19 on hooks)\n",
      "\u001b[32m[02/04 21:06:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 21:06:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 21:06:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 21:06:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 21:06:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 21:06:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 21:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0725 s/iter. Total: 0.1646 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/04 21:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0009 s/iter. Inference: 0.0903 s/iter. Eval: 0.0862 s/iter. Total: 0.1774 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 21:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0811 s/iter. Total: 0.1700 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 21:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0856 s/iter. Total: 0.1745 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 21:06:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.893219 (0.171493 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 21:06:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087762 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 21:06:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 21:06:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27545081364782537\n"
     ]
    }
   ],
   "source": [
    "# Increasing the RPN batch size per image and decreasing the ROI heads minimum score threshold\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80bbb17c-0698-4a1d-803b-3c8e6ffb3878",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 21:55:08 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 21:55:09 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 21:55:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/04 21:55:11 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/04 21:55:11 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/04 21:55:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/04 21:55:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/04 21:55:11 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 21:55:11 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (15, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (60, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 21:55:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/04 21:55:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:55:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:55:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:55:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:55:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:55:44 d2.utils.events]: \u001b[0m eta: 1:27:25  iter: 19  total_loss: 3.087  loss_cls: 1.35  loss_box_reg: 0.05116  loss_mask: 0.6923  loss_rpn_cls: 0.6956  loss_rpn_loc: 0.2911  time: 1.7304  data_time: 0.1277  lr: 9.9905e-06  max_mem: 9210M\n",
      "\u001b[32m[02/04 21:55:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:55:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:55:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:55:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:36 d2.utils.events]: \u001b[0m eta: 1:38:29  iter: 39  total_loss: 3.02  loss_cls: 1.234  loss_box_reg: 0.1142  loss_mask: 0.6857  loss_rpn_cls: 0.6853  loss_rpn_loc: 0.2998  time: 2.1937  data_time: 0.1501  lr: 1.998e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 21:56:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:56:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:02 d2.utils.events]: \u001b[0m eta: 1:28:12  iter: 59  total_loss: 2.462  loss_cls: 0.7824  loss_box_reg: 0.03378  loss_mask: 0.6736  loss_rpn_cls: 0.6926  loss_rpn_loc: 0.2444  time: 1.8807  data_time: 0.0821  lr: 2.997e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 21:57:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:44 d2.utils.events]: \u001b[0m eta: 1:28:01  iter: 79  total_loss: 2.17  loss_cls: 0.5007  loss_box_reg: 0.06293  loss_mask: 0.6516  loss_rpn_cls: 0.6869  loss_rpn_loc: 0.2821  time: 1.9473  data_time: 0.1474  lr: 3.9961e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 21:57:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:57:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:58:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:58:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:58:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:58:23 d2.utils.events]: \u001b[0m eta: 1:30:38  iter: 99  total_loss: 2.09  loss_cls: 0.4171  loss_box_reg: 0.03679  loss_mask: 0.6327  loss_rpn_cls: 0.682  loss_rpn_loc: 0.3009  time: 1.9431  data_time: 0.1204  lr: 4.9951e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 21:58:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:58:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:58:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:58:47 d2.utils.events]: \u001b[0m eta: 1:28:56  iter: 119  total_loss: 2.009  loss_cls: 0.3721  loss_box_reg: 0.06294  loss_mask: 0.5855  loss_rpn_cls: 0.6682  loss_rpn_loc: 0.2569  time: 1.8130  data_time: 0.0507  lr: 5.9941e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 21:58:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:58:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:19 d2.utils.events]: \u001b[0m eta: 1:27:53  iter: 139  total_loss: 1.989  loss_cls: 0.3696  loss_box_reg: 0.1295  loss_mask: 0.5644  loss_rpn_cls: 0.6497  loss_rpn_loc: 0.2666  time: 1.7832  data_time: 0.0881  lr: 6.993e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 21:59:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 21:59:50 d2.utils.events]: \u001b[0m eta: 1:30:25  iter: 159  total_loss: 2.282  loss_cls: 0.4885  loss_box_reg: 0.3255  loss_mask: 0.5268  loss_rpn_cls: 0.6385  loss_rpn_loc: 0.2539  time: 1.7579  data_time: 0.0850  lr: 7.9921e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 21:59:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:18 d2.utils.events]: \u001b[0m eta: 1:31:47  iter: 179  total_loss: 2.43  loss_cls: 0.5491  loss_box_reg: 0.4264  loss_mask: 0.5065  loss_rpn_cls: 0.6167  loss_rpn_loc: 0.2593  time: 1.7170  data_time: 0.1127  lr: 8.991e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:00:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:00:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:06 d2.utils.events]: \u001b[0m eta: 1:33:21  iter: 199  total_loss: 2.453  loss_cls: 0.5552  loss_box_reg: 0.4848  loss_mask: 0.4745  loss_rpn_cls: 0.6052  loss_rpn_loc: 0.2341  time: 1.7825  data_time: 0.1189  lr: 9.9901e-05  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:01:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:36 d2.utils.events]: \u001b[0m eta: 1:33:58  iter: 219  total_loss: 2.442  loss_cls: 0.5349  loss_box_reg: 0.5873  loss_mask: 0.4493  loss_rpn_cls: 0.5655  loss_rpn_loc: 0.2645  time: 1.7564  data_time: 0.0771  lr: 0.00010989  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:01:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:01:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:01 d2.utils.events]: \u001b[0m eta: 1:32:44  iter: 239  total_loss: 2.224  loss_cls: 0.5054  loss_box_reg: 0.632  loss_mask: 0.4176  loss_rpn_cls: 0.5236  loss_rpn_loc: 0.2153  time: 1.7174  data_time: 0.0811  lr: 0.00011988  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:02:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:02:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 22:02:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 22:02:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 22:02:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:02:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 22:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0942 s/iter. Eval: 0.0045 s/iter. Total: 0.0993 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/04 22:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0008 s/iter. Inference: 0.0980 s/iter. Eval: 0.0064 s/iter. Total: 0.1052 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/04 22:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0967 s/iter. Eval: 0.0055 s/iter. Total: 0.1031 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/04 22:02:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.951444 (0.103030 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:02:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.096254 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:02:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 22:02:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.029071099014604987\n",
      "\u001b[32m[02/04 22:02:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:02:57 d2.utils.events]: \u001b[0m eta: 1:33:16  iter: 259  total_loss: 2.222  loss_cls: 0.4937  loss_box_reg: 0.6357  loss_mask: 0.3972  loss_rpn_cls: 0.502  loss_rpn_loc: 0.2591  time: 1.7461  data_time: 0.0909  lr: 0.00012987  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:03:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:23 d2.utils.events]: \u001b[0m eta: 1:33:00  iter: 279  total_loss: 2.099  loss_cls: 0.4412  loss_box_reg: 0.6709  loss_mask: 0.3584  loss_rpn_cls: 0.4765  loss_rpn_loc: 0.2432  time: 1.7169  data_time: 0.1693  lr: 0.00013986  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:03:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:03:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:00 d2.utils.events]: \u001b[0m eta: 1:32:48  iter: 299  total_loss: 2.007  loss_cls: 0.4066  loss_box_reg: 0.6522  loss_mask: 0.3381  loss_rpn_cls: 0.4242  loss_rpn_loc: 0.2283  time: 1.7236  data_time: 0.0959  lr: 0.00014985  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:04:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:29 d2.utils.events]: \u001b[0m eta: 1:32:12  iter: 319  total_loss: 1.81  loss_cls: 0.322  loss_box_reg: 0.5969  loss_mask: 0.318  loss_rpn_cls: 0.3859  loss_rpn_loc: 0.2146  time: 1.7063  data_time: 0.0991  lr: 0.00015984  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:04:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:04:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:06 d2.utils.events]: \u001b[0m eta: 1:32:01  iter: 339  total_loss: 1.894  loss_cls: 0.3555  loss_box_reg: 0.6263  loss_mask: 0.3436  loss_rpn_cls: 0.3622  loss_rpn_loc: 0.2239  time: 1.7155  data_time: 0.1487  lr: 0.00016983  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:05:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:05:50 d2.utils.events]: \u001b[0m eta: 1:32:16  iter: 359  total_loss: 1.953  loss_cls: 0.3709  loss_box_reg: 0.5906  loss_mask: 0.3308  loss_rpn_cls: 0.3908  loss_rpn_loc: 0.2752  time: 1.7424  data_time: 0.0932  lr: 0.00017982  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:05:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:17 d2.utils.events]: \u001b[0m eta: 1:32:02  iter: 379  total_loss: 1.757  loss_cls: 0.3239  loss_box_reg: 0.5738  loss_mask: 0.3236  loss_rpn_cls: 0.3182  loss_rpn_loc: 0.2106  time: 1.7227  data_time: 0.0713  lr: 0.00018981  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:06:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:06:50 d2.utils.events]: \u001b[0m eta: 1:31:55  iter: 399  total_loss: 1.85  loss_cls: 0.3686  loss_box_reg: 0.6258  loss_mask: 0.3229  loss_rpn_cls: 0.2873  loss_rpn_loc: 0.2065  time: 1.7169  data_time: 0.1370  lr: 0.0001998  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:06:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:31 d2.utils.events]: \u001b[0m eta: 1:31:42  iter: 419  total_loss: 1.83  loss_cls: 0.323  loss_box_reg: 0.6168  loss_mask: 0.3245  loss_rpn_cls: 0.3239  loss_rpn_loc: 0.2434  time: 1.7342  data_time: 0.1529  lr: 0.00020979  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:07:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:07:57 d2.utils.events]: \u001b[0m eta: 1:31:32  iter: 439  total_loss: 1.693  loss_cls: 0.3177  loss_box_reg: 0.5867  loss_mask: 0.3114  loss_rpn_cls: 0.2693  loss_rpn_loc: 0.2356  time: 1.7149  data_time: 0.0651  lr: 0.00021978  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:08:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:28 d2.utils.events]: \u001b[0m eta: 1:31:21  iter: 459  total_loss: 1.742  loss_cls: 0.3505  loss_box_reg: 0.5629  loss_mask: 0.3024  loss_rpn_cls: 0.2738  loss_rpn_loc: 0.2058  time: 1.7078  data_time: 0.0805  lr: 0.00022977  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:08:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:08:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:09:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:09:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:09:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:09:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:09:23 d2.utils.events]: \u001b[0m eta: 1:31:28  iter: 479  total_loss: 1.754  loss_cls: 0.3626  loss_box_reg: 0.6142  loss_mask: 0.3211  loss_rpn_cls: 0.2516  loss_rpn_loc: 0.224  time: 1.7500  data_time: 0.0380  lr: 0.00023976  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:09:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:09:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:09:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 22:09:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 22:09:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 22:09:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:09:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 22:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0959 s/iter. Eval: 0.0533 s/iter. Total: 0.1499 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 22:09:36 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0980 s/iter. Eval: 0.0706 s/iter. Total: 0.1694 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 22:09:41 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0984 s/iter. Eval: 0.0697 s/iter. Total: 0.1690 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 22:09:46 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0981 s/iter. Eval: 0.0749 s/iter. Total: 0.1738 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 22:09:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.879450 (0.171375 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:09:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097484 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:09:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 22:09:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20448499385530908\n",
      "\u001b[32m[02/04 22:09:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:29 d2.utils.events]: \u001b[0m eta: 1:31:19  iter: 499  total_loss: 1.877  loss_cls: 0.3813  loss_box_reg: 0.6127  loss_mask: 0.3395  loss_rpn_cls: 0.2749  loss_rpn_loc: 0.2731  time: 1.7697  data_time: 0.0980  lr: 0.00024975  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:10:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:10:54 d2.utils.events]: \u001b[0m eta: 1:31:08  iter: 519  total_loss: 1.683  loss_cls: 0.2876  loss_box_reg: 0.586  loss_mask: 0.3078  loss_rpn_cls: 0.2665  loss_rpn_loc: 0.2191  time: 1.7490  data_time: 0.0158  lr: 0.00025974  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:11:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:29 d2.utils.events]: \u001b[0m eta: 1:31:08  iter: 539  total_loss: 1.662  loss_cls: 0.3244  loss_box_reg: 0.6049  loss_mask: 0.3097  loss_rpn_cls: 0.2049  loss_rpn_loc: 0.1907  time: 1.7498  data_time: 0.0830  lr: 0.00026973  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:11:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:11:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:06 d2.utils.events]: \u001b[0m eta: 1:31:10  iter: 559  total_loss: 1.808  loss_cls: 0.3576  loss_box_reg: 0.6197  loss_mask: 0.31  loss_rpn_cls: 0.2585  loss_rpn_loc: 0.231  time: 1.7535  data_time: 0.1482  lr: 0.00027972  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:12:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:37 d2.utils.events]: \u001b[0m eta: 1:30:53  iter: 579  total_loss: 1.727  loss_cls: 0.3412  loss_box_reg: 0.6118  loss_mask: 0.3204  loss_rpn_cls: 0.2174  loss_rpn_loc: 0.2088  time: 1.7465  data_time: 0.0337  lr: 0.00028971  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:12:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:12:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:23 d2.utils.events]: \u001b[0m eta: 1:30:47  iter: 599  total_loss: 1.697  loss_cls: 0.3764  loss_box_reg: 0.5899  loss_mask: 0.3166  loss_rpn_cls: 0.2031  loss_rpn_loc: 0.2079  time: 1.7644  data_time: 0.1079  lr: 0.0002997  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:13:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:13:54 d2.utils.events]: \u001b[0m eta: 1:30:30  iter: 619  total_loss: 1.701  loss_cls: 0.3674  loss_box_reg: 0.6013  loss_mask: 0.3051  loss_rpn_cls: 0.1808  loss_rpn_loc: 0.1992  time: 1.7567  data_time: 0.1354  lr: 0.00030969  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:13:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:14:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:14:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:14:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:14:22 d2.utils.events]: \u001b[0m eta: 1:30:10  iter: 639  total_loss: 1.609  loss_cls: 0.3107  loss_box_reg: 0.5985  loss_mask: 0.2944  loss_rpn_cls: 0.1967  loss_rpn_loc: 0.2062  time: 1.7462  data_time: 0.0884  lr: 0.00031968  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:14:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:14:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:14:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:14:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:14:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:00 d2.utils.events]: \u001b[0m eta: 1:29:53  iter: 659  total_loss: 1.739  loss_cls: 0.3627  loss_box_reg: 0.6219  loss_mask: 0.3121  loss_rpn_cls: 0.186  loss_rpn_loc: 0.1981  time: 1.7513  data_time: 0.1553  lr: 0.00032967  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:15:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:27 d2.utils.events]: \u001b[0m eta: 1:29:38  iter: 679  total_loss: 1.635  loss_cls: 0.3354  loss_box_reg: 0.6027  loss_mask: 0.3111  loss_rpn_cls: 0.1832  loss_rpn_loc: 0.1787  time: 1.7388  data_time: 0.0308  lr: 0.00033966  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:15:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:15:55 d2.utils.events]: \u001b[0m eta: 1:29:21  iter: 699  total_loss: 1.561  loss_cls: 0.3325  loss_box_reg: 0.6009  loss_mask: 0.3042  loss_rpn_cls: 0.1446  loss_rpn_loc: 0.1588  time: 1.7297  data_time: 0.0830  lr: 0.00034965  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:15:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:16:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:16:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:16:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:16:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:16:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:16:28 d2.utils.events]: \u001b[0m eta: 1:29:04  iter: 719  total_loss: 1.562  loss_cls: 0.2998  loss_box_reg: 0.5852  loss_mask: 0.3021  loss_rpn_cls: 0.1504  loss_rpn_loc: 0.1808  time: 1.7272  data_time: 0.0683  lr: 0.00035964  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:16:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:16:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:16:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 22:16:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 22:16:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 22:16:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:16:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 22:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0928 s/iter. Eval: 0.0632 s/iter. Total: 0.1567 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 22:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0739 s/iter. Total: 0.1679 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 22:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0929 s/iter. Eval: 0.0726 s/iter. Total: 0.1663 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 22:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0933 s/iter. Eval: 0.0768 s/iter. Total: 0.1709 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 22:16:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.755657 (0.170307 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:16:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093207 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:16:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 22:16:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22826289884802967\n",
      "\u001b[32m[02/04 22:17:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:29 d2.utils.events]: \u001b[0m eta: 1:28:58  iter: 739  total_loss: 1.929  loss_cls: 0.4275  loss_box_reg: 0.6574  loss_mask: 0.3167  loss_rpn_cls: 0.1981  loss_rpn_loc: 0.2497  time: 1.7335  data_time: 0.0629  lr: 0.00036963  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:17:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:17:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:06 d2.utils.events]: \u001b[0m eta: 1:28:44  iter: 759  total_loss: 1.712  loss_cls: 0.3519  loss_box_reg: 0.616  loss_mask: 0.3146  loss_rpn_cls: 0.2041  loss_rpn_loc: 0.1844  time: 1.7372  data_time: 0.1068  lr: 0.00037962  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:18:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:37 d2.utils.events]: \u001b[0m eta: 1:28:32  iter: 779  total_loss: 1.567  loss_cls: 0.346  loss_box_reg: 0.5984  loss_mask: 0.2956  loss_rpn_cls: 0.139  loss_rpn_loc: 0.1834  time: 1.7320  data_time: 0.0904  lr: 0.00038961  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:18:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:18:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:07 d2.utils.events]: \u001b[0m eta: 1:28:15  iter: 799  total_loss: 1.756  loss_cls: 0.3853  loss_box_reg: 0.6156  loss_mask: 0.3085  loss_rpn_cls: 0.1744  loss_rpn_loc: 0.2113  time: 1.7258  data_time: 0.0950  lr: 0.0003996  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:19:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:19:55 d2.utils.events]: \u001b[0m eta: 1:28:06  iter: 819  total_loss: 1.729  loss_cls: 0.4056  loss_box_reg: 0.6324  loss_mask: 0.3221  loss_rpn_cls: 0.1952  loss_rpn_loc: 0.2369  time: 1.7427  data_time: 0.1273  lr: 0.00040959  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:19:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:26 d2.utils.events]: \u001b[0m eta: 1:27:56  iter: 839  total_loss: 1.666  loss_cls: 0.3526  loss_box_reg: 0.6186  loss_mask: 0.3188  loss_rpn_cls: 0.1636  loss_rpn_loc: 0.2027  time: 1.7382  data_time: 0.0394  lr: 0.00041958  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:20:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:42 d2.utils.events]: \u001b[0m eta: 1:27:32  iter: 859  total_loss: 1.489  loss_cls: 0.3259  loss_box_reg: 0.5607  loss_mask: 0.2882  loss_rpn_cls: 0.1379  loss_rpn_loc: 0.1446  time: 1.7158  data_time: 0.0162  lr: 0.00042957  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:20:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:20:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:12 d2.utils.events]: \u001b[0m eta: 1:27:21  iter: 879  total_loss: 1.59  loss_cls: 0.36  loss_box_reg: 0.614  loss_mask: 0.3034  loss_rpn_cls: 0.1493  loss_rpn_loc: 0.1832  time: 1.7110  data_time: 0.0662  lr: 0.00043956  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:21:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:21:51 d2.utils.events]: \u001b[0m eta: 1:27:13  iter: 899  total_loss: 1.556  loss_cls: 0.3662  loss_box_reg: 0.586  loss_mask: 0.3005  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.1885  time: 1.7166  data_time: 0.0845  lr: 0.00044955  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:21:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:26 d2.utils.events]: \u001b[0m eta: 1:26:57  iter: 919  total_loss: 1.567  loss_cls: 0.3574  loss_box_reg: 0.5893  loss_mask: 0.2849  loss_rpn_cls: 0.138  loss_rpn_loc: 0.1731  time: 1.7173  data_time: 0.1278  lr: 0.00045954  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:22:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:54 d2.utils.events]: \u001b[0m eta: 1:26:45  iter: 939  total_loss: 1.513  loss_cls: 0.3421  loss_box_reg: 0.5739  loss_mask: 0.2977  loss_rpn_cls: 0.1263  loss_rpn_loc: 0.1983  time: 1.7101  data_time: 0.0870  lr: 0.00046953  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:22:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:22:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:41 d2.utils.events]: \u001b[0m eta: 1:26:35  iter: 959  total_loss: 1.588  loss_cls: 0.3754  loss_box_reg: 0.571  loss_mask: 0.304  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.1858  time: 1.7242  data_time: 0.0657  lr: 0.00047952  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:23:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:23:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:23:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 22:23:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 22:23:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 22:23:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:23:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 22:23:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0905 s/iter. Eval: 0.0576 s/iter. Total: 0.1487 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 22:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0942 s/iter. Eval: 0.0706 s/iter. Total: 0.1656 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 22:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0936 s/iter. Eval: 0.0683 s/iter. Total: 0.1628 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/04 22:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0936 s/iter. Eval: 0.0723 s/iter. Total: 0.1668 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 22:24:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.321102 (0.166561 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:24:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093744 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:24:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 22:24:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22003647134286475\n",
      "\u001b[32m[02/04 22:24:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:24:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:24:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:24:37 d2.utils.events]: \u001b[0m eta: 1:26:24  iter: 979  total_loss: 1.587  loss_cls: 0.4078  loss_box_reg: 0.5764  loss_mask: 0.3012  loss_rpn_cls: 0.1439  loss_rpn_loc: 0.1831  time: 1.7244  data_time: 0.0676  lr: 0.00048951  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:24:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:24:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:24:56 d2.utils.events]: \u001b[0m eta: 1:26:08  iter: 999  total_loss: 1.559  loss_cls: 0.3816  loss_box_reg: 0.5575  loss_mask: 0.2887  loss_rpn_cls: 0.1394  loss_rpn_loc: 0.1713  time: 1.7085  data_time: 0.0608  lr: 0.0004995  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:24:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:42 d2.utils.events]: \u001b[0m eta: 1:26:00  iter: 1019  total_loss: 1.545  loss_cls: 0.334  loss_box_reg: 0.5906  loss_mask: 0.3275  loss_rpn_cls: 0.1287  loss_rpn_loc: 0.1598  time: 1.7204  data_time: 0.1555  lr: 0.0005  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:25:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:25:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:23 d2.utils.events]: \u001b[0m eta: 1:25:46  iter: 1039  total_loss: 1.621  loss_cls: 0.379  loss_box_reg: 0.585  loss_mask: 0.3063  loss_rpn_cls: 0.1515  loss_rpn_loc: 0.1965  time: 1.7271  data_time: 0.0201  lr: 0.0005  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:26:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:49 d2.utils.events]: \u001b[0m eta: 1:25:32  iter: 1059  total_loss: 1.532  loss_cls: 0.3287  loss_box_reg: 0.5857  loss_mask: 0.2839  loss_rpn_cls: 0.1373  loss_rpn_loc: 0.1556  time: 1.7192  data_time: 0.0977  lr: 0.0005  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:26:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:26:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:19 d2.utils.events]: \u001b[0m eta: 1:25:20  iter: 1079  total_loss: 1.485  loss_cls: 0.3495  loss_box_reg: 0.5838  loss_mask: 0.313  loss_rpn_cls: 0.105  loss_rpn_loc: 0.1659  time: 1.7147  data_time: 0.0281  lr: 0.0005  max_mem: 9370M\n",
      "\u001b[32m[02/04 22:27:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:45 d2.utils.events]: \u001b[0m eta: 1:24:59  iter: 1099  total_loss: 1.564  loss_cls: 0.3434  loss_box_reg: 0.5676  loss_mask: 0.303  loss_rpn_cls: 0.1434  loss_rpn_loc: 0.1818  time: 1.7075  data_time: 0.0686  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:27:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:27:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:36 d2.utils.events]: \u001b[0m eta: 1:25:00  iter: 1119  total_loss: 1.554  loss_cls: 0.3658  loss_box_reg: 0.5662  loss_mask: 0.3117  loss_rpn_cls: 0.1375  loss_rpn_loc: 0.1934  time: 1.7227  data_time: 0.1668  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:28:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:28:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:16 d2.utils.events]: \u001b[0m eta: 1:25:03  iter: 1139  total_loss: 1.59  loss_cls: 0.3522  loss_box_reg: 0.5813  loss_mask: 0.3098  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.202  time: 1.7275  data_time: 0.0918  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:29:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:45 d2.utils.events]: \u001b[0m eta: 1:24:50  iter: 1159  total_loss: 1.577  loss_cls: 0.3817  loss_box_reg: 0.5851  loss_mask: 0.2991  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.196  time: 1.7225  data_time: 0.0526  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:29:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:29:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:26 d2.utils.events]: \u001b[0m eta: 1:24:45  iter: 1179  total_loss: 1.585  loss_cls: 0.3713  loss_box_reg: 0.5874  loss_mask: 0.3061  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.1966  time: 1.7280  data_time: 0.1430  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:30:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:30:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:31:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:31:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:31:11 d2.utils.events]: \u001b[0m eta: 1:24:33  iter: 1199  total_loss: 1.567  loss_cls: 0.3589  loss_box_reg: 0.5913  loss_mask: 0.2994  loss_rpn_cls: 0.1294  loss_rpn_loc: 0.1859  time: 1.7366  data_time: 0.2563  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:31:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:31:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:31:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:31:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:31:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:31:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 22:31:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 22:31:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 22:31:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:31:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 22:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0956 s/iter. Eval: 0.0596 s/iter. Total: 0.1559 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 22:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0982 s/iter. Eval: 0.0721 s/iter. Total: 0.1712 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 22:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0978 s/iter. Eval: 0.0711 s/iter. Total: 0.1697 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 22:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0980 s/iter. Eval: 0.0762 s/iter. Total: 0.1750 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 22:31:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.116213 (0.173416 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:31:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097536 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:31:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 22:31:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24871487445688192\n",
      "\u001b[32m[02/04 22:32:01 d2.utils.events]: \u001b[0m eta: 1:24:25  iter: 1219  total_loss: 1.584  loss_cls: 0.3835  loss_box_reg: 0.5827  loss_mask: 0.2973  loss_rpn_cls: 0.1538  loss_rpn_loc: 0.1771  time: 1.7308  data_time: 0.0264  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:32:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:40 d2.utils.events]: \u001b[0m eta: 1:24:27  iter: 1239  total_loss: 1.542  loss_cls: 0.3704  loss_box_reg: 0.5772  loss_mask: 0.2965  loss_rpn_cls: 0.1327  loss_rpn_loc: 0.19  time: 1.7349  data_time: 0.0857  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:32:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:32:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:16 d2.utils.events]: \u001b[0m eta: 1:24:12  iter: 1259  total_loss: 1.543  loss_cls: 0.349  loss_box_reg: 0.562  loss_mask: 0.3075  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.1944  time: 1.7360  data_time: 0.1418  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:33:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:33:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:09 d2.utils.events]: \u001b[0m eta: 1:24:15  iter: 1279  total_loss: 1.566  loss_cls: 0.3651  loss_box_reg: 0.5764  loss_mask: 0.3218  loss_rpn_cls: 0.1245  loss_rpn_loc: 0.1629  time: 1.7497  data_time: 0.0962  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:34:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:34:55 d2.utils.events]: \u001b[0m eta: 1:24:05  iter: 1299  total_loss: 1.656  loss_cls: 0.365  loss_box_reg: 0.5761  loss_mask: 0.3216  loss_rpn_cls: 0.1332  loss_rpn_loc: 0.1928  time: 1.7587  data_time: 0.1481  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:34:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:35 d2.utils.events]: \u001b[0m eta: 1:23:57  iter: 1319  total_loss: 1.499  loss_cls: 0.3545  loss_box_reg: 0.562  loss_mask: 0.2866  loss_rpn_cls: 0.1233  loss_rpn_loc: 0.1957  time: 1.7622  data_time: 0.1242  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:35:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:35:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:08 d2.utils.events]: \u001b[0m eta: 1:23:52  iter: 1339  total_loss: 1.529  loss_cls: 0.3771  loss_box_reg: 0.5766  loss_mask: 0.2898  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.1663  time: 1.7606  data_time: 0.0540  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:36:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:42 d2.utils.events]: \u001b[0m eta: 1:23:33  iter: 1359  total_loss: 1.568  loss_cls: 0.3697  loss_box_reg: 0.5837  loss_mask: 0.3027  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.1682  time: 1.7594  data_time: 0.0537  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:36:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:36:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:33 d2.utils.events]: \u001b[0m eta: 1:23:31  iter: 1379  total_loss: 1.562  loss_cls: 0.3776  loss_box_reg: 0.5749  loss_mask: 0.2936  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.1861  time: 1.7709  data_time: 0.0802  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:37:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:37:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:38:04 d2.utils.events]: \u001b[0m eta: 1:23:19  iter: 1399  total_loss: 1.504  loss_cls: 0.3599  loss_box_reg: 0.5725  loss_mask: 0.301  loss_rpn_cls: 0.11  loss_rpn_loc: 0.1838  time: 1.7680  data_time: 0.0957  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:38:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:38:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:38:24 d2.utils.events]: \u001b[0m eta: 1:23:08  iter: 1419  total_loss: 1.574  loss_cls: 0.358  loss_box_reg: 0.5791  loss_mask: 0.2904  loss_rpn_cls: 0.1324  loss_rpn_loc: 0.1723  time: 1.7572  data_time: 0.0697  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:38:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:38:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:38:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:38:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:38:56 d2.utils.events]: \u001b[0m eta: 1:22:51  iter: 1439  total_loss: 1.429  loss_cls: 0.3405  loss_box_reg: 0.5546  loss_mask: 0.2814  loss_rpn_cls: 0.07965  loss_rpn_loc: 0.1627  time: 1.7550  data_time: 0.1332  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:38:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:39:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:39:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:39:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 22:39:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 22:39:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 22:39:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:39:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 22:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0936 s/iter. Eval: 0.0523 s/iter. Total: 0.1466 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 22:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0962 s/iter. Eval: 0.0692 s/iter. Total: 0.1662 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 22:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0970 s/iter. Eval: 0.0700 s/iter. Total: 0.1678 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 22:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0977 s/iter. Eval: 0.0756 s/iter. Total: 0.1742 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 22:39:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.042035 (0.172776 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:39:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097904 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:39:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 22:39:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2473089362724854\n",
      "\u001b[32m[02/04 22:39:36 d2.utils.events]: \u001b[0m eta: 1:22:41  iter: 1459  total_loss: 1.512  loss_cls: 0.3368  loss_box_reg: 0.5871  loss_mask: 0.2993  loss_rpn_cls: 0.09081  loss_rpn_loc: 0.1456  time: 1.7430  data_time: 0.0155  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:39:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:39:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:39:55 d2.utils.events]: \u001b[0m eta: 1:22:19  iter: 1479  total_loss: 1.489  loss_cls: 0.339  loss_box_reg: 0.5725  loss_mask: 0.2826  loss_rpn_cls: 0.125  loss_rpn_loc: 0.1658  time: 1.7323  data_time: 0.0434  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:39:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:44 d2.utils.events]: \u001b[0m eta: 1:22:18  iter: 1499  total_loss: 1.575  loss_cls: 0.3954  loss_box_reg: 0.5693  loss_mask: 0.3093  loss_rpn_cls: 0.1256  loss_rpn_loc: 0.1695  time: 1.7420  data_time: 0.0600  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:40:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:40:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:29 d2.utils.events]: \u001b[0m eta: 1:22:08  iter: 1519  total_loss: 1.607  loss_cls: 0.3673  loss_box_reg: 0.5958  loss_mask: 0.3094  loss_rpn_cls: 0.1336  loss_rpn_loc: 0.1627  time: 1.7485  data_time: 0.0964  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:41:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:41:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:04 d2.utils.events]: \u001b[0m eta: 1:21:49  iter: 1539  total_loss: 1.508  loss_cls: 0.3313  loss_box_reg: 0.5785  loss_mask: 0.2992  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.187  time: 1.7485  data_time: 0.1364  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:42:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:50 d2.utils.events]: \u001b[0m eta: 1:21:45  iter: 1559  total_loss: 1.697  loss_cls: 0.4229  loss_box_reg: 0.5808  loss_mask: 0.2962  loss_rpn_cls: 0.1213  loss_rpn_loc: 0.186  time: 1.7560  data_time: 0.0778  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:42:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:42:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:29 d2.utils.events]: \u001b[0m eta: 1:21:56  iter: 1579  total_loss: 1.593  loss_cls: 0.3755  loss_box_reg: 0.6007  loss_mask: 0.3199  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.2221  time: 1.7582  data_time: 0.0488  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:43:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:43:55 d2.utils.events]: \u001b[0m eta: 1:21:22  iter: 1599  total_loss: 1.425  loss_cls: 0.3148  loss_box_reg: 0.5442  loss_mask: 0.2725  loss_rpn_cls: 0.09903  loss_rpn_loc: 0.1642  time: 1.7523  data_time: 0.0459  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:43:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:21 d2.utils.events]: \u001b[0m eta: 1:21:08  iter: 1619  total_loss: 1.362  loss_cls: 0.3229  loss_box_reg: 0.5366  loss_mask: 0.284  loss_rpn_cls: 0.082  loss_rpn_loc: 0.1252  time: 1.7471  data_time: 0.0294  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:44:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:44:50 d2.utils.events]: \u001b[0m eta: 1:21:09  iter: 1639  total_loss: 1.477  loss_cls: 0.3318  loss_box_reg: 0.5695  loss_mask: 0.2992  loss_rpn_cls: 0.09868  loss_rpn_loc: 0.1605  time: 1.7431  data_time: 0.0705  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:44:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:27 d2.utils.events]: \u001b[0m eta: 1:21:21  iter: 1659  total_loss: 1.543  loss_cls: 0.3661  loss_box_reg: 0.5778  loss_mask: 0.2991  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.1865  time: 1.7447  data_time: 0.1026  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:45:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:45:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:46:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:46:07 d2.utils.events]: \u001b[0m eta: 1:21:20  iter: 1679  total_loss: 1.534  loss_cls: 0.3678  loss_box_reg: 0.567  loss_mask: 0.2865  loss_rpn_cls: 0.1217  loss_rpn_loc: 0.1747  time: 1.7473  data_time: 0.0970  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:46:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:46:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:46:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 22:46:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 22:46:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 22:46:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:46:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 22:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0985 s/iter. Eval: 0.0523 s/iter. Total: 0.1514 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 22:46:27 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0969 s/iter. Eval: 0.0689 s/iter. Total: 0.1666 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 22:46:32 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0960 s/iter. Eval: 0.0674 s/iter. Total: 0.1642 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 22:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0975 s/iter. Eval: 0.0743 s/iter. Total: 0.1727 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 22:46:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.751504 (0.170272 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:46:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097078 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:46:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 22:46:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.261411643301188\n",
      "\u001b[32m[02/04 22:46:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:46:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:46:53 d2.utils.events]: \u001b[0m eta: 1:21:11  iter: 1699  total_loss: 1.446  loss_cls: 0.3308  loss_box_reg: 0.5319  loss_mask: 0.2831  loss_rpn_cls: 0.09608  loss_rpn_loc: 0.174  time: 1.7411  data_time: 0.0666  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:46:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:46:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:47:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:47:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:47:20 d2.utils.events]: \u001b[0m eta: 1:20:59  iter: 1719  total_loss: 1.402  loss_cls: 0.3253  loss_box_reg: 0.57  loss_mask: 0.2941  loss_rpn_cls: 0.07994  loss_rpn_loc: 0.1405  time: 1.7369  data_time: 0.0603  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:47:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:47:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:47:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:47:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:47:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:47:55 d2.utils.events]: \u001b[0m eta: 1:20:45  iter: 1739  total_loss: 1.538  loss_cls: 0.3673  loss_box_reg: 0.5823  loss_mask: 0.3152  loss_rpn_cls: 0.08793  loss_rpn_loc: 0.1662  time: 1.7366  data_time: 0.0690  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:48:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:37 d2.utils.events]: \u001b[0m eta: 1:20:43  iter: 1759  total_loss: 1.551  loss_cls: 0.358  loss_box_reg: 0.5724  loss_mask: 0.2854  loss_rpn_cls: 0.121  loss_rpn_loc: 0.2014  time: 1.7411  data_time: 0.1104  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:48:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:48:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:06 d2.utils.events]: \u001b[0m eta: 1:20:54  iter: 1779  total_loss: 1.443  loss_cls: 0.3417  loss_box_reg: 0.5636  loss_mask: 0.2985  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.162  time: 1.7379  data_time: 0.0292  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:49:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:39 d2.utils.events]: \u001b[0m eta: 1:20:53  iter: 1799  total_loss: 1.52  loss_cls: 0.3494  loss_box_reg: 0.5607  loss_mask: 0.2909  loss_rpn_cls: 0.08832  loss_rpn_loc: 0.1729  time: 1.7365  data_time: 0.0950  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:49:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:49:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:23 d2.utils.events]: \u001b[0m eta: 1:20:43  iter: 1819  total_loss: 1.592  loss_cls: 0.3606  loss_box_reg: 0.6056  loss_mask: 0.2992  loss_rpn_cls: 0.124  loss_rpn_loc: 0.2035  time: 1.7418  data_time: 0.0692  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:50:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:50:57 d2.utils.events]: \u001b[0m eta: 1:20:33  iter: 1839  total_loss: 1.533  loss_cls: 0.3512  loss_box_reg: 0.5732  loss_mask: 0.3056  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.1698  time: 1.7412  data_time: 0.0713  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:51:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:51:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:51:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:51:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:51:23 d2.utils.events]: \u001b[0m eta: 1:20:36  iter: 1859  total_loss: 1.498  loss_cls: 0.3402  loss_box_reg: 0.5949  loss_mask: 0.2949  loss_rpn_cls: 0.08479  loss_rpn_loc: 0.1688  time: 1.7365  data_time: 0.0575  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:51:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:51:39 d2.utils.events]: \u001b[0m eta: 1:20:28  iter: 1879  total_loss: 1.389  loss_cls: 0.3417  loss_box_reg: 0.5409  loss_mask: 0.2731  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.1484  time: 1.7268  data_time: 0.0578  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:51:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:51:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:51:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:13 d2.utils.events]: \u001b[0m eta: 1:20:11  iter: 1899  total_loss: 1.454  loss_cls: 0.3492  loss_box_reg: 0.552  loss_mask: 0.2946  loss_rpn_cls: 0.09758  loss_rpn_loc: 0.1673  time: 1.7264  data_time: 0.0585  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:52:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:52:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:02 d2.utils.events]: \u001b[0m eta: 1:20:14  iter: 1919  total_loss: 1.557  loss_cls: 0.3604  loss_box_reg: 0.5758  loss_mask: 0.3004  loss_rpn_cls: 0.09351  loss_rpn_loc: 0.1784  time: 1.7341  data_time: 0.0647  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:53:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:53:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:53:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 22:53:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 22:53:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 22:53:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 22:53:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 22:53:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0975 s/iter. Eval: 0.0565 s/iter. Total: 0.1547 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/04 22:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0975 s/iter. Eval: 0.0715 s/iter. Total: 0.1698 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 22:53:54 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0974 s/iter. Eval: 0.0708 s/iter. Total: 0.1691 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 22:53:59 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0978 s/iter. Eval: 0.0765 s/iter. Total: 0.1751 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 22:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.154764 (0.173748 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097693 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 22:54:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 22:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25145640185405327\n",
      "\u001b[32m[02/04 22:54:06 d2.utils.events]: \u001b[0m eta: 1:20:14  iter: 1939  total_loss: 1.576  loss_cls: 0.3876  loss_box_reg: 0.6004  loss_mask: 0.3083  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.1569  time: 1.7376  data_time: 0.0868  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:54:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:41 d2.utils.events]: \u001b[0m eta: 1:19:56  iter: 1959  total_loss: 1.36  loss_cls: 0.337  loss_box_reg: 0.5407  loss_mask: 0.2871  loss_rpn_cls: 0.09646  loss_rpn_loc: 0.1537  time: 1.7377  data_time: 0.1021  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:54:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:54:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:39 d2.utils.events]: \u001b[0m eta: 1:20:00  iter: 1979  total_loss: 1.546  loss_cls: 0.3714  loss_box_reg: 0.5965  loss_mask: 0.3086  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.1761  time: 1.7495  data_time: 0.1688  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:55:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:55:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:16 d2.utils.events]: \u001b[0m eta: 1:20:10  iter: 1999  total_loss: 1.397  loss_cls: 0.3458  loss_box_reg: 0.5343  loss_mask: 0.2763  loss_rpn_cls: 0.08367  loss_rpn_loc: 0.1406  time: 1.7508  data_time: 0.1388  lr: 0.0005  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:56:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:50 d2.utils.events]: \u001b[0m eta: 1:19:58  iter: 2019  total_loss: 1.406  loss_cls: 0.3426  loss_box_reg: 0.5518  loss_mask: 0.2845  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.1513  time: 1.7500  data_time: 0.0982  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:56:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:56:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:09 d2.utils.events]: \u001b[0m eta: 1:19:36  iter: 2039  total_loss: 1.43  loss_cls: 0.3427  loss_box_reg: 0.5436  loss_mask: 0.2841  loss_rpn_cls: 0.09743  loss_rpn_loc: 0.1566  time: 1.7421  data_time: 0.0546  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:57:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:57:56 d2.utils.events]: \u001b[0m eta: 1:19:42  iter: 2059  total_loss: 1.47  loss_cls: 0.3588  loss_box_reg: 0.5773  loss_mask: 0.3057  loss_rpn_cls: 0.09507  loss_rpn_loc: 0.1785  time: 1.7480  data_time: 0.1128  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:57:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:26 d2.utils.events]: \u001b[0m eta: 1:19:30  iter: 2079  total_loss: 1.493  loss_cls: 0.3592  loss_box_reg: 0.5582  loss_mask: 0.3065  loss_rpn_cls: 0.09336  loss_rpn_loc: 0.1478  time: 1.7460  data_time: 0.0323  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:58:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:47 d2.utils.events]: \u001b[0m eta: 1:19:18  iter: 2099  total_loss: 1.533  loss_cls: 0.3309  loss_box_reg: 0.567  loss_mask: 0.3087  loss_rpn_cls: 0.08623  loss_rpn_loc: 0.1708  time: 1.7389  data_time: 0.0679  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:58:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:58:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:17 d2.utils.events]: \u001b[0m eta: 1:19:03  iter: 2119  total_loss: 1.523  loss_cls: 0.3465  loss_box_reg: 0.5801  loss_mask: 0.287  loss_rpn_cls: 0.1132  loss_rpn_loc: 0.1811  time: 1.7370  data_time: 0.0742  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:59:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 22:59:56 d2.utils.events]: \u001b[0m eta: 1:18:46  iter: 2139  total_loss: 1.55  loss_cls: 0.3815  loss_box_reg: 0.5771  loss_mask: 0.3153  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.1763  time: 1.7390  data_time: 0.0920  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 22:59:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:00:55 d2.utils.events]: \u001b[0m eta: 1:18:41  iter: 2159  total_loss: 1.521  loss_cls: 0.3473  loss_box_reg: 0.571  loss_mask: 0.2952  loss_rpn_cls: 0.08648  loss_rpn_loc: 0.1718  time: 1.7501  data_time: 0.1299  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:00:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:01:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:01:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:01:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:01:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:01:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:01:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:01:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 23:01:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 23:01:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 23:01:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:01:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 23:01:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0970 s/iter. Eval: 0.0535 s/iter. Total: 0.1512 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/04 23:01:34 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0961 s/iter. Eval: 0.0691 s/iter. Total: 0.1660 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 23:01:39 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0963 s/iter. Eval: 0.0694 s/iter. Total: 0.1666 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 23:01:45 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0968 s/iter. Eval: 0.0750 s/iter. Total: 0.1726 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/04 23:01:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.791218 (0.170614 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:01:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.096518 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:01:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 23:01:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26056906733073265\n",
      "\u001b[32m[02/04 23:01:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:01:52 d2.utils.events]: \u001b[0m eta: 1:18:29  iter: 2179  total_loss: 1.523  loss_cls: 0.3429  loss_box_reg: 0.5701  loss_mask: 0.2936  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.1691  time: 1.7504  data_time: 0.0325  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:01:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:02:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:02:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:02:19 d2.utils.events]: \u001b[0m eta: 1:18:12  iter: 2199  total_loss: 1.487  loss_cls: 0.35  loss_box_reg: 0.5629  loss_mask: 0.2945  loss_rpn_cls: 0.1151  loss_rpn_loc: 0.1408  time: 1.7467  data_time: 0.1402  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:02:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:02:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:02:41 d2.utils.events]: \u001b[0m eta: 1:17:59  iter: 2219  total_loss: 1.364  loss_cls: 0.3337  loss_box_reg: 0.5421  loss_mask: 0.284  loss_rpn_cls: 0.06497  loss_rpn_loc: 0.1514  time: 1.7408  data_time: 0.0715  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:02:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:02:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:02:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:02:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:25 d2.utils.events]: \u001b[0m eta: 1:17:48  iter: 2239  total_loss: 1.456  loss_cls: 0.3521  loss_box_reg: 0.5515  loss_mask: 0.2996  loss_rpn_cls: 0.08913  loss_rpn_loc: 0.1596  time: 1.7449  data_time: 0.0622  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:03:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:03:58 d2.utils.events]: \u001b[0m eta: 1:17:39  iter: 2259  total_loss: 1.429  loss_cls: 0.3463  loss_box_reg: 0.5554  loss_mask: 0.2988  loss_rpn_cls: 0.08763  loss_rpn_loc: 0.1496  time: 1.7440  data_time: 0.0499  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:04:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:34 d2.utils.events]: \u001b[0m eta: 1:17:28  iter: 2279  total_loss: 1.536  loss_cls: 0.3619  loss_box_reg: 0.5822  loss_mask: 0.3052  loss_rpn_cls: 0.09449  loss_rpn_loc: 0.1674  time: 1.7446  data_time: 0.0793  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:04:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:04:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:00 d2.utils.events]: \u001b[0m eta: 1:17:15  iter: 2299  total_loss: 1.466  loss_cls: 0.3521  loss_box_reg: 0.561  loss_mask: 0.3021  loss_rpn_cls: 0.09527  loss_rpn_loc: 0.163  time: 1.7404  data_time: 0.0504  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:05:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:40 d2.utils.events]: \u001b[0m eta: 1:17:05  iter: 2319  total_loss: 1.554  loss_cls: 0.3578  loss_box_reg: 0.5821  loss_mask: 0.3034  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.1665  time: 1.7429  data_time: 0.0832  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:05:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:05:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:12 d2.utils.events]: \u001b[0m eta: 1:17:02  iter: 2339  total_loss: 1.474  loss_cls: 0.345  loss_box_reg: 0.5356  loss_mask: 0.2756  loss_rpn_cls: 0.08432  loss_rpn_loc: 0.1654  time: 1.7417  data_time: 0.0778  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:06:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:51 d2.utils.events]: \u001b[0m eta: 1:16:48  iter: 2359  total_loss: 1.52  loss_cls: 0.3839  loss_box_reg: 0.5911  loss_mask: 0.2905  loss_rpn_cls: 0.09415  loss_rpn_loc: 0.154  time: 1.7432  data_time: 0.1743  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:06:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:06:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:46 d2.utils.events]: \u001b[0m eta: 1:16:39  iter: 2379  total_loss: 1.48  loss_cls: 0.3773  loss_box_reg: 0.5721  loss_mask: 0.3033  loss_rpn_cls: 0.09331  loss_rpn_loc: 0.1724  time: 1.7517  data_time: 0.0638  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:07:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:07:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:08:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:08:12 d2.utils.events]: \u001b[0m eta: 1:16:24  iter: 2399  total_loss: 1.468  loss_cls: 0.3538  loss_box_reg: 0.5812  loss_mask: 0.2778  loss_rpn_cls: 0.07808  loss_rpn_loc: 0.1566  time: 1.7480  data_time: 0.0429  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:08:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:08:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:08:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:08:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:08:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:08:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 23:08:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 23:08:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 23:08:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:08:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 23:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1029 s/iter. Eval: 0.0709 s/iter. Total: 0.1746 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/04 23:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0971 s/iter. Eval: 0.0723 s/iter. Total: 0.1703 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/04 23:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0978 s/iter. Eval: 0.0718 s/iter. Total: 0.1704 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 23:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0989 s/iter. Eval: 0.0773 s/iter. Total: 0.1771 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 23:09:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.285252 (0.174873 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:09:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.098395 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:09:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 23:09:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2452743254034972\n",
      "\u001b[32m[02/04 23:09:00 d2.utils.events]: \u001b[0m eta: 1:16:14  iter: 2419  total_loss: 1.521  loss_cls: 0.3658  loss_box_reg: 0.569  loss_mask: 0.2834  loss_rpn_cls: 0.08021  loss_rpn_loc: 0.1712  time: 1.7445  data_time: 0.0526  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:09:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:29 d2.utils.events]: \u001b[0m eta: 1:16:12  iter: 2439  total_loss: 1.468  loss_cls: 0.3652  loss_box_reg: 0.5884  loss_mask: 0.2918  loss_rpn_cls: 0.0946  loss_rpn_loc: 0.18  time: 1.7420  data_time: 0.0481  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:09:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:09:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:19 d2.utils.events]: \u001b[0m eta: 1:16:10  iter: 2459  total_loss: 1.563  loss_cls: 0.3736  loss_box_reg: 0.5841  loss_mask: 0.3042  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.1809  time: 1.7478  data_time: 0.0560  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:10:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:50 d2.utils.events]: \u001b[0m eta: 1:15:53  iter: 2479  total_loss: 1.391  loss_cls: 0.3392  loss_box_reg: 0.5551  loss_mask: 0.2962  loss_rpn_cls: 0.07943  loss_rpn_loc: 0.1298  time: 1.7465  data_time: 0.0568  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:10:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:10:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:24 d2.utils.events]: \u001b[0m eta: 1:15:36  iter: 2499  total_loss: 1.476  loss_cls: 0.3461  loss_box_reg: 0.5583  loss_mask: 0.2976  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.1626  time: 1.7461  data_time: 0.0438  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:11:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:11:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:07 d2.utils.events]: \u001b[0m eta: 1:15:24  iter: 2519  total_loss: 1.497  loss_cls: 0.3623  loss_box_reg: 0.5599  loss_mask: 0.301  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.1804  time: 1.7494  data_time: 0.0852  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:12:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:12:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:06 d2.utils.events]: \u001b[0m eta: 1:15:22  iter: 2539  total_loss: 1.547  loss_cls: 0.3482  loss_box_reg: 0.5761  loss_mask: 0.2979  loss_rpn_cls: 0.115  loss_rpn_loc: 0.2  time: 1.7588  data_time: 0.1149  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:13:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:43 d2.utils.events]: \u001b[0m eta: 1:15:10  iter: 2559  total_loss: 1.606  loss_cls: 0.3928  loss_box_reg: 0.5949  loss_mask: 0.308  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.2017  time: 1.7596  data_time: 0.0323  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:13:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:13:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:16 d2.utils.events]: \u001b[0m eta: 1:14:48  iter: 2579  total_loss: 1.471  loss_cls: 0.3574  loss_box_reg: 0.5465  loss_mask: 0.2926  loss_rpn_cls: 0.09172  loss_rpn_loc: 0.1518  time: 1.7588  data_time: 0.0859  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:14:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:14:51 d2.utils.events]: \u001b[0m eta: 1:14:43  iter: 2599  total_loss: 1.472  loss_cls: 0.3604  loss_box_reg: 0.5544  loss_mask: 0.295  loss_rpn_cls: 0.09525  loss_rpn_loc: 0.1643  time: 1.7585  data_time: 0.0689  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:14:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:16 d2.utils.events]: \u001b[0m eta: 1:14:34  iter: 2619  total_loss: 1.489  loss_cls: 0.3665  loss_box_reg: 0.5625  loss_mask: 0.3106  loss_rpn_cls: 0.07889  loss_rpn_loc: 0.144  time: 1.7547  data_time: 0.0284  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:15:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:15:51 d2.utils.events]: \u001b[0m eta: 1:14:16  iter: 2639  total_loss: 1.431  loss_cls: 0.3288  loss_box_reg: 0.5353  loss_mask: 0.2871  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1758  time: 1.7546  data_time: 0.1320  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:15:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:16:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:16:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:16:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:16:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:16:26 d2.utils.events]: \u001b[0m eta: 1:13:59  iter: 2659  total_loss: 1.403  loss_cls: 0.3248  loss_box_reg: 0.5328  loss_mask: 0.2946  loss_rpn_cls: 0.05949  loss_rpn_loc: 0.1295  time: 1.7547  data_time: 0.1445  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:16:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:16:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:16:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:16:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 23:16:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 23:16:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 23:16:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:16:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 23:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1037 s/iter. Eval: 0.0688 s/iter. Total: 0.1733 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/04 23:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0009 s/iter. Inference: 0.0992 s/iter. Eval: 0.0751 s/iter. Total: 0.1753 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 23:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0978 s/iter. Eval: 0.0720 s/iter. Total: 0.1707 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 23:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0982 s/iter. Eval: 0.0771 s/iter. Total: 0.1761 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 23:16:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.121823 (0.173464 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:16:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097804 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:16:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 23:16:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26734917449154955\n",
      "\u001b[32m[02/04 23:17:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:17:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:17:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:17:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:17:22 d2.utils.events]: \u001b[0m eta: 1:13:46  iter: 2679  total_loss: 1.429  loss_cls: 0.3465  loss_box_reg: 0.5526  loss_mask: 0.2879  loss_rpn_cls: 0.08955  loss_rpn_loc: 0.1523  time: 1.7543  data_time: 0.0543  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:17:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:17:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:17:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:17:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:17:53 d2.utils.events]: \u001b[0m eta: 1:13:34  iter: 2699  total_loss: 1.391  loss_cls: 0.3385  loss_box_reg: 0.5361  loss_mask: 0.2853  loss_rpn_cls: 0.08031  loss_rpn_loc: 0.1583  time: 1.7525  data_time: 0.0975  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:17:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:43 d2.utils.events]: \u001b[0m eta: 1:13:35  iter: 2719  total_loss: 1.521  loss_cls: 0.3644  loss_box_reg: 0.5717  loss_mask: 0.2986  loss_rpn_cls: 0.0917  loss_rpn_loc: 0.1518  time: 1.7580  data_time: 0.1098  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:18:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:18:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:11 d2.utils.events]: \u001b[0m eta: 1:13:27  iter: 2739  total_loss: 1.417  loss_cls: 0.3297  loss_box_reg: 0.5461  loss_mask: 0.2921  loss_rpn_cls: 0.07512  loss_rpn_loc: 0.1537  time: 1.7557  data_time: 0.0421  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:19:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:19:57 d2.utils.events]: \u001b[0m eta: 1:13:15  iter: 2759  total_loss: 1.551  loss_cls: 0.3637  loss_box_reg: 0.5855  loss_mask: 0.2999  loss_rpn_cls: 0.1  loss_rpn_loc: 0.2065  time: 1.7593  data_time: 0.1630  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:19:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:29 d2.utils.events]: \u001b[0m eta: 1:13:03  iter: 2779  total_loss: 1.44  loss_cls: 0.3457  loss_box_reg: 0.5538  loss_mask: 0.2936  loss_rpn_cls: 0.06674  loss_rpn_loc: 0.1519  time: 1.7585  data_time: 0.0558  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:20:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:20:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:21:07 d2.utils.events]: \u001b[0m eta: 1:12:47  iter: 2799  total_loss: 1.425  loss_cls: 0.3562  loss_box_reg: 0.5357  loss_mask: 0.2782  loss_rpn_cls: 0.08318  loss_rpn_loc: 0.1467  time: 1.7593  data_time: 0.0853  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:21:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:21:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:21:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:21:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:21:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:21:43 d2.utils.events]: \u001b[0m eta: 1:12:27  iter: 2819  total_loss: 1.403  loss_cls: 0.3346  loss_box_reg: 0.5495  loss_mask: 0.3009  loss_rpn_cls: 0.08206  loss_rpn_loc: 0.1546  time: 1.7595  data_time: 0.0754  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:21:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:21:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:09 d2.utils.events]: \u001b[0m eta: 1:12:13  iter: 2839  total_loss: 1.416  loss_cls: 0.3394  loss_box_reg: 0.5583  loss_mask: 0.3003  loss_rpn_cls: 0.07334  loss_rpn_loc: 0.1369  time: 1.7564  data_time: 0.0755  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:22:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:46 d2.utils.events]: \u001b[0m eta: 1:12:08  iter: 2859  total_loss: 1.545  loss_cls: 0.3569  loss_box_reg: 0.5529  loss_mask: 0.2856  loss_rpn_cls: 0.09396  loss_rpn_loc: 0.1731  time: 1.7571  data_time: 0.0845  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:22:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:22:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:17 d2.utils.events]: \u001b[0m eta: 1:12:02  iter: 2879  total_loss: 1.43  loss_cls: 0.3546  loss_box_reg: 0.5618  loss_mask: 0.2852  loss_rpn_cls: 0.09015  loss_rpn_loc: 0.1464  time: 1.7556  data_time: 0.0594  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:23:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:45 d2.utils.events]: \u001b[0m eta: 1:11:41  iter: 2899  total_loss: 1.475  loss_cls: 0.3528  loss_box_reg: 0.563  loss_mask: 0.2868  loss_rpn_cls: 0.08161  loss_rpn_loc: 0.1648  time: 1.7530  data_time: 0.0906  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:23:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:23:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:23:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 23:23:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 23:23:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 23:23:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:23:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 23:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1050 s/iter. Eval: 0.0798 s/iter. Total: 0.1857 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/04 23:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0009 s/iter. Inference: 0.1008 s/iter. Eval: 0.0794 s/iter. Total: 0.1812 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 23:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0009 s/iter. Inference: 0.0990 s/iter. Eval: 0.0773 s/iter. Total: 0.1772 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 23:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0009 s/iter. Inference: 0.0988 s/iter. Eval: 0.0822 s/iter. Total: 0.1819 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 23:24:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.682590 (0.178298 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:24:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.098188 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:24:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 23:24:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26382873910593324\n",
      "\u001b[32m[02/04 23:24:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:24:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:24:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:24:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:24:43 d2.utils.events]: \u001b[0m eta: 1:11:26  iter: 2919  total_loss: 1.45  loss_cls: 0.3393  loss_box_reg: 0.566  loss_mask: 0.2951  loss_rpn_cls: 0.08993  loss_rpn_loc: 0.1627  time: 1.7532  data_time: 0.0303  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:24:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:24:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:24:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:26 d2.utils.events]: \u001b[0m eta: 1:11:11  iter: 2939  total_loss: 1.467  loss_cls: 0.3419  loss_box_reg: 0.5607  loss_mask: 0.2928  loss_rpn_cls: 0.08548  loss_rpn_loc: 0.1629  time: 1.7560  data_time: 0.1142  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:25:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:51 d2.utils.events]: \u001b[0m eta: 1:10:57  iter: 2959  total_loss: 1.347  loss_cls: 0.3202  loss_box_reg: 0.5471  loss_mask: 0.2822  loss_rpn_cls: 0.07105  loss_rpn_loc: 0.146  time: 1.7524  data_time: 0.0897  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:25:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:25:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:26:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:26:15 d2.utils.events]: \u001b[0m eta: 1:10:37  iter: 2979  total_loss: 1.42  loss_cls: 0.3449  loss_box_reg: 0.5381  loss_mask: 0.2798  loss_rpn_cls: 0.07678  loss_rpn_loc: 0.1488  time: 1.7487  data_time: 0.1062  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:26:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:26:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:26:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:26:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:26:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:26:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:26:53 d2.utils.events]: \u001b[0m eta: 1:10:25  iter: 2999  total_loss: 1.487  loss_cls: 0.3732  loss_box_reg: 0.5594  loss_mask: 0.2877  loss_rpn_cls: 0.08585  loss_rpn_loc: 0.1667  time: 1.7496  data_time: 0.0526  lr: 0.0004  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:26:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:15 d2.utils.events]: \u001b[0m eta: 1:10:12  iter: 3019  total_loss: 1.421  loss_cls: 0.3313  loss_box_reg: 0.5418  loss_mask: 0.2981  loss_rpn_cls: 0.08432  loss_rpn_loc: 0.151  time: 1.7454  data_time: 0.0606  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:27:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:43 d2.utils.events]: \u001b[0m eta: 1:10:08  iter: 3039  total_loss: 1.407  loss_cls: 0.3457  loss_box_reg: 0.5399  loss_mask: 0.294  loss_rpn_cls: 0.07957  loss_rpn_loc: 0.1434  time: 1.7433  data_time: 0.1102  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:27:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:27:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:36 d2.utils.events]: \u001b[0m eta: 1:09:51  iter: 3059  total_loss: 1.496  loss_cls: 0.3575  loss_box_reg: 0.557  loss_mask: 0.3021  loss_rpn_cls: 0.09023  loss_rpn_loc: 0.1623  time: 1.7493  data_time: 0.0486  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:28:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:28:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:02 d2.utils.events]: \u001b[0m eta: 1:09:49  iter: 3079  total_loss: 1.46  loss_cls: 0.3435  loss_box_reg: 0.5727  loss_mask: 0.3043  loss_rpn_cls: 0.09383  loss_rpn_loc: 0.1576  time: 1.7461  data_time: 0.0632  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:29:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:29:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:15 d2.utils.events]: \u001b[0m eta: 1:09:54  iter: 3099  total_loss: 1.443  loss_cls: 0.3339  loss_box_reg: 0.5435  loss_mask: 0.2969  loss_rpn_cls: 0.08458  loss_rpn_loc: 0.1519  time: 1.7586  data_time: 0.0907  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:30:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:40 d2.utils.events]: \u001b[0m eta: 1:09:39  iter: 3119  total_loss: 1.492  loss_cls: 0.3696  loss_box_reg: 0.555  loss_mask: 0.2907  loss_rpn_cls: 0.09308  loss_rpn_loc: 0.1604  time: 1.7552  data_time: 0.0419  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:30:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:30:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:31:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:31:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:31:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:31:18 d2.utils.events]: \u001b[0m eta: 1:09:22  iter: 3139  total_loss: 1.417  loss_cls: 0.3247  loss_box_reg: 0.5225  loss_mask: 0.2791  loss_rpn_cls: 0.07639  loss_rpn_loc: 0.166  time: 1.7563  data_time: 0.1208  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:31:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:31:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:31:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 23:31:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 23:31:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 23:31:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:31:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 23:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0978 s/iter. Eval: 0.0699 s/iter. Total: 0.1686 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/04 23:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0009 s/iter. Inference: 0.0975 s/iter. Eval: 0.0779 s/iter. Total: 0.1764 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 23:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0009 s/iter. Inference: 0.0970 s/iter. Eval: 0.0748 s/iter. Total: 0.1727 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/04 23:31:45 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0009 s/iter. Inference: 0.0983 s/iter. Eval: 0.0813 s/iter. Total: 0.1805 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 23:31:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.524972 (0.176939 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:31:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097562 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:31:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 23:31:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2704707687928712\n",
      "\u001b[32m[02/04 23:31:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:02 d2.utils.events]: \u001b[0m eta: 1:09:05  iter: 3159  total_loss: 1.516  loss_cls: 0.3633  loss_box_reg: 0.5845  loss_mask: 0.3104  loss_rpn_cls: 0.08745  loss_rpn_loc: 0.1713  time: 1.7519  data_time: 0.0929  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:32:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:38 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 3179  total_loss: 1.282  loss_cls: 0.3165  loss_box_reg: 0.5391  loss_mask: 0.2887  loss_rpn_cls: 0.0639  loss_rpn_loc: 0.1341  time: 1.7522  data_time: 0.1092  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:32:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:32:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:11 d2.utils.events]: \u001b[0m eta: 1:08:40  iter: 3199  total_loss: 1.36  loss_cls: 0.317  loss_box_reg: 0.5315  loss_mask: 0.2801  loss_rpn_cls: 0.07623  loss_rpn_loc: 0.1434  time: 1.7515  data_time: 0.0493  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:33:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:51 d2.utils.events]: \u001b[0m eta: 1:08:33  iter: 3219  total_loss: 1.419  loss_cls: 0.3406  loss_box_reg: 0.5546  loss_mask: 0.2984  loss_rpn_cls: 0.08101  loss_rpn_loc: 0.1428  time: 1.7529  data_time: 0.0635  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:33:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:33:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:46 d2.utils.events]: \u001b[0m eta: 1:08:24  iter: 3239  total_loss: 1.453  loss_cls: 0.3465  loss_box_reg: 0.5579  loss_mask: 0.2874  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.1761  time: 1.7591  data_time: 0.0867  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:34:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:34:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:14 d2.utils.events]: \u001b[0m eta: 1:08:11  iter: 3259  total_loss: 1.368  loss_cls: 0.3448  loss_box_reg: 0.533  loss_mask: 0.2733  loss_rpn_cls: 0.068  loss_rpn_loc: 0.163  time: 1.7569  data_time: 0.0588  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:35:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:48 d2.utils.events]: \u001b[0m eta: 1:07:55  iter: 3279  total_loss: 1.437  loss_cls: 0.357  loss_box_reg: 0.5543  loss_mask: 0.2915  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.1532  time: 1.7567  data_time: 0.1230  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:35:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:35:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:39 d2.utils.events]: \u001b[0m eta: 1:07:45  iter: 3299  total_loss: 1.569  loss_cls: 0.3737  loss_box_reg: 0.6069  loss_mask: 0.3167  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.1702  time: 1.7615  data_time: 0.1338  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:36:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:36:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:20 d2.utils.events]: \u001b[0m eta: 1:07:28  iter: 3319  total_loss: 1.41  loss_cls: 0.3407  loss_box_reg: 0.5428  loss_mask: 0.3011  loss_rpn_cls: 0.0725  loss_rpn_loc: 0.1607  time: 1.7632  data_time: 0.1127  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:37:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:37:57 d2.utils.events]: \u001b[0m eta: 1:07:02  iter: 3339  total_loss: 1.406  loss_cls: 0.3413  loss_box_reg: 0.5482  loss_mask: 0.2906  loss_rpn_cls: 0.07834  loss_rpn_loc: 0.1387  time: 1.7637  data_time: 0.1441  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:38:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:35 d2.utils.events]: \u001b[0m eta: 1:06:52  iter: 3359  total_loss: 1.498  loss_cls: 0.367  loss_box_reg: 0.5672  loss_mask: 0.2962  loss_rpn_cls: 0.09458  loss_rpn_loc: 0.1768  time: 1.7646  data_time: 0.1636  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:38:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:38:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:39:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:39:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:39:22 d2.utils.events]: \u001b[0m eta: 1:06:40  iter: 3379  total_loss: 1.497  loss_cls: 0.3711  loss_box_reg: 0.5488  loss_mask: 0.2863  loss_rpn_cls: 0.08591  loss_rpn_loc: 0.1741  time: 1.7679  data_time: 0.1273  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:39:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:39:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:39:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 23:39:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 23:39:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 23:39:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:39:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 23:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0994 s/iter. Eval: 0.0665 s/iter. Total: 0.1667 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/04 23:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0009 s/iter. Inference: 0.1012 s/iter. Eval: 0.0772 s/iter. Total: 0.1794 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/04 23:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0009 s/iter. Inference: 0.0996 s/iter. Eval: 0.0745 s/iter. Total: 0.1751 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 23:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0009 s/iter. Inference: 0.1000 s/iter. Eval: 0.0799 s/iter. Total: 0.1808 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 23:39:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.891830 (0.180102 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:39:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.100373 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:39:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 23:39:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27027190077899593\n",
      "\u001b[32m[02/04 23:39:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:39:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:40:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:40:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:40:15 d2.utils.events]: \u001b[0m eta: 1:06:35  iter: 3399  total_loss: 1.404  loss_cls: 0.35  loss_box_reg: 0.5172  loss_mask: 0.2801  loss_rpn_cls: 0.07875  loss_rpn_loc: 0.1505  time: 1.7665  data_time: 0.0711  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:40:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:40:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:40:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:40:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:40:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:40:48 d2.utils.events]: \u001b[0m eta: 1:06:23  iter: 3419  total_loss: 1.441  loss_cls: 0.3437  loss_box_reg: 0.5655  loss_mask: 0.3021  loss_rpn_cls: 0.07388  loss_rpn_loc: 0.164  time: 1.7657  data_time: 0.0494  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:40:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:20 d2.utils.events]: \u001b[0m eta: 1:06:05  iter: 3439  total_loss: 1.454  loss_cls: 0.3629  loss_box_reg: 0.5619  loss_mask: 0.2705  loss_rpn_cls: 0.08718  loss_rpn_loc: 0.1413  time: 1.7647  data_time: 0.1391  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:41:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:41:53 d2.utils.events]: \u001b[0m eta: 1:05:49  iter: 3459  total_loss: 1.441  loss_cls: 0.3548  loss_box_reg: 0.5649  loss_mask: 0.2927  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.1592  time: 1.7640  data_time: 0.0650  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:42:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:42:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:42:11 d2.utils.events]: \u001b[0m eta: 1:05:37  iter: 3479  total_loss: 1.432  loss_cls: 0.3476  loss_box_reg: 0.5525  loss_mask: 0.2754  loss_rpn_cls: 0.07845  loss_rpn_loc: 0.1739  time: 1.7592  data_time: 0.0173  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:42:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:42:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:42:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:42:33 d2.utils.events]: \u001b[0m eta: 1:05:21  iter: 3499  total_loss: 1.31  loss_cls: 0.2959  loss_box_reg: 0.5278  loss_mask: 0.2835  loss_rpn_cls: 0.05659  loss_rpn_loc: 0.1331  time: 1.7555  data_time: 0.0382  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:42:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:42:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:42:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:42:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:35 d2.utils.events]: \u001b[0m eta: 1:05:11  iter: 3519  total_loss: 1.513  loss_cls: 0.3714  loss_box_reg: 0.5662  loss_mask: 0.3086  loss_rpn_cls: 0.09919  loss_rpn_loc: 0.1717  time: 1.7630  data_time: 0.1525  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:43:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:43:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:02 d2.utils.events]: \u001b[0m eta: 1:04:50  iter: 3539  total_loss: 1.276  loss_cls: 0.3063  loss_box_reg: 0.521  loss_mask: 0.2849  loss_rpn_cls: 0.06334  loss_rpn_loc: 0.1351  time: 1.7608  data_time: 0.0291  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:44:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:44:52 d2.utils.events]: \u001b[0m eta: 1:04:36  iter: 3559  total_loss: 1.487  loss_cls: 0.3441  loss_box_reg: 0.56  loss_mask: 0.2974  loss_rpn_cls: 0.07424  loss_rpn_loc: 0.1603  time: 1.7647  data_time: 0.0963  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:44:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:27 d2.utils.events]: \u001b[0m eta: 1:04:25  iter: 3579  total_loss: 1.455  loss_cls: 0.3617  loss_box_reg: 0.5557  loss_mask: 0.3055  loss_rpn_cls: 0.06769  loss_rpn_loc: 0.1607  time: 1.7648  data_time: 0.0704  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:45:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:45:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:46:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:46:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:46:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:46:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:46:29 d2.utils.events]: \u001b[0m eta: 1:04:14  iter: 3599  total_loss: 1.463  loss_cls: 0.3739  loss_box_reg: 0.5494  loss_mask: 0.2833  loss_rpn_cls: 0.08481  loss_rpn_loc: 0.1652  time: 1.7723  data_time: 0.2156  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:46:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:46:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:46:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:46:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:47:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:47:04 d2.utils.events]: \u001b[0m eta: 1:04:05  iter: 3619  total_loss: 1.499  loss_cls: 0.368  loss_box_reg: 0.5693  loss_mask: 0.2956  loss_rpn_cls: 0.08717  loss_rpn_loc: 0.1573  time: 1.7722  data_time: 0.0776  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:47:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:47:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:47:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:47:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:47:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:47:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:47:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 23:47:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 23:47:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 23:47:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:47:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 23:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1031 s/iter. Eval: 0.0708 s/iter. Total: 0.1749 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/04 23:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0009 s/iter. Inference: 0.1005 s/iter. Eval: 0.0848 s/iter. Total: 0.1862 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 23:47:42 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0009 s/iter. Inference: 0.0977 s/iter. Eval: 0.0762 s/iter. Total: 0.1749 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 23:47:47 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0009 s/iter. Inference: 0.0978 s/iter. Eval: 0.0813 s/iter. Total: 0.1800 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/04 23:47:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.459523 (0.176375 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:47:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097185 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:47:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 23:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2656938171980313\n",
      "\u001b[32m[02/04 23:47:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:48:02 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 3639  total_loss: 1.453  loss_cls: 0.3707  loss_box_reg: 0.5534  loss_mask: 0.2795  loss_rpn_cls: 0.09972  loss_rpn_loc: 0.1623  time: 1.7721  data_time: 0.0582  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:48:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:48:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:48:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:48:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:48:32 d2.utils.events]: \u001b[0m eta: 1:03:49  iter: 3659  total_loss: 1.396  loss_cls: 0.3511  loss_box_reg: 0.5531  loss_mask: 0.3035  loss_rpn_cls: 0.07682  loss_rpn_loc: 0.1362  time: 1.7705  data_time: 0.1001  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:48:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:48:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:48:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:48:54 d2.utils.events]: \u001b[0m eta: 1:03:33  iter: 3679  total_loss: 1.323  loss_cls: 0.2962  loss_box_reg: 0.5287  loss_mask: 0.2779  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.1655  time: 1.7670  data_time: 0.0163  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:48:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:49:53 d2.utils.events]: \u001b[0m eta: 1:03:25  iter: 3699  total_loss: 1.488  loss_cls: 0.3655  loss_box_reg: 0.5558  loss_mask: 0.2977  loss_rpn_cls: 0.09452  loss_rpn_loc: 0.1832  time: 1.7735  data_time: 0.0974  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:49:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:39 d2.utils.events]: \u001b[0m eta: 1:03:12  iter: 3719  total_loss: 1.546  loss_cls: 0.3763  loss_box_reg: 0.5861  loss_mask: 0.3061  loss_rpn_cls: 0.08568  loss_rpn_loc: 0.1594  time: 1.7763  data_time: 0.1335  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:50:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:50:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:24 d2.utils.events]: \u001b[0m eta: 1:03:13  iter: 3739  total_loss: 1.405  loss_cls: 0.3396  loss_box_reg: 0.5382  loss_mask: 0.2832  loss_rpn_cls: 0.07442  loss_rpn_loc: 0.147  time: 1.7788  data_time: 0.0837  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:51:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:51:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:52:01 d2.utils.events]: \u001b[0m eta: 1:02:48  iter: 3759  total_loss: 1.51  loss_cls: 0.3539  loss_box_reg: 0.56  loss_mask: 0.3037  loss_rpn_cls: 0.08872  loss_rpn_loc: 0.154  time: 1.7792  data_time: 0.0441  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:52:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:52:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:52:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:52:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:52:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:52:35 d2.utils.events]: \u001b[0m eta: 1:02:34  iter: 3779  total_loss: 1.386  loss_cls: 0.3458  loss_box_reg: 0.544  loss_mask: 0.2738  loss_rpn_cls: 0.08597  loss_rpn_loc: 0.1507  time: 1.7788  data_time: 0.0906  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:52:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:52:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:52:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:03 d2.utils.events]: \u001b[0m eta: 1:02:11  iter: 3799  total_loss: 1.356  loss_cls: 0.3147  loss_box_reg: 0.544  loss_mask: 0.2877  loss_rpn_cls: 0.07126  loss_rpn_loc: 0.1295  time: 1.7768  data_time: 0.0975  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:53:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:41 d2.utils.events]: \u001b[0m eta: 1:02:02  iter: 3819  total_loss: 1.485  loss_cls: 0.3687  loss_box_reg: 0.5674  loss_mask: 0.3041  loss_rpn_cls: 0.09732  loss_rpn_loc: 0.1865  time: 1.7774  data_time: 0.1196  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:53:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:53:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:54:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:54:15 d2.utils.events]: \u001b[0m eta: 1:01:48  iter: 3839  total_loss: 1.464  loss_cls: 0.34  loss_box_reg: 0.5752  loss_mask: 0.3055  loss_rpn_cls: 0.08044  loss_rpn_loc: 0.1506  time: 1.7769  data_time: 0.0556  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:54:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:54:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:54:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:54:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:54:45 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 3859  total_loss: 1.358  loss_cls: 0.3271  loss_box_reg: 0.5346  loss_mask: 0.2874  loss_rpn_cls: 0.07625  loss_rpn_loc: 0.1519  time: 1.7755  data_time: 0.1247  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:54:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:54:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:54:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:55:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:55:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:55:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/04 23:55:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/04 23:55:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/04 23:55:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/04 23:55:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/04 23:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0027 s/iter. Inference: 0.1006 s/iter. Eval: 0.0708 s/iter. Total: 0.1741 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/04 23:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0013 s/iter. Inference: 0.1023 s/iter. Eval: 0.0864 s/iter. Total: 0.1901 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/04 23:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0012 s/iter. Inference: 0.0995 s/iter. Eval: 0.0789 s/iter. Total: 0.1796 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/04 23:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0011 s/iter. Inference: 0.0991 s/iter. Eval: 0.0834 s/iter. Total: 0.1836 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/04 23:55:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.919921 (0.180344 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:55:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.098918 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/04 23:55:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/04 23:55:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2595705963495848\n",
      "\u001b[32m[02/04 23:55:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:55:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:55:42 d2.utils.events]: \u001b[0m eta: 1:01:23  iter: 3879  total_loss: 1.4  loss_cls: 0.3532  loss_box_reg: 0.5455  loss_mask: 0.2944  loss_rpn_cls: 0.08366  loss_rpn_loc: 0.1492  time: 1.7752  data_time: 0.0500  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:55:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:55:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:55:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:08 d2.utils.events]: \u001b[0m eta: 1:01:11  iter: 3899  total_loss: 1.374  loss_cls: 0.3324  loss_box_reg: 0.5252  loss_mask: 0.2786  loss_rpn_cls: 0.0758  loss_rpn_loc: 0.1314  time: 1.7729  data_time: 0.0516  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:56:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:56:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:05 d2.utils.events]: \u001b[0m eta: 1:01:00  iter: 3919  total_loss: 1.456  loss_cls: 0.376  loss_box_reg: 0.5582  loss_mask: 0.2947  loss_rpn_cls: 0.08721  loss_rpn_loc: 0.1449  time: 1.7783  data_time: 0.0616  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:57:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:32 d2.utils.events]: \u001b[0m eta: 1:00:47  iter: 3939  total_loss: 1.321  loss_cls: 0.3244  loss_box_reg: 0.5243  loss_mask: 0.2724  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1391  time: 1.7760  data_time: 0.0671  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:57:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:57:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:58:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:58:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:58:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:58:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:58:21 d2.utils.events]: \u001b[0m eta: 1:00:45  iter: 3959  total_loss: 1.452  loss_cls: 0.359  loss_box_reg: 0.551  loss_mask: 0.2948  loss_rpn_cls: 0.07356  loss_rpn_loc: 0.1513  time: 1.7793  data_time: 0.0871  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:58:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:58:35 d2.utils.events]: \u001b[0m eta: 1:00:24  iter: 3979  total_loss: 1.327  loss_cls: 0.3278  loss_box_reg: 0.5183  loss_mask: 0.2729  loss_rpn_cls: 0.07947  loss_rpn_loc: 0.1408  time: 1.7740  data_time: 0.0180  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:58:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:58:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:58:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:14 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 3999  total_loss: 1.424  loss_cls: 0.3629  loss_box_reg: 0.5456  loss_mask: 0.2894  loss_rpn_cls: 0.0794  loss_rpn_loc: 0.1437  time: 1.7749  data_time: 0.1241  lr: 0.00032  max_mem: 9510M\n",
      "\u001b[32m[02/04 23:59:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/04 23:59:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:18 d2.utils.events]: \u001b[0m eta: 1:00:13  iter: 4019  total_loss: 1.443  loss_cls: 0.3429  loss_box_reg: 0.5419  loss_mask: 0.3109  loss_rpn_cls: 0.07847  loss_rpn_loc: 0.155  time: 1.7820  data_time: 0.0957  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:00:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:00:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:13 d2.utils.events]: \u001b[0m eta: 1:00:08  iter: 4039  total_loss: 1.514  loss_cls: 0.3867  loss_box_reg: 0.5664  loss_mask: 0.2923  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.1679  time: 1.7868  data_time: 0.0355  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:01:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:51 d2.utils.events]: \u001b[0m eta: 0:59:54  iter: 4059  total_loss: 1.407  loss_cls: 0.3506  loss_box_reg: 0.5494  loss_mask: 0.2845  loss_rpn_cls: 0.0958  loss_rpn_loc: 0.164  time: 1.7873  data_time: 0.0451  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:01:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:01:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:26 d2.utils.events]: \u001b[0m eta: 0:59:35  iter: 4079  total_loss: 1.345  loss_cls: 0.312  loss_box_reg: 0.5421  loss_mask: 0.2838  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.1429  time: 1.7873  data_time: 0.1472  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:02:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:02:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:03:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:03:08 d2.utils.events]: \u001b[0m eta: 0:59:23  iter: 4099  total_loss: 1.612  loss_cls: 0.4051  loss_box_reg: 0.5862  loss_mask: 0.301  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.1849  time: 1.7887  data_time: 0.0698  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:03:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:03:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:03:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:03:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 00:03:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 00:03:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 00:03:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:03:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 00:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1034 s/iter. Eval: 0.0633 s/iter. Total: 0.1676 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 00:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0010 s/iter. Inference: 0.1032 s/iter. Eval: 0.0904 s/iter. Total: 0.1946 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 00:03:36 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0009 s/iter. Inference: 0.1002 s/iter. Eval: 0.0800 s/iter. Total: 0.1811 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 00:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.1001 s/iter. Eval: 0.0836 s/iter. Total: 0.1846 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 00:03:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.777950 (0.179120 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:03:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.098964 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:03:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 00:03:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26843108170153407\n",
      "\u001b[32m[02/05 00:03:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:03:54 d2.utils.events]: \u001b[0m eta: 0:58:59  iter: 4119  total_loss: 1.428  loss_cls: 0.3527  loss_box_reg: 0.5715  loss_mask: 0.2726  loss_rpn_cls: 0.08753  loss_rpn_loc: 0.1516  time: 1.7856  data_time: 0.0516  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:03:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:28 d2.utils.events]: \u001b[0m eta: 0:58:46  iter: 4139  total_loss: 1.473  loss_cls: 0.3485  loss_box_reg: 0.5575  loss_mask: 0.2834  loss_rpn_cls: 0.08919  loss_rpn_loc: 0.1501  time: 1.7853  data_time: 0.1384  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:04:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:53 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 4159  total_loss: 1.352  loss_cls: 0.3358  loss_box_reg: 0.526  loss_mask: 0.2824  loss_rpn_cls: 0.064  loss_rpn_loc: 0.1378  time: 1.7828  data_time: 0.0748  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:04:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:04:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:45 d2.utils.events]: \u001b[0m eta: 0:58:35  iter: 4179  total_loss: 1.42  loss_cls: 0.3544  loss_box_reg: 0.5616  loss_mask: 0.2952  loss_rpn_cls: 0.07041  loss_rpn_loc: 0.1455  time: 1.7865  data_time: 0.0704  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:05:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:05:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:11 d2.utils.events]: \u001b[0m eta: 0:58:19  iter: 4199  total_loss: 1.451  loss_cls: 0.3393  loss_box_reg: 0.556  loss_mask: 0.2914  loss_rpn_cls: 0.07753  loss_rpn_loc: 0.1612  time: 1.7844  data_time: 0.0350  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:06:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:37 d2.utils.events]: \u001b[0m eta: 0:57:58  iter: 4219  total_loss: 1.354  loss_cls: 0.3293  loss_box_reg: 0.5242  loss_mask: 0.274  loss_rpn_cls: 0.07071  loss_rpn_loc: 0.1519  time: 1.7821  data_time: 0.0549  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:06:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:06:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:07:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:07:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:07:16 d2.utils.events]: \u001b[0m eta: 0:57:38  iter: 4239  total_loss: 1.364  loss_cls: 0.3348  loss_box_reg: 0.5478  loss_mask: 0.3021  loss_rpn_cls: 0.07426  loss_rpn_loc: 0.1351  time: 1.7827  data_time: 0.1236  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:07:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:07:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:07:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:07:41 d2.utils.events]: \u001b[0m eta: 0:57:26  iter: 4259  total_loss: 1.264  loss_cls: 0.3177  loss_box_reg: 0.5122  loss_mask: 0.2739  loss_rpn_cls: 0.06932  loss_rpn_loc: 0.1366  time: 1.7802  data_time: 0.0870  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:07:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:07:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:07:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:18 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 4279  total_loss: 1.367  loss_cls: 0.3392  loss_box_reg: 0.5245  loss_mask: 0.2881  loss_rpn_cls: 0.08139  loss_rpn_loc: 0.1438  time: 1.7805  data_time: 0.1843  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:08:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:43 d2.utils.events]: \u001b[0m eta: 0:57:11  iter: 4299  total_loss: 1.55  loss_cls: 0.373  loss_box_reg: 0.5813  loss_mask: 0.3066  loss_rpn_cls: 0.08004  loss_rpn_loc: 0.1735  time: 1.7782  data_time: 0.0933  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:08:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:08:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:34 d2.utils.events]: \u001b[0m eta: 0:57:06  iter: 4319  total_loss: 1.436  loss_cls: 0.3632  loss_box_reg: 0.5508  loss_mask: 0.2935  loss_rpn_cls: 0.08615  loss_rpn_loc: 0.1559  time: 1.7817  data_time: 0.0662  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:09:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:09:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:29 d2.utils.events]: \u001b[0m eta: 0:56:58  iter: 4339  total_loss: 1.483  loss_cls: 0.3692  loss_box_reg: 0.573  loss_mask: 0.3071  loss_rpn_cls: 0.09436  loss_rpn_loc: 0.1892  time: 1.7862  data_time: 0.0662  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:10:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:10:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:11:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:11:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 00:11:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 00:11:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 00:11:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:11:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 00:11:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0990 s/iter. Eval: 0.0678 s/iter. Total: 0.1678 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 00:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 34/121. Dataloading: 0.0016 s/iter. Inference: 0.1053 s/iter. Eval: 0.1033 s/iter. Total: 0.2102 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 00:11:12 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0013 s/iter. Inference: 0.1029 s/iter. Eval: 0.0921 s/iter. Total: 0.1963 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 00:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0011 s/iter. Inference: 0.1024 s/iter. Eval: 0.0944 s/iter. Total: 0.1980 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 00:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0010 s/iter. Inference: 0.1010 s/iter. Eval: 0.0879 s/iter. Total: 0.1901 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 00:11:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.354342 (0.192710 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:11:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.101284 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:11:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 00:11:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27127322796150066\n",
      "\u001b[32m[02/05 00:11:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:11:30 d2.utils.events]: \u001b[0m eta: 0:56:46  iter: 4359  total_loss: 1.407  loss_cls: 0.3368  loss_box_reg: 0.5662  loss_mask: 0.2773  loss_rpn_cls: 0.07232  loss_rpn_loc: 0.1371  time: 1.7865  data_time: 0.0926  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:11:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:11:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:11:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:11:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:11:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:11:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:15 d2.utils.events]: \u001b[0m eta: 0:56:28  iter: 4379  total_loss: 1.479  loss_cls: 0.3565  loss_box_reg: 0.5715  loss_mask: 0.2984  loss_rpn_cls: 0.07787  loss_rpn_loc: 0.1495  time: 1.7885  data_time: 0.1153  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:12:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:12:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:13:02 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 4399  total_loss: 1.499  loss_cls: 0.3592  loss_box_reg: 0.5367  loss_mask: 0.2941  loss_rpn_cls: 0.09954  loss_rpn_loc: 0.1745  time: 1.7911  data_time: 0.0888  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:13:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:13:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:13:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:13:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:13:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:13:32 d2.utils.events]: \u001b[0m eta: 0:56:09  iter: 4419  total_loss: 1.392  loss_cls: 0.3463  loss_box_reg: 0.5206  loss_mask: 0.2831  loss_rpn_cls: 0.08522  loss_rpn_loc: 0.1476  time: 1.7897  data_time: 0.0163  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:13:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:13:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:13:52 d2.utils.events]: \u001b[0m eta: 0:55:52  iter: 4439  total_loss: 1.361  loss_cls: 0.336  loss_box_reg: 0.5405  loss_mask: 0.2721  loss_rpn_cls: 0.06402  loss_rpn_loc: 0.1287  time: 1.7861  data_time: 0.0549  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:13:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:31 d2.utils.events]: \u001b[0m eta: 0:55:42  iter: 4459  total_loss: 1.413  loss_cls: 0.3428  loss_box_reg: 0.5503  loss_mask: 0.279  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.1888  time: 1.7870  data_time: 0.0575  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:14:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:14:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:11 d2.utils.events]: \u001b[0m eta: 0:55:33  iter: 4479  total_loss: 1.407  loss_cls: 0.3482  loss_box_reg: 0.5401  loss_mask: 0.2902  loss_rpn_cls: 0.06742  loss_rpn_loc: 0.1551  time: 1.7879  data_time: 0.1295  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:15:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:15:59 d2.utils.events]: \u001b[0m eta: 0:55:31  iter: 4499  total_loss: 1.474  loss_cls: 0.3613  loss_box_reg: 0.5658  loss_mask: 0.2991  loss_rpn_cls: 0.08497  loss_rpn_loc: 0.1552  time: 1.7905  data_time: 0.1059  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:16:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:16:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:16:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:16:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:16:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:16:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:16:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:16:44 d2.utils.events]: \u001b[0m eta: 0:55:19  iter: 4519  total_loss: 1.519  loss_cls: 0.3609  loss_box_reg: 0.5676  loss_mask: 0.2871  loss_rpn_cls: 0.07765  loss_rpn_loc: 0.162  time: 1.7926  data_time: 0.0485  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:16:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:16:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:19 d2.utils.events]: \u001b[0m eta: 0:55:16  iter: 4539  total_loss: 1.471  loss_cls: 0.3597  loss_box_reg: 0.5753  loss_mask: 0.3026  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.1593  time: 1.7924  data_time: 0.0613  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:17:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:17:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:18:04 d2.utils.events]: \u001b[0m eta: 0:55:05  iter: 4559  total_loss: 1.399  loss_cls: 0.3447  loss_box_reg: 0.5497  loss_mask: 0.3006  loss_rpn_cls: 0.07921  loss_rpn_loc: 0.1436  time: 1.7945  data_time: 0.0301  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:18:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:18:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:18:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:18:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:18:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:18:42 d2.utils.events]: \u001b[0m eta: 0:54:55  iter: 4579  total_loss: 1.394  loss_cls: 0.3456  loss_box_reg: 0.5331  loss_mask: 0.2842  loss_rpn_cls: 0.07602  loss_rpn_loc: 0.1441  time: 1.7948  data_time: 0.1670  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:18:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:18:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:19:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:19:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:19:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:19:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 00:19:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 00:19:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 00:19:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:19:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 00:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0980 s/iter. Eval: 0.0684 s/iter. Total: 0.1672 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 00:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0009 s/iter. Inference: 0.1033 s/iter. Eval: 0.0920 s/iter. Total: 0.1963 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 00:19:22 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0009 s/iter. Inference: 0.1022 s/iter. Eval: 0.0884 s/iter. Total: 0.1916 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 00:19:27 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0009 s/iter. Inference: 0.1014 s/iter. Eval: 0.0886 s/iter. Total: 0.1910 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 00:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0009 s/iter. Inference: 0.1000 s/iter. Eval: 0.0839 s/iter. Total: 0.1848 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 00:19:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.594009 (0.186155 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:19:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.100076 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:19:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 00:19:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2729501881206704\n",
      "\u001b[32m[02/05 00:19:34 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 4599  total_loss: 1.378  loss_cls: 0.3425  loss_box_reg: 0.5816  loss_mask: 0.3236  loss_rpn_cls: 0.0771  loss_rpn_loc: 0.1463  time: 1.7932  data_time: 0.0694  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:19:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:19:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:19:56 d2.utils.events]: \u001b[0m eta: 0:54:40  iter: 4619  total_loss: 1.454  loss_cls: 0.357  loss_box_reg: 0.5751  loss_mask: 0.2984  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.1645  time: 1.7903  data_time: 0.0809  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:20:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:24 d2.utils.events]: \u001b[0m eta: 0:54:29  iter: 4639  total_loss: 1.504  loss_cls: 0.3701  loss_box_reg: 0.5698  loss_mask: 0.3077  loss_rpn_cls: 0.0801  loss_rpn_loc: 0.1536  time: 1.7886  data_time: 0.0618  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:20:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:20:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:00 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 4659  total_loss: 1.45  loss_cls: 0.3726  loss_box_reg: 0.5703  loss_mask: 0.2974  loss_rpn_cls: 0.08067  loss_rpn_loc: 0.1585  time: 1.7887  data_time: 0.0763  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:21:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:21:54 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 4679  total_loss: 1.449  loss_cls: 0.3606  loss_box_reg: 0.5308  loss_mask: 0.2916  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.1632  time: 1.7924  data_time: 0.1796  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:21:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:18 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 4699  total_loss: 1.384  loss_cls: 0.3372  loss_box_reg: 0.5392  loss_mask: 0.2835  loss_rpn_cls: 0.05556  loss_rpn_loc: 0.1361  time: 1.7901  data_time: 0.0893  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:22:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:22:59 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 4719  total_loss: 1.416  loss_cls: 0.3402  loss_box_reg: 0.4963  loss_mask: 0.2839  loss_rpn_cls: 0.08318  loss_rpn_loc: 0.1437  time: 1.7912  data_time: 0.1637  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:23:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:30 d2.utils.events]: \u001b[0m eta: 0:53:17  iter: 4739  total_loss: 1.385  loss_cls: 0.3205  loss_box_reg: 0.5324  loss_mask: 0.2834  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.1499  time: 1.7901  data_time: 0.1059  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:23:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:23:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:13 d2.utils.events]: \u001b[0m eta: 0:53:12  iter: 4759  total_loss: 1.546  loss_cls: 0.3736  loss_box_reg: 0.5768  loss_mask: 0.2839  loss_rpn_cls: 0.09816  loss_rpn_loc: 0.182  time: 1.7916  data_time: 0.0801  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:24:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:24:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:25:04 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 4779  total_loss: 1.405  loss_cls: 0.3217  loss_box_reg: 0.5365  loss_mask: 0.2977  loss_rpn_cls: 0.07327  loss_rpn_loc: 0.1603  time: 1.7947  data_time: 0.1312  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:25:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:25:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:25:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:25:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:25:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:25:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:25:41 d2.utils.events]: \u001b[0m eta: 0:53:05  iter: 4799  total_loss: 1.476  loss_cls: 0.3622  loss_box_reg: 0.5617  loss_mask: 0.3008  loss_rpn_cls: 0.07777  loss_rpn_loc: 0.161  time: 1.7950  data_time: 0.0385  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:25:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:25:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:26:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:26:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:26:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:26:17 d2.utils.events]: \u001b[0m eta: 0:52:52  iter: 4819  total_loss: 1.396  loss_cls: 0.3332  loss_box_reg: 0.5693  loss_mask: 0.3059  loss_rpn_cls: 0.07443  loss_rpn_loc: 0.1452  time: 1.7951  data_time: 0.1378  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:26:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:26:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:26:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:26:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:26:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 00:26:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 00:26:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 00:26:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:26:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 00:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.1058 s/iter. Eval: 0.0681 s/iter. Total: 0.1749 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 00:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0010 s/iter. Inference: 0.1025 s/iter. Eval: 0.0882 s/iter. Total: 0.1918 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 00:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1018 s/iter. Eval: 0.0859 s/iter. Total: 0.1889 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 00:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0010 s/iter. Inference: 0.1008 s/iter. Eval: 0.0869 s/iter. Total: 0.1888 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 00:27:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.219914 (0.182930 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:27:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.099645 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:27:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 00:27:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26569553279130803\n",
      "\u001b[32m[02/05 00:27:06 d2.utils.events]: \u001b[0m eta: 0:52:39  iter: 4839  total_loss: 1.328  loss_cls: 0.3171  loss_box_reg: 0.5257  loss_mask: 0.2845  loss_rpn_cls: 0.06898  loss_rpn_loc: 0.1496  time: 1.7929  data_time: 0.0760  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:27:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:27:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:27:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:27:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:27:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:27:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:27:47 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 4859  total_loss: 1.38  loss_cls: 0.331  loss_box_reg: 0.5692  loss_mask: 0.2862  loss_rpn_cls: 0.07357  loss_rpn_loc: 0.1485  time: 1.7940  data_time: 0.1281  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:27:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:27:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:21 d2.utils.events]: \u001b[0m eta: 0:52:10  iter: 4879  total_loss: 1.411  loss_cls: 0.3657  loss_box_reg: 0.5459  loss_mask: 0.2981  loss_rpn_cls: 0.0803  loss_rpn_loc: 0.1455  time: 1.7937  data_time: 0.0366  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:28:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:28:57 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 4899  total_loss: 1.426  loss_cls: 0.3527  loss_box_reg: 0.5679  loss_mask: 0.2929  loss_rpn_cls: 0.07275  loss_rpn_loc: 0.1539  time: 1.7936  data_time: 0.0538  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:28:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:40 d2.utils.events]: \u001b[0m eta: 0:51:50  iter: 4919  total_loss: 1.468  loss_cls: 0.3648  loss_box_reg: 0.5502  loss_mask: 0.2973  loss_rpn_cls: 0.08934  loss_rpn_loc: 0.1783  time: 1.7952  data_time: 0.0744  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:29:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:29:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:07 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 4939  total_loss: 1.297  loss_cls: 0.3296  loss_box_reg: 0.4955  loss_mask: 0.2764  loss_rpn_cls: 0.05018  loss_rpn_loc: 0.1283  time: 1.7932  data_time: 0.0299  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:30:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:44 d2.utils.events]: \u001b[0m eta: 0:51:15  iter: 4959  total_loss: 1.412  loss_cls: 0.3365  loss_box_reg: 0.5488  loss_mask: 0.2886  loss_rpn_cls: 0.07667  loss_rpn_loc: 0.1365  time: 1.7936  data_time: 0.0735  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:30:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:30:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:27 d2.utils.events]: \u001b[0m eta: 0:51:17  iter: 4979  total_loss: 1.371  loss_cls: 0.3386  loss_box_reg: 0.5462  loss_mask: 0.285  loss_rpn_cls: 0.06818  loss_rpn_loc: 0.1519  time: 1.7951  data_time: 0.1211  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:31:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:31:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:10 d2.utils.events]: \u001b[0m eta: 0:50:59  iter: 4999  total_loss: 1.367  loss_cls: 0.3374  loss_box_reg: 0.5338  loss_mask: 0.2881  loss_rpn_cls: 0.06393  loss_rpn_loc: 0.1448  time: 1.7964  data_time: 0.0716  lr: 0.000256  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:32:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:32:55 d2.utils.events]: \u001b[0m eta: 0:50:47  iter: 5019  total_loss: 1.41  loss_cls: 0.3412  loss_box_reg: 0.5725  loss_mask: 0.3029  loss_rpn_cls: 0.08257  loss_rpn_loc: 0.1414  time: 1.7981  data_time: 0.1020  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:32:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:25 d2.utils.events]: \u001b[0m eta: 0:50:25  iter: 5039  total_loss: 1.447  loss_cls: 0.3412  loss_box_reg: 0.5585  loss_mask: 0.2758  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.15  time: 1.7970  data_time: 0.1183  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:33:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:33:58 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 5059  total_loss: 1.498  loss_cls: 0.3528  loss_box_reg: 0.5792  loss_mask: 0.3073  loss_rpn_cls: 0.07899  loss_rpn_loc: 0.1593  time: 1.7964  data_time: 0.0251  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:34:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:34:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:34:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:34:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:34:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:34:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:34:40 d2.utils.events]: \u001b[0m eta: 0:50:01  iter: 5079  total_loss: 1.418  loss_cls: 0.3513  loss_box_reg: 0.5222  loss_mask: 0.2949  loss_rpn_cls: 0.07802  loss_rpn_loc: 0.1593  time: 1.7975  data_time: 0.1442  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:34:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:34:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 00:34:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 00:34:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 00:34:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:34:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 00:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1026 s/iter. Eval: 0.0658 s/iter. Total: 0.1692 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 00:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0019 s/iter. Inference: 0.1021 s/iter. Eval: 0.0912 s/iter. Total: 0.1953 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 00:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0015 s/iter. Inference: 0.1018 s/iter. Eval: 0.0906 s/iter. Total: 0.1940 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 00:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0013 s/iter. Inference: 0.1008 s/iter. Eval: 0.0906 s/iter. Total: 0.1927 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 00:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0012 s/iter. Inference: 0.0994 s/iter. Eval: 0.0850 s/iter. Total: 0.1857 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 00:35:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.652390 (0.186659 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:35:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.099444 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:35:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 00:35:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27186307091330925\n",
      "\u001b[32m[02/05 00:35:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:35:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:35:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:35:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:35:34 d2.utils.events]: \u001b[0m eta: 0:49:39  iter: 5099  total_loss: 1.317  loss_cls: 0.3227  loss_box_reg: 0.5181  loss_mask: 0.2777  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.1317  time: 1.7965  data_time: 0.0962  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:35:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:35:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:35:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:35:58 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 5119  total_loss: 1.285  loss_cls: 0.3114  loss_box_reg: 0.5423  loss_mask: 0.2839  loss_rpn_cls: 0.06315  loss_rpn_loc: 0.1202  time: 1.7942  data_time: 0.0498  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:36:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:36:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:36:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:36:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:36:27 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 5139  total_loss: 1.358  loss_cls: 0.3472  loss_box_reg: 0.5322  loss_mask: 0.2828  loss_rpn_cls: 0.08993  loss_rpn_loc: 0.1404  time: 1.7928  data_time: 0.0850  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:36:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:36:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:36:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:36:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:36:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:06 d2.utils.events]: \u001b[0m eta: 0:49:12  iter: 5159  total_loss: 1.307  loss_cls: 0.3284  loss_box_reg: 0.5214  loss_mask: 0.2811  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.1309  time: 1.7934  data_time: 0.0409  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:37:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:37:51 d2.utils.events]: \u001b[0m eta: 0:48:57  iter: 5179  total_loss: 1.415  loss_cls: 0.3359  loss_box_reg: 0.5408  loss_mask: 0.2945  loss_rpn_cls: 0.07488  loss_rpn_loc: 0.1573  time: 1.7952  data_time: 0.1656  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:37:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:22 d2.utils.events]: \u001b[0m eta: 0:48:42  iter: 5199  total_loss: 1.548  loss_cls: 0.3644  loss_box_reg: 0.5888  loss_mask: 0.3133  loss_rpn_cls: 0.112  loss_rpn_loc: 0.1662  time: 1.7943  data_time: 0.1005  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:38:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:38:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:39:01 d2.utils.events]: \u001b[0m eta: 0:48:35  iter: 5219  total_loss: 1.394  loss_cls: 0.3361  loss_box_reg: 0.5283  loss_mask: 0.2864  loss_rpn_cls: 0.0763  loss_rpn_loc: 0.1518  time: 1.7949  data_time: 0.1388  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:39:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:39:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:39:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:39:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:39:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:39:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:39:42 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 5239  total_loss: 1.44  loss_cls: 0.3505  loss_box_reg: 0.5528  loss_mask: 0.3077  loss_rpn_cls: 0.08793  loss_rpn_loc: 0.1545  time: 1.7959  data_time: 0.0756  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:39:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:39:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:15 d2.utils.events]: \u001b[0m eta: 0:48:11  iter: 5259  total_loss: 1.42  loss_cls: 0.3603  loss_box_reg: 0.5422  loss_mask: 0.2782  loss_rpn_cls: 0.07233  loss_rpn_loc: 0.1471  time: 1.7954  data_time: 0.0845  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:40:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:49 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 5279  total_loss: 1.341  loss_cls: 0.3472  loss_box_reg: 0.5321  loss_mask: 0.2908  loss_rpn_cls: 0.05828  loss_rpn_loc: 0.129  time: 1.7950  data_time: 0.0963  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:40:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:40:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:34 d2.utils.events]: \u001b[0m eta: 0:47:46  iter: 5299  total_loss: 1.468  loss_cls: 0.383  loss_box_reg: 0.5657  loss_mask: 0.2969  loss_rpn_cls: 0.09194  loss_rpn_loc: 0.1895  time: 1.7966  data_time: 0.0657  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:41:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:41:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:42:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:42:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:42:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:42:19 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 5319  total_loss: 1.39  loss_cls: 0.3442  loss_box_reg: 0.5427  loss_mask: 0.2889  loss_rpn_cls: 0.06432  loss_rpn_loc: 0.1609  time: 1.7983  data_time: 0.0834  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:42:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:42:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 00:42:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 00:42:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 00:42:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:42:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 00:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1060 s/iter. Eval: 0.0645 s/iter. Total: 0.1714 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 00:42:29 d2.evaluation.evaluator]: \u001b[0mInference done 35/121. Dataloading: 0.0020 s/iter. Inference: 0.1057 s/iter. Eval: 0.0940 s/iter. Total: 0.2018 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 00:42:34 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0015 s/iter. Inference: 0.1034 s/iter. Eval: 0.0909 s/iter. Total: 0.1959 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 00:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0014 s/iter. Inference: 0.1028 s/iter. Eval: 0.0941 s/iter. Total: 0.1983 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 00:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0013 s/iter. Inference: 0.1011 s/iter. Eval: 0.0874 s/iter. Total: 0.1899 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 00:42:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.241600 (0.191738 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:42:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.101231 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:42:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 00:42:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2747748638766763\n",
      "\u001b[32m[02/05 00:42:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:42:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:18 d2.utils.events]: \u001b[0m eta: 0:47:17  iter: 5339  total_loss: 1.385  loss_cls: 0.3481  loss_box_reg: 0.5223  loss_mask: 0.2858  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.13  time: 1.7981  data_time: 0.1179  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:43:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:43:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:07 d2.utils.events]: \u001b[0m eta: 0:47:09  iter: 5359  total_loss: 1.441  loss_cls: 0.3604  loss_box_reg: 0.5596  loss_mask: 0.2982  loss_rpn_cls: 0.078  loss_rpn_loc: 0.1487  time: 1.8006  data_time: 0.0463  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:44:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:44:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:45:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:45:09 d2.utils.events]: \u001b[0m eta: 0:47:00  iter: 5379  total_loss: 1.469  loss_cls: 0.3505  loss_box_reg: 0.5734  loss_mask: 0.3099  loss_rpn_cls: 0.08659  loss_rpn_loc: 0.196  time: 1.8054  data_time: 0.0306  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:45:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:45:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:45:30 d2.utils.events]: \u001b[0m eta: 0:46:44  iter: 5399  total_loss: 1.401  loss_cls: 0.3444  loss_box_reg: 0.5512  loss_mask: 0.2818  loss_rpn_cls: 0.08359  loss_rpn_loc: 0.1618  time: 1.8025  data_time: 0.0195  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:45:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:45:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:45:51 d2.utils.events]: \u001b[0m eta: 0:46:26  iter: 5419  total_loss: 1.366  loss_cls: 0.3152  loss_box_reg: 0.5356  loss_mask: 0.2725  loss_rpn_cls: 0.0501  loss_rpn_loc: 0.162  time: 1.7998  data_time: 0.0850  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:45:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:45:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:35 d2.utils.events]: \u001b[0m eta: 0:46:21  iter: 5439  total_loss: 1.562  loss_cls: 0.4027  loss_box_reg: 0.5568  loss_mask: 0.2934  loss_rpn_cls: 0.08847  loss_rpn_loc: 0.1895  time: 1.8012  data_time: 0.0564  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:46:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:46:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:33 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 5459  total_loss: 1.39  loss_cls: 0.3538  loss_box_reg: 0.5298  loss_mask: 0.291  loss_rpn_cls: 0.07378  loss_rpn_loc: 0.1773  time: 1.8054  data_time: 0.0646  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:47:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:47:59 d2.utils.events]: \u001b[0m eta: 0:45:57  iter: 5479  total_loss: 1.348  loss_cls: 0.328  loss_box_reg: 0.5319  loss_mask: 0.2866  loss_rpn_cls: 0.06584  loss_rpn_loc: 0.1421  time: 1.8034  data_time: 0.0642  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:48:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:48:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:48:19 d2.utils.events]: \u001b[0m eta: 0:45:34  iter: 5499  total_loss: 1.191  loss_cls: 0.2878  loss_box_reg: 0.5042  loss_mask: 0.2743  loss_rpn_cls: 0.04306  loss_rpn_loc: 0.1132  time: 1.8006  data_time: 0.0138  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:48:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:48:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:48:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:48:51 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 5519  total_loss: 1.438  loss_cls: 0.3578  loss_box_reg: 0.5431  loss_mask: 0.3075  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.165  time: 1.7998  data_time: 0.1004  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:48:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:26 d2.utils.events]: \u001b[0m eta: 0:45:10  iter: 5539  total_loss: 1.439  loss_cls: 0.3559  loss_box_reg: 0.5544  loss_mask: 0.2897  loss_rpn_cls: 0.09054  loss_rpn_loc: 0.1401  time: 1.7997  data_time: 0.0894  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:49:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:49:59 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 5559  total_loss: 1.384  loss_cls: 0.323  loss_box_reg: 0.5677  loss_mask: 0.2882  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.1291  time: 1.7992  data_time: 0.0921  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:50:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:50:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:50:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:50:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 00:50:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 00:50:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 00:50:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:50:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 00:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1032 s/iter. Eval: 0.0653 s/iter. Total: 0.1693 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 00:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0009 s/iter. Inference: 0.1047 s/iter. Eval: 0.0899 s/iter. Total: 0.1957 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 00:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0017 s/iter. Inference: 0.1049 s/iter. Eval: 0.0911 s/iter. Total: 0.1977 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 00:50:33 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0015 s/iter. Inference: 0.1048 s/iter. Eval: 0.0971 s/iter. Total: 0.2034 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 00:50:38 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0013 s/iter. Inference: 0.1033 s/iter. Eval: 0.0909 s/iter. Total: 0.1955 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 00:50:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.871869 (0.197171 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:50:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.103474 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:50:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 00:50:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.269533071711147\n",
      "\u001b[32m[02/05 00:50:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:50:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:50:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:50:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:51:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:51:13 d2.utils.events]: \u001b[0m eta: 0:44:37  iter: 5579  total_loss: 1.334  loss_cls: 0.323  loss_box_reg: 0.5288  loss_mask: 0.2848  loss_rpn_cls: 0.07025  loss_rpn_loc: 0.1398  time: 1.8015  data_time: 0.2003  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:51:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:51:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:51:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:51:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:51:43 d2.utils.events]: \u001b[0m eta: 0:44:22  iter: 5599  total_loss: 1.465  loss_cls: 0.3355  loss_box_reg: 0.5522  loss_mask: 0.3001  loss_rpn_cls: 0.06657  loss_rpn_loc: 0.1485  time: 1.8004  data_time: 0.0547  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:51:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:51:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:52:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:52:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:52:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:52:22 d2.utils.events]: \u001b[0m eta: 0:44:02  iter: 5619  total_loss: 1.419  loss_cls: 0.3402  loss_box_reg: 0.5608  loss_mask: 0.2957  loss_rpn_cls: 0.08626  loss_rpn_loc: 0.1505  time: 1.8010  data_time: 0.1681  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:52:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:52:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:52:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:52:49 d2.utils.events]: \u001b[0m eta: 0:43:48  iter: 5639  total_loss: 1.453  loss_cls: 0.3586  loss_box_reg: 0.5487  loss_mask: 0.2995  loss_rpn_cls: 0.07666  loss_rpn_loc: 0.1528  time: 1.7993  data_time: 0.0454  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:52:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:13 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 5659  total_loss: 1.43  loss_cls: 0.3574  loss_box_reg: 0.538  loss_mask: 0.2786  loss_rpn_cls: 0.07107  loss_rpn_loc: 0.1713  time: 1.7973  data_time: 0.0386  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:53:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:53:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:01 d2.utils.events]: \u001b[0m eta: 0:43:30  iter: 5679  total_loss: 1.4  loss_cls: 0.3527  loss_box_reg: 0.5599  loss_mask: 0.2825  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.1653  time: 1.7993  data_time: 0.0498  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:54:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:37 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 5699  total_loss: 1.272  loss_cls: 0.3114  loss_box_reg: 0.5297  loss_mask: 0.2751  loss_rpn_cls: 0.05477  loss_rpn_loc: 0.1269  time: 1.7994  data_time: 0.0964  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:54:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:54:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:55:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:55:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:55:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:55:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:55:31 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 5719  total_loss: 1.467  loss_cls: 0.3551  loss_box_reg: 0.5581  loss_mask: 0.2961  loss_rpn_cls: 0.08895  loss_rpn_loc: 0.1692  time: 1.8025  data_time: 0.1220  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:55:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:55:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:55:49 d2.utils.events]: \u001b[0m eta: 0:42:51  iter: 5739  total_loss: 1.358  loss_cls: 0.3308  loss_box_reg: 0.533  loss_mask: 0.279  loss_rpn_cls: 0.05963  loss_rpn_loc: 0.1425  time: 1.7994  data_time: 0.0189  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:55:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:55:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:23 d2.utils.events]: \u001b[0m eta: 0:42:33  iter: 5759  total_loss: 1.319  loss_cls: 0.313  loss_box_reg: 0.5365  loss_mask: 0.2907  loss_rpn_cls: 0.05384  loss_rpn_loc: 0.1461  time: 1.7991  data_time: 0.0877  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:56:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:56:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:06 d2.utils.events]: \u001b[0m eta: 0:42:16  iter: 5779  total_loss: 1.492  loss_cls: 0.3711  loss_box_reg: 0.5747  loss_mask: 0.3026  loss_rpn_cls: 0.0737  loss_rpn_loc: 0.1518  time: 1.8003  data_time: 0.1276  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:57:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:57:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:58:02 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 5799  total_loss: 1.481  loss_cls: 0.3611  loss_box_reg: 0.5594  loss_mask: 0.3184  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.1739  time: 1.8037  data_time: 0.1050  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:58:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:58:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 00:58:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 00:58:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 00:58:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 00:58:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 00:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0976 s/iter. Eval: 0.0685 s/iter. Total: 0.1669 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 00:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0010 s/iter. Inference: 0.0999 s/iter. Eval: 0.0947 s/iter. Total: 0.1957 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 00:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0012 s/iter. Inference: 0.1008 s/iter. Eval: 0.0920 s/iter. Total: 0.1942 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 00:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0012 s/iter. Inference: 0.1019 s/iter. Eval: 0.0993 s/iter. Total: 0.2024 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 00:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0011 s/iter. Inference: 0.1009 s/iter. Eval: 0.0924 s/iter. Total: 0.1945 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 00:58:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.689441 (0.195599 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:58:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.100935 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 00:58:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 00:58:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27365328232813363\n",
      "\u001b[32m[02/05 00:58:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:58:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:58:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:58:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:58:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:01 d2.utils.events]: \u001b[0m eta: 0:41:53  iter: 5819  total_loss: 1.417  loss_cls: 0.3662  loss_box_reg: 0.5627  loss_mask: 0.2921  loss_rpn_cls: 0.06905  loss_rpn_loc: 0.1328  time: 1.8034  data_time: 0.0743  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:59:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:29 d2.utils.events]: \u001b[0m eta: 0:41:49  iter: 5839  total_loss: 1.467  loss_cls: 0.3525  loss_box_reg: 0.5561  loss_mask: 0.2803  loss_rpn_cls: 0.0971  loss_rpn_loc: 0.1664  time: 1.8020  data_time: 0.0488  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 00:59:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 00:59:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:11 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 5859  total_loss: 1.47  loss_cls: 0.3507  loss_box_reg: 0.5755  loss_mask: 0.2883  loss_rpn_cls: 0.07399  loss_rpn_loc: 0.1471  time: 1.8029  data_time: 0.1217  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:00:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:43 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 5879  total_loss: 1.424  loss_cls: 0.3483  loss_box_reg: 0.5625  loss_mask: 0.2826  loss_rpn_cls: 0.07951  loss_rpn_loc: 0.1463  time: 1.8024  data_time: 0.0655  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:00:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:00:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:01:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:01:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:01:18 d2.utils.events]: \u001b[0m eta: 0:41:13  iter: 5899  total_loss: 1.463  loss_cls: 0.3701  loss_box_reg: 0.5666  loss_mask: 0.2994  loss_rpn_cls: 0.07489  loss_rpn_loc: 0.1485  time: 1.8021  data_time: 0.0406  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:01:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:01:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:01:39 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 5919  total_loss: 1.405  loss_cls: 0.3237  loss_box_reg: 0.5462  loss_mask: 0.2964  loss_rpn_cls: 0.07233  loss_rpn_loc: 0.1459  time: 1.7996  data_time: 0.0742  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:01:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:01:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:01:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:01:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:27 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 5939  total_loss: 1.414  loss_cls: 0.3393  loss_box_reg: 0.5382  loss_mask: 0.2941  loss_rpn_cls: 0.06443  loss_rpn_loc: 0.1483  time: 1.8017  data_time: 0.1482  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:02:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:02:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:03:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:03:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:03:20 d2.utils.events]: \u001b[0m eta: 0:40:47  iter: 5959  total_loss: 1.429  loss_cls: 0.3418  loss_box_reg: 0.544  loss_mask: 0.3005  loss_rpn_cls: 0.06269  loss_rpn_loc: 0.1399  time: 1.8044  data_time: 0.1597  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:03:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:03:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:03:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:03:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:03:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:03:59 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 5979  total_loss: 1.307  loss_cls: 0.3269  loss_box_reg: 0.514  loss_mask: 0.2704  loss_rpn_cls: 0.06577  loss_rpn_loc: 0.1267  time: 1.8049  data_time: 0.0842  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:04:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:52 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 5999  total_loss: 1.358  loss_cls: 0.3426  loss_box_reg: 0.5376  loss_mask: 0.2948  loss_rpn_cls: 0.06698  loss_rpn_loc: 0.1318  time: 1.8078  data_time: 0.0803  lr: 0.0002048  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:04:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:04:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:05:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:05:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:05:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:05:32 d2.utils.events]: \u001b[0m eta: 0:40:13  iter: 6019  total_loss: 1.434  loss_cls: 0.344  loss_box_reg: 0.5751  loss_mask: 0.2861  loss_rpn_cls: 0.08077  loss_rpn_loc: 0.1322  time: 1.8083  data_time: 0.0803  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:05:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:05:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:05:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:05:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:05:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:06:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:06:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:06:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:06:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:06:21 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 6039  total_loss: 1.342  loss_cls: 0.3212  loss_box_reg: 0.5192  loss_mask: 0.2815  loss_rpn_cls: 0.0555  loss_rpn_loc: 0.1416  time: 1.8105  data_time: 0.0565  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:06:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:06:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:06:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:06:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:06:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 01:06:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 01:06:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 01:06:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:06:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 01:06:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1002 s/iter. Eval: 0.0667 s/iter. Total: 0.1678 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 01:06:47 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0014 s/iter. Inference: 0.1008 s/iter. Eval: 0.0920 s/iter. Total: 0.1944 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 01:06:52 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0012 s/iter. Inference: 0.1009 s/iter. Eval: 0.0919 s/iter. Total: 0.1942 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 01:06:57 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0012 s/iter. Inference: 0.1031 s/iter. Eval: 0.0988 s/iter. Total: 0.2032 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 01:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0957 s/iter. Total: 0.1995 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 01:07:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.254822 (0.200473 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:07:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.102504 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:07:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 01:07:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2774697659146443\n",
      "\u001b[32m[02/05 01:07:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:07:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:07:23 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 6059  total_loss: 1.464  loss_cls: 0.3622  loss_box_reg: 0.5379  loss_mask: 0.285  loss_rpn_cls: 0.08422  loss_rpn_loc: 0.1577  time: 1.8106  data_time: 0.1198  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:07:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:07:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:07:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:07:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:07:58 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 6079  total_loss: 1.414  loss_cls: 0.3428  loss_box_reg: 0.5212  loss_mask: 0.2821  loss_rpn_cls: 0.06794  loss_rpn_loc: 0.1407  time: 1.8104  data_time: 0.0888  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:08:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:08:56 d2.utils.events]: \u001b[0m eta: 0:39:40  iter: 6099  total_loss: 1.443  loss_cls: 0.3671  loss_box_reg: 0.5174  loss_mask: 0.2779  loss_rpn_cls: 0.08086  loss_rpn_loc: 0.1552  time: 1.8141  data_time: 0.0822  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:09:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:09:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:09:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:09:21 d2.utils.events]: \u001b[0m eta: 0:39:22  iter: 6119  total_loss: 1.279  loss_cls: 0.2877  loss_box_reg: 0.5128  loss_mask: 0.297  loss_rpn_cls: 0.05311  loss_rpn_loc: 0.1152  time: 1.8122  data_time: 0.0785  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:09:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:09:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:09:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:09:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:09:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:09:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:02 d2.utils.events]: \u001b[0m eta: 0:39:09  iter: 6139  total_loss: 1.401  loss_cls: 0.3523  loss_box_reg: 0.5303  loss_mask: 0.3034  loss_rpn_cls: 0.0727  loss_rpn_loc: 0.1496  time: 1.8129  data_time: 0.0949  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:10:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:40 d2.utils.events]: \u001b[0m eta: 0:38:56  iter: 6159  total_loss: 1.414  loss_cls: 0.3465  loss_box_reg: 0.557  loss_mask: 0.294  loss_rpn_cls: 0.06666  loss_rpn_loc: 0.142  time: 1.8132  data_time: 0.0394  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:10:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:10:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:11:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:11:15 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 6179  total_loss: 1.453  loss_cls: 0.3668  loss_box_reg: 0.5455  loss_mask: 0.2854  loss_rpn_cls: 0.06965  loss_rpn_loc: 0.1586  time: 1.8129  data_time: 0.0576  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:11:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:11:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:11:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:11:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:11:44 d2.utils.events]: \u001b[0m eta: 0:38:42  iter: 6199  total_loss: 1.379  loss_cls: 0.3599  loss_box_reg: 0.5421  loss_mask: 0.3016  loss_rpn_cls: 0.06958  loss_rpn_loc: 0.1252  time: 1.8118  data_time: 0.0291  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:11:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:11:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:12:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:12:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:12:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:12:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:12:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:12:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:12:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:12:47 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 6219  total_loss: 1.47  loss_cls: 0.369  loss_box_reg: 0.5473  loss_mask: 0.301  loss_rpn_cls: 0.06921  loss_rpn_loc: 0.175  time: 1.8160  data_time: 0.1749  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:12:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:13:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:13:09 d2.utils.events]: \u001b[0m eta: 0:38:12  iter: 6239  total_loss: 1.345  loss_cls: 0.3328  loss_box_reg: 0.553  loss_mask: 0.2855  loss_rpn_cls: 0.05569  loss_rpn_loc: 0.1343  time: 1.8138  data_time: 0.0818  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:13:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:13:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:13:30 d2.utils.events]: \u001b[0m eta: 0:38:03  iter: 6259  total_loss: 1.429  loss_cls: 0.3402  loss_box_reg: 0.5146  loss_mask: 0.281  loss_rpn_cls: 0.07552  loss_rpn_loc: 0.1694  time: 1.8113  data_time: 0.0421  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:13:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:13:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:13:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:13:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:13:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:14:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:14:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:14:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:14:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:14:26 d2.utils.events]: \u001b[0m eta: 0:37:53  iter: 6279  total_loss: 1.402  loss_cls: 0.3482  loss_box_reg: 0.5291  loss_mask: 0.3058  loss_rpn_cls: 0.07778  loss_rpn_loc: 0.1662  time: 1.8146  data_time: 0.0909  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:14:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:14:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:14:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:14:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 01:14:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 01:14:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 01:14:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:14:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 01:14:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0970 s/iter. Eval: 0.0656 s/iter. Total: 0.1634 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 01:14:50 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0930 s/iter. Total: 0.1964 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 01:14:55 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0015 s/iter. Inference: 0.1042 s/iter. Eval: 0.0948 s/iter. Total: 0.2005 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 01:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0014 s/iter. Inference: 0.1039 s/iter. Eval: 0.1004 s/iter. Total: 0.2057 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 01:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0013 s/iter. Inference: 0.1035 s/iter. Eval: 0.1001 s/iter. Total: 0.2050 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 01:15:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.753275 (0.204770 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:15:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.103255 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:15:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 01:15:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2713545530991609\n",
      "\u001b[32m[02/05 01:15:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:15:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:15:23 d2.utils.events]: \u001b[0m eta: 0:37:41  iter: 6299  total_loss: 1.471  loss_cls: 0.3504  loss_box_reg: 0.57  loss_mask: 0.2964  loss_rpn_cls: 0.0703  loss_rpn_loc: 0.1618  time: 1.8138  data_time: 0.1005  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:15:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:15:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:15:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:15:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:15:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:15:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:13 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 6319  total_loss: 1.506  loss_cls: 0.3863  loss_box_reg: 0.5662  loss_mask: 0.2989  loss_rpn_cls: 0.08259  loss_rpn_loc: 0.1791  time: 1.8158  data_time: 0.0655  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:16:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:16:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:17:01 d2.utils.events]: \u001b[0m eta: 0:37:23  iter: 6339  total_loss: 1.426  loss_cls: 0.3486  loss_box_reg: 0.5635  loss_mask: 0.2841  loss_rpn_cls: 0.08971  loss_rpn_loc: 0.1509  time: 1.8178  data_time: 0.1551  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:17:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:17:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:17:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:17:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:17:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:17:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:17:50 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 6359  total_loss: 1.25  loss_cls: 0.2965  loss_box_reg: 0.524  loss_mask: 0.2837  loss_rpn_cls: 0.03762  loss_rpn_loc: 0.1173  time: 1.8197  data_time: 0.1879  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:17:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:17:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:18:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:18:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:18:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:18:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:18:32 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 6379  total_loss: 1.497  loss_cls: 0.3495  loss_box_reg: 0.5946  loss_mask: 0.3226  loss_rpn_cls: 0.0619  loss_rpn_loc: 0.1441  time: 1.8207  data_time: 0.1207  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:18:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:18:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:18:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:18:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:08 d2.utils.events]: \u001b[0m eta: 0:36:41  iter: 6399  total_loss: 1.323  loss_cls: 0.3279  loss_box_reg: 0.5101  loss_mask: 0.2912  loss_rpn_cls: 0.04996  loss_rpn_loc: 0.1296  time: 1.8205  data_time: 0.1144  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:19:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:19:52 d2.utils.events]: \u001b[0m eta: 0:36:36  iter: 6419  total_loss: 1.433  loss_cls: 0.3598  loss_box_reg: 0.5393  loss_mask: 0.2931  loss_rpn_cls: 0.08016  loss_rpn_loc: 0.1483  time: 1.8217  data_time: 0.0821  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:19:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:20:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:20:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:20:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:20:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:20:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:20:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:20:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:20:48 d2.utils.events]: \u001b[0m eta: 0:36:20  iter: 6439  total_loss: 1.351  loss_cls: 0.3448  loss_box_reg: 0.5263  loss_mask: 0.2975  loss_rpn_cls: 0.06817  loss_rpn_loc: 0.1331  time: 1.8248  data_time: 0.0938  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:20:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:21:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:21:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:21:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:21:19 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 6459  total_loss: 1.285  loss_cls: 0.3175  loss_box_reg: 0.5317  loss_mask: 0.2812  loss_rpn_cls: 0.06543  loss_rpn_loc: 0.1566  time: 1.8239  data_time: 0.0751  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:21:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:21:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:21:42 d2.utils.events]: \u001b[0m eta: 0:35:55  iter: 6479  total_loss: 1.406  loss_cls: 0.3607  loss_box_reg: 0.545  loss_mask: 0.2929  loss_rpn_cls: 0.07823  loss_rpn_loc: 0.1511  time: 1.8219  data_time: 0.0925  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:21:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:21:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:21:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:22:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:22:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:22:18 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 6499  total_loss: 1.475  loss_cls: 0.3608  loss_box_reg: 0.5522  loss_mask: 0.3095  loss_rpn_cls: 0.08157  loss_rpn_loc: 0.1528  time: 1.8217  data_time: 0.0890  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:22:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:22:36 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 6519  total_loss: 1.366  loss_cls: 0.3311  loss_box_reg: 0.5412  loss_mask: 0.2757  loss_rpn_cls: 0.08591  loss_rpn_loc: 0.1487  time: 1.8190  data_time: 0.0445  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:22:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:22:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:22:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:22:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:23:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:23:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:23:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 01:23:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 01:23:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 01:23:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:23:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 01:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0984 s/iter. Eval: 0.0650 s/iter. Total: 0.1643 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 01:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0014 s/iter. Inference: 0.1001 s/iter. Eval: 0.0875 s/iter. Total: 0.1891 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 01:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0012 s/iter. Inference: 0.1004 s/iter. Eval: 0.0908 s/iter. Total: 0.1925 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 01:23:24 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0013 s/iter. Inference: 0.1014 s/iter. Eval: 0.0968 s/iter. Total: 0.1996 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 01:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0012 s/iter. Inference: 0.1012 s/iter. Eval: 0.0942 s/iter. Total: 0.1967 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 01:23:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.009093 (0.198354 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:23:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.101375 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:23:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 01:23:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2728858649897399\n",
      "\u001b[32m[02/05 01:23:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:23:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:23:46 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 6539  total_loss: 1.411  loss_cls: 0.3544  loss_box_reg: 0.5522  loss_mask: 0.3026  loss_rpn_cls: 0.07108  loss_rpn_loc: 0.1376  time: 1.8202  data_time: 0.1353  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:23:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:23:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:24:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:24:13 d2.utils.events]: \u001b[0m eta: 0:35:07  iter: 6559  total_loss: 1.275  loss_cls: 0.3071  loss_box_reg: 0.4966  loss_mask: 0.2741  loss_rpn_cls: 0.05166  loss_rpn_loc: 0.1312  time: 1.8189  data_time: 0.0452  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:24:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:24:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:24:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:24:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:24:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:24:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:24:53 d2.utils.events]: \u001b[0m eta: 0:34:55  iter: 6579  total_loss: 1.463  loss_cls: 0.3701  loss_box_reg: 0.5472  loss_mask: 0.2717  loss_rpn_cls: 0.08319  loss_rpn_loc: 0.1573  time: 1.8194  data_time: 0.1243  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:24:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:25:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:25:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:25:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:25:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:25:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:25:35 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 6599  total_loss: 1.431  loss_cls: 0.3453  loss_box_reg: 0.552  loss_mask: 0.2908  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.1348  time: 1.8202  data_time: 0.1027  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:25:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:25:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:25:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:03 d2.utils.events]: \u001b[0m eta: 0:34:34  iter: 6619  total_loss: 1.353  loss_cls: 0.322  loss_box_reg: 0.5268  loss_mask: 0.2808  loss_rpn_cls: 0.06177  loss_rpn_loc: 0.1259  time: 1.8190  data_time: 0.1042  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:26:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:51 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 6639  total_loss: 1.448  loss_cls: 0.3614  loss_box_reg: 0.5452  loss_mask: 0.2795  loss_rpn_cls: 0.08099  loss_rpn_loc: 0.1619  time: 1.8208  data_time: 0.0783  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:26:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:26:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:46 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 6659  total_loss: 1.571  loss_cls: 0.3703  loss_box_reg: 0.5761  loss_mask: 0.3119  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.182  time: 1.8235  data_time: 0.0788  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:27:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:27:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:27 d2.utils.events]: \u001b[0m eta: 0:33:57  iter: 6679  total_loss: 1.373  loss_cls: 0.3309  loss_box_reg: 0.5305  loss_mask: 0.2945  loss_rpn_cls: 0.0596  loss_rpn_loc: 0.1369  time: 1.8241  data_time: 0.0683  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:28:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:28:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:12 d2.utils.events]: \u001b[0m eta: 0:33:48  iter: 6699  total_loss: 1.304  loss_cls: 0.294  loss_box_reg: 0.5454  loss_mask: 0.296  loss_rpn_cls: 0.04711  loss_rpn_loc: 0.1267  time: 1.8255  data_time: 0.1869  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:29:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:29:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:30:02 d2.utils.events]: \u001b[0m eta: 0:33:33  iter: 6719  total_loss: 1.355  loss_cls: 0.3309  loss_box_reg: 0.5409  loss_mask: 0.2893  loss_rpn_cls: 0.05706  loss_rpn_loc: 0.1336  time: 1.8275  data_time: 0.1269  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:30:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:30:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:30:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:30:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:30:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:30:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:30:43 d2.utils.events]: \u001b[0m eta: 0:33:28  iter: 6739  total_loss: 1.426  loss_cls: 0.3605  loss_box_reg: 0.5521  loss_mask: 0.2989  loss_rpn_cls: 0.09257  loss_rpn_loc: 0.1727  time: 1.8282  data_time: 0.1047  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:30:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:30:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:31:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:31:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:31:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:31:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:31:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:31:30 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 6759  total_loss: 1.4  loss_cls: 0.3552  loss_box_reg: 0.5656  loss_mask: 0.2954  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.1466  time: 1.8297  data_time: 0.1288  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:31:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:31:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 01:31:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 01:31:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 01:31:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:31:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 01:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0996 s/iter. Eval: 0.0617 s/iter. Total: 0.1621 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 01:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0009 s/iter. Inference: 0.1020 s/iter. Eval: 0.0899 s/iter. Total: 0.1929 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 01:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0009 s/iter. Inference: 0.1022 s/iter. Eval: 0.0900 s/iter. Total: 0.1932 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 01:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 86/121. Dataloading: 0.0010 s/iter. Inference: 0.1028 s/iter. Eval: 0.0956 s/iter. Total: 0.1993 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 01:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0011 s/iter. Inference: 0.1028 s/iter. Eval: 0.0962 s/iter. Total: 0.2001 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 01:32:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.294021 (0.200811 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:32:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.102872 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:32:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 01:32:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2748927239086776\n",
      "\u001b[32m[02/05 01:32:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:32:12 d2.utils.events]: \u001b[0m eta: 0:32:54  iter: 6779  total_loss: 1.25  loss_cls: 0.332  loss_box_reg: 0.5035  loss_mask: 0.2737  loss_rpn_cls: 0.05484  loss_rpn_loc: 0.1262  time: 1.8268  data_time: 0.0216  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:32:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:32:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:32:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:32:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:32:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:32:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:32:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:12 d2.utils.events]: \u001b[0m eta: 0:32:42  iter: 6799  total_loss: 1.421  loss_cls: 0.3745  loss_box_reg: 0.531  loss_mask: 0.2828  loss_rpn_cls: 0.09258  loss_rpn_loc: 0.1886  time: 1.8302  data_time: 0.1538  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:33:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:39 d2.utils.events]: \u001b[0m eta: 0:32:34  iter: 6819  total_loss: 1.446  loss_cls: 0.3582  loss_box_reg: 0.5554  loss_mask: 0.2906  loss_rpn_cls: 0.0776  loss_rpn_loc: 0.1469  time: 1.8288  data_time: 0.0794  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:33:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:33:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:34:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:34:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:34:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:34:22 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 6839  total_loss: 1.324  loss_cls: 0.3224  loss_box_reg: 0.529  loss_mask: 0.2899  loss_rpn_cls: 0.0519  loss_rpn_loc: 0.1416  time: 1.8297  data_time: 0.0597  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:34:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:34:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:34:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:34:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:00 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 6859  total_loss: 1.266  loss_cls: 0.303  loss_box_reg: 0.4858  loss_mask: 0.267  loss_rpn_cls: 0.05869  loss_rpn_loc: 0.1416  time: 1.8299  data_time: 0.2255  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:35:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:46 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 6879  total_loss: 1.38  loss_cls: 0.3346  loss_box_reg: 0.5559  loss_mask: 0.2843  loss_rpn_cls: 0.05692  loss_rpn_loc: 0.1444  time: 1.8313  data_time: 0.0687  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:35:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:35:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:50 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 6899  total_loss: 1.445  loss_cls: 0.3605  loss_box_reg: 0.5543  loss_mask: 0.2969  loss_rpn_cls: 0.08645  loss_rpn_loc: 0.1743  time: 1.8352  data_time: 0.0871  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:36:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:36:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:37:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:37:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:37:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:37:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:37:33 d2.utils.events]: \u001b[0m eta: 0:31:35  iter: 6919  total_loss: 1.461  loss_cls: 0.3538  loss_box_reg: 0.5692  loss_mask: 0.3024  loss_rpn_cls: 0.07557  loss_rpn_loc: 0.1513  time: 1.8362  data_time: 0.0899  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:37:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:37:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:37:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:10 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 6939  total_loss: 1.357  loss_cls: 0.3219  loss_box_reg: 0.5463  loss_mask: 0.2917  loss_rpn_cls: 0.06577  loss_rpn_loc: 0.141  time: 1.8362  data_time: 0.1519  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:38:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:37 d2.utils.events]: \u001b[0m eta: 0:31:00  iter: 6959  total_loss: 1.168  loss_cls: 0.2702  loss_box_reg: 0.4958  loss_mask: 0.2829  loss_rpn_cls: 0.03151  loss_rpn_loc: 0.08321  time: 1.8348  data_time: 0.1019  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:38:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:38:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:28 d2.utils.events]: \u001b[0m eta: 0:30:49  iter: 6979  total_loss: 1.4  loss_cls: 0.3477  loss_box_reg: 0.5443  loss_mask: 0.2813  loss_rpn_cls: 0.07928  loss_rpn_loc: 0.1388  time: 1.8369  data_time: 0.0911  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:39:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:39:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:40:07 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 6999  total_loss: 1.518  loss_cls: 0.3824  loss_box_reg: 0.5593  loss_mask: 0.3012  loss_rpn_cls: 0.08555  loss_rpn_loc: 0.184  time: 1.8372  data_time: 0.0292  lr: 0.00016384  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:40:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:40:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:40:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:40:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:40:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:40:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 01:40:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 01:40:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 01:40:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:40:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 01:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0953 s/iter. Eval: 0.0672 s/iter. Total: 0.1633 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 01:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0010 s/iter. Inference: 0.1029 s/iter. Eval: 0.0900 s/iter. Total: 0.1939 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 01:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0010 s/iter. Inference: 0.1028 s/iter. Eval: 0.0905 s/iter. Total: 0.1943 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 01:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0010 s/iter. Inference: 0.1045 s/iter. Eval: 0.0991 s/iter. Total: 0.2046 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 01:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0011 s/iter. Inference: 0.1040 s/iter. Eval: 0.0974 s/iter. Total: 0.2026 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 01:41:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.654584 (0.203919 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:41:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.104156 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:41:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 01:41:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2766674912084039\n",
      "\u001b[32m[02/05 01:41:04 d2.utils.events]: \u001b[0m eta: 0:30:17  iter: 7019  total_loss: 1.461  loss_cls: 0.369  loss_box_reg: 0.5401  loss_mask: 0.2867  loss_rpn_cls: 0.07566  loss_rpn_loc: 0.1531  time: 1.8364  data_time: 0.0655  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:41:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:41:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:41:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:41:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:41:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:41:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:41:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:42:01 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 7039  total_loss: 1.466  loss_cls: 0.3663  loss_box_reg: 0.5305  loss_mask: 0.299  loss_rpn_cls: 0.08609  loss_rpn_loc: 0.1657  time: 1.8392  data_time: 0.1582  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:42:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:42:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:42:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:42:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:42:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:42:36 d2.utils.events]: \u001b[0m eta: 0:29:55  iter: 7059  total_loss: 1.432  loss_cls: 0.358  loss_box_reg: 0.5362  loss_mask: 0.2815  loss_rpn_cls: 0.06235  loss_rpn_loc: 0.1382  time: 1.8390  data_time: 0.0376  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:42:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:42:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:42:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:43:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:43:09 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 7079  total_loss: 1.461  loss_cls: 0.3647  loss_box_reg: 0.5547  loss_mask: 0.3105  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.1418  time: 1.8385  data_time: 0.1738  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:43:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:43:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:43:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:43:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:43:45 d2.utils.events]: \u001b[0m eta: 0:29:31  iter: 7099  total_loss: 1.369  loss_cls: 0.339  loss_box_reg: 0.5622  loss_mask: 0.2786  loss_rpn_cls: 0.06047  loss_rpn_loc: 0.1451  time: 1.8384  data_time: 0.0753  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:43:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:43:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:44:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:44:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:44:19 d2.utils.events]: \u001b[0m eta: 0:29:21  iter: 7119  total_loss: 1.328  loss_cls: 0.3236  loss_box_reg: 0.5234  loss_mask: 0.2791  loss_rpn_cls: 0.06977  loss_rpn_loc: 0.1393  time: 1.8379  data_time: 0.1607  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:44:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:44:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:44:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:44:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:44:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:44:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:07 d2.utils.events]: \u001b[0m eta: 0:29:10  iter: 7139  total_loss: 1.494  loss_cls: 0.3633  loss_box_reg: 0.58  loss_mask: 0.2984  loss_rpn_cls: 0.08144  loss_rpn_loc: 0.1686  time: 1.8396  data_time: 0.1293  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:45:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:50 d2.utils.events]: \u001b[0m eta: 0:28:59  iter: 7159  total_loss: 1.367  loss_cls: 0.3411  loss_box_reg: 0.5469  loss_mask: 0.2987  loss_rpn_cls: 0.05368  loss_rpn_loc: 0.1432  time: 1.8404  data_time: 0.1061  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:45:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:45:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:37 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 7179  total_loss: 1.388  loss_cls: 0.3566  loss_box_reg: 0.5145  loss_mask: 0.283  loss_rpn_cls: 0.07615  loss_rpn_loc: 0.1559  time: 1.8419  data_time: 0.0774  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:46:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:46:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:47:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:47:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:47:17 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 7199  total_loss: 1.409  loss_cls: 0.3311  loss_box_reg: 0.5353  loss_mask: 0.2704  loss_rpn_cls: 0.06046  loss_rpn_loc: 0.1366  time: 1.8423  data_time: 0.1768  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:47:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:47:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:47:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:47:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:47:51 d2.utils.events]: \u001b[0m eta: 0:28:19  iter: 7219  total_loss: 1.393  loss_cls: 0.3261  loss_box_reg: 0.5426  loss_mask: 0.2747  loss_rpn_cls: 0.08653  loss_rpn_loc: 0.1552  time: 1.8419  data_time: 0.1356  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:47:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:13 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 7239  total_loss: 1.392  loss_cls: 0.3195  loss_box_reg: 0.5378  loss_mask: 0.2895  loss_rpn_cls: 0.0622  loss_rpn_loc: 0.1373  time: 1.8398  data_time: 0.0494  lr: 0.00013107  max_mem: 9510M\n",
      "\u001b[32m[02/05 01:48:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:48:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:49:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:49:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:49:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 01:49:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 01:49:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 01:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:49:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 01:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0982 s/iter. Eval: 0.0665 s/iter. Total: 0.1655 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 01:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0010 s/iter. Inference: 0.1023 s/iter. Eval: 0.0871 s/iter. Total: 0.1906 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 01:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.1016 s/iter. Eval: 0.0887 s/iter. Total: 0.1914 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 01:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0010 s/iter. Inference: 0.1022 s/iter. Eval: 0.0965 s/iter. Total: 0.1998 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 01:49:36 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0010 s/iter. Inference: 0.1023 s/iter. Eval: 0.0964 s/iter. Total: 0.1998 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 01:49:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.235609 (0.200307 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:49:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.102140 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:49:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 01:49:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2764776532505037\n",
      "\u001b[32m[02/05 01:49:38 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 7259  total_loss: 1.453  loss_cls: 0.3498  loss_box_reg: 0.5527  loss_mask: 0.3004  loss_rpn_cls: 0.069  loss_rpn_loc: 0.1681  time: 1.8430  data_time: 0.1152  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:49:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:49:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:49:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:49:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:50:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:50:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:50:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:50:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:50:34 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 7279  total_loss: 1.459  loss_cls: 0.3646  loss_box_reg: 0.5573  loss_mask: 0.2963  loss_rpn_cls: 0.06783  loss_rpn_loc: 0.1506  time: 1.8457  data_time: 0.1462  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:50:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:50:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:50:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:50:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:24 d2.utils.events]: \u001b[0m eta: 0:27:34  iter: 7299  total_loss: 1.545  loss_cls: 0.381  loss_box_reg: 0.5692  loss_mask: 0.304  loss_rpn_cls: 0.07739  loss_rpn_loc: 0.1715  time: 1.8474  data_time: 0.0728  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:51:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:51:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:00 d2.utils.events]: \u001b[0m eta: 0:27:18  iter: 7319  total_loss: 1.377  loss_cls: 0.3499  loss_box_reg: 0.5127  loss_mask: 0.2802  loss_rpn_cls: 0.08005  loss_rpn_loc: 0.1484  time: 1.8472  data_time: 0.0503  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:52:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:31 d2.utils.events]: \u001b[0m eta: 0:27:07  iter: 7339  total_loss: 1.442  loss_cls: 0.3745  loss_box_reg: 0.5734  loss_mask: 0.2922  loss_rpn_cls: 0.08126  loss_rpn_loc: 0.1665  time: 1.8465  data_time: 0.1036  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:52:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:52:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:28 d2.utils.events]: \u001b[0m eta: 0:26:57  iter: 7359  total_loss: 1.392  loss_cls: 0.3452  loss_box_reg: 0.5346  loss_mask: 0.3046  loss_rpn_cls: 0.07565  loss_rpn_loc: 0.1584  time: 1.8493  data_time: 0.0833  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:53:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:53:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:12 d2.utils.events]: \u001b[0m eta: 0:26:44  iter: 7379  total_loss: 1.383  loss_cls: 0.3542  loss_box_reg: 0.5375  loss_mask: 0.3007  loss_rpn_cls: 0.05488  loss_rpn_loc: 0.1389  time: 1.8502  data_time: 0.0846  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:54:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:36 d2.utils.events]: \u001b[0m eta: 0:26:33  iter: 7399  total_loss: 1.367  loss_cls: 0.3367  loss_box_reg: 0.5465  loss_mask: 0.2908  loss_rpn_cls: 0.0642  loss_rpn_loc: 0.1317  time: 1.8485  data_time: 0.0245  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:54:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:54:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:55:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:55:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:55:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:55:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:55:30 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 7419  total_loss: 1.316  loss_cls: 0.3184  loss_box_reg: 0.5023  loss_mask: 0.2731  loss_rpn_cls: 0.05361  loss_rpn_loc: 0.1407  time: 1.8507  data_time: 0.0864  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:55:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:55:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:55:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:55:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:56:00 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 7439  total_loss: 1.279  loss_cls: 0.309  loss_box_reg: 0.5209  loss_mask: 0.2872  loss_rpn_cls: 0.05111  loss_rpn_loc: 0.1368  time: 1.8498  data_time: 0.0510  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:56:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:56:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:56:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:56:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:56:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:56:37 d2.utils.events]: \u001b[0m eta: 0:25:56  iter: 7459  total_loss: 1.421  loss_cls: 0.3413  loss_box_reg: 0.5359  loss_mask: 0.2945  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.1632  time: 1.8498  data_time: 0.0653  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:56:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:56:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:56:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:57:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:57:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:57:22 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 7479  total_loss: 1.495  loss_cls: 0.3548  loss_box_reg: 0.5433  loss_mask: 0.3007  loss_rpn_cls: 0.07918  loss_rpn_loc: 0.1492  time: 1.8509  data_time: 0.2128  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:57:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:57:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:57:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:57:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:57:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:58:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:58:06 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 7499  total_loss: 1.311  loss_cls: 0.321  loss_box_reg: 0.5271  loss_mask: 0.2781  loss_rpn_cls: 0.06133  loss_rpn_loc: 0.1358  time: 1.8518  data_time: 0.1386  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:58:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:58:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 01:58:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 01:58:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 01:58:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 01:58:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 01:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1044 s/iter. Eval: 0.0676 s/iter. Total: 0.1728 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 01:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 34/121. Dataloading: 0.0010 s/iter. Inference: 0.1073 s/iter. Eval: 0.1010 s/iter. Total: 0.2093 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 01:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0013 s/iter. Inference: 0.1056 s/iter. Eval: 0.0984 s/iter. Total: 0.2054 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 01:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0012 s/iter. Inference: 0.1059 s/iter. Eval: 0.1052 s/iter. Total: 0.2123 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 01:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0012 s/iter. Inference: 0.1059 s/iter. Eval: 0.1033 s/iter. Total: 0.2105 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 01:58:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.287700 (0.209377 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:58:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.105545 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 01:58:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 01:58:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2784880546799241\n",
      "\u001b[32m[02/05 01:58:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:58:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:58:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:58:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:59:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:59:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:59:17 d2.utils.events]: \u001b[0m eta: 0:25:25  iter: 7519  total_loss: 1.365  loss_cls: 0.3342  loss_box_reg: 0.5275  loss_mask: 0.2865  loss_rpn_cls: 0.05886  loss_rpn_loc: 0.145  time: 1.8528  data_time: 0.0389  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:59:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:59:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:59:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:59:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:59:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 01:59:56 d2.utils.events]: \u001b[0m eta: 0:25:14  iter: 7539  total_loss: 1.371  loss_cls: 0.3336  loss_box_reg: 0.5383  loss_mask: 0.2847  loss_rpn_cls: 0.0568  loss_rpn_loc: 0.1448  time: 1.8530  data_time: 0.0850  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 01:59:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:00:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:00:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:00:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:00:30 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 7559  total_loss: 1.402  loss_cls: 0.3426  loss_box_reg: 0.555  loss_mask: 0.2918  loss_rpn_cls: 0.05144  loss_rpn_loc: 0.1312  time: 1.8526  data_time: 0.1047  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:00:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:00:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:00:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:00:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:26 d2.utils.events]: \u001b[0m eta: 0:24:50  iter: 7579  total_loss: 1.425  loss_cls: 0.3618  loss_box_reg: 0.5343  loss_mask: 0.287  loss_rpn_cls: 0.0724  loss_rpn_loc: 0.1478  time: 1.8551  data_time: 0.1661  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:01:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:01:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:02:05 d2.utils.events]: \u001b[0m eta: 0:24:38  iter: 7599  total_loss: 1.422  loss_cls: 0.3367  loss_box_reg: 0.5501  loss_mask: 0.2838  loss_rpn_cls: 0.07129  loss_rpn_loc: 0.1676  time: 1.8553  data_time: 0.0920  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:02:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:02:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:02:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:02:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:02:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:02:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:02:48 d2.utils.events]: \u001b[0m eta: 0:24:31  iter: 7619  total_loss: 1.501  loss_cls: 0.3827  loss_box_reg: 0.5789  loss_mask: 0.289  loss_rpn_cls: 0.08814  loss_rpn_loc: 0.1666  time: 1.8562  data_time: 0.0498  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:02:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:11 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 7639  total_loss: 1.312  loss_cls: 0.3064  loss_box_reg: 0.5222  loss_mask: 0.2913  loss_rpn_cls: 0.04603  loss_rpn_loc: 0.1162  time: 1.8543  data_time: 0.0304  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:03:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:03:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:26 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 7659  total_loss: 1.399  loss_cls: 0.3327  loss_box_reg: 0.5596  loss_mask: 0.3095  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.1451  time: 1.8593  data_time: 0.0933  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:04:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:04:59 d2.utils.events]: \u001b[0m eta: 0:23:45  iter: 7679  total_loss: 1.302  loss_cls: 0.3202  loss_box_reg: 0.515  loss_mask: 0.298  loss_rpn_cls: 0.05436  loss_rpn_loc: 0.1319  time: 1.8587  data_time: 0.0651  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:05:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:05:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:05:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:05:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:05:34 d2.utils.events]: \u001b[0m eta: 0:23:35  iter: 7699  total_loss: 1.512  loss_cls: 0.3845  loss_box_reg: 0.6075  loss_mask: 0.3047  loss_rpn_cls: 0.09531  loss_rpn_loc: 0.1629  time: 1.8584  data_time: 0.1698  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:05:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:05:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:05:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:06:00 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 7719  total_loss: 1.327  loss_cls: 0.345  loss_box_reg: 0.5247  loss_mask: 0.279  loss_rpn_cls: 0.05149  loss_rpn_loc: 0.1266  time: 1.8570  data_time: 0.0263  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:06:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:06:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:06:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:06:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:06:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:06:37 d2.utils.events]: \u001b[0m eta: 0:23:08  iter: 7739  total_loss: 1.358  loss_cls: 0.3401  loss_box_reg: 0.5195  loss_mask: 0.2858  loss_rpn_cls: 0.0797  loss_rpn_loc: 0.1443  time: 1.8570  data_time: 0.0750  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:06:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:06:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:06:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 02:06:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 02:06:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 02:06:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:06:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 02:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1009 s/iter. Eval: 0.0662 s/iter. Total: 0.1680 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 02:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0010 s/iter. Inference: 0.1016 s/iter. Eval: 0.0914 s/iter. Total: 0.1940 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 02:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0014 s/iter. Inference: 0.1010 s/iter. Eval: 0.0927 s/iter. Total: 0.1951 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 02:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0013 s/iter. Inference: 0.1021 s/iter. Eval: 0.1005 s/iter. Total: 0.2040 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 02:07:10 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0012 s/iter. Inference: 0.1018 s/iter. Eval: 0.0976 s/iter. Total: 0.2007 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 02:07:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.418048 (0.201880 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:07:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.101801 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:07:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 02:07:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2782707153472473\n",
      "\u001b[32m[02/05 02:07:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:07:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:07:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:07:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:07:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:07:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:07:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:05 d2.utils.events]: \u001b[0m eta: 0:23:00  iter: 7759  total_loss: 1.455  loss_cls: 0.3539  loss_box_reg: 0.5365  loss_mask: 0.2951  loss_rpn_cls: 0.09914  loss_rpn_loc: 0.1536  time: 1.8603  data_time: 0.1898  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:08:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:08:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:09:02 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 7779  total_loss: 1.347  loss_cls: 0.3181  loss_box_reg: 0.5481  loss_mask: 0.2995  loss_rpn_cls: 0.06678  loss_rpn_loc: 0.1255  time: 1.8627  data_time: 0.1080  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:09:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:09:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:09:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:09:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:09:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:09:42 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 7799  total_loss: 1.535  loss_cls: 0.3749  loss_box_reg: 0.5781  loss_mask: 0.3064  loss_rpn_cls: 0.07475  loss_rpn_loc: 0.1776  time: 1.8631  data_time: 0.0958  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:09:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:09:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:09:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:10:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:10:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:10:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:10:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:10:27 d2.utils.events]: \u001b[0m eta: 0:22:23  iter: 7819  total_loss: 1.384  loss_cls: 0.3312  loss_box_reg: 0.5394  loss_mask: 0.2929  loss_rpn_cls: 0.054  loss_rpn_loc: 0.1574  time: 1.8641  data_time: 0.0749  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:10:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:10:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:10:50 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 7839  total_loss: 1.25  loss_cls: 0.2896  loss_box_reg: 0.5221  loss_mask: 0.2783  loss_rpn_cls: 0.04678  loss_rpn_loc: 0.1214  time: 1.8622  data_time: 0.0979  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:10:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:10:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:11:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:11:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:11:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:11:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:11:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:11:43 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 7859  total_loss: 1.475  loss_cls: 0.3918  loss_box_reg: 0.5699  loss_mask: 0.3104  loss_rpn_cls: 0.0763  loss_rpn_loc: 0.163  time: 1.8643  data_time: 0.0777  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:11:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:11:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:11:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:12:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:12:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:12:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:12:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:12:33 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 7879  total_loss: 1.397  loss_cls: 0.3535  loss_box_reg: 0.5254  loss_mask: 0.295  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.1625  time: 1.8659  data_time: 0.0777  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:12:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:12:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:12:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:13:01 d2.utils.events]: \u001b[0m eta: 0:21:32  iter: 7899  total_loss: 1.43  loss_cls: 0.3436  loss_box_reg: 0.5598  loss_mask: 0.2984  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.14  time: 1.8647  data_time: 0.0474  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:13:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:13:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:13:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:13:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:13:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:13:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:13:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:13:49 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 7919  total_loss: 1.369  loss_cls: 0.3313  loss_box_reg: 0.5456  loss_mask: 0.2876  loss_rpn_cls: 0.06484  loss_rpn_loc: 0.1499  time: 1.8661  data_time: 0.0735  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:13:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:14:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:14:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:14:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:14:21 d2.utils.events]: \u001b[0m eta: 0:21:07  iter: 7939  total_loss: 1.443  loss_cls: 0.3611  loss_box_reg: 0.5524  loss_mask: 0.293  loss_rpn_cls: 0.07248  loss_rpn_loc: 0.1445  time: 1.8655  data_time: 0.0780  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:14:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:14:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:14:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:14:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:14:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:00 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 7959  total_loss: 1.286  loss_cls: 0.3091  loss_box_reg: 0.505  loss_mask: 0.2722  loss_rpn_cls: 0.07168  loss_rpn_loc: 0.1446  time: 1.8656  data_time: 0.1267  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:15:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:15:49 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 7979  total_loss: 1.413  loss_cls: 0.3503  loss_box_reg: 0.5616  loss_mask: 0.289  loss_rpn_cls: 0.07813  loss_rpn_loc: 0.1682  time: 1.8671  data_time: 0.0674  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:15:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:16:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:16:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 02:16:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 02:16:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 02:16:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:16:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 02:16:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0963 s/iter. Eval: 0.0669 s/iter. Total: 0.1640 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 02:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 35/121. Dataloading: 0.0010 s/iter. Inference: 0.1034 s/iter. Eval: 0.0957 s/iter. Total: 0.2003 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 02:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0010 s/iter. Inference: 0.1022 s/iter. Eval: 0.0909 s/iter. Total: 0.1943 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 02:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0010 s/iter. Inference: 0.1021 s/iter. Eval: 0.1008 s/iter. Total: 0.2039 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 02:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0011 s/iter. Inference: 0.1023 s/iter. Eval: 0.0987 s/iter. Total: 0.2022 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 02:16:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.530762 (0.202851 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:16:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.102301 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:16:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 02:16:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2747390545768083\n",
      "\u001b[32m[02/05 02:16:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:16:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:16:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:16:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:16:57 d2.utils.events]: \u001b[0m eta: 0:20:33  iter: 7999  total_loss: 1.25  loss_cls: 0.3063  loss_box_reg: 0.5179  loss_mask: 0.2775  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.1267  time: 1.8678  data_time: 0.1827  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:16:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:17:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:17:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:17:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:17:31 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 8019  total_loss: 1.357  loss_cls: 0.3361  loss_box_reg: 0.5257  loss_mask: 0.2861  loss_rpn_cls: 0.07758  loss_rpn_loc: 0.1347  time: 1.8673  data_time: 0.1064  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:17:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:17:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:17:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:17:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:18:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:18:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:18:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:18:22 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 8039  total_loss: 1.425  loss_cls: 0.342  loss_box_reg: 0.528  loss_mask: 0.3028  loss_rpn_cls: 0.06268  loss_rpn_loc: 0.1436  time: 1.8690  data_time: 0.0936  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:18:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:18:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:18:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:18:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:18:59 d2.utils.events]: \u001b[0m eta: 0:19:52  iter: 8059  total_loss: 1.44  loss_cls: 0.3311  loss_box_reg: 0.544  loss_mask: 0.3041  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.1511  time: 1.8689  data_time: 0.1867  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:19:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:19:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:19:22 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 8079  total_loss: 1.444  loss_cls: 0.3416  loss_box_reg: 0.5571  loss_mask: 0.2787  loss_rpn_cls: 0.07699  loss_rpn_loc: 0.1464  time: 1.8671  data_time: 0.0520  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:19:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:19:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:19:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:19:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:19:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:01 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 8099  total_loss: 1.459  loss_cls: 0.362  loss_box_reg: 0.5491  loss_mask: 0.2941  loss_rpn_cls: 0.08012  loss_rpn_loc: 0.1497  time: 1.8674  data_time: 0.0712  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:20:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:20:54 d2.utils.events]: \u001b[0m eta: 0:19:19  iter: 8119  total_loss: 1.411  loss_cls: 0.3557  loss_box_reg: 0.5298  loss_mask: 0.2884  loss_rpn_cls: 0.07095  loss_rpn_loc: 0.1362  time: 1.8693  data_time: 0.1049  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:20:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:44 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 8139  total_loss: 1.415  loss_cls: 0.3508  loss_box_reg: 0.5318  loss_mask: 0.2809  loss_rpn_cls: 0.07304  loss_rpn_loc: 0.1773  time: 1.8709  data_time: 0.0805  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:21:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:21:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:22:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:22:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:22:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:22:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:22:35 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 8159  total_loss: 1.41  loss_cls: 0.3473  loss_box_reg: 0.5424  loss_mask: 0.2896  loss_rpn_cls: 0.06834  loss_rpn_loc: 0.153  time: 1.8725  data_time: 0.0692  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:22:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:22:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:22:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:23:01 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 8179  total_loss: 1.298  loss_cls: 0.2989  loss_box_reg: 0.5314  loss_mask: 0.2789  loss_rpn_cls: 0.04137  loss_rpn_loc: 0.1274  time: 1.8712  data_time: 0.0675  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:23:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:23:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:23:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:23:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:23:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:23:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:23:46 d2.utils.events]: \u001b[0m eta: 0:18:31  iter: 8199  total_loss: 1.266  loss_cls: 0.3257  loss_box_reg: 0.5005  loss_mask: 0.2771  loss_rpn_cls: 0.06918  loss_rpn_loc: 0.1243  time: 1.8721  data_time: 0.1520  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:23:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:23:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:24:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:24:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:24:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:24:25 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 8219  total_loss: 1.459  loss_cls: 0.3777  loss_box_reg: 0.5657  loss_mask: 0.3081  loss_rpn_cls: 0.086  loss_rpn_loc: 0.1817  time: 1.8723  data_time: 0.1493  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:24:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:24:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:24:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 02:24:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 02:24:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 02:24:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:24:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 02:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.1089 s/iter. Eval: 0.0681 s/iter. Total: 0.1780 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 02:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 35/121. Dataloading: 0.0012 s/iter. Inference: 0.1077 s/iter. Eval: 0.0967 s/iter. Total: 0.2056 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 02:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0012 s/iter. Inference: 0.1060 s/iter. Eval: 0.0938 s/iter. Total: 0.2011 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 02:24:54 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0011 s/iter. Inference: 0.1052 s/iter. Eval: 0.1005 s/iter. Total: 0.2069 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 02:24:59 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0011 s/iter. Inference: 0.1050 s/iter. Eval: 0.1006 s/iter. Total: 0.2068 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 02:25:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.955346 (0.206512 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:25:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.105066 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:25:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 02:25:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2778781521329201\n",
      "\u001b[32m[02/05 02:25:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:25:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:25:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:25:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:25:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:25:40 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 8239  total_loss: 1.327  loss_cls: 0.3223  loss_box_reg: 0.5315  loss_mask: 0.2964  loss_rpn_cls: 0.05828  loss_rpn_loc: 0.126  time: 1.8737  data_time: 0.1551  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:25:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:25:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:25:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:26:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:26:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:26:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:26:30 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 8259  total_loss: 1.353  loss_cls: 0.337  loss_box_reg: 0.5256  loss_mask: 0.2777  loss_rpn_cls: 0.0696  loss_rpn_loc: 0.1499  time: 1.8751  data_time: 0.1545  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:26:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:26:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:26:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:26:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:05 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 8279  total_loss: 1.386  loss_cls: 0.3337  loss_box_reg: 0.5356  loss_mask: 0.2846  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.1383  time: 1.8748  data_time: 0.0812  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:27:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:50 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 8299  total_loss: 1.299  loss_cls: 0.3206  loss_box_reg: 0.5196  loss_mask: 0.2855  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.1345  time: 1.8758  data_time: 0.0994  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:27:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:27:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:28:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:28:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:28:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:28:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:28:38 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 8319  total_loss: 1.471  loss_cls: 0.3498  loss_box_reg: 0.5435  loss_mask: 0.3055  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.1486  time: 1.8770  data_time: 0.1122  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:28:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:28:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:28:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:29:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:29:12 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 8339  total_loss: 1.321  loss_cls: 0.317  loss_box_reg: 0.5281  loss_mask: 0.2741  loss_rpn_cls: 0.05653  loss_rpn_loc: 0.1279  time: 1.8766  data_time: 0.0329  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:29:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:29:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:29:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:29:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:29:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:29:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:29:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:30:01 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 8359  total_loss: 1.487  loss_cls: 0.3736  loss_box_reg: 0.552  loss_mask: 0.3022  loss_rpn_cls: 0.0746  loss_rpn_loc: 0.1453  time: 1.8780  data_time: 0.0867  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:30:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:30:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:30:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:30:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:30:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:30:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:30:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:30:54 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 8379  total_loss: 1.35  loss_cls: 0.3288  loss_box_reg: 0.5235  loss_mask: 0.2891  loss_rpn_cls: 0.06429  loss_rpn_loc: 0.1418  time: 1.8798  data_time: 0.1460  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:30:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:31:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:31:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:31:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:31:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:31:33 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 8399  total_loss: 1.328  loss_cls: 0.3316  loss_box_reg: 0.5533  loss_mask: 0.3018  loss_rpn_cls: 0.0611  loss_rpn_loc: 0.1289  time: 1.8800  data_time: 0.1431  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:31:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:31:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:31:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:31:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:32:06 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 8419  total_loss: 1.358  loss_cls: 0.3367  loss_box_reg: 0.5394  loss_mask: 0.2995  loss_rpn_cls: 0.06666  loss_rpn_loc: 0.1352  time: 1.8795  data_time: 0.0211  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:32:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:32:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:32:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:32:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:32:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:32:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:32:49 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 8439  total_loss: 1.376  loss_cls: 0.3618  loss_box_reg: 0.5494  loss_mask: 0.307  loss_rpn_cls: 0.0612  loss_rpn_loc: 0.1377  time: 1.8800  data_time: 0.1327  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:32:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:32:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:33:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:33:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:33:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:33:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:33:33 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 8459  total_loss: 1.369  loss_cls: 0.3447  loss_box_reg: 0.5306  loss_mask: 0.2776  loss_rpn_cls: 0.06362  loss_rpn_loc: 0.1392  time: 1.8809  data_time: 0.0951  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:33:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:33:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:33:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:33:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:34:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:34:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:34:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 02:34:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 02:34:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 02:34:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:34:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 02:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1010 s/iter. Eval: 0.0590 s/iter. Total: 0.1607 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 02:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 36/121. Dataloading: 0.0009 s/iter. Inference: 0.1037 s/iter. Eval: 0.0899 s/iter. Total: 0.1946 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 02:34:20 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0901 s/iter. Total: 0.1936 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 02:34:25 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0974 s/iter. Total: 0.2010 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 02:34:30 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0011 s/iter. Inference: 0.1026 s/iter. Eval: 0.0960 s/iter. Total: 0.1998 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 02:34:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.199080 (0.199992 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:34:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.102522 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:34:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 02:34:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27481251655637445\n",
      "\u001b[32m[02/05 02:34:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:34:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:34:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:34:58 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 8479  total_loss: 1.389  loss_cls: 0.3413  loss_box_reg: 0.5196  loss_mask: 0.2894  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.1548  time: 1.8835  data_time: 0.2045  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:34:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:35:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:35:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:35:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:35:31 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 8499  total_loss: 1.381  loss_cls: 0.3128  loss_box_reg: 0.5463  loss_mask: 0.2968  loss_rpn_cls: 0.06514  loss_rpn_loc: 0.1424  time: 1.8829  data_time: 0.1459  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:35:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:35:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:35:55 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 8519  total_loss: 1.417  loss_cls: 0.3689  loss_box_reg: 0.5496  loss_mask: 0.2812  loss_rpn_cls: 0.07283  loss_rpn_loc: 0.1512  time: 1.8813  data_time: 0.1189  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:35:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:36:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:36:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:36:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:36:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:36:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:36:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:36:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:36:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:37:04 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 8539  total_loss: 1.402  loss_cls: 0.3625  loss_box_reg: 0.5366  loss_mask: 0.2886  loss_rpn_cls: 0.0698  loss_rpn_loc: 0.1546  time: 1.8849  data_time: 0.2525  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:37:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:37:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:37:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:37:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:37:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:37:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:37:46 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 8559  total_loss: 1.442  loss_cls: 0.3546  loss_box_reg: 0.5473  loss_mask: 0.3125  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.1429  time: 1.8855  data_time: 0.0928  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:37:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:37:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:38:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:38:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:38:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:38:30 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 8579  total_loss: 1.418  loss_cls: 0.3577  loss_box_reg: 0.5264  loss_mask: 0.2663  loss_rpn_cls: 0.0776  loss_rpn_loc: 0.1514  time: 1.8862  data_time: 0.1348  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:38:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:38:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:38:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:38:57 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 8599  total_loss: 1.34  loss_cls: 0.3384  loss_box_reg: 0.5089  loss_mask: 0.2831  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.1193  time: 1.8850  data_time: 0.1034  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:39:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:39:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:39:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:39:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:39:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:39:34 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 8619  total_loss: 1.372  loss_cls: 0.3464  loss_box_reg: 0.5521  loss_mask: 0.2758  loss_rpn_cls: 0.06859  loss_rpn_loc: 0.1477  time: 1.8849  data_time: 0.1107  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:39:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:39:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:39:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:40:05 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 8639  total_loss: 1.42  loss_cls: 0.3667  loss_box_reg: 0.5286  loss_mask: 0.2822  loss_rpn_cls: 0.08858  loss_rpn_loc: 0.1516  time: 1.8841  data_time: 0.1154  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:40:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:40:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:40:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:40:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:40:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:40:46 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 8659  total_loss: 1.433  loss_cls: 0.3623  loss_box_reg: 0.5547  loss_mask: 0.298  loss_rpn_cls: 0.08006  loss_rpn_loc: 0.1536  time: 1.8845  data_time: 0.0885  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:40:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:40:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:30 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 8679  total_loss: 1.336  loss_cls: 0.3345  loss_box_reg: 0.5331  loss_mask: 0.2896  loss_rpn_cls: 0.07002  loss_rpn_loc: 0.1328  time: 1.8852  data_time: 0.1435  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:41:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:41:58 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 8699  total_loss: 1.273  loss_cls: 0.3121  loss_box_reg: 0.5294  loss_mask: 0.2735  loss_rpn_cls: 0.0568  loss_rpn_loc: 0.1293  time: 1.8841  data_time: 0.0403  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:41:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:42:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:42:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:42:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:42:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:42:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 02:42:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 02:42:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 02:42:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:42:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 02:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.0958 s/iter. Eval: 0.0595 s/iter. Total: 0.1564 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 02:42:35 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0010 s/iter. Inference: 0.0965 s/iter. Eval: 0.0811 s/iter. Total: 0.1787 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 02:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0015 s/iter. Inference: 0.0971 s/iter. Eval: 0.0848 s/iter. Total: 0.1834 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 02:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0014 s/iter. Inference: 0.0975 s/iter. Eval: 0.0932 s/iter. Total: 0.1922 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 02:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0013 s/iter. Inference: 0.0976 s/iter. Eval: 0.0918 s/iter. Total: 0.1907 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 02:42:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.260545 (0.191901 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:42:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097665 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:42:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 02:42:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27753205521322005\n",
      "\u001b[32m[02/05 02:42:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:07 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 8719  total_loss: 1.452  loss_cls: 0.3334  loss_box_reg: 0.5579  loss_mask: 0.3051  loss_rpn_cls: 0.05479  loss_rpn_loc: 0.1412  time: 1.8849  data_time: 0.1517  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:43:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:43:54 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 8739  total_loss: 1.371  loss_cls: 0.3407  loss_box_reg: 0.5491  loss_mask: 0.2933  loss_rpn_cls: 0.06461  loss_rpn_loc: 0.1503  time: 1.8860  data_time: 0.1120  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:44:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:44:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:44:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:44:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:44:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:44:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:44:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:44:43 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 8759  total_loss: 1.367  loss_cls: 0.338  loss_box_reg: 0.5226  loss_mask: 0.2784  loss_rpn_cls: 0.07212  loss_rpn_loc: 0.1442  time: 1.8873  data_time: 0.1888  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:44:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:44:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:46 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 8779  total_loss: 1.417  loss_cls: 0.3596  loss_box_reg: 0.5263  loss_mask: 0.2839  loss_rpn_cls: 0.07388  loss_rpn_loc: 0.1505  time: 1.8902  data_time: 0.2058  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:45:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:45:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:46:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:46:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:46:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:46:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:46:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:46:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:46:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:46:54 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 8799  total_loss: 1.48  loss_cls: 0.3649  loss_box_reg: 0.5576  loss_mask: 0.2978  loss_rpn_cls: 0.07441  loss_rpn_loc: 0.1565  time: 1.8936  data_time: 0.2617  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:47:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:47:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:47:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:47:21 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 8819  total_loss: 1.315  loss_cls: 0.3247  loss_box_reg: 0.5231  loss_mask: 0.293  loss_rpn_cls: 0.06478  loss_rpn_loc: 0.137  time: 1.8924  data_time: 0.1289  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:47:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:47:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:47:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:47:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:47:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:48:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:48:08 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 8839  total_loss: 1.4  loss_cls: 0.3475  loss_box_reg: 0.5564  loss_mask: 0.3103  loss_rpn_cls: 0.06406  loss_rpn_loc: 0.1489  time: 1.8934  data_time: 0.1606  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:48:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:48:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:48:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:48:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:48:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:48:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:48:53 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 8859  total_loss: 1.384  loss_cls: 0.351  loss_box_reg: 0.54  loss_mask: 0.2825  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.1486  time: 1.8942  data_time: 0.1060  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:48:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:27 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 8879  total_loss: 1.327  loss_cls: 0.3292  loss_box_reg: 0.522  loss_mask: 0.2671  loss_rpn_cls: 0.06205  loss_rpn_loc: 0.1312  time: 1.8937  data_time: 0.0901  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:49:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:49:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:50:07 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 8899  total_loss: 1.455  loss_cls: 0.3758  loss_box_reg: 0.5547  loss_mask: 0.2999  loss_rpn_cls: 0.08958  loss_rpn_loc: 0.1552  time: 1.8940  data_time: 0.1346  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:50:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:50:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:50:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:50:35 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 8919  total_loss: 1.378  loss_cls: 0.3509  loss_box_reg: 0.5436  loss_mask: 0.2732  loss_rpn_cls: 0.06684  loss_rpn_loc: 0.1348  time: 1.8929  data_time: 0.0900  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:50:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:50:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:50:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:51:00 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 8939  total_loss: 1.355  loss_cls: 0.3302  loss_box_reg: 0.5593  loss_mask: 0.29  loss_rpn_cls: 0.04887  loss_rpn_loc: 0.1397  time: 1.8914  data_time: 0.0296  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:51:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:51:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:51:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:51:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:51:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 02:51:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 02:51:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 02:51:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:51:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 02:51:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0988 s/iter. Eval: 0.0598 s/iter. Total: 0.1595 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 02:51:30 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0010 s/iter. Inference: 0.0975 s/iter. Eval: 0.0847 s/iter. Total: 0.1833 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 02:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0011 s/iter. Inference: 0.0979 s/iter. Eval: 0.0864 s/iter. Total: 0.1855 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 02:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 89/121. Dataloading: 0.0011 s/iter. Inference: 0.0984 s/iter. Eval: 0.0944 s/iter. Total: 0.1939 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 02:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0011 s/iter. Inference: 0.0985 s/iter. Eval: 0.0931 s/iter. Total: 0.1927 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 02:51:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.523403 (0.194167 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:51:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.098584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 02:51:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 02:51:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27771956712022333\n",
      "\u001b[32m[02/05 02:51:50 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 8959  total_loss: 1.247  loss_cls: 0.2985  loss_box_reg: 0.4958  loss_mask: 0.2701  loss_rpn_cls: 0.05288  loss_rpn_loc: 0.131  time: 1.8901  data_time: 0.0628  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:51:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:51:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:52:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:52:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:52:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:52:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:52:32 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 8979  total_loss: 1.41  loss_cls: 0.3564  loss_box_reg: 0.5395  loss_mask: 0.278  loss_rpn_cls: 0.07672  loss_rpn_loc: 0.1459  time: 1.8905  data_time: 0.1360  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:52:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:52:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:52:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:52:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:23 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 8999  total_loss: 1.331  loss_cls: 0.3255  loss_box_reg: 0.5516  loss_mask: 0.3045  loss_rpn_cls: 0.05416  loss_rpn_loc: 0.1367  time: 1.8920  data_time: 0.1059  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:53:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:53 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 9019  total_loss: 1.297  loss_cls: 0.3069  loss_box_reg: 0.5179  loss_mask: 0.2831  loss_rpn_cls: 0.05142  loss_rpn_loc: 0.1182  time: 1.8911  data_time: 0.1351  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:53:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:53:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:54:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:54:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:54:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:54:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:54:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:54:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:54:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:54:52 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 9039  total_loss: 1.367  loss_cls: 0.3371  loss_box_reg: 0.5505  loss_mask: 0.2883  loss_rpn_cls: 0.08285  loss_rpn_loc: 0.1452  time: 1.8934  data_time: 0.1487  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:54:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:55:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:55:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:55:17 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 9059  total_loss: 1.266  loss_cls: 0.3065  loss_box_reg: 0.5021  loss_mask: 0.2613  loss_rpn_cls: 0.04141  loss_rpn_loc: 0.1324  time: 1.8920  data_time: 0.0730  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:55:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:55:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:55:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:55:47 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 9079  total_loss: 1.346  loss_cls: 0.3509  loss_box_reg: 0.519  loss_mask: 0.276  loss_rpn_cls: 0.05814  loss_rpn_loc: 0.1342  time: 1.8911  data_time: 0.1253  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:55:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:56:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:56:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:56:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:56:20 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 9099  total_loss: 1.478  loss_cls: 0.368  loss_box_reg: 0.5739  loss_mask: 0.2988  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.1496  time: 1.8907  data_time: 0.1231  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:56:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:56:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:56:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:56:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:56:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:57:05 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 9119  total_loss: 1.364  loss_cls: 0.334  loss_box_reg: 0.5355  loss_mask: 0.2957  loss_rpn_cls: 0.05409  loss_rpn_loc: 0.1339  time: 1.8914  data_time: 0.0739  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:57:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:57:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:57:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:57:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:57:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:57:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:57:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:57:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:58:00 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 9139  total_loss: 1.379  loss_cls: 0.3445  loss_box_reg: 0.541  loss_mask: 0.2808  loss_rpn_cls: 0.0677  loss_rpn_loc: 0.1274  time: 1.8933  data_time: 0.1593  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:58:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:58:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:58:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:58:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:58:32 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 9159  total_loss: 1.407  loss_cls: 0.347  loss_box_reg: 0.5286  loss_mask: 0.2816  loss_rpn_cls: 0.0894  loss_rpn_loc: 0.1652  time: 1.8927  data_time: 0.0502  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:58:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:58:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:58:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:58:57 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 9179  total_loss: 1.484  loss_cls: 0.3701  loss_box_reg: 0.5819  loss_mask: 0.2959  loss_rpn_cls: 0.08548  loss_rpn_loc: 0.149  time: 1.8913  data_time: 0.0864  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 02:58:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:59:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:59:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:59:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:59:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:59:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 02:59:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:59:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 02:59:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 02:59:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 02:59:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 02:59:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 02:59:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0990 s/iter. Eval: 0.0618 s/iter. Total: 0.1617 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 02:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0010 s/iter. Inference: 0.0978 s/iter. Eval: 0.0883 s/iter. Total: 0.1872 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 02:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0012 s/iter. Inference: 0.0980 s/iter. Eval: 0.0904 s/iter. Total: 0.1897 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 02:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0012 s/iter. Inference: 0.0981 s/iter. Eval: 0.0964 s/iter. Total: 0.1958 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 03:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0011 s/iter. Inference: 0.0977 s/iter. Eval: 0.0936 s/iter. Total: 0.1925 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 03:00:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.526499 (0.194194 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:00:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097893 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:00:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 03:00:04 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2764080302787783\n",
      "\u001b[32m[02/05 03:00:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:00:14 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 9199  total_loss: 1.41  loss_cls: 0.3441  loss_box_reg: 0.5455  loss_mask: 0.2881  loss_rpn_cls: 0.07746  loss_rpn_loc: 0.157  time: 1.8929  data_time: 0.2079  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:00:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:00:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:00:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:00:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:00:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:00:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:00:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:22 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 9219  total_loss: 1.4  loss_cls: 0.3546  loss_box_reg: 0.5517  loss_mask: 0.3003  loss_rpn_cls: 0.06584  loss_rpn_loc: 0.1506  time: 1.8961  data_time: 0.1590  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:01:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:01:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:02:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:02:08 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 9239  total_loss: 1.369  loss_cls: 0.3208  loss_box_reg: 0.5378  loss_mask: 0.2854  loss_rpn_cls: 0.06568  loss_rpn_loc: 0.1312  time: 1.8971  data_time: 0.1170  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:02:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:02:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:02:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:02:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:02:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:02:45 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 9259  total_loss: 1.35  loss_cls: 0.3215  loss_box_reg: 0.5212  loss_mask: 0.2825  loss_rpn_cls: 0.06499  loss_rpn_loc: 0.13  time: 1.8970  data_time: 0.1171  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:02:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:02:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:03:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:03:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:03:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:03:23 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 9279  total_loss: 1.35  loss_cls: 0.3475  loss_box_reg: 0.5207  loss_mask: 0.2793  loss_rpn_cls: 0.06314  loss_rpn_loc: 0.1294  time: 1.8970  data_time: 0.1158  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:03:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:03:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:03:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:03:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:03:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:04:01 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 9299  total_loss: 1.431  loss_cls: 0.3485  loss_box_reg: 0.5419  loss_mask: 0.2878  loss_rpn_cls: 0.0732  loss_rpn_loc: 0.1339  time: 1.8969  data_time: 0.1250  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:04:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:04:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:04:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:04:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:04:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:04:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:04:50 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 9319  total_loss: 1.342  loss_cls: 0.3171  loss_box_reg: 0.4985  loss_mask: 0.2723  loss_rpn_cls: 0.06593  loss_rpn_loc: 0.1289  time: 1.8982  data_time: 0.1445  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:04:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:05:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:05:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:05:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:05:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:05:27 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 9339  total_loss: 1.425  loss_cls: 0.3497  loss_box_reg: 0.5298  loss_mask: 0.2889  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.1775  time: 1.8981  data_time: 0.0923  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:05:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:05:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:05:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:05:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:15 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 9359  total_loss: 1.378  loss_cls: 0.3564  loss_box_reg: 0.5391  loss_mask: 0.2785  loss_rpn_cls: 0.06292  loss_rpn_loc: 0.143  time: 1.8991  data_time: 0.1790  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:06:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:51 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 9379  total_loss: 1.49  loss_cls: 0.3678  loss_box_reg: 0.5717  loss_mask: 0.2875  loss_rpn_cls: 0.07853  loss_rpn_loc: 0.1652  time: 1.8989  data_time: 0.1110  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:06:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:06:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:07:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:07:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:07:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:07:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:07:37 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 9399  total_loss: 1.365  loss_cls: 0.3247  loss_box_reg: 0.5574  loss_mask: 0.2954  loss_rpn_cls: 0.05719  loss_rpn_loc: 0.1422  time: 1.8997  data_time: 0.1025  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:07:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:07:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:08:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:08:09 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 9419  total_loss: 1.388  loss_cls: 0.3394  loss_box_reg: 0.5477  loss_mask: 0.2949  loss_rpn_cls: 0.05986  loss_rpn_loc: 0.1344  time: 1.8991  data_time: 0.1169  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:08:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:08:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:08:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:08:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:08:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:08:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 03:08:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 03:08:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 03:08:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 03:08:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 03:08:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 03:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0941 s/iter. Eval: 0.0583 s/iter. Total: 0.1533 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 03:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0010 s/iter. Inference: 0.0971 s/iter. Eval: 0.0875 s/iter. Total: 0.1857 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 03:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0010 s/iter. Inference: 0.0975 s/iter. Eval: 0.0878 s/iter. Total: 0.1863 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 03:09:03 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0010 s/iter. Inference: 0.0980 s/iter. Eval: 0.0945 s/iter. Total: 0.1936 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 03:09:08 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0010 s/iter. Inference: 0.0975 s/iter. Eval: 0.0927 s/iter. Total: 0.1912 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 03:09:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.344392 (0.192624 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:09:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097610 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:09:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 03:09:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.28039846482842384\n",
      "\u001b[32m[02/05 03:09:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:09:16 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 9439  total_loss: 1.395  loss_cls: 0.3395  loss_box_reg: 0.563  loss_mask: 0.2981  loss_rpn_cls: 0.06607  loss_rpn_loc: 0.14  time: 1.8996  data_time: 0.1458  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:09:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:09:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:09:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:09:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:09:53 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 9459  total_loss: 1.467  loss_cls: 0.3676  loss_box_reg: 0.5484  loss_mask: 0.2935  loss_rpn_cls: 0.08301  loss_rpn_loc: 0.1526  time: 1.8995  data_time: 0.1451  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:09:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:47 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 9479  total_loss: 1.38  loss_cls: 0.3382  loss_box_reg: 0.5506  loss_mask: 0.2934  loss_rpn_cls: 0.06901  loss_rpn_loc: 0.1524  time: 1.9012  data_time: 0.1983  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:10:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:10:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:11:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:11:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:11:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:11:29 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 9499  total_loss: 1.433  loss_cls: 0.3609  loss_box_reg: 0.5626  loss_mask: 0.3049  loss_rpn_cls: 0.0673  loss_rpn_loc: 0.1381  time: 1.9016  data_time: 0.1520  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:11:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:11:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:11:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:11:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:12:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:12:16 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 9519  total_loss: 1.434  loss_cls: 0.3564  loss_box_reg: 0.5721  loss_mask: 0.3102  loss_rpn_cls: 0.07074  loss_rpn_loc: 0.1551  time: 1.9025  data_time: 0.2388  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:12:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:12:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:12:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:12:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:12:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:12:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:13:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:13:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:13:21 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 9539  total_loss: 1.36  loss_cls: 0.353  loss_box_reg: 0.517  loss_mask: 0.2838  loss_rpn_cls: 0.07663  loss_rpn_loc: 0.139  time: 1.9054  data_time: 0.3064  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:13:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:13:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:13:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:13:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:13:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:13:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:14:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:14:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:14:13 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 9559  total_loss: 1.327  loss_cls: 0.3251  loss_box_reg: 0.5202  loss_mask: 0.2817  loss_rpn_cls: 0.06059  loss_rpn_loc: 0.1451  time: 1.9069  data_time: 0.1215  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:14:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:14:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:14:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:14:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:14:48 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 9579  total_loss: 1.331  loss_cls: 0.3364  loss_box_reg: 0.5251  loss_mask: 0.2853  loss_rpn_cls: 0.05329  loss_rpn_loc: 0.128  time: 1.9065  data_time: 0.0631  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:14:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:14:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:15:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:15:17 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 9599  total_loss: 1.283  loss_cls: 0.3006  loss_box_reg: 0.5188  loss_mask: 0.273  loss_rpn_cls: 0.0513  loss_rpn_loc: 0.1262  time: 1.9056  data_time: 0.1212  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:15:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:15:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:15:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:15:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:15:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:15:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:15:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:16:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:16:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:16:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:16:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:16:25 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 9619  total_loss: 1.526  loss_cls: 0.3774  loss_box_reg: 0.5601  loss_mask: 0.3012  loss_rpn_cls: 0.0721  loss_rpn_loc: 0.16  time: 1.9087  data_time: 0.2054  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:16:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:16:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:16:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:16:52 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 9639  total_loss: 1.357  loss_cls: 0.3489  loss_box_reg: 0.5435  loss_mask: 0.2961  loss_rpn_cls: 0.06052  loss_rpn_loc: 0.1398  time: 1.9075  data_time: 0.0804  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:16:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:17:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:17:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:17:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:17:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:17:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:17:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:17:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:17:45 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 9659  total_loss: 1.424  loss_cls: 0.3522  loss_box_reg: 0.5487  loss_mask: 0.292  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.1532  time: 1.9091  data_time: 0.1229  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:17:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:18:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 03:18:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 03:18:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 03:18:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 03:18:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 03:18:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 03:18:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0940 s/iter. Eval: 0.0646 s/iter. Total: 0.1595 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 03:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0010 s/iter. Inference: 0.0957 s/iter. Eval: 0.0905 s/iter. Total: 0.1872 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 03:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0013 s/iter. Inference: 0.0960 s/iter. Eval: 0.0901 s/iter. Total: 0.1874 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 03:18:20 d2.evaluation.evaluator]: \u001b[0mInference done 88/121. Dataloading: 0.0012 s/iter. Inference: 0.0968 s/iter. Eval: 0.0963 s/iter. Total: 0.1943 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 03:18:25 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0011 s/iter. Inference: 0.0967 s/iter. Eval: 0.0947 s/iter. Total: 0.1927 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 03:18:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.569725 (0.194567 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:18:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.096839 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:18:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 03:18:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2732037733740875\n",
      "\u001b[32m[02/05 03:18:26 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9679  total_loss: 1.356  loss_cls: 0.3184  loss_box_reg: 0.543  loss_mask: 0.2929  loss_rpn_cls: 0.04908  loss_rpn_loc: 0.1323  time: 1.9068  data_time: 0.0535  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:18:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:18:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:18:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:18:56 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 9699  total_loss: 1.349  loss_cls: 0.3448  loss_box_reg: 0.5121  loss_mask: 0.2644  loss_rpn_cls: 0.06619  loss_rpn_loc: 0.1439  time: 1.9060  data_time: 0.1673  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:19:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:19:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:19:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:19:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:19:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:19:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:19:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:19:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:19:53 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 9719  total_loss: 1.43  loss_cls: 0.3412  loss_box_reg: 0.5527  loss_mask: 0.2928  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.1594  time: 1.9079  data_time: 0.2493  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:19:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:20:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:20:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:20:21 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 9739  total_loss: 1.234  loss_cls: 0.305  loss_box_reg: 0.5042  loss_mask: 0.2784  loss_rpn_cls: 0.04396  loss_rpn_loc: 0.1174  time: 1.9068  data_time: 0.1430  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:20:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:20:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:20:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:20:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:20:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:15 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 9759  total_loss: 1.405  loss_cls: 0.3428  loss_box_reg: 0.5218  loss_mask: 0.2908  loss_rpn_cls: 0.08778  loss_rpn_loc: 0.1433  time: 1.9085  data_time: 0.2359  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:21:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:21:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:22:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:22:09 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 9779  total_loss: 1.371  loss_cls: 0.333  loss_box_reg: 0.5505  loss_mask: 0.3067  loss_rpn_cls: 0.06086  loss_rpn_loc: 0.1331  time: 1.9101  data_time: 0.1346  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:22:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:22:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:22:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:22:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:22:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:22:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:22:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:23:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:23:05 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9799  total_loss: 1.315  loss_cls: 0.3403  loss_box_reg: 0.4996  loss_mask: 0.2723  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.1367  time: 1.9119  data_time: 0.2310  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:23:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:23:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:23:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:23:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:23:43 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 9819  total_loss: 1.448  loss_cls: 0.3721  loss_box_reg: 0.5564  loss_mask: 0.3072  loss_rpn_cls: 0.0681  loss_rpn_loc: 0.1672  time: 1.9119  data_time: 0.1185  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:23:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:23:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:24:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:24:13 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9839  total_loss: 1.313  loss_cls: 0.3156  loss_box_reg: 0.5162  loss_mask: 0.2968  loss_rpn_cls: 0.05891  loss_rpn_loc: 0.126  time: 1.9110  data_time: 0.1186  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:24:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:24:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:24:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:24:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:24:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:24:54 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 9859  total_loss: 1.379  loss_cls: 0.351  loss_box_reg: 0.5286  loss_mask: 0.2849  loss_rpn_cls: 0.06968  loss_rpn_loc: 0.1275  time: 1.9113  data_time: 0.2068  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:25:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:25:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:25:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:25:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:25:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:25:30 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 9879  total_loss: 1.35  loss_cls: 0.3302  loss_box_reg: 0.5129  loss_mask: 0.2761  loss_rpn_cls: 0.07164  loss_rpn_loc: 0.134  time: 1.9111  data_time: 0.0740  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:25:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:25:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:25:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:25:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:26:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:26:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:26:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:26:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:26:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:26:37 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 9899  total_loss: 1.517  loss_cls: 0.3771  loss_box_reg: 0.558  loss_mask: 0.2977  loss_rpn_cls: 0.09399  loss_rpn_loc: 0.156  time: 1.9140  data_time: 0.2293  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:26:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:26:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:27:01 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 9919  total_loss: 1.428  loss_cls: 0.3438  loss_box_reg: 0.5401  loss_mask: 0.2939  loss_rpn_cls: 0.06423  loss_rpn_loc: 0.1376  time: 1.9125  data_time: 0.1220  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:27:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 03:27:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 03:27:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 03:27:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 03:27:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 03:27:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 03:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0026 s/iter. Inference: 0.0976 s/iter. Eval: 0.0627 s/iter. Total: 0.1630 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 03:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0013 s/iter. Inference: 0.0976 s/iter. Eval: 0.0887 s/iter. Total: 0.1877 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 03:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0017 s/iter. Inference: 0.0979 s/iter. Eval: 0.0924 s/iter. Total: 0.1922 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 03:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0016 s/iter. Inference: 0.0982 s/iter. Eval: 0.0995 s/iter. Total: 0.1995 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 03:27:25 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0014 s/iter. Inference: 0.0978 s/iter. Eval: 0.0954 s/iter. Total: 0.1947 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 03:27:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.794011 (0.196500 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:27:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097797 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:27:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 03:27:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2709892201137247\n",
      "\u001b[32m[02/05 03:27:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:27:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:27:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:27:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:27:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:28:04 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 9939  total_loss: 1.393  loss_cls: 0.3552  loss_box_reg: 0.5418  loss_mask: 0.294  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.1395  time: 1.9126  data_time: 0.1640  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:28:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:28:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:28:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:28:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:28:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:28:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:28:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:28:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:07 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 9959  total_loss: 1.448  loss_cls: 0.362  loss_box_reg: 0.5688  loss_mask: 0.2948  loss_rpn_cls: 0.07297  loss_rpn_loc: 0.1432  time: 1.9151  data_time: 0.1722  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:29:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:29:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:30:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:30:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 03:30:16 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 9979  total_loss: 1.5  loss_cls: 0.3713  loss_box_reg: 0.5746  loss_mask: 0.3149  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.1647  time: 1.9181  data_time: 0.0640  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:30:27 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.332  loss_cls: 0.3193  loss_box_reg: 0.5322  loss_mask: 0.2715  loss_rpn_cls: 0.06659  loss_rpn_loc: 0.1284  time: 1.9154  data_time: 0.0240  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 03:30:27 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 5:19:10 (1.9154 s / it)\n",
      "\u001b[32m[02/05 03:30:27 d2.engine.hooks]: \u001b[0mTotal training time: 5:35:14 (0:16:04 on hooks)\n",
      "\u001b[32m[02/05 03:30:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 03:30:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 03:30:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 03:30:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 03:30:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 03:30:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 03:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0010 s/iter. Inference: 0.0969 s/iter. Eval: 0.0716 s/iter. Total: 0.1695 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 03:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0010 s/iter. Inference: 0.0981 s/iter. Eval: 0.0900 s/iter. Total: 0.1892 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 03:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0012 s/iter. Inference: 0.0981 s/iter. Eval: 0.0915 s/iter. Total: 0.1909 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 03:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0011 s/iter. Inference: 0.0986 s/iter. Eval: 0.0972 s/iter. Total: 0.1970 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 03:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0011 s/iter. Inference: 0.0983 s/iter. Eval: 0.0954 s/iter. Total: 0.1948 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 03:30:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.721049 (0.195871 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:30:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.098272 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 03:30:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 03:30:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27449642590649975\n"
     ]
    }
   ],
   "source": [
    "# changing the anchor generator sizes and aspect ratios\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24, 40, 80, 128, 256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 1.0, 3.0]]\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9254479-cbf2-4764-82e4-01a0cc1c3850",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 11:02:00 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 11:02:01 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 11:02:02 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/05 11:02:02 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 11:02:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/05 11:02:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/05 11:02:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/05 11:02:03 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:02:03 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 11:02:03 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/05 11:02:17 d2.utils.events]: \u001b[0m eta: 1:22:24  iter: 19  total_loss: 3.285  loss_cls: 1.383  loss_box_reg: 0.5793  loss_mask: 0.6971  loss_rpn_cls: 0.3415  loss_rpn_loc: 0.2482  time: 0.7281  data_time: 0.2516  lr: 9.9905e-06  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:02:31 d2.utils.events]: \u001b[0m eta: 1:22:14  iter: 39  total_loss: 3.136  loss_cls: 1.287  loss_box_reg: 0.5804  loss_mask: 0.6898  loss_rpn_cls: 0.2998  loss_rpn_loc: 0.241  time: 0.7004  data_time: 0.2197  lr: 1.998e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:02:43 d2.utils.events]: \u001b[0m eta: 1:21:31  iter: 59  total_loss: 2.939  loss_cls: 1.107  loss_box_reg: 0.5904  loss_mask: 0.6756  loss_rpn_cls: 0.2893  loss_rpn_loc: 0.2273  time: 0.6633  data_time: 0.1438  lr: 2.997e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:02:55 d2.utils.events]: \u001b[0m eta: 1:19:52  iter: 79  total_loss: 2.786  loss_cls: 0.9529  loss_box_reg: 0.7385  loss_mask: 0.6531  loss_rpn_cls: 0.2553  loss_rpn_loc: 0.2336  time: 0.6509  data_time: 0.1692  lr: 3.9961e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:03:06 d2.utils.events]: \u001b[0m eta: 1:18:29  iter: 99  total_loss: 2.629  loss_cls: 0.832  loss_box_reg: 0.7431  loss_mask: 0.6185  loss_rpn_cls: 0.2357  loss_rpn_loc: 0.2315  time: 0.6320  data_time: 0.1090  lr: 4.9951e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:03:19 d2.utils.events]: \u001b[0m eta: 1:18:19  iter: 119  total_loss: 2.595  loss_cls: 0.7754  loss_box_reg: 0.777  loss_mask: 0.595  loss_rpn_cls: 0.1999  loss_rpn_loc: 0.22  time: 0.6337  data_time: 0.1675  lr: 5.9941e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:03:30 d2.utils.events]: \u001b[0m eta: 1:17:39  iter: 139  total_loss: 2.453  loss_cls: 0.7381  loss_box_reg: 0.8234  loss_mask: 0.5577  loss_rpn_cls: 0.1543  loss_rpn_loc: 0.184  time: 0.6214  data_time: 0.1044  lr: 6.993e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:03:45 d2.utils.events]: \u001b[0m eta: 1:18:17  iter: 159  total_loss: 2.353  loss_cls: 0.6946  loss_box_reg: 0.782  loss_mask: 0.5232  loss_rpn_cls: 0.1587  loss_rpn_loc: 0.2006  time: 0.6371  data_time: 0.2734  lr: 7.9921e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:04:00 d2.utils.events]: \u001b[0m eta: 1:18:24  iter: 179  total_loss: 2.337  loss_cls: 0.6509  loss_box_reg: 0.7688  loss_mask: 0.502  loss_rpn_cls: 0.1744  loss_rpn_loc: 0.2246  time: 0.6497  data_time: 0.2767  lr: 8.991e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:04:13 d2.utils.events]: \u001b[0m eta: 1:19:14  iter: 199  total_loss: 2.314  loss_cls: 0.6398  loss_box_reg: 0.7817  loss_mask: 0.4862  loss_rpn_cls: 0.15  loss_rpn_loc: 0.2145  time: 0.6512  data_time: 0.1923  lr: 9.9901e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:04:28 d2.utils.events]: \u001b[0m eta: 1:19:15  iter: 219  total_loss: 2.19  loss_cls: 0.5676  loss_box_reg: 0.7801  loss_mask: 0.4611  loss_rpn_cls: 0.16  loss_rpn_loc: 0.22  time: 0.6595  data_time: 0.2679  lr: 0.00010989  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:04:39 d2.utils.events]: \u001b[0m eta: 1:18:46  iter: 239  total_loss: 2.042  loss_cls: 0.5519  loss_box_reg: 0.742  loss_mask: 0.4038  loss_rpn_cls: 0.1366  loss_rpn_loc: 0.1845  time: 0.6529  data_time: 0.1300  lr: 0.00011988  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:04:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:04:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:04:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:04:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:04:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:04:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0825 s/iter. Eval: 0.0109 s/iter. Total: 0.0940 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 11:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0819 s/iter. Eval: 0.0131 s/iter. Total: 0.0958 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 11:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0007 s/iter. Inference: 0.0808 s/iter. Eval: 0.0114 s/iter. Total: 0.0930 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 11:04:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.823200 (0.093303 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:04:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.080768 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:04:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:04:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.09229610201801074\n",
      "\u001b[32m[02/05 11:05:04 d2.utils.events]: \u001b[0m eta: 1:18:46  iter: 259  total_loss: 1.907  loss_cls: 0.4596  loss_box_reg: 0.7638  loss_mask: 0.3763  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.1872  time: 0.6509  data_time: 0.1693  lr: 0.00012987  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:05:17 d2.utils.events]: \u001b[0m eta: 1:18:36  iter: 279  total_loss: 1.874  loss_cls: 0.4274  loss_box_reg: 0.7287  loss_mask: 0.3587  loss_rpn_cls: 0.1338  loss_rpn_loc: 0.1916  time: 0.6518  data_time: 0.2123  lr: 0.00013986  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:05:27 d2.utils.events]: \u001b[0m eta: 1:17:54  iter: 299  total_loss: 1.812  loss_cls: 0.412  loss_box_reg: 0.7205  loss_mask: 0.3554  loss_rpn_cls: 0.1307  loss_rpn_loc: 0.1947  time: 0.6407  data_time: 0.0463  lr: 0.00014985  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:05:41 d2.utils.events]: \u001b[0m eta: 1:18:05  iter: 319  total_loss: 1.785  loss_cls: 0.4198  loss_box_reg: 0.707  loss_mask: 0.3398  loss_rpn_cls: 0.1302  loss_rpn_loc: 0.1984  time: 0.6444  data_time: 0.2176  lr: 0.00015984  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:05:57 d2.utils.events]: \u001b[0m eta: 1:18:17  iter: 339  total_loss: 1.834  loss_cls: 0.4498  loss_box_reg: 0.7222  loss_mask: 0.3375  loss_rpn_cls: 0.1484  loss_rpn_loc: 0.2095  time: 0.6528  data_time: 0.3111  lr: 0.00016983  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:06:08 d2.utils.events]: \u001b[0m eta: 1:17:48  iter: 359  total_loss: 1.847  loss_cls: 0.4374  loss_box_reg: 0.6993  loss_mask: 0.3326  loss_rpn_cls: 0.1266  loss_rpn_loc: 0.1874  time: 0.6476  data_time: 0.1066  lr: 0.00017982  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:06:19 d2.utils.events]: \u001b[0m eta: 1:17:36  iter: 379  total_loss: 1.773  loss_cls: 0.4081  loss_box_reg: 0.6848  loss_mask: 0.3267  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.1938  time: 0.6433  data_time: 0.1119  lr: 0.00018981  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:06:32 d2.utils.events]: \u001b[0m eta: 1:17:27  iter: 399  total_loss: 1.706  loss_cls: 0.3857  loss_box_reg: 0.6552  loss_mask: 0.3192  loss_rpn_cls: 0.1352  loss_rpn_loc: 0.1972  time: 0.6439  data_time: 0.1845  lr: 0.0001998  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:06:47 d2.utils.events]: \u001b[0m eta: 1:17:14  iter: 419  total_loss: 1.858  loss_cls: 0.4201  loss_box_reg: 0.6767  loss_mask: 0.3221  loss_rpn_cls: 0.1431  loss_rpn_loc: 0.1848  time: 0.6481  data_time: 0.2612  lr: 0.00020979  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:07:02 d2.utils.events]: \u001b[0m eta: 1:17:10  iter: 439  total_loss: 1.776  loss_cls: 0.3748  loss_box_reg: 0.6575  loss_mask: 0.3181  loss_rpn_cls: 0.1496  loss_rpn_loc: 0.2011  time: 0.6537  data_time: 0.2932  lr: 0.00021978  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:07:14 d2.utils.events]: \u001b[0m eta: 1:17:00  iter: 459  total_loss: 1.672  loss_cls: 0.3708  loss_box_reg: 0.6316  loss_mask: 0.3207  loss_rpn_cls: 0.1358  loss_rpn_loc: 0.1999  time: 0.6494  data_time: 0.0909  lr: 0.00022977  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:07:24 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 479  total_loss: 1.572  loss_cls: 0.3013  loss_box_reg: 0.6282  loss_mask: 0.3188  loss_rpn_cls: 0.09079  loss_rpn_loc: 0.1836  time: 0.6434  data_time: 0.0745  lr: 0.00023976  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:07:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:07:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:07:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:07:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:07:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:07:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:07:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0844 s/iter. Eval: 0.0459 s/iter. Total: 0.1309 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 11:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0861 s/iter. Eval: 0.0619 s/iter. Total: 0.1488 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 11:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0007 s/iter. Inference: 0.0864 s/iter. Eval: 0.0651 s/iter. Total: 0.1523 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 11:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0866 s/iter. Eval: 0.0668 s/iter. Total: 0.1543 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:07:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.783450 (0.153306 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:07:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086607 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:07:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:07:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22248759797268244\n",
      "\u001b[32m[02/05 11:07:56 d2.utils.events]: \u001b[0m eta: 1:16:07  iter: 499  total_loss: 1.538  loss_cls: 0.3385  loss_box_reg: 0.6119  loss_mask: 0.3002  loss_rpn_cls: 0.09137  loss_rpn_loc: 0.1859  time: 0.6426  data_time: 0.1744  lr: 0.00024975  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:08:08 d2.utils.events]: \u001b[0m eta: 1:15:57  iter: 519  total_loss: 1.631  loss_cls: 0.3483  loss_box_reg: 0.6451  loss_mask: 0.314  loss_rpn_cls: 0.07635  loss_rpn_loc: 0.1631  time: 0.6423  data_time: 0.1780  lr: 0.00025974  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:08:23 d2.utils.events]: \u001b[0m eta: 1:15:50  iter: 539  total_loss: 1.67  loss_cls: 0.3934  loss_box_reg: 0.6407  loss_mask: 0.313  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.2079  time: 0.6457  data_time: 0.2707  lr: 0.00026973  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:08:35 d2.utils.events]: \u001b[0m eta: 1:15:28  iter: 559  total_loss: 1.482  loss_cls: 0.3256  loss_box_reg: 0.5953  loss_mask: 0.3013  loss_rpn_cls: 0.08736  loss_rpn_loc: 0.1475  time: 0.6441  data_time: 0.1511  lr: 0.00027972  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:08:50 d2.utils.events]: \u001b[0m eta: 1:15:19  iter: 579  total_loss: 1.789  loss_cls: 0.3916  loss_box_reg: 0.6427  loss_mask: 0.3212  loss_rpn_cls: 0.1403  loss_rpn_loc: 0.2193  time: 0.6478  data_time: 0.2880  lr: 0.00028971  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:09:06 d2.utils.events]: \u001b[0m eta: 1:15:21  iter: 599  total_loss: 1.671  loss_cls: 0.3765  loss_box_reg: 0.6334  loss_mask: 0.3202  loss_rpn_cls: 0.1294  loss_rpn_loc: 0.1981  time: 0.6535  data_time: 0.3340  lr: 0.0002997  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:09:21 d2.utils.events]: \u001b[0m eta: 1:15:18  iter: 619  total_loss: 1.644  loss_cls: 0.3637  loss_box_reg: 0.6162  loss_mask: 0.3226  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.1927  time: 0.6559  data_time: 0.2603  lr: 0.00030969  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:09:32 d2.utils.events]: \u001b[0m eta: 1:14:55  iter: 639  total_loss: 1.562  loss_cls: 0.3523  loss_box_reg: 0.6034  loss_mask: 0.3004  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.1849  time: 0.6523  data_time: 0.0891  lr: 0.00031968  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:09:44 d2.utils.events]: \u001b[0m eta: 1:14:41  iter: 659  total_loss: 1.571  loss_cls: 0.3597  loss_box_reg: 0.5852  loss_mask: 0.3224  loss_rpn_cls: 0.1145  loss_rpn_loc: 0.21  time: 0.6505  data_time: 0.1300  lr: 0.00032967  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:09:56 d2.utils.events]: \u001b[0m eta: 1:14:31  iter: 679  total_loss: 1.639  loss_cls: 0.3786  loss_box_reg: 0.631  loss_mask: 0.3167  loss_rpn_cls: 0.1  loss_rpn_loc: 0.1631  time: 0.6492  data_time: 0.1368  lr: 0.00033966  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:10:08 d2.utils.events]: \u001b[0m eta: 1:14:21  iter: 699  total_loss: 1.552  loss_cls: 0.3348  loss_box_reg: 0.5784  loss_mask: 0.3162  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.1964  time: 0.6475  data_time: 0.1395  lr: 0.00034965  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:10:19 d2.utils.events]: \u001b[0m eta: 1:14:11  iter: 719  total_loss: 1.536  loss_cls: 0.3475  loss_box_reg: 0.59  loss_mask: 0.3076  loss_rpn_cls: 0.119  loss_rpn_loc: 0.1811  time: 0.6458  data_time: 0.1174  lr: 0.00035964  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:10:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:10:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:10:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:10:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:10:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:10:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:10:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0826 s/iter. Eval: 0.0410 s/iter. Total: 0.1241 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 11:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0007 s/iter. Inference: 0.0846 s/iter. Eval: 0.0634 s/iter. Total: 0.1487 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 11:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0007 s/iter. Inference: 0.0848 s/iter. Eval: 0.0648 s/iter. Total: 0.1503 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 11:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0007 s/iter. Inference: 0.0849 s/iter. Eval: 0.0654 s/iter. Total: 0.1510 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 11:10:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.569258 (0.151459 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:10:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084985 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:10:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:10:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24208748711346992\n",
      "\u001b[32m[02/05 11:10:53 d2.utils.events]: \u001b[0m eta: 1:14:02  iter: 739  total_loss: 1.648  loss_cls: 0.3749  loss_box_reg: 0.6284  loss_mask: 0.3145  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.1883  time: 0.6476  data_time: 0.2478  lr: 0.00036963  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:11:05 d2.utils.events]: \u001b[0m eta: 1:13:52  iter: 759  total_loss: 1.588  loss_cls: 0.3807  loss_box_reg: 0.6296  loss_mask: 0.3128  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2233  time: 0.6467  data_time: 0.1591  lr: 0.00037962  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:11:18 d2.utils.events]: \u001b[0m eta: 1:13:40  iter: 779  total_loss: 1.623  loss_cls: 0.3655  loss_box_reg: 0.5864  loss_mask: 0.3024  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.2099  time: 0.6464  data_time: 0.1718  lr: 0.00038961  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:11:29 d2.utils.events]: \u001b[0m eta: 1:13:23  iter: 799  total_loss: 1.483  loss_cls: 0.321  loss_box_reg: 0.594  loss_mask: 0.3056  loss_rpn_cls: 0.07275  loss_rpn_loc: 0.1677  time: 0.6440  data_time: 0.1209  lr: 0.0003996  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:11:41 d2.utils.events]: \u001b[0m eta: 1:13:13  iter: 819  total_loss: 1.512  loss_cls: 0.3481  loss_box_reg: 0.6013  loss_mask: 0.2857  loss_rpn_cls: 0.09738  loss_rpn_loc: 0.1833  time: 0.6437  data_time: 0.1776  lr: 0.00040959  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:11:52 d2.utils.events]: \u001b[0m eta: 1:13:00  iter: 839  total_loss: 1.645  loss_cls: 0.365  loss_box_reg: 0.6232  loss_mask: 0.3093  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.1837  time: 0.6404  data_time: 0.0532  lr: 0.00041958  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:12:03 d2.utils.events]: \u001b[0m eta: 1:12:49  iter: 859  total_loss: 1.54  loss_cls: 0.3266  loss_box_reg: 0.6181  loss_mask: 0.3225  loss_rpn_cls: 0.08235  loss_rpn_loc: 0.1515  time: 0.6394  data_time: 0.1483  lr: 0.00042957  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:12:17 d2.utils.events]: \u001b[0m eta: 1:12:51  iter: 879  total_loss: 1.591  loss_cls: 0.3981  loss_box_reg: 0.6161  loss_mask: 0.3136  loss_rpn_cls: 0.124  loss_rpn_loc: 0.1855  time: 0.6400  data_time: 0.1874  lr: 0.00043956  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:12:34 d2.utils.events]: \u001b[0m eta: 1:12:45  iter: 899  total_loss: 1.542  loss_cls: 0.3521  loss_box_reg: 0.5902  loss_mask: 0.3057  loss_rpn_cls: 0.08217  loss_rpn_loc: 0.1979  time: 0.6454  data_time: 0.4017  lr: 0.00044955  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:12:47 d2.utils.events]: \u001b[0m eta: 1:12:36  iter: 919  total_loss: 1.541  loss_cls: 0.3501  loss_box_reg: 0.587  loss_mask: 0.3089  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.1899  time: 0.6446  data_time: 0.1468  lr: 0.00045954  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:13:01 d2.utils.events]: \u001b[0m eta: 1:12:27  iter: 939  total_loss: 1.616  loss_cls: 0.3714  loss_box_reg: 0.583  loss_mask: 0.3189  loss_rpn_cls: 0.1189  loss_rpn_loc: 0.2063  time: 0.6458  data_time: 0.2343  lr: 0.00046953  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:13:14 d2.utils.events]: \u001b[0m eta: 1:12:20  iter: 959  total_loss: 1.58  loss_cls: 0.3514  loss_box_reg: 0.6068  loss_mask: 0.3034  loss_rpn_cls: 0.09963  loss_rpn_loc: 0.1859  time: 0.6466  data_time: 0.2078  lr: 0.00047952  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:13:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:13:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:13:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:13:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:13:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:13:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0827 s/iter. Eval: 0.0434 s/iter. Total: 0.1268 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 11:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0007 s/iter. Inference: 0.0846 s/iter. Eval: 0.0641 s/iter. Total: 0.1495 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 11:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0655 s/iter. Total: 0.1511 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 11:13:39 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0851 s/iter. Eval: 0.0686 s/iter. Total: 0.1545 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:13:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.847040 (0.153854 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:13:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085060 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:13:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:13:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2459414825621442\n",
      "\u001b[32m[02/05 11:13:51 d2.utils.events]: \u001b[0m eta: 1:12:19  iter: 979  total_loss: 1.633  loss_cls: 0.3784  loss_box_reg: 0.5792  loss_mask: 0.3071  loss_rpn_cls: 0.1189  loss_rpn_loc: 0.1785  time: 0.6512  data_time: 0.3888  lr: 0.00048951  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:14:08 d2.utils.events]: \u001b[0m eta: 1:12:17  iter: 999  total_loss: 1.581  loss_cls: 0.3823  loss_box_reg: 0.6076  loss_mask: 0.3161  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.1932  time: 0.6548  data_time: 0.3427  lr: 0.0004995  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:14:22 d2.utils.events]: \u001b[0m eta: 1:12:03  iter: 1019  total_loss: 1.72  loss_cls: 0.3658  loss_box_reg: 0.6132  loss_mask: 0.3146  loss_rpn_cls: 0.1243  loss_rpn_loc: 0.2172  time: 0.6563  data_time: 0.2622  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:14:36 d2.utils.events]: \u001b[0m eta: 1:11:55  iter: 1039  total_loss: 1.506  loss_cls: 0.3486  loss_box_reg: 0.5656  loss_mask: 0.3195  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.18  time: 0.6569  data_time: 0.2176  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:14:49 d2.utils.events]: \u001b[0m eta: 1:11:44  iter: 1059  total_loss: 1.524  loss_cls: 0.3433  loss_box_reg: 0.5782  loss_mask: 0.2998  loss_rpn_cls: 0.09212  loss_rpn_loc: 0.1534  time: 0.6569  data_time: 0.1977  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:15:04 d2.utils.events]: \u001b[0m eta: 1:11:41  iter: 1079  total_loss: 1.518  loss_cls: 0.356  loss_box_reg: 0.5981  loss_mask: 0.3004  loss_rpn_cls: 0.09796  loss_rpn_loc: 0.1807  time: 0.6580  data_time: 0.2431  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:15:14 d2.utils.events]: \u001b[0m eta: 1:11:33  iter: 1099  total_loss: 1.525  loss_cls: 0.3324  loss_box_reg: 0.5919  loss_mask: 0.3041  loss_rpn_cls: 0.0915  loss_rpn_loc: 0.1947  time: 0.6553  data_time: 0.0624  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:15:27 d2.utils.events]: \u001b[0m eta: 1:11:23  iter: 1119  total_loss: 1.573  loss_cls: 0.3529  loss_box_reg: 0.5925  loss_mask: 0.3079  loss_rpn_cls: 0.107  loss_rpn_loc: 0.1966  time: 0.6554  data_time: 0.2053  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:15:39 d2.utils.events]: \u001b[0m eta: 1:11:15  iter: 1139  total_loss: 1.519  loss_cls: 0.3639  loss_box_reg: 0.5761  loss_mask: 0.2953  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.1777  time: 0.6542  data_time: 0.1190  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:15:50 d2.utils.events]: \u001b[0m eta: 1:11:04  iter: 1159  total_loss: 1.648  loss_cls: 0.3784  loss_box_reg: 0.6032  loss_mask: 0.3164  loss_rpn_cls: 0.09668  loss_rpn_loc: 0.1954  time: 0.6530  data_time: 0.1140  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:16:01 d2.utils.events]: \u001b[0m eta: 1:10:50  iter: 1179  total_loss: 1.502  loss_cls: 0.3173  loss_box_reg: 0.5936  loss_mask: 0.3062  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.168  time: 0.6509  data_time: 0.0743  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:16:13 d2.utils.events]: \u001b[0m eta: 1:10:28  iter: 1199  total_loss: 1.443  loss_cls: 0.3105  loss_box_reg: 0.5741  loss_mask: 0.2982  loss_rpn_cls: 0.07024  loss_rpn_loc: 0.1694  time: 0.6497  data_time: 0.1368  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:16:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:16:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:16:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:16:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:16:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:16:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0847 s/iter. Eval: 0.0510 s/iter. Total: 0.1363 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 11:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0859 s/iter. Eval: 0.0674 s/iter. Total: 0.1541 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0007 s/iter. Inference: 0.0861 s/iter. Eval: 0.0701 s/iter. Total: 0.1571 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0727 s/iter. Total: 0.1598 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:16:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.484326 (0.159348 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:16:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086296 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:16:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:16:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2452752587230226\n",
      "\u001b[32m[02/05 11:16:46 d2.utils.events]: \u001b[0m eta: 1:10:12  iter: 1219  total_loss: 1.464  loss_cls: 0.3512  loss_box_reg: 0.5939  loss_mask: 0.3067  loss_rpn_cls: 0.1  loss_rpn_loc: 0.1615  time: 0.6496  data_time: 0.1900  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:16:56 d2.utils.events]: \u001b[0m eta: 1:10:02  iter: 1239  total_loss: 1.474  loss_cls: 0.347  loss_box_reg: 0.5606  loss_mask: 0.3161  loss_rpn_cls: 0.09414  loss_rpn_loc: 0.1773  time: 0.6474  data_time: 0.0634  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:17:10 d2.utils.events]: \u001b[0m eta: 1:09:49  iter: 1259  total_loss: 1.511  loss_cls: 0.3453  loss_box_reg: 0.5688  loss_mask: 0.2927  loss_rpn_cls: 0.1274  loss_rpn_loc: 0.1987  time: 0.6483  data_time: 0.2490  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:17:22 d2.utils.events]: \u001b[0m eta: 1:09:37  iter: 1279  total_loss: 1.322  loss_cls: 0.293  loss_box_reg: 0.5469  loss_mask: 0.3046  loss_rpn_cls: 0.06782  loss_rpn_loc: 0.1578  time: 0.6472  data_time: 0.1312  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:17:33 d2.utils.events]: \u001b[0m eta: 1:09:30  iter: 1299  total_loss: 1.565  loss_cls: 0.3457  loss_box_reg: 0.5915  loss_mask: 0.3261  loss_rpn_cls: 0.09955  loss_rpn_loc: 0.188  time: 0.6463  data_time: 0.1439  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:17:44 d2.utils.events]: \u001b[0m eta: 1:09:16  iter: 1319  total_loss: 1.497  loss_cls: 0.347  loss_box_reg: 0.6303  loss_mask: 0.298  loss_rpn_cls: 0.08855  loss_rpn_loc: 0.1646  time: 0.6448  data_time: 0.0823  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:17:59 d2.utils.events]: \u001b[0m eta: 1:09:03  iter: 1339  total_loss: 1.556  loss_cls: 0.3414  loss_box_reg: 0.5949  loss_mask: 0.3094  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.1977  time: 0.6461  data_time: 0.2611  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:18:11 d2.utils.events]: \u001b[0m eta: 1:08:52  iter: 1359  total_loss: 1.544  loss_cls: 0.3271  loss_box_reg: 0.612  loss_mask: 0.3125  loss_rpn_cls: 0.09126  loss_rpn_loc: 0.1779  time: 0.6453  data_time: 0.1349  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:18:24 d2.utils.events]: \u001b[0m eta: 1:08:47  iter: 1379  total_loss: 1.545  loss_cls: 0.3566  loss_box_reg: 0.5991  loss_mask: 0.3177  loss_rpn_cls: 0.09009  loss_rpn_loc: 0.1931  time: 0.6459  data_time: 0.2102  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:18:38 d2.utils.events]: \u001b[0m eta: 1:08:35  iter: 1399  total_loss: 1.501  loss_cls: 0.3282  loss_box_reg: 0.5873  loss_mask: 0.3133  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.1928  time: 0.6465  data_time: 0.2208  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:18:53 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 1419  total_loss: 1.511  loss_cls: 0.34  loss_box_reg: 0.5829  loss_mask: 0.3169  loss_rpn_cls: 0.0932  loss_rpn_loc: 0.1642  time: 0.6479  data_time: 0.2690  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:19:06 d2.utils.events]: \u001b[0m eta: 1:08:19  iter: 1439  total_loss: 1.458  loss_cls: 0.3424  loss_box_reg: 0.574  loss_mask: 0.2986  loss_rpn_cls: 0.07863  loss_rpn_loc: 0.1639  time: 0.6476  data_time: 0.1495  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:19:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:19:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:19:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:19:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:19:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:19:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0826 s/iter. Eval: 0.0445 s/iter. Total: 0.1277 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 11:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0650 s/iter. Total: 0.1506 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 11:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0008 s/iter. Inference: 0.0848 s/iter. Eval: 0.0663 s/iter. Total: 0.1520 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 11:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.0850 s/iter. Eval: 0.0689 s/iter. Total: 0.1548 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:19:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.861384 (0.153977 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:19:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084953 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:19:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:19:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26345371269449674\n",
      "\u001b[32m[02/05 11:19:41 d2.utils.events]: \u001b[0m eta: 1:08:13  iter: 1459  total_loss: 1.477  loss_cls: 0.346  loss_box_reg: 0.5769  loss_mask: 0.3035  loss_rpn_cls: 0.09843  loss_rpn_loc: 0.1772  time: 0.6495  data_time: 0.2761  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:19:57 d2.utils.events]: \u001b[0m eta: 1:08:16  iter: 1479  total_loss: 1.464  loss_cls: 0.3318  loss_box_reg: 0.5736  loss_mask: 0.3079  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.1851  time: 0.6514  data_time: 0.2953  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:20:09 d2.utils.events]: \u001b[0m eta: 1:08:12  iter: 1499  total_loss: 1.37  loss_cls: 0.2879  loss_box_reg: 0.5533  loss_mask: 0.2876  loss_rpn_cls: 0.06765  loss_rpn_loc: 0.1743  time: 0.6508  data_time: 0.1494  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:20:19 d2.utils.events]: \u001b[0m eta: 1:08:03  iter: 1519  total_loss: 1.334  loss_cls: 0.2929  loss_box_reg: 0.5352  loss_mask: 0.27  loss_rpn_cls: 0.06323  loss_rpn_loc: 0.1415  time: 0.6488  data_time: 0.0400  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:20:36 d2.utils.events]: \u001b[0m eta: 1:07:56  iter: 1539  total_loss: 1.608  loss_cls: 0.3861  loss_box_reg: 0.6018  loss_mask: 0.316  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.1918  time: 0.6514  data_time: 0.3507  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:20:49 d2.utils.events]: \u001b[0m eta: 1:07:54  iter: 1559  total_loss: 1.59  loss_cls: 0.3473  loss_box_reg: 0.5967  loss_mask: 0.3166  loss_rpn_cls: 0.09358  loss_rpn_loc: 0.1925  time: 0.6515  data_time: 0.1806  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:21:01 d2.utils.events]: \u001b[0m eta: 1:07:40  iter: 1579  total_loss: 1.47  loss_cls: 0.3413  loss_box_reg: 0.5756  loss_mask: 0.2969  loss_rpn_cls: 0.07994  loss_rpn_loc: 0.1546  time: 0.6511  data_time: 0.1595  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:21:12 d2.utils.events]: \u001b[0m eta: 1:07:27  iter: 1599  total_loss: 1.556  loss_cls: 0.3438  loss_box_reg: 0.5954  loss_mask: 0.3082  loss_rpn_cls: 0.07334  loss_rpn_loc: 0.1924  time: 0.6493  data_time: 0.0455  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:21:24 d2.utils.events]: \u001b[0m eta: 1:07:18  iter: 1619  total_loss: 1.471  loss_cls: 0.3216  loss_box_reg: 0.5844  loss_mask: 0.3186  loss_rpn_cls: 0.0887  loss_rpn_loc: 0.1699  time: 0.6492  data_time: 0.1646  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:21:36 d2.utils.events]: \u001b[0m eta: 1:07:14  iter: 1639  total_loss: 1.47  loss_cls: 0.342  loss_box_reg: 0.5579  loss_mask: 0.2993  loss_rpn_cls: 0.0913  loss_rpn_loc: 0.1631  time: 0.6482  data_time: 0.0997  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:21:53 d2.utils.events]: \u001b[0m eta: 1:07:12  iter: 1659  total_loss: 1.579  loss_cls: 0.3723  loss_box_reg: 0.5756  loss_mask: 0.3021  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.2076  time: 0.6510  data_time: 0.3881  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:22:12 d2.utils.events]: \u001b[0m eta: 1:07:07  iter: 1679  total_loss: 1.543  loss_cls: 0.3384  loss_box_reg: 0.553  loss_mask: 0.3134  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.2025  time: 0.6543  data_time: 0.4461  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:22:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:22:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:22:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:22:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:22:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:22:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0871 s/iter. Eval: 0.0508 s/iter. Total: 0.1386 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0706 s/iter. Total: 0.1592 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:22:34 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0715 s/iter. Total: 0.1599 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0741 s/iter. Total: 0.1629 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:22:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.889659 (0.162842 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:22:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:22:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:22:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26131805180408924\n",
      "\u001b[32m[02/05 11:22:47 d2.utils.events]: \u001b[0m eta: 1:06:58  iter: 1699  total_loss: 1.525  loss_cls: 0.3689  loss_box_reg: 0.584  loss_mask: 0.3103  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.1803  time: 0.6551  data_time: 0.2423  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:23:02 d2.utils.events]: \u001b[0m eta: 1:06:50  iter: 1719  total_loss: 1.564  loss_cls: 0.3415  loss_box_reg: 0.585  loss_mask: 0.315  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.1845  time: 0.6564  data_time: 0.2917  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:23:17 d2.utils.events]: \u001b[0m eta: 1:06:48  iter: 1739  total_loss: 1.536  loss_cls: 0.3527  loss_box_reg: 0.5704  loss_mask: 0.295  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.1919  time: 0.6573  data_time: 0.2532  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:23:31 d2.utils.events]: \u001b[0m eta: 1:06:38  iter: 1759  total_loss: 1.466  loss_cls: 0.3406  loss_box_reg: 0.5897  loss_mask: 0.3136  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.1746  time: 0.6578  data_time: 0.2300  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:23:45 d2.utils.events]: \u001b[0m eta: 1:06:28  iter: 1779  total_loss: 1.527  loss_cls: 0.3429  loss_box_reg: 0.5752  loss_mask: 0.3092  loss_rpn_cls: 0.0899  loss_rpn_loc: 0.1877  time: 0.6583  data_time: 0.2417  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:23:58 d2.utils.events]: \u001b[0m eta: 1:06:23  iter: 1799  total_loss: 1.473  loss_cls: 0.3378  loss_box_reg: 0.5701  loss_mask: 0.3026  loss_rpn_cls: 0.08642  loss_rpn_loc: 0.1714  time: 0.6580  data_time: 0.1606  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:24:11 d2.utils.events]: \u001b[0m eta: 1:06:15  iter: 1819  total_loss: 1.468  loss_cls: 0.3391  loss_box_reg: 0.578  loss_mask: 0.3017  loss_rpn_cls: 0.08455  loss_rpn_loc: 0.1866  time: 0.6579  data_time: 0.1741  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:24:22 d2.utils.events]: \u001b[0m eta: 1:06:13  iter: 1839  total_loss: 1.473  loss_cls: 0.3301  loss_box_reg: 0.5365  loss_mask: 0.301  loss_rpn_cls: 0.09972  loss_rpn_loc: 0.15  time: 0.6570  data_time: 0.1102  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:24:34 d2.utils.events]: \u001b[0m eta: 1:06:03  iter: 1859  total_loss: 1.481  loss_cls: 0.3136  loss_box_reg: 0.6084  loss_mask: 0.305  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.1815  time: 0.6563  data_time: 0.1129  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:24:50 d2.utils.events]: \u001b[0m eta: 1:05:53  iter: 1879  total_loss: 1.585  loss_cls: 0.3648  loss_box_reg: 0.5871  loss_mask: 0.3026  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.179  time: 0.6576  data_time: 0.2811  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:25:00 d2.utils.events]: \u001b[0m eta: 1:05:34  iter: 1899  total_loss: 1.48  loss_cls: 0.368  loss_box_reg: 0.6087  loss_mask: 0.307  loss_rpn_cls: 0.0937  loss_rpn_loc: 0.1649  time: 0.6564  data_time: 0.0863  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:25:13 d2.utils.events]: \u001b[0m eta: 1:05:24  iter: 1919  total_loss: 1.52  loss_cls: 0.3364  loss_box_reg: 0.5628  loss_mask: 0.2935  loss_rpn_cls: 0.09344  loss_rpn_loc: 0.173  time: 0.6561  data_time: 0.1693  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:25:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:25:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:25:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:25:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:25:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:25:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0848 s/iter. Eval: 0.0546 s/iter. Total: 0.1400 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0697 s/iter. Total: 0.1569 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0866 s/iter. Eval: 0.0721 s/iter. Total: 0.1595 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0746 s/iter. Total: 0.1621 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:25:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.769261 (0.161804 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:25:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086734 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:25:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:25:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25165606960710835\n",
      "\u001b[32m[02/05 11:25:45 d2.utils.events]: \u001b[0m eta: 1:05:11  iter: 1939  total_loss: 1.456  loss_cls: 0.3499  loss_box_reg: 0.5578  loss_mask: 0.2994  loss_rpn_cls: 0.07098  loss_rpn_loc: 0.1599  time: 0.6553  data_time: 0.1337  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:25:59 d2.utils.events]: \u001b[0m eta: 1:05:06  iter: 1959  total_loss: 1.56  loss_cls: 0.3925  loss_box_reg: 0.6022  loss_mask: 0.3218  loss_rpn_cls: 0.1127  loss_rpn_loc: 0.2132  time: 0.6560  data_time: 0.2362  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:26:11 d2.utils.events]: \u001b[0m eta: 1:04:49  iter: 1979  total_loss: 1.35  loss_cls: 0.3296  loss_box_reg: 0.5376  loss_mask: 0.2723  loss_rpn_cls: 0.07787  loss_rpn_loc: 0.1442  time: 0.6552  data_time: 0.1300  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:26:25 d2.utils.events]: \u001b[0m eta: 1:04:39  iter: 1999  total_loss: 1.547  loss_cls: 0.3436  loss_box_reg: 0.5976  loss_mask: 0.3175  loss_rpn_cls: 0.08595  loss_rpn_loc: 0.1755  time: 0.6554  data_time: 0.1917  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:26:39 d2.utils.events]: \u001b[0m eta: 1:04:31  iter: 2019  total_loss: 1.452  loss_cls: 0.3253  loss_box_reg: 0.569  loss_mask: 0.3048  loss_rpn_cls: 0.0723  loss_rpn_loc: 0.1605  time: 0.6561  data_time: 0.2466  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:26:52 d2.utils.events]: \u001b[0m eta: 1:04:22  iter: 2039  total_loss: 1.549  loss_cls: 0.342  loss_box_reg: 0.5708  loss_mask: 0.3147  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.1963  time: 0.6561  data_time: 0.1879  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:27:07 d2.utils.events]: \u001b[0m eta: 1:04:21  iter: 2059  total_loss: 1.399  loss_cls: 0.3294  loss_box_reg: 0.5642  loss_mask: 0.297  loss_rpn_cls: 0.08466  loss_rpn_loc: 0.1514  time: 0.6568  data_time: 0.2342  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:27:20 d2.utils.events]: \u001b[0m eta: 1:04:07  iter: 2079  total_loss: 1.437  loss_cls: 0.2924  loss_box_reg: 0.548  loss_mask: 0.2989  loss_rpn_cls: 0.07966  loss_rpn_loc: 0.1688  time: 0.6570  data_time: 0.1942  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:27:31 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 2099  total_loss: 1.378  loss_cls: 0.3146  loss_box_reg: 0.563  loss_mask: 0.2866  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.1557  time: 0.6560  data_time: 0.1123  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:27:45 d2.utils.events]: \u001b[0m eta: 1:03:52  iter: 2119  total_loss: 1.459  loss_cls: 0.3388  loss_box_reg: 0.5757  loss_mask: 0.2902  loss_rpn_cls: 0.08985  loss_rpn_loc: 0.1969  time: 0.6565  data_time: 0.2225  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:28:00 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 2139  total_loss: 1.617  loss_cls: 0.3603  loss_box_reg: 0.5995  loss_mask: 0.3144  loss_rpn_cls: 0.09256  loss_rpn_loc: 0.1875  time: 0.6572  data_time: 0.2534  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:28:12 d2.utils.events]: \u001b[0m eta: 1:03:40  iter: 2159  total_loss: 1.486  loss_cls: 0.3116  loss_box_reg: 0.5684  loss_mask: 0.3133  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.1916  time: 0.6566  data_time: 0.1356  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:28:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:28:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:28:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:28:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:28:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:28:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0861 s/iter. Eval: 0.0550 s/iter. Total: 0.1417 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0881 s/iter. Eval: 0.0708 s/iter. Total: 0.1598 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0714 s/iter. Total: 0.1598 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0743 s/iter. Total: 0.1625 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:28:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.774111 (0.161846 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:28:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087113 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:28:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:28:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25762383427832597\n",
      "\u001b[32m[02/05 11:28:45 d2.utils.events]: \u001b[0m eta: 1:03:42  iter: 2179  total_loss: 1.511  loss_cls: 0.3526  loss_box_reg: 0.5965  loss_mask: 0.3149  loss_rpn_cls: 0.08943  loss_rpn_loc: 0.1705  time: 0.6561  data_time: 0.1190  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:28:58 d2.utils.events]: \u001b[0m eta: 1:03:47  iter: 2199  total_loss: 1.498  loss_cls: 0.3615  loss_box_reg: 0.5683  loss_mask: 0.3131  loss_rpn_cls: 0.09582  loss_rpn_loc: 0.1904  time: 0.6564  data_time: 0.2160  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:29:11 d2.utils.events]: \u001b[0m eta: 1:03:39  iter: 2219  total_loss: 1.438  loss_cls: 0.3075  loss_box_reg: 0.5808  loss_mask: 0.299  loss_rpn_cls: 0.08281  loss_rpn_loc: 0.1733  time: 0.6562  data_time: 0.1566  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:29:24 d2.utils.events]: \u001b[0m eta: 1:03:33  iter: 2239  total_loss: 1.484  loss_cls: 0.3301  loss_box_reg: 0.5769  loss_mask: 0.3099  loss_rpn_cls: 0.08236  loss_rpn_loc: 0.1826  time: 0.6562  data_time: 0.1875  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:29:36 d2.utils.events]: \u001b[0m eta: 1:03:21  iter: 2259  total_loss: 1.409  loss_cls: 0.304  loss_box_reg: 0.542  loss_mask: 0.289  loss_rpn_cls: 0.06482  loss_rpn_loc: 0.1692  time: 0.6555  data_time: 0.1229  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:29:48 d2.utils.events]: \u001b[0m eta: 1:03:15  iter: 2279  total_loss: 1.467  loss_cls: 0.3338  loss_box_reg: 0.5711  loss_mask: 0.3065  loss_rpn_cls: 0.07734  loss_rpn_loc: 0.1637  time: 0.6550  data_time: 0.1330  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:30:00 d2.utils.events]: \u001b[0m eta: 1:03:03  iter: 2299  total_loss: 1.434  loss_cls: 0.3239  loss_box_reg: 0.5509  loss_mask: 0.2845  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.1655  time: 0.6545  data_time: 0.1437  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:30:15 d2.utils.events]: \u001b[0m eta: 1:02:59  iter: 2319  total_loss: 1.426  loss_cls: 0.3076  loss_box_reg: 0.5621  loss_mask: 0.3023  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.1805  time: 0.6553  data_time: 0.2559  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:30:29 d2.utils.events]: \u001b[0m eta: 1:02:56  iter: 2339  total_loss: 1.583  loss_cls: 0.3748  loss_box_reg: 0.5673  loss_mask: 0.3068  loss_rpn_cls: 0.09859  loss_rpn_loc: 0.2077  time: 0.6558  data_time: 0.2227  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:30:44 d2.utils.events]: \u001b[0m eta: 1:02:53  iter: 2359  total_loss: 1.449  loss_cls: 0.2997  loss_box_reg: 0.5679  loss_mask: 0.3035  loss_rpn_cls: 0.07051  loss_rpn_loc: 0.1722  time: 0.6565  data_time: 0.2685  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:30:54 d2.utils.events]: \u001b[0m eta: 1:02:34  iter: 2379  total_loss: 1.369  loss_cls: 0.3045  loss_box_reg: 0.5616  loss_mask: 0.2977  loss_rpn_cls: 0.05845  loss_rpn_loc: 0.1675  time: 0.6554  data_time: 0.0653  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:31:08 d2.utils.events]: \u001b[0m eta: 1:02:34  iter: 2399  total_loss: 1.619  loss_cls: 0.3672  loss_box_reg: 0.5826  loss_mask: 0.3102  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.204  time: 0.6558  data_time: 0.2127  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:31:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:31:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:31:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:31:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:31:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:31:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:31:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0866 s/iter. Eval: 0.0529 s/iter. Total: 0.1401 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0703 s/iter. Total: 0.1595 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0708 s/iter. Total: 0.1604 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0754 s/iter. Total: 0.1659 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 11:31:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.125771 (0.164877 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:31:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089188 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:31:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:31:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26313188066061016\n",
      "\u001b[32m[02/05 11:31:43 d2.utils.events]: \u001b[0m eta: 1:02:23  iter: 2419  total_loss: 1.552  loss_cls: 0.35  loss_box_reg: 0.5861  loss_mask: 0.3109  loss_rpn_cls: 0.09921  loss_rpn_loc: 0.198  time: 0.6560  data_time: 0.2036  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:31:56 d2.utils.events]: \u001b[0m eta: 1:02:15  iter: 2439  total_loss: 1.46  loss_cls: 0.327  loss_box_reg: 0.5887  loss_mask: 0.3217  loss_rpn_cls: 0.07244  loss_rpn_loc: 0.1664  time: 0.6561  data_time: 0.1785  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:32:12 d2.utils.events]: \u001b[0m eta: 1:01:57  iter: 2459  total_loss: 1.504  loss_cls: 0.3221  loss_box_reg: 0.5628  loss_mask: 0.3152  loss_rpn_cls: 0.07978  loss_rpn_loc: 0.1949  time: 0.6573  data_time: 0.3098  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:32:26 d2.utils.events]: \u001b[0m eta: 1:01:39  iter: 2479  total_loss: 1.565  loss_cls: 0.3533  loss_box_reg: 0.5788  loss_mask: 0.3052  loss_rpn_cls: 0.09655  loss_rpn_loc: 0.1906  time: 0.6576  data_time: 0.2206  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:32:37 d2.utils.events]: \u001b[0m eta: 1:01:30  iter: 2499  total_loss: 1.37  loss_cls: 0.2926  loss_box_reg: 0.5556  loss_mask: 0.2945  loss_rpn_cls: 0.06599  loss_rpn_loc: 0.1496  time: 0.6568  data_time: 0.0895  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:32:50 d2.utils.events]: \u001b[0m eta: 1:01:27  iter: 2519  total_loss: 1.411  loss_cls: 0.3081  loss_box_reg: 0.5561  loss_mask: 0.285  loss_rpn_cls: 0.06339  loss_rpn_loc: 0.1575  time: 0.6568  data_time: 0.1779  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:33:06 d2.utils.events]: \u001b[0m eta: 1:01:13  iter: 2539  total_loss: 1.419  loss_cls: 0.3207  loss_box_reg: 0.5506  loss_mask: 0.3063  loss_rpn_cls: 0.06882  loss_rpn_loc: 0.1559  time: 0.6577  data_time: 0.2850  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:33:21 d2.utils.events]: \u001b[0m eta: 1:01:14  iter: 2559  total_loss: 1.546  loss_cls: 0.3599  loss_box_reg: 0.5989  loss_mask: 0.3125  loss_rpn_cls: 0.09971  loss_rpn_loc: 0.2155  time: 0.6584  data_time: 0.2346  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:33:32 d2.utils.events]: \u001b[0m eta: 1:01:09  iter: 2579  total_loss: 1.503  loss_cls: 0.3459  loss_box_reg: 0.5639  loss_mask: 0.2953  loss_rpn_cls: 0.08798  loss_rpn_loc: 0.1782  time: 0.6575  data_time: 0.0667  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:33:44 d2.utils.events]: \u001b[0m eta: 1:00:59  iter: 2599  total_loss: 1.313  loss_cls: 0.3002  loss_box_reg: 0.5543  loss_mask: 0.2738  loss_rpn_cls: 0.06416  loss_rpn_loc: 0.147  time: 0.6573  data_time: 0.1637  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:33:56 d2.utils.events]: \u001b[0m eta: 1:00:40  iter: 2619  total_loss: 1.467  loss_cls: 0.3399  loss_box_reg: 0.5823  loss_mask: 0.3033  loss_rpn_cls: 0.06467  loss_rpn_loc: 0.1593  time: 0.6569  data_time: 0.1379  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:34:09 d2.utils.events]: \u001b[0m eta: 1:00:29  iter: 2639  total_loss: 1.397  loss_cls: 0.2775  loss_box_reg: 0.5415  loss_mask: 0.3012  loss_rpn_cls: 0.0706  loss_rpn_loc: 0.1749  time: 0.6568  data_time: 0.1675  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:34:24 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 2659  total_loss: 1.514  loss_cls: 0.3354  loss_box_reg: 0.5768  loss_mask: 0.3102  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1878  time: 0.6575  data_time: 0.2699  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:34:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:34:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:34:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:34:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:34:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:34:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:34:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0838 s/iter. Eval: 0.0539 s/iter. Total: 0.1384 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:34:33 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0852 s/iter. Eval: 0.0676 s/iter. Total: 0.1536 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 11:34:38 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0707 s/iter. Total: 0.1574 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0748 s/iter. Total: 0.1627 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:34:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.770513 (0.161815 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:34:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086842 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:34:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:34:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26182009075806434\n",
      "\u001b[32m[02/05 11:34:58 d2.utils.events]: \u001b[0m eta: 0:59:58  iter: 2679  total_loss: 1.496  loss_cls: 0.3438  loss_box_reg: 0.5657  loss_mask: 0.2947  loss_rpn_cls: 0.0831  loss_rpn_loc: 0.184  time: 0.6578  data_time: 0.2290  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:35:15 d2.utils.events]: \u001b[0m eta: 0:59:49  iter: 2699  total_loss: 1.574  loss_cls: 0.3818  loss_box_reg: 0.5635  loss_mask: 0.3097  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.1881  time: 0.6591  data_time: 0.3613  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:35:30 d2.utils.events]: \u001b[0m eta: 0:59:39  iter: 2719  total_loss: 1.427  loss_cls: 0.3165  loss_box_reg: 0.5462  loss_mask: 0.3036  loss_rpn_cls: 0.09238  loss_rpn_loc: 0.1781  time: 0.6598  data_time: 0.2907  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:35:45 d2.utils.events]: \u001b[0m eta: 0:59:29  iter: 2739  total_loss: 1.439  loss_cls: 0.3331  loss_box_reg: 0.5644  loss_mask: 0.3096  loss_rpn_cls: 0.0938  loss_rpn_loc: 0.165  time: 0.6604  data_time: 0.2704  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:35:58 d2.utils.events]: \u001b[0m eta: 0:59:20  iter: 2759  total_loss: 1.433  loss_cls: 0.3202  loss_box_reg: 0.5486  loss_mask: 0.2985  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.1725  time: 0.6602  data_time: 0.1616  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:36:10 d2.utils.events]: \u001b[0m eta: 0:59:15  iter: 2779  total_loss: 1.393  loss_cls: 0.3044  loss_box_reg: 0.5284  loss_mask: 0.2855  loss_rpn_cls: 0.09796  loss_rpn_loc: 0.1609  time: 0.6600  data_time: 0.1624  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:36:20 d2.utils.events]: \u001b[0m eta: 0:59:01  iter: 2799  total_loss: 1.442  loss_cls: 0.3066  loss_box_reg: 0.5788  loss_mask: 0.2863  loss_rpn_cls: 0.06784  loss_rpn_loc: 0.1687  time: 0.6588  data_time: 0.0402  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:36:31 d2.utils.events]: \u001b[0m eta: 0:58:44  iter: 2819  total_loss: 1.386  loss_cls: 0.3211  loss_box_reg: 0.546  loss_mask: 0.2875  loss_rpn_cls: 0.07256  loss_rpn_loc: 0.1591  time: 0.6581  data_time: 0.1044  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:36:42 d2.utils.events]: \u001b[0m eta: 0:58:32  iter: 2839  total_loss: 1.523  loss_cls: 0.3579  loss_box_reg: 0.5754  loss_mask: 0.31  loss_rpn_cls: 0.09437  loss_rpn_loc: 0.1858  time: 0.6573  data_time: 0.0778  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:36:57 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 2859  total_loss: 1.572  loss_cls: 0.402  loss_box_reg: 0.5868  loss_mask: 0.3159  loss_rpn_cls: 0.09882  loss_rpn_loc: 0.1941  time: 0.6578  data_time: 0.2281  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:37:09 d2.utils.events]: \u001b[0m eta: 0:58:14  iter: 2879  total_loss: 1.512  loss_cls: 0.3483  loss_box_reg: 0.6085  loss_mask: 0.3062  loss_rpn_cls: 0.07431  loss_rpn_loc: 0.1789  time: 0.6574  data_time: 0.1342  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:37:23 d2.utils.events]: \u001b[0m eta: 0:58:05  iter: 2899  total_loss: 1.359  loss_cls: 0.3002  loss_box_reg: 0.5576  loss_mask: 0.2776  loss_rpn_cls: 0.07042  loss_rpn_loc: 0.1382  time: 0.6577  data_time: 0.2454  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:37:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:37:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:37:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:37:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:37:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:37:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0842 s/iter. Eval: 0.0555 s/iter. Total: 0.1403 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0857 s/iter. Eval: 0.0694 s/iter. Total: 0.1558 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:37:38 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0717 s/iter. Total: 0.1584 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:37:43 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0759 s/iter. Total: 0.1631 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:37:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.779731 (0.161894 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:37:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086270 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:37:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:37:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2544144169397819\n",
      "\u001b[32m[02/05 11:37:56 d2.utils.events]: \u001b[0m eta: 0:57:55  iter: 2919  total_loss: 1.486  loss_cls: 0.3263  loss_box_reg: 0.5841  loss_mask: 0.3006  loss_rpn_cls: 0.07629  loss_rpn_loc: 0.1774  time: 0.6576  data_time: 0.1683  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:38:10 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 2939  total_loss: 1.544  loss_cls: 0.358  loss_box_reg: 0.5961  loss_mask: 0.3189  loss_rpn_cls: 0.08351  loss_rpn_loc: 0.163  time: 0.6577  data_time: 0.2025  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:38:21 d2.utils.events]: \u001b[0m eta: 0:57:35  iter: 2959  total_loss: 1.439  loss_cls: 0.3156  loss_box_reg: 0.5401  loss_mask: 0.3013  loss_rpn_cls: 0.06657  loss_rpn_loc: 0.1609  time: 0.6570  data_time: 0.0981  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:38:33 d2.utils.events]: \u001b[0m eta: 0:57:35  iter: 2979  total_loss: 1.553  loss_cls: 0.3449  loss_box_reg: 0.5878  loss_mask: 0.2952  loss_rpn_cls: 0.08601  loss_rpn_loc: 0.1817  time: 0.6566  data_time: 0.1186  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:38:46 d2.utils.events]: \u001b[0m eta: 0:57:25  iter: 2999  total_loss: 1.421  loss_cls: 0.3096  loss_box_reg: 0.5627  loss_mask: 0.2943  loss_rpn_cls: 0.08732  loss_rpn_loc: 0.1744  time: 0.6564  data_time: 0.1528  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:39:04 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 3019  total_loss: 1.458  loss_cls: 0.315  loss_box_reg: 0.5549  loss_mask: 0.2988  loss_rpn_cls: 0.09329  loss_rpn_loc: 0.1621  time: 0.6581  data_time: 0.3984  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:39:16 d2.utils.events]: \u001b[0m eta: 0:57:09  iter: 3039  total_loss: 1.387  loss_cls: 0.31  loss_box_reg: 0.5628  loss_mask: 0.2931  loss_rpn_cls: 0.07697  loss_rpn_loc: 0.151  time: 0.6577  data_time: 0.1380  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:39:31 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 3059  total_loss: 1.418  loss_cls: 0.3201  loss_box_reg: 0.5674  loss_mask: 0.2972  loss_rpn_cls: 0.06379  loss_rpn_loc: 0.1707  time: 0.6583  data_time: 0.2739  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:39:44 d2.utils.events]: \u001b[0m eta: 0:56:43  iter: 3079  total_loss: 1.373  loss_cls: 0.316  loss_box_reg: 0.5191  loss_mask: 0.2896  loss_rpn_cls: 0.07671  loss_rpn_loc: 0.1572  time: 0.6583  data_time: 0.1933  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:39:55 d2.utils.events]: \u001b[0m eta: 0:56:39  iter: 3099  total_loss: 1.481  loss_cls: 0.3399  loss_box_reg: 0.5952  loss_mask: 0.2961  loss_rpn_cls: 0.09338  loss_rpn_loc: 0.1668  time: 0.6577  data_time: 0.0868  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:40:08 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 3119  total_loss: 1.434  loss_cls: 0.3084  loss_box_reg: 0.5731  loss_mask: 0.2961  loss_rpn_cls: 0.08542  loss_rpn_loc: 0.1895  time: 0.6574  data_time: 0.1621  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:40:19 d2.utils.events]: \u001b[0m eta: 0:56:03  iter: 3139  total_loss: 1.392  loss_cls: 0.315  loss_box_reg: 0.5424  loss_mask: 0.2909  loss_rpn_cls: 0.06791  loss_rpn_loc: 0.1814  time: 0.6568  data_time: 0.0931  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:40:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:40:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:40:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:40:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:40:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:40:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0840 s/iter. Eval: 0.0510 s/iter. Total: 0.1357 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 11:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0872 s/iter. Eval: 0.0681 s/iter. Total: 0.1561 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0711 s/iter. Total: 0.1589 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0747 s/iter. Total: 0.1631 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:40:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.773157 (0.161838 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:40:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087222 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:40:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:40:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26417776916912694\n",
      "\u001b[32m[02/05 11:40:52 d2.utils.events]: \u001b[0m eta: 0:55:56  iter: 3159  total_loss: 1.486  loss_cls: 0.3534  loss_box_reg: 0.5774  loss_mask: 0.3076  loss_rpn_cls: 0.08803  loss_rpn_loc: 0.1842  time: 0.6567  data_time: 0.1832  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:41:05 d2.utils.events]: \u001b[0m eta: 0:55:44  iter: 3179  total_loss: 1.382  loss_cls: 0.3292  loss_box_reg: 0.5375  loss_mask: 0.2988  loss_rpn_cls: 0.07335  loss_rpn_loc: 0.1637  time: 0.6566  data_time: 0.1605  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:41:18 d2.utils.events]: \u001b[0m eta: 0:55:32  iter: 3199  total_loss: 1.434  loss_cls: 0.3124  loss_box_reg: 0.594  loss_mask: 0.3049  loss_rpn_cls: 0.06117  loss_rpn_loc: 0.1625  time: 0.6567  data_time: 0.1935  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:41:32 d2.utils.events]: \u001b[0m eta: 0:55:24  iter: 3219  total_loss: 1.508  loss_cls: 0.3772  loss_box_reg: 0.5795  loss_mask: 0.3259  loss_rpn_cls: 0.08667  loss_rpn_loc: 0.1784  time: 0.6569  data_time: 0.2252  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:41:46 d2.utils.events]: \u001b[0m eta: 0:55:15  iter: 3239  total_loss: 1.523  loss_cls: 0.3323  loss_box_reg: 0.5696  loss_mask: 0.3156  loss_rpn_cls: 0.119  loss_rpn_loc: 0.194  time: 0.6571  data_time: 0.1991  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:42:01 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 3259  total_loss: 1.447  loss_cls: 0.336  loss_box_reg: 0.5414  loss_mask: 0.3042  loss_rpn_cls: 0.06748  loss_rpn_loc: 0.1704  time: 0.6577  data_time: 0.2476  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:42:15 d2.utils.events]: \u001b[0m eta: 0:55:09  iter: 3279  total_loss: 1.405  loss_cls: 0.3142  loss_box_reg: 0.5501  loss_mask: 0.2953  loss_rpn_cls: 0.08199  loss_rpn_loc: 0.1588  time: 0.6581  data_time: 0.2395  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:42:28 d2.utils.events]: \u001b[0m eta: 0:55:03  iter: 3299  total_loss: 1.449  loss_cls: 0.3179  loss_box_reg: 0.572  loss_mask: 0.3056  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.2114  time: 0.6581  data_time: 0.1834  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:42:40 d2.utils.events]: \u001b[0m eta: 0:54:49  iter: 3319  total_loss: 1.372  loss_cls: 0.3315  loss_box_reg: 0.5354  loss_mask: 0.2795  loss_rpn_cls: 0.06563  loss_rpn_loc: 0.1681  time: 0.6575  data_time: 0.0997  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:42:52 d2.utils.events]: \u001b[0m eta: 0:54:28  iter: 3339  total_loss: 1.359  loss_cls: 0.3167  loss_box_reg: 0.5358  loss_mask: 0.2782  loss_rpn_cls: 0.06701  loss_rpn_loc: 0.1673  time: 0.6573  data_time: 0.1435  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:43:05 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 3359  total_loss: 1.415  loss_cls: 0.3106  loss_box_reg: 0.5592  loss_mask: 0.2975  loss_rpn_cls: 0.08383  loss_rpn_loc: 0.1849  time: 0.6571  data_time: 0.1726  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:43:18 d2.utils.events]: \u001b[0m eta: 0:54:12  iter: 3379  total_loss: 1.539  loss_cls: 0.3464  loss_box_reg: 0.5885  loss_mask: 0.3083  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.1712  time: 0.6573  data_time: 0.1999  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:43:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:43:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:43:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:43:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:43:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:43:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0868 s/iter. Eval: 0.0561 s/iter. Total: 0.1435 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0726 s/iter. Total: 0.1605 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0736 s/iter. Total: 0.1612 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0769 s/iter. Total: 0.1647 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:43:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.979656 (0.163618 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:43:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086717 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:43:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:43:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25892582729171976\n",
      "\u001b[32m[02/05 11:43:52 d2.utils.events]: \u001b[0m eta: 0:54:00  iter: 3399  total_loss: 1.364  loss_cls: 0.3196  loss_box_reg: 0.543  loss_mask: 0.2836  loss_rpn_cls: 0.07968  loss_rpn_loc: 0.1459  time: 0.6571  data_time: 0.1361  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:44:09 d2.utils.events]: \u001b[0m eta: 0:54:00  iter: 3419  total_loss: 1.518  loss_cls: 0.3638  loss_box_reg: 0.6013  loss_mask: 0.3075  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.1864  time: 0.6583  data_time: 0.3221  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:44:25 d2.utils.events]: \u001b[0m eta: 0:53:52  iter: 3439  total_loss: 1.471  loss_cls: 0.3423  loss_box_reg: 0.575  loss_mask: 0.2973  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.1681  time: 0.6591  data_time: 0.3068  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:44:39 d2.utils.events]: \u001b[0m eta: 0:53:42  iter: 3459  total_loss: 1.412  loss_cls: 0.2954  loss_box_reg: 0.5593  loss_mask: 0.2899  loss_rpn_cls: 0.09513  loss_rpn_loc: 0.1787  time: 0.6593  data_time: 0.2094  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:44:52 d2.utils.events]: \u001b[0m eta: 0:53:35  iter: 3479  total_loss: 1.379  loss_cls: 0.2916  loss_box_reg: 0.5326  loss_mask: 0.292  loss_rpn_cls: 0.07925  loss_rpn_loc: 0.1586  time: 0.6594  data_time: 0.1756  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:45:05 d2.utils.events]: \u001b[0m eta: 0:53:27  iter: 3499  total_loss: 1.415  loss_cls: 0.2937  loss_box_reg: 0.5493  loss_mask: 0.3045  loss_rpn_cls: 0.07904  loss_rpn_loc: 0.1859  time: 0.6594  data_time: 0.1752  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:45:17 d2.utils.events]: \u001b[0m eta: 0:53:18  iter: 3519  total_loss: 1.443  loss_cls: 0.325  loss_box_reg: 0.5465  loss_mask: 0.3016  loss_rpn_cls: 0.0738  loss_rpn_loc: 0.184  time: 0.6590  data_time: 0.1144  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:45:29 d2.utils.events]: \u001b[0m eta: 0:53:04  iter: 3539  total_loss: 1.321  loss_cls: 0.2921  loss_box_reg: 0.55  loss_mask: 0.2932  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.1568  time: 0.6587  data_time: 0.1242  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:45:41 d2.utils.events]: \u001b[0m eta: 0:52:53  iter: 3559  total_loss: 1.409  loss_cls: 0.2976  loss_box_reg: 0.5824  loss_mask: 0.2925  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1671  time: 0.6583  data_time: 0.1152  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:45:53 d2.utils.events]: \u001b[0m eta: 0:52:45  iter: 3579  total_loss: 1.402  loss_cls: 0.3164  loss_box_reg: 0.5708  loss_mask: 0.3008  loss_rpn_cls: 0.07369  loss_rpn_loc: 0.1468  time: 0.6579  data_time: 0.0817  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:46:06 d2.utils.events]: \u001b[0m eta: 0:52:39  iter: 3599  total_loss: 1.453  loss_cls: 0.2976  loss_box_reg: 0.5398  loss_mask: 0.3075  loss_rpn_cls: 0.07697  loss_rpn_loc: 0.1949  time: 0.6578  data_time: 0.1651  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:46:20 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 3619  total_loss: 1.502  loss_cls: 0.3295  loss_box_reg: 0.5648  loss_mask: 0.3001  loss_rpn_cls: 0.08881  loss_rpn_loc: 0.1807  time: 0.6581  data_time: 0.2273  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:46:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:46:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:46:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:46:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:46:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:46:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0880 s/iter. Eval: 0.0539 s/iter. Total: 0.1426 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0892 s/iter. Eval: 0.0693 s/iter. Total: 0.1593 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0704 s/iter. Total: 0.1607 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0897 s/iter. Eval: 0.0747 s/iter. Total: 0.1652 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 11:46:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.073151 (0.164424 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:46:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089631 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:46:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:46:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2699646871005512\n",
      "\u001b[32m[02/05 11:46:55 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 3639  total_loss: 1.434  loss_cls: 0.3182  loss_box_reg: 0.576  loss_mask: 0.3114  loss_rpn_cls: 0.08172  loss_rpn_loc: 0.1609  time: 0.6583  data_time: 0.2147  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:47:08 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 3659  total_loss: 1.423  loss_cls: 0.302  loss_box_reg: 0.568  loss_mask: 0.2995  loss_rpn_cls: 0.09056  loss_rpn_loc: 0.1764  time: 0.6583  data_time: 0.1819  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:47:20 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 3679  total_loss: 1.339  loss_cls: 0.3095  loss_box_reg: 0.5366  loss_mask: 0.2834  loss_rpn_cls: 0.0787  loss_rpn_loc: 0.152  time: 0.6581  data_time: 0.1331  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:47:34 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 3699  total_loss: 1.544  loss_cls: 0.3483  loss_box_reg: 0.5608  loss_mask: 0.3118  loss_rpn_cls: 0.08184  loss_rpn_loc: 0.1777  time: 0.6583  data_time: 0.2089  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:47:48 d2.utils.events]: \u001b[0m eta: 0:52:00  iter: 3719  total_loss: 1.551  loss_cls: 0.3406  loss_box_reg: 0.5385  loss_mask: 0.2908  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.1676  time: 0.6584  data_time: 0.1699  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:48:03 d2.utils.events]: \u001b[0m eta: 0:51:50  iter: 3739  total_loss: 1.508  loss_cls: 0.319  loss_box_reg: 0.5646  loss_mask: 0.3043  loss_rpn_cls: 0.08556  loss_rpn_loc: 0.1888  time: 0.6591  data_time: 0.3035  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:48:18 d2.utils.events]: \u001b[0m eta: 0:51:42  iter: 3759  total_loss: 1.439  loss_cls: 0.3493  loss_box_reg: 0.5575  loss_mask: 0.295  loss_rpn_cls: 0.08139  loss_rpn_loc: 0.1735  time: 0.6595  data_time: 0.2359  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:48:35 d2.utils.events]: \u001b[0m eta: 0:51:36  iter: 3779  total_loss: 1.466  loss_cls: 0.3267  loss_box_reg: 0.5529  loss_mask: 0.3027  loss_rpn_cls: 0.09068  loss_rpn_loc: 0.1797  time: 0.6605  data_time: 0.3250  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:48:49 d2.utils.events]: \u001b[0m eta: 0:51:40  iter: 3799  total_loss: 1.421  loss_cls: 0.3186  loss_box_reg: 0.5543  loss_mask: 0.302  loss_rpn_cls: 0.08106  loss_rpn_loc: 0.175  time: 0.6606  data_time: 0.1840  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:48:59 d2.utils.events]: \u001b[0m eta: 0:51:32  iter: 3819  total_loss: 1.339  loss_cls: 0.3004  loss_box_reg: 0.5437  loss_mask: 0.2848  loss_rpn_cls: 0.05701  loss_rpn_loc: 0.1474  time: 0.6599  data_time: 0.0495  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:49:12 d2.utils.events]: \u001b[0m eta: 0:51:30  iter: 3839  total_loss: 1.44  loss_cls: 0.3078  loss_box_reg: 0.5545  loss_mask: 0.3043  loss_rpn_cls: 0.07871  loss_rpn_loc: 0.1747  time: 0.6596  data_time: 0.1405  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:49:26 d2.utils.events]: \u001b[0m eta: 0:51:17  iter: 3859  total_loss: 1.594  loss_cls: 0.3744  loss_box_reg: 0.5934  loss_mask: 0.3081  loss_rpn_cls: 0.09598  loss_rpn_loc: 0.2129  time: 0.6599  data_time: 0.2059  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:49:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:49:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:49:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:49:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:49:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:49:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0926 s/iter. Eval: 0.0636 s/iter. Total: 0.1569 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 11:49:43 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0009 s/iter. Inference: 0.0941 s/iter. Eval: 0.0795 s/iter. Total: 0.1744 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 11:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0009 s/iter. Inference: 0.0942 s/iter. Eval: 0.0789 s/iter. Total: 0.1741 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 11:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0009 s/iter. Inference: 0.0940 s/iter. Eval: 0.0844 s/iter. Total: 0.1793 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 11:49:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.417171 (0.176010 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:49:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093018 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:49:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:49:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2674678050908742\n",
      "\u001b[32m[02/05 11:50:03 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 3879  total_loss: 1.414  loss_cls: 0.3244  loss_box_reg: 0.5514  loss_mask: 0.3031  loss_rpn_cls: 0.09593  loss_rpn_loc: 0.1636  time: 0.6602  data_time: 0.2387  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:50:13 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 3899  total_loss: 1.277  loss_cls: 0.2811  loss_box_reg: 0.5365  loss_mask: 0.2805  loss_rpn_cls: 0.05652  loss_rpn_loc: 0.1484  time: 0.6595  data_time: 0.0443  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:50:25 d2.utils.events]: \u001b[0m eta: 0:50:51  iter: 3919  total_loss: 1.419  loss_cls: 0.3193  loss_box_reg: 0.561  loss_mask: 0.3073  loss_rpn_cls: 0.08214  loss_rpn_loc: 0.1617  time: 0.6591  data_time: 0.1144  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:50:42 d2.utils.events]: \u001b[0m eta: 0:50:41  iter: 3939  total_loss: 1.48  loss_cls: 0.3371  loss_box_reg: 0.5581  loss_mask: 0.2952  loss_rpn_cls: 0.08745  loss_rpn_loc: 0.1737  time: 0.6601  data_time: 0.3781  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:50:53 d2.utils.events]: \u001b[0m eta: 0:50:31  iter: 3959  total_loss: 1.397  loss_cls: 0.2982  loss_box_reg: 0.5641  loss_mask: 0.29  loss_rpn_cls: 0.06045  loss_rpn_loc: 0.1613  time: 0.6596  data_time: 0.1027  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:51:07 d2.utils.events]: \u001b[0m eta: 0:50:23  iter: 3979  total_loss: 1.441  loss_cls: 0.3375  loss_box_reg: 0.5513  loss_mask: 0.2849  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.1741  time: 0.6598  data_time: 0.2225  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:51:21 d2.utils.events]: \u001b[0m eta: 0:50:17  iter: 3999  total_loss: 1.659  loss_cls: 0.4093  loss_box_reg: 0.6103  loss_mask: 0.3154  loss_rpn_cls: 0.09247  loss_rpn_loc: 0.2  time: 0.6599  data_time: 0.1930  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:51:34 d2.utils.events]: \u001b[0m eta: 0:50:02  iter: 4019  total_loss: 1.392  loss_cls: 0.3145  loss_box_reg: 0.5583  loss_mask: 0.3081  loss_rpn_cls: 0.07961  loss_rpn_loc: 0.1687  time: 0.6599  data_time: 0.1896  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:51:51 d2.utils.events]: \u001b[0m eta: 0:49:58  iter: 4039  total_loss: 1.45  loss_cls: 0.3423  loss_box_reg: 0.5763  loss_mask: 0.321  loss_rpn_cls: 0.08815  loss_rpn_loc: 0.1824  time: 0.6610  data_time: 0.3621  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:52:06 d2.utils.events]: \u001b[0m eta: 0:49:52  iter: 4059  total_loss: 1.435  loss_cls: 0.3089  loss_box_reg: 0.5521  loss_mask: 0.3006  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.1743  time: 0.6614  data_time: 0.2628  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:52:18 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 4079  total_loss: 1.437  loss_cls: 0.318  loss_box_reg: 0.5523  loss_mask: 0.2892  loss_rpn_cls: 0.0646  loss_rpn_loc: 0.1513  time: 0.6609  data_time: 0.0843  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:52:32 d2.utils.events]: \u001b[0m eta: 0:49:30  iter: 4099  total_loss: 1.356  loss_cls: 0.3075  loss_box_reg: 0.5557  loss_mask: 0.3117  loss_rpn_cls: 0.05919  loss_rpn_loc: 0.143  time: 0.6611  data_time: 0.2006  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:52:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:52:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:52:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:52:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:52:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:52:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:52:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0882 s/iter. Eval: 0.0509 s/iter. Total: 0.1397 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 11:52:51 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0898 s/iter. Eval: 0.0685 s/iter. Total: 0.1590 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:52:56 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0703 s/iter. Total: 0.1608 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:53:01 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0746 s/iter. Total: 0.1658 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:53:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.441222 (0.167597 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:53:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090720 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:53:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:53:04 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26743799810110663\n",
      "\u001b[32m[02/05 11:53:07 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 4119  total_loss: 1.402  loss_cls: 0.3191  loss_box_reg: 0.5594  loss_mask: 0.303  loss_rpn_cls: 0.08373  loss_rpn_loc: 0.1514  time: 0.6614  data_time: 0.2216  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:53:21 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 4139  total_loss: 1.51  loss_cls: 0.3465  loss_box_reg: 0.5558  loss_mask: 0.3009  loss_rpn_cls: 0.08873  loss_rpn_loc: 0.1814  time: 0.6615  data_time: 0.1899  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:53:33 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 4159  total_loss: 1.357  loss_cls: 0.3125  loss_box_reg: 0.5366  loss_mask: 0.2947  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.1623  time: 0.6612  data_time: 0.1279  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:53:46 d2.utils.events]: \u001b[0m eta: 0:48:52  iter: 4179  total_loss: 1.379  loss_cls: 0.3045  loss_box_reg: 0.5661  loss_mask: 0.2957  loss_rpn_cls: 0.06995  loss_rpn_loc: 0.1754  time: 0.6612  data_time: 0.2007  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:54:01 d2.utils.events]: \u001b[0m eta: 0:48:44  iter: 4199  total_loss: 1.316  loss_cls: 0.2778  loss_box_reg: 0.5328  loss_mask: 0.2938  loss_rpn_cls: 0.05709  loss_rpn_loc: 0.1676  time: 0.6615  data_time: 0.2497  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:54:13 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 4219  total_loss: 1.433  loss_cls: 0.3176  loss_box_reg: 0.5462  loss_mask: 0.3187  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.1704  time: 0.6614  data_time: 0.1853  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:54:29 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 4239  total_loss: 1.5  loss_cls: 0.3393  loss_box_reg: 0.5796  loss_mask: 0.3032  loss_rpn_cls: 0.08266  loss_rpn_loc: 0.1615  time: 0.6619  data_time: 0.2753  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:54:41 d2.utils.events]: \u001b[0m eta: 0:48:11  iter: 4259  total_loss: 1.409  loss_cls: 0.3058  loss_box_reg: 0.5517  loss_mask: 0.3018  loss_rpn_cls: 0.08775  loss_rpn_loc: 0.1551  time: 0.6617  data_time: 0.1498  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:54:54 d2.utils.events]: \u001b[0m eta: 0:48:01  iter: 4279  total_loss: 1.377  loss_cls: 0.3218  loss_box_reg: 0.5517  loss_mask: 0.2882  loss_rpn_cls: 0.06076  loss_rpn_loc: 0.1649  time: 0.6616  data_time: 0.1701  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:55:08 d2.utils.events]: \u001b[0m eta: 0:47:47  iter: 4299  total_loss: 1.39  loss_cls: 0.3119  loss_box_reg: 0.544  loss_mask: 0.2933  loss_rpn_cls: 0.07255  loss_rpn_loc: 0.1572  time: 0.6618  data_time: 0.2552  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:55:21 d2.utils.events]: \u001b[0m eta: 0:47:40  iter: 4319  total_loss: 1.378  loss_cls: 0.3132  loss_box_reg: 0.5302  loss_mask: 0.2819  loss_rpn_cls: 0.08507  loss_rpn_loc: 0.1574  time: 0.6617  data_time: 0.1592  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:55:35 d2.utils.events]: \u001b[0m eta: 0:47:31  iter: 4339  total_loss: 1.366  loss_cls: 0.3064  loss_box_reg: 0.5486  loss_mask: 0.2964  loss_rpn_cls: 0.06596  loss_rpn_loc: 0.1548  time: 0.6619  data_time: 0.2230  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:55:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:55:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:55:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:55:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:55:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:55:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0837 s/iter. Eval: 0.0512 s/iter. Total: 0.1355 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 11:55:53 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0852 s/iter. Eval: 0.0687 s/iter. Total: 0.1547 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0861 s/iter. Eval: 0.0715 s/iter. Total: 0.1584 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:56:04 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0762 s/iter. Total: 0.1643 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:56:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.983617 (0.163652 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:56:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087732 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:56:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:56:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26938315336680346\n",
      "\u001b[32m[02/05 11:56:08 d2.utils.events]: \u001b[0m eta: 0:47:21  iter: 4359  total_loss: 1.411  loss_cls: 0.3288  loss_box_reg: 0.5501  loss_mask: 0.3017  loss_rpn_cls: 0.08156  loss_rpn_loc: 0.1709  time: 0.6617  data_time: 0.1565  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:56:22 d2.utils.events]: \u001b[0m eta: 0:47:10  iter: 4379  total_loss: 1.396  loss_cls: 0.3051  loss_box_reg: 0.5294  loss_mask: 0.2985  loss_rpn_cls: 0.07871  loss_rpn_loc: 0.1928  time: 0.6619  data_time: 0.2293  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:56:36 d2.utils.events]: \u001b[0m eta: 0:47:00  iter: 4399  total_loss: 1.525  loss_cls: 0.3226  loss_box_reg: 0.5742  loss_mask: 0.3138  loss_rpn_cls: 0.08579  loss_rpn_loc: 0.178  time: 0.6620  data_time: 0.2059  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:56:47 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 4419  total_loss: 1.376  loss_cls: 0.3334  loss_box_reg: 0.5467  loss_mask: 0.2854  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.1664  time: 0.6615  data_time: 0.0802  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:57:01 d2.utils.events]: \u001b[0m eta: 0:46:25  iter: 4439  total_loss: 1.343  loss_cls: 0.2866  loss_box_reg: 0.5326  loss_mask: 0.2868  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.1403  time: 0.6616  data_time: 0.2193  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:57:13 d2.utils.events]: \u001b[0m eta: 0:46:12  iter: 4459  total_loss: 1.383  loss_cls: 0.3212  loss_box_reg: 0.5322  loss_mask: 0.2876  loss_rpn_cls: 0.07139  loss_rpn_loc: 0.1652  time: 0.6613  data_time: 0.1188  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:57:24 d2.utils.events]: \u001b[0m eta: 0:45:56  iter: 4479  total_loss: 1.375  loss_cls: 0.3114  loss_box_reg: 0.5392  loss_mask: 0.2956  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.1782  time: 0.6609  data_time: 0.1105  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:57:37 d2.utils.events]: \u001b[0m eta: 0:45:46  iter: 4499  total_loss: 1.372  loss_cls: 0.3213  loss_box_reg: 0.5696  loss_mask: 0.3012  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.1613  time: 0.6609  data_time: 0.2002  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:57:50 d2.utils.events]: \u001b[0m eta: 0:45:35  iter: 4519  total_loss: 1.454  loss_cls: 0.3282  loss_box_reg: 0.5517  loss_mask: 0.3063  loss_rpn_cls: 0.08936  loss_rpn_loc: 0.1737  time: 0.6607  data_time: 0.1629  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:58:03 d2.utils.events]: \u001b[0m eta: 0:45:24  iter: 4539  total_loss: 1.522  loss_cls: 0.3366  loss_box_reg: 0.5682  loss_mask: 0.3037  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1919  time: 0.6607  data_time: 0.1784  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:58:18 d2.utils.events]: \u001b[0m eta: 0:45:12  iter: 4559  total_loss: 1.482  loss_cls: 0.31  loss_box_reg: 0.5603  loss_mask: 0.3064  loss_rpn_cls: 0.08189  loss_rpn_loc: 0.1789  time: 0.6611  data_time: 0.2888  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:58:32 d2.utils.events]: \u001b[0m eta: 0:44:58  iter: 4579  total_loss: 1.502  loss_cls: 0.339  loss_box_reg: 0.5562  loss_mask: 0.2882  loss_rpn_cls: 0.09347  loss_rpn_loc: 0.1913  time: 0.6613  data_time: 0.2315  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:58:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:58:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 11:58:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 11:58:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 11:58:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 11:58:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 11:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0839 s/iter. Eval: 0.0497 s/iter. Total: 0.1342 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 11:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0854 s/iter. Eval: 0.0682 s/iter. Total: 0.1545 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 11:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0706 s/iter. Total: 0.1571 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 11:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0735 s/iter. Total: 0.1602 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 11:59:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.547076 (0.159889 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:59:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085902 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 11:59:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 11:59:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2678927623270321\n",
      "\u001b[32m[02/05 11:59:04 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 4599  total_loss: 1.413  loss_cls: 0.3225  loss_box_reg: 0.5505  loss_mask: 0.2784  loss_rpn_cls: 0.06861  loss_rpn_loc: 0.1626  time: 0.6609  data_time: 0.1118  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:59:19 d2.utils.events]: \u001b[0m eta: 0:44:35  iter: 4619  total_loss: 1.453  loss_cls: 0.3292  loss_box_reg: 0.5551  loss_mask: 0.3075  loss_rpn_cls: 0.07615  loss_rpn_loc: 0.1709  time: 0.6613  data_time: 0.2631  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:59:30 d2.utils.events]: \u001b[0m eta: 0:44:22  iter: 4639  total_loss: 1.438  loss_cls: 0.33  loss_box_reg: 0.5529  loss_mask: 0.2842  loss_rpn_cls: 0.07588  loss_rpn_loc: 0.1696  time: 0.6607  data_time: 0.0714  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:59:44 d2.utils.events]: \u001b[0m eta: 0:44:12  iter: 4659  total_loss: 1.383  loss_cls: 0.3172  loss_box_reg: 0.5055  loss_mask: 0.2971  loss_rpn_cls: 0.08209  loss_rpn_loc: 0.1723  time: 0.6610  data_time: 0.2564  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 11:59:56 d2.utils.events]: \u001b[0m eta: 0:43:56  iter: 4679  total_loss: 1.444  loss_cls: 0.3172  loss_box_reg: 0.5641  loss_mask: 0.2935  loss_rpn_cls: 0.07341  loss_rpn_loc: 0.1597  time: 0.6606  data_time: 0.1202  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:00:06 d2.utils.events]: \u001b[0m eta: 0:43:45  iter: 4699  total_loss: 1.284  loss_cls: 0.2723  loss_box_reg: 0.5436  loss_mask: 0.2753  loss_rpn_cls: 0.05313  loss_rpn_loc: 0.1419  time: 0.6601  data_time: 0.0673  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:00:21 d2.utils.events]: \u001b[0m eta: 0:43:31  iter: 4719  total_loss: 1.528  loss_cls: 0.3395  loss_box_reg: 0.5843  loss_mask: 0.3206  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.1818  time: 0.6603  data_time: 0.2575  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:00:33 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 4739  total_loss: 1.308  loss_cls: 0.2972  loss_box_reg: 0.5403  loss_mask: 0.2919  loss_rpn_cls: 0.0707  loss_rpn_loc: 0.1374  time: 0.6602  data_time: 0.1669  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:00:46 d2.utils.events]: \u001b[0m eta: 0:43:05  iter: 4759  total_loss: 1.473  loss_cls: 0.3284  loss_box_reg: 0.5545  loss_mask: 0.3056  loss_rpn_cls: 0.09065  loss_rpn_loc: 0.1659  time: 0.6602  data_time: 0.1883  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:00:59 d2.utils.events]: \u001b[0m eta: 0:42:46  iter: 4779  total_loss: 1.409  loss_cls: 0.3172  loss_box_reg: 0.5406  loss_mask: 0.29  loss_rpn_cls: 0.06243  loss_rpn_loc: 0.1648  time: 0.6601  data_time: 0.1591  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:01:17 d2.utils.events]: \u001b[0m eta: 0:42:33  iter: 4799  total_loss: 1.479  loss_cls: 0.3334  loss_box_reg: 0.5528  loss_mask: 0.3015  loss_rpn_cls: 0.09274  loss_rpn_loc: 0.1871  time: 0.6611  data_time: 0.4288  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:01:31 d2.utils.events]: \u001b[0m eta: 0:42:26  iter: 4819  total_loss: 1.339  loss_cls: 0.3032  loss_box_reg: 0.5713  loss_mask: 0.2936  loss_rpn_cls: 0.093  loss_rpn_loc: 0.1652  time: 0.6613  data_time: 0.2265  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:01:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:01:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:01:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:01:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:01:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:01:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:01:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0837 s/iter. Eval: 0.0515 s/iter. Total: 0.1358 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 12:01:53 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0683 s/iter. Total: 0.1547 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0711 s/iter. Total: 0.1576 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0740 s/iter. Total: 0.1608 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:02:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.572292 (0.160106 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:02:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085898 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:02:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:02:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26957641162889134\n",
      "\u001b[32m[02/05 12:02:06 d2.utils.events]: \u001b[0m eta: 0:42:13  iter: 4839  total_loss: 1.411  loss_cls: 0.3038  loss_box_reg: 0.5827  loss_mask: 0.3167  loss_rpn_cls: 0.08466  loss_rpn_loc: 0.1774  time: 0.6615  data_time: 0.2466  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:02:17 d2.utils.events]: \u001b[0m eta: 0:42:00  iter: 4859  total_loss: 1.349  loss_cls: 0.2899  loss_box_reg: 0.5558  loss_mask: 0.3048  loss_rpn_cls: 0.06211  loss_rpn_loc: 0.1824  time: 0.6610  data_time: 0.0799  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:02:30 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 4879  total_loss: 1.507  loss_cls: 0.3556  loss_box_reg: 0.5591  loss_mask: 0.3073  loss_rpn_cls: 0.09379  loss_rpn_loc: 0.1831  time: 0.6611  data_time: 0.2131  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:02:41 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 4899  total_loss: 1.392  loss_cls: 0.3072  loss_box_reg: 0.5553  loss_mask: 0.2968  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.1574  time: 0.6607  data_time: 0.1104  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:02:56 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 4919  total_loss: 1.332  loss_cls: 0.297  loss_box_reg: 0.53  loss_mask: 0.2822  loss_rpn_cls: 0.0656  loss_rpn_loc: 0.1667  time: 0.6609  data_time: 0.2447  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:03:10 d2.utils.events]: \u001b[0m eta: 0:41:13  iter: 4939  total_loss: 1.421  loss_cls: 0.3192  loss_box_reg: 0.5285  loss_mask: 0.3053  loss_rpn_cls: 0.08978  loss_rpn_loc: 0.168  time: 0.6611  data_time: 0.2399  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:03:23 d2.utils.events]: \u001b[0m eta: 0:41:09  iter: 4959  total_loss: 1.435  loss_cls: 0.3014  loss_box_reg: 0.5768  loss_mask: 0.3036  loss_rpn_cls: 0.08421  loss_rpn_loc: 0.1646  time: 0.6611  data_time: 0.2040  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:03:39 d2.utils.events]: \u001b[0m eta: 0:40:54  iter: 4979  total_loss: 1.466  loss_cls: 0.3311  loss_box_reg: 0.5587  loss_mask: 0.3084  loss_rpn_cls: 0.09225  loss_rpn_loc: 0.1726  time: 0.6616  data_time: 0.3250  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:03:53 d2.utils.events]: \u001b[0m eta: 0:40:44  iter: 4999  total_loss: 1.484  loss_cls: 0.3546  loss_box_reg: 0.5469  loss_mask: 0.2986  loss_rpn_cls: 0.105  loss_rpn_loc: 0.1598  time: 0.6617  data_time: 0.2066  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:04:07 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 5019  total_loss: 1.46  loss_cls: 0.3243  loss_box_reg: 0.5674  loss_mask: 0.2996  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1719  time: 0.6619  data_time: 0.2529  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:04:19 d2.utils.events]: \u001b[0m eta: 0:40:21  iter: 5039  total_loss: 1.409  loss_cls: 0.3307  loss_box_reg: 0.5554  loss_mask: 0.288  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.1608  time: 0.6617  data_time: 0.1515  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:04:29 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 5059  total_loss: 1.306  loss_cls: 0.3027  loss_box_reg: 0.5387  loss_mask: 0.2754  loss_rpn_cls: 0.06076  loss_rpn_loc: 0.1436  time: 0.6610  data_time: 0.0216  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:04:41 d2.utils.events]: \u001b[0m eta: 0:39:56  iter: 5079  total_loss: 1.425  loss_cls: 0.3431  loss_box_reg: 0.5648  loss_mask: 0.2936  loss_rpn_cls: 0.08321  loss_rpn_loc: 0.1704  time: 0.6607  data_time: 0.1381  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:04:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:04:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:04:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:04:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:04:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:04:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:04:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0835 s/iter. Eval: 0.0491 s/iter. Total: 0.1332 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 12:04:51 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0852 s/iter. Eval: 0.0667 s/iter. Total: 0.1527 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 12:04:56 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0853 s/iter. Eval: 0.0692 s/iter. Total: 0.1554 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0724 s/iter. Total: 0.1588 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:05:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.369144 (0.158355 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:05:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085608 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:05:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:05:04 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26667863316375834\n",
      "\u001b[32m[02/05 12:05:15 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 5099  total_loss: 1.408  loss_cls: 0.3401  loss_box_reg: 0.5408  loss_mask: 0.2992  loss_rpn_cls: 0.07863  loss_rpn_loc: 0.1649  time: 0.6609  data_time: 0.2229  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:05:26 d2.utils.events]: \u001b[0m eta: 0:39:35  iter: 5119  total_loss: 1.392  loss_cls: 0.3205  loss_box_reg: 0.5431  loss_mask: 0.2861  loss_rpn_cls: 0.06635  loss_rpn_loc: 0.162  time: 0.6604  data_time: 0.0576  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:05:39 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 5139  total_loss: 1.365  loss_cls: 0.3096  loss_box_reg: 0.5254  loss_mask: 0.2813  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.1645  time: 0.6604  data_time: 0.1925  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:05:50 d2.utils.events]: \u001b[0m eta: 0:39:12  iter: 5159  total_loss: 1.25  loss_cls: 0.2806  loss_box_reg: 0.5401  loss_mask: 0.299  loss_rpn_cls: 0.04087  loss_rpn_loc: 0.1305  time: 0.6601  data_time: 0.1172  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:06:04 d2.utils.events]: \u001b[0m eta: 0:39:02  iter: 5179  total_loss: 1.375  loss_cls: 0.3105  loss_box_reg: 0.5221  loss_mask: 0.2963  loss_rpn_cls: 0.08418  loss_rpn_loc: 0.1594  time: 0.6602  data_time: 0.2301  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:06:17 d2.utils.events]: \u001b[0m eta: 0:38:53  iter: 5199  total_loss: 1.376  loss_cls: 0.3226  loss_box_reg: 0.5441  loss_mask: 0.2829  loss_rpn_cls: 0.07108  loss_rpn_loc: 0.1533  time: 0.6600  data_time: 0.1355  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:06:32 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 5219  total_loss: 1.493  loss_cls: 0.3392  loss_box_reg: 0.5659  loss_mask: 0.312  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.1876  time: 0.6605  data_time: 0.3090  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:06:45 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 5239  total_loss: 1.494  loss_cls: 0.3325  loss_box_reg: 0.5567  loss_mask: 0.2923  loss_rpn_cls: 0.08162  loss_rpn_loc: 0.1704  time: 0.6604  data_time: 0.1716  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:07:00 d2.utils.events]: \u001b[0m eta: 0:38:23  iter: 5259  total_loss: 1.518  loss_cls: 0.34  loss_box_reg: 0.5716  loss_mask: 0.3083  loss_rpn_cls: 0.08959  loss_rpn_loc: 0.1789  time: 0.6608  data_time: 0.2913  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:07:13 d2.utils.events]: \u001b[0m eta: 0:38:10  iter: 5279  total_loss: 1.42  loss_cls: 0.3012  loss_box_reg: 0.5375  loss_mask: 0.3004  loss_rpn_cls: 0.06679  loss_rpn_loc: 0.1703  time: 0.6606  data_time: 0.1734  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:07:25 d2.utils.events]: \u001b[0m eta: 0:38:01  iter: 5299  total_loss: 1.496  loss_cls: 0.3375  loss_box_reg: 0.5608  loss_mask: 0.3061  loss_rpn_cls: 0.08543  loss_rpn_loc: 0.1622  time: 0.6605  data_time: 0.1559  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:07:38 d2.utils.events]: \u001b[0m eta: 0:37:53  iter: 5319  total_loss: 1.367  loss_cls: 0.3113  loss_box_reg: 0.5405  loss_mask: 0.2859  loss_rpn_cls: 0.08301  loss_rpn_loc: 0.1663  time: 0.6605  data_time: 0.1951  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:07:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:07:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:07:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:07:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:07:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:07:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:07:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0838 s/iter. Eval: 0.0504 s/iter. Total: 0.1349 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 12:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0853 s/iter. Eval: 0.0681 s/iter. Total: 0.1542 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 12:07:54 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0855 s/iter. Eval: 0.0708 s/iter. Total: 0.1572 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 107/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0726 s/iter. Total: 0.1591 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:08:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.446187 (0.159019 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:08:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085710 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:08:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:08:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2686744078224317\n",
      "\u001b[32m[02/05 12:08:12 d2.utils.events]: \u001b[0m eta: 0:37:44  iter: 5339  total_loss: 1.43  loss_cls: 0.3218  loss_box_reg: 0.538  loss_mask: 0.2925  loss_rpn_cls: 0.07429  loss_rpn_loc: 0.1827  time: 0.6605  data_time: 0.1848  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:08:26 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 5359  total_loss: 1.414  loss_cls: 0.315  loss_box_reg: 0.5602  loss_mask: 0.2963  loss_rpn_cls: 0.07056  loss_rpn_loc: 0.1748  time: 0.6607  data_time: 0.2250  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:08:40 d2.utils.events]: \u001b[0m eta: 0:37:24  iter: 5379  total_loss: 1.508  loss_cls: 0.3261  loss_box_reg: 0.5441  loss_mask: 0.3154  loss_rpn_cls: 0.08222  loss_rpn_loc: 0.1993  time: 0.6607  data_time: 0.2077  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:08:55 d2.utils.events]: \u001b[0m eta: 0:37:11  iter: 5399  total_loss: 1.292  loss_cls: 0.3017  loss_box_reg: 0.5213  loss_mask: 0.2995  loss_rpn_cls: 0.06038  loss_rpn_loc: 0.1447  time: 0.6611  data_time: 0.2897  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:09:06 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 5419  total_loss: 1.284  loss_cls: 0.2743  loss_box_reg: 0.5372  loss_mask: 0.2829  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.1464  time: 0.6608  data_time: 0.1229  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:09:18 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 5439  total_loss: 1.336  loss_cls: 0.2943  loss_box_reg: 0.545  loss_mask: 0.2974  loss_rpn_cls: 0.06925  loss_rpn_loc: 0.1622  time: 0.6605  data_time: 0.1368  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:09:31 d2.utils.events]: \u001b[0m eta: 0:36:46  iter: 5459  total_loss: 1.435  loss_cls: 0.3376  loss_box_reg: 0.5764  loss_mask: 0.3099  loss_rpn_cls: 0.08508  loss_rpn_loc: 0.1599  time: 0.6604  data_time: 0.1307  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:09:46 d2.utils.events]: \u001b[0m eta: 0:36:39  iter: 5479  total_loss: 1.547  loss_cls: 0.3257  loss_box_reg: 0.5718  loss_mask: 0.3106  loss_rpn_cls: 0.09047  loss_rpn_loc: 0.187  time: 0.6608  data_time: 0.2674  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:10:01 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 5499  total_loss: 1.474  loss_cls: 0.3296  loss_box_reg: 0.5784  loss_mask: 0.3069  loss_rpn_cls: 0.0915  loss_rpn_loc: 0.1916  time: 0.6610  data_time: 0.2401  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:10:14 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 5519  total_loss: 1.34  loss_cls: 0.3105  loss_box_reg: 0.5142  loss_mask: 0.2895  loss_rpn_cls: 0.06416  loss_rpn_loc: 0.1618  time: 0.6611  data_time: 0.2034  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:10:27 d2.utils.events]: \u001b[0m eta: 0:36:14  iter: 5539  total_loss: 1.409  loss_cls: 0.3233  loss_box_reg: 0.5785  loss_mask: 0.2882  loss_rpn_cls: 0.06702  loss_rpn_loc: 0.1602  time: 0.6610  data_time: 0.1642  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:10:38 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 5559  total_loss: 1.198  loss_cls: 0.2753  loss_box_reg: 0.4979  loss_mask: 0.2793  loss_rpn_cls: 0.04793  loss_rpn_loc: 0.1267  time: 0.6606  data_time: 0.0789  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:10:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:10:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:10:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:10:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:10:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:10:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:10:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0836 s/iter. Eval: 0.0500 s/iter. Total: 0.1342 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 12:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0676 s/iter. Total: 0.1541 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:10:54 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0857 s/iter. Eval: 0.0704 s/iter. Total: 0.1570 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0733 s/iter. Total: 0.1600 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:11:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.598622 (0.160333 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:11:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.086166 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:11:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:11:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2709808054853694\n",
      "\u001b[32m[02/05 12:11:11 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 5579  total_loss: 1.323  loss_cls: 0.3144  loss_box_reg: 0.521  loss_mask: 0.2853  loss_rpn_cls: 0.07724  loss_rpn_loc: 0.1578  time: 0.6605  data_time: 0.1547  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:11:22 d2.utils.events]: \u001b[0m eta: 0:35:41  iter: 5599  total_loss: 1.327  loss_cls: 0.2878  loss_box_reg: 0.5387  loss_mask: 0.2769  loss_rpn_cls: 0.05911  loss_rpn_loc: 0.1487  time: 0.6601  data_time: 0.0896  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:11:36 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 5619  total_loss: 1.39  loss_cls: 0.3175  loss_box_reg: 0.5356  loss_mask: 0.2917  loss_rpn_cls: 0.06426  loss_rpn_loc: 0.1736  time: 0.6603  data_time: 0.2544  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:11:48 d2.utils.events]: \u001b[0m eta: 0:35:24  iter: 5639  total_loss: 1.453  loss_cls: 0.332  loss_box_reg: 0.5781  loss_mask: 0.3088  loss_rpn_cls: 0.08422  loss_rpn_loc: 0.1818  time: 0.6600  data_time: 0.1146  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:12:01 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 5659  total_loss: 1.433  loss_cls: 0.3297  loss_box_reg: 0.5469  loss_mask: 0.3015  loss_rpn_cls: 0.07798  loss_rpn_loc: 0.1757  time: 0.6600  data_time: 0.1775  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:12:14 d2.utils.events]: \u001b[0m eta: 0:35:07  iter: 5679  total_loss: 1.444  loss_cls: 0.3156  loss_box_reg: 0.5398  loss_mask: 0.2871  loss_rpn_cls: 0.07727  loss_rpn_loc: 0.1771  time: 0.6600  data_time: 0.1791  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:12:29 d2.utils.events]: \u001b[0m eta: 0:34:59  iter: 5699  total_loss: 1.448  loss_cls: 0.3217  loss_box_reg: 0.5461  loss_mask: 0.2951  loss_rpn_cls: 0.08032  loss_rpn_loc: 0.1683  time: 0.6603  data_time: 0.2691  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:12:47 d2.utils.events]: \u001b[0m eta: 0:34:51  iter: 5719  total_loss: 1.495  loss_cls: 0.3449  loss_box_reg: 0.5575  loss_mask: 0.3063  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.1947  time: 0.6611  data_time: 0.3847  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:12:59 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 5739  total_loss: 1.406  loss_cls: 0.3195  loss_box_reg: 0.5521  loss_mask: 0.3128  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.162  time: 0.6609  data_time: 0.1388  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:13:12 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 5759  total_loss: 1.445  loss_cls: 0.301  loss_box_reg: 0.5589  loss_mask: 0.3027  loss_rpn_cls: 0.0812  loss_rpn_loc: 0.1766  time: 0.6609  data_time: 0.2211  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:13:26 d2.utils.events]: \u001b[0m eta: 0:34:28  iter: 5779  total_loss: 1.423  loss_cls: 0.2948  loss_box_reg: 0.549  loss_mask: 0.3017  loss_rpn_cls: 0.06845  loss_rpn_loc: 0.1848  time: 0.6610  data_time: 0.1968  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:13:39 d2.utils.events]: \u001b[0m eta: 0:34:16  iter: 5799  total_loss: 1.398  loss_cls: 0.3154  loss_box_reg: 0.5532  loss_mask: 0.306  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.1804  time: 0.6610  data_time: 0.1792  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:13:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:13:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:13:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:13:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:13:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:13:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:13:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0847 s/iter. Eval: 0.0530 s/iter. Total: 0.1384 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 12:13:51 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0684 s/iter. Total: 0.1552 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:13:56 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0714 s/iter. Total: 0.1582 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0762 s/iter. Total: 0.1638 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:14:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.907652 (0.162997 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:14:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086703 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:14:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:14:04 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2698325685323751\n",
      "\u001b[32m[02/05 12:14:11 d2.utils.events]: \u001b[0m eta: 0:34:04  iter: 5819  total_loss: 1.308  loss_cls: 0.2804  loss_box_reg: 0.5466  loss_mask: 0.2849  loss_rpn_cls: 0.04288  loss_rpn_loc: 0.1601  time: 0.6606  data_time: 0.0748  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:14:22 d2.utils.events]: \u001b[0m eta: 0:33:52  iter: 5839  total_loss: 1.344  loss_cls: 0.3053  loss_box_reg: 0.5498  loss_mask: 0.2961  loss_rpn_cls: 0.07103  loss_rpn_loc: 0.1816  time: 0.6602  data_time: 0.0976  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:14:35 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 5859  total_loss: 1.289  loss_cls: 0.303  loss_box_reg: 0.5199  loss_mask: 0.2894  loss_rpn_cls: 0.07448  loss_rpn_loc: 0.1471  time: 0.6602  data_time: 0.1788  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:14:47 d2.utils.events]: \u001b[0m eta: 0:33:35  iter: 5879  total_loss: 1.386  loss_cls: 0.3205  loss_box_reg: 0.5518  loss_mask: 0.3062  loss_rpn_cls: 0.07378  loss_rpn_loc: 0.1624  time: 0.6600  data_time: 0.1028  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:15:00 d2.utils.events]: \u001b[0m eta: 0:33:34  iter: 5899  total_loss: 1.462  loss_cls: 0.3251  loss_box_reg: 0.5511  loss_mask: 0.2947  loss_rpn_cls: 0.09222  loss_rpn_loc: 0.1844  time: 0.6600  data_time: 0.1723  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:15:17 d2.utils.events]: \u001b[0m eta: 0:33:29  iter: 5919  total_loss: 1.493  loss_cls: 0.3203  loss_box_reg: 0.5504  loss_mask: 0.3093  loss_rpn_cls: 0.08904  loss_rpn_loc: 0.1949  time: 0.6606  data_time: 0.3341  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:15:28 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 5939  total_loss: 1.446  loss_cls: 0.3182  loss_box_reg: 0.5516  loss_mask: 0.2961  loss_rpn_cls: 0.07364  loss_rpn_loc: 0.1833  time: 0.6603  data_time: 0.1109  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:15:42 d2.utils.events]: \u001b[0m eta: 0:33:09  iter: 5959  total_loss: 1.434  loss_cls: 0.3169  loss_box_reg: 0.5634  loss_mask: 0.2944  loss_rpn_cls: 0.0761  loss_rpn_loc: 0.1831  time: 0.6603  data_time: 0.2220  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:15:53 d2.utils.events]: \u001b[0m eta: 0:32:57  iter: 5979  total_loss: 1.293  loss_cls: 0.2933  loss_box_reg: 0.5298  loss_mask: 0.2779  loss_rpn_cls: 0.04462  loss_rpn_loc: 0.1431  time: 0.6601  data_time: 0.1318  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:16:04 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 5999  total_loss: 1.448  loss_cls: 0.3302  loss_box_reg: 0.564  loss_mask: 0.29  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.1716  time: 0.6597  data_time: 0.0769  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:16:18 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 6019  total_loss: 1.531  loss_cls: 0.3337  loss_box_reg: 0.5666  loss_mask: 0.3167  loss_rpn_cls: 0.09654  loss_rpn_loc: 0.1908  time: 0.6597  data_time: 0.1966  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:16:35 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 6039  total_loss: 1.372  loss_cls: 0.3119  loss_box_reg: 0.5274  loss_mask: 0.2901  loss_rpn_cls: 0.06841  loss_rpn_loc: 0.1786  time: 0.6604  data_time: 0.3700  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:16:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:16:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:16:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:16:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:16:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:16:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0851 s/iter. Eval: 0.0563 s/iter. Total: 0.1421 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 12:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0865 s/iter. Eval: 0.0697 s/iter. Total: 0.1571 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0725 s/iter. Total: 0.1595 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0750 s/iter. Total: 0.1621 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:17:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.737170 (0.161527 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:17:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086303 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:17:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:17:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2691730486722194\n",
      "\u001b[32m[02/05 12:17:08 d2.utils.events]: \u001b[0m eta: 0:32:24  iter: 6059  total_loss: 1.482  loss_cls: 0.3102  loss_box_reg: 0.526  loss_mask: 0.2907  loss_rpn_cls: 0.08725  loss_rpn_loc: 0.1682  time: 0.6603  data_time: 0.1831  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:17:20 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 6079  total_loss: 1.418  loss_cls: 0.3199  loss_box_reg: 0.544  loss_mask: 0.2872  loss_rpn_cls: 0.06745  loss_rpn_loc: 0.1837  time: 0.6600  data_time: 0.1082  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:17:31 d2.utils.events]: \u001b[0m eta: 0:32:04  iter: 6099  total_loss: 1.323  loss_cls: 0.3004  loss_box_reg: 0.523  loss_mask: 0.2826  loss_rpn_cls: 0.05773  loss_rpn_loc: 0.1424  time: 0.6598  data_time: 0.1129  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:17:49 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 6119  total_loss: 1.472  loss_cls: 0.3342  loss_box_reg: 0.5712  loss_mask: 0.3091  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.1704  time: 0.6605  data_time: 0.4211  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:18:02 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 6139  total_loss: 1.507  loss_cls: 0.3113  loss_box_reg: 0.569  loss_mask: 0.3088  loss_rpn_cls: 0.08624  loss_rpn_loc: 0.1806  time: 0.6604  data_time: 0.1362  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:18:15 d2.utils.events]: \u001b[0m eta: 0:31:39  iter: 6159  total_loss: 1.419  loss_cls: 0.3287  loss_box_reg: 0.567  loss_mask: 0.2804  loss_rpn_cls: 0.08061  loss_rpn_loc: 0.1521  time: 0.6604  data_time: 0.1780  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:18:27 d2.utils.events]: \u001b[0m eta: 0:31:29  iter: 6179  total_loss: 1.372  loss_cls: 0.2948  loss_box_reg: 0.5344  loss_mask: 0.3026  loss_rpn_cls: 0.08438  loss_rpn_loc: 0.1684  time: 0.6602  data_time: 0.1540  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:18:41 d2.utils.events]: \u001b[0m eta: 0:31:19  iter: 6199  total_loss: 1.453  loss_cls: 0.3219  loss_box_reg: 0.5822  loss_mask: 0.3006  loss_rpn_cls: 0.0781  loss_rpn_loc: 0.1684  time: 0.6604  data_time: 0.2377  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:18:56 d2.utils.events]: \u001b[0m eta: 0:31:09  iter: 6219  total_loss: 1.419  loss_cls: 0.3146  loss_box_reg: 0.5515  loss_mask: 0.2958  loss_rpn_cls: 0.08197  loss_rpn_loc: 0.1715  time: 0.6607  data_time: 0.2590  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:19:12 d2.utils.events]: \u001b[0m eta: 0:31:02  iter: 6239  total_loss: 1.516  loss_cls: 0.3223  loss_box_reg: 0.5687  loss_mask: 0.3151  loss_rpn_cls: 0.08809  loss_rpn_loc: 0.1731  time: 0.6611  data_time: 0.3075  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:19:24 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 6259  total_loss: 1.204  loss_cls: 0.267  loss_box_reg: 0.5207  loss_mask: 0.2806  loss_rpn_cls: 0.06756  loss_rpn_loc: 0.1487  time: 0.6608  data_time: 0.1234  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:19:39 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 6279  total_loss: 1.513  loss_cls: 0.3539  loss_box_reg: 0.5527  loss_mask: 0.3004  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.1867  time: 0.6612  data_time: 0.2839  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:19:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:19:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:19:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:19:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:19:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:19:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0897 s/iter. Eval: 0.0573 s/iter. Total: 0.1477 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 12:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0716 s/iter. Total: 0.1601 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0729 s/iter. Total: 0.1610 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0774 s/iter. Total: 0.1657 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:20:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.121817 (0.164843 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:20:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087401 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:20:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:20:09 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26785151829513615\n",
      "\u001b[32m[02/05 12:20:13 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 6299  total_loss: 1.385  loss_cls: 0.3107  loss_box_reg: 0.5638  loss_mask: 0.3048  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.1608  time: 0.6611  data_time: 0.1670  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:20:26 d2.utils.events]: \u001b[0m eta: 0:30:31  iter: 6319  total_loss: 1.308  loss_cls: 0.3062  loss_box_reg: 0.5188  loss_mask: 0.2863  loss_rpn_cls: 0.0618  loss_rpn_loc: 0.1511  time: 0.6611  data_time: 0.1817  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:20:39 d2.utils.events]: \u001b[0m eta: 0:30:18  iter: 6339  total_loss: 1.332  loss_cls: 0.2795  loss_box_reg: 0.5298  loss_mask: 0.2915  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.1731  time: 0.6610  data_time: 0.1708  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:20:53 d2.utils.events]: \u001b[0m eta: 0:30:10  iter: 6359  total_loss: 1.405  loss_cls: 0.3206  loss_box_reg: 0.5685  loss_mask: 0.3065  loss_rpn_cls: 0.07221  loss_rpn_loc: 0.1769  time: 0.6612  data_time: 0.2439  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:21:06 d2.utils.events]: \u001b[0m eta: 0:29:55  iter: 6379  total_loss: 1.411  loss_cls: 0.3174  loss_box_reg: 0.5608  loss_mask: 0.2917  loss_rpn_cls: 0.06497  loss_rpn_loc: 0.1699  time: 0.6611  data_time: 0.1697  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:21:19 d2.utils.events]: \u001b[0m eta: 0:29:47  iter: 6399  total_loss: 1.49  loss_cls: 0.339  loss_box_reg: 0.5707  loss_mask: 0.3199  loss_rpn_cls: 0.07726  loss_rpn_loc: 0.1726  time: 0.6610  data_time: 0.1602  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:21:32 d2.utils.events]: \u001b[0m eta: 0:29:40  iter: 6419  total_loss: 1.461  loss_cls: 0.334  loss_box_reg: 0.5617  loss_mask: 0.3167  loss_rpn_cls: 0.08845  loss_rpn_loc: 0.2014  time: 0.6610  data_time: 0.2074  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:21:44 d2.utils.events]: \u001b[0m eta: 0:29:30  iter: 6439  total_loss: 1.381  loss_cls: 0.3002  loss_box_reg: 0.5257  loss_mask: 0.2928  loss_rpn_cls: 0.06398  loss_rpn_loc: 0.1688  time: 0.6609  data_time: 0.1403  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:21:58 d2.utils.events]: \u001b[0m eta: 0:29:17  iter: 6459  total_loss: 1.441  loss_cls: 0.3177  loss_box_reg: 0.5598  loss_mask: 0.2978  loss_rpn_cls: 0.09229  loss_rpn_loc: 0.1714  time: 0.6609  data_time: 0.1881  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:22:09 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 6479  total_loss: 1.364  loss_cls: 0.3034  loss_box_reg: 0.5551  loss_mask: 0.2951  loss_rpn_cls: 0.0661  loss_rpn_loc: 0.1579  time: 0.6607  data_time: 0.1144  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:22:25 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 6499  total_loss: 1.41  loss_cls: 0.3134  loss_box_reg: 0.5372  loss_mask: 0.3011  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1615  time: 0.6611  data_time: 0.2912  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:22:38 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 6519  total_loss: 1.303  loss_cls: 0.2756  loss_box_reg: 0.5248  loss_mask: 0.2909  loss_rpn_cls: 0.05638  loss_rpn_loc: 0.1505  time: 0.6610  data_time: 0.1543  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:22:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:22:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:22:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:22:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:22:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:22:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0851 s/iter. Eval: 0.0562 s/iter. Total: 0.1420 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 12:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0723 s/iter. Total: 0.1607 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0730 s/iter. Total: 0.1611 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0768 s/iter. Total: 0.1651 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:23:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.021153 (0.163975 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:23:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087172 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:23:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:23:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2679236258032335\n",
      "\u001b[32m[02/05 12:23:12 d2.utils.events]: \u001b[0m eta: 0:28:31  iter: 6539  total_loss: 1.428  loss_cls: 0.3388  loss_box_reg: 0.5605  loss_mask: 0.3019  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1741  time: 0.6611  data_time: 0.2013  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:23:30 d2.utils.events]: \u001b[0m eta: 0:28:30  iter: 6559  total_loss: 1.462  loss_cls: 0.3312  loss_box_reg: 0.5572  loss_mask: 0.3002  loss_rpn_cls: 0.08708  loss_rpn_loc: 0.1729  time: 0.6617  data_time: 0.3787  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:23:43 d2.utils.events]: \u001b[0m eta: 0:28:20  iter: 6579  total_loss: 1.42  loss_cls: 0.3166  loss_box_reg: 0.5685  loss_mask: 0.3044  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.1666  time: 0.6617  data_time: 0.1638  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:23:55 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 6599  total_loss: 1.442  loss_cls: 0.3104  loss_box_reg: 0.5193  loss_mask: 0.3012  loss_rpn_cls: 0.09089  loss_rpn_loc: 0.1795  time: 0.6616  data_time: 0.1469  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:24:10 d2.utils.events]: \u001b[0m eta: 0:28:05  iter: 6619  total_loss: 1.374  loss_cls: 0.3249  loss_box_reg: 0.553  loss_mask: 0.2887  loss_rpn_cls: 0.07931  loss_rpn_loc: 0.1681  time: 0.6619  data_time: 0.2662  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:24:30 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 6639  total_loss: 1.486  loss_cls: 0.336  loss_box_reg: 0.5766  loss_mask: 0.3049  loss_rpn_cls: 0.09063  loss_rpn_loc: 0.1978  time: 0.6628  data_time: 0.4781  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:24:43 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 6659  total_loss: 1.422  loss_cls: 0.3108  loss_box_reg: 0.5439  loss_mask: 0.2952  loss_rpn_cls: 0.06492  loss_rpn_loc: 0.1628  time: 0.6627  data_time: 0.1759  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:24:57 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 6679  total_loss: 1.328  loss_cls: 0.2944  loss_box_reg: 0.5152  loss_mask: 0.2783  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.1571  time: 0.6629  data_time: 0.2541  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:25:12 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 6699  total_loss: 1.36  loss_cls: 0.3097  loss_box_reg: 0.5649  loss_mask: 0.2914  loss_rpn_cls: 0.06858  loss_rpn_loc: 0.1551  time: 0.6632  data_time: 0.2797  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:25:23 d2.utils.events]: \u001b[0m eta: 0:27:11  iter: 6719  total_loss: 1.362  loss_cls: 0.2916  loss_box_reg: 0.5615  loss_mask: 0.3054  loss_rpn_cls: 0.05443  loss_rpn_loc: 0.1455  time: 0.6629  data_time: 0.0800  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:25:37 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 6739  total_loss: 1.308  loss_cls: 0.2923  loss_box_reg: 0.5477  loss_mask: 0.2995  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.1393  time: 0.6629  data_time: 0.2024  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:25:49 d2.utils.events]: \u001b[0m eta: 0:26:48  iter: 6759  total_loss: 1.4  loss_cls: 0.2728  loss_box_reg: 0.5513  loss_mask: 0.3075  loss_rpn_cls: 0.05506  loss_rpn_loc: 0.1641  time: 0.6628  data_time: 0.1790  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:26:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:26:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:26:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:26:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:26:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:26:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:26:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0850 s/iter. Eval: 0.0555 s/iter. Total: 0.1413 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 12:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0728 s/iter. Total: 0.1610 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0730 s/iter. Total: 0.1607 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0769 s/iter. Total: 0.1653 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:26:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.021911 (0.163982 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:26:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087288 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:26:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:26:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2670410010281615\n",
      "\u001b[32m[02/05 12:26:23 d2.utils.events]: \u001b[0m eta: 0:26:38  iter: 6779  total_loss: 1.454  loss_cls: 0.3321  loss_box_reg: 0.5712  loss_mask: 0.2991  loss_rpn_cls: 0.08493  loss_rpn_loc: 0.1795  time: 0.6628  data_time: 0.1650  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:26:38 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 6799  total_loss: 1.43  loss_cls: 0.3357  loss_box_reg: 0.5321  loss_mask: 0.3084  loss_rpn_cls: 0.09002  loss_rpn_loc: 0.1686  time: 0.6630  data_time: 0.2570  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:26:51 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 6819  total_loss: 1.367  loss_cls: 0.3052  loss_box_reg: 0.5411  loss_mask: 0.2822  loss_rpn_cls: 0.07003  loss_rpn_loc: 0.1573  time: 0.6630  data_time: 0.1597  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:27:04 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 6839  total_loss: 1.496  loss_cls: 0.3394  loss_box_reg: 0.5649  loss_mask: 0.2998  loss_rpn_cls: 0.07357  loss_rpn_loc: 0.1719  time: 0.6629  data_time: 0.1824  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:27:20 d2.utils.events]: \u001b[0m eta: 0:26:02  iter: 6859  total_loss: 1.375  loss_cls: 0.3284  loss_box_reg: 0.5486  loss_mask: 0.2961  loss_rpn_cls: 0.07226  loss_rpn_loc: 0.1672  time: 0.6633  data_time: 0.3135  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:27:34 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 6879  total_loss: 1.279  loss_cls: 0.2287  loss_box_reg: 0.5022  loss_mask: 0.284  loss_rpn_cls: 0.06348  loss_rpn_loc: 0.1492  time: 0.6634  data_time: 0.2155  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:27:47 d2.utils.events]: \u001b[0m eta: 0:25:39  iter: 6899  total_loss: 1.321  loss_cls: 0.3155  loss_box_reg: 0.519  loss_mask: 0.293  loss_rpn_cls: 0.05882  loss_rpn_loc: 0.1465  time: 0.6634  data_time: 0.1784  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:28:02 d2.utils.events]: \u001b[0m eta: 0:25:28  iter: 6919  total_loss: 1.488  loss_cls: 0.3474  loss_box_reg: 0.5656  loss_mask: 0.3158  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.1498  time: 0.6636  data_time: 0.2392  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:28:15 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 6939  total_loss: 1.348  loss_cls: 0.3059  loss_box_reg: 0.5204  loss_mask: 0.2896  loss_rpn_cls: 0.06363  loss_rpn_loc: 0.1741  time: 0.6636  data_time: 0.1853  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:28:28 d2.utils.events]: \u001b[0m eta: 0:25:10  iter: 6959  total_loss: 1.477  loss_cls: 0.3395  loss_box_reg: 0.5853  loss_mask: 0.3071  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.1784  time: 0.6636  data_time: 0.1578  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:28:40 d2.utils.events]: \u001b[0m eta: 0:25:05  iter: 6979  total_loss: 1.391  loss_cls: 0.2933  loss_box_reg: 0.5386  loss_mask: 0.2972  loss_rpn_cls: 0.0806  loss_rpn_loc: 0.1518  time: 0.6633  data_time: 0.0890  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:28:52 d2.utils.events]: \u001b[0m eta: 0:24:56  iter: 6999  total_loss: 1.319  loss_cls: 0.2911  loss_box_reg: 0.5158  loss_mask: 0.2814  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.1427  time: 0.6632  data_time: 0.1220  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:29:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:29:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:29:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:29:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:29:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:29:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0629 s/iter. Total: 0.1546 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 12:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0897 s/iter. Eval: 0.0708 s/iter. Total: 0.1613 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0717 s/iter. Total: 0.1619 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0899 s/iter. Eval: 0.0765 s/iter. Total: 0.1673 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 12:29:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.330544 (0.166643 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:29:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:29:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:29:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2710218086748517\n",
      "\u001b[32m[02/05 12:29:27 d2.utils.events]: \u001b[0m eta: 0:24:45  iter: 7019  total_loss: 1.499  loss_cls: 0.3286  loss_box_reg: 0.5482  loss_mask: 0.2944  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.1861  time: 0.6633  data_time: 0.1954  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:29:39 d2.utils.events]: \u001b[0m eta: 0:24:35  iter: 7039  total_loss: 1.473  loss_cls: 0.313  loss_box_reg: 0.5648  loss_mask: 0.3031  loss_rpn_cls: 0.06889  loss_rpn_loc: 0.1703  time: 0.6630  data_time: 0.0998  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:29:50 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 7059  total_loss: 1.434  loss_cls: 0.3208  loss_box_reg: 0.549  loss_mask: 0.3075  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.1533  time: 0.6628  data_time: 0.1068  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:30:03 d2.utils.events]: \u001b[0m eta: 0:24:17  iter: 7079  total_loss: 1.421  loss_cls: 0.3188  loss_box_reg: 0.531  loss_mask: 0.2884  loss_rpn_cls: 0.08479  loss_rpn_loc: 0.1646  time: 0.6627  data_time: 0.1629  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:30:14 d2.utils.events]: \u001b[0m eta: 0:24:05  iter: 7099  total_loss: 1.355  loss_cls: 0.3101  loss_box_reg: 0.5466  loss_mask: 0.303  loss_rpn_cls: 0.04631  loss_rpn_loc: 0.1374  time: 0.6624  data_time: 0.0775  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:30:31 d2.utils.events]: \u001b[0m eta: 0:23:55  iter: 7119  total_loss: 1.425  loss_cls: 0.3158  loss_box_reg: 0.5289  loss_mask: 0.2963  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.169  time: 0.6629  data_time: 0.3599  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:30:47 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 7139  total_loss: 1.431  loss_cls: 0.3152  loss_box_reg: 0.5675  loss_mask: 0.2998  loss_rpn_cls: 0.08011  loss_rpn_loc: 0.17  time: 0.6633  data_time: 0.2869  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:31:01 d2.utils.events]: \u001b[0m eta: 0:23:37  iter: 7159  total_loss: 1.569  loss_cls: 0.3626  loss_box_reg: 0.5977  loss_mask: 0.3182  loss_rpn_cls: 0.1224  loss_rpn_loc: 0.1922  time: 0.6634  data_time: 0.2512  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:31:13 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 7179  total_loss: 1.282  loss_cls: 0.2685  loss_box_reg: 0.4947  loss_mask: 0.2757  loss_rpn_cls: 0.05625  loss_rpn_loc: 0.1515  time: 0.6632  data_time: 0.1288  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:31:26 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 7199  total_loss: 1.26  loss_cls: 0.2908  loss_box_reg: 0.496  loss_mask: 0.2759  loss_rpn_cls: 0.06444  loss_rpn_loc: 0.1385  time: 0.6632  data_time: 0.1906  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:31:41 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 7219  total_loss: 1.425  loss_cls: 0.3269  loss_box_reg: 0.5417  loss_mask: 0.2838  loss_rpn_cls: 0.09229  loss_rpn_loc: 0.1589  time: 0.6634  data_time: 0.2407  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:31:55 d2.utils.events]: \u001b[0m eta: 0:22:55  iter: 7239  total_loss: 1.42  loss_cls: 0.309  loss_box_reg: 0.567  loss_mask: 0.2937  loss_rpn_cls: 0.08674  loss_rpn_loc: 0.1867  time: 0.6635  data_time: 0.2256  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:32:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:32:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:32:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:32:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:32:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:32:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0928 s/iter. Eval: 0.0656 s/iter. Total: 0.1593 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 12:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0910 s/iter. Eval: 0.0767 s/iter. Total: 0.1686 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 12:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0738 s/iter. Total: 0.1634 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0791 s/iter. Total: 0.1690 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 12:32:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.549736 (0.168532 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:32:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089186 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:32:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:32:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26964517247380576\n",
      "\u001b[32m[02/05 12:32:29 d2.utils.events]: \u001b[0m eta: 0:22:45  iter: 7259  total_loss: 1.344  loss_cls: 0.2986  loss_box_reg: 0.5328  loss_mask: 0.2921  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.1613  time: 0.6634  data_time: 0.1651  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:32:42 d2.utils.events]: \u001b[0m eta: 0:22:33  iter: 7279  total_loss: 1.559  loss_cls: 0.3456  loss_box_reg: 0.5613  loss_mask: 0.3063  loss_rpn_cls: 0.09458  loss_rpn_loc: 0.1975  time: 0.6634  data_time: 0.1759  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:32:54 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 7299  total_loss: 1.318  loss_cls: 0.2986  loss_box_reg: 0.5461  loss_mask: 0.2963  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.1579  time: 0.6632  data_time: 0.1028  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:33:09 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 7319  total_loss: 1.371  loss_cls: 0.3083  loss_box_reg: 0.5522  loss_mask: 0.2915  loss_rpn_cls: 0.08241  loss_rpn_loc: 0.1617  time: 0.6635  data_time: 0.2974  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:33:20 d2.utils.events]: \u001b[0m eta: 0:22:02  iter: 7339  total_loss: 1.454  loss_cls: 0.3537  loss_box_reg: 0.5715  loss_mask: 0.2939  loss_rpn_cls: 0.07662  loss_rpn_loc: 0.1643  time: 0.6632  data_time: 0.0863  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:33:37 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 7359  total_loss: 1.419  loss_cls: 0.3164  loss_box_reg: 0.5469  loss_mask: 0.3081  loss_rpn_cls: 0.07931  loss_rpn_loc: 0.171  time: 0.6637  data_time: 0.3537  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:33:50 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 7379  total_loss: 1.394  loss_cls: 0.3212  loss_box_reg: 0.5583  loss_mask: 0.2946  loss_rpn_cls: 0.0712  loss_rpn_loc: 0.1652  time: 0.6636  data_time: 0.1365  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:34:04 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 7399  total_loss: 1.325  loss_cls: 0.3034  loss_box_reg: 0.5073  loss_mask: 0.287  loss_rpn_cls: 0.06197  loss_rpn_loc: 0.1398  time: 0.6638  data_time: 0.2512  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:34:18 d2.utils.events]: \u001b[0m eta: 0:21:30  iter: 7419  total_loss: 1.538  loss_cls: 0.3368  loss_box_reg: 0.5701  loss_mask: 0.3166  loss_rpn_cls: 0.09845  loss_rpn_loc: 0.199  time: 0.6638  data_time: 0.1841  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:34:30 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 7439  total_loss: 1.36  loss_cls: 0.2866  loss_box_reg: 0.5461  loss_mask: 0.2956  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.1578  time: 0.6636  data_time: 0.1377  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:34:43 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 7459  total_loss: 1.391  loss_cls: 0.3182  loss_box_reg: 0.5366  loss_mask: 0.2969  loss_rpn_cls: 0.07655  loss_rpn_loc: 0.1564  time: 0.6636  data_time: 0.1698  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:34:56 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 7479  total_loss: 1.383  loss_cls: 0.2916  loss_box_reg: 0.5085  loss_mask: 0.2894  loss_rpn_cls: 0.04733  loss_rpn_loc: 0.1454  time: 0.6636  data_time: 0.1892  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:35:11 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 7499  total_loss: 1.356  loss_cls: 0.303  loss_box_reg: 0.5447  loss_mask: 0.2918  loss_rpn_cls: 0.07743  loss_rpn_loc: 0.1701  time: 0.6637  data_time: 0.2543  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:35:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:35:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:35:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:35:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:35:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:35:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0636 s/iter. Total: 0.1535 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 12:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0695 s/iter. Total: 0.1567 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0861 s/iter. Eval: 0.0719 s/iter. Total: 0.1589 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0744 s/iter. Total: 0.1616 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:35:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.771410 (0.161823 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:35:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086319 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:35:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:35:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2702985463629367\n",
      "\u001b[32m[02/05 12:35:43 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 7519  total_loss: 1.304  loss_cls: 0.2816  loss_box_reg: 0.5242  loss_mask: 0.282  loss_rpn_cls: 0.05138  loss_rpn_loc: 0.1377  time: 0.6636  data_time: 0.1457  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:35:59 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 7539  total_loss: 1.487  loss_cls: 0.3058  loss_box_reg: 0.5469  loss_mask: 0.3183  loss_rpn_cls: 0.0873  loss_rpn_loc: 0.1842  time: 0.6638  data_time: 0.3018  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:36:11 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 7559  total_loss: 1.376  loss_cls: 0.3047  loss_box_reg: 0.5505  loss_mask: 0.2971  loss_rpn_cls: 0.08086  loss_rpn_loc: 0.1611  time: 0.6637  data_time: 0.1480  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:36:21 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 7579  total_loss: 1.371  loss_cls: 0.3085  loss_box_reg: 0.5227  loss_mask: 0.2836  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.1529  time: 0.6633  data_time: 0.0653  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:36:35 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 7599  total_loss: 1.33  loss_cls: 0.2905  loss_box_reg: 0.5302  loss_mask: 0.2967  loss_rpn_cls: 0.07482  loss_rpn_loc: 0.1454  time: 0.6634  data_time: 0.2092  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:36:49 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 7619  total_loss: 1.371  loss_cls: 0.2992  loss_box_reg: 0.5257  loss_mask: 0.2911  loss_rpn_cls: 0.07768  loss_rpn_loc: 0.1856  time: 0.6635  data_time: 0.2406  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:37:01 d2.utils.events]: \u001b[0m eta: 0:19:32  iter: 7639  total_loss: 1.381  loss_cls: 0.3169  loss_box_reg: 0.5327  loss_mask: 0.2775  loss_rpn_cls: 0.07531  loss_rpn_loc: 0.1525  time: 0.6634  data_time: 0.1394  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:37:14 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 7659  total_loss: 1.563  loss_cls: 0.3582  loss_box_reg: 0.579  loss_mask: 0.3045  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.1966  time: 0.6633  data_time: 0.1604  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:37:26 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 7679  total_loss: 1.41  loss_cls: 0.3204  loss_box_reg: 0.5616  loss_mask: 0.3071  loss_rpn_cls: 0.07879  loss_rpn_loc: 0.1622  time: 0.6631  data_time: 0.1454  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:37:41 d2.utils.events]: \u001b[0m eta: 0:19:03  iter: 7699  total_loss: 1.41  loss_cls: 0.3108  loss_box_reg: 0.5462  loss_mask: 0.2931  loss_rpn_cls: 0.07119  loss_rpn_loc: 0.1628  time: 0.6633  data_time: 0.2548  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:37:54 d2.utils.events]: \u001b[0m eta: 0:18:54  iter: 7719  total_loss: 1.454  loss_cls: 0.3408  loss_box_reg: 0.5839  loss_mask: 0.3141  loss_rpn_cls: 0.08595  loss_rpn_loc: 0.1662  time: 0.6633  data_time: 0.1514  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:38:06 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 7739  total_loss: 1.343  loss_cls: 0.2928  loss_box_reg: 0.5225  loss_mask: 0.2914  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.1701  time: 0.6632  data_time: 0.1774  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:38:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:38:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:38:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:38:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:38:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:38:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0875 s/iter. Eval: 0.0705 s/iter. Total: 0.1587 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 12:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0009 s/iter. Inference: 0.0869 s/iter. Eval: 0.0717 s/iter. Total: 0.1595 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 12:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0728 s/iter. Total: 0.1601 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0747 s/iter. Total: 0.1622 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 12:38:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.923113 (0.163130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:38:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086945 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:38:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:38:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26967184987780196\n",
      "\u001b[32m[02/05 12:38:41 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 7759  total_loss: 1.412  loss_cls: 0.3151  loss_box_reg: 0.5423  loss_mask: 0.2983  loss_rpn_cls: 0.08057  loss_rpn_loc: 0.1781  time: 0.6633  data_time: 0.2267  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:38:51 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 7779  total_loss: 1.239  loss_cls: 0.2723  loss_box_reg: 0.5473  loss_mask: 0.281  loss_rpn_cls: 0.06028  loss_rpn_loc: 0.1221  time: 0.6629  data_time: 0.0537  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:39:08 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 7799  total_loss: 1.477  loss_cls: 0.354  loss_box_reg: 0.5695  loss_mask: 0.3078  loss_rpn_cls: 0.0909  loss_rpn_loc: 0.1835  time: 0.6633  data_time: 0.3196  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:39:22 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 7819  total_loss: 1.338  loss_cls: 0.2988  loss_box_reg: 0.5107  loss_mask: 0.3008  loss_rpn_cls: 0.07905  loss_rpn_loc: 0.1641  time: 0.6634  data_time: 0.2167  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:39:37 d2.utils.events]: \u001b[0m eta: 0:17:55  iter: 7839  total_loss: 1.225  loss_cls: 0.2777  loss_box_reg: 0.5221  loss_mask: 0.2761  loss_rpn_cls: 0.05617  loss_rpn_loc: 0.1331  time: 0.6636  data_time: 0.2554  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:39:51 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 7859  total_loss: 1.395  loss_cls: 0.33  loss_box_reg: 0.5333  loss_mask: 0.2996  loss_rpn_cls: 0.08633  loss_rpn_loc: 0.176  time: 0.6638  data_time: 0.2445  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:40:04 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 7879  total_loss: 1.376  loss_cls: 0.3006  loss_box_reg: 0.5477  loss_mask: 0.2913  loss_rpn_cls: 0.06133  loss_rpn_loc: 0.1665  time: 0.6637  data_time: 0.1806  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:40:21 d2.utils.events]: \u001b[0m eta: 0:17:24  iter: 7899  total_loss: 1.4  loss_cls: 0.3267  loss_box_reg: 0.522  loss_mask: 0.2912  loss_rpn_cls: 0.07115  loss_rpn_loc: 0.1795  time: 0.6641  data_time: 0.3275  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:40:35 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 7919  total_loss: 1.495  loss_cls: 0.3723  loss_box_reg: 0.5825  loss_mask: 0.2948  loss_rpn_cls: 0.0877  loss_rpn_loc: 0.1785  time: 0.6642  data_time: 0.2044  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:40:48 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 7939  total_loss: 1.423  loss_cls: 0.3199  loss_box_reg: 0.5464  loss_mask: 0.3183  loss_rpn_cls: 0.08037  loss_rpn_loc: 0.1736  time: 0.6642  data_time: 0.1895  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:41:01 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 7959  total_loss: 1.396  loss_cls: 0.3115  loss_box_reg: 0.5624  loss_mask: 0.2928  loss_rpn_cls: 0.08063  loss_rpn_loc: 0.1553  time: 0.6642  data_time: 0.1761  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:41:17 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 7979  total_loss: 1.303  loss_cls: 0.3013  loss_box_reg: 0.5277  loss_mask: 0.2834  loss_rpn_cls: 0.06014  loss_rpn_loc: 0.1452  time: 0.6645  data_time: 0.2719  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:41:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:41:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:41:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:41:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:41:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:41:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0939 s/iter. Eval: 0.0723 s/iter. Total: 0.1671 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 12:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0734 s/iter. Total: 0.1646 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 12:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0897 s/iter. Eval: 0.0731 s/iter. Total: 0.1638 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0899 s/iter. Eval: 0.0772 s/iter. Total: 0.1679 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 12:41:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.410849 (0.167335 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:41:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089854 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:41:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:41:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2714105062698874\n",
      "\u001b[32m[02/05 12:41:49 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 7999  total_loss: 1.253  loss_cls: 0.2625  loss_box_reg: 0.5223  loss_mask: 0.2925  loss_rpn_cls: 0.05244  loss_rpn_loc: 0.1479  time: 0.6642  data_time: 0.0556  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:42:07 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 8019  total_loss: 1.549  loss_cls: 0.3675  loss_box_reg: 0.5769  loss_mask: 0.313  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.1828  time: 0.6647  data_time: 0.3881  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:42:22 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 8039  total_loss: 1.427  loss_cls: 0.3158  loss_box_reg: 0.5541  loss_mask: 0.317  loss_rpn_cls: 0.0782  loss_rpn_loc: 0.1647  time: 0.6649  data_time: 0.2481  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:42:37 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 8059  total_loss: 1.431  loss_cls: 0.2925  loss_box_reg: 0.5442  loss_mask: 0.305  loss_rpn_cls: 0.07224  loss_rpn_loc: 0.1649  time: 0.6652  data_time: 0.2907  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:42:49 d2.utils.events]: \u001b[0m eta: 0:15:56  iter: 8079  total_loss: 1.302  loss_cls: 0.2675  loss_box_reg: 0.5167  loss_mask: 0.2893  loss_rpn_cls: 0.05298  loss_rpn_loc: 0.138  time: 0.6650  data_time: 0.1226  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:43:02 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 8099  total_loss: 1.475  loss_cls: 0.3372  loss_box_reg: 0.5753  loss_mask: 0.2994  loss_rpn_cls: 0.07805  loss_rpn_loc: 0.1833  time: 0.6650  data_time: 0.1720  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:43:20 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 8119  total_loss: 1.448  loss_cls: 0.3153  loss_box_reg: 0.5542  loss_mask: 0.3118  loss_rpn_cls: 0.08394  loss_rpn_loc: 0.1844  time: 0.6656  data_time: 0.3805  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:43:31 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 8139  total_loss: 1.37  loss_cls: 0.2998  loss_box_reg: 0.5476  loss_mask: 0.2911  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.1547  time: 0.6652  data_time: 0.0140  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:43:43 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 8159  total_loss: 1.289  loss_cls: 0.2588  loss_box_reg: 0.5043  loss_mask: 0.2722  loss_rpn_cls: 0.06363  loss_rpn_loc: 0.1405  time: 0.6651  data_time: 0.1288  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:43:55 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 8179  total_loss: 1.41  loss_cls: 0.3041  loss_box_reg: 0.5439  loss_mask: 0.2987  loss_rpn_cls: 0.07883  loss_rpn_loc: 0.1604  time: 0.6649  data_time: 0.1095  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:44:09 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 8199  total_loss: 1.376  loss_cls: 0.2981  loss_box_reg: 0.5417  loss_mask: 0.3086  loss_rpn_cls: 0.06413  loss_rpn_loc: 0.1636  time: 0.6651  data_time: 0.2395  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:44:22 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 8219  total_loss: 1.443  loss_cls: 0.3299  loss_box_reg: 0.5509  loss_mask: 0.2983  loss_rpn_cls: 0.07521  loss_rpn_loc: 0.1593  time: 0.6650  data_time: 0.1548  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:44:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:44:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:44:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:44:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:44:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:44:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0963 s/iter. Eval: 0.0698 s/iter. Total: 0.1669 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 12:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0752 s/iter. Total: 0.1671 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 12:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0009 s/iter. Inference: 0.0901 s/iter. Eval: 0.0736 s/iter. Total: 0.1647 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 12:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0783 s/iter. Total: 0.1697 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 12:44:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.557309 (0.168597 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:44:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:44:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:44:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.271112238190268\n",
      "\u001b[32m[02/05 12:44:55 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 8239  total_loss: 1.399  loss_cls: 0.3002  loss_box_reg: 0.5547  loss_mask: 0.2938  loss_rpn_cls: 0.0779  loss_rpn_loc: 0.1575  time: 0.6648  data_time: 0.0764  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:45:07 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 8259  total_loss: 1.342  loss_cls: 0.292  loss_box_reg: 0.5467  loss_mask: 0.2967  loss_rpn_cls: 0.05352  loss_rpn_loc: 0.1605  time: 0.6647  data_time: 0.1187  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:45:22 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 8279  total_loss: 1.436  loss_cls: 0.3329  loss_box_reg: 0.5418  loss_mask: 0.3004  loss_rpn_cls: 0.08133  loss_rpn_loc: 0.1659  time: 0.6649  data_time: 0.2644  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:45:37 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 8299  total_loss: 1.349  loss_cls: 0.2996  loss_box_reg: 0.5542  loss_mask: 0.3139  loss_rpn_cls: 0.06579  loss_rpn_loc: 0.1657  time: 0.6651  data_time: 0.2555  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:45:50 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 8319  total_loss: 1.388  loss_cls: 0.2781  loss_box_reg: 0.539  loss_mask: 0.295  loss_rpn_cls: 0.05746  loss_rpn_loc: 0.157  time: 0.6651  data_time: 0.1645  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:46:04 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 8339  total_loss: 1.427  loss_cls: 0.3157  loss_box_reg: 0.5462  loss_mask: 0.3028  loss_rpn_cls: 0.07713  loss_rpn_loc: 0.186  time: 0.6651  data_time: 0.2008  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:46:17 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 8359  total_loss: 1.335  loss_cls: 0.2964  loss_box_reg: 0.5299  loss_mask: 0.2892  loss_rpn_cls: 0.05412  loss_rpn_loc: 0.1451  time: 0.6650  data_time: 0.1199  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:46:31 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 8379  total_loss: 1.308  loss_cls: 0.3022  loss_box_reg: 0.496  loss_mask: 0.2708  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.141  time: 0.6651  data_time: 0.2294  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:46:42 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 8399  total_loss: 1.324  loss_cls: 0.2939  loss_box_reg: 0.5422  loss_mask: 0.2764  loss_rpn_cls: 0.04995  loss_rpn_loc: 0.1528  time: 0.6649  data_time: 0.1016  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:46:55 d2.utils.events]: \u001b[0m eta: 0:13:11  iter: 8419  total_loss: 1.441  loss_cls: 0.3274  loss_box_reg: 0.5428  loss_mask: 0.3036  loss_rpn_cls: 0.07492  loss_rpn_loc: 0.1816  time: 0.6649  data_time: 0.1851  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:47:08 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 8439  total_loss: 1.363  loss_cls: 0.3008  loss_box_reg: 0.5451  loss_mask: 0.2888  loss_rpn_cls: 0.06811  loss_rpn_loc: 0.1511  time: 0.6648  data_time: 0.1366  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:47:21 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 8459  total_loss: 1.425  loss_cls: 0.319  loss_box_reg: 0.5622  loss_mask: 0.3123  loss_rpn_cls: 0.07809  loss_rpn_loc: 0.1858  time: 0.6648  data_time: 0.1425  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:47:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:47:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:47:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:47:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:47:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:47:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0022 s/iter. Inference: 0.1010 s/iter. Eval: 0.0789 s/iter. Total: 0.1821 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/05 12:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0011 s/iter. Inference: 0.0932 s/iter. Eval: 0.0807 s/iter. Total: 0.1751 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 12:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0010 s/iter. Inference: 0.0914 s/iter. Eval: 0.0770 s/iter. Total: 0.1694 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 12:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0009 s/iter. Inference: 0.0912 s/iter. Eval: 0.0806 s/iter. Total: 0.1727 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 12:47:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.836859 (0.171007 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:47:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:47:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:47:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2701065293216857\n",
      "\u001b[32m[02/05 12:47:55 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 8479  total_loss: 1.367  loss_cls: 0.3164  loss_box_reg: 0.5257  loss_mask: 0.2943  loss_rpn_cls: 0.06099  loss_rpn_loc: 0.1674  time: 0.6647  data_time: 0.1323  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:48:08 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 8499  total_loss: 1.449  loss_cls: 0.3322  loss_box_reg: 0.5445  loss_mask: 0.2934  loss_rpn_cls: 0.07135  loss_rpn_loc: 0.163  time: 0.6646  data_time: 0.1656  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:48:24 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 8519  total_loss: 1.597  loss_cls: 0.3389  loss_box_reg: 0.5829  loss_mask: 0.3248  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1883  time: 0.6649  data_time: 0.3160  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:48:38 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 8539  total_loss: 1.341  loss_cls: 0.3046  loss_box_reg: 0.5197  loss_mask: 0.2729  loss_rpn_cls: 0.08146  loss_rpn_loc: 0.1499  time: 0.6650  data_time: 0.2118  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:48:50 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 8559  total_loss: 1.362  loss_cls: 0.3003  loss_box_reg: 0.5263  loss_mask: 0.2902  loss_rpn_cls: 0.07139  loss_rpn_loc: 0.1547  time: 0.6649  data_time: 0.1284  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:49:03 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 8579  total_loss: 1.357  loss_cls: 0.2868  loss_box_reg: 0.5296  loss_mask: 0.289  loss_rpn_cls: 0.07188  loss_rpn_loc: 0.1727  time: 0.6648  data_time: 0.1911  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:49:17 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 8599  total_loss: 1.416  loss_cls: 0.3089  loss_box_reg: 0.558  loss_mask: 0.3138  loss_rpn_cls: 0.06284  loss_rpn_loc: 0.1613  time: 0.6649  data_time: 0.1994  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:49:30 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 8619  total_loss: 1.433  loss_cls: 0.3322  loss_box_reg: 0.5566  loss_mask: 0.2974  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.1539  time: 0.6648  data_time: 0.1604  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:49:43 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 8639  total_loss: 1.397  loss_cls: 0.3037  loss_box_reg: 0.5483  loss_mask: 0.2945  loss_rpn_cls: 0.07295  loss_rpn_loc: 0.1588  time: 0.6649  data_time: 0.2121  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:49:58 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 8659  total_loss: 1.491  loss_cls: 0.3311  loss_box_reg: 0.5732  loss_mask: 0.3074  loss_rpn_cls: 0.08206  loss_rpn_loc: 0.1878  time: 0.6650  data_time: 0.2398  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:50:11 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 8679  total_loss: 1.449  loss_cls: 0.3212  loss_box_reg: 0.548  loss_mask: 0.2985  loss_rpn_cls: 0.09097  loss_rpn_loc: 0.1595  time: 0.6650  data_time: 0.1774  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:50:26 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 8699  total_loss: 1.365  loss_cls: 0.3087  loss_box_reg: 0.5408  loss_mask: 0.2913  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.1451  time: 0.6652  data_time: 0.2574  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:50:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:50:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:50:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:50:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:50:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:50:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0921 s/iter. Eval: 0.0712 s/iter. Total: 0.1641 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 12:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0010 s/iter. Inference: 0.0907 s/iter. Eval: 0.0820 s/iter. Total: 0.1738 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 12:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0010 s/iter. Inference: 0.0906 s/iter. Eval: 0.0802 s/iter. Total: 0.1718 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 12:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0009 s/iter. Inference: 0.0897 s/iter. Eval: 0.0837 s/iter. Total: 0.1744 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 12:50:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.074201 (0.173053 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:50:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090140 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:50:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:50:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27003292671839263\n",
      "\u001b[32m[02/05 12:51:01 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 8719  total_loss: 1.269  loss_cls: 0.2695  loss_box_reg: 0.525  loss_mask: 0.2949  loss_rpn_cls: 0.05742  loss_rpn_loc: 0.1499  time: 0.6651  data_time: 0.1653  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:51:12 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 8739  total_loss: 1.291  loss_cls: 0.3054  loss_box_reg: 0.5227  loss_mask: 0.2814  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.1366  time: 0.6649  data_time: 0.1029  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:51:27 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 8759  total_loss: 1.439  loss_cls: 0.3288  loss_box_reg: 0.5474  loss_mask: 0.2965  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.1733  time: 0.6651  data_time: 0.2804  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:51:38 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 8779  total_loss: 1.231  loss_cls: 0.2695  loss_box_reg: 0.5197  loss_mask: 0.2846  loss_rpn_cls: 0.05395  loss_rpn_loc: 0.1526  time: 0.6648  data_time: 0.0807  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:51:52 d2.utils.events]: \u001b[0m eta: 0:10:08  iter: 8799  total_loss: 1.34  loss_cls: 0.2993  loss_box_reg: 0.5324  loss_mask: 0.2892  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.1631  time: 0.6649  data_time: 0.1932  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:52:07 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 8819  total_loss: 1.419  loss_cls: 0.319  loss_box_reg: 0.5523  loss_mask: 0.2982  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.1688  time: 0.6651  data_time: 0.2647  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:52:21 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 8839  total_loss: 1.468  loss_cls: 0.3205  loss_box_reg: 0.5577  loss_mask: 0.2937  loss_rpn_cls: 0.08218  loss_rpn_loc: 0.1769  time: 0.6652  data_time: 0.2176  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:52:33 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 8859  total_loss: 1.341  loss_cls: 0.2795  loss_box_reg: 0.5502  loss_mask: 0.3019  loss_rpn_cls: 0.06531  loss_rpn_loc: 0.1593  time: 0.6651  data_time: 0.1190  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:52:48 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 8879  total_loss: 1.399  loss_cls: 0.3303  loss_box_reg: 0.5497  loss_mask: 0.2878  loss_rpn_cls: 0.08176  loss_rpn_loc: 0.181  time: 0.6652  data_time: 0.2116  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:53:03 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 8899  total_loss: 1.346  loss_cls: 0.3034  loss_box_reg: 0.5359  loss_mask: 0.2887  loss_rpn_cls: 0.07232  loss_rpn_loc: 0.1745  time: 0.6654  data_time: 0.2260  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:53:18 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 8919  total_loss: 1.39  loss_cls: 0.3142  loss_box_reg: 0.5459  loss_mask: 0.2835  loss_rpn_cls: 0.07734  loss_rpn_loc: 0.1691  time: 0.6656  data_time: 0.2687  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:53:34 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 8939  total_loss: 1.471  loss_cls: 0.3553  loss_box_reg: 0.5806  loss_mask: 0.3088  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.1844  time: 0.6659  data_time: 0.2993  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:53:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:53:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:53:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:53:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:53:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:53:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0933 s/iter. Eval: 0.0655 s/iter. Total: 0.1597 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 12:53:53 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.0921 s/iter. Eval: 0.0766 s/iter. Total: 0.1696 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 12:53:58 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0739 s/iter. Total: 0.1655 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:54:03 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0779 s/iter. Total: 0.1695 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 12:54:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.566008 (0.168672 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:54:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090526 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:54:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:54:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27165216322938196\n",
      "\u001b[32m[02/05 12:54:09 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 8959  total_loss: 1.199  loss_cls: 0.2345  loss_box_reg: 0.5046  loss_mask: 0.2898  loss_rpn_cls: 0.05302  loss_rpn_loc: 0.133  time: 0.6660  data_time: 0.1986  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:54:23 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 8979  total_loss: 1.295  loss_cls: 0.2825  loss_box_reg: 0.5011  loss_mask: 0.2802  loss_rpn_cls: 0.05764  loss_rpn_loc: 0.1334  time: 0.6660  data_time: 0.1779  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:54:35 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 8999  total_loss: 1.343  loss_cls: 0.3056  loss_box_reg: 0.5266  loss_mask: 0.28  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.1729  time: 0.6658  data_time: 0.1255  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:54:49 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 9019  total_loss: 1.404  loss_cls: 0.3294  loss_box_reg: 0.5333  loss_mask: 0.3007  loss_rpn_cls: 0.08671  loss_rpn_loc: 0.1739  time: 0.6659  data_time: 0.2123  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:55:03 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 9039  total_loss: 1.384  loss_cls: 0.3112  loss_box_reg: 0.5427  loss_mask: 0.2858  loss_rpn_cls: 0.05355  loss_rpn_loc: 0.1559  time: 0.6659  data_time: 0.1940  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:55:16 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 9059  total_loss: 1.384  loss_cls: 0.2993  loss_box_reg: 0.5509  loss_mask: 0.2995  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.1588  time: 0.6660  data_time: 0.1976  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:55:32 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 9079  total_loss: 1.44  loss_cls: 0.3295  loss_box_reg: 0.5524  loss_mask: 0.3058  loss_rpn_cls: 0.08895  loss_rpn_loc: 0.1747  time: 0.6663  data_time: 0.3342  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:55:46 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 9099  total_loss: 1.455  loss_cls: 0.3342  loss_box_reg: 0.5571  loss_mask: 0.2881  loss_rpn_cls: 0.06863  loss_rpn_loc: 0.1836  time: 0.6663  data_time: 0.1928  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:55:58 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 9119  total_loss: 1.468  loss_cls: 0.3234  loss_box_reg: 0.554  loss_mask: 0.3016  loss_rpn_cls: 0.09245  loss_rpn_loc: 0.1878  time: 0.6661  data_time: 0.1390  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:56:10 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 9139  total_loss: 1.315  loss_cls: 0.2977  loss_box_reg: 0.5306  loss_mask: 0.2938  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.1381  time: 0.6660  data_time: 0.1724  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:56:21 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 9159  total_loss: 1.321  loss_cls: 0.301  loss_box_reg: 0.5029  loss_mask: 0.2794  loss_rpn_cls: 0.06266  loss_rpn_loc: 0.1499  time: 0.6658  data_time: 0.1104  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:56:35 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 9179  total_loss: 1.362  loss_cls: 0.2958  loss_box_reg: 0.5367  loss_mask: 0.2996  loss_rpn_cls: 0.0756  loss_rpn_loc: 0.1635  time: 0.6659  data_time: 0.2093  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:56:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:56:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:56:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:56:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:56:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:56:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:56:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0925 s/iter. Eval: 0.0696 s/iter. Total: 0.1629 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 12:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0011 s/iter. Inference: 0.0885 s/iter. Eval: 0.0784 s/iter. Total: 0.1680 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 12:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0010 s/iter. Inference: 0.0871 s/iter. Eval: 0.0753 s/iter. Total: 0.1635 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 12:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0009 s/iter. Inference: 0.0872 s/iter. Eval: 0.0790 s/iter. Total: 0.1672 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 12:57:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.252356 (0.165969 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:57:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087045 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 12:57:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 12:57:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2702752450902384\n",
      "\u001b[32m[02/05 12:57:13 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 9199  total_loss: 1.415  loss_cls: 0.316  loss_box_reg: 0.5343  loss_mask: 0.3011  loss_rpn_cls: 0.08776  loss_rpn_loc: 0.1498  time: 0.6663  data_time: 0.3815  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:57:24 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 9219  total_loss: 1.368  loss_cls: 0.316  loss_box_reg: 0.5374  loss_mask: 0.2847  loss_rpn_cls: 0.06964  loss_rpn_loc: 0.1574  time: 0.6660  data_time: 0.0767  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:57:39 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 9239  total_loss: 1.385  loss_cls: 0.3137  loss_box_reg: 0.5284  loss_mask: 0.3011  loss_rpn_cls: 0.0872  loss_rpn_loc: 0.1666  time: 0.6661  data_time: 0.2524  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:57:51 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 9259  total_loss: 1.408  loss_cls: 0.3045  loss_box_reg: 0.5534  loss_mask: 0.3071  loss_rpn_cls: 0.07824  loss_rpn_loc: 0.1546  time: 0.6660  data_time: 0.1550  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:58:03 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 9279  total_loss: 1.37  loss_cls: 0.3112  loss_box_reg: 0.5402  loss_mask: 0.2942  loss_rpn_cls: 0.0718  loss_rpn_loc: 0.1785  time: 0.6658  data_time: 0.1167  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:58:15 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 9299  total_loss: 1.344  loss_cls: 0.2955  loss_box_reg: 0.5128  loss_mask: 0.2841  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.1522  time: 0.6657  data_time: 0.1475  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:58:28 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 9319  total_loss: 1.368  loss_cls: 0.2979  loss_box_reg: 0.5224  loss_mask: 0.2794  loss_rpn_cls: 0.07326  loss_rpn_loc: 0.1715  time: 0.6657  data_time: 0.1963  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:58:41 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 9339  total_loss: 1.402  loss_cls: 0.307  loss_box_reg: 0.5478  loss_mask: 0.3031  loss_rpn_cls: 0.06356  loss_rpn_loc: 0.1556  time: 0.6656  data_time: 0.1556  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:58:56 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 9359  total_loss: 1.34  loss_cls: 0.307  loss_box_reg: 0.5379  loss_mask: 0.2814  loss_rpn_cls: 0.07188  loss_rpn_loc: 0.1782  time: 0.6658  data_time: 0.2592  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:59:08 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9379  total_loss: 1.418  loss_cls: 0.3254  loss_box_reg: 0.5626  loss_mask: 0.2807  loss_rpn_cls: 0.0538  loss_rpn_loc: 0.17  time: 0.6657  data_time: 0.1607  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:59:21 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 9399  total_loss: 1.229  loss_cls: 0.2227  loss_box_reg: 0.5027  loss_mask: 0.2785  loss_rpn_cls: 0.05735  loss_rpn_loc: 0.1437  time: 0.6657  data_time: 0.1892  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:59:36 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 9419  total_loss: 1.586  loss_cls: 0.3563  loss_box_reg: 0.5725  loss_mask: 0.3017  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.1975  time: 0.6658  data_time: 0.2343  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 12:59:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:59:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 12:59:49 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 12:59:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 12:59:49 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 12:59:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 12:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0978 s/iter. Eval: 0.0680 s/iter. Total: 0.1667 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 12:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.0912 s/iter. Eval: 0.0788 s/iter. Total: 0.1710 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 13:00:02 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0009 s/iter. Inference: 0.0897 s/iter. Eval: 0.0757 s/iter. Total: 0.1663 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 13:00:07 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0009 s/iter. Inference: 0.0904 s/iter. Eval: 0.0794 s/iter. Total: 0.1707 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 13:00:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.629982 (0.169224 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:00:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089832 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:00:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:00:10 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26954750143225975\n",
      "\u001b[32m[02/05 13:00:11 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 9439  total_loss: 1.485  loss_cls: 0.3214  loss_box_reg: 0.5636  loss_mask: 0.3128  loss_rpn_cls: 0.08  loss_rpn_loc: 0.1727  time: 0.6659  data_time: 0.2128  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:00:24 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 9459  total_loss: 1.284  loss_cls: 0.2979  loss_box_reg: 0.5216  loss_mask: 0.2954  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.1384  time: 0.6659  data_time: 0.1869  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:00:37 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 9479  total_loss: 1.383  loss_cls: 0.3063  loss_box_reg: 0.5355  loss_mask: 0.306  loss_rpn_cls: 0.07658  loss_rpn_loc: 0.1684  time: 0.6658  data_time: 0.1704  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:00:49 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 9499  total_loss: 1.386  loss_cls: 0.3115  loss_box_reg: 0.5378  loss_mask: 0.2929  loss_rpn_cls: 0.07826  loss_rpn_loc: 0.1745  time: 0.6657  data_time: 0.1504  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:01:03 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 9519  total_loss: 1.522  loss_cls: 0.3314  loss_box_reg: 0.5561  loss_mask: 0.3137  loss_rpn_cls: 0.08025  loss_rpn_loc: 0.1688  time: 0.6657  data_time: 0.1874  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:01:19 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 9539  total_loss: 1.358  loss_cls: 0.3091  loss_box_reg: 0.5534  loss_mask: 0.2921  loss_rpn_cls: 0.05943  loss_rpn_loc: 0.1281  time: 0.6660  data_time: 0.3114  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:01:32 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 9559  total_loss: 1.479  loss_cls: 0.355  loss_box_reg: 0.5776  loss_mask: 0.3221  loss_rpn_cls: 0.07386  loss_rpn_loc: 0.1876  time: 0.6659  data_time: 0.1657  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:01:43 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 9579  total_loss: 1.227  loss_cls: 0.2495  loss_box_reg: 0.5254  loss_mask: 0.2836  loss_rpn_cls: 0.04357  loss_rpn_loc: 0.1249  time: 0.6657  data_time: 0.1010  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:01:54 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 9599  total_loss: 1.415  loss_cls: 0.31  loss_box_reg: 0.5519  loss_mask: 0.291  loss_rpn_cls: 0.07052  loss_rpn_loc: 0.1685  time: 0.6655  data_time: 0.1206  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:02:09 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 9619  total_loss: 1.428  loss_cls: 0.308  loss_box_reg: 0.5598  loss_mask: 0.3055  loss_rpn_cls: 0.08716  loss_rpn_loc: 0.1719  time: 0.6657  data_time: 0.2624  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:02:21 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 9639  total_loss: 1.365  loss_cls: 0.3236  loss_box_reg: 0.5284  loss_mask: 0.2812  loss_rpn_cls: 0.08166  loss_rpn_loc: 0.1678  time: 0.6655  data_time: 0.1197  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:02:36 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 9659  total_loss: 1.442  loss_cls: 0.327  loss_box_reg: 0.5317  loss_mask: 0.2944  loss_rpn_cls: 0.0823  loss_rpn_loc: 0.1656  time: 0.6657  data_time: 0.2860  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:02:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:02:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:02:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:02:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:02:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:02:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0940 s/iter. Eval: 0.0665 s/iter. Total: 0.1613 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 13:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0784 s/iter. Total: 0.1680 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 13:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0009 s/iter. Inference: 0.0873 s/iter. Eval: 0.0753 s/iter. Total: 0.1635 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 13:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0793 s/iter. Total: 0.1675 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 13:03:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.320944 (0.166560 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:03:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087174 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:03:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:03:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26968728582032697\n",
      "\u001b[32m[02/05 13:03:12 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 9679  total_loss: 1.332  loss_cls: 0.291  loss_box_reg: 0.532  loss_mask: 0.2839  loss_rpn_cls: 0.07123  loss_rpn_loc: 0.1537  time: 0.6659  data_time: 0.2805  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:03:26 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 9699  total_loss: 1.365  loss_cls: 0.3269  loss_box_reg: 0.5454  loss_mask: 0.2893  loss_rpn_cls: 0.07169  loss_rpn_loc: 0.1655  time: 0.6660  data_time: 0.2280  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:03:41 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 9719  total_loss: 1.435  loss_cls: 0.3132  loss_box_reg: 0.54  loss_mask: 0.3079  loss_rpn_cls: 0.08832  loss_rpn_loc: 0.1789  time: 0.6661  data_time: 0.2617  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:03:55 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 9739  total_loss: 1.417  loss_cls: 0.3263  loss_box_reg: 0.5571  loss_mask: 0.2962  loss_rpn_cls: 0.09202  loss_rpn_loc: 0.1808  time: 0.6662  data_time: 0.2134  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:04:09 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 9759  total_loss: 1.411  loss_cls: 0.3059  loss_box_reg: 0.5377  loss_mask: 0.3034  loss_rpn_cls: 0.06388  loss_rpn_loc: 0.1602  time: 0.6662  data_time: 0.2019  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:04:25 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 9779  total_loss: 1.447  loss_cls: 0.3036  loss_box_reg: 0.5314  loss_mask: 0.3067  loss_rpn_cls: 0.08904  loss_rpn_loc: 0.1935  time: 0.6665  data_time: 0.3177  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:04:38 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 9799  total_loss: 1.391  loss_cls: 0.3081  loss_box_reg: 0.5441  loss_mask: 0.2818  loss_rpn_cls: 0.07257  loss_rpn_loc: 0.1737  time: 0.6664  data_time: 0.1683  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:04:51 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 9819  total_loss: 1.385  loss_cls: 0.3081  loss_box_reg: 0.5303  loss_mask: 0.308  loss_rpn_cls: 0.06898  loss_rpn_loc: 0.1725  time: 0.6664  data_time: 0.1830  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:05:05 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 9839  total_loss: 1.325  loss_cls: 0.288  loss_box_reg: 0.5299  loss_mask: 0.2961  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.1651  time: 0.6665  data_time: 0.2762  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:05:16 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 9859  total_loss: 1.354  loss_cls: 0.2895  loss_box_reg: 0.5282  loss_mask: 0.2834  loss_rpn_cls: 0.07127  loss_rpn_loc: 0.165  time: 0.6663  data_time: 0.0730  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:05:28 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 9879  total_loss: 1.254  loss_cls: 0.2527  loss_box_reg: 0.5196  loss_mask: 0.2841  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.1437  time: 0.6662  data_time: 0.1566  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:05:41 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 9899  total_loss: 1.356  loss_cls: 0.3074  loss_box_reg: 0.5392  loss_mask: 0.2842  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.1469  time: 0.6661  data_time: 0.1604  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:05:53 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9919  total_loss: 1.354  loss_cls: 0.3059  loss_box_reg: 0.5205  loss_mask: 0.3036  loss_rpn_cls: 0.07229  loss_rpn_loc: 0.1672  time: 0.6660  data_time: 0.1365  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:05:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:05:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:05:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:05:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:05:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:05:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0903 s/iter. Eval: 0.0701 s/iter. Total: 0.1612 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 13:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0011 s/iter. Inference: 0.0885 s/iter. Eval: 0.0777 s/iter. Total: 0.1674 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 13:06:07 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0013 s/iter. Inference: 0.0870 s/iter. Eval: 0.0750 s/iter. Total: 0.1634 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 13:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0011 s/iter. Inference: 0.0870 s/iter. Eval: 0.0790 s/iter. Total: 0.1672 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 13:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.276093 (0.166173 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:06:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086846 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:06:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:06:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2722455032027363\n",
      "\u001b[32m[02/05 13:06:26 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 9939  total_loss: 1.43  loss_cls: 0.3299  loss_box_reg: 0.5767  loss_mask: 0.3205  loss_rpn_cls: 0.08717  loss_rpn_loc: 0.1777  time: 0.6658  data_time: 0.1132  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:06:38 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9959  total_loss: 1.486  loss_cls: 0.3188  loss_box_reg: 0.571  loss_mask: 0.3048  loss_rpn_cls: 0.07257  loss_rpn_loc: 0.1877  time: 0.6657  data_time: 0.1517  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:06:52 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 9979  total_loss: 1.387  loss_cls: 0.3038  loss_box_reg: 0.5519  loss_mask: 0.3021  loss_rpn_cls: 0.0779  loss_rpn_loc: 0.1746  time: 0.6658  data_time: 0.2378  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:07:08 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.435  loss_cls: 0.3308  loss_box_reg: 0.5607  loss_mask: 0.2949  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.1877  time: 0.6660  data_time: 0.3068  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:07:08 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:50:58 (0.6660 s / it)\n",
      "\u001b[32m[02/05 13:07:08 d2.engine.hooks]: \u001b[0mTotal training time: 2:05:03 (0:14:04 on hooks)\n",
      "\u001b[32m[02/05 13:07:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:07:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:07:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:07:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:07:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:07:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0898 s/iter. Eval: 0.0742 s/iter. Total: 0.1649 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 13:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0010 s/iter. Inference: 0.0898 s/iter. Eval: 0.0883 s/iter. Total: 0.1791 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 13:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0009 s/iter. Inference: 0.0877 s/iter. Eval: 0.0815 s/iter. Total: 0.1701 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 13:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0009 s/iter. Inference: 0.0876 s/iter. Eval: 0.0833 s/iter. Total: 0.1718 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 13:07:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.663351 (0.169512 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:07:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087264 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:07:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:07:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2695389737816085\n"
     ]
    }
   ],
   "source": [
    "# changing only the anchor generator aspect ratios\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 1.0, 3.0]]\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6d1f438c-3c3b-45e5-830d-bad7c8053341",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 13:41:35 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 13:41:36 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 13:41:37 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/05 13:41:37 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 13:41:38 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/05 13:41:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/05 13:41:38 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/05 13:41:38 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:41:38 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 13:41:38 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/05 13:41:54 d2.utils.events]: \u001b[0m eta: 1:16:35  iter: 19  total_loss: 2.925  loss_cls: 1.395  loss_box_reg: 0.2373  loss_mask: 0.6913  loss_rpn_cls: 0.3704  loss_rpn_loc: 0.1941  time: 0.6930  data_time: 0.3306  lr: 9.9905e-06  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:42:06 d2.utils.events]: \u001b[0m eta: 1:15:46  iter: 39  total_loss: 2.633  loss_cls: 1.239  loss_box_reg: 0.2358  loss_mask: 0.687  loss_rpn_cls: 0.3196  loss_rpn_loc: 0.1787  time: 0.6595  data_time: 0.1953  lr: 1.998e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:42:18 d2.utils.events]: \u001b[0m eta: 1:15:39  iter: 59  total_loss: 2.387  loss_cls: 0.9911  loss_box_reg: 0.3298  loss_mask: 0.6743  loss_rpn_cls: 0.2766  loss_rpn_loc: 0.16  time: 0.6251  data_time: 0.1238  lr: 2.997e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:42:31 d2.utils.events]: \u001b[0m eta: 1:15:40  iter: 79  total_loss: 2.164  loss_cls: 0.7837  loss_box_reg: 0.3739  loss_mask: 0.6556  loss_rpn_cls: 0.2705  loss_rpn_loc: 0.1717  time: 0.6424  data_time: 0.2422  lr: 3.9961e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:42:46 d2.utils.events]: \u001b[0m eta: 1:16:11  iter: 99  total_loss: 2.166  loss_cls: 0.6774  loss_box_reg: 0.4146  loss_mask: 0.6348  loss_rpn_cls: 0.2285  loss_rpn_loc: 0.1619  time: 0.6548  data_time: 0.2347  lr: 4.9951e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:43:03 d2.utils.events]: \u001b[0m eta: 1:17:41  iter: 119  total_loss: 2.051  loss_cls: 0.624  loss_box_reg: 0.4574  loss_mask: 0.614  loss_rpn_cls: 0.2246  loss_rpn_loc: 0.1646  time: 0.6961  data_time: 0.4092  lr: 5.9941e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:43:15 d2.utils.events]: \u001b[0m eta: 1:18:23  iter: 139  total_loss: 2.174  loss_cls: 0.6869  loss_box_reg: 0.659  loss_mask: 0.5662  loss_rpn_cls: 0.1429  loss_rpn_loc: 0.1167  time: 0.6786  data_time: 0.0880  lr: 6.993e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:43:29 d2.utils.events]: \u001b[0m eta: 1:19:14  iter: 159  total_loss: 2.291  loss_cls: 0.7021  loss_box_reg: 0.6835  loss_mask: 0.5532  loss_rpn_cls: 0.1699  loss_rpn_loc: 0.1649  time: 0.6785  data_time: 0.1966  lr: 7.9921e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:43:43 d2.utils.events]: \u001b[0m eta: 1:19:37  iter: 179  total_loss: 2.321  loss_cls: 0.6841  loss_box_reg: 0.7036  loss_mask: 0.5208  loss_rpn_cls: 0.1793  loss_rpn_loc: 0.176  time: 0.6807  data_time: 0.2078  lr: 8.991e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:43:56 d2.utils.events]: \u001b[0m eta: 1:19:40  iter: 199  total_loss: 2.164  loss_cls: 0.6272  loss_box_reg: 0.7653  loss_mask: 0.4746  loss_rpn_cls: 0.1557  loss_rpn_loc: 0.1582  time: 0.6779  data_time: 0.1825  lr: 9.9901e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:44:08 d2.utils.events]: \u001b[0m eta: 1:20:17  iter: 219  total_loss: 2.069  loss_cls: 0.5948  loss_box_reg: 0.7639  loss_mask: 0.4423  loss_rpn_cls: 0.1258  loss_rpn_loc: 0.1326  time: 0.6743  data_time: 0.1624  lr: 0.00010989  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:44:20 d2.utils.events]: \u001b[0m eta: 1:19:21  iter: 239  total_loss: 1.849  loss_cls: 0.4349  loss_box_reg: 0.8124  loss_mask: 0.4278  loss_rpn_cls: 0.08161  loss_rpn_loc: 0.07348  time: 0.6662  data_time: 0.1179  lr: 0.00011988  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:44:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:44:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:44:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:44:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:44:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:44:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0876 s/iter. Eval: 0.0154 s/iter. Total: 0.1036 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 13:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0007 s/iter. Inference: 0.0859 s/iter. Eval: 0.0153 s/iter. Total: 0.1019 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 13:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0007 s/iter. Inference: 0.0850 s/iter. Eval: 0.0134 s/iter. Total: 0.0992 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 13:44:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.504175 (0.099174 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:44:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084919 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:44:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:44:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.09723204579400604\n",
      "\u001b[32m[02/05 13:44:46 d2.utils.events]: \u001b[0m eta: 1:18:55  iter: 259  total_loss: 1.913  loss_cls: 0.4851  loss_box_reg: 0.7969  loss_mask: 0.3896  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.0792  time: 0.6666  data_time: 0.2047  lr: 0.00012987  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:44:58 d2.utils.events]: \u001b[0m eta: 1:18:39  iter: 279  total_loss: 1.836  loss_cls: 0.4758  loss_box_reg: 0.7944  loss_mask: 0.3548  loss_rpn_cls: 0.07877  loss_rpn_loc: 0.0849  time: 0.6618  data_time: 0.1459  lr: 0.00013986  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:45:13 d2.utils.events]: \u001b[0m eta: 1:18:26  iter: 299  total_loss: 1.802  loss_cls: 0.4544  loss_box_reg: 0.7588  loss_mask: 0.3539  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.1076  time: 0.6660  data_time: 0.2523  lr: 0.00014985  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:45:24 d2.utils.events]: \u001b[0m eta: 1:18:07  iter: 319  total_loss: 1.64  loss_cls: 0.4113  loss_box_reg: 0.7536  loss_mask: 0.3207  loss_rpn_cls: 0.06746  loss_rpn_loc: 0.08871  time: 0.6613  data_time: 0.1265  lr: 0.00015984  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:45:36 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 339  total_loss: 1.718  loss_cls: 0.4105  loss_box_reg: 0.6756  loss_mask: 0.3266  loss_rpn_cls: 0.1262  loss_rpn_loc: 0.155  time: 0.6557  data_time: 0.1013  lr: 0.00016983  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:45:48 d2.utils.events]: \u001b[0m eta: 1:17:48  iter: 359  total_loss: 1.682  loss_cls: 0.4181  loss_box_reg: 0.6663  loss_mask: 0.3187  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.1122  time: 0.6534  data_time: 0.1515  lr: 0.00017982  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:46:02 d2.utils.events]: \u001b[0m eta: 1:17:57  iter: 379  total_loss: 1.661  loss_cls: 0.4144  loss_box_reg: 0.6709  loss_mask: 0.3286  loss_rpn_cls: 0.1205  loss_rpn_loc: 0.1497  time: 0.6567  data_time: 0.2292  lr: 0.00018981  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:46:16 d2.utils.events]: \u001b[0m eta: 1:17:53  iter: 399  total_loss: 1.622  loss_cls: 0.4114  loss_box_reg: 0.6958  loss_mask: 0.3159  loss_rpn_cls: 0.1137  loss_rpn_loc: 0.1411  time: 0.6571  data_time: 0.1893  lr: 0.0001998  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:46:30 d2.utils.events]: \u001b[0m eta: 1:18:02  iter: 419  total_loss: 1.95  loss_cls: 0.5133  loss_box_reg: 0.7064  loss_mask: 0.3259  loss_rpn_cls: 0.1371  loss_rpn_loc: 0.1752  time: 0.6591  data_time: 0.2219  lr: 0.00020979  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:46:42 d2.utils.events]: \u001b[0m eta: 1:18:02  iter: 439  total_loss: 1.783  loss_cls: 0.4652  loss_box_reg: 0.7283  loss_mask: 0.3178  loss_rpn_cls: 0.11  loss_rpn_loc: 0.1487  time: 0.6570  data_time: 0.1335  lr: 0.00021978  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:46:55 d2.utils.events]: \u001b[0m eta: 1:17:52  iter: 459  total_loss: 1.628  loss_cls: 0.3959  loss_box_reg: 0.6683  loss_mask: 0.313  loss_rpn_cls: 0.09115  loss_rpn_loc: 0.125  time: 0.6564  data_time: 0.1681  lr: 0.00022977  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:47:09 d2.utils.events]: \u001b[0m eta: 1:17:41  iter: 479  total_loss: 1.55  loss_cls: 0.3864  loss_box_reg: 0.6594  loss_mask: 0.316  loss_rpn_cls: 0.07879  loss_rpn_loc: 0.1056  time: 0.6578  data_time: 0.2215  lr: 0.00023976  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:47:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:47:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:47:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:47:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:47:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:47:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0875 s/iter. Eval: 0.0598 s/iter. Total: 0.1479 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 13:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0886 s/iter. Eval: 0.0714 s/iter. Total: 0.1608 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 13:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0885 s/iter. Eval: 0.0724 s/iter. Total: 0.1617 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 13:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0752 s/iter. Total: 0.1649 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 13:47:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.065871 (0.164361 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:47:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088872 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:47:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:47:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2150988283703736\n",
      "\u001b[32m[02/05 13:47:42 d2.utils.events]: \u001b[0m eta: 1:17:31  iter: 499  total_loss: 1.546  loss_cls: 0.3768  loss_box_reg: 0.6675  loss_mask: 0.3286  loss_rpn_cls: 0.07071  loss_rpn_loc: 0.0965  time: 0.6577  data_time: 0.1939  lr: 0.00024975  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:47:58 d2.utils.events]: \u001b[0m eta: 1:17:26  iter: 519  total_loss: 1.592  loss_cls: 0.3921  loss_box_reg: 0.6638  loss_mask: 0.3105  loss_rpn_cls: 0.09544  loss_rpn_loc: 0.127  time: 0.6615  data_time: 0.2670  lr: 0.00025974  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:48:08 d2.utils.events]: \u001b[0m eta: 1:17:06  iter: 539  total_loss: 1.397  loss_cls: 0.3483  loss_box_reg: 0.609  loss_mask: 0.2955  loss_rpn_cls: 0.04563  loss_rpn_loc: 0.05007  time: 0.6561  data_time: 0.0627  lr: 0.00026973  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:48:21 d2.utils.events]: \u001b[0m eta: 1:17:03  iter: 559  total_loss: 1.597  loss_cls: 0.4095  loss_box_reg: 0.6557  loss_mask: 0.3141  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.1159  time: 0.6567  data_time: 0.2024  lr: 0.00027972  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:48:34 d2.utils.events]: \u001b[0m eta: 1:17:04  iter: 579  total_loss: 1.561  loss_cls: 0.4238  loss_box_reg: 0.6398  loss_mask: 0.3056  loss_rpn_cls: 0.09777  loss_rpn_loc: 0.1214  time: 0.6565  data_time: 0.1693  lr: 0.00028971  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:48:47 d2.utils.events]: \u001b[0m eta: 1:16:53  iter: 599  total_loss: 1.477  loss_cls: 0.3833  loss_box_reg: 0.608  loss_mask: 0.3052  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.07237  time: 0.6561  data_time: 0.1820  lr: 0.0002997  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:48:59 d2.utils.events]: \u001b[0m eta: 1:16:37  iter: 619  total_loss: 1.507  loss_cls: 0.3896  loss_box_reg: 0.6221  loss_mask: 0.3174  loss_rpn_cls: 0.07795  loss_rpn_loc: 0.08091  time: 0.6543  data_time: 0.1308  lr: 0.00030969  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:49:13 d2.utils.events]: \u001b[0m eta: 1:16:22  iter: 639  total_loss: 1.409  loss_cls: 0.3577  loss_box_reg: 0.5955  loss_mask: 0.3068  loss_rpn_cls: 0.07689  loss_rpn_loc: 0.09952  time: 0.6546  data_time: 0.2040  lr: 0.00031968  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:49:27 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 659  total_loss: 1.468  loss_cls: 0.3946  loss_box_reg: 0.6227  loss_mask: 0.2982  loss_rpn_cls: 0.07225  loss_rpn_loc: 0.114  time: 0.6564  data_time: 0.2245  lr: 0.00032967  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:49:40 d2.utils.events]: \u001b[0m eta: 1:16:03  iter: 679  total_loss: 1.677  loss_cls: 0.4667  loss_box_reg: 0.6317  loss_mask: 0.3234  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.1232  time: 0.6559  data_time: 0.1693  lr: 0.00033966  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:49:53 d2.utils.events]: \u001b[0m eta: 1:15:57  iter: 699  total_loss: 1.492  loss_cls: 0.3839  loss_box_reg: 0.6136  loss_mask: 0.309  loss_rpn_cls: 0.09465  loss_rpn_loc: 0.1299  time: 0.6565  data_time: 0.1971  lr: 0.00034965  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:50:09 d2.utils.events]: \u001b[0m eta: 1:15:55  iter: 719  total_loss: 1.451  loss_cls: 0.3766  loss_box_reg: 0.5838  loss_mask: 0.3068  loss_rpn_cls: 0.08431  loss_rpn_loc: 0.1237  time: 0.6595  data_time: 0.2916  lr: 0.00035964  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:50:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:50:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:50:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:50:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:50:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:50:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0865 s/iter. Eval: 0.0508 s/iter. Total: 0.1379 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 13:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0877 s/iter. Eval: 0.0666 s/iter. Total: 0.1551 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 13:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0007 s/iter. Inference: 0.0879 s/iter. Eval: 0.0696 s/iter. Total: 0.1582 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 13:50:30 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0723 s/iter. Total: 0.1611 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 13:50:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.654394 (0.160814 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:50:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087962 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:50:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:50:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23742978273018245\n",
      "\u001b[32m[02/05 13:50:41 d2.utils.events]: \u001b[0m eta: 1:15:44  iter: 739  total_loss: 1.456  loss_cls: 0.3756  loss_box_reg: 0.5995  loss_mask: 0.3059  loss_rpn_cls: 0.08746  loss_rpn_loc: 0.08832  time: 0.6581  data_time: 0.1377  lr: 0.00036963  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:50:54 d2.utils.events]: \u001b[0m eta: 1:15:35  iter: 759  total_loss: 1.518  loss_cls: 0.3994  loss_box_reg: 0.6139  loss_mask: 0.3128  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.1259  time: 0.6579  data_time: 0.1757  lr: 0.00037962  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:51:06 d2.utils.events]: \u001b[0m eta: 1:15:18  iter: 779  total_loss: 1.408  loss_cls: 0.3538  loss_box_reg: 0.5959  loss_mask: 0.2983  loss_rpn_cls: 0.05882  loss_rpn_loc: 0.0806  time: 0.6561  data_time: 0.1213  lr: 0.00038961  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:51:18 d2.utils.events]: \u001b[0m eta: 1:15:12  iter: 799  total_loss: 1.564  loss_cls: 0.4057  loss_box_reg: 0.6192  loss_mask: 0.3114  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.08907  time: 0.6551  data_time: 0.1346  lr: 0.0003996  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:51:31 d2.utils.events]: \u001b[0m eta: 1:15:05  iter: 819  total_loss: 1.524  loss_cls: 0.4016  loss_box_reg: 0.5836  loss_mask: 0.293  loss_rpn_cls: 0.07898  loss_rpn_loc: 0.1238  time: 0.6546  data_time: 0.1633  lr: 0.00040959  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:51:43 d2.utils.events]: \u001b[0m eta: 1:14:45  iter: 839  total_loss: 1.415  loss_cls: 0.3655  loss_box_reg: 0.5778  loss_mask: 0.2925  loss_rpn_cls: 0.06152  loss_rpn_loc: 0.08037  time: 0.6534  data_time: 0.1495  lr: 0.00041958  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:51:57 d2.utils.events]: \u001b[0m eta: 1:14:35  iter: 859  total_loss: 1.501  loss_cls: 0.3759  loss_box_reg: 0.6191  loss_mask: 0.3054  loss_rpn_cls: 0.06959  loss_rpn_loc: 0.105  time: 0.6552  data_time: 0.2687  lr: 0.00042957  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:52:12 d2.utils.events]: \u001b[0m eta: 1:14:34  iter: 879  total_loss: 1.506  loss_cls: 0.3966  loss_box_reg: 0.5935  loss_mask: 0.328  loss_rpn_cls: 0.09167  loss_rpn_loc: 0.1255  time: 0.6570  data_time: 0.2588  lr: 0.00043956  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:52:24 d2.utils.events]: \u001b[0m eta: 1:14:26  iter: 899  total_loss: 1.431  loss_cls: 0.3656  loss_box_reg: 0.5839  loss_mask: 0.2933  loss_rpn_cls: 0.05347  loss_rpn_loc: 0.09033  time: 0.6556  data_time: 0.1213  lr: 0.00044955  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:52:36 d2.utils.events]: \u001b[0m eta: 1:14:16  iter: 919  total_loss: 1.548  loss_cls: 0.39  loss_box_reg: 0.6155  loss_mask: 0.3169  loss_rpn_cls: 0.06999  loss_rpn_loc: 0.09698  time: 0.6548  data_time: 0.1497  lr: 0.00045954  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:52:51 d2.utils.events]: \u001b[0m eta: 1:14:09  iter: 939  total_loss: 1.438  loss_cls: 0.3574  loss_box_reg: 0.5853  loss_mask: 0.306  loss_rpn_cls: 0.06816  loss_rpn_loc: 0.0981  time: 0.6560  data_time: 0.2377  lr: 0.00046953  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:53:02 d2.utils.events]: \u001b[0m eta: 1:13:56  iter: 959  total_loss: 1.429  loss_cls: 0.3622  loss_box_reg: 0.5712  loss_mask: 0.3005  loss_rpn_cls: 0.04962  loss_rpn_loc: 0.08901  time: 0.6541  data_time: 0.1010  lr: 0.00047952  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:53:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:53:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:53:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:53:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:53:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:53:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:53:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0857 s/iter. Eval: 0.0548 s/iter. Total: 0.1411 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 13:53:15 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0688 s/iter. Total: 0.1565 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 13:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0711 s/iter. Total: 0.1591 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 13:53:25 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0733 s/iter. Total: 0.1616 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 13:53:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.719312 (0.161373 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:53:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087414 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:53:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:53:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24215677005743275\n",
      "\u001b[32m[02/05 13:53:36 d2.utils.events]: \u001b[0m eta: 1:13:47  iter: 979  total_loss: 1.417  loss_cls: 0.3775  loss_box_reg: 0.5866  loss_mask: 0.3118  loss_rpn_cls: 0.08533  loss_rpn_loc: 0.1181  time: 0.6553  data_time: 0.2422  lr: 0.00048951  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:53:49 d2.utils.events]: \u001b[0m eta: 1:13:40  iter: 999  total_loss: 1.473  loss_cls: 0.4254  loss_box_reg: 0.6089  loss_mask: 0.307  loss_rpn_cls: 0.05828  loss_rpn_loc: 0.08852  time: 0.6548  data_time: 0.1433  lr: 0.0004995  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:54:00 d2.utils.events]: \u001b[0m eta: 1:13:27  iter: 1019  total_loss: 1.241  loss_cls: 0.3363  loss_box_reg: 0.5595  loss_mask: 0.2766  loss_rpn_cls: 0.04036  loss_rpn_loc: 0.0565  time: 0.6527  data_time: 0.0975  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:54:11 d2.utils.events]: \u001b[0m eta: 1:13:20  iter: 1039  total_loss: 1.411  loss_cls: 0.3586  loss_box_reg: 0.6023  loss_mask: 0.3068  loss_rpn_cls: 0.05722  loss_rpn_loc: 0.07452  time: 0.6511  data_time: 0.1011  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:54:24 d2.utils.events]: \u001b[0m eta: 1:13:13  iter: 1059  total_loss: 1.361  loss_cls: 0.3636  loss_box_reg: 0.5766  loss_mask: 0.2957  loss_rpn_cls: 0.05791  loss_rpn_loc: 0.07584  time: 0.6508  data_time: 0.1780  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:54:37 d2.utils.events]: \u001b[0m eta: 1:13:01  iter: 1079  total_loss: 1.428  loss_cls: 0.3452  loss_box_reg: 0.5843  loss_mask: 0.2944  loss_rpn_cls: 0.06984  loss_rpn_loc: 0.1013  time: 0.6503  data_time: 0.1558  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:54:49 d2.utils.events]: \u001b[0m eta: 1:12:51  iter: 1099  total_loss: 1.542  loss_cls: 0.3911  loss_box_reg: 0.582  loss_mask: 0.327  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.1266  time: 0.6500  data_time: 0.1682  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:55:05 d2.utils.events]: \u001b[0m eta: 1:12:41  iter: 1119  total_loss: 1.445  loss_cls: 0.3621  loss_box_reg: 0.588  loss_mask: 0.3068  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.08804  time: 0.6527  data_time: 0.3163  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:55:17 d2.utils.events]: \u001b[0m eta: 1:12:30  iter: 1139  total_loss: 1.417  loss_cls: 0.3687  loss_box_reg: 0.5858  loss_mask: 0.3032  loss_rpn_cls: 0.0357  loss_rpn_loc: 0.07078  time: 0.6516  data_time: 0.1225  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:55:31 d2.utils.events]: \u001b[0m eta: 1:12:20  iter: 1159  total_loss: 1.499  loss_cls: 0.3914  loss_box_reg: 0.5724  loss_mask: 0.3149  loss_rpn_cls: 0.05945  loss_rpn_loc: 0.09851  time: 0.6524  data_time: 0.2273  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:55:45 d2.utils.events]: \u001b[0m eta: 1:12:05  iter: 1179  total_loss: 1.407  loss_cls: 0.3713  loss_box_reg: 0.6076  loss_mask: 0.3021  loss_rpn_cls: 0.04805  loss_rpn_loc: 0.1124  time: 0.6530  data_time: 0.2144  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:56:00 d2.utils.events]: \u001b[0m eta: 1:12:00  iter: 1199  total_loss: 1.396  loss_cls: 0.3716  loss_box_reg: 0.5829  loss_mask: 0.3055  loss_rpn_cls: 0.06599  loss_rpn_loc: 0.1018  time: 0.6551  data_time: 0.2858  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:56:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:56:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:56:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:56:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:56:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:56:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0856 s/iter. Eval: 0.0530 s/iter. Total: 0.1392 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 13:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0868 s/iter. Eval: 0.0686 s/iter. Total: 0.1561 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 13:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0710 s/iter. Total: 0.1588 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 13:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0738 s/iter. Total: 0.1619 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 13:56:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.743327 (0.161580 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:56:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087231 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:56:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:56:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25271902981398386\n",
      "\u001b[32m[02/05 13:56:35 d2.utils.events]: \u001b[0m eta: 1:11:50  iter: 1219  total_loss: 1.455  loss_cls: 0.3612  loss_box_reg: 0.6014  loss_mask: 0.3128  loss_rpn_cls: 0.06254  loss_rpn_loc: 0.1128  time: 0.6563  data_time: 0.2485  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:56:47 d2.utils.events]: \u001b[0m eta: 1:11:42  iter: 1239  total_loss: 1.416  loss_cls: 0.367  loss_box_reg: 0.5715  loss_mask: 0.2958  loss_rpn_cls: 0.0439  loss_rpn_loc: 0.09002  time: 0.6549  data_time: 0.0950  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:57:01 d2.utils.events]: \u001b[0m eta: 1:11:45  iter: 1259  total_loss: 1.403  loss_cls: 0.3732  loss_box_reg: 0.57  loss_mask: 0.2882  loss_rpn_cls: 0.08029  loss_rpn_loc: 0.1142  time: 0.6561  data_time: 0.2448  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:57:15 d2.utils.events]: \u001b[0m eta: 1:11:32  iter: 1279  total_loss: 1.312  loss_cls: 0.3018  loss_box_reg: 0.5484  loss_mask: 0.2854  loss_rpn_cls: 0.0435  loss_rpn_loc: 0.05009  time: 0.6568  data_time: 0.2356  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:57:29 d2.utils.events]: \u001b[0m eta: 1:11:20  iter: 1299  total_loss: 1.316  loss_cls: 0.3407  loss_box_reg: 0.5796  loss_mask: 0.3013  loss_rpn_cls: 0.05407  loss_rpn_loc: 0.05453  time: 0.6569  data_time: 0.1900  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:57:43 d2.utils.events]: \u001b[0m eta: 1:11:17  iter: 1319  total_loss: 1.488  loss_cls: 0.3726  loss_box_reg: 0.5934  loss_mask: 0.3291  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.1129  time: 0.6575  data_time: 0.2311  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:57:58 d2.utils.events]: \u001b[0m eta: 1:11:07  iter: 1339  total_loss: 1.444  loss_cls: 0.383  loss_box_reg: 0.5693  loss_mask: 0.3067  loss_rpn_cls: 0.07124  loss_rpn_loc: 0.1113  time: 0.6589  data_time: 0.2804  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:58:12 d2.utils.events]: \u001b[0m eta: 1:11:05  iter: 1359  total_loss: 1.427  loss_cls: 0.3919  loss_box_reg: 0.5799  loss_mask: 0.3122  loss_rpn_cls: 0.07299  loss_rpn_loc: 0.1106  time: 0.6597  data_time: 0.2367  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:58:22 d2.utils.events]: \u001b[0m eta: 1:10:41  iter: 1379  total_loss: 1.288  loss_cls: 0.325  loss_box_reg: 0.5752  loss_mask: 0.2954  loss_rpn_cls: 0.03958  loss_rpn_loc: 0.05812  time: 0.6577  data_time: 0.0693  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:58:35 d2.utils.events]: \u001b[0m eta: 1:10:36  iter: 1399  total_loss: 1.546  loss_cls: 0.4075  loss_box_reg: 0.6188  loss_mask: 0.3345  loss_rpn_cls: 0.06549  loss_rpn_loc: 0.1049  time: 0.6572  data_time: 0.1551  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:58:49 d2.utils.events]: \u001b[0m eta: 1:10:15  iter: 1419  total_loss: 1.421  loss_cls: 0.3719  loss_box_reg: 0.5523  loss_mask: 0.3034  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.0987  time: 0.6576  data_time: 0.2328  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:59:01 d2.utils.events]: \u001b[0m eta: 1:10:03  iter: 1439  total_loss: 1.417  loss_cls: 0.3626  loss_box_reg: 0.5936  loss_mask: 0.3075  loss_rpn_cls: 0.06138  loss_rpn_loc: 0.1009  time: 0.6571  data_time: 0.1486  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:59:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:59:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 13:59:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 13:59:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 13:59:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 13:59:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 13:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0862 s/iter. Eval: 0.0553 s/iter. Total: 0.1421 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 13:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0875 s/iter. Eval: 0.0701 s/iter. Total: 0.1584 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 13:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0717 s/iter. Total: 0.1602 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 13:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0754 s/iter. Total: 0.1644 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 13:59:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.949417 (0.163357 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:59:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087948 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 13:59:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 13:59:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2592427794115303\n",
      "\u001b[32m[02/05 13:59:34 d2.utils.events]: \u001b[0m eta: 1:09:52  iter: 1459  total_loss: 1.483  loss_cls: 0.389  loss_box_reg: 0.5693  loss_mask: 0.3011  loss_rpn_cls: 0.07995  loss_rpn_loc: 0.1068  time: 0.6569  data_time: 0.1767  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 13:59:49 d2.utils.events]: \u001b[0m eta: 1:09:44  iter: 1479  total_loss: 1.44  loss_cls: 0.376  loss_box_reg: 0.5713  loss_mask: 0.2926  loss_rpn_cls: 0.08072  loss_rpn_loc: 0.1095  time: 0.6580  data_time: 0.2589  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:00:01 d2.utils.events]: \u001b[0m eta: 1:09:32  iter: 1499  total_loss: 1.327  loss_cls: 0.3404  loss_box_reg: 0.5614  loss_mask: 0.2888  loss_rpn_cls: 0.04318  loss_rpn_loc: 0.07106  time: 0.6568  data_time: 0.1226  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:00:13 d2.utils.events]: \u001b[0m eta: 1:09:22  iter: 1519  total_loss: 1.405  loss_cls: 0.3801  loss_box_reg: 0.5728  loss_mask: 0.2994  loss_rpn_cls: 0.06073  loss_rpn_loc: 0.104  time: 0.6567  data_time: 0.1544  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:00:27 d2.utils.events]: \u001b[0m eta: 1:09:15  iter: 1539  total_loss: 1.352  loss_cls: 0.333  loss_box_reg: 0.5911  loss_mask: 0.3138  loss_rpn_cls: 0.05354  loss_rpn_loc: 0.06364  time: 0.6567  data_time: 0.1943  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:00:38 d2.utils.events]: \u001b[0m eta: 1:08:58  iter: 1559  total_loss: 1.361  loss_cls: 0.3465  loss_box_reg: 0.5625  loss_mask: 0.2777  loss_rpn_cls: 0.0546  loss_rpn_loc: 0.09228  time: 0.6558  data_time: 0.1261  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:00:50 d2.utils.events]: \u001b[0m eta: 1:08:38  iter: 1579  total_loss: 1.423  loss_cls: 0.3699  loss_box_reg: 0.5931  loss_mask: 0.3196  loss_rpn_cls: 0.06149  loss_rpn_loc: 0.108  time: 0.6551  data_time: 0.1521  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:01:03 d2.utils.events]: \u001b[0m eta: 1:08:28  iter: 1599  total_loss: 1.267  loss_cls: 0.33  loss_box_reg: 0.5759  loss_mask: 0.2844  loss_rpn_cls: 0.04806  loss_rpn_loc: 0.0588  time: 0.6550  data_time: 0.1860  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:01:14 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 1619  total_loss: 1.343  loss_cls: 0.3627  loss_box_reg: 0.5801  loss_mask: 0.2959  loss_rpn_cls: 0.0515  loss_rpn_loc: 0.07763  time: 0.6534  data_time: 0.0796  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:01:26 d2.utils.events]: \u001b[0m eta: 1:08:09  iter: 1639  total_loss: 1.42  loss_cls: 0.3723  loss_box_reg: 0.586  loss_mask: 0.3001  loss_rpn_cls: 0.07332  loss_rpn_loc: 0.1106  time: 0.6531  data_time: 0.1776  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:01:41 d2.utils.events]: \u001b[0m eta: 1:07:56  iter: 1659  total_loss: 1.456  loss_cls: 0.3798  loss_box_reg: 0.5911  loss_mask: 0.3105  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.09181  time: 0.6537  data_time: 0.2358  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:01:56 d2.utils.events]: \u001b[0m eta: 1:07:51  iter: 1679  total_loss: 1.521  loss_cls: 0.3948  loss_box_reg: 0.6011  loss_mask: 0.316  loss_rpn_cls: 0.07546  loss_rpn_loc: 0.116  time: 0.6554  data_time: 0.3024  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:02:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:02:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:02:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:02:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:02:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:02:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0868 s/iter. Eval: 0.0581 s/iter. Total: 0.1455 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 14:02:13 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0724 s/iter. Total: 0.1610 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0727 s/iter. Total: 0.1614 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:02:23 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0763 s/iter. Total: 0.1654 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 14:02:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.105888 (0.164706 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:02:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088200 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:02:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:02:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24505977686926214\n",
      "\u001b[32m[02/05 14:02:30 d2.utils.events]: \u001b[0m eta: 1:07:41  iter: 1699  total_loss: 1.392  loss_cls: 0.3405  loss_box_reg: 0.5625  loss_mask: 0.3086  loss_rpn_cls: 0.07243  loss_rpn_loc: 0.1065  time: 0.6555  data_time: 0.1936  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:02:43 d2.utils.events]: \u001b[0m eta: 1:07:29  iter: 1719  total_loss: 1.385  loss_cls: 0.3617  loss_box_reg: 0.5602  loss_mask: 0.2799  loss_rpn_cls: 0.05429  loss_rpn_loc: 0.09298  time: 0.6550  data_time: 0.1548  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:02:57 d2.utils.events]: \u001b[0m eta: 1:07:20  iter: 1739  total_loss: 1.355  loss_cls: 0.3475  loss_box_reg: 0.5598  loss_mask: 0.3034  loss_rpn_cls: 0.04836  loss_rpn_loc: 0.09799  time: 0.6558  data_time: 0.2434  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:03:12 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 1759  total_loss: 1.479  loss_cls: 0.3638  loss_box_reg: 0.5818  loss_mask: 0.3051  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.1175  time: 0.6569  data_time: 0.2816  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:03:24 d2.utils.events]: \u001b[0m eta: 1:07:00  iter: 1779  total_loss: 1.372  loss_cls: 0.3488  loss_box_reg: 0.5789  loss_mask: 0.2944  loss_rpn_cls: 0.04197  loss_rpn_loc: 0.06321  time: 0.6564  data_time: 0.1476  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:03:39 d2.utils.events]: \u001b[0m eta: 1:06:51  iter: 1799  total_loss: 1.384  loss_cls: 0.3666  loss_box_reg: 0.5801  loss_mask: 0.2966  loss_rpn_cls: 0.05352  loss_rpn_loc: 0.08641  time: 0.6571  data_time: 0.2347  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:03:51 d2.utils.events]: \u001b[0m eta: 1:06:40  iter: 1819  total_loss: 1.34  loss_cls: 0.3417  loss_box_reg: 0.5813  loss_mask: 0.3093  loss_rpn_cls: 0.03651  loss_rpn_loc: 0.06333  time: 0.6564  data_time: 0.1301  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:04:03 d2.utils.events]: \u001b[0m eta: 1:06:31  iter: 1839  total_loss: 1.334  loss_cls: 0.3162  loss_box_reg: 0.5488  loss_mask: 0.2978  loss_rpn_cls: 0.05686  loss_rpn_loc: 0.05829  time: 0.6559  data_time: 0.1653  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:04:15 d2.utils.events]: \u001b[0m eta: 1:06:21  iter: 1859  total_loss: 1.465  loss_cls: 0.3669  loss_box_reg: 0.5646  loss_mask: 0.3095  loss_rpn_cls: 0.05406  loss_rpn_loc: 0.103  time: 0.6551  data_time: 0.1194  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:04:26 d2.utils.events]: \u001b[0m eta: 1:06:09  iter: 1879  total_loss: 1.362  loss_cls: 0.369  loss_box_reg: 0.5849  loss_mask: 0.3081  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.09672  time: 0.6544  data_time: 0.1222  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:04:44 d2.utils.events]: \u001b[0m eta: 1:05:59  iter: 1899  total_loss: 1.389  loss_cls: 0.3531  loss_box_reg: 0.5669  loss_mask: 0.3068  loss_rpn_cls: 0.06669  loss_rpn_loc: 0.1034  time: 0.6567  data_time: 0.3959  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:04:57 d2.utils.events]: \u001b[0m eta: 1:05:43  iter: 1919  total_loss: 1.393  loss_cls: 0.3457  loss_box_reg: 0.5623  loss_mask: 0.2996  loss_rpn_cls: 0.05143  loss_rpn_loc: 0.09407  time: 0.6565  data_time: 0.1787  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:05:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:05:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:05:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:05:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:05:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:05:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0868 s/iter. Eval: 0.0596 s/iter. Total: 0.1471 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 14:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0724 s/iter. Total: 0.1611 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0730 s/iter. Total: 0.1616 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0770 s/iter. Total: 0.1660 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:05:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.184098 (0.165380 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:05:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088066 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:05:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:05:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25063591690305825\n",
      "\u001b[32m[02/05 14:05:30 d2.utils.events]: \u001b[0m eta: 1:05:33  iter: 1939  total_loss: 1.494  loss_cls: 0.3906  loss_box_reg: 0.6032  loss_mask: 0.3057  loss_rpn_cls: 0.0797  loss_rpn_loc: 0.1189  time: 0.6562  data_time: 0.1514  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:05:43 d2.utils.events]: \u001b[0m eta: 1:05:28  iter: 1959  total_loss: 1.385  loss_cls: 0.3622  loss_box_reg: 0.6132  loss_mask: 0.3133  loss_rpn_cls: 0.05618  loss_rpn_loc: 0.07407  time: 0.6559  data_time: 0.1537  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:05:57 d2.utils.events]: \u001b[0m eta: 1:05:19  iter: 1979  total_loss: 1.41  loss_cls: 0.3595  loss_box_reg: 0.5791  loss_mask: 0.3011  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.1052  time: 0.6565  data_time: 0.2332  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:06:12 d2.utils.events]: \u001b[0m eta: 1:05:03  iter: 1999  total_loss: 1.266  loss_cls: 0.3301  loss_box_reg: 0.5477  loss_mask: 0.3114  loss_rpn_cls: 0.03902  loss_rpn_loc: 0.05927  time: 0.6573  data_time: 0.2702  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:06:24 d2.utils.events]: \u001b[0m eta: 1:05:02  iter: 2019  total_loss: 1.427  loss_cls: 0.3827  loss_box_reg: 0.5667  loss_mask: 0.2977  loss_rpn_cls: 0.05709  loss_rpn_loc: 0.1068  time: 0.6571  data_time: 0.1503  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:06:37 d2.utils.events]: \u001b[0m eta: 1:04:49  iter: 2039  total_loss: 1.389  loss_cls: 0.3496  loss_box_reg: 0.5645  loss_mask: 0.3019  loss_rpn_cls: 0.0687  loss_rpn_loc: 0.1075  time: 0.6566  data_time: 0.1432  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:06:51 d2.utils.events]: \u001b[0m eta: 1:04:45  iter: 2059  total_loss: 1.561  loss_cls: 0.4194  loss_box_reg: 0.6376  loss_mask: 0.3134  loss_rpn_cls: 0.08363  loss_rpn_loc: 0.108  time: 0.6574  data_time: 0.2552  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:07:04 d2.utils.events]: \u001b[0m eta: 1:04:34  iter: 2079  total_loss: 1.378  loss_cls: 0.3587  loss_box_reg: 0.5673  loss_mask: 0.3033  loss_rpn_cls: 0.05495  loss_rpn_loc: 0.1026  time: 0.6570  data_time: 0.1726  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:07:19 d2.utils.events]: \u001b[0m eta: 1:04:22  iter: 2099  total_loss: 1.302  loss_cls: 0.3318  loss_box_reg: 0.5598  loss_mask: 0.297  loss_rpn_cls: 0.05108  loss_rpn_loc: 0.08069  time: 0.6581  data_time: 0.2927  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:07:30 d2.utils.events]: \u001b[0m eta: 1:04:05  iter: 2119  total_loss: 1.295  loss_cls: 0.3205  loss_box_reg: 0.5591  loss_mask: 0.3095  loss_rpn_cls: 0.03428  loss_rpn_loc: 0.06562  time: 0.6571  data_time: 0.1035  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:07:43 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 2139  total_loss: 1.298  loss_cls: 0.3207  loss_box_reg: 0.5756  loss_mask: 0.2932  loss_rpn_cls: 0.04211  loss_rpn_loc: 0.07108  time: 0.6571  data_time: 0.1923  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:07:55 d2.utils.events]: \u001b[0m eta: 1:03:47  iter: 2159  total_loss: 1.319  loss_cls: 0.334  loss_box_reg: 0.5434  loss_mask: 0.2779  loss_rpn_cls: 0.05241  loss_rpn_loc: 0.08147  time: 0.6563  data_time: 0.1072  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:08:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:08:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:08:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:08:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:08:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:08:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0860 s/iter. Eval: 0.0569 s/iter. Total: 0.1434 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0872 s/iter. Eval: 0.0711 s/iter. Total: 0.1591 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0722 s/iter. Total: 0.1604 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0757 s/iter. Total: 0.1642 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 14:08:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.922141 (0.163122 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:08:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087523 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:08:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:08:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2618517661260108\n",
      "\u001b[32m[02/05 14:08:26 d2.utils.events]: \u001b[0m eta: 1:03:37  iter: 2179  total_loss: 1.372  loss_cls: 0.3563  loss_box_reg: 0.5653  loss_mask: 0.2967  loss_rpn_cls: 0.07062  loss_rpn_loc: 0.1211  time: 0.6553  data_time: 0.0757  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:08:37 d2.utils.events]: \u001b[0m eta: 1:03:21  iter: 2199  total_loss: 1.362  loss_cls: 0.3378  loss_box_reg: 0.5791  loss_mask: 0.3016  loss_rpn_cls: 0.04653  loss_rpn_loc: 0.06891  time: 0.6541  data_time: 0.0657  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:08:51 d2.utils.events]: \u001b[0m eta: 1:03:10  iter: 2219  total_loss: 1.364  loss_cls: 0.3637  loss_box_reg: 0.5616  loss_mask: 0.2995  loss_rpn_cls: 0.0499  loss_rpn_loc: 0.09552  time: 0.6546  data_time: 0.2546  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:09:04 d2.utils.events]: \u001b[0m eta: 1:03:00  iter: 2239  total_loss: 1.395  loss_cls: 0.3642  loss_box_reg: 0.5609  loss_mask: 0.29  loss_rpn_cls: 0.05505  loss_rpn_loc: 0.1102  time: 0.6547  data_time: 0.1898  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:09:16 d2.utils.events]: \u001b[0m eta: 1:02:47  iter: 2259  total_loss: 1.33  loss_cls: 0.3407  loss_box_reg: 0.561  loss_mask: 0.3127  loss_rpn_cls: 0.05091  loss_rpn_loc: 0.08451  time: 0.6543  data_time: 0.1533  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:09:31 d2.utils.events]: \u001b[0m eta: 1:02:40  iter: 2279  total_loss: 1.475  loss_cls: 0.3694  loss_box_reg: 0.6047  loss_mask: 0.3039  loss_rpn_cls: 0.07935  loss_rpn_loc: 0.1134  time: 0.6550  data_time: 0.2699  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:09:44 d2.utils.events]: \u001b[0m eta: 1:02:28  iter: 2299  total_loss: 1.256  loss_cls: 0.3048  loss_box_reg: 0.5395  loss_mask: 0.29  loss_rpn_cls: 0.03554  loss_rpn_loc: 0.0453  time: 0.6547  data_time: 0.1695  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:09:55 d2.utils.events]: \u001b[0m eta: 1:02:17  iter: 2319  total_loss: 1.277  loss_cls: 0.3384  loss_box_reg: 0.5485  loss_mask: 0.2971  loss_rpn_cls: 0.04625  loss_rpn_loc: 0.07  time: 0.6541  data_time: 0.1138  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:10:10 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 2339  total_loss: 1.377  loss_cls: 0.3511  loss_box_reg: 0.5646  loss_mask: 0.2906  loss_rpn_cls: 0.05512  loss_rpn_loc: 0.1096  time: 0.6547  data_time: 0.2337  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:10:21 d2.utils.events]: \u001b[0m eta: 1:01:53  iter: 2359  total_loss: 1.297  loss_cls: 0.3294  loss_box_reg: 0.5651  loss_mask: 0.2924  loss_rpn_cls: 0.04571  loss_rpn_loc: 0.07064  time: 0.6539  data_time: 0.1039  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:10:34 d2.utils.events]: \u001b[0m eta: 1:01:48  iter: 2379  total_loss: 1.443  loss_cls: 0.3564  loss_box_reg: 0.5944  loss_mask: 0.3105  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.1055  time: 0.6537  data_time: 0.1619  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:10:51 d2.utils.events]: \u001b[0m eta: 1:01:40  iter: 2399  total_loss: 1.576  loss_cls: 0.4202  loss_box_reg: 0.5947  loss_mask: 0.3083  loss_rpn_cls: 0.0597  loss_rpn_loc: 0.102  time: 0.6553  data_time: 0.3600  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:11:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:11:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:11:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:11:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:11:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:11:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:11:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0859 s/iter. Eval: 0.0540 s/iter. Total: 0.1406 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:11:10 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0687 s/iter. Total: 0.1565 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0871 s/iter. Eval: 0.0719 s/iter. Total: 0.1598 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0753 s/iter. Total: 0.1637 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 14:11:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.841321 (0.162425 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:11:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087334 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:11:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:11:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2651724103354519\n",
      "\u001b[32m[02/05 14:11:23 d2.utils.events]: \u001b[0m eta: 1:01:31  iter: 2419  total_loss: 1.328  loss_cls: 0.353  loss_box_reg: 0.5415  loss_mask: 0.2896  loss_rpn_cls: 0.05107  loss_rpn_loc: 0.09307  time: 0.6550  data_time: 0.1501  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:11:37 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 2439  total_loss: 1.31  loss_cls: 0.3485  loss_box_reg: 0.5778  loss_mask: 0.2884  loss_rpn_cls: 0.0556  loss_rpn_loc: 0.07595  time: 0.6550  data_time: 0.2024  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:11:54 d2.utils.events]: \u001b[0m eta: 1:01:10  iter: 2459  total_loss: 1.524  loss_cls: 0.3894  loss_box_reg: 0.589  loss_mask: 0.3044  loss_rpn_cls: 0.05713  loss_rpn_loc: 0.1154  time: 0.6567  data_time: 0.3631  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:12:08 d2.utils.events]: \u001b[0m eta: 1:00:59  iter: 2479  total_loss: 1.381  loss_cls: 0.3411  loss_box_reg: 0.5695  loss_mask: 0.2902  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.09586  time: 0.6572  data_time: 0.2477  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:12:20 d2.utils.events]: \u001b[0m eta: 1:00:49  iter: 2499  total_loss: 1.332  loss_cls: 0.3201  loss_box_reg: 0.5884  loss_mask: 0.3104  loss_rpn_cls: 0.03524  loss_rpn_loc: 0.07261  time: 0.6565  data_time: 0.1204  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:12:34 d2.utils.events]: \u001b[0m eta: 1:00:36  iter: 2519  total_loss: 1.474  loss_cls: 0.365  loss_box_reg: 0.5916  loss_mask: 0.3004  loss_rpn_cls: 0.04878  loss_rpn_loc: 0.07737  time: 0.6570  data_time: 0.2475  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:12:45 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 2539  total_loss: 1.321  loss_cls: 0.3403  loss_box_reg: 0.5733  loss_mask: 0.3  loss_rpn_cls: 0.03256  loss_rpn_loc: 0.06036  time: 0.6563  data_time: 0.0969  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:13:01 d2.utils.events]: \u001b[0m eta: 1:00:23  iter: 2559  total_loss: 1.456  loss_cls: 0.3671  loss_box_reg: 0.581  loss_mask: 0.3126  loss_rpn_cls: 0.07388  loss_rpn_loc: 0.1088  time: 0.6572  data_time: 0.2911  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:13:12 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 2579  total_loss: 1.304  loss_cls: 0.3271  loss_box_reg: 0.5613  loss_mask: 0.2994  loss_rpn_cls: 0.04291  loss_rpn_loc: 0.08129  time: 0.6565  data_time: 0.1120  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:13:28 d2.utils.events]: \u001b[0m eta: 1:00:10  iter: 2599  total_loss: 1.386  loss_cls: 0.3721  loss_box_reg: 0.5719  loss_mask: 0.3045  loss_rpn_cls: 0.06849  loss_rpn_loc: 0.1064  time: 0.6575  data_time: 0.2953  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:13:38 d2.utils.events]: \u001b[0m eta: 0:59:59  iter: 2619  total_loss: 1.18  loss_cls: 0.2811  loss_box_reg: 0.5406  loss_mask: 0.2945  loss_rpn_cls: 0.03183  loss_rpn_loc: 0.052  time: 0.6562  data_time: 0.0455  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:13:49 d2.utils.events]: \u001b[0m eta: 0:59:51  iter: 2639  total_loss: 1.351  loss_cls: 0.3525  loss_box_reg: 0.5623  loss_mask: 0.3053  loss_rpn_cls: 0.04701  loss_rpn_loc: 0.1086  time: 0.6555  data_time: 0.1056  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:14:02 d2.utils.events]: \u001b[0m eta: 0:59:42  iter: 2659  total_loss: 1.297  loss_cls: 0.3226  loss_box_reg: 0.5436  loss_mask: 0.2875  loss_rpn_cls: 0.04164  loss_rpn_loc: 0.08862  time: 0.6557  data_time: 0.2006  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:14:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:14:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:14:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:14:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:14:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:14:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:14:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0867 s/iter. Eval: 0.0585 s/iter. Total: 0.1458 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 14:14:12 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0721 s/iter. Total: 0.1605 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:14:17 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0726 s/iter. Total: 0.1610 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:14:22 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0772 s/iter. Total: 0.1659 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:14:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.180685 (0.165351 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:14:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087854 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:14:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:14:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2595089580918179\n",
      "\u001b[32m[02/05 14:14:40 d2.utils.events]: \u001b[0m eta: 0:59:27  iter: 2679  total_loss: 1.458  loss_cls: 0.39  loss_box_reg: 0.583  loss_mask: 0.3188  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.1  time: 0.6570  data_time: 0.3545  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:14:51 d2.utils.events]: \u001b[0m eta: 0:59:16  iter: 2699  total_loss: 1.3  loss_cls: 0.3217  loss_box_reg: 0.5361  loss_mask: 0.3012  loss_rpn_cls: 0.04788  loss_rpn_loc: 0.07199  time: 0.6564  data_time: 0.1211  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:15:05 d2.utils.events]: \u001b[0m eta: 0:59:05  iter: 2719  total_loss: 1.269  loss_cls: 0.3385  loss_box_reg: 0.534  loss_mask: 0.2874  loss_rpn_cls: 0.04715  loss_rpn_loc: 0.07392  time: 0.6564  data_time: 0.1993  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:15:18 d2.utils.events]: \u001b[0m eta: 0:58:47  iter: 2739  total_loss: 1.485  loss_cls: 0.376  loss_box_reg: 0.5991  loss_mask: 0.3086  loss_rpn_cls: 0.06277  loss_rpn_loc: 0.0909  time: 0.6565  data_time: 0.1954  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:15:27 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 2759  total_loss: 1.171  loss_cls: 0.299  loss_box_reg: 0.5385  loss_mask: 0.2755  loss_rpn_cls: 0.02423  loss_rpn_loc: 0.0397  time: 0.6551  data_time: 0.0269  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:15:41 d2.utils.events]: \u001b[0m eta: 0:58:21  iter: 2779  total_loss: 1.295  loss_cls: 0.3231  loss_box_reg: 0.5513  loss_mask: 0.3114  loss_rpn_cls: 0.05668  loss_rpn_loc: 0.08068  time: 0.6552  data_time: 0.1999  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:15:54 d2.utils.events]: \u001b[0m eta: 0:58:11  iter: 2799  total_loss: 1.426  loss_cls: 0.3678  loss_box_reg: 0.5822  loss_mask: 0.3073  loss_rpn_cls: 0.07173  loss_rpn_loc: 0.1089  time: 0.6554  data_time: 0.2023  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:16:06 d2.utils.events]: \u001b[0m eta: 0:58:02  iter: 2819  total_loss: 1.357  loss_cls: 0.329  loss_box_reg: 0.5786  loss_mask: 0.3055  loss_rpn_cls: 0.04956  loss_rpn_loc: 0.06602  time: 0.6548  data_time: 0.1118  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:16:17 d2.utils.events]: \u001b[0m eta: 0:58:03  iter: 2839  total_loss: 1.301  loss_cls: 0.3432  loss_box_reg: 0.5522  loss_mask: 0.2959  loss_rpn_cls: 0.03413  loss_rpn_loc: 0.06875  time: 0.6542  data_time: 0.0594  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:16:31 d2.utils.events]: \u001b[0m eta: 0:57:52  iter: 2859  total_loss: 1.399  loss_cls: 0.3587  loss_box_reg: 0.5569  loss_mask: 0.2993  loss_rpn_cls: 0.06052  loss_rpn_loc: 0.09986  time: 0.6545  data_time: 0.2226  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:16:46 d2.utils.events]: \u001b[0m eta: 0:57:50  iter: 2879  total_loss: 1.457  loss_cls: 0.3698  loss_box_reg: 0.5579  loss_mask: 0.3052  loss_rpn_cls: 0.08117  loss_rpn_loc: 0.1132  time: 0.6551  data_time: 0.2565  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:17:03 d2.utils.events]: \u001b[0m eta: 0:57:44  iter: 2899  total_loss: 1.416  loss_cls: 0.3873  loss_box_reg: 0.5706  loss_mask: 0.3115  loss_rpn_cls: 0.07011  loss_rpn_loc: 0.1099  time: 0.6564  data_time: 0.3433  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:17:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:17:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:17:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:17:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:17:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:17:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0862 s/iter. Eval: 0.0569 s/iter. Total: 0.1437 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0741 s/iter. Total: 0.1635 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 14:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0736 s/iter. Total: 0.1625 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0771 s/iter. Total: 0.1662 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:17:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.214495 (0.165642 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:17:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088195 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:17:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:17:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2648437695166141\n",
      "\u001b[32m[02/05 14:17:35 d2.utils.events]: \u001b[0m eta: 0:57:35  iter: 2919  total_loss: 1.33  loss_cls: 0.3693  loss_box_reg: 0.5671  loss_mask: 0.3015  loss_rpn_cls: 0.0478  loss_rpn_loc: 0.08586  time: 0.6560  data_time: 0.1304  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:17:49 d2.utils.events]: \u001b[0m eta: 0:57:26  iter: 2939  total_loss: 1.425  loss_cls: 0.3589  loss_box_reg: 0.5678  loss_mask: 0.295  loss_rpn_cls: 0.05452  loss_rpn_loc: 0.1078  time: 0.6563  data_time: 0.2135  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:18:04 d2.utils.events]: \u001b[0m eta: 0:57:19  iter: 2959  total_loss: 1.312  loss_cls: 0.3258  loss_box_reg: 0.5442  loss_mask: 0.2762  loss_rpn_cls: 0.04547  loss_rpn_loc: 0.09882  time: 0.6568  data_time: 0.2623  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:18:21 d2.utils.events]: \u001b[0m eta: 0:57:12  iter: 2979  total_loss: 1.342  loss_cls: 0.3386  loss_box_reg: 0.561  loss_mask: 0.308  loss_rpn_cls: 0.05507  loss_rpn_loc: 0.1084  time: 0.6579  data_time: 0.3188  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:18:33 d2.utils.events]: \u001b[0m eta: 0:57:00  iter: 2999  total_loss: 1.368  loss_cls: 0.3453  loss_box_reg: 0.5513  loss_mask: 0.3017  loss_rpn_cls: 0.04464  loss_rpn_loc: 0.06701  time: 0.6576  data_time: 0.1494  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:18:45 d2.utils.events]: \u001b[0m eta: 0:56:46  iter: 3019  total_loss: 1.313  loss_cls: 0.3466  loss_box_reg: 0.5581  loss_mask: 0.2973  loss_rpn_cls: 0.04524  loss_rpn_loc: 0.06675  time: 0.6572  data_time: 0.1372  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:18:58 d2.utils.events]: \u001b[0m eta: 0:56:45  iter: 3039  total_loss: 1.42  loss_cls: 0.3703  loss_box_reg: 0.5704  loss_mask: 0.3014  loss_rpn_cls: 0.05644  loss_rpn_loc: 0.1088  time: 0.6572  data_time: 0.1481  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:19:10 d2.utils.events]: \u001b[0m eta: 0:56:26  iter: 3059  total_loss: 1.28  loss_cls: 0.3306  loss_box_reg: 0.5472  loss_mask: 0.3055  loss_rpn_cls: 0.02801  loss_rpn_loc: 0.04571  time: 0.6568  data_time: 0.1459  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:19:21 d2.utils.events]: \u001b[0m eta: 0:56:17  iter: 3079  total_loss: 1.324  loss_cls: 0.3095  loss_box_reg: 0.5529  loss_mask: 0.2923  loss_rpn_cls: 0.05856  loss_rpn_loc: 0.0576  time: 0.6560  data_time: 0.0703  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:19:34 d2.utils.events]: \u001b[0m eta: 0:56:08  iter: 3099  total_loss: 1.468  loss_cls: 0.3642  loss_box_reg: 0.5687  loss_mask: 0.3088  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.1159  time: 0.6561  data_time: 0.2070  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:19:47 d2.utils.events]: \u001b[0m eta: 0:56:04  iter: 3119  total_loss: 1.345  loss_cls: 0.3439  loss_box_reg: 0.5429  loss_mask: 0.3036  loss_rpn_cls: 0.04648  loss_rpn_loc: 0.06472  time: 0.6560  data_time: 0.1708  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:20:00 d2.utils.events]: \u001b[0m eta: 0:55:54  iter: 3139  total_loss: 1.289  loss_cls: 0.3132  loss_box_reg: 0.5531  loss_mask: 0.2821  loss_rpn_cls: 0.04445  loss_rpn_loc: 0.08857  time: 0.6561  data_time: 0.2045  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:20:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:20:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:20:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:20:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:20:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:20:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0859 s/iter. Eval: 0.0543 s/iter. Total: 0.1409 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0730 s/iter. Total: 0.1625 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 14:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0721 s/iter. Total: 0.1616 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0759 s/iter. Total: 0.1654 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:20:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.188686 (0.165420 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:20:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088819 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:20:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:20:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26538841826084375\n",
      "\u001b[32m[02/05 14:20:36 d2.utils.events]: \u001b[0m eta: 0:55:49  iter: 3159  total_loss: 1.381  loss_cls: 0.357  loss_box_reg: 0.5731  loss_mask: 0.2936  loss_rpn_cls: 0.05545  loss_rpn_loc: 0.09157  time: 0.6566  data_time: 0.2357  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:20:49 d2.utils.events]: \u001b[0m eta: 0:55:44  iter: 3179  total_loss: 1.369  loss_cls: 0.3629  loss_box_reg: 0.5631  loss_mask: 0.3127  loss_rpn_cls: 0.04832  loss_rpn_loc: 0.105  time: 0.6567  data_time: 0.1848  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:21:04 d2.utils.events]: \u001b[0m eta: 0:55:45  iter: 3199  total_loss: 1.465  loss_cls: 0.3522  loss_box_reg: 0.5617  loss_mask: 0.3018  loss_rpn_cls: 0.06009  loss_rpn_loc: 0.1023  time: 0.6571  data_time: 0.2361  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:21:15 d2.utils.events]: \u001b[0m eta: 0:55:40  iter: 3219  total_loss: 1.285  loss_cls: 0.3036  loss_box_reg: 0.5863  loss_mask: 0.2949  loss_rpn_cls: 0.03475  loss_rpn_loc: 0.05579  time: 0.6567  data_time: 0.1059  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:21:31 d2.utils.events]: \u001b[0m eta: 0:55:31  iter: 3239  total_loss: 1.348  loss_cls: 0.3381  loss_box_reg: 0.5527  loss_mask: 0.2877  loss_rpn_cls: 0.04868  loss_rpn_loc: 0.0817  time: 0.6572  data_time: 0.2740  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:21:43 d2.utils.events]: \u001b[0m eta: 0:55:20  iter: 3259  total_loss: 1.198  loss_cls: 0.2846  loss_box_reg: 0.5396  loss_mask: 0.3048  loss_rpn_cls: 0.02842  loss_rpn_loc: 0.05602  time: 0.6569  data_time: 0.1378  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:21:56 d2.utils.events]: \u001b[0m eta: 0:55:13  iter: 3279  total_loss: 1.377  loss_cls: 0.3395  loss_box_reg: 0.5545  loss_mask: 0.2938  loss_rpn_cls: 0.06808  loss_rpn_loc: 0.11  time: 0.6571  data_time: 0.1832  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:22:10 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 3299  total_loss: 1.343  loss_cls: 0.3524  loss_box_reg: 0.563  loss_mask: 0.2933  loss_rpn_cls: 0.05425  loss_rpn_loc: 0.09088  time: 0.6573  data_time: 0.1956  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:22:23 d2.utils.events]: \u001b[0m eta: 0:54:58  iter: 3319  total_loss: 1.186  loss_cls: 0.3163  loss_box_reg: 0.5305  loss_mask: 0.274  loss_rpn_cls: 0.03867  loss_rpn_loc: 0.09448  time: 0.6573  data_time: 0.1709  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:22:37 d2.utils.events]: \u001b[0m eta: 0:54:48  iter: 3339  total_loss: 1.371  loss_cls: 0.3579  loss_box_reg: 0.5552  loss_mask: 0.2925  loss_rpn_cls: 0.06672  loss_rpn_loc: 0.1078  time: 0.6575  data_time: 0.2112  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:22:51 d2.utils.events]: \u001b[0m eta: 0:54:48  iter: 3359  total_loss: 1.347  loss_cls: 0.3287  loss_box_reg: 0.5653  loss_mask: 0.2973  loss_rpn_cls: 0.05201  loss_rpn_loc: 0.09594  time: 0.6578  data_time: 0.2227  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:23:07 d2.utils.events]: \u001b[0m eta: 0:54:38  iter: 3379  total_loss: 1.337  loss_cls: 0.3366  loss_box_reg: 0.5351  loss_mask: 0.2936  loss_rpn_cls: 0.04888  loss_rpn_loc: 0.09434  time: 0.6586  data_time: 0.2981  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:23:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:23:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:23:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:23:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:23:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:23:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:23:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0900 s/iter. Eval: 0.0599 s/iter. Total: 0.1505 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 14:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0753 s/iter. Total: 0.1667 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 14:23:24 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0756 s/iter. Total: 0.1670 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 14:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0914 s/iter. Eval: 0.0812 s/iter. Total: 0.1735 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:23:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.917606 (0.171704 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:23:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091395 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:23:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:23:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2642182658782577\n",
      "\u001b[32m[02/05 14:23:41 d2.utils.events]: \u001b[0m eta: 0:54:26  iter: 3399  total_loss: 1.248  loss_cls: 0.3258  loss_box_reg: 0.5486  loss_mask: 0.2912  loss_rpn_cls: 0.042  loss_rpn_loc: 0.07656  time: 0.6582  data_time: 0.1104  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:23:52 d2.utils.events]: \u001b[0m eta: 0:54:18  iter: 3419  total_loss: 1.166  loss_cls: 0.263  loss_box_reg: 0.5287  loss_mask: 0.2825  loss_rpn_cls: 0.02257  loss_rpn_loc: 0.04644  time: 0.6577  data_time: 0.0921  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:24:07 d2.utils.events]: \u001b[0m eta: 0:54:18  iter: 3439  total_loss: 1.348  loss_cls: 0.3432  loss_box_reg: 0.5578  loss_mask: 0.2903  loss_rpn_cls: 0.06806  loss_rpn_loc: 0.0973  time: 0.6581  data_time: 0.2524  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:24:19 d2.utils.events]: \u001b[0m eta: 0:54:08  iter: 3459  total_loss: 1.285  loss_cls: 0.3381  loss_box_reg: 0.5277  loss_mask: 0.283  loss_rpn_cls: 0.04595  loss_rpn_loc: 0.07822  time: 0.6579  data_time: 0.1392  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:24:33 d2.utils.events]: \u001b[0m eta: 0:53:58  iter: 3479  total_loss: 1.329  loss_cls: 0.3134  loss_box_reg: 0.566  loss_mask: 0.3075  loss_rpn_cls: 0.04171  loss_rpn_loc: 0.04447  time: 0.6581  data_time: 0.2162  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:24:47 d2.utils.events]: \u001b[0m eta: 0:53:52  iter: 3499  total_loss: 1.341  loss_cls: 0.3456  loss_box_reg: 0.553  loss_mask: 0.2866  loss_rpn_cls: 0.03712  loss_rpn_loc: 0.09068  time: 0.6582  data_time: 0.1742  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:25:01 d2.utils.events]: \u001b[0m eta: 0:53:43  iter: 3519  total_loss: 1.406  loss_cls: 0.3445  loss_box_reg: 0.5692  loss_mask: 0.3039  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.08279  time: 0.6585  data_time: 0.2442  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:25:13 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 3539  total_loss: 1.242  loss_cls: 0.2945  loss_box_reg: 0.5537  loss_mask: 0.2949  loss_rpn_cls: 0.03916  loss_rpn_loc: 0.05643  time: 0.6582  data_time: 0.1178  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:25:28 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 3559  total_loss: 1.285  loss_cls: 0.321  loss_box_reg: 0.516  loss_mask: 0.3008  loss_rpn_cls: 0.04258  loss_rpn_loc: 0.05554  time: 0.6588  data_time: 0.2639  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:25:40 d2.utils.events]: \u001b[0m eta: 0:53:21  iter: 3579  total_loss: 1.235  loss_cls: 0.3338  loss_box_reg: 0.5149  loss_mask: 0.2843  loss_rpn_cls: 0.03447  loss_rpn_loc: 0.05657  time: 0.6586  data_time: 0.1449  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:25:55 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 3599  total_loss: 1.378  loss_cls: 0.3661  loss_box_reg: 0.579  loss_mask: 0.3143  loss_rpn_cls: 0.04062  loss_rpn_loc: 0.1085  time: 0.6588  data_time: 0.2087  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:26:08 d2.utils.events]: \u001b[0m eta: 0:53:10  iter: 3619  total_loss: 1.461  loss_cls: 0.3541  loss_box_reg: 0.5721  loss_mask: 0.2971  loss_rpn_cls: 0.06508  loss_rpn_loc: 0.1083  time: 0.6590  data_time: 0.1830  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:26:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:26:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:26:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:26:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:26:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:26:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0906 s/iter. Eval: 0.0643 s/iter. Total: 0.1556 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 14:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0741 s/iter. Total: 0.1637 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0885 s/iter. Eval: 0.0738 s/iter. Total: 0.1632 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0772 s/iter. Total: 0.1666 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:26:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.208313 (0.165589 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:26:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088437 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:26:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:26:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2617878116265905\n",
      "\u001b[32m[02/05 14:26:43 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 3639  total_loss: 1.437  loss_cls: 0.3619  loss_box_reg: 0.5817  loss_mask: 0.307  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.1065  time: 0.6590  data_time: 0.1466  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:26:55 d2.utils.events]: \u001b[0m eta: 0:52:51  iter: 3659  total_loss: 1.303  loss_cls: 0.3092  loss_box_reg: 0.5466  loss_mask: 0.2954  loss_rpn_cls: 0.05038  loss_rpn_loc: 0.0719  time: 0.6587  data_time: 0.1440  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:27:10 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 3679  total_loss: 1.285  loss_cls: 0.3175  loss_box_reg: 0.573  loss_mask: 0.2977  loss_rpn_cls: 0.04399  loss_rpn_loc: 0.07559  time: 0.6593  data_time: 0.2808  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:27:23 d2.utils.events]: \u001b[0m eta: 0:52:40  iter: 3699  total_loss: 1.331  loss_cls: 0.3332  loss_box_reg: 0.5369  loss_mask: 0.2899  loss_rpn_cls: 0.04826  loss_rpn_loc: 0.09406  time: 0.6593  data_time: 0.1826  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:27:39 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 3719  total_loss: 1.28  loss_cls: 0.3304  loss_box_reg: 0.5508  loss_mask: 0.2905  loss_rpn_cls: 0.05394  loss_rpn_loc: 0.0956  time: 0.6599  data_time: 0.2649  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:27:52 d2.utils.events]: \u001b[0m eta: 0:52:21  iter: 3739  total_loss: 1.295  loss_cls: 0.3044  loss_box_reg: 0.5421  loss_mask: 0.2959  loss_rpn_cls: 0.03213  loss_rpn_loc: 0.07679  time: 0.6600  data_time: 0.2175  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:28:06 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 3759  total_loss: 1.337  loss_cls: 0.3387  loss_box_reg: 0.5617  loss_mask: 0.2939  loss_rpn_cls: 0.04887  loss_rpn_loc: 0.06472  time: 0.6602  data_time: 0.2340  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:28:19 d2.utils.events]: \u001b[0m eta: 0:52:03  iter: 3779  total_loss: 1.194  loss_cls: 0.3122  loss_box_reg: 0.5306  loss_mask: 0.2841  loss_rpn_cls: 0.03783  loss_rpn_loc: 0.04204  time: 0.6601  data_time: 0.1781  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:28:35 d2.utils.events]: \u001b[0m eta: 0:51:53  iter: 3799  total_loss: 1.371  loss_cls: 0.359  loss_box_reg: 0.5901  loss_mask: 0.318  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.09147  time: 0.6607  data_time: 0.2900  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:28:48 d2.utils.events]: \u001b[0m eta: 0:51:46  iter: 3819  total_loss: 1.542  loss_cls: 0.4046  loss_box_reg: 0.6045  loss_mask: 0.3206  loss_rpn_cls: 0.05867  loss_rpn_loc: 0.1156  time: 0.6607  data_time: 0.1908  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:29:02 d2.utils.events]: \u001b[0m eta: 0:51:32  iter: 3839  total_loss: 1.262  loss_cls: 0.3192  loss_box_reg: 0.5571  loss_mask: 0.2943  loss_rpn_cls: 0.05023  loss_rpn_loc: 0.06987  time: 0.6609  data_time: 0.2191  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:29:17 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 3859  total_loss: 1.424  loss_cls: 0.3538  loss_box_reg: 0.5748  loss_mask: 0.3022  loss_rpn_cls: 0.07408  loss_rpn_loc: 0.1118  time: 0.6613  data_time: 0.2503  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:29:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:29:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:29:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:29:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:29:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:29:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0872 s/iter. Eval: 0.0565 s/iter. Total: 0.1442 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0890 s/iter. Eval: 0.0720 s/iter. Total: 0.1618 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0726 s/iter. Total: 0.1626 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0764 s/iter. Total: 0.1667 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:29:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.275227 (0.166166 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:29:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089284 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:29:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:29:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2673905733498299\n",
      "\u001b[32m[02/05 14:29:49 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 3879  total_loss: 1.268  loss_cls: 0.3192  loss_box_reg: 0.539  loss_mask: 0.297  loss_rpn_cls: 0.04033  loss_rpn_loc: 0.05927  time: 0.6607  data_time: 0.0735  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:30:03 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 3899  total_loss: 1.39  loss_cls: 0.3339  loss_box_reg: 0.5694  loss_mask: 0.3121  loss_rpn_cls: 0.04739  loss_rpn_loc: 0.1073  time: 0.6610  data_time: 0.2233  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:30:17 d2.utils.events]: \u001b[0m eta: 0:50:57  iter: 3919  total_loss: 1.272  loss_cls: 0.3332  loss_box_reg: 0.557  loss_mask: 0.2848  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.09618  time: 0.6612  data_time: 0.1912  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:30:31 d2.utils.events]: \u001b[0m eta: 0:50:42  iter: 3939  total_loss: 1.118  loss_cls: 0.2799  loss_box_reg: 0.5109  loss_mask: 0.2739  loss_rpn_cls: 0.04142  loss_rpn_loc: 0.0453  time: 0.6615  data_time: 0.2514  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:30:44 d2.utils.events]: \u001b[0m eta: 0:50:32  iter: 3959  total_loss: 1.383  loss_cls: 0.3541  loss_box_reg: 0.5569  loss_mask: 0.3004  loss_rpn_cls: 0.06805  loss_rpn_loc: 0.1004  time: 0.6614  data_time: 0.1515  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:30:58 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 3979  total_loss: 1.317  loss_cls: 0.3231  loss_box_reg: 0.5578  loss_mask: 0.3006  loss_rpn_cls: 0.04568  loss_rpn_loc: 0.09234  time: 0.6615  data_time: 0.1711  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:31:11 d2.utils.events]: \u001b[0m eta: 0:50:14  iter: 3999  total_loss: 1.484  loss_cls: 0.37  loss_box_reg: 0.6097  loss_mask: 0.3105  loss_rpn_cls: 0.06308  loss_rpn_loc: 0.102  time: 0.6615  data_time: 0.1909  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:31:21 d2.utils.events]: \u001b[0m eta: 0:50:02  iter: 4019  total_loss: 1.189  loss_cls: 0.2879  loss_box_reg: 0.5232  loss_mask: 0.2887  loss_rpn_cls: 0.02921  loss_rpn_loc: 0.03951  time: 0.6608  data_time: 0.0453  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:31:35 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 4039  total_loss: 1.392  loss_cls: 0.3384  loss_box_reg: 0.5662  loss_mask: 0.3043  loss_rpn_cls: 0.05165  loss_rpn_loc: 0.08977  time: 0.6610  data_time: 0.2216  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:31:48 d2.utils.events]: \u001b[0m eta: 0:49:44  iter: 4059  total_loss: 1.326  loss_cls: 0.3337  loss_box_reg: 0.5543  loss_mask: 0.3138  loss_rpn_cls: 0.05217  loss_rpn_loc: 0.06259  time: 0.6609  data_time: 0.1731  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:32:01 d2.utils.events]: \u001b[0m eta: 0:49:40  iter: 4079  total_loss: 1.258  loss_cls: 0.3184  loss_box_reg: 0.5251  loss_mask: 0.2747  loss_rpn_cls: 0.03893  loss_rpn_loc: 0.077  time: 0.6607  data_time: 0.1335  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:32:16 d2.utils.events]: \u001b[0m eta: 0:49:29  iter: 4099  total_loss: 1.247  loss_cls: 0.2854  loss_box_reg: 0.5547  loss_mask: 0.2869  loss_rpn_cls: 0.04509  loss_rpn_loc: 0.06602  time: 0.6613  data_time: 0.2879  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:32:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:32:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:32:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:32:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:32:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:32:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0848 s/iter. Eval: 0.0505 s/iter. Total: 0.1360 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 14:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0712 s/iter. Total: 0.1597 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0726 s/iter. Total: 0.1613 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:32:44 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0770 s/iter. Total: 0.1661 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 14:32:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.124217 (0.164864 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:32:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088212 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:32:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:32:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27345550770312294\n",
      "\u001b[32m[02/05 14:32:51 d2.utils.events]: \u001b[0m eta: 0:49:20  iter: 4119  total_loss: 1.304  loss_cls: 0.3358  loss_box_reg: 0.5311  loss_mask: 0.2985  loss_rpn_cls: 0.04748  loss_rpn_loc: 0.07091  time: 0.6614  data_time: 0.2075  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:33:04 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 4139  total_loss: 1.31  loss_cls: 0.3345  loss_box_reg: 0.5624  loss_mask: 0.2857  loss_rpn_cls: 0.04384  loss_rpn_loc: 0.08553  time: 0.6613  data_time: 0.1342  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:33:20 d2.utils.events]: \u001b[0m eta: 0:49:17  iter: 4159  total_loss: 1.404  loss_cls: 0.3346  loss_box_reg: 0.5567  loss_mask: 0.2993  loss_rpn_cls: 0.07009  loss_rpn_loc: 0.108  time: 0.6622  data_time: 0.3119  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:33:35 d2.utils.events]: \u001b[0m eta: 0:49:08  iter: 4179  total_loss: 1.335  loss_cls: 0.3619  loss_box_reg: 0.5224  loss_mask: 0.2998  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.1038  time: 0.6624  data_time: 0.2265  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:33:51 d2.utils.events]: \u001b[0m eta: 0:48:58  iter: 4199  total_loss: 1.466  loss_cls: 0.3489  loss_box_reg: 0.5972  loss_mask: 0.3148  loss_rpn_cls: 0.07474  loss_rpn_loc: 0.1122  time: 0.6631  data_time: 0.3010  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:34:03 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 4219  total_loss: 1.187  loss_cls: 0.3023  loss_box_reg: 0.5172  loss_mask: 0.2792  loss_rpn_cls: 0.02725  loss_rpn_loc: 0.06753  time: 0.6627  data_time: 0.1256  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:34:18 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 4239  total_loss: 1.32  loss_cls: 0.3377  loss_box_reg: 0.5252  loss_mask: 0.2819  loss_rpn_cls: 0.04922  loss_rpn_loc: 0.08183  time: 0.6632  data_time: 0.2851  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:34:32 d2.utils.events]: \u001b[0m eta: 0:48:26  iter: 4259  total_loss: 1.224  loss_cls: 0.3022  loss_box_reg: 0.5517  loss_mask: 0.2924  loss_rpn_cls: 0.04075  loss_rpn_loc: 0.0561  time: 0.6633  data_time: 0.2267  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:34:43 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 4279  total_loss: 1.303  loss_cls: 0.3153  loss_box_reg: 0.547  loss_mask: 0.3033  loss_rpn_cls: 0.03687  loss_rpn_loc: 0.06525  time: 0.6628  data_time: 0.0648  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:34:55 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 4299  total_loss: 1.401  loss_cls: 0.3595  loss_box_reg: 0.5777  loss_mask: 0.3036  loss_rpn_cls: 0.05495  loss_rpn_loc: 0.07697  time: 0.6627  data_time: 0.1371  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:35:06 d2.utils.events]: \u001b[0m eta: 0:47:45  iter: 4319  total_loss: 1.117  loss_cls: 0.2586  loss_box_reg: 0.5214  loss_mask: 0.28  loss_rpn_cls: 0.02101  loss_rpn_loc: 0.03394  time: 0.6620  data_time: 0.0534  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:35:20 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 4339  total_loss: 1.43  loss_cls: 0.3439  loss_box_reg: 0.5802  loss_mask: 0.3049  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.07809  time: 0.6622  data_time: 0.2283  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:35:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:35:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:35:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:35:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:35:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:35:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0856 s/iter. Eval: 0.0559 s/iter. Total: 0.1421 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0875 s/iter. Eval: 0.0702 s/iter. Total: 0.1585 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:35:44 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0009 s/iter. Inference: 0.0872 s/iter. Eval: 0.0716 s/iter. Total: 0.1598 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0009 s/iter. Inference: 0.0878 s/iter. Eval: 0.0754 s/iter. Total: 0.1642 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 14:35:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.915758 (0.163067 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:35:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087621 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:35:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:35:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26386007652221144\n",
      "\u001b[32m[02/05 14:35:54 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 4359  total_loss: 1.372  loss_cls: 0.3458  loss_box_reg: 0.5711  loss_mask: 0.3029  loss_rpn_cls: 0.05634  loss_rpn_loc: 0.1024  time: 0.6623  data_time: 0.2192  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:36:10 d2.utils.events]: \u001b[0m eta: 0:47:14  iter: 4379  total_loss: 1.399  loss_cls: 0.346  loss_box_reg: 0.5666  loss_mask: 0.2966  loss_rpn_cls: 0.05169  loss_rpn_loc: 0.1144  time: 0.6630  data_time: 0.3298  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:36:23 d2.utils.events]: \u001b[0m eta: 0:47:04  iter: 4399  total_loss: 1.29  loss_cls: 0.3253  loss_box_reg: 0.562  loss_mask: 0.2988  loss_rpn_cls: 0.04872  loss_rpn_loc: 0.07766  time: 0.6628  data_time: 0.1579  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:36:37 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 4419  total_loss: 1.338  loss_cls: 0.3397  loss_box_reg: 0.5427  loss_mask: 0.2953  loss_rpn_cls: 0.05488  loss_rpn_loc: 0.08026  time: 0.6631  data_time: 0.2523  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:36:49 d2.utils.events]: \u001b[0m eta: 0:46:42  iter: 4439  total_loss: 1.269  loss_cls: 0.3142  loss_box_reg: 0.548  loss_mask: 0.2915  loss_rpn_cls: 0.03383  loss_rpn_loc: 0.06208  time: 0.6627  data_time: 0.1237  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:37:01 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 4459  total_loss: 1.335  loss_cls: 0.3292  loss_box_reg: 0.5557  loss_mask: 0.2994  loss_rpn_cls: 0.04972  loss_rpn_loc: 0.09288  time: 0.6625  data_time: 0.1097  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:37:15 d2.utils.events]: \u001b[0m eta: 0:46:23  iter: 4479  total_loss: 1.347  loss_cls: 0.3594  loss_box_reg: 0.5479  loss_mask: 0.2957  loss_rpn_cls: 0.05602  loss_rpn_loc: 0.1054  time: 0.6626  data_time: 0.2087  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:37:29 d2.utils.events]: \u001b[0m eta: 0:46:13  iter: 4499  total_loss: 1.33  loss_cls: 0.3318  loss_box_reg: 0.5532  loss_mask: 0.2886  loss_rpn_cls: 0.04009  loss_rpn_loc: 0.08437  time: 0.6627  data_time: 0.1875  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:37:40 d2.utils.events]: \u001b[0m eta: 0:46:01  iter: 4519  total_loss: 1.303  loss_cls: 0.3067  loss_box_reg: 0.547  loss_mask: 0.3078  loss_rpn_cls: 0.04206  loss_rpn_loc: 0.05827  time: 0.6623  data_time: 0.1235  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:37:57 d2.utils.events]: \u001b[0m eta: 0:45:52  iter: 4539  total_loss: 1.353  loss_cls: 0.3434  loss_box_reg: 0.5632  loss_mask: 0.2978  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.1069  time: 0.6631  data_time: 0.3678  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:38:15 d2.utils.events]: \u001b[0m eta: 0:45:39  iter: 4559  total_loss: 1.418  loss_cls: 0.3398  loss_box_reg: 0.5608  loss_mask: 0.3009  loss_rpn_cls: 0.06623  loss_rpn_loc: 0.09534  time: 0.6641  data_time: 0.4022  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:38:28 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 4579  total_loss: 1.142  loss_cls: 0.2887  loss_box_reg: 0.4895  loss_mask: 0.2742  loss_rpn_cls: 0.03303  loss_rpn_loc: 0.04769  time: 0.6641  data_time: 0.1649  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:38:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:38:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:38:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:38:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:38:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:38:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.0620 s/iter. Total: 0.1581 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 14:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0934 s/iter. Eval: 0.0758 s/iter. Total: 0.1701 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 14:38:54 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0742 s/iter. Total: 0.1662 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 14:38:59 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0927 s/iter. Eval: 0.0807 s/iter. Total: 0.1743 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 14:39:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.904512 (0.171591 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:39:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:39:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:39:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27033014807991024\n",
      "\u001b[32m[02/05 14:39:04 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 4599  total_loss: 1.321  loss_cls: 0.3383  loss_box_reg: 0.5447  loss_mask: 0.3038  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.1032  time: 0.6643  data_time: 0.2353  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:39:15 d2.utils.events]: \u001b[0m eta: 0:45:01  iter: 4619  total_loss: 1.219  loss_cls: 0.3083  loss_box_reg: 0.541  loss_mask: 0.2865  loss_rpn_cls: 0.02692  loss_rpn_loc: 0.05627  time: 0.6639  data_time: 0.1069  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:39:29 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 4639  total_loss: 1.27  loss_cls: 0.2831  loss_box_reg: 0.564  loss_mask: 0.2917  loss_rpn_cls: 0.0419  loss_rpn_loc: 0.06673  time: 0.6638  data_time: 0.1894  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:39:43 d2.utils.events]: \u001b[0m eta: 0:44:41  iter: 4659  total_loss: 1.346  loss_cls: 0.3375  loss_box_reg: 0.5351  loss_mask: 0.2956  loss_rpn_cls: 0.05443  loss_rpn_loc: 0.1068  time: 0.6640  data_time: 0.2172  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:39:54 d2.utils.events]: \u001b[0m eta: 0:44:27  iter: 4679  total_loss: 1.302  loss_cls: 0.3459  loss_box_reg: 0.5547  loss_mask: 0.285  loss_rpn_cls: 0.05299  loss_rpn_loc: 0.08362  time: 0.6635  data_time: 0.0889  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:40:05 d2.utils.events]: \u001b[0m eta: 0:44:17  iter: 4699  total_loss: 1.324  loss_cls: 0.3398  loss_box_reg: 0.5288  loss_mask: 0.297  loss_rpn_cls: 0.053  loss_rpn_loc: 0.09483  time: 0.6632  data_time: 0.1090  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:40:19 d2.utils.events]: \u001b[0m eta: 0:44:10  iter: 4719  total_loss: 1.396  loss_cls: 0.3648  loss_box_reg: 0.5771  loss_mask: 0.3194  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.1169  time: 0.6633  data_time: 0.1794  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:40:34 d2.utils.events]: \u001b[0m eta: 0:44:01  iter: 4739  total_loss: 1.262  loss_cls: 0.3262  loss_box_reg: 0.5252  loss_mask: 0.2937  loss_rpn_cls: 0.04719  loss_rpn_loc: 0.08234  time: 0.6636  data_time: 0.2517  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:40:47 d2.utils.events]: \u001b[0m eta: 0:43:57  iter: 4759  total_loss: 1.309  loss_cls: 0.3431  loss_box_reg: 0.5522  loss_mask: 0.2954  loss_rpn_cls: 0.05764  loss_rpn_loc: 0.1023  time: 0.6636  data_time: 0.1641  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:40:59 d2.utils.events]: \u001b[0m eta: 0:43:47  iter: 4779  total_loss: 1.344  loss_cls: 0.3396  loss_box_reg: 0.5547  loss_mask: 0.3008  loss_rpn_cls: 0.04434  loss_rpn_loc: 0.08193  time: 0.6634  data_time: 0.1376  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:41:13 d2.utils.events]: \u001b[0m eta: 0:43:38  iter: 4799  total_loss: 1.378  loss_cls: 0.3467  loss_box_reg: 0.5418  loss_mask: 0.2874  loss_rpn_cls: 0.06667  loss_rpn_loc: 0.1027  time: 0.6634  data_time: 0.1871  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:41:26 d2.utils.events]: \u001b[0m eta: 0:43:26  iter: 4819  total_loss: 1.363  loss_cls: 0.3422  loss_box_reg: 0.5589  loss_mask: 0.2923  loss_rpn_cls: 0.05105  loss_rpn_loc: 0.08007  time: 0.6633  data_time: 0.1607  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:41:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:41:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:41:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:41:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:41:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:41:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0854 s/iter. Eval: 0.0541 s/iter. Total: 0.1401 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0871 s/iter. Eval: 0.0703 s/iter. Total: 0.1582 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0720 s/iter. Total: 0.1610 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:41:59 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0766 s/iter. Total: 0.1663 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:42:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.250984 (0.165957 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:42:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088865 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:42:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:42:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.270260032332308\n",
      "\u001b[32m[02/05 14:42:03 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 4839  total_loss: 1.322  loss_cls: 0.3471  loss_box_reg: 0.5473  loss_mask: 0.2851  loss_rpn_cls: 0.05546  loss_rpn_loc: 0.1  time: 0.6639  data_time: 0.3101  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:42:15 d2.utils.events]: \u001b[0m eta: 0:43:05  iter: 4859  total_loss: 1.186  loss_cls: 0.3155  loss_box_reg: 0.538  loss_mask: 0.2937  loss_rpn_cls: 0.03891  loss_rpn_loc: 0.08199  time: 0.6636  data_time: 0.1338  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:42:32 d2.utils.events]: \u001b[0m eta: 0:42:58  iter: 4879  total_loss: 1.335  loss_cls: 0.3443  loss_box_reg: 0.557  loss_mask: 0.2954  loss_rpn_cls: 0.0653  loss_rpn_loc: 0.0993  time: 0.6645  data_time: 0.3779  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:42:45 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 4899  total_loss: 1.265  loss_cls: 0.3196  loss_box_reg: 0.552  loss_mask: 0.2966  loss_rpn_cls: 0.04357  loss_rpn_loc: 0.08415  time: 0.6643  data_time: 0.1466  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:42:56 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 4919  total_loss: 1.232  loss_cls: 0.3128  loss_box_reg: 0.5401  loss_mask: 0.2974  loss_rpn_cls: 0.03585  loss_rpn_loc: 0.06579  time: 0.6639  data_time: 0.0907  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:43:09 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 4939  total_loss: 1.213  loss_cls: 0.3107  loss_box_reg: 0.5472  loss_mask: 0.2855  loss_rpn_cls: 0.033  loss_rpn_loc: 0.05801  time: 0.6638  data_time: 0.1261  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:43:20 d2.utils.events]: \u001b[0m eta: 0:42:18  iter: 4959  total_loss: 1.303  loss_cls: 0.3094  loss_box_reg: 0.5315  loss_mask: 0.2998  loss_rpn_cls: 0.03565  loss_rpn_loc: 0.06307  time: 0.6634  data_time: 0.1017  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:43:35 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 4979  total_loss: 1.295  loss_cls: 0.309  loss_box_reg: 0.5725  loss_mask: 0.2925  loss_rpn_cls: 0.03473  loss_rpn_loc: 0.06481  time: 0.6638  data_time: 0.2796  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:43:49 d2.utils.events]: \u001b[0m eta: 0:41:54  iter: 4999  total_loss: 1.267  loss_cls: 0.297  loss_box_reg: 0.5433  loss_mask: 0.3022  loss_rpn_cls: 0.04063  loss_rpn_loc: 0.06522  time: 0.6639  data_time: 0.2016  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:44:02 d2.utils.events]: \u001b[0m eta: 0:41:49  iter: 5019  total_loss: 1.392  loss_cls: 0.3478  loss_box_reg: 0.6028  loss_mask: 0.316  loss_rpn_cls: 0.05922  loss_rpn_loc: 0.1037  time: 0.6638  data_time: 0.1716  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:44:16 d2.utils.events]: \u001b[0m eta: 0:41:38  iter: 5039  total_loss: 1.295  loss_cls: 0.3124  loss_box_reg: 0.5036  loss_mask: 0.2829  loss_rpn_cls: 0.04568  loss_rpn_loc: 0.09687  time: 0.6639  data_time: 0.2092  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:44:33 d2.utils.events]: \u001b[0m eta: 0:41:27  iter: 5059  total_loss: 1.367  loss_cls: 0.3378  loss_box_reg: 0.5621  loss_mask: 0.3041  loss_rpn_cls: 0.05109  loss_rpn_loc: 0.09727  time: 0.6646  data_time: 0.3680  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:44:45 d2.utils.events]: \u001b[0m eta: 0:41:14  iter: 5079  total_loss: 1.279  loss_cls: 0.3178  loss_box_reg: 0.5669  loss_mask: 0.2925  loss_rpn_cls: 0.05412  loss_rpn_loc: 0.06275  time: 0.6644  data_time: 0.1333  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:44:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:44:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:44:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:44:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:44:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:44:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0877 s/iter. Eval: 0.0606 s/iter. Total: 0.1490 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 14:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0897 s/iter. Eval: 0.0755 s/iter. Total: 0.1661 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 14:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0747 s/iter. Total: 0.1651 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 14:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0788 s/iter. Total: 0.1692 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:45:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.484627 (0.167971 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:45:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089186 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:45:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:45:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27061611142089986\n",
      "\u001b[32m[02/05 14:45:18 d2.utils.events]: \u001b[0m eta: 0:41:05  iter: 5099  total_loss: 1.327  loss_cls: 0.3456  loss_box_reg: 0.5453  loss_mask: 0.2985  loss_rpn_cls: 0.05598  loss_rpn_loc: 0.1051  time: 0.6642  data_time: 0.1501  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:45:34 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 5119  total_loss: 1.461  loss_cls: 0.3653  loss_box_reg: 0.5962  loss_mask: 0.3197  loss_rpn_cls: 0.06344  loss_rpn_loc: 0.1039  time: 0.6647  data_time: 0.2826  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:45:45 d2.utils.events]: \u001b[0m eta: 0:40:43  iter: 5139  total_loss: 1.323  loss_cls: 0.3432  loss_box_reg: 0.5369  loss_mask: 0.2894  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.08446  time: 0.6642  data_time: 0.0696  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:46:02 d2.utils.events]: \u001b[0m eta: 0:40:30  iter: 5159  total_loss: 1.351  loss_cls: 0.3433  loss_box_reg: 0.5574  loss_mask: 0.3023  loss_rpn_cls: 0.05875  loss_rpn_loc: 0.09737  time: 0.6649  data_time: 0.3524  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:46:16 d2.utils.events]: \u001b[0m eta: 0:40:15  iter: 5179  total_loss: 1.425  loss_cls: 0.3596  loss_box_reg: 0.581  loss_mask: 0.3144  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1085  time: 0.6652  data_time: 0.2287  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:46:34 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 5199  total_loss: 1.344  loss_cls: 0.3428  loss_box_reg: 0.5414  loss_mask: 0.2949  loss_rpn_cls: 0.05797  loss_rpn_loc: 0.1068  time: 0.6661  data_time: 0.3976  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:46:50 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 5219  total_loss: 1.302  loss_cls: 0.3219  loss_box_reg: 0.5401  loss_mask: 0.2917  loss_rpn_cls: 0.04699  loss_rpn_loc: 0.07241  time: 0.6664  data_time: 0.2470  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:47:00 d2.utils.events]: \u001b[0m eta: 0:39:48  iter: 5239  total_loss: 1.198  loss_cls: 0.2896  loss_box_reg: 0.5364  loss_mask: 0.2811  loss_rpn_cls: 0.03296  loss_rpn_loc: 0.05832  time: 0.6659  data_time: 0.0527  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:47:13 d2.utils.events]: \u001b[0m eta: 0:39:43  iter: 5259  total_loss: 1.337  loss_cls: 0.3248  loss_box_reg: 0.5276  loss_mask: 0.2794  loss_rpn_cls: 0.05732  loss_rpn_loc: 0.09855  time: 0.6657  data_time: 0.1205  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:47:23 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 5279  total_loss: 1.212  loss_cls: 0.2983  loss_box_reg: 0.5578  loss_mask: 0.2945  loss_rpn_cls: 0.02831  loss_rpn_loc: 0.05914  time: 0.6652  data_time: 0.0580  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:47:34 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 5299  total_loss: 1.275  loss_cls: 0.3124  loss_box_reg: 0.537  loss_mask: 0.3039  loss_rpn_cls: 0.0329  loss_rpn_loc: 0.04907  time: 0.6648  data_time: 0.1167  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:47:50 d2.utils.events]: \u001b[0m eta: 0:39:03  iter: 5319  total_loss: 1.35  loss_cls: 0.3467  loss_box_reg: 0.5464  loss_mask: 0.2902  loss_rpn_cls: 0.05147  loss_rpn_loc: 0.09242  time: 0.6652  data_time: 0.2856  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:47:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:47:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:47:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:47:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:47:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:47:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0869 s/iter. Eval: 0.0587 s/iter. Total: 0.1463 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 14:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0742 s/iter. Total: 0.1636 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 14:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0733 s/iter. Total: 0.1626 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0773 s/iter. Total: 0.1668 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:48:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.363107 (0.166923 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:48:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088786 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:48:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:48:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2706203122623409\n",
      "\u001b[32m[02/05 14:48:25 d2.utils.events]: \u001b[0m eta: 0:38:59  iter: 5339  total_loss: 1.256  loss_cls: 0.3016  loss_box_reg: 0.5492  loss_mask: 0.3002  loss_rpn_cls: 0.04147  loss_rpn_loc: 0.08945  time: 0.6654  data_time: 0.2072  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:48:40 d2.utils.events]: \u001b[0m eta: 0:38:51  iter: 5359  total_loss: 1.399  loss_cls: 0.3394  loss_box_reg: 0.5581  loss_mask: 0.2886  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.1027  time: 0.6657  data_time: 0.2713  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:48:54 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 5379  total_loss: 1.308  loss_cls: 0.3281  loss_box_reg: 0.5514  loss_mask: 0.2979  loss_rpn_cls: 0.04987  loss_rpn_loc: 0.09572  time: 0.6658  data_time: 0.2071  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:49:07 d2.utils.events]: \u001b[0m eta: 0:38:32  iter: 5399  total_loss: 1.317  loss_cls: 0.3245  loss_box_reg: 0.5405  loss_mask: 0.2873  loss_rpn_cls: 0.04608  loss_rpn_loc: 0.07645  time: 0.6658  data_time: 0.1901  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:49:20 d2.utils.events]: \u001b[0m eta: 0:38:25  iter: 5419  total_loss: 1.396  loss_cls: 0.3462  loss_box_reg: 0.5774  loss_mask: 0.3006  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.1091  time: 0.6656  data_time: 0.1037  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:49:34 d2.utils.events]: \u001b[0m eta: 0:38:17  iter: 5439  total_loss: 1.236  loss_cls: 0.3053  loss_box_reg: 0.5403  loss_mask: 0.2862  loss_rpn_cls: 0.03176  loss_rpn_loc: 0.05509  time: 0.6657  data_time: 0.2102  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:49:49 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 5459  total_loss: 1.395  loss_cls: 0.342  loss_box_reg: 0.5566  loss_mask: 0.3155  loss_rpn_cls: 0.07828  loss_rpn_loc: 0.1128  time: 0.6662  data_time: 0.2982  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:50:03 d2.utils.events]: \u001b[0m eta: 0:37:58  iter: 5479  total_loss: 1.276  loss_cls: 0.3021  loss_box_reg: 0.547  loss_mask: 0.2948  loss_rpn_cls: 0.04015  loss_rpn_loc: 0.05895  time: 0.6662  data_time: 0.2000  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:50:14 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 5499  total_loss: 1.237  loss_cls: 0.3146  loss_box_reg: 0.5267  loss_mask: 0.2893  loss_rpn_cls: 0.04264  loss_rpn_loc: 0.07571  time: 0.6658  data_time: 0.1023  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:50:29 d2.utils.events]: \u001b[0m eta: 0:37:42  iter: 5519  total_loss: 1.338  loss_cls: 0.3318  loss_box_reg: 0.5667  loss_mask: 0.3096  loss_rpn_cls: 0.03765  loss_rpn_loc: 0.06812  time: 0.6661  data_time: 0.2646  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:50:41 d2.utils.events]: \u001b[0m eta: 0:37:27  iter: 5539  total_loss: 1.235  loss_cls: 0.3105  loss_box_reg: 0.5429  loss_mask: 0.2923  loss_rpn_cls: 0.03776  loss_rpn_loc: 0.07123  time: 0.6658  data_time: 0.1168  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:50:53 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 5559  total_loss: 1.247  loss_cls: 0.2971  loss_box_reg: 0.522  loss_mask: 0.2978  loss_rpn_cls: 0.03482  loss_rpn_loc: 0.06245  time: 0.6656  data_time: 0.1240  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:50:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:50:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:50:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:50:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:50:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:50:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0866 s/iter. Eval: 0.0538 s/iter. Total: 0.1411 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0721 s/iter. Total: 0.1612 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 14:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0731 s/iter. Total: 0.1620 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 14:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0771 s/iter. Total: 0.1663 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:51:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.174536 (0.165298 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:51:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088159 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:51:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:51:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26952791512892454\n",
      "\u001b[32m[02/05 14:51:26 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 5579  total_loss: 1.292  loss_cls: 0.3118  loss_box_reg: 0.555  loss_mask: 0.2891  loss_rpn_cls: 0.02917  loss_rpn_loc: 0.05024  time: 0.6655  data_time: 0.1615  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:51:41 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 5599  total_loss: 1.33  loss_cls: 0.3397  loss_box_reg: 0.5418  loss_mask: 0.2975  loss_rpn_cls: 0.04673  loss_rpn_loc: 0.09689  time: 0.6656  data_time: 0.2322  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:51:54 d2.utils.events]: \u001b[0m eta: 0:36:44  iter: 5619  total_loss: 1.245  loss_cls: 0.3039  loss_box_reg: 0.54  loss_mask: 0.2889  loss_rpn_cls: 0.04486  loss_rpn_loc: 0.06544  time: 0.6657  data_time: 0.1996  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:52:10 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 5639  total_loss: 1.324  loss_cls: 0.3334  loss_box_reg: 0.5614  loss_mask: 0.3205  loss_rpn_cls: 0.05006  loss_rpn_loc: 0.08043  time: 0.6661  data_time: 0.3181  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:52:23 d2.utils.events]: \u001b[0m eta: 0:36:23  iter: 5659  total_loss: 1.183  loss_cls: 0.274  loss_box_reg: 0.511  loss_mask: 0.2696  loss_rpn_cls: 0.02341  loss_rpn_loc: 0.04522  time: 0.6660  data_time: 0.1587  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:52:35 d2.utils.events]: \u001b[0m eta: 0:36:12  iter: 5679  total_loss: 1.209  loss_cls: 0.3152  loss_box_reg: 0.5293  loss_mask: 0.2862  loss_rpn_cls: 0.03206  loss_rpn_loc: 0.06305  time: 0.6659  data_time: 0.1652  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:52:49 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 5699  total_loss: 1.379  loss_cls: 0.353  loss_box_reg: 0.5616  loss_mask: 0.2889  loss_rpn_cls: 0.05364  loss_rpn_loc: 0.08676  time: 0.6660  data_time: 0.2159  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:53:04 d2.utils.events]: \u001b[0m eta: 0:35:48  iter: 5719  total_loss: 1.326  loss_cls: 0.3427  loss_box_reg: 0.5551  loss_mask: 0.2956  loss_rpn_cls: 0.05731  loss_rpn_loc: 0.1101  time: 0.6662  data_time: 0.2388  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:53:16 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 5739  total_loss: 1.276  loss_cls: 0.3179  loss_box_reg: 0.569  loss_mask: 0.2944  loss_rpn_cls: 0.04594  loss_rpn_loc: 0.0684  time: 0.6660  data_time: 0.1659  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:53:32 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 5759  total_loss: 1.267  loss_cls: 0.3244  loss_box_reg: 0.5431  loss_mask: 0.276  loss_rpn_cls: 0.03914  loss_rpn_loc: 0.09331  time: 0.6664  data_time: 0.2736  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:53:45 d2.utils.events]: \u001b[0m eta: 0:35:21  iter: 5779  total_loss: 1.337  loss_cls: 0.3506  loss_box_reg: 0.5497  loss_mask: 0.297  loss_rpn_cls: 0.0583  loss_rpn_loc: 0.08885  time: 0.6665  data_time: 0.1900  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:53:59 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 5799  total_loss: 1.324  loss_cls: 0.3154  loss_box_reg: 0.5547  loss_mask: 0.2958  loss_rpn_cls: 0.06229  loss_rpn_loc: 0.1017  time: 0.6665  data_time: 0.2091  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:54:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:54:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:54:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:54:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:54:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:54:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0882 s/iter. Eval: 0.0557 s/iter. Total: 0.1446 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 14:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0919 s/iter. Eval: 0.0755 s/iter. Total: 0.1683 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 14:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0009 s/iter. Inference: 0.0912 s/iter. Eval: 0.0754 s/iter. Total: 0.1675 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 14:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0009 s/iter. Inference: 0.0913 s/iter. Eval: 0.0799 s/iter. Total: 0.1721 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 14:54:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.792652 (0.170626 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:54:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091124 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:54:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:54:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26591552377306077\n",
      "\u001b[32m[02/05 14:54:31 d2.utils.events]: \u001b[0m eta: 0:34:54  iter: 5819  total_loss: 1.257  loss_cls: 0.3228  loss_box_reg: 0.5376  loss_mask: 0.2848  loss_rpn_cls: 0.04807  loss_rpn_loc: 0.06708  time: 0.6661  data_time: 0.0672  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:54:42 d2.utils.events]: \u001b[0m eta: 0:34:39  iter: 5839  total_loss: 1.327  loss_cls: 0.3079  loss_box_reg: 0.5515  loss_mask: 0.3016  loss_rpn_cls: 0.03762  loss_rpn_loc: 0.06171  time: 0.6657  data_time: 0.0946  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:54:56 d2.utils.events]: \u001b[0m eta: 0:34:31  iter: 5859  total_loss: 1.345  loss_cls: 0.3513  loss_box_reg: 0.579  loss_mask: 0.3036  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.08782  time: 0.6657  data_time: 0.2055  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:55:11 d2.utils.events]: \u001b[0m eta: 0:34:21  iter: 5879  total_loss: 1.38  loss_cls: 0.3499  loss_box_reg: 0.5751  loss_mask: 0.3105  loss_rpn_cls: 0.06351  loss_rpn_loc: 0.09511  time: 0.6660  data_time: 0.2904  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:55:24 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 5899  total_loss: 1.305  loss_cls: 0.3415  loss_box_reg: 0.5326  loss_mask: 0.2842  loss_rpn_cls: 0.04305  loss_rpn_loc: 0.0979  time: 0.6660  data_time: 0.1771  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:55:36 d2.utils.events]: \u001b[0m eta: 0:34:05  iter: 5919  total_loss: 1.344  loss_cls: 0.336  loss_box_reg: 0.5644  loss_mask: 0.3014  loss_rpn_cls: 0.04824  loss_rpn_loc: 0.09981  time: 0.6658  data_time: 0.1213  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:55:51 d2.utils.events]: \u001b[0m eta: 0:33:49  iter: 5939  total_loss: 1.324  loss_cls: 0.334  loss_box_reg: 0.5457  loss_mask: 0.2879  loss_rpn_cls: 0.03624  loss_rpn_loc: 0.07109  time: 0.6660  data_time: 0.2500  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:56:08 d2.utils.events]: \u001b[0m eta: 0:33:40  iter: 5959  total_loss: 1.385  loss_cls: 0.3563  loss_box_reg: 0.5262  loss_mask: 0.311  loss_rpn_cls: 0.05822  loss_rpn_loc: 0.0961  time: 0.6667  data_time: 0.3995  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:56:20 d2.utils.events]: \u001b[0m eta: 0:33:29  iter: 5979  total_loss: 1.066  loss_cls: 0.2345  loss_box_reg: 0.5038  loss_mask: 0.2794  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.03261  time: 0.6663  data_time: 0.0846  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:56:36 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 5999  total_loss: 1.438  loss_cls: 0.3431  loss_box_reg: 0.5631  loss_mask: 0.3181  loss_rpn_cls: 0.0769  loss_rpn_loc: 0.1079  time: 0.6668  data_time: 0.3261  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:56:50 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 6019  total_loss: 1.328  loss_cls: 0.332  loss_box_reg: 0.5428  loss_mask: 0.2956  loss_rpn_cls: 0.04776  loss_rpn_loc: 0.09372  time: 0.6670  data_time: 0.2127  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:57:03 d2.utils.events]: \u001b[0m eta: 0:33:05  iter: 6039  total_loss: 1.293  loss_cls: 0.3105  loss_box_reg: 0.5211  loss_mask: 0.2869  loss_rpn_cls: 0.05445  loss_rpn_loc: 0.1042  time: 0.6668  data_time: 0.1170  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:57:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:57:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 14:57:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 14:57:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 14:57:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 14:57:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 14:57:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0919 s/iter. Eval: 0.0606 s/iter. Total: 0.1532 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 14:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0918 s/iter. Eval: 0.0753 s/iter. Total: 0.1680 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 14:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0922 s/iter. Eval: 0.0759 s/iter. Total: 0.1690 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 14:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0009 s/iter. Inference: 0.0927 s/iter. Eval: 0.0821 s/iter. Total: 0.1757 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 14:57:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.283002 (0.174853 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:57:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092921 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 14:57:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 14:57:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2723060958196876\n",
      "\u001b[32m[02/05 14:57:40 d2.utils.events]: \u001b[0m eta: 0:32:56  iter: 6059  total_loss: 1.326  loss_cls: 0.3395  loss_box_reg: 0.5406  loss_mask: 0.2982  loss_rpn_cls: 0.05131  loss_rpn_loc: 0.07992  time: 0.6671  data_time: 0.2583  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:57:53 d2.utils.events]: \u001b[0m eta: 0:32:46  iter: 6079  total_loss: 1.335  loss_cls: 0.3347  loss_box_reg: 0.5616  loss_mask: 0.2936  loss_rpn_cls: 0.05003  loss_rpn_loc: 0.07956  time: 0.6671  data_time: 0.1909  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:58:07 d2.utils.events]: \u001b[0m eta: 0:32:36  iter: 6099  total_loss: 1.345  loss_cls: 0.3335  loss_box_reg: 0.5545  loss_mask: 0.2989  loss_rpn_cls: 0.05451  loss_rpn_loc: 0.1041  time: 0.6672  data_time: 0.2070  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:58:22 d2.utils.events]: \u001b[0m eta: 0:32:26  iter: 6119  total_loss: 1.409  loss_cls: 0.3918  loss_box_reg: 0.5403  loss_mask: 0.2981  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.1077  time: 0.6675  data_time: 0.2451  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:58:33 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 6139  total_loss: 1.205  loss_cls: 0.2894  loss_box_reg: 0.5306  loss_mask: 0.277  loss_rpn_cls: 0.03718  loss_rpn_loc: 0.07332  time: 0.6671  data_time: 0.0700  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:58:47 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 6159  total_loss: 1.302  loss_cls: 0.3206  loss_box_reg: 0.5616  loss_mask: 0.3024  loss_rpn_cls: 0.03852  loss_rpn_loc: 0.07766  time: 0.6672  data_time: 0.1884  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:59:04 d2.utils.events]: \u001b[0m eta: 0:32:01  iter: 6179  total_loss: 1.436  loss_cls: 0.4007  loss_box_reg: 0.5538  loss_mask: 0.2933  loss_rpn_cls: 0.07753  loss_rpn_loc: 0.1034  time: 0.6677  data_time: 0.3274  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:59:17 d2.utils.events]: \u001b[0m eta: 0:31:50  iter: 6199  total_loss: 1.249  loss_cls: 0.3166  loss_box_reg: 0.5254  loss_mask: 0.291  loss_rpn_cls: 0.03202  loss_rpn_loc: 0.07446  time: 0.6678  data_time: 0.2218  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:59:31 d2.utils.events]: \u001b[0m eta: 0:31:36  iter: 6219  total_loss: 1.223  loss_cls: 0.3178  loss_box_reg: 0.5254  loss_mask: 0.2775  loss_rpn_cls: 0.051  loss_rpn_loc: 0.07436  time: 0.6679  data_time: 0.2189  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:59:43 d2.utils.events]: \u001b[0m eta: 0:31:29  iter: 6239  total_loss: 1.217  loss_cls: 0.2849  loss_box_reg: 0.5367  loss_mask: 0.2881  loss_rpn_cls: 0.02519  loss_rpn_loc: 0.05351  time: 0.6676  data_time: 0.1009  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 14:59:58 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 6259  total_loss: 1.371  loss_cls: 0.3366  loss_box_reg: 0.5566  loss_mask: 0.3067  loss_rpn_cls: 0.0449  loss_rpn_loc: 0.0715  time: 0.6679  data_time: 0.2680  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:00:10 d2.utils.events]: \u001b[0m eta: 0:31:10  iter: 6279  total_loss: 1.22  loss_cls: 0.33  loss_box_reg: 0.5214  loss_mask: 0.2725  loss_rpn_cls: 0.03972  loss_rpn_loc: 0.08031  time: 0.6676  data_time: 0.1163  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:00:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:00:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:00:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:00:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:00:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:00:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:00:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0887 s/iter. Eval: 0.0589 s/iter. Total: 0.1482 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 15:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0729 s/iter. Total: 0.1620 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 15:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0743 s/iter. Total: 0.1640 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 15:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0784 s/iter. Total: 0.1684 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:00:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.696558 (0.169798 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:00:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089766 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:00:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:00:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2713182304260853\n",
      "\u001b[32m[02/05 15:00:45 d2.utils.events]: \u001b[0m eta: 0:31:03  iter: 6299  total_loss: 1.304  loss_cls: 0.2936  loss_box_reg: 0.56  loss_mask: 0.2946  loss_rpn_cls: 0.03932  loss_rpn_loc: 0.08965  time: 0.6677  data_time: 0.2198  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:00:59 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 6319  total_loss: 1.388  loss_cls: 0.3475  loss_box_reg: 0.5501  loss_mask: 0.2985  loss_rpn_cls: 0.05709  loss_rpn_loc: 0.09339  time: 0.6677  data_time: 0.1717  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:01:13 d2.utils.events]: \u001b[0m eta: 0:30:43  iter: 6339  total_loss: 1.416  loss_cls: 0.3556  loss_box_reg: 0.5535  loss_mask: 0.3084  loss_rpn_cls: 0.05732  loss_rpn_loc: 0.1011  time: 0.6679  data_time: 0.2276  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:01:27 d2.utils.events]: \u001b[0m eta: 0:30:32  iter: 6359  total_loss: 1.272  loss_cls: 0.31  loss_box_reg: 0.5604  loss_mask: 0.3111  loss_rpn_cls: 0.03959  loss_rpn_loc: 0.06931  time: 0.6679  data_time: 0.1964  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:01:38 d2.utils.events]: \u001b[0m eta: 0:30:21  iter: 6379  total_loss: 1.241  loss_cls: 0.3175  loss_box_reg: 0.5275  loss_mask: 0.2862  loss_rpn_cls: 0.04528  loss_rpn_loc: 0.07333  time: 0.6676  data_time: 0.1076  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:01:50 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 6399  total_loss: 1.205  loss_cls: 0.3007  loss_box_reg: 0.5305  loss_mask: 0.2867  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.05081  time: 0.6674  data_time: 0.1123  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:02:02 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 6419  total_loss: 1.285  loss_cls: 0.298  loss_box_reg: 0.5389  loss_mask: 0.2845  loss_rpn_cls: 0.04626  loss_rpn_loc: 0.06795  time: 0.6672  data_time: 0.1371  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:02:17 d2.utils.events]: \u001b[0m eta: 0:29:48  iter: 6439  total_loss: 1.353  loss_cls: 0.3254  loss_box_reg: 0.5794  loss_mask: 0.301  loss_rpn_cls: 0.05192  loss_rpn_loc: 0.08385  time: 0.6674  data_time: 0.2696  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:02:31 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 6459  total_loss: 1.123  loss_cls: 0.27  loss_box_reg: 0.4975  loss_mask: 0.2755  loss_rpn_cls: 0.02761  loss_rpn_loc: 0.0666  time: 0.6675  data_time: 0.2091  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:02:46 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 6479  total_loss: 1.484  loss_cls: 0.3733  loss_box_reg: 0.5959  loss_mask: 0.3209  loss_rpn_cls: 0.08718  loss_rpn_loc: 0.1116  time: 0.6677  data_time: 0.2277  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:02:59 d2.utils.events]: \u001b[0m eta: 0:29:20  iter: 6499  total_loss: 1.274  loss_cls: 0.3212  loss_box_reg: 0.5481  loss_mask: 0.2933  loss_rpn_cls: 0.04474  loss_rpn_loc: 0.05465  time: 0.6677  data_time: 0.1544  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:03:13 d2.utils.events]: \u001b[0m eta: 0:29:10  iter: 6519  total_loss: 1.254  loss_cls: 0.3214  loss_box_reg: 0.5708  loss_mask: 0.3007  loss_rpn_cls: 0.0548  loss_rpn_loc: 0.07858  time: 0.6678  data_time: 0.2156  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:03:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:03:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:03:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:03:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:03:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:03:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0921 s/iter. Eval: 0.0596 s/iter. Total: 0.1524 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 15:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0926 s/iter. Eval: 0.0752 s/iter. Total: 0.1686 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0925 s/iter. Eval: 0.0748 s/iter. Total: 0.1681 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:03:40 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0938 s/iter. Eval: 0.0823 s/iter. Total: 0.1769 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 15:03:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.205319 (0.174184 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:03:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093115 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:03:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:03:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27317198553628785\n",
      "\u001b[32m[02/05 15:03:47 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 6539  total_loss: 1.271  loss_cls: 0.3112  loss_box_reg: 0.5501  loss_mask: 0.2861  loss_rpn_cls: 0.03283  loss_rpn_loc: 0.06367  time: 0.6677  data_time: 0.1306  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:04:01 d2.utils.events]: \u001b[0m eta: 0:28:52  iter: 6559  total_loss: 1.245  loss_cls: 0.3135  loss_box_reg: 0.5226  loss_mask: 0.2771  loss_rpn_cls: 0.05307  loss_rpn_loc: 0.09641  time: 0.6677  data_time: 0.1756  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:04:16 d2.utils.events]: \u001b[0m eta: 0:28:44  iter: 6579  total_loss: 1.402  loss_cls: 0.3596  loss_box_reg: 0.5615  loss_mask: 0.3016  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.1181  time: 0.6679  data_time: 0.2662  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:04:30 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 6599  total_loss: 1.316  loss_cls: 0.3277  loss_box_reg: 0.5442  loss_mask: 0.3029  loss_rpn_cls: 0.05382  loss_rpn_loc: 0.05543  time: 0.6680  data_time: 0.2378  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:04:41 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 6619  total_loss: 1.238  loss_cls: 0.302  loss_box_reg: 0.5295  loss_mask: 0.2853  loss_rpn_cls: 0.04741  loss_rpn_loc: 0.09414  time: 0.6677  data_time: 0.0887  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:04:56 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 6639  total_loss: 1.336  loss_cls: 0.3425  loss_box_reg: 0.5465  loss_mask: 0.3032  loss_rpn_cls: 0.05831  loss_rpn_loc: 0.1002  time: 0.6679  data_time: 0.2515  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:05:10 d2.utils.events]: \u001b[0m eta: 0:28:02  iter: 6659  total_loss: 1.353  loss_cls: 0.3462  loss_box_reg: 0.5612  loss_mask: 0.2962  loss_rpn_cls: 0.04143  loss_rpn_loc: 0.08437  time: 0.6681  data_time: 0.2324  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:05:22 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 6679  total_loss: 1.325  loss_cls: 0.3336  loss_box_reg: 0.5536  loss_mask: 0.2846  loss_rpn_cls: 0.04907  loss_rpn_loc: 0.09943  time: 0.6678  data_time: 0.1192  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:05:35 d2.utils.events]: \u001b[0m eta: 0:27:42  iter: 6699  total_loss: 1.172  loss_cls: 0.2813  loss_box_reg: 0.5057  loss_mask: 0.2846  loss_rpn_cls: 0.02875  loss_rpn_loc: 0.05122  time: 0.6678  data_time: 0.1842  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:05:47 d2.utils.events]: \u001b[0m eta: 0:27:32  iter: 6719  total_loss: 1.29  loss_cls: 0.3044  loss_box_reg: 0.538  loss_mask: 0.2947  loss_rpn_cls: 0.04737  loss_rpn_loc: 0.08786  time: 0.6676  data_time: 0.1323  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:06:00 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 6739  total_loss: 1.229  loss_cls: 0.302  loss_box_reg: 0.5633  loss_mask: 0.3001  loss_rpn_cls: 0.0275  loss_rpn_loc: 0.07675  time: 0.6675  data_time: 0.1407  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:06:12 d2.utils.events]: \u001b[0m eta: 0:27:16  iter: 6759  total_loss: 1.246  loss_cls: 0.3091  loss_box_reg: 0.5456  loss_mask: 0.2964  loss_rpn_cls: 0.03349  loss_rpn_loc: 0.05658  time: 0.6674  data_time: 0.1194  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:06:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:06:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:06:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:06:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:06:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:06:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:06:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0907 s/iter. Eval: 0.0572 s/iter. Total: 0.1486 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 15:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0742 s/iter. Total: 0.1655 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0915 s/iter. Eval: 0.0746 s/iter. Total: 0.1670 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0925 s/iter. Eval: 0.0812 s/iter. Total: 0.1746 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 15:06:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.063340 (0.172960 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:06:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092424 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:06:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:06:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27399682050360236\n",
      "\u001b[32m[02/05 15:06:50 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 6779  total_loss: 1.328  loss_cls: 0.3395  loss_box_reg: 0.5473  loss_mask: 0.3065  loss_rpn_cls: 0.04094  loss_rpn_loc: 0.07566  time: 0.6677  data_time: 0.2877  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:07:01 d2.utils.events]: \u001b[0m eta: 0:26:56  iter: 6799  total_loss: 1.279  loss_cls: 0.304  loss_box_reg: 0.5524  loss_mask: 0.3002  loss_rpn_cls: 0.03503  loss_rpn_loc: 0.05321  time: 0.6673  data_time: 0.0516  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:07:18 d2.utils.events]: \u001b[0m eta: 0:26:49  iter: 6819  total_loss: 1.332  loss_cls: 0.3238  loss_box_reg: 0.5537  loss_mask: 0.3064  loss_rpn_cls: 0.05391  loss_rpn_loc: 0.09575  time: 0.6678  data_time: 0.3385  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:07:31 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 6839  total_loss: 1.273  loss_cls: 0.3258  loss_box_reg: 0.5406  loss_mask: 0.274  loss_rpn_cls: 0.04177  loss_rpn_loc: 0.08756  time: 0.6678  data_time: 0.1405  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:07:46 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 6859  total_loss: 1.29  loss_cls: 0.316  loss_box_reg: 0.5527  loss_mask: 0.3013  loss_rpn_cls: 0.05042  loss_rpn_loc: 0.07699  time: 0.6681  data_time: 0.2546  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:07:59 d2.utils.events]: \u001b[0m eta: 0:26:27  iter: 6879  total_loss: 1.328  loss_cls: 0.319  loss_box_reg: 0.5354  loss_mask: 0.2827  loss_rpn_cls: 0.03949  loss_rpn_loc: 0.08563  time: 0.6681  data_time: 0.1569  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:08:15 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 6899  total_loss: 1.337  loss_cls: 0.3295  loss_box_reg: 0.5338  loss_mask: 0.2835  loss_rpn_cls: 0.05368  loss_rpn_loc: 0.104  time: 0.6685  data_time: 0.3039  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:08:29 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 6919  total_loss: 1.373  loss_cls: 0.35  loss_box_reg: 0.5596  loss_mask: 0.291  loss_rpn_cls: 0.05921  loss_rpn_loc: 0.08854  time: 0.6685  data_time: 0.1920  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:08:43 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 6939  total_loss: 1.223  loss_cls: 0.2859  loss_box_reg: 0.5531  loss_mask: 0.3093  loss_rpn_cls: 0.0465  loss_rpn_loc: 0.05278  time: 0.6686  data_time: 0.1904  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:08:59 d2.utils.events]: \u001b[0m eta: 0:25:47  iter: 6959  total_loss: 1.414  loss_cls: 0.3627  loss_box_reg: 0.5697  loss_mask: 0.3005  loss_rpn_cls: 0.0511  loss_rpn_loc: 0.1074  time: 0.6690  data_time: 0.3263  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:09:11 d2.utils.events]: \u001b[0m eta: 0:25:38  iter: 6979  total_loss: 1.187  loss_cls: 0.2733  loss_box_reg: 0.5059  loss_mask: 0.284  loss_rpn_cls: 0.02529  loss_rpn_loc: 0.037  time: 0.6687  data_time: 0.1042  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:09:24 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 6999  total_loss: 1.36  loss_cls: 0.3406  loss_box_reg: 0.5619  loss_mask: 0.3003  loss_rpn_cls: 0.06149  loss_rpn_loc: 0.09669  time: 0.6688  data_time: 0.2065  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:09:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:09:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:09:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:09:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:09:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:09:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0588 s/iter. Total: 0.1480 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 15:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0718 s/iter. Total: 0.1619 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 15:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0722 s/iter. Total: 0.1618 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 15:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0762 s/iter. Total: 0.1659 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:09:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.229108 (0.165768 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:09:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088880 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:09:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:09:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27408902503013566\n",
      "\u001b[32m[02/05 15:09:57 d2.utils.events]: \u001b[0m eta: 0:25:13  iter: 7019  total_loss: 1.172  loss_cls: 0.2901  loss_box_reg: 0.5339  loss_mask: 0.2832  loss_rpn_cls: 0.04159  loss_rpn_loc: 0.05272  time: 0.6684  data_time: 0.0849  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:10:09 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 7039  total_loss: 1.323  loss_cls: 0.3394  loss_box_reg: 0.5436  loss_mask: 0.3017  loss_rpn_cls: 0.04415  loss_rpn_loc: 0.08354  time: 0.6683  data_time: 0.1429  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:10:21 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 7059  total_loss: 1.373  loss_cls: 0.3469  loss_box_reg: 0.5888  loss_mask: 0.309  loss_rpn_cls: 0.04239  loss_rpn_loc: 0.07354  time: 0.6682  data_time: 0.1452  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:10:33 d2.utils.events]: \u001b[0m eta: 0:24:37  iter: 7079  total_loss: 1.205  loss_cls: 0.3097  loss_box_reg: 0.5303  loss_mask: 0.2817  loss_rpn_cls: 0.03836  loss_rpn_loc: 0.06264  time: 0.6679  data_time: 0.0828  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:10:45 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 7099  total_loss: 1.26  loss_cls: 0.3312  loss_box_reg: 0.5354  loss_mask: 0.2922  loss_rpn_cls: 0.04614  loss_rpn_loc: 0.08672  time: 0.6678  data_time: 0.1654  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:11:00 d2.utils.events]: \u001b[0m eta: 0:24:16  iter: 7119  total_loss: 1.268  loss_cls: 0.3147  loss_box_reg: 0.5174  loss_mask: 0.2909  loss_rpn_cls: 0.04647  loss_rpn_loc: 0.07995  time: 0.6680  data_time: 0.2490  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:11:16 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 7139  total_loss: 1.47  loss_cls: 0.3677  loss_box_reg: 0.5767  loss_mask: 0.3125  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.1147  time: 0.6684  data_time: 0.3005  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:11:31 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 7159  total_loss: 1.266  loss_cls: 0.3166  loss_box_reg: 0.5456  loss_mask: 0.2932  loss_rpn_cls: 0.04053  loss_rpn_loc: 0.06808  time: 0.6685  data_time: 0.2200  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:11:43 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 7179  total_loss: 1.204  loss_cls: 0.2859  loss_box_reg: 0.5143  loss_mask: 0.2916  loss_rpn_cls: 0.03061  loss_rpn_loc: 0.04566  time: 0.6684  data_time: 0.1454  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:12:01 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 7199  total_loss: 1.45  loss_cls: 0.3601  loss_box_reg: 0.5705  loss_mask: 0.3085  loss_rpn_cls: 0.06592  loss_rpn_loc: 0.1114  time: 0.6690  data_time: 0.3583  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:12:13 d2.utils.events]: \u001b[0m eta: 0:23:24  iter: 7219  total_loss: 1.073  loss_cls: 0.2504  loss_box_reg: 0.4942  loss_mask: 0.2656  loss_rpn_cls: 0.02195  loss_rpn_loc: 0.05571  time: 0.6688  data_time: 0.1315  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:12:26 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 7239  total_loss: 1.356  loss_cls: 0.3247  loss_box_reg: 0.5413  loss_mask: 0.2978  loss_rpn_cls: 0.05203  loss_rpn_loc: 0.08243  time: 0.6687  data_time: 0.1327  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:12:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:12:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:12:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:12:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:12:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:12:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0922 s/iter. Eval: 0.0633 s/iter. Total: 0.1562 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 15:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0742 s/iter. Total: 0.1663 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0901 s/iter. Eval: 0.0737 s/iter. Total: 0.1646 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0798 s/iter. Total: 0.1717 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:13:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.783653 (0.170549 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:13:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091082 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:13:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:13:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27157332719908917\n",
      "\u001b[32m[02/05 15:13:02 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 7259  total_loss: 1.31  loss_cls: 0.33  loss_box_reg: 0.5334  loss_mask: 0.2834  loss_rpn_cls: 0.03838  loss_rpn_loc: 0.1019  time: 0.6689  data_time: 0.2316  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:13:16 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 7279  total_loss: 1.327  loss_cls: 0.3176  loss_box_reg: 0.5465  loss_mask: 0.2937  loss_rpn_cls: 0.05794  loss_rpn_loc: 0.08915  time: 0.6689  data_time: 0.1931  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:13:31 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 7299  total_loss: 1.275  loss_cls: 0.3079  loss_box_reg: 0.5536  loss_mask: 0.2978  loss_rpn_cls: 0.05561  loss_rpn_loc: 0.08478  time: 0.6692  data_time: 0.2848  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:13:45 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 7319  total_loss: 1.294  loss_cls: 0.3213  loss_box_reg: 0.5381  loss_mask: 0.2831  loss_rpn_cls: 0.0504  loss_rpn_loc: 0.1039  time: 0.6693  data_time: 0.1823  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:13:56 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 7339  total_loss: 1.258  loss_cls: 0.3183  loss_box_reg: 0.5292  loss_mask: 0.2813  loss_rpn_cls: 0.03411  loss_rpn_loc: 0.05435  time: 0.6690  data_time: 0.0856  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:14:12 d2.utils.events]: \u001b[0m eta: 0:22:17  iter: 7359  total_loss: 1.324  loss_cls: 0.3191  loss_box_reg: 0.5287  loss_mask: 0.3097  loss_rpn_cls: 0.05083  loss_rpn_loc: 0.0994  time: 0.6693  data_time: 0.3041  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:14:25 d2.utils.events]: \u001b[0m eta: 0:22:09  iter: 7379  total_loss: 1.262  loss_cls: 0.3047  loss_box_reg: 0.5506  loss_mask: 0.2996  loss_rpn_cls: 0.05607  loss_rpn_loc: 0.07033  time: 0.6692  data_time: 0.1524  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:14:38 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 7399  total_loss: 1.348  loss_cls: 0.3379  loss_box_reg: 0.5491  loss_mask: 0.2863  loss_rpn_cls: 0.04633  loss_rpn_loc: 0.1116  time: 0.6692  data_time: 0.1648  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:14:49 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 7419  total_loss: 1.296  loss_cls: 0.3411  loss_box_reg: 0.5575  loss_mask: 0.2843  loss_rpn_cls: 0.05219  loss_rpn_loc: 0.09576  time: 0.6689  data_time: 0.0858  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:15:04 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 7439  total_loss: 1.264  loss_cls: 0.3127  loss_box_reg: 0.5321  loss_mask: 0.2862  loss_rpn_cls: 0.05346  loss_rpn_loc: 0.08043  time: 0.6690  data_time: 0.2285  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:15:14 d2.utils.events]: \u001b[0m eta: 0:21:32  iter: 7459  total_loss: 1.28  loss_cls: 0.3071  loss_box_reg: 0.5501  loss_mask: 0.2967  loss_rpn_cls: 0.02857  loss_rpn_loc: 0.06863  time: 0.6687  data_time: 0.0680  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:15:28 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 7479  total_loss: 1.355  loss_cls: 0.3449  loss_box_reg: 0.5813  loss_mask: 0.32  loss_rpn_cls: 0.05152  loss_rpn_loc: 0.1006  time: 0.6687  data_time: 0.1743  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:15:43 d2.utils.events]: \u001b[0m eta: 0:21:07  iter: 7499  total_loss: 1.206  loss_cls: 0.3141  loss_box_reg: 0.504  loss_mask: 0.2691  loss_rpn_cls: 0.05029  loss_rpn_loc: 0.08113  time: 0.6690  data_time: 0.2840  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:15:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:15:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:15:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:15:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:15:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:15:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:15:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0905 s/iter. Eval: 0.0671 s/iter. Total: 0.1582 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 15:15:53 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0743 s/iter. Total: 0.1637 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 15:15:58 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0743 s/iter. Total: 0.1634 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 15:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0897 s/iter. Eval: 0.0811 s/iter. Total: 0.1716 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:16:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.890900 (0.171473 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:16:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090372 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:16:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:16:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27211385912322666\n",
      "\u001b[32m[02/05 15:16:21 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 7519  total_loss: 1.343  loss_cls: 0.341  loss_box_reg: 0.5423  loss_mask: 0.2943  loss_rpn_cls: 0.04245  loss_rpn_loc: 0.08317  time: 0.6693  data_time: 0.3182  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:16:36 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 7539  total_loss: 1.279  loss_cls: 0.3276  loss_box_reg: 0.5635  loss_mask: 0.2923  loss_rpn_cls: 0.05111  loss_rpn_loc: 0.09598  time: 0.6695  data_time: 0.2228  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:16:47 d2.utils.events]: \u001b[0m eta: 0:20:40  iter: 7559  total_loss: 1.277  loss_cls: 0.3019  loss_box_reg: 0.5309  loss_mask: 0.2787  loss_rpn_cls: 0.03598  loss_rpn_loc: 0.03874  time: 0.6692  data_time: 0.0855  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:17:00 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 7579  total_loss: 1.346  loss_cls: 0.3429  loss_box_reg: 0.5473  loss_mask: 0.2923  loss_rpn_cls: 0.04858  loss_rpn_loc: 0.09017  time: 0.6691  data_time: 0.1506  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:17:13 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 7599  total_loss: 1.356  loss_cls: 0.3435  loss_box_reg: 0.5492  loss_mask: 0.2921  loss_rpn_cls: 0.05476  loss_rpn_loc: 0.1092  time: 0.6691  data_time: 0.1570  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:17:28 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 7619  total_loss: 1.203  loss_cls: 0.2754  loss_box_reg: 0.5486  loss_mask: 0.2894  loss_rpn_cls: 0.03151  loss_rpn_loc: 0.06728  time: 0.6693  data_time: 0.2667  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:17:42 d2.utils.events]: \u001b[0m eta: 0:19:59  iter: 7639  total_loss: 1.25  loss_cls: 0.3151  loss_box_reg: 0.5497  loss_mask: 0.3001  loss_rpn_cls: 0.03454  loss_rpn_loc: 0.06611  time: 0.6694  data_time: 0.2160  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:17:56 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 7659  total_loss: 1.343  loss_cls: 0.341  loss_box_reg: 0.5521  loss_mask: 0.3105  loss_rpn_cls: 0.04899  loss_rpn_loc: 0.1058  time: 0.6695  data_time: 0.2107  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:18:10 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 7679  total_loss: 1.311  loss_cls: 0.3216  loss_box_reg: 0.5324  loss_mask: 0.2896  loss_rpn_cls: 0.03918  loss_rpn_loc: 0.09759  time: 0.6696  data_time: 0.2071  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:18:25 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 7699  total_loss: 1.304  loss_cls: 0.3243  loss_box_reg: 0.545  loss_mask: 0.2935  loss_rpn_cls: 0.05075  loss_rpn_loc: 0.1053  time: 0.6698  data_time: 0.2505  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:18:39 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 7719  total_loss: 1.369  loss_cls: 0.3556  loss_box_reg: 0.5573  loss_mask: 0.3026  loss_rpn_cls: 0.05575  loss_rpn_loc: 0.1028  time: 0.6698  data_time: 0.1637  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:18:53 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 7739  total_loss: 1.331  loss_cls: 0.3365  loss_box_reg: 0.5531  loss_mask: 0.2991  loss_rpn_cls: 0.03363  loss_rpn_loc: 0.06966  time: 0.6699  data_time: 0.2523  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:18:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:18:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:18:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:18:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:18:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:18:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0946 s/iter. Eval: 0.0740 s/iter. Total: 0.1694 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 15:19:04 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0773 s/iter. Total: 0.1689 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:19:09 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0915 s/iter. Eval: 0.0759 s/iter. Total: 0.1683 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0804 s/iter. Total: 0.1725 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:19:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.771227 (0.170442 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:19:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090451 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:19:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:19:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2680440164208667\n",
      "\u001b[32m[02/05 15:19:27 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 7759  total_loss: 1.29  loss_cls: 0.3404  loss_box_reg: 0.542  loss_mask: 0.2937  loss_rpn_cls: 0.03848  loss_rpn_loc: 0.06363  time: 0.6698  data_time: 0.1115  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:19:39 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 7779  total_loss: 1.086  loss_cls: 0.2623  loss_box_reg: 0.4859  loss_mask: 0.2806  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.04959  time: 0.6697  data_time: 0.1436  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:19:51 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 7799  total_loss: 1.267  loss_cls: 0.3237  loss_box_reg: 0.5391  loss_mask: 0.2983  loss_rpn_cls: 0.03821  loss_rpn_loc: 0.06234  time: 0.6695  data_time: 0.1144  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:20:05 d2.utils.events]: \u001b[0m eta: 0:18:31  iter: 7819  total_loss: 1.298  loss_cls: 0.318  loss_box_reg: 0.5457  loss_mask: 0.2826  loss_rpn_cls: 0.03677  loss_rpn_loc: 0.06987  time: 0.6695  data_time: 0.2055  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:20:21 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 7839  total_loss: 1.404  loss_cls: 0.348  loss_box_reg: 0.5547  loss_mask: 0.3077  loss_rpn_cls: 0.06898  loss_rpn_loc: 0.1087  time: 0.6698  data_time: 0.3100  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:20:33 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 7859  total_loss: 1.262  loss_cls: 0.3346  loss_box_reg: 0.5533  loss_mask: 0.3052  loss_rpn_cls: 0.04113  loss_rpn_loc: 0.08019  time: 0.6697  data_time: 0.1263  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:20:48 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 7879  total_loss: 1.33  loss_cls: 0.3357  loss_box_reg: 0.5499  loss_mask: 0.317  loss_rpn_cls: 0.06888  loss_rpn_loc: 0.1102  time: 0.6698  data_time: 0.2442  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:21:02 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 7899  total_loss: 1.267  loss_cls: 0.3077  loss_box_reg: 0.5256  loss_mask: 0.2847  loss_rpn_cls: 0.03917  loss_rpn_loc: 0.08093  time: 0.6699  data_time: 0.2464  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:21:16 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 7919  total_loss: 1.389  loss_cls: 0.3529  loss_box_reg: 0.5829  loss_mask: 0.3137  loss_rpn_cls: 0.04744  loss_rpn_loc: 0.1027  time: 0.6700  data_time: 0.1968  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:21:27 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 7939  total_loss: 1.228  loss_cls: 0.312  loss_box_reg: 0.5339  loss_mask: 0.2935  loss_rpn_cls: 0.03852  loss_rpn_loc: 0.0604  time: 0.6697  data_time: 0.0686  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:21:39 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 7959  total_loss: 1.284  loss_cls: 0.3133  loss_box_reg: 0.5538  loss_mask: 0.2913  loss_rpn_cls: 0.04741  loss_rpn_loc: 0.07146  time: 0.6695  data_time: 0.1013  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:21:53 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 7979  total_loss: 1.328  loss_cls: 0.3425  loss_box_reg: 0.5313  loss_mask: 0.2875  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.1056  time: 0.6697  data_time: 0.2681  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:21:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:21:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:21:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:21:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:21:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:21:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0786 s/iter. Total: 0.1698 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 15:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0764 s/iter. Total: 0.1661 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0756 s/iter. Total: 0.1646 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 15:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0793 s/iter. Total: 0.1688 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:22:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.569821 (0.168705 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:22:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088648 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:22:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:22:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.270343487089714\n",
      "\u001b[32m[02/05 15:22:31 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 7999  total_loss: 1.232  loss_cls: 0.2923  loss_box_reg: 0.5233  loss_mask: 0.2892  loss_rpn_cls: 0.03003  loss_rpn_loc: 0.078  time: 0.6701  data_time: 0.3363  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:22:44 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 8019  total_loss: 1.178  loss_cls: 0.2915  loss_box_reg: 0.5125  loss_mask: 0.2835  loss_rpn_cls: 0.03126  loss_rpn_loc: 0.06771  time: 0.6700  data_time: 0.1568  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:22:58 d2.utils.events]: \u001b[0m eta: 0:16:36  iter: 8039  total_loss: 1.227  loss_cls: 0.3063  loss_box_reg: 0.5172  loss_mask: 0.2853  loss_rpn_cls: 0.03701  loss_rpn_loc: 0.06898  time: 0.6700  data_time: 0.1857  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:23:12 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 8059  total_loss: 1.385  loss_cls: 0.3428  loss_box_reg: 0.5664  loss_mask: 0.306  loss_rpn_cls: 0.05411  loss_rpn_loc: 0.1036  time: 0.6701  data_time: 0.2229  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:23:23 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 8079  total_loss: 1.227  loss_cls: 0.3174  loss_box_reg: 0.5391  loss_mask: 0.2875  loss_rpn_cls: 0.03498  loss_rpn_loc: 0.04507  time: 0.6699  data_time: 0.0984  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:23:42 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 8099  total_loss: 1.356  loss_cls: 0.3565  loss_box_reg: 0.5373  loss_mask: 0.3084  loss_rpn_cls: 0.0681  loss_rpn_loc: 0.1031  time: 0.6705  data_time: 0.4553  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:23:59 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 8119  total_loss: 1.384  loss_cls: 0.3636  loss_box_reg: 0.557  loss_mask: 0.3103  loss_rpn_cls: 0.05599  loss_rpn_loc: 0.1037  time: 0.6709  data_time: 0.3411  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:24:13 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 8139  total_loss: 1.327  loss_cls: 0.3446  loss_box_reg: 0.5711  loss_mask: 0.3001  loss_rpn_cls: 0.0578  loss_rpn_loc: 0.1086  time: 0.6711  data_time: 0.2576  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:24:24 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 8159  total_loss: 1.069  loss_cls: 0.2619  loss_box_reg: 0.5152  loss_mask: 0.282  loss_rpn_cls: 0.0301  loss_rpn_loc: 0.03494  time: 0.6707  data_time: 0.0743  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:24:36 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 8179  total_loss: 1.226  loss_cls: 0.3183  loss_box_reg: 0.5252  loss_mask: 0.2664  loss_rpn_cls: 0.03344  loss_rpn_loc: 0.06277  time: 0.6706  data_time: 0.1310  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:24:49 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 8199  total_loss: 1.246  loss_cls: 0.3183  loss_box_reg: 0.529  loss_mask: 0.2884  loss_rpn_cls: 0.02508  loss_rpn_loc: 0.06148  time: 0.6706  data_time: 0.1706  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:25:02 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 8219  total_loss: 1.385  loss_cls: 0.3629  loss_box_reg: 0.5519  loss_mask: 0.2832  loss_rpn_cls: 0.05287  loss_rpn_loc: 0.09027  time: 0.6704  data_time: 0.1442  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:25:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:25:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:25:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:25:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:25:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:25:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0766 s/iter. Total: 0.1687 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 15:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.0893 s/iter. Eval: 0.0773 s/iter. Total: 0.1676 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0759 s/iter. Total: 0.1650 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 15:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0801 s/iter. Total: 0.1703 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:25:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.691569 (0.169755 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:25:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089216 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:25:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:25:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2741239110735849\n",
      "\u001b[32m[02/05 15:25:37 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 8239  total_loss: 1.357  loss_cls: 0.3407  loss_box_reg: 0.5536  loss_mask: 0.2974  loss_rpn_cls: 0.05389  loss_rpn_loc: 0.1087  time: 0.6705  data_time: 0.2079  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:25:51 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 8259  total_loss: 1.192  loss_cls: 0.2868  loss_box_reg: 0.5352  loss_mask: 0.296  loss_rpn_cls: 0.03908  loss_rpn_loc: 0.05885  time: 0.6706  data_time: 0.2028  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:26:07 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 8279  total_loss: 1.339  loss_cls: 0.3375  loss_box_reg: 0.5225  loss_mask: 0.2901  loss_rpn_cls: 0.06519  loss_rpn_loc: 0.1029  time: 0.6709  data_time: 0.2988  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:26:20 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 8299  total_loss: 1.364  loss_cls: 0.3387  loss_box_reg: 0.5555  loss_mask: 0.3012  loss_rpn_cls: 0.04711  loss_rpn_loc: 0.1039  time: 0.6708  data_time: 0.1734  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:26:32 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 8319  total_loss: 1.318  loss_cls: 0.3138  loss_box_reg: 0.5596  loss_mask: 0.3054  loss_rpn_cls: 0.04013  loss_rpn_loc: 0.06838  time: 0.6706  data_time: 0.0879  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:26:45 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 8339  total_loss: 1.332  loss_cls: 0.3532  loss_box_reg: 0.533  loss_mask: 0.2847  loss_rpn_cls: 0.05714  loss_rpn_loc: 0.0954  time: 0.6706  data_time: 0.1932  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:26:57 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 8359  total_loss: 1.387  loss_cls: 0.3297  loss_box_reg: 0.5743  loss_mask: 0.3077  loss_rpn_cls: 0.0516  loss_rpn_loc: 0.09736  time: 0.6705  data_time: 0.1362  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:27:10 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 8379  total_loss: 1.34  loss_cls: 0.3367  loss_box_reg: 0.5482  loss_mask: 0.2886  loss_rpn_cls: 0.06973  loss_rpn_loc: 0.101  time: 0.6704  data_time: 0.1584  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:27:24 d2.utils.events]: \u001b[0m eta: 0:13:30  iter: 8399  total_loss: 1.343  loss_cls: 0.3304  loss_box_reg: 0.5504  loss_mask: 0.2988  loss_rpn_cls: 0.04364  loss_rpn_loc: 0.08007  time: 0.6704  data_time: 0.2091  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:27:36 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 8419  total_loss: 1.257  loss_cls: 0.2977  loss_box_reg: 0.5325  loss_mask: 0.2874  loss_rpn_cls: 0.04193  loss_rpn_loc: 0.06207  time: 0.6702  data_time: 0.1302  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:27:49 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 8439  total_loss: 1.292  loss_cls: 0.338  loss_box_reg: 0.5214  loss_mask: 0.2934  loss_rpn_cls: 0.05787  loss_rpn_loc: 0.1005  time: 0.6702  data_time: 0.1824  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:28:03 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 8459  total_loss: 1.317  loss_cls: 0.3268  loss_box_reg: 0.5215  loss_mask: 0.2959  loss_rpn_cls: 0.053  loss_rpn_loc: 0.09619  time: 0.6703  data_time: 0.2284  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:28:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:28:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:28:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:28:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:28:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:28:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0982 s/iter. Eval: 0.0715 s/iter. Total: 0.1705 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 15:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0008 s/iter. Inference: 0.0955 s/iter. Eval: 0.0821 s/iter. Total: 0.1785 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 15:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0922 s/iter. Eval: 0.0781 s/iter. Total: 0.1711 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0916 s/iter. Eval: 0.0830 s/iter. Total: 0.1754 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 15:28:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.014597 (0.172540 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:28:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090984 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:28:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:28:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27253974411069626\n",
      "\u001b[32m[02/05 15:28:39 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 8479  total_loss: 1.222  loss_cls: 0.3096  loss_box_reg: 0.5092  loss_mask: 0.2782  loss_rpn_cls: 0.03587  loss_rpn_loc: 0.06739  time: 0.6703  data_time: 0.1855  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:28:55 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 8499  total_loss: 1.307  loss_cls: 0.3004  loss_box_reg: 0.5509  loss_mask: 0.3007  loss_rpn_cls: 0.05168  loss_rpn_loc: 0.07654  time: 0.6707  data_time: 0.3399  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:29:09 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 8519  total_loss: 1.425  loss_cls: 0.3547  loss_box_reg: 0.5893  loss_mask: 0.304  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.0896  time: 0.6708  data_time: 0.2062  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:29:23 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 8539  total_loss: 1.253  loss_cls: 0.3158  loss_box_reg: 0.528  loss_mask: 0.2832  loss_rpn_cls: 0.04754  loss_rpn_loc: 0.09755  time: 0.6709  data_time: 0.1973  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:29:38 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 8559  total_loss: 1.38  loss_cls: 0.3485  loss_box_reg: 0.5658  loss_mask: 0.3084  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.101  time: 0.6710  data_time: 0.2103  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:29:54 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 8579  total_loss: 1.266  loss_cls: 0.3196  loss_box_reg: 0.508  loss_mask: 0.2823  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.08507  time: 0.6713  data_time: 0.3196  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:30:05 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 8599  total_loss: 1.263  loss_cls: 0.3109  loss_box_reg: 0.5362  loss_mask: 0.2961  loss_rpn_cls: 0.03054  loss_rpn_loc: 0.07152  time: 0.6710  data_time: 0.0538  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:30:16 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 8619  total_loss: 1.201  loss_cls: 0.292  loss_box_reg: 0.5332  loss_mask: 0.2896  loss_rpn_cls: 0.04128  loss_rpn_loc: 0.06659  time: 0.6707  data_time: 0.1150  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:30:30 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 8639  total_loss: 1.331  loss_cls: 0.3229  loss_box_reg: 0.5408  loss_mask: 0.2972  loss_rpn_cls: 0.04184  loss_rpn_loc: 0.08173  time: 0.6708  data_time: 0.2184  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:30:42 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 8659  total_loss: 1.272  loss_cls: 0.3171  loss_box_reg: 0.5392  loss_mask: 0.2799  loss_rpn_cls: 0.03611  loss_rpn_loc: 0.06274  time: 0.6706  data_time: 0.0705  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:30:57 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 8679  total_loss: 1.329  loss_cls: 0.3365  loss_box_reg: 0.5377  loss_mask: 0.2867  loss_rpn_cls: 0.04643  loss_rpn_loc: 0.09628  time: 0.6709  data_time: 0.2920  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:31:13 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 8699  total_loss: 1.276  loss_cls: 0.3204  loss_box_reg: 0.5489  loss_mask: 0.2905  loss_rpn_cls: 0.0393  loss_rpn_loc: 0.08286  time: 0.6711  data_time: 0.2750  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:31:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:31:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:31:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:31:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:31:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:31:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0024 s/iter. Inference: 0.0954 s/iter. Eval: 0.0689 s/iter. Total: 0.1667 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 15:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0011 s/iter. Inference: 0.0916 s/iter. Eval: 0.0798 s/iter. Total: 0.1725 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0010 s/iter. Inference: 0.0905 s/iter. Eval: 0.0772 s/iter. Total: 0.1688 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0009 s/iter. Inference: 0.0911 s/iter. Eval: 0.0826 s/iter. Total: 0.1747 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 15:31:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.139887 (0.173620 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:31:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091824 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:31:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:31:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2704899212491054\n",
      "\u001b[32m[02/05 15:31:47 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 8719  total_loss: 1.332  loss_cls: 0.3324  loss_box_reg: 0.5658  loss_mask: 0.3053  loss_rpn_cls: 0.04587  loss_rpn_loc: 0.07308  time: 0.6710  data_time: 0.1354  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:32:04 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 8739  total_loss: 1.321  loss_cls: 0.3119  loss_box_reg: 0.5479  loss_mask: 0.3123  loss_rpn_cls: 0.0435  loss_rpn_loc: 0.07686  time: 0.6713  data_time: 0.3439  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:32:16 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 8759  total_loss: 1.187  loss_cls: 0.2988  loss_box_reg: 0.5301  loss_mask: 0.2831  loss_rpn_cls: 0.02908  loss_rpn_loc: 0.05444  time: 0.6712  data_time: 0.1481  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:32:32 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 8779  total_loss: 1.348  loss_cls: 0.3209  loss_box_reg: 0.5279  loss_mask: 0.288  loss_rpn_cls: 0.04481  loss_rpn_loc: 0.08879  time: 0.6715  data_time: 0.2826  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:32:45 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 8799  total_loss: 1.276  loss_cls: 0.3244  loss_box_reg: 0.5253  loss_mask: 0.2973  loss_rpn_cls: 0.04295  loss_rpn_loc: 0.0872  time: 0.6714  data_time: 0.1638  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:32:57 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 8819  total_loss: 1.329  loss_cls: 0.3429  loss_box_reg: 0.5507  loss_mask: 0.2804  loss_rpn_cls: 0.05129  loss_rpn_loc: 0.109  time: 0.6713  data_time: 0.1385  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:33:08 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 8839  total_loss: 1.252  loss_cls: 0.3039  loss_box_reg: 0.5589  loss_mask: 0.2925  loss_rpn_cls: 0.02856  loss_rpn_loc: 0.06047  time: 0.6710  data_time: 0.0768  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:33:25 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 8859  total_loss: 1.254  loss_cls: 0.301  loss_box_reg: 0.532  loss_mask: 0.3114  loss_rpn_cls: 0.03902  loss_rpn_loc: 0.06655  time: 0.6714  data_time: 0.3592  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:33:39 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 8879  total_loss: 1.318  loss_cls: 0.3101  loss_box_reg: 0.559  loss_mask: 0.2865  loss_rpn_cls: 0.04141  loss_rpn_loc: 0.08654  time: 0.6714  data_time: 0.1976  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:33:52 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 8899  total_loss: 1.337  loss_cls: 0.3402  loss_box_reg: 0.5226  loss_mask: 0.2888  loss_rpn_cls: 0.04728  loss_rpn_loc: 0.09696  time: 0.6714  data_time: 0.1617  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:34:03 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 8919  total_loss: 1.299  loss_cls: 0.3232  loss_box_reg: 0.5439  loss_mask: 0.2895  loss_rpn_cls: 0.05177  loss_rpn_loc: 0.07948  time: 0.6711  data_time: 0.0909  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:34:18 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 8939  total_loss: 1.305  loss_cls: 0.341  loss_box_reg: 0.5476  loss_mask: 0.2939  loss_rpn_cls: 0.06784  loss_rpn_loc: 0.1037  time: 0.6713  data_time: 0.2395  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:34:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:34:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:34:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:34:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:34:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:34:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:34:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0965 s/iter. Eval: 0.0748 s/iter. Total: 0.1721 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 15:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0921 s/iter. Eval: 0.0808 s/iter. Total: 0.1739 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 15:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0772 s/iter. Total: 0.1690 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0910 s/iter. Eval: 0.0822 s/iter. Total: 0.1740 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 15:34:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.028784 (0.172662 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:34:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091226 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:34:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:34:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26996392175366\n",
      "\u001b[32m[02/05 15:34:52 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 8959  total_loss: 1.219  loss_cls: 0.3001  loss_box_reg: 0.5317  loss_mask: 0.2873  loss_rpn_cls: 0.04001  loss_rpn_loc: 0.07734  time: 0.6712  data_time: 0.1668  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:35:03 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 8979  total_loss: 1.212  loss_cls: 0.2999  loss_box_reg: 0.5176  loss_mask: 0.2842  loss_rpn_cls: 0.03109  loss_rpn_loc: 0.04305  time: 0.6709  data_time: 0.0301  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:35:16 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 8999  total_loss: 1.29  loss_cls: 0.3182  loss_box_reg: 0.5291  loss_mask: 0.2808  loss_rpn_cls: 0.04003  loss_rpn_loc: 0.07034  time: 0.6708  data_time: 0.1800  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:35:30 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 9019  total_loss: 1.311  loss_cls: 0.3212  loss_box_reg: 0.5588  loss_mask: 0.2879  loss_rpn_cls: 0.04876  loss_rpn_loc: 0.09608  time: 0.6709  data_time: 0.2219  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:35:45 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 9039  total_loss: 1.365  loss_cls: 0.3292  loss_box_reg: 0.5475  loss_mask: 0.3034  loss_rpn_cls: 0.06061  loss_rpn_loc: 0.1115  time: 0.6710  data_time: 0.2281  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:35:58 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 9059  total_loss: 1.271  loss_cls: 0.3225  loss_box_reg: 0.5211  loss_mask: 0.2803  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.09028  time: 0.6710  data_time: 0.1757  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:36:10 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 9079  total_loss: 1.268  loss_cls: 0.3214  loss_box_reg: 0.5172  loss_mask: 0.2949  loss_rpn_cls: 0.03559  loss_rpn_loc: 0.0711  time: 0.6709  data_time: 0.1058  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:36:24 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 9099  total_loss: 1.294  loss_cls: 0.31  loss_box_reg: 0.534  loss_mask: 0.2948  loss_rpn_cls: 0.04208  loss_rpn_loc: 0.07989  time: 0.6709  data_time: 0.2359  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:36:40 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 9119  total_loss: 1.358  loss_cls: 0.3307  loss_box_reg: 0.5441  loss_mask: 0.3132  loss_rpn_cls: 0.05105  loss_rpn_loc: 0.09254  time: 0.6712  data_time: 0.3143  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:36:55 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 9139  total_loss: 1.331  loss_cls: 0.3377  loss_box_reg: 0.5782  loss_mask: 0.3129  loss_rpn_cls: 0.05057  loss_rpn_loc: 0.09965  time: 0.6713  data_time: 0.2663  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:37:11 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 9159  total_loss: 1.291  loss_cls: 0.3125  loss_box_reg: 0.5454  loss_mask: 0.2985  loss_rpn_cls: 0.04758  loss_rpn_loc: 0.08192  time: 0.6716  data_time: 0.2960  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:37:23 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 9179  total_loss: 1.239  loss_cls: 0.321  loss_box_reg: 0.535  loss_mask: 0.2939  loss_rpn_cls: 0.0495  loss_rpn_loc: 0.09604  time: 0.6715  data_time: 0.1577  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:37:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:37:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:37:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:37:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:37:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:37:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0936 s/iter. Eval: 0.0738 s/iter. Total: 0.1681 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 15:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0900 s/iter. Eval: 0.0812 s/iter. Total: 0.1720 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0009 s/iter. Inference: 0.0913 s/iter. Eval: 0.0790 s/iter. Total: 0.1711 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0922 s/iter. Eval: 0.0847 s/iter. Total: 0.1778 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 15:37:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.324374 (0.175210 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:37:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091439 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:37:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:37:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27156086832897314\n",
      "\u001b[32m[02/05 15:38:00 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 9199  total_loss: 1.212  loss_cls: 0.2984  loss_box_reg: 0.5132  loss_mask: 0.2784  loss_rpn_cls: 0.05346  loss_rpn_loc: 0.08949  time: 0.6717  data_time: 0.2520  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:38:10 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 9219  total_loss: 1.12  loss_cls: 0.2814  loss_box_reg: 0.5159  loss_mask: 0.284  loss_rpn_cls: 0.02243  loss_rpn_loc: 0.0573  time: 0.6713  data_time: 0.0647  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:38:23 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 9239  total_loss: 1.077  loss_cls: 0.2546  loss_box_reg: 0.4999  loss_mask: 0.267  loss_rpn_cls: 0.02174  loss_rpn_loc: 0.03144  time: 0.6713  data_time: 0.1760  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:38:36 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 9259  total_loss: 1.242  loss_cls: 0.3018  loss_box_reg: 0.5289  loss_mask: 0.2826  loss_rpn_cls: 0.04225  loss_rpn_loc: 0.07431  time: 0.6712  data_time: 0.1741  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:38:48 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 9279  total_loss: 1.243  loss_cls: 0.3325  loss_box_reg: 0.5334  loss_mask: 0.2944  loss_rpn_cls: 0.03838  loss_rpn_loc: 0.06698  time: 0.6711  data_time: 0.1346  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:39:02 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 9299  total_loss: 1.355  loss_cls: 0.3355  loss_box_reg: 0.5791  loss_mask: 0.3118  loss_rpn_cls: 0.05111  loss_rpn_loc: 0.08008  time: 0.6711  data_time: 0.1505  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:39:17 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 9319  total_loss: 1.324  loss_cls: 0.3465  loss_box_reg: 0.5344  loss_mask: 0.2779  loss_rpn_cls: 0.05581  loss_rpn_loc: 0.1013  time: 0.6713  data_time: 0.2473  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:39:32 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 9339  total_loss: 1.341  loss_cls: 0.3335  loss_box_reg: 0.5576  loss_mask: 0.2971  loss_rpn_cls: 0.06435  loss_rpn_loc: 0.1109  time: 0.6715  data_time: 0.2817  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:39:47 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 9359  total_loss: 1.322  loss_cls: 0.3321  loss_box_reg: 0.5398  loss_mask: 0.2883  loss_rpn_cls: 0.06583  loss_rpn_loc: 0.1021  time: 0.6716  data_time: 0.2123  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:39:58 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9379  total_loss: 1.322  loss_cls: 0.3244  loss_box_reg: 0.5651  loss_mask: 0.2931  loss_rpn_cls: 0.03581  loss_rpn_loc: 0.07291  time: 0.6714  data_time: 0.1147  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:40:12 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 9399  total_loss: 1.402  loss_cls: 0.3427  loss_box_reg: 0.5713  loss_mask: 0.3153  loss_rpn_cls: 0.05909  loss_rpn_loc: 0.103  time: 0.6714  data_time: 0.1828  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:40:25 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 9419  total_loss: 1.273  loss_cls: 0.3309  loss_box_reg: 0.5577  loss_mask: 0.2879  loss_rpn_cls: 0.05127  loss_rpn_loc: 0.09715  time: 0.6714  data_time: 0.1683  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:40:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:40:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:40:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:40:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:40:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:40:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0921 s/iter. Eval: 0.0683 s/iter. Total: 0.1611 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 15:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0779 s/iter. Total: 0.1697 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0758 s/iter. Total: 0.1661 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 15:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0796 s/iter. Total: 0.1699 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:40:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.678094 (0.169639 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:40:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089286 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:40:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:40:58 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27170383958949956\n",
      "\u001b[32m[02/05 15:41:00 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 9439  total_loss: 1.21  loss_cls: 0.3136  loss_box_reg: 0.5241  loss_mask: 0.2987  loss_rpn_cls: 0.03009  loss_rpn_loc: 0.0713  time: 0.6713  data_time: 0.1685  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:41:13 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 9459  total_loss: 1.235  loss_cls: 0.2842  loss_box_reg: 0.516  loss_mask: 0.2996  loss_rpn_cls: 0.03885  loss_rpn_loc: 0.06283  time: 0.6713  data_time: 0.1831  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:41:28 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 9479  total_loss: 1.245  loss_cls: 0.3118  loss_box_reg: 0.5234  loss_mask: 0.2924  loss_rpn_cls: 0.04504  loss_rpn_loc: 0.09038  time: 0.6714  data_time: 0.2388  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:41:40 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 9499  total_loss: 1.278  loss_cls: 0.3326  loss_box_reg: 0.5269  loss_mask: 0.2979  loss_rpn_cls: 0.03665  loss_rpn_loc: 0.07012  time: 0.6713  data_time: 0.1344  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:41:53 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 9519  total_loss: 1.244  loss_cls: 0.3065  loss_box_reg: 0.5292  loss_mask: 0.2886  loss_rpn_cls: 0.03623  loss_rpn_loc: 0.06982  time: 0.6713  data_time: 0.1619  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:42:03 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 9539  total_loss: 1.25  loss_cls: 0.3016  loss_box_reg: 0.528  loss_mask: 0.2876  loss_rpn_cls: 0.03477  loss_rpn_loc: 0.06913  time: 0.6709  data_time: 0.0509  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:42:17 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 9559  total_loss: 1.368  loss_cls: 0.3497  loss_box_reg: 0.5541  loss_mask: 0.3025  loss_rpn_cls: 0.0685  loss_rpn_loc: 0.1033  time: 0.6710  data_time: 0.2387  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:42:28 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 9579  total_loss: 1.35  loss_cls: 0.3292  loss_box_reg: 0.5447  loss_mask: 0.2938  loss_rpn_cls: 0.04659  loss_rpn_loc: 0.06026  time: 0.6707  data_time: 0.0838  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:42:42 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 9599  total_loss: 1.418  loss_cls: 0.3353  loss_box_reg: 0.5712  loss_mask: 0.3257  loss_rpn_cls: 0.04622  loss_rpn_loc: 0.102  time: 0.6708  data_time: 0.2007  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:42:56 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 9619  total_loss: 1.296  loss_cls: 0.3427  loss_box_reg: 0.5182  loss_mask: 0.2895  loss_rpn_cls: 0.05252  loss_rpn_loc: 0.09424  time: 0.6708  data_time: 0.2084  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:43:09 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 9639  total_loss: 1.26  loss_cls: 0.3135  loss_box_reg: 0.5167  loss_mask: 0.276  loss_rpn_cls: 0.03634  loss_rpn_loc: 0.07431  time: 0.6708  data_time: 0.1711  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:43:23 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 9659  total_loss: 1.258  loss_cls: 0.3186  loss_box_reg: 0.5112  loss_mask: 0.3044  loss_rpn_cls: 0.05491  loss_rpn_loc: 0.0958  time: 0.6709  data_time: 0.2569  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:43:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:43:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:43:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:43:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:43:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:43:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:43:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0903 s/iter. Eval: 0.0751 s/iter. Total: 0.1663 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 15:43:42 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0809 s/iter. Total: 0.1731 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 15:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0775 s/iter. Total: 0.1679 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0900 s/iter. Eval: 0.0824 s/iter. Total: 0.1733 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:43:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.867449 (0.171271 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:43:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089773 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:43:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:43:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27237280216493887\n",
      "\u001b[32m[02/05 15:43:56 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 9679  total_loss: 1.193  loss_cls: 0.2751  loss_box_reg: 0.5214  loss_mask: 0.2842  loss_rpn_cls: 0.02763  loss_rpn_loc: 0.06064  time: 0.6706  data_time: 0.0780  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:44:09 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 9699  total_loss: 1.413  loss_cls: 0.3582  loss_box_reg: 0.5627  loss_mask: 0.3059  loss_rpn_cls: 0.05718  loss_rpn_loc: 0.1039  time: 0.6706  data_time: 0.1918  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:44:24 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 9719  total_loss: 1.349  loss_cls: 0.3478  loss_box_reg: 0.5542  loss_mask: 0.2787  loss_rpn_cls: 0.04595  loss_rpn_loc: 0.09372  time: 0.6707  data_time: 0.2569  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:44:39 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 9739  total_loss: 1.237  loss_cls: 0.3081  loss_box_reg: 0.513  loss_mask: 0.278  loss_rpn_cls: 0.03765  loss_rpn_loc: 0.0635  time: 0.6709  data_time: 0.2805  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:44:50 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 9759  total_loss: 1.291  loss_cls: 0.3247  loss_box_reg: 0.5096  loss_mask: 0.2739  loss_rpn_cls: 0.04187  loss_rpn_loc: 0.09469  time: 0.6707  data_time: 0.1140  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:45:03 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 9779  total_loss: 1.188  loss_cls: 0.2881  loss_box_reg: 0.5106  loss_mask: 0.2967  loss_rpn_cls: 0.02601  loss_rpn_loc: 0.04584  time: 0.6706  data_time: 0.1488  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:45:17 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 9799  total_loss: 1.387  loss_cls: 0.3501  loss_box_reg: 0.5746  loss_mask: 0.3096  loss_rpn_cls: 0.04974  loss_rpn_loc: 0.09004  time: 0.6707  data_time: 0.2246  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:45:33 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 9819  total_loss: 1.322  loss_cls: 0.3219  loss_box_reg: 0.5427  loss_mask: 0.2728  loss_rpn_cls: 0.05419  loss_rpn_loc: 0.09905  time: 0.6709  data_time: 0.2702  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:45:47 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 9839  total_loss: 1.31  loss_cls: 0.3281  loss_box_reg: 0.5568  loss_mask: 0.2983  loss_rpn_cls: 0.05146  loss_rpn_loc: 0.09486  time: 0.6710  data_time: 0.2093  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:45:59 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 9859  total_loss: 1.235  loss_cls: 0.3058  loss_box_reg: 0.5401  loss_mask: 0.3021  loss_rpn_cls: 0.03562  loss_rpn_loc: 0.04286  time: 0.6709  data_time: 0.1086  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:46:11 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 9879  total_loss: 1.23  loss_cls: 0.3083  loss_box_reg: 0.5416  loss_mask: 0.2923  loss_rpn_cls: 0.04311  loss_rpn_loc: 0.07738  time: 0.6707  data_time: 0.0786  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:46:25 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 9899  total_loss: 1.374  loss_cls: 0.3376  loss_box_reg: 0.5486  loss_mask: 0.3171  loss_rpn_cls: 0.05917  loss_rpn_loc: 0.1087  time: 0.6708  data_time: 0.1964  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:46:44 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 9919  total_loss: 1.33  loss_cls: 0.3276  loss_box_reg: 0.5287  loss_mask: 0.3045  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.1055  time: 0.6714  data_time: 0.4068  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:46:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:46:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:46:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:46:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:46:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:46:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0013 s/iter. Inference: 0.0979 s/iter. Eval: 0.0761 s/iter. Total: 0.1752 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 15:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0011 s/iter. Inference: 0.0970 s/iter. Eval: 0.0827 s/iter. Total: 0.1809 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 15:46:59 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0010 s/iter. Inference: 0.0927 s/iter. Eval: 0.0783 s/iter. Total: 0.1721 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0009 s/iter. Inference: 0.0920 s/iter. Eval: 0.0831 s/iter. Total: 0.1761 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 15:47:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.034939 (0.172715 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:47:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091232 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:47:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:47:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2745998090131565\n",
      "\u001b[32m[02/05 15:47:18 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 9939  total_loss: 1.236  loss_cls: 0.3048  loss_box_reg: 0.5268  loss_mask: 0.2884  loss_rpn_cls: 0.03368  loss_rpn_loc: 0.07605  time: 0.6711  data_time: 0.0830  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:47:28 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 9959  total_loss: 1.192  loss_cls: 0.2915  loss_box_reg: 0.5362  loss_mask: 0.2884  loss_rpn_cls: 0.02386  loss_rpn_loc: 0.05113  time: 0.6708  data_time: 0.0638  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:47:42 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 9979  total_loss: 1.3  loss_cls: 0.3086  loss_box_reg: 0.5328  loss_mask: 0.2986  loss_rpn_cls: 0.04082  loss_rpn_loc: 0.05867  time: 0.6709  data_time: 0.2393  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:47:53 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.314  loss_cls: 0.337  loss_box_reg: 0.5495  loss_mask: 0.3022  loss_rpn_cls: 0.04572  loss_rpn_loc: 0.08868  time: 0.6707  data_time: 0.0811  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:47:53 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:51:45 (0.6707 s / it)\n",
      "\u001b[32m[02/05 15:47:53 d2.engine.hooks]: \u001b[0mTotal training time: 2:06:12 (0:14:26 on hooks)\n",
      "\u001b[32m[02/05 15:47:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:47:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:47:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:47:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:47:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:47:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0974 s/iter. Eval: 0.0779 s/iter. Total: 0.1761 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 15:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0009 s/iter. Inference: 0.0957 s/iter. Eval: 0.0936 s/iter. Total: 0.1902 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 15:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.0923 s/iter. Eval: 0.0839 s/iter. Total: 0.1772 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 15:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0009 s/iter. Inference: 0.0920 s/iter. Eval: 0.0870 s/iter. Total: 0.1799 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 15:48:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.433708 (0.176153 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:48:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091424 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:48:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:48:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2711644831379809\n"
     ]
    }
   ],
   "source": [
    "# changing only the anchor generator sizes\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16], [32], [64], [128], [256]]\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413dc08a-d0a6-4029-b735-f50a088dce02",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 15:52:21 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 15:52:22 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 15:52:23 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/05 15:52:23 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 15:52:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/05 15:52:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/05 15:52:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/05 15:52:24 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:52:24 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (20, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 15:52:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/05 15:52:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:52:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:52:43 d2.utils.events]: \u001b[0m eta: 1:21:07  iter: 19  total_loss: 2.919  loss_cls: 1.315  loss_box_reg: 0.01587  loss_mask: 0.6953  loss_rpn_cls: 0.6952  loss_rpn_loc: 0.1944  time: 0.9617  data_time: 0.2748  lr: 9.9905e-06  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:52:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:52:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:53:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:53:02 d2.utils.events]: \u001b[0m eta: 1:17:04  iter: 39  total_loss: 2.666  loss_cls: 1.107  loss_box_reg: 0.01558  loss_mask: 0.69  loss_rpn_cls: 0.6892  loss_rpn_loc: 0.1469  time: 0.9552  data_time: 0.2136  lr: 1.998e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:53:13 d2.utils.events]: \u001b[0m eta: 1:14:15  iter: 59  total_loss: 2.202  loss_cls: 0.6841  loss_box_reg: 0.0177  loss_mask: 0.6741  loss_rpn_cls: 0.6696  loss_rpn_loc: 0.1047  time: 0.8080  data_time: 0.0949  lr: 2.997e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:53:25 d2.utils.events]: \u001b[0m eta: 1:14:05  iter: 79  total_loss: 1.927  loss_cls: 0.449  loss_box_reg: 0.05513  loss_mask: 0.6497  loss_rpn_cls: 0.6369  loss_rpn_loc: 0.1229  time: 0.7565  data_time: 0.1659  lr: 3.9961e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:53:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:53:39 d2.utils.events]: \u001b[0m eta: 1:14:10  iter: 99  total_loss: 1.927  loss_cls: 0.4854  loss_box_reg: 0.1842  loss_mask: 0.6219  loss_rpn_cls: 0.568  loss_rpn_loc: 0.1017  time: 0.7387  data_time: 0.1129  lr: 4.9951e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:53:51 d2.utils.events]: \u001b[0m eta: 1:15:01  iter: 119  total_loss: 2.08  loss_cls: 0.6172  loss_box_reg: 0.3572  loss_mask: 0.5879  loss_rpn_cls: 0.475  loss_rpn_loc: 0.1244  time: 0.7187  data_time: 0.1323  lr: 5.9941e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:54:01 d2.utils.events]: \u001b[0m eta: 1:14:52  iter: 139  total_loss: 2.189  loss_cls: 0.6104  loss_box_reg: 0.4817  loss_mask: 0.5333  loss_rpn_cls: 0.3966  loss_rpn_loc: 0.1227  time: 0.6880  data_time: 0.0490  lr: 6.993e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:54:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:54:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:54:18 d2.utils.events]: \u001b[0m eta: 1:15:17  iter: 159  total_loss: 2.171  loss_cls: 0.6006  loss_box_reg: 0.4832  loss_mask: 0.5082  loss_rpn_cls: 0.3342  loss_rpn_loc: 0.1202  time: 0.7088  data_time: 0.2217  lr: 7.9921e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:54:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:54:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:54:40 d2.utils.events]: \u001b[0m eta: 1:16:03  iter: 179  total_loss: 2.125  loss_cls: 0.5797  loss_box_reg: 0.5422  loss_mask: 0.5098  loss_rpn_cls: 0.3654  loss_rpn_loc: 0.1826  time: 0.7544  data_time: 0.3741  lr: 8.991e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:54:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:54:57 d2.utils.events]: \u001b[0m eta: 1:18:12  iter: 199  total_loss: 2.103  loss_cls: 0.5667  loss_box_reg: 0.5223  loss_mask: 0.4627  loss_rpn_cls: 0.328  loss_rpn_loc: 0.1656  time: 0.7628  data_time: 0.2403  lr: 9.9901e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:55:09 d2.utils.events]: \u001b[0m eta: 1:18:44  iter: 219  total_loss: 1.906  loss_cls: 0.4903  loss_box_reg: 0.58  loss_mask: 0.4302  loss_rpn_cls: 0.2841  loss_rpn_loc: 0.1362  time: 0.7476  data_time: 0.0932  lr: 0.00010989  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:55:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:55:24 d2.utils.events]: \u001b[0m eta: 1:20:24  iter: 239  total_loss: 2.072  loss_cls: 0.5199  loss_box_reg: 0.6607  loss_mask: 0.4027  loss_rpn_cls: 0.3325  loss_rpn_loc: 0.1705  time: 0.7462  data_time: 0.1362  lr: 0.00011988  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:55:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:55:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:55:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:55:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:55:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:55:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0873 s/iter. Eval: 0.0063 s/iter. Total: 0.0942 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 15:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0007 s/iter. Inference: 0.0876 s/iter. Eval: 0.0074 s/iter. Total: 0.0958 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 15:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0007 s/iter. Inference: 0.0866 s/iter. Eval: 0.0068 s/iter. Total: 0.0942 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 15:55:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:10.943124 (0.094337 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:55:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086497 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:55:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:55:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.03673559406812308\n",
      "\u001b[32m[02/05 15:55:49 d2.utils.events]: \u001b[0m eta: 1:20:28  iter: 259  total_loss: 1.977  loss_cls: 0.481  loss_box_reg: 0.6396  loss_mask: 0.3923  loss_rpn_cls: 0.2741  loss_rpn_loc: 0.1489  time: 0.7382  data_time: 0.1443  lr: 0.00012987  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:56:01 d2.utils.events]: \u001b[0m eta: 1:20:18  iter: 279  total_loss: 1.829  loss_cls: 0.4258  loss_box_reg: 0.6847  loss_mask: 0.3498  loss_rpn_cls: 0.2066  loss_rpn_loc: 0.1023  time: 0.7281  data_time: 0.1115  lr: 0.00013986  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:56:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:56:19 d2.utils.events]: \u001b[0m eta: 1:20:28  iter: 299  total_loss: 1.963  loss_cls: 0.4259  loss_box_reg: 0.7102  loss_mask: 0.3513  loss_rpn_cls: 0.2942  loss_rpn_loc: 0.1635  time: 0.7417  data_time: 0.3055  lr: 0.00014985  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:56:30 d2.utils.events]: \u001b[0m eta: 1:20:06  iter: 319  total_loss: 1.67  loss_cls: 0.3523  loss_box_reg: 0.7596  loss_mask: 0.3336  loss_rpn_cls: 0.1826  loss_rpn_loc: 0.09669  time: 0.7288  data_time: 0.0652  lr: 0.00015984  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:56:44 d2.utils.events]: \u001b[0m eta: 1:19:59  iter: 339  total_loss: 1.768  loss_cls: 0.3941  loss_box_reg: 0.7348  loss_mask: 0.3222  loss_rpn_cls: 0.2049  loss_rpn_loc: 0.1061  time: 0.7253  data_time: 0.1714  lr: 0.00016983  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:56:57 d2.utils.events]: \u001b[0m eta: 1:20:10  iter: 359  total_loss: 1.824  loss_cls: 0.3788  loss_box_reg: 0.6929  loss_mask: 0.3243  loss_rpn_cls: 0.2355  loss_rpn_loc: 0.1467  time: 0.7209  data_time: 0.1338  lr: 0.00017982  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:57:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:57:13 d2.utils.events]: \u001b[0m eta: 1:20:31  iter: 379  total_loss: 1.746  loss_cls: 0.4088  loss_box_reg: 0.6634  loss_mask: 0.3216  loss_rpn_cls: 0.2076  loss_rpn_loc: 0.1148  time: 0.7252  data_time: 0.2354  lr: 0.00018981  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:57:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:57:26 d2.utils.events]: \u001b[0m eta: 1:20:21  iter: 399  total_loss: 1.596  loss_cls: 0.36  loss_box_reg: 0.6678  loss_mask: 0.3106  loss_rpn_cls: 0.1257  loss_rpn_loc: 0.07566  time: 0.7237  data_time: 0.1217  lr: 0.0001998  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:57:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:57:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:57:43 d2.utils.events]: \u001b[0m eta: 1:20:05  iter: 419  total_loss: 1.622  loss_cls: 0.3469  loss_box_reg: 0.6636  loss_mask: 0.3151  loss_rpn_cls: 0.142  loss_rpn_loc: 0.08159  time: 0.7296  data_time: 0.1982  lr: 0.00020979  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:57:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:57:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:58:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:58:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:58:09 d2.utils.events]: \u001b[0m eta: 1:20:16  iter: 439  total_loss: 1.75  loss_cls: 0.4233  loss_box_reg: 0.6458  loss_mask: 0.3321  loss_rpn_cls: 0.2411  loss_rpn_loc: 0.1766  time: 0.7553  data_time: 0.3555  lr: 0.00021978  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:58:23 d2.utils.events]: \u001b[0m eta: 1:20:09  iter: 459  total_loss: 1.648  loss_cls: 0.3712  loss_box_reg: 0.6328  loss_mask: 0.3047  loss_rpn_cls: 0.1883  loss_rpn_loc: 0.1348  time: 0.7514  data_time: 0.1529  lr: 0.00022977  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:58:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:58:36 d2.utils.events]: \u001b[0m eta: 1:20:04  iter: 479  total_loss: 1.651  loss_cls: 0.3729  loss_box_reg: 0.6755  loss_mask: 0.3107  loss_rpn_cls: 0.1335  loss_rpn_loc: 0.08314  time: 0.7487  data_time: 0.1255  lr: 0.00023976  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:58:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:58:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 15:58:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 15:58:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 15:58:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 15:58:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 15:58:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0912 s/iter. Eval: 0.0589 s/iter. Total: 0.1508 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 15:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0922 s/iter. Eval: 0.0752 s/iter. Total: 0.1682 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 15:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0925 s/iter. Eval: 0.0756 s/iter. Total: 0.1690 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 15:58:56 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0925 s/iter. Eval: 0.0794 s/iter. Total: 0.1728 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 15:59:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.827043 (0.170923 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:59:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092255 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 15:59:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 15:59:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.18672624483384065\n",
      "\u001b[32m[02/05 15:59:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:59:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:59:13 d2.utils.events]: \u001b[0m eta: 1:20:06  iter: 499  total_loss: 1.629  loss_cls: 0.3892  loss_box_reg: 0.6626  loss_mask: 0.3066  loss_rpn_cls: 0.1541  loss_rpn_loc: 0.1341  time: 0.7483  data_time: 0.0586  lr: 0.00024975  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:59:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:59:26 d2.utils.events]: \u001b[0m eta: 1:19:44  iter: 519  total_loss: 1.479  loss_cls: 0.3589  loss_box_reg: 0.6024  loss_mask: 0.3007  loss_rpn_cls: 0.1398  loss_rpn_loc: 0.1106  time: 0.7454  data_time: 0.1002  lr: 0.00025974  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:59:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 15:59:41 d2.utils.events]: \u001b[0m eta: 1:19:26  iter: 539  total_loss: 1.702  loss_cls: 0.403  loss_box_reg: 0.6474  loss_mask: 0.3179  loss_rpn_cls: 0.133  loss_rpn_loc: 0.0977  time: 0.7450  data_time: 0.1519  lr: 0.00026973  max_mem: 9526M\n",
      "\u001b[32m[02/05 15:59:54 d2.utils.events]: \u001b[0m eta: 1:19:19  iter: 559  total_loss: 1.587  loss_cls: 0.413  loss_box_reg: 0.6101  loss_mask: 0.323  loss_rpn_cls: 0.1516  loss_rpn_loc: 0.1317  time: 0.7422  data_time: 0.1597  lr: 0.00027972  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:00:08 d2.utils.events]: \u001b[0m eta: 1:19:13  iter: 579  total_loss: 1.503  loss_cls: 0.3597  loss_box_reg: 0.6159  loss_mask: 0.3027  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.1116  time: 0.7405  data_time: 0.1968  lr: 0.00028971  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:00:19 d2.utils.events]: \u001b[0m eta: 1:18:56  iter: 599  total_loss: 1.29  loss_cls: 0.3014  loss_box_reg: 0.5936  loss_mask: 0.3042  loss_rpn_cls: 0.05249  loss_rpn_loc: 0.05299  time: 0.7337  data_time: 0.0624  lr: 0.0002997  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:00:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:00:34 d2.utils.events]: \u001b[0m eta: 1:18:58  iter: 619  total_loss: 1.543  loss_cls: 0.3555  loss_box_reg: 0.6035  loss_mask: 0.3127  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.1061  time: 0.7346  data_time: 0.1569  lr: 0.00030969  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:00:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:00:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:00:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:00:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:01:00 d2.utils.events]: \u001b[0m eta: 1:19:02  iter: 639  total_loss: 1.558  loss_cls: 0.3957  loss_box_reg: 0.6132  loss_mask: 0.3039  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.1241  time: 0.7524  data_time: 0.3341  lr: 0.00031968  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:01:14 d2.utils.events]: \u001b[0m eta: 1:18:54  iter: 659  total_loss: 1.489  loss_cls: 0.3572  loss_box_reg: 0.5877  loss_mask: 0.3111  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.1148  time: 0.7512  data_time: 0.1955  lr: 0.00032967  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:01:27 d2.utils.events]: \u001b[0m eta: 1:18:53  iter: 679  total_loss: 1.518  loss_cls: 0.4013  loss_box_reg: 0.6054  loss_mask: 0.3201  loss_rpn_cls: 0.09433  loss_rpn_loc: 0.07822  time: 0.7483  data_time: 0.1299  lr: 0.00033966  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:01:40 d2.utils.events]: \u001b[0m eta: 1:18:41  iter: 699  total_loss: 1.463  loss_cls: 0.356  loss_box_reg: 0.6012  loss_mask: 0.3044  loss_rpn_cls: 0.08096  loss_rpn_loc: 0.06319  time: 0.7447  data_time: 0.1334  lr: 0.00034965  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:01:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:01:55 d2.utils.events]: \u001b[0m eta: 1:18:31  iter: 719  total_loss: 1.515  loss_cls: 0.3953  loss_box_reg: 0.5866  loss_mask: 0.3018  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.1154  time: 0.7453  data_time: 0.1605  lr: 0.00035964  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:02:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:02:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:02:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:02:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:02:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:02:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:02:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0902 s/iter. Eval: 0.0587 s/iter. Total: 0.1495 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 16:02:07 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0909 s/iter. Eval: 0.0745 s/iter. Total: 0.1662 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 16:02:12 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0738 s/iter. Total: 0.1650 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 16:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0780 s/iter. Total: 0.1694 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 16:02:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.586288 (0.168847 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:02:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090682 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:02:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:02:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.21614666841387786\n",
      "\u001b[32m[02/05 16:02:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:02:32 d2.utils.events]: \u001b[0m eta: 1:18:22  iter: 739  total_loss: 1.557  loss_cls: 0.4099  loss_box_reg: 0.619  loss_mask: 0.3054  loss_rpn_cls: 0.09516  loss_rpn_loc: 0.1209  time: 0.7458  data_time: 0.1710  lr: 0.00036963  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:02:48 d2.utils.events]: \u001b[0m eta: 1:18:16  iter: 759  total_loss: 1.569  loss_cls: 0.3917  loss_box_reg: 0.6125  loss_mask: 0.3227  loss_rpn_cls: 0.1326  loss_rpn_loc: 0.1185  time: 0.7481  data_time: 0.3003  lr: 0.00037962  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:03:05 d2.utils.events]: \u001b[0m eta: 1:18:23  iter: 779  total_loss: 1.534  loss_cls: 0.3905  loss_box_reg: 0.6145  loss_mask: 0.309  loss_rpn_cls: 0.1166  loss_rpn_loc: 0.1331  time: 0.7504  data_time: 0.3112  lr: 0.00038961  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:03:18 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 799  total_loss: 1.522  loss_cls: 0.4136  loss_box_reg: 0.6275  loss_mask: 0.3363  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.08835  time: 0.7475  data_time: 0.1344  lr: 0.0003996  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:03:29 d2.utils.events]: \u001b[0m eta: 1:17:49  iter: 819  total_loss: 1.278  loss_cls: 0.324  loss_box_reg: 0.569  loss_mask: 0.2821  loss_rpn_cls: 0.04959  loss_rpn_loc: 0.04839  time: 0.7426  data_time: 0.0784  lr: 0.00040959  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:03:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:03:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:03:47 d2.utils.events]: \u001b[0m eta: 1:17:44  iter: 839  total_loss: 1.509  loss_cls: 0.3802  loss_box_reg: 0.5803  loss_mask: 0.3111  loss_rpn_cls: 0.09918  loss_rpn_loc: 0.1341  time: 0.7466  data_time: 0.2026  lr: 0.00041958  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:03:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:04:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:04:04 d2.utils.events]: \u001b[0m eta: 1:17:34  iter: 859  total_loss: 1.443  loss_cls: 0.3688  loss_box_reg: 0.5955  loss_mask: 0.2987  loss_rpn_cls: 0.09126  loss_rpn_loc: 0.1198  time: 0.7489  data_time: 0.1403  lr: 0.00042957  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:04:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:04:18 d2.utils.events]: \u001b[0m eta: 1:17:27  iter: 879  total_loss: 1.532  loss_cls: 0.3862  loss_box_reg: 0.6314  loss_mask: 0.3057  loss_rpn_cls: 0.06323  loss_rpn_loc: 0.06724  time: 0.7483  data_time: 0.1383  lr: 0.00043956  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:04:33 d2.utils.events]: \u001b[0m eta: 1:17:20  iter: 899  total_loss: 1.474  loss_cls: 0.3753  loss_box_reg: 0.5972  loss_mask: 0.316  loss_rpn_cls: 0.08179  loss_rpn_loc: 0.1169  time: 0.7482  data_time: 0.2368  lr: 0.00044955  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:04:45 d2.utils.events]: \u001b[0m eta: 1:17:09  iter: 919  total_loss: 1.407  loss_cls: 0.3793  loss_box_reg: 0.5793  loss_mask: 0.2853  loss_rpn_cls: 0.05132  loss_rpn_loc: 0.06205  time: 0.7447  data_time: 0.1070  lr: 0.00045954  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:04:57 d2.utils.events]: \u001b[0m eta: 1:16:54  iter: 939  total_loss: 1.463  loss_cls: 0.3546  loss_box_reg: 0.5667  loss_mask: 0.3029  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.07119  time: 0.7411  data_time: 0.0957  lr: 0.00046953  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:05:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:05:13 d2.utils.events]: \u001b[0m eta: 1:16:42  iter: 959  total_loss: 1.383  loss_cls: 0.3695  loss_box_reg: 0.5426  loss_mask: 0.2856  loss_rpn_cls: 0.06423  loss_rpn_loc: 0.06565  time: 0.7425  data_time: 0.1990  lr: 0.00047952  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:05:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:05:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:05:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:05:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:05:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:05:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0875 s/iter. Eval: 0.0529 s/iter. Total: 0.1410 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0889 s/iter. Eval: 0.0689 s/iter. Total: 0.1586 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:05:29 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0890 s/iter. Eval: 0.0702 s/iter. Total: 0.1600 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0739 s/iter. Total: 0.1641 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 16:05:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.944625 (0.163316 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:05:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089278 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:05:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:05:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23631228835002885\n",
      "\u001b[32m[02/05 16:05:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:05:48 d2.utils.events]: \u001b[0m eta: 1:16:32  iter: 979  total_loss: 1.458  loss_cls: 0.3773  loss_box_reg: 0.605  loss_mask: 0.3021  loss_rpn_cls: 0.06941  loss_rpn_loc: 0.07002  time: 0.7419  data_time: 0.1071  lr: 0.00048951  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:05:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:06:04 d2.utils.events]: \u001b[0m eta: 1:16:28  iter: 999  total_loss: 1.551  loss_cls: 0.3999  loss_box_reg: 0.597  loss_mask: 0.3105  loss_rpn_cls: 0.09238  loss_rpn_loc: 0.109  time: 0.7438  data_time: 0.2116  lr: 0.0004995  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:06:17 d2.utils.events]: \u001b[0m eta: 1:16:19  iter: 1019  total_loss: 1.507  loss_cls: 0.3844  loss_box_reg: 0.593  loss_mask: 0.3089  loss_rpn_cls: 0.08472  loss_rpn_loc: 0.1252  time: 0.7419  data_time: 0.1419  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:06:30 d2.utils.events]: \u001b[0m eta: 1:16:19  iter: 1039  total_loss: 1.503  loss_cls: 0.4113  loss_box_reg: 0.6126  loss_mask: 0.3032  loss_rpn_cls: 0.08053  loss_rpn_loc: 0.07615  time: 0.7402  data_time: 0.1349  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:06:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:06:47 d2.utils.events]: \u001b[0m eta: 1:16:23  iter: 1059  total_loss: 1.558  loss_cls: 0.4058  loss_box_reg: 0.5927  loss_mask: 0.3156  loss_rpn_cls: 0.06997  loss_rpn_loc: 0.08421  time: 0.7419  data_time: 0.2104  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:06:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:07:01 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 1079  total_loss: 1.481  loss_cls: 0.4039  loss_box_reg: 0.5762  loss_mask: 0.2926  loss_rpn_cls: 0.08367  loss_rpn_loc: 0.09356  time: 0.7413  data_time: 0.1135  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:07:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:07:16 d2.utils.events]: \u001b[0m eta: 1:16:15  iter: 1099  total_loss: 1.416  loss_cls: 0.376  loss_box_reg: 0.5778  loss_mask: 0.2895  loss_rpn_cls: 0.06659  loss_rpn_loc: 0.07929  time: 0.7413  data_time: 0.1268  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:07:30 d2.utils.events]: \u001b[0m eta: 1:16:06  iter: 1119  total_loss: 1.451  loss_cls: 0.3779  loss_box_reg: 0.57  loss_mask: 0.3076  loss_rpn_cls: 0.07837  loss_rpn_loc: 0.09787  time: 0.7406  data_time: 0.1953  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:07:42 d2.utils.events]: \u001b[0m eta: 1:15:59  iter: 1139  total_loss: 1.353  loss_cls: 0.3782  loss_box_reg: 0.5594  loss_mask: 0.2946  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.07471  time: 0.7383  data_time: 0.1025  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:07:55 d2.utils.events]: \u001b[0m eta: 1:15:46  iter: 1159  total_loss: 1.367  loss_cls: 0.3655  loss_box_reg: 0.595  loss_mask: 0.3068  loss_rpn_cls: 0.0506  loss_rpn_loc: 0.08083  time: 0.7369  data_time: 0.1697  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:08:09 d2.utils.events]: \u001b[0m eta: 1:15:35  iter: 1179  total_loss: 1.448  loss_cls: 0.3683  loss_box_reg: 0.5502  loss_mask: 0.303  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.09079  time: 0.7359  data_time: 0.1829  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:08:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:08:22 d2.utils.events]: \u001b[0m eta: 1:15:17  iter: 1199  total_loss: 1.37  loss_cls: 0.3639  loss_box_reg: 0.5845  loss_mask: 0.2958  loss_rpn_cls: 0.05146  loss_rpn_loc: 0.06056  time: 0.7348  data_time: 0.0998  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:08:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:08:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:08:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:08:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:08:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:08:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:08:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:08:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:08:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0922 s/iter. Eval: 0.0519 s/iter. Total: 0.1448 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:08:44 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0927 s/iter. Eval: 0.0705 s/iter. Total: 0.1641 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 16:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0903 s/iter. Eval: 0.0690 s/iter. Total: 0.1602 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:08:54 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0728 s/iter. Total: 0.1643 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 16:08:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.916297 (0.163072 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:08:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090231 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:08:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:08:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2541260690427049\n",
      "\u001b[32m[02/05 16:09:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:09:06 d2.utils.events]: \u001b[0m eta: 1:15:13  iter: 1219  total_loss: 1.482  loss_cls: 0.382  loss_box_reg: 0.6024  loss_mask: 0.3109  loss_rpn_cls: 0.07204  loss_rpn_loc: 0.112  time: 0.7413  data_time: 0.2616  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:09:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:09:19 d2.utils.events]: \u001b[0m eta: 1:14:58  iter: 1239  total_loss: 1.326  loss_cls: 0.3411  loss_box_reg: 0.5836  loss_mask: 0.3094  loss_rpn_cls: 0.03906  loss_rpn_loc: 0.05206  time: 0.7405  data_time: 0.1170  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:09:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:09:36 d2.utils.events]: \u001b[0m eta: 1:14:53  iter: 1259  total_loss: 1.447  loss_cls: 0.3719  loss_box_reg: 0.5804  loss_mask: 0.3066  loss_rpn_cls: 0.07172  loss_rpn_loc: 0.0874  time: 0.7417  data_time: 0.1730  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:09:49 d2.utils.events]: \u001b[0m eta: 1:14:42  iter: 1279  total_loss: 1.386  loss_cls: 0.3534  loss_box_reg: 0.5747  loss_mask: 0.2977  loss_rpn_cls: 0.06975  loss_rpn_loc: 0.1067  time: 0.7403  data_time: 0.1502  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:09:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:10:05 d2.utils.events]: \u001b[0m eta: 1:14:26  iter: 1299  total_loss: 1.405  loss_cls: 0.3874  loss_box_reg: 0.568  loss_mask: 0.2943  loss_rpn_cls: 0.06494  loss_rpn_loc: 0.0836  time: 0.7411  data_time: 0.2091  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:10:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:10:19 d2.utils.events]: \u001b[0m eta: 1:14:23  iter: 1319  total_loss: 1.432  loss_cls: 0.3999  loss_box_reg: 0.571  loss_mask: 0.3112  loss_rpn_cls: 0.05091  loss_rpn_loc: 0.07691  time: 0.7410  data_time: 0.1554  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:10:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:10:33 d2.utils.events]: \u001b[0m eta: 1:14:13  iter: 1339  total_loss: 1.286  loss_cls: 0.3562  loss_box_reg: 0.5617  loss_mask: 0.2878  loss_rpn_cls: 0.05276  loss_rpn_loc: 0.06958  time: 0.7400  data_time: 0.0966  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:10:49 d2.utils.events]: \u001b[0m eta: 1:14:03  iter: 1359  total_loss: 1.533  loss_cls: 0.4142  loss_box_reg: 0.5838  loss_mask: 0.3014  loss_rpn_cls: 0.09013  loss_rpn_loc: 0.1268  time: 0.7413  data_time: 0.2966  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:11:05 d2.utils.events]: \u001b[0m eta: 1:13:59  iter: 1379  total_loss: 1.564  loss_cls: 0.4313  loss_box_reg: 0.6008  loss_mask: 0.2856  loss_rpn_cls: 0.08522  loss_rpn_loc: 0.1274  time: 0.7419  data_time: 0.2544  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:11:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:11:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:11:22 d2.utils.events]: \u001b[0m eta: 1:13:50  iter: 1399  total_loss: 1.351  loss_cls: 0.3601  loss_box_reg: 0.5599  loss_mask: 0.2793  loss_rpn_cls: 0.07376  loss_rpn_loc: 0.09728  time: 0.7431  data_time: 0.1589  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:11:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:11:38 d2.utils.events]: \u001b[0m eta: 1:13:44  iter: 1419  total_loss: 1.392  loss_cls: 0.3621  loss_box_reg: 0.5689  loss_mask: 0.3069  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.09847  time: 0.7439  data_time: 0.1878  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:11:50 d2.utils.events]: \u001b[0m eta: 1:13:29  iter: 1439  total_loss: 1.435  loss_cls: 0.4004  loss_box_reg: 0.6033  loss_mask: 0.2966  loss_rpn_cls: 0.05712  loss_rpn_loc: 0.0914  time: 0.7422  data_time: 0.1315  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:11:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:11:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:11:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:11:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:11:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:11:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0902 s/iter. Eval: 0.0571 s/iter. Total: 0.1481 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 16:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0666 s/iter. Total: 0.1560 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:12:10 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0008 s/iter. Inference: 0.0898 s/iter. Eval: 0.0685 s/iter. Total: 0.1591 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:12:15 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0899 s/iter. Eval: 0.0709 s/iter. Total: 0.1617 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 16:12:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.709814 (0.161292 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:12:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090128 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:12:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:12:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2558416268308546\n",
      "\u001b[32m[02/05 16:12:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:12:26 d2.utils.events]: \u001b[0m eta: 1:13:18  iter: 1459  total_loss: 1.459  loss_cls: 0.3901  loss_box_reg: 0.5886  loss_mask: 0.3094  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.0892  time: 0.7425  data_time: 0.1321  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:12:38 d2.utils.events]: \u001b[0m eta: 1:13:10  iter: 1479  total_loss: 1.343  loss_cls: 0.354  loss_box_reg: 0.5365  loss_mask: 0.2932  loss_rpn_cls: 0.05631  loss_rpn_loc: 0.08182  time: 0.7409  data_time: 0.1272  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:12:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:12:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:12:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:12:57 d2.utils.events]: \u001b[0m eta: 1:12:50  iter: 1499  total_loss: 1.36  loss_cls: 0.358  loss_box_reg: 0.5661  loss_mask: 0.2991  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.05059  time: 0.7437  data_time: 0.1804  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:13:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:13:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:13:15 d2.utils.events]: \u001b[0m eta: 1:12:44  iter: 1519  total_loss: 1.513  loss_cls: 0.3852  loss_box_reg: 0.5713  loss_mask: 0.2996  loss_rpn_cls: 0.077  loss_rpn_loc: 0.1107  time: 0.7457  data_time: 0.1765  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:13:26 d2.utils.events]: \u001b[0m eta: 1:12:34  iter: 1539  total_loss: 1.358  loss_cls: 0.3806  loss_box_reg: 0.5651  loss_mask: 0.2935  loss_rpn_cls: 0.04409  loss_rpn_loc: 0.0591  time: 0.7432  data_time: 0.0624  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:13:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:13:45 d2.utils.events]: \u001b[0m eta: 1:12:28  iter: 1559  total_loss: 1.445  loss_cls: 0.3729  loss_box_reg: 0.5785  loss_mask: 0.3054  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.1156  time: 0.7458  data_time: 0.3160  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:13:59 d2.utils.events]: \u001b[0m eta: 1:12:19  iter: 1579  total_loss: 1.471  loss_cls: 0.3983  loss_box_reg: 0.5837  loss_mask: 0.3073  loss_rpn_cls: 0.05944  loss_rpn_loc: 0.1173  time: 0.7452  data_time: 0.1932  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:14:12 d2.utils.events]: \u001b[0m eta: 1:12:10  iter: 1599  total_loss: 1.401  loss_cls: 0.362  loss_box_reg: 0.5784  loss_mask: 0.2995  loss_rpn_cls: 0.05661  loss_rpn_loc: 0.08531  time: 0.7437  data_time: 0.1305  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:14:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:14:28 d2.utils.events]: \u001b[0m eta: 1:12:01  iter: 1619  total_loss: 1.417  loss_cls: 0.3817  loss_box_reg: 0.5686  loss_mask: 0.3065  loss_rpn_cls: 0.07341  loss_rpn_loc: 0.1157  time: 0.7443  data_time: 0.1920  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:14:42 d2.utils.events]: \u001b[0m eta: 1:11:50  iter: 1639  total_loss: 1.492  loss_cls: 0.4226  loss_box_reg: 0.571  loss_mask: 0.3011  loss_rpn_cls: 0.08927  loss_rpn_loc: 0.1182  time: 0.7438  data_time: 0.2058  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:14:54 d2.utils.events]: \u001b[0m eta: 1:11:36  iter: 1659  total_loss: 1.441  loss_cls: 0.3859  loss_box_reg: 0.5939  loss_mask: 0.3013  loss_rpn_cls: 0.06074  loss_rpn_loc: 0.09546  time: 0.7421  data_time: 0.1107  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:15:06 d2.utils.events]: \u001b[0m eta: 1:11:18  iter: 1679  total_loss: 1.384  loss_cls: 0.368  loss_box_reg: 0.5655  loss_mask: 0.2804  loss_rpn_cls: 0.0539  loss_rpn_loc: 0.06772  time: 0.7405  data_time: 0.1321  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:15:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:15:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:15:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:15:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:15:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:15:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:15:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0892 s/iter. Eval: 0.0521 s/iter. Total: 0.1419 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:15:23 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0883 s/iter. Eval: 0.0665 s/iter. Total: 0.1556 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:15:28 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0007 s/iter. Inference: 0.0883 s/iter. Eval: 0.0690 s/iter. Total: 0.1581 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:15:33 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0716 s/iter. Total: 0.1607 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 16:15:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.641493 (0.160703 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:15:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088263 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:15:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:15:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2516080707294924\n",
      "\u001b[32m[02/05 16:15:39 d2.utils.events]: \u001b[0m eta: 1:11:06  iter: 1699  total_loss: 1.333  loss_cls: 0.3649  loss_box_reg: 0.5438  loss_mask: 0.2907  loss_rpn_cls: 0.05483  loss_rpn_loc: 0.07277  time: 0.7394  data_time: 0.1664  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:15:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:15:54 d2.utils.events]: \u001b[0m eta: 1:10:57  iter: 1719  total_loss: 1.534  loss_cls: 0.3967  loss_box_reg: 0.5909  loss_mask: 0.3208  loss_rpn_cls: 0.07814  loss_rpn_loc: 0.1198  time: 0.7395  data_time: 0.1437  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:16:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:16:11 d2.utils.events]: \u001b[0m eta: 1:10:49  iter: 1739  total_loss: 1.382  loss_cls: 0.3623  loss_box_reg: 0.5521  loss_mask: 0.3042  loss_rpn_cls: 0.07005  loss_rpn_loc: 0.1132  time: 0.7407  data_time: 0.2034  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:16:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:16:26 d2.utils.events]: \u001b[0m eta: 1:10:37  iter: 1759  total_loss: 1.321  loss_cls: 0.3473  loss_box_reg: 0.5469  loss_mask: 0.2959  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.06894  time: 0.7410  data_time: 0.1860  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:16:41 d2.utils.events]: \u001b[0m eta: 1:10:23  iter: 1779  total_loss: 1.466  loss_cls: 0.3845  loss_box_reg: 0.591  loss_mask: 0.3093  loss_rpn_cls: 0.06458  loss_rpn_loc: 0.1117  time: 0.7410  data_time: 0.2265  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:16:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:16:56 d2.utils.events]: \u001b[0m eta: 1:10:13  iter: 1799  total_loss: 1.389  loss_cls: 0.3635  loss_box_reg: 0.5376  loss_mask: 0.2849  loss_rpn_cls: 0.04513  loss_rpn_loc: 0.07978  time: 0.7408  data_time: 0.1328  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:17:11 d2.utils.events]: \u001b[0m eta: 1:10:13  iter: 1819  total_loss: 1.438  loss_cls: 0.3778  loss_box_reg: 0.5872  loss_mask: 0.3019  loss_rpn_cls: 0.05116  loss_rpn_loc: 0.09854  time: 0.7414  data_time: 0.2705  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:17:25 d2.utils.events]: \u001b[0m eta: 1:10:02  iter: 1839  total_loss: 1.443  loss_cls: 0.3619  loss_box_reg: 0.5874  loss_mask: 0.3047  loss_rpn_cls: 0.06216  loss_rpn_loc: 0.08469  time: 0.7405  data_time: 0.1478  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:17:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:17:40 d2.utils.events]: \u001b[0m eta: 1:09:54  iter: 1859  total_loss: 1.33  loss_cls: 0.3479  loss_box_reg: 0.5361  loss_mask: 0.286  loss_rpn_cls: 0.04258  loss_rpn_loc: 0.07657  time: 0.7407  data_time: 0.1630  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:17:52 d2.utils.events]: \u001b[0m eta: 1:09:46  iter: 1879  total_loss: 1.263  loss_cls: 0.3401  loss_box_reg: 0.5348  loss_mask: 0.2767  loss_rpn_cls: 0.03655  loss_rpn_loc: 0.06137  time: 0.7393  data_time: 0.0932  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:18:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:18:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:18:10 d2.utils.events]: \u001b[0m eta: 1:09:34  iter: 1899  total_loss: 1.378  loss_cls: 0.3699  loss_box_reg: 0.5801  loss_mask: 0.2975  loss_rpn_cls: 0.05638  loss_rpn_loc: 0.08917  time: 0.7409  data_time: 0.1362  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:18:23 d2.utils.events]: \u001b[0m eta: 1:09:31  iter: 1919  total_loss: 1.501  loss_cls: 0.3919  loss_box_reg: 0.5932  loss_mask: 0.3007  loss_rpn_cls: 0.06806  loss_rpn_loc: 0.1117  time: 0.7399  data_time: 0.1005  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:18:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:18:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:18:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:18:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:18:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:18:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:18:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0889 s/iter. Eval: 0.0535 s/iter. Total: 0.1430 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0926 s/iter. Eval: 0.0729 s/iter. Total: 0.1663 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 16:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0903 s/iter. Eval: 0.0702 s/iter. Total: 0.1612 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0898 s/iter. Eval: 0.0726 s/iter. Total: 0.1633 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 16:18:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.845828 (0.162464 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:18:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089496 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:18:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:18:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2579202688595517\n",
      "\u001b[32m[02/05 16:18:59 d2.utils.events]: \u001b[0m eta: 1:09:26  iter: 1939  total_loss: 1.406  loss_cls: 0.3704  loss_box_reg: 0.604  loss_mask: 0.2922  loss_rpn_cls: 0.04898  loss_rpn_loc: 0.06183  time: 0.7402  data_time: 0.1676  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:19:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:19:15 d2.utils.events]: \u001b[0m eta: 1:09:20  iter: 1959  total_loss: 1.327  loss_cls: 0.3472  loss_box_reg: 0.577  loss_mask: 0.2971  loss_rpn_cls: 0.05318  loss_rpn_loc: 0.07673  time: 0.7408  data_time: 0.2198  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:19:26 d2.utils.events]: \u001b[0m eta: 1:09:10  iter: 1979  total_loss: 1.341  loss_cls: 0.3383  loss_box_reg: 0.5698  loss_mask: 0.2914  loss_rpn_cls: 0.04062  loss_rpn_loc: 0.06298  time: 0.7391  data_time: 0.0880  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:19:38 d2.utils.events]: \u001b[0m eta: 1:08:50  iter: 1999  total_loss: 1.366  loss_cls: 0.3621  loss_box_reg: 0.5637  loss_mask: 0.3024  loss_rpn_cls: 0.05015  loss_rpn_loc: 0.0822  time: 0.7376  data_time: 0.1015  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:19:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:19:54 d2.utils.events]: \u001b[0m eta: 1:08:40  iter: 2019  total_loss: 1.465  loss_cls: 0.3771  loss_box_reg: 0.5873  loss_mask: 0.32  loss_rpn_cls: 0.0544  loss_rpn_loc: 0.1123  time: 0.7382  data_time: 0.1816  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:20:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:20:12 d2.utils.events]: \u001b[0m eta: 1:08:28  iter: 2039  total_loss: 1.431  loss_cls: 0.4206  loss_box_reg: 0.5793  loss_mask: 0.3126  loss_rpn_cls: 0.0512  loss_rpn_loc: 0.09534  time: 0.7397  data_time: 0.2416  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:20:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:20:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:20:30 d2.utils.events]: \u001b[0m eta: 1:08:25  iter: 2059  total_loss: 1.414  loss_cls: 0.4003  loss_box_reg: 0.5757  loss_mask: 0.3017  loss_rpn_cls: 0.08163  loss_rpn_loc: 0.1123  time: 0.7416  data_time: 0.1815  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:20:44 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 2079  total_loss: 1.345  loss_cls: 0.36  loss_box_reg: 0.5589  loss_mask: 0.2989  loss_rpn_cls: 0.04734  loss_rpn_loc: 0.06522  time: 0.7410  data_time: 0.1744  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:20:58 d2.utils.events]: \u001b[0m eta: 1:07:58  iter: 2099  total_loss: 1.338  loss_cls: 0.3504  loss_box_reg: 0.5627  loss_mask: 0.2948  loss_rpn_cls: 0.04726  loss_rpn_loc: 0.05762  time: 0.7406  data_time: 0.2006  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:21:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:21:13 d2.utils.events]: \u001b[0m eta: 1:07:56  iter: 2119  total_loss: 1.367  loss_cls: 0.3521  loss_box_reg: 0.5577  loss_mask: 0.304  loss_rpn_cls: 0.03974  loss_rpn_loc: 0.0514  time: 0.7406  data_time: 0.1413  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:21:26 d2.utils.events]: \u001b[0m eta: 1:07:45  iter: 2139  total_loss: 1.379  loss_cls: 0.363  loss_box_reg: 0.5664  loss_mask: 0.2962  loss_rpn_cls: 0.06874  loss_rpn_loc: 0.1026  time: 0.7396  data_time: 0.1313  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:21:38 d2.utils.events]: \u001b[0m eta: 1:07:39  iter: 2159  total_loss: 1.338  loss_cls: 0.3546  loss_box_reg: 0.573  loss_mask: 0.2873  loss_rpn_cls: 0.0476  loss_rpn_loc: 0.07882  time: 0.7385  data_time: 0.1139  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:21:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:21:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:21:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:21:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:21:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:21:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0895 s/iter. Eval: 0.0541 s/iter. Total: 0.1442 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0720 s/iter. Total: 0.1640 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 16:22:02 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0914 s/iter. Eval: 0.0709 s/iter. Total: 0.1631 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0916 s/iter. Eval: 0.0752 s/iter. Total: 0.1677 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 16:22:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.429815 (0.167498 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:22:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091846 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:22:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:22:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.263890668495212\n",
      "\u001b[32m[02/05 16:22:12 d2.utils.events]: \u001b[0m eta: 1:07:28  iter: 2179  total_loss: 1.336  loss_cls: 0.3424  loss_box_reg: 0.5253  loss_mask: 0.2946  loss_rpn_cls: 0.05538  loss_rpn_loc: 0.07608  time: 0.7376  data_time: 0.1329  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:22:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:22:29 d2.utils.events]: \u001b[0m eta: 1:07:20  iter: 2199  total_loss: 1.254  loss_cls: 0.3216  loss_box_reg: 0.5501  loss_mask: 0.2938  loss_rpn_cls: 0.0405  loss_rpn_loc: 0.05566  time: 0.7384  data_time: 0.2088  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:22:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:22:46 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 2219  total_loss: 1.392  loss_cls: 0.3581  loss_box_reg: 0.5686  loss_mask: 0.3047  loss_rpn_cls: 0.06189  loss_rpn_loc: 0.08973  time: 0.7396  data_time: 0.2319  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:22:59 d2.utils.events]: \u001b[0m eta: 1:07:01  iter: 2239  total_loss: 1.331  loss_cls: 0.3531  loss_box_reg: 0.5509  loss_mask: 0.2921  loss_rpn_cls: 0.03998  loss_rpn_loc: 0.06253  time: 0.7390  data_time: 0.1618  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:23:12 d2.utils.events]: \u001b[0m eta: 1:06:50  iter: 2259  total_loss: 1.368  loss_cls: 0.3723  loss_box_reg: 0.5591  loss_mask: 0.2974  loss_rpn_cls: 0.04755  loss_rpn_loc: 0.0947  time: 0.7380  data_time: 0.1185  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:23:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:23:27 d2.utils.events]: \u001b[0m eta: 1:06:48  iter: 2279  total_loss: 1.424  loss_cls: 0.3479  loss_box_reg: 0.5817  loss_mask: 0.3008  loss_rpn_cls: 0.04656  loss_rpn_loc: 0.09067  time: 0.7380  data_time: 0.1314  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:23:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:23:44 d2.utils.events]: \u001b[0m eta: 1:06:42  iter: 2299  total_loss: 1.43  loss_cls: 0.3894  loss_box_reg: 0.569  loss_mask: 0.31  loss_rpn_cls: 0.06909  loss_rpn_loc: 0.1138  time: 0.7390  data_time: 0.2075  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:23:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:23:59 d2.utils.events]: \u001b[0m eta: 1:06:37  iter: 2319  total_loss: 1.356  loss_cls: 0.3722  loss_box_reg: 0.5228  loss_mask: 0.2685  loss_rpn_cls: 0.05761  loss_rpn_loc: 0.105  time: 0.7391  data_time: 0.1400  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:24:12 d2.utils.events]: \u001b[0m eta: 1:06:24  iter: 2339  total_loss: 1.309  loss_cls: 0.3404  loss_box_reg: 0.577  loss_mask: 0.3013  loss_rpn_cls: 0.033  loss_rpn_loc: 0.04886  time: 0.7383  data_time: 0.1440  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:24:28 d2.utils.events]: \u001b[0m eta: 1:06:19  iter: 2359  total_loss: 1.399  loss_cls: 0.3562  loss_box_reg: 0.5656  loss_mask: 0.2993  loss_rpn_cls: 0.06851  loss_rpn_loc: 0.1046  time: 0.7388  data_time: 0.2786  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:24:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:24:45 d2.utils.events]: \u001b[0m eta: 1:06:06  iter: 2379  total_loss: 1.313  loss_cls: 0.3468  loss_box_reg: 0.5558  loss_mask: 0.3061  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.09609  time: 0.7400  data_time: 0.2476  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:24:57 d2.utils.events]: \u001b[0m eta: 1:05:53  iter: 2399  total_loss: 1.416  loss_cls: 0.3669  loss_box_reg: 0.5691  loss_mask: 0.2942  loss_rpn_cls: 0.05506  loss_rpn_loc: 0.06428  time: 0.7389  data_time: 0.1018  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:25:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:25:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:25:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:25:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:25:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:25:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0861 s/iter. Eval: 0.0496 s/iter. Total: 0.1364 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0696 s/iter. Total: 0.1598 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0705 s/iter. Total: 0.1605 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0747 s/iter. Total: 0.1649 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 16:25:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.997801 (0.163774 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:25:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089112 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:25:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:25:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26281144541775\n",
      "\u001b[32m[02/05 16:25:32 d2.utils.events]: \u001b[0m eta: 1:05:45  iter: 2419  total_loss: 1.329  loss_cls: 0.3452  loss_box_reg: 0.5775  loss_mask: 0.3049  loss_rpn_cls: 0.04622  loss_rpn_loc: 0.09551  time: 0.7387  data_time: 0.2069  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:25:45 d2.utils.events]: \u001b[0m eta: 1:05:30  iter: 2439  total_loss: 1.36  loss_cls: 0.3569  loss_box_reg: 0.5429  loss_mask: 0.2801  loss_rpn_cls: 0.04624  loss_rpn_loc: 0.08689  time: 0.7377  data_time: 0.1156  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:25:59 d2.utils.events]: \u001b[0m eta: 1:05:21  iter: 2459  total_loss: 1.293  loss_cls: 0.3284  loss_box_reg: 0.5562  loss_mask: 0.3038  loss_rpn_cls: 0.05352  loss_rpn_loc: 0.06681  time: 0.7373  data_time: 0.1826  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:26:13 d2.utils.events]: \u001b[0m eta: 1:05:12  iter: 2479  total_loss: 1.386  loss_cls: 0.3647  loss_box_reg: 0.5437  loss_mask: 0.2987  loss_rpn_cls: 0.06488  loss_rpn_loc: 0.1102  time: 0.7370  data_time: 0.2025  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:26:25 d2.utils.events]: \u001b[0m eta: 1:05:05  iter: 2499  total_loss: 1.339  loss_cls: 0.3488  loss_box_reg: 0.5741  loss_mask: 0.3224  loss_rpn_cls: 0.04192  loss_rpn_loc: 0.06703  time: 0.7361  data_time: 0.1380  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:26:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:26:42 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 2519  total_loss: 1.367  loss_cls: 0.3457  loss_box_reg: 0.5685  loss_mask: 0.3043  loss_rpn_cls: 0.04729  loss_rpn_loc: 0.05647  time: 0.7370  data_time: 0.2348  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:26:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:26:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:26:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:27:03 d2.utils.events]: \u001b[0m eta: 1:04:46  iter: 2539  total_loss: 1.365  loss_cls: 0.3507  loss_box_reg: 0.5487  loss_mask: 0.3083  loss_rpn_cls: 0.05999  loss_rpn_loc: 0.07656  time: 0.7396  data_time: 0.2676  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:27:14 d2.utils.events]: \u001b[0m eta: 1:04:26  iter: 2559  total_loss: 1.27  loss_cls: 0.3188  loss_box_reg: 0.5474  loss_mask: 0.2762  loss_rpn_cls: 0.04612  loss_rpn_loc: 0.07526  time: 0.7381  data_time: 0.0618  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:27:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:27:29 d2.utils.events]: \u001b[0m eta: 1:04:15  iter: 2579  total_loss: 1.382  loss_cls: 0.3693  loss_box_reg: 0.5774  loss_mask: 0.2962  loss_rpn_cls: 0.06195  loss_rpn_loc: 0.1045  time: 0.7381  data_time: 0.1603  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:27:41 d2.utils.events]: \u001b[0m eta: 1:03:59  iter: 2599  total_loss: 1.39  loss_cls: 0.3737  loss_box_reg: 0.5832  loss_mask: 0.2904  loss_rpn_cls: 0.04547  loss_rpn_loc: 0.09491  time: 0.7370  data_time: 0.1132  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:27:54 d2.utils.events]: \u001b[0m eta: 1:03:55  iter: 2619  total_loss: 1.501  loss_cls: 0.3895  loss_box_reg: 0.5882  loss_mask: 0.3156  loss_rpn_cls: 0.0632  loss_rpn_loc: 0.1029  time: 0.7365  data_time: 0.1505  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:27:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:27:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:28:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:28:14 d2.utils.events]: \u001b[0m eta: 1:03:50  iter: 2639  total_loss: 1.276  loss_cls: 0.3222  loss_box_reg: 0.5431  loss_mask: 0.2894  loss_rpn_cls: 0.05706  loss_rpn_loc: 0.109  time: 0.7384  data_time: 0.2043  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:28:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:28:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:28:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:28:34 d2.utils.events]: \u001b[0m eta: 1:03:40  iter: 2659  total_loss: 1.311  loss_cls: 0.3411  loss_box_reg: 0.5566  loss_mask: 0.2966  loss_rpn_cls: 0.05889  loss_rpn_loc: 0.09567  time: 0.7402  data_time: 0.2159  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:28:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:28:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:28:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:28:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:28:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:28:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0871 s/iter. Eval: 0.0511 s/iter. Total: 0.1388 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0883 s/iter. Eval: 0.0674 s/iter. Total: 0.1565 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0698 s/iter. Total: 0.1588 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0737 s/iter. Total: 0.1632 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 16:28:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.800914 (0.162077 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:28:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088525 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:28:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:28:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2646624351070195\n",
      "\u001b[32m[02/05 16:29:05 d2.utils.events]: \u001b[0m eta: 1:03:25  iter: 2679  total_loss: 1.195  loss_cls: 0.321  loss_box_reg: 0.5443  loss_mask: 0.2834  loss_rpn_cls: 0.02466  loss_rpn_loc: 0.04946  time: 0.7386  data_time: 0.0523  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:29:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:29:21 d2.utils.events]: \u001b[0m eta: 1:03:19  iter: 2699  total_loss: 1.276  loss_cls: 0.323  loss_box_reg: 0.5436  loss_mask: 0.2811  loss_rpn_cls: 0.02465  loss_rpn_loc: 0.04499  time: 0.7391  data_time: 0.1911  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:29:34 d2.utils.events]: \u001b[0m eta: 1:03:08  iter: 2719  total_loss: 1.43  loss_cls: 0.3892  loss_box_reg: 0.5734  loss_mask: 0.3027  loss_rpn_cls: 0.05164  loss_rpn_loc: 0.09655  time: 0.7383  data_time: 0.1100  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:29:45 d2.utils.events]: \u001b[0m eta: 1:02:49  iter: 2739  total_loss: 1.306  loss_cls: 0.3434  loss_box_reg: 0.5367  loss_mask: 0.2874  loss_rpn_cls: 0.04973  loss_rpn_loc: 0.08749  time: 0.7370  data_time: 0.0878  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:29:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:29:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:29:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:30:03 d2.utils.events]: \u001b[0m eta: 1:02:33  iter: 2759  total_loss: 1.418  loss_cls: 0.3694  loss_box_reg: 0.5871  loss_mask: 0.3166  loss_rpn_cls: 0.04097  loss_rpn_loc: 0.07212  time: 0.7384  data_time: 0.1674  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:30:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:30:17 d2.utils.events]: \u001b[0m eta: 1:02:21  iter: 2779  total_loss: 1.359  loss_cls: 0.3459  loss_box_reg: 0.5543  loss_mask: 0.2786  loss_rpn_cls: 0.04808  loss_rpn_loc: 0.09578  time: 0.7380  data_time: 0.1122  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:30:33 d2.utils.events]: \u001b[0m eta: 1:02:18  iter: 2799  total_loss: 1.34  loss_cls: 0.3526  loss_box_reg: 0.5493  loss_mask: 0.2926  loss_rpn_cls: 0.06649  loss_rpn_loc: 0.1047  time: 0.7382  data_time: 0.2646  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:30:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:30:48 d2.utils.events]: \u001b[0m eta: 1:02:02  iter: 2819  total_loss: 1.34  loss_cls: 0.3375  loss_box_reg: 0.5599  loss_mask: 0.2928  loss_rpn_cls: 0.04618  loss_rpn_loc: 0.07168  time: 0.7384  data_time: 0.1838  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:31:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:31:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:31:08 d2.utils.events]: \u001b[0m eta: 1:01:57  iter: 2839  total_loss: 1.42  loss_cls: 0.3918  loss_box_reg: 0.5745  loss_mask: 0.3016  loss_rpn_cls: 0.07651  loss_rpn_loc: 0.1132  time: 0.7403  data_time: 0.2804  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:31:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:31:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:31:27 d2.utils.events]: \u001b[0m eta: 1:01:56  iter: 2859  total_loss: 1.367  loss_cls: 0.3618  loss_box_reg: 0.5275  loss_mask: 0.2914  loss_rpn_cls: 0.06027  loss_rpn_loc: 0.1131  time: 0.7416  data_time: 0.1925  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:31:37 d2.utils.events]: \u001b[0m eta: 1:01:37  iter: 2879  total_loss: 1.366  loss_cls: 0.3642  loss_box_reg: 0.5637  loss_mask: 0.3011  loss_rpn_cls: 0.04433  loss_rpn_loc: 0.0628  time: 0.7400  data_time: 0.0268  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:31:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:31:55 d2.utils.events]: \u001b[0m eta: 1:01:28  iter: 2899  total_loss: 1.473  loss_cls: 0.3816  loss_box_reg: 0.5914  loss_mask: 0.3175  loss_rpn_cls: 0.07754  loss_rpn_loc: 0.1283  time: 0.7413  data_time: 0.2897  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:31:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:31:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:31:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:31:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:31:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:31:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0904 s/iter. Eval: 0.0568 s/iter. Total: 0.1479 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 16:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0915 s/iter. Eval: 0.0731 s/iter. Total: 0.1654 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 16:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0727 s/iter. Total: 0.1647 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 16:32:17 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0763 s/iter. Total: 0.1679 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 16:32:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.439366 (0.167581 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:32:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090653 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:32:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:32:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26504147974165343\n",
      "\u001b[32m[02/05 16:32:29 d2.utils.events]: \u001b[0m eta: 1:01:10  iter: 2919  total_loss: 1.385  loss_cls: 0.3566  loss_box_reg: 0.5592  loss_mask: 0.3092  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.05926  time: 0.7405  data_time: 0.1284  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:32:40 d2.utils.events]: \u001b[0m eta: 1:01:03  iter: 2939  total_loss: 1.387  loss_cls: 0.3592  loss_box_reg: 0.557  loss_mask: 0.2921  loss_rpn_cls: 0.05059  loss_rpn_loc: 0.09291  time: 0.7393  data_time: 0.0704  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:32:53 d2.utils.events]: \u001b[0m eta: 1:00:47  iter: 2959  total_loss: 1.316  loss_cls: 0.3344  loss_box_reg: 0.5553  loss_mask: 0.3015  loss_rpn_cls: 0.04616  loss_rpn_loc: 0.06614  time: 0.7386  data_time: 0.1301  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:33:04 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 2979  total_loss: 1.361  loss_cls: 0.3624  loss_box_reg: 0.581  loss_mask: 0.2913  loss_rpn_cls: 0.04858  loss_rpn_loc: 0.07768  time: 0.7372  data_time: 0.0445  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:33:14 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 2999  total_loss: 1.287  loss_cls: 0.3669  loss_box_reg: 0.5415  loss_mask: 0.2933  loss_rpn_cls: 0.0406  loss_rpn_loc: 0.06783  time: 0.7358  data_time: 0.0361  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:33:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:33:33 d2.utils.events]: \u001b[0m eta: 1:00:17  iter: 3019  total_loss: 1.301  loss_cls: 0.3544  loss_box_reg: 0.574  loss_mask: 0.2884  loss_rpn_cls: 0.04698  loss_rpn_loc: 0.09566  time: 0.7371  data_time: 0.2633  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:33:45 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 3039  total_loss: 1.334  loss_cls: 0.3557  loss_box_reg: 0.563  loss_mask: 0.2926  loss_rpn_cls: 0.05508  loss_rpn_loc: 0.07886  time: 0.7364  data_time: 0.1444  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:33:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:34:02 d2.utils.events]: \u001b[0m eta: 0:59:45  iter: 3059  total_loss: 1.366  loss_cls: 0.3534  loss_box_reg: 0.5374  loss_mask: 0.3004  loss_rpn_cls: 0.05399  loss_rpn_loc: 0.1062  time: 0.7370  data_time: 0.2341  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:34:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:34:20 d2.utils.events]: \u001b[0m eta: 0:59:37  iter: 3079  total_loss: 1.425  loss_cls: 0.3868  loss_box_reg: 0.5842  loss_mask: 0.3095  loss_rpn_cls: 0.07379  loss_rpn_loc: 0.1201  time: 0.7381  data_time: 0.2578  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:34:35 d2.utils.events]: \u001b[0m eta: 0:59:36  iter: 3099  total_loss: 1.38  loss_cls: 0.3472  loss_box_reg: 0.5362  loss_mask: 0.2875  loss_rpn_cls: 0.06363  loss_rpn_loc: 0.113  time: 0.7382  data_time: 0.2309  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:34:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:34:49 d2.utils.events]: \u001b[0m eta: 0:59:16  iter: 3119  total_loss: 1.239  loss_cls: 0.3197  loss_box_reg: 0.5415  loss_mask: 0.2846  loss_rpn_cls: 0.03192  loss_rpn_loc: 0.07046  time: 0.7380  data_time: 0.1252  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:35:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:35:09 d2.utils.events]: \u001b[0m eta: 0:59:10  iter: 3139  total_loss: 1.33  loss_cls: 0.3408  loss_box_reg: 0.5518  loss_mask: 0.2938  loss_rpn_cls: 0.05646  loss_rpn_loc: 0.1015  time: 0.7395  data_time: 0.3249  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:35:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:35:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:35:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:35:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:35:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:35:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:35:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:35:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0866 s/iter. Eval: 0.0566 s/iter. Total: 0.1439 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:35:23 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0885 s/iter. Eval: 0.0715 s/iter. Total: 0.1608 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:35:28 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0727 s/iter. Total: 0.1622 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0765 s/iter. Total: 0.1662 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 16:35:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.217767 (0.165670 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:35:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088700 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:35:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:35:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2576039405531233\n",
      "\u001b[32m[02/05 16:35:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:35:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:35:49 d2.utils.events]: \u001b[0m eta: 0:58:56  iter: 3159  total_loss: 1.314  loss_cls: 0.3405  loss_box_reg: 0.5363  loss_mask: 0.2995  loss_rpn_cls: 0.03782  loss_rpn_loc: 0.05681  time: 0.7410  data_time: 0.2151  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:36:01 d2.utils.events]: \u001b[0m eta: 0:58:43  iter: 3179  total_loss: 1.285  loss_cls: 0.3545  loss_box_reg: 0.5417  loss_mask: 0.2805  loss_rpn_cls: 0.03879  loss_rpn_loc: 0.066  time: 0.7401  data_time: 0.1079  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:36:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:36:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:36:19 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 3199  total_loss: 1.279  loss_cls: 0.3304  loss_box_reg: 0.5323  loss_mask: 0.2795  loss_rpn_cls: 0.04148  loss_rpn_loc: 0.07545  time: 0.7411  data_time: 0.2055  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:36:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:36:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:36:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:36:38 d2.utils.events]: \u001b[0m eta: 0:58:15  iter: 3219  total_loss: 1.407  loss_cls: 0.3612  loss_box_reg: 0.5899  loss_mask: 0.3007  loss_rpn_cls: 0.05617  loss_rpn_loc: 0.1051  time: 0.7423  data_time: 0.1555  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:36:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:36:53 d2.utils.events]: \u001b[0m eta: 0:58:05  iter: 3239  total_loss: 1.486  loss_cls: 0.3801  loss_box_reg: 0.5757  loss_mask: 0.309  loss_rpn_cls: 0.06352  loss_rpn_loc: 0.1035  time: 0.7423  data_time: 0.1392  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:37:05 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 3259  total_loss: 1.353  loss_cls: 0.3355  loss_box_reg: 0.5561  loss_mask: 0.2882  loss_rpn_cls: 0.03463  loss_rpn_loc: 0.06266  time: 0.7417  data_time: 0.1526  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:37:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:37:20 d2.utils.events]: \u001b[0m eta: 0:57:37  iter: 3279  total_loss: 1.308  loss_cls: 0.3329  loss_box_reg: 0.5216  loss_mask: 0.2904  loss_rpn_cls: 0.04243  loss_rpn_loc: 0.06249  time: 0.7417  data_time: 0.1618  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:37:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:37:37 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 3299  total_loss: 1.416  loss_cls: 0.3726  loss_box_reg: 0.5613  loss_mask: 0.3183  loss_rpn_cls: 0.058  loss_rpn_loc: 0.1096  time: 0.7422  data_time: 0.1903  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:37:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:37:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:37:54 d2.utils.events]: \u001b[0m eta: 0:57:03  iter: 3319  total_loss: 1.316  loss_cls: 0.341  loss_box_reg: 0.5544  loss_mask: 0.283  loss_rpn_cls: 0.03498  loss_rpn_loc: 0.05809  time: 0.7429  data_time: 0.2083  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:38:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:38:09 d2.utils.events]: \u001b[0m eta: 0:56:52  iter: 3339  total_loss: 1.263  loss_cls: 0.3319  loss_box_reg: 0.5378  loss_mask: 0.2941  loss_rpn_cls: 0.02931  loss_rpn_loc: 0.04592  time: 0.7428  data_time: 0.1457  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:38:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:38:24 d2.utils.events]: \u001b[0m eta: 0:56:36  iter: 3359  total_loss: 1.441  loss_cls: 0.3707  loss_box_reg: 0.5913  loss_mask: 0.3177  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.0772  time: 0.7428  data_time: 0.1649  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:38:37 d2.utils.events]: \u001b[0m eta: 0:56:27  iter: 3379  total_loss: 1.397  loss_cls: 0.3687  loss_box_reg: 0.5719  loss_mask: 0.3012  loss_rpn_cls: 0.04993  loss_rpn_loc: 0.08413  time: 0.7423  data_time: 0.1384  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:38:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:38:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:38:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:38:46 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:38:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:38:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:38:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0876 s/iter. Eval: 0.0562 s/iter. Total: 0.1445 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0011 s/iter. Inference: 0.0894 s/iter. Eval: 0.0708 s/iter. Total: 0.1614 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0010 s/iter. Inference: 0.0897 s/iter. Eval: 0.0710 s/iter. Total: 0.1618 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0009 s/iter. Inference: 0.0900 s/iter. Eval: 0.0753 s/iter. Total: 0.1663 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 16:39:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.182022 (0.165362 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:39:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089746 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:39:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:39:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26081038590968336\n",
      "\u001b[32m[02/05 16:39:12 d2.utils.events]: \u001b[0m eta: 0:56:11  iter: 3399  total_loss: 1.26  loss_cls: 0.3298  loss_box_reg: 0.5443  loss_mask: 0.2826  loss_rpn_cls: 0.05332  loss_rpn_loc: 0.06167  time: 0.7423  data_time: 0.1335  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:39:24 d2.utils.events]: \u001b[0m eta: 0:55:57  iter: 3419  total_loss: 1.268  loss_cls: 0.3336  loss_box_reg: 0.5452  loss_mask: 0.2784  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.06204  time: 0.7412  data_time: 0.0472  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:39:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:39:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:39:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:39:42 d2.utils.events]: \u001b[0m eta: 0:55:48  iter: 3439  total_loss: 1.373  loss_cls: 0.3439  loss_box_reg: 0.5693  loss_mask: 0.3004  loss_rpn_cls: 0.04638  loss_rpn_loc: 0.09335  time: 0.7424  data_time: 0.1656  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:39:57 d2.utils.events]: \u001b[0m eta: 0:55:42  iter: 3459  total_loss: 1.355  loss_cls: 0.3552  loss_box_reg: 0.5489  loss_mask: 0.296  loss_rpn_cls: 0.05329  loss_rpn_loc: 0.1059  time: 0.7424  data_time: 0.2439  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:40:10 d2.utils.events]: \u001b[0m eta: 0:55:28  iter: 3479  total_loss: 1.25  loss_cls: 0.3293  loss_box_reg: 0.5493  loss_mask: 0.2843  loss_rpn_cls: 0.03784  loss_rpn_loc: 0.06066  time: 0.7417  data_time: 0.1379  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:40:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:40:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:40:29 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 3499  total_loss: 1.437  loss_cls: 0.3902  loss_box_reg: 0.5703  loss_mask: 0.297  loss_rpn_cls: 0.06074  loss_rpn_loc: 0.06692  time: 0.7430  data_time: 0.2628  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:40:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:40:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:40:47 d2.utils.events]: \u001b[0m eta: 0:55:13  iter: 3519  total_loss: 1.477  loss_cls: 0.3911  loss_box_reg: 0.5752  loss_mask: 0.3081  loss_rpn_cls: 0.07147  loss_rpn_loc: 0.1181  time: 0.7438  data_time: 0.1984  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:40:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:41:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:41:06 d2.utils.events]: \u001b[0m eta: 0:55:04  iter: 3539  total_loss: 1.364  loss_cls: 0.3481  loss_box_reg: 0.5377  loss_mask: 0.3153  loss_rpn_cls: 0.04312  loss_rpn_loc: 0.04768  time: 0.7450  data_time: 0.1840  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:41:17 d2.utils.events]: \u001b[0m eta: 0:54:54  iter: 3559  total_loss: 1.216  loss_cls: 0.3112  loss_box_reg: 0.5379  loss_mask: 0.2692  loss_rpn_cls: 0.03084  loss_rpn_loc: 0.04418  time: 0.7439  data_time: 0.0726  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:41:30 d2.utils.events]: \u001b[0m eta: 0:54:42  iter: 3579  total_loss: 1.3  loss_cls: 0.3472  loss_box_reg: 0.5585  loss_mask: 0.2852  loss_rpn_cls: 0.03059  loss_rpn_loc: 0.05995  time: 0.7433  data_time: 0.1598  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:41:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:41:46 d2.utils.events]: \u001b[0m eta: 0:54:36  iter: 3599  total_loss: 1.312  loss_cls: 0.3468  loss_box_reg: 0.5347  loss_mask: 0.2865  loss_rpn_cls: 0.06258  loss_rpn_loc: 0.1063  time: 0.7437  data_time: 0.2181  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:41:58 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 3619  total_loss: 1.363  loss_cls: 0.353  loss_box_reg: 0.5315  loss_mask: 0.3017  loss_rpn_cls: 0.05861  loss_rpn_loc: 0.1009  time: 0.7430  data_time: 0.1269  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:42:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:42:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:42:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:42:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:42:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:42:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:42:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0862 s/iter. Eval: 0.0541 s/iter. Total: 0.1409 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0874 s/iter. Eval: 0.0674 s/iter. Total: 0.1556 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0700 s/iter. Total: 0.1583 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0723 s/iter. Total: 0.1609 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 16:42:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.701246 (0.161218 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:42:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087818 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:42:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:42:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2613985245487029\n",
      "\u001b[32m[02/05 16:42:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:42:35 d2.utils.events]: \u001b[0m eta: 0:54:13  iter: 3639  total_loss: 1.427  loss_cls: 0.3694  loss_box_reg: 0.5864  loss_mask: 0.2955  loss_rpn_cls: 0.05075  loss_rpn_loc: 0.08942  time: 0.7434  data_time: 0.1187  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:42:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:42:49 d2.utils.events]: \u001b[0m eta: 0:54:00  iter: 3659  total_loss: 1.361  loss_cls: 0.3369  loss_box_reg: 0.5829  loss_mask: 0.2983  loss_rpn_cls: 0.04532  loss_rpn_loc: 0.05454  time: 0.7433  data_time: 0.1549  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:42:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:42:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:43:06 d2.utils.events]: \u001b[0m eta: 0:53:54  iter: 3679  total_loss: 1.366  loss_cls: 0.3559  loss_box_reg: 0.5689  loss_mask: 0.2942  loss_rpn_cls: 0.04648  loss_rpn_loc: 0.06579  time: 0.7438  data_time: 0.1707  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:43:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:43:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:43:22 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 3699  total_loss: 1.304  loss_cls: 0.3456  loss_box_reg: 0.5429  loss_mask: 0.294  loss_rpn_cls: 0.04576  loss_rpn_loc: 0.0828  time: 0.7441  data_time: 0.1452  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:43:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:43:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:43:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:43:43 d2.utils.events]: \u001b[0m eta: 0:53:32  iter: 3719  total_loss: 1.385  loss_cls: 0.3419  loss_box_reg: 0.5555  loss_mask: 0.2888  loss_rpn_cls: 0.05558  loss_rpn_loc: 0.1147  time: 0.7457  data_time: 0.2096  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:43:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:43:59 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 3739  total_loss: 1.278  loss_cls: 0.3456  loss_box_reg: 0.5461  loss_mask: 0.2972  loss_rpn_cls: 0.04484  loss_rpn_loc: 0.06189  time: 0.7460  data_time: 0.1802  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:44:12 d2.utils.events]: \u001b[0m eta: 0:53:14  iter: 3759  total_loss: 1.289  loss_cls: 0.3376  loss_box_reg: 0.5394  loss_mask: 0.2757  loss_rpn_cls: 0.04299  loss_rpn_loc: 0.07371  time: 0.7455  data_time: 0.1352  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:44:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:44:27 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 3779  total_loss: 1.352  loss_cls: 0.3502  loss_box_reg: 0.5616  loss_mask: 0.2979  loss_rpn_cls: 0.05557  loss_rpn_loc: 0.1001  time: 0.7455  data_time: 0.1378  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:44:40 d2.utils.events]: \u001b[0m eta: 0:52:53  iter: 3799  total_loss: 1.25  loss_cls: 0.3297  loss_box_reg: 0.5326  loss_mask: 0.2808  loss_rpn_cls: 0.03934  loss_rpn_loc: 0.06584  time: 0.7450  data_time: 0.1137  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:44:55 d2.utils.events]: \u001b[0m eta: 0:52:50  iter: 3819  total_loss: 1.372  loss_cls: 0.357  loss_box_reg: 0.5516  loss_mask: 0.2946  loss_rpn_cls: 0.05858  loss_rpn_loc: 0.1012  time: 0.7449  data_time: 0.1895  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:45:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:45:13 d2.utils.events]: \u001b[0m eta: 0:52:39  iter: 3839  total_loss: 1.352  loss_cls: 0.3724  loss_box_reg: 0.5475  loss_mask: 0.2964  loss_rpn_cls: 0.05644  loss_rpn_loc: 0.1066  time: 0.7459  data_time: 0.2739  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:45:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:45:32 d2.utils.events]: \u001b[0m eta: 0:52:30  iter: 3859  total_loss: 1.279  loss_cls: 0.328  loss_box_reg: 0.529  loss_mask: 0.285  loss_rpn_cls: 0.0548  loss_rpn_loc: 0.09522  time: 0.7468  data_time: 0.2776  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:45:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:45:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:45:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:45:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:45:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:45:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0971 s/iter. Eval: 0.0634 s/iter. Total: 0.1612 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 16:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0008 s/iter. Inference: 0.0978 s/iter. Eval: 0.0774 s/iter. Total: 0.1760 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 16:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.0975 s/iter. Eval: 0.0782 s/iter. Total: 0.1766 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 16:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0008 s/iter. Inference: 0.0983 s/iter. Eval: 0.0854 s/iter. Total: 0.1846 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 16:46:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.206170 (0.182812 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:46:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.098161 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:46:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:46:04 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25488012197574744\n",
      "\u001b[32m[02/05 16:46:08 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 3879  total_loss: 1.372  loss_cls: 0.3553  loss_box_reg: 0.5598  loss_mask: 0.3085  loss_rpn_cls: 0.04703  loss_rpn_loc: 0.09106  time: 0.7463  data_time: 0.1201  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:46:23 d2.utils.events]: \u001b[0m eta: 0:52:22  iter: 3899  total_loss: 1.356  loss_cls: 0.3556  loss_box_reg: 0.5588  loss_mask: 0.2992  loss_rpn_cls: 0.04664  loss_rpn_loc: 0.08864  time: 0.7463  data_time: 0.1631  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:46:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:46:39 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 3919  total_loss: 1.277  loss_cls: 0.3337  loss_box_reg: 0.529  loss_mask: 0.2992  loss_rpn_cls: 0.03956  loss_rpn_loc: 0.07262  time: 0.7466  data_time: 0.1676  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:46:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:46:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:46:56 d2.utils.events]: \u001b[0m eta: 0:52:25  iter: 3939  total_loss: 1.296  loss_cls: 0.3338  loss_box_reg: 0.5426  loss_mask: 0.2889  loss_rpn_cls: 0.03706  loss_rpn_loc: 0.04925  time: 0.7471  data_time: 0.1389  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:47:10 d2.utils.events]: \u001b[0m eta: 0:52:19  iter: 3959  total_loss: 1.338  loss_cls: 0.3353  loss_box_reg: 0.5471  loss_mask: 0.2967  loss_rpn_cls: 0.03502  loss_rpn_loc: 0.06373  time: 0.7469  data_time: 0.1673  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:47:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:47:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:47:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:47:30 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 3979  total_loss: 1.383  loss_cls: 0.3649  loss_box_reg: 0.568  loss_mask: 0.3023  loss_rpn_cls: 0.06731  loss_rpn_loc: 0.1113  time: 0.7483  data_time: 0.1475  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:47:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:47:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:47:48 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 3999  total_loss: 1.275  loss_cls: 0.3343  loss_box_reg: 0.5425  loss_mask: 0.288  loss_rpn_cls: 0.04265  loss_rpn_loc: 0.08388  time: 0.7490  data_time: 0.1594  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:47:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:48:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:48:06 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 4019  total_loss: 1.317  loss_cls: 0.3614  loss_box_reg: 0.5447  loss_mask: 0.2985  loss_rpn_cls: 0.0349  loss_rpn_loc: 0.06109  time: 0.7497  data_time: 0.1396  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:48:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:48:21 d2.utils.events]: \u001b[0m eta: 0:52:17  iter: 4039  total_loss: 1.316  loss_cls: 0.3465  loss_box_reg: 0.5562  loss_mask: 0.3029  loss_rpn_cls: 0.03923  loss_rpn_loc: 0.07661  time: 0.7496  data_time: 0.1226  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:48:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:48:35 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 4059  total_loss: 1.194  loss_cls: 0.293  loss_box_reg: 0.5483  loss_mask: 0.2849  loss_rpn_cls: 0.02507  loss_rpn_loc: 0.04515  time: 0.7494  data_time: 0.1512  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:48:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:48:50 d2.utils.events]: \u001b[0m eta: 0:51:50  iter: 4079  total_loss: 1.363  loss_cls: 0.3577  loss_box_reg: 0.5294  loss_mask: 0.286  loss_rpn_cls: 0.05572  loss_rpn_loc: 0.1003  time: 0.7494  data_time: 0.1742  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:49:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:49:04 d2.utils.events]: \u001b[0m eta: 0:51:36  iter: 4099  total_loss: 1.3  loss_cls: 0.3509  loss_box_reg: 0.5355  loss_mask: 0.2815  loss_rpn_cls: 0.05423  loss_rpn_loc: 0.08561  time: 0.7493  data_time: 0.1579  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:49:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:49:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:49:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:49:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:49:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0863 s/iter. Eval: 0.0561 s/iter. Total: 0.1430 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 16:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0699 s/iter. Total: 0.1590 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 16:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0900 s/iter. Eval: 0.0721 s/iter. Total: 0.1628 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 16:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0903 s/iter. Eval: 0.0767 s/iter. Total: 0.1678 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 16:49:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.353992 (0.166845 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:49:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090156 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:49:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:49:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26723331180288085\n",
      "\u001b[32m[02/05 16:49:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:49:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:49:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:49:43 d2.utils.events]: \u001b[0m eta: 0:51:26  iter: 4119  total_loss: 1.381  loss_cls: 0.3674  loss_box_reg: 0.5666  loss_mask: 0.2991  loss_rpn_cls: 0.05312  loss_rpn_loc: 0.1018  time: 0.7500  data_time: 0.1319  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:49:56 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 4139  total_loss: 1.374  loss_cls: 0.3604  loss_box_reg: 0.5746  loss_mask: 0.3119  loss_rpn_cls: 0.05509  loss_rpn_loc: 0.09919  time: 0.7494  data_time: 0.1271  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:50:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:50:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:50:11 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 4159  total_loss: 1.224  loss_cls: 0.3125  loss_box_reg: 0.5019  loss_mask: 0.261  loss_rpn_cls: 0.0342  loss_rpn_loc: 0.05719  time: 0.7495  data_time: 0.1007  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:50:24 d2.utils.events]: \u001b[0m eta: 0:50:53  iter: 4179  total_loss: 1.322  loss_cls: 0.3338  loss_box_reg: 0.5446  loss_mask: 0.2889  loss_rpn_cls: 0.04804  loss_rpn_loc: 0.07421  time: 0.7489  data_time: 0.1245  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:50:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:50:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:50:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:50:44 d2.utils.events]: \u001b[0m eta: 0:50:43  iter: 4199  total_loss: 1.382  loss_cls: 0.3737  loss_box_reg: 0.5655  loss_mask: 0.2962  loss_rpn_cls: 0.04588  loss_rpn_loc: 0.08569  time: 0.7501  data_time: 0.1884  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:50:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:50:57 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 4219  total_loss: 1.282  loss_cls: 0.3237  loss_box_reg: 0.5204  loss_mask: 0.2804  loss_rpn_cls: 0.03763  loss_rpn_loc: 0.07634  time: 0.7496  data_time: 0.0957  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:51:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:51:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:51:14 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 4239  total_loss: 1.464  loss_cls: 0.3843  loss_box_reg: 0.5971  loss_mask: 0.3099  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.1081  time: 0.7502  data_time: 0.1755  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:51:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:51:29 d2.utils.events]: \u001b[0m eta: 0:50:12  iter: 4259  total_loss: 1.329  loss_cls: 0.3612  loss_box_reg: 0.5606  loss_mask: 0.2894  loss_rpn_cls: 0.03861  loss_rpn_loc: 0.08891  time: 0.7500  data_time: 0.1376  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:51:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:51:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:51:46 d2.utils.events]: \u001b[0m eta: 0:50:05  iter: 4279  total_loss: 1.448  loss_cls: 0.3768  loss_box_reg: 0.5791  loss_mask: 0.3018  loss_rpn_cls: 0.05839  loss_rpn_loc: 0.1174  time: 0.7507  data_time: 0.1743  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:51:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:51:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:52:04 d2.utils.events]: \u001b[0m eta: 0:49:52  iter: 4299  total_loss: 1.244  loss_cls: 0.324  loss_box_reg: 0.5272  loss_mask: 0.2958  loss_rpn_cls: 0.0369  loss_rpn_loc: 0.08012  time: 0.7513  data_time: 0.1885  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:52:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:52:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:52:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:52:24 d2.utils.events]: \u001b[0m eta: 0:49:42  iter: 4319  total_loss: 1.358  loss_cls: 0.3669  loss_box_reg: 0.5372  loss_mask: 0.2886  loss_rpn_cls: 0.05012  loss_rpn_loc: 0.082  time: 0.7524  data_time: 0.1747  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:52:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:52:38 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 4339  total_loss: 1.364  loss_cls: 0.3443  loss_box_reg: 0.5495  loss_mask: 0.2932  loss_rpn_cls: 0.03523  loss_rpn_loc: 0.06825  time: 0.7523  data_time: 0.1247  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:52:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:52:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:52:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:52:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:52:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:52:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0914 s/iter. Eval: 0.0639 s/iter. Total: 0.1560 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 16:52:59 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0008 s/iter. Inference: 0.0947 s/iter. Eval: 0.0804 s/iter. Total: 0.1759 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 16:53:04 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.0936 s/iter. Eval: 0.0776 s/iter. Total: 0.1721 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 16:53:09 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0936 s/iter. Eval: 0.0826 s/iter. Total: 0.1772 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 16:53:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.239509 (0.174479 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:53:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093015 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:53:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:53:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2629333859133063\n",
      "\u001b[32m[02/05 16:53:16 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 4359  total_loss: 1.382  loss_cls: 0.378  loss_box_reg: 0.5588  loss_mask: 0.3012  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.106  time: 0.7524  data_time: 0.2499  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:53:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:53:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:53:35 d2.utils.events]: \u001b[0m eta: 0:49:27  iter: 4379  total_loss: 1.262  loss_cls: 0.3413  loss_box_reg: 0.5584  loss_mask: 0.2901  loss_rpn_cls: 0.03494  loss_rpn_loc: 0.06468  time: 0.7533  data_time: 0.1732  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:53:48 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 4399  total_loss: 1.425  loss_cls: 0.3578  loss_box_reg: 0.5668  loss_mask: 0.312  loss_rpn_cls: 0.05957  loss_rpn_loc: 0.1022  time: 0.7527  data_time: 0.1234  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:53:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:54:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:54:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:54:08 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 4419  total_loss: 1.381  loss_cls: 0.3524  loss_box_reg: 0.5412  loss_mask: 0.2966  loss_rpn_cls: 0.05986  loss_rpn_loc: 0.1055  time: 0.7539  data_time: 0.1993  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:54:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:54:23 d2.utils.events]: \u001b[0m eta: 0:49:15  iter: 4439  total_loss: 1.318  loss_cls: 0.332  loss_box_reg: 0.5548  loss_mask: 0.2968  loss_rpn_cls: 0.03314  loss_rpn_loc: 0.04892  time: 0.7539  data_time: 0.1577  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:54:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:54:40 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 4459  total_loss: 1.37  loss_cls: 0.35  loss_box_reg: 0.5624  loss_mask: 0.2969  loss_rpn_cls: 0.04997  loss_rpn_loc: 0.09929  time: 0.7543  data_time: 0.1973  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:54:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:54:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:55:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:55:03 d2.utils.events]: \u001b[0m eta: 0:48:54  iter: 4479  total_loss: 1.297  loss_cls: 0.3404  loss_box_reg: 0.5236  loss_mask: 0.2758  loss_rpn_cls: 0.05498  loss_rpn_loc: 0.07946  time: 0.7560  data_time: 0.3419  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:55:16 d2.utils.events]: \u001b[0m eta: 0:48:44  iter: 4499  total_loss: 1.348  loss_cls: 0.3535  loss_box_reg: 0.5665  loss_mask: 0.3049  loss_rpn_cls: 0.04074  loss_rpn_loc: 0.09266  time: 0.7556  data_time: 0.1664  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:55:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:55:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:55:33 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 4519  total_loss: 1.315  loss_cls: 0.3425  loss_box_reg: 0.5344  loss_mask: 0.2956  loss_rpn_cls: 0.05126  loss_rpn_loc: 0.104  time: 0.7561  data_time: 0.1867  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:55:46 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 4539  total_loss: 1.423  loss_cls: 0.3819  loss_box_reg: 0.6033  loss_mask: 0.2916  loss_rpn_cls: 0.04621  loss_rpn_loc: 0.07573  time: 0.7556  data_time: 0.0971  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:55:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:56:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:56:06 d2.utils.events]: \u001b[0m eta: 0:48:24  iter: 4559  total_loss: 1.3  loss_cls: 0.3338  loss_box_reg: 0.5401  loss_mask: 0.2982  loss_rpn_cls: 0.0517  loss_rpn_loc: 0.1074  time: 0.7566  data_time: 0.2468  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:56:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:56:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:56:23 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 4579  total_loss: 1.215  loss_cls: 0.3136  loss_box_reg: 0.5213  loss_mask: 0.2706  loss_rpn_cls: 0.03224  loss_rpn_loc: 0.05927  time: 0.7570  data_time: 0.1254  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:56:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:56:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:56:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 16:56:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 16:56:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 16:56:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 16:56:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 16:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0980 s/iter. Eval: 0.0729 s/iter. Total: 0.1718 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 16:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0972 s/iter. Eval: 0.0782 s/iter. Total: 0.1763 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 16:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0009 s/iter. Inference: 0.0966 s/iter. Eval: 0.0770 s/iter. Total: 0.1745 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 16:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0009 s/iter. Inference: 0.0974 s/iter. Eval: 0.0850 s/iter. Total: 0.1834 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 16:57:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.988935 (0.180939 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:57:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097325 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 16:57:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 16:57:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27392226139985293\n",
      "\u001b[32m[02/05 16:57:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:57:03 d2.utils.events]: \u001b[0m eta: 0:48:10  iter: 4599  total_loss: 1.315  loss_cls: 0.3389  loss_box_reg: 0.5358  loss_mask: 0.2911  loss_rpn_cls: 0.03682  loss_rpn_loc: 0.07769  time: 0.7573  data_time: 0.1311  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:57:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:57:17 d2.utils.events]: \u001b[0m eta: 0:48:08  iter: 4619  total_loss: 1.274  loss_cls: 0.3303  loss_box_reg: 0.5349  loss_mask: 0.2831  loss_rpn_cls: 0.04261  loss_rpn_loc: 0.06093  time: 0.7571  data_time: 0.0837  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:57:31 d2.utils.events]: \u001b[0m eta: 0:48:06  iter: 4639  total_loss: 1.334  loss_cls: 0.3197  loss_box_reg: 0.5444  loss_mask: 0.2912  loss_rpn_cls: 0.0449  loss_rpn_loc: 0.08566  time: 0.7569  data_time: 0.1434  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:57:43 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 4659  total_loss: 1.303  loss_cls: 0.3544  loss_box_reg: 0.5538  loss_mask: 0.293  loss_rpn_cls: 0.03457  loss_rpn_loc: 0.07037  time: 0.7562  data_time: 0.0690  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:57:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:57:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:58:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:58:03 d2.utils.events]: \u001b[0m eta: 0:47:47  iter: 4679  total_loss: 1.326  loss_cls: 0.3494  loss_box_reg: 0.5585  loss_mask: 0.294  loss_rpn_cls: 0.04388  loss_rpn_loc: 0.07581  time: 0.7572  data_time: 0.2397  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:58:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:58:18 d2.utils.events]: \u001b[0m eta: 0:47:38  iter: 4699  total_loss: 1.334  loss_cls: 0.3516  loss_box_reg: 0.5443  loss_mask: 0.2894  loss_rpn_cls: 0.04472  loss_rpn_loc: 0.1053  time: 0.7573  data_time: 0.1866  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:58:31 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 4719  total_loss: 1.274  loss_cls: 0.3368  loss_box_reg: 0.5557  loss_mask: 0.2866  loss_rpn_cls: 0.03516  loss_rpn_loc: 0.05325  time: 0.7567  data_time: 0.1082  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:58:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:58:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:58:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:58:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:58:53 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 4739  total_loss: 1.426  loss_cls: 0.3782  loss_box_reg: 0.5724  loss_mask: 0.2954  loss_rpn_cls: 0.06369  loss_rpn_loc: 0.103  time: 0.7583  data_time: 0.1961  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:59:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:59:10 d2.utils.events]: \u001b[0m eta: 0:47:16  iter: 4759  total_loss: 1.434  loss_cls: 0.3865  loss_box_reg: 0.5648  loss_mask: 0.2957  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.1058  time: 0.7586  data_time: 0.1938  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:59:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:59:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:59:27 d2.utils.events]: \u001b[0m eta: 0:47:05  iter: 4779  total_loss: 1.28  loss_cls: 0.335  loss_box_reg: 0.5327  loss_mask: 0.3059  loss_rpn_cls: 0.02906  loss_rpn_loc: 0.05466  time: 0.7589  data_time: 0.1421  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:59:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:59:40 d2.utils.events]: \u001b[0m eta: 0:46:44  iter: 4799  total_loss: 1.283  loss_cls: 0.3369  loss_box_reg: 0.5504  loss_mask: 0.2993  loss_rpn_cls: 0.03549  loss_rpn_loc: 0.0564  time: 0.7585  data_time: 0.0704  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 16:59:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:59:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 16:59:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:00:00 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 4819  total_loss: 1.41  loss_cls: 0.3628  loss_box_reg: 0.5613  loss_mask: 0.3041  loss_rpn_cls: 0.05865  loss_rpn_loc: 0.1103  time: 0.7596  data_time: 0.1881  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:00:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:00:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:00:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:00:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:00:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:00:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:00:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:00:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:00:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0873 s/iter. Eval: 0.0535 s/iter. Total: 0.1414 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 17:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0902 s/iter. Eval: 0.0722 s/iter. Total: 0.1632 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 17:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0910 s/iter. Eval: 0.0751 s/iter. Total: 0.1669 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 17:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0807 s/iter. Total: 0.1729 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 17:00:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.699478 (0.169823 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:00:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090665 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:00:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:00:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27185221062061526\n",
      "\u001b[32m[02/05 17:00:40 d2.utils.events]: \u001b[0m eta: 0:46:21  iter: 4839  total_loss: 1.395  loss_cls: 0.3573  loss_box_reg: 0.5756  loss_mask: 0.2998  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.1045  time: 0.7602  data_time: 0.2005  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:00:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:00:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:00:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:01:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:01:02 d2.utils.events]: \u001b[0m eta: 0:45:57  iter: 4859  total_loss: 1.291  loss_cls: 0.3397  loss_box_reg: 0.5351  loss_mask: 0.2961  loss_rpn_cls: 0.04649  loss_rpn_loc: 0.07754  time: 0.7617  data_time: 0.1858  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:01:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:01:18 d2.utils.events]: \u001b[0m eta: 0:45:47  iter: 4879  total_loss: 1.367  loss_cls: 0.3699  loss_box_reg: 0.5612  loss_mask: 0.2914  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.1108  time: 0.7619  data_time: 0.2245  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:01:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:01:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:01:35 d2.utils.events]: \u001b[0m eta: 0:45:26  iter: 4899  total_loss: 1.246  loss_cls: 0.3363  loss_box_reg: 0.5218  loss_mask: 0.2949  loss_rpn_cls: 0.04569  loss_rpn_loc: 0.06089  time: 0.7622  data_time: 0.1732  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:01:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:01:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:01:56 d2.utils.events]: \u001b[0m eta: 0:45:15  iter: 4919  total_loss: 1.368  loss_cls: 0.3583  loss_box_reg: 0.5382  loss_mask: 0.294  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.1177  time: 0.7633  data_time: 0.2692  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:02:09 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 4939  total_loss: 1.197  loss_cls: 0.3275  loss_box_reg: 0.5282  loss_mask: 0.2877  loss_rpn_cls: 0.02443  loss_rpn_loc: 0.04228  time: 0.7628  data_time: 0.1280  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:02:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:02:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:02:26 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 4959  total_loss: 1.208  loss_cls: 0.3116  loss_box_reg: 0.5209  loss_mask: 0.271  loss_rpn_cls: 0.03626  loss_rpn_loc: 0.05914  time: 0.7632  data_time: 0.1297  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:02:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:02:40 d2.utils.events]: \u001b[0m eta: 0:44:29  iter: 4979  total_loss: 1.321  loss_cls: 0.3331  loss_box_reg: 0.5438  loss_mask: 0.3003  loss_rpn_cls: 0.05438  loss_rpn_loc: 0.08624  time: 0.7629  data_time: 0.1277  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:02:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:02:55 d2.utils.events]: \u001b[0m eta: 0:44:15  iter: 4999  total_loss: 1.299  loss_cls: 0.3633  loss_box_reg: 0.5382  loss_mask: 0.2972  loss_rpn_cls: 0.0375  loss_rpn_loc: 0.07593  time: 0.7630  data_time: 0.1878  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:03:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:03:11 d2.utils.events]: \u001b[0m eta: 0:44:07  iter: 5019  total_loss: 1.395  loss_cls: 0.3559  loss_box_reg: 0.5634  loss_mask: 0.2944  loss_rpn_cls: 0.04875  loss_rpn_loc: 0.07778  time: 0.7630  data_time: 0.1280  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:03:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:03:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:03:27 d2.utils.events]: \u001b[0m eta: 0:43:59  iter: 5039  total_loss: 1.425  loss_cls: 0.3806  loss_box_reg: 0.5608  loss_mask: 0.2957  loss_rpn_cls: 0.05783  loss_rpn_loc: 0.09776  time: 0.7632  data_time: 0.1059  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:03:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:03:42 d2.utils.events]: \u001b[0m eta: 0:44:00  iter: 5059  total_loss: 1.299  loss_cls: 0.3376  loss_box_reg: 0.5294  loss_mask: 0.287  loss_rpn_cls: 0.05303  loss_rpn_loc: 0.07928  time: 0.7631  data_time: 0.1096  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:03:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:03:58 d2.utils.events]: \u001b[0m eta: 0:43:49  iter: 5079  total_loss: 1.361  loss_cls: 0.3364  loss_box_reg: 0.5467  loss_mask: 0.3038  loss_rpn_cls: 0.04235  loss_rpn_loc: 0.08088  time: 0.7634  data_time: 0.1696  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:04:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:04:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:04:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:04:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:04:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:04:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0965 s/iter. Eval: 0.0620 s/iter. Total: 0.1592 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 17:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0939 s/iter. Eval: 0.0756 s/iter. Total: 0.1704 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 17:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0928 s/iter. Eval: 0.0752 s/iter. Total: 0.1688 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 17:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0935 s/iter. Eval: 0.0815 s/iter. Total: 0.1759 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 17:04:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.096703 (0.173247 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:04:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092749 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:04:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:04:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.273398762654121\n",
      "\u001b[32m[02/05 17:04:34 d2.utils.events]: \u001b[0m eta: 0:43:37  iter: 5099  total_loss: 1.402  loss_cls: 0.3582  loss_box_reg: 0.5683  loss_mask: 0.297  loss_rpn_cls: 0.03268  loss_rpn_loc: 0.07824  time: 0.7630  data_time: 0.1504  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:04:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:04:50 d2.utils.events]: \u001b[0m eta: 0:43:28  iter: 5119  total_loss: 1.438  loss_cls: 0.3896  loss_box_reg: 0.5804  loss_mask: 0.3056  loss_rpn_cls: 0.06134  loss_rpn_loc: 0.1035  time: 0.7632  data_time: 0.2156  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:05:03 d2.utils.events]: \u001b[0m eta: 0:43:19  iter: 5139  total_loss: 1.367  loss_cls: 0.3496  loss_box_reg: 0.5742  loss_mask: 0.307  loss_rpn_cls: 0.05095  loss_rpn_loc: 0.1102  time: 0.7627  data_time: 0.1380  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:05:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:05:16 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 5159  total_loss: 1.19  loss_cls: 0.2999  loss_box_reg: 0.5444  loss_mask: 0.3022  loss_rpn_cls: 0.02997  loss_rpn_loc: 0.05057  time: 0.7623  data_time: 0.1086  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:05:30 d2.utils.events]: \u001b[0m eta: 0:42:56  iter: 5179  total_loss: 1.246  loss_cls: 0.3288  loss_box_reg: 0.545  loss_mask: 0.2894  loss_rpn_cls: 0.0344  loss_rpn_loc: 0.06134  time: 0.7620  data_time: 0.1959  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:05:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:05:46 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 5199  total_loss: 1.373  loss_cls: 0.3429  loss_box_reg: 0.574  loss_mask: 0.3076  loss_rpn_cls: 0.04909  loss_rpn_loc: 0.08894  time: 0.7621  data_time: 0.1706  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:05:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:06:00 d2.utils.events]: \u001b[0m eta: 0:42:36  iter: 5219  total_loss: 1.273  loss_cls: 0.3294  loss_box_reg: 0.5239  loss_mask: 0.2785  loss_rpn_cls: 0.0398  loss_rpn_loc: 0.09525  time: 0.7620  data_time: 0.1367  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:06:13 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 5239  total_loss: 1.246  loss_cls: 0.3227  loss_box_reg: 0.5033  loss_mask: 0.2777  loss_rpn_cls: 0.0423  loss_rpn_loc: 0.07171  time: 0.7616  data_time: 0.1668  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:06:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:06:28 d2.utils.events]: \u001b[0m eta: 0:42:13  iter: 5259  total_loss: 1.314  loss_cls: 0.3161  loss_box_reg: 0.5464  loss_mask: 0.2903  loss_rpn_cls: 0.04158  loss_rpn_loc: 0.06357  time: 0.7615  data_time: 0.1422  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:06:42 d2.utils.events]: \u001b[0m eta: 0:42:00  iter: 5279  total_loss: 1.389  loss_cls: 0.3639  loss_box_reg: 0.5619  loss_mask: 0.3123  loss_rpn_cls: 0.0503  loss_rpn_loc: 0.1026  time: 0.7612  data_time: 0.1681  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:06:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:06:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:06:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:06:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:07:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:07:07 d2.utils.events]: \u001b[0m eta: 0:41:52  iter: 5299  total_loss: 1.41  loss_cls: 0.3853  loss_box_reg: 0.5538  loss_mask: 0.3139  loss_rpn_cls: 0.05591  loss_rpn_loc: 0.1075  time: 0.7630  data_time: 0.2194  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:07:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:07:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:07:23 d2.utils.events]: \u001b[0m eta: 0:41:41  iter: 5319  total_loss: 1.229  loss_cls: 0.3192  loss_box_reg: 0.5363  loss_mask: 0.2747  loss_rpn_cls: 0.03335  loss_rpn_loc: 0.04601  time: 0.7633  data_time: 0.1621  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:07:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:07:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:07:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:07:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:07:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:07:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:07:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.0586 s/iter. Total: 0.1548 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 17:07:34 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0710 s/iter. Total: 0.1629 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 17:07:39 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0711 s/iter. Total: 0.1623 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 17:07:44 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0757 s/iter. Total: 0.1671 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 17:07:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.362011 (0.166914 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:07:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090415 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:07:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:07:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27039715970702866\n",
      "\u001b[32m[02/05 17:07:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:08:01 d2.utils.events]: \u001b[0m eta: 0:41:29  iter: 5339  total_loss: 1.24  loss_cls: 0.3267  loss_box_reg: 0.5271  loss_mask: 0.2859  loss_rpn_cls: 0.03367  loss_rpn_loc: 0.0732  time: 0.7636  data_time: 0.2216  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:08:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:08:17 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 5359  total_loss: 1.341  loss_cls: 0.3418  loss_box_reg: 0.567  loss_mask: 0.303  loss_rpn_cls: 0.0513  loss_rpn_loc: 0.07701  time: 0.7636  data_time: 0.1678  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:08:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:08:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:08:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:08:37 d2.utils.events]: \u001b[0m eta: 0:40:57  iter: 5379  total_loss: 1.338  loss_cls: 0.3565  loss_box_reg: 0.5391  loss_mask: 0.283  loss_rpn_cls: 0.05961  loss_rpn_loc: 0.1026  time: 0.7644  data_time: 0.1930  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:08:49 d2.utils.events]: \u001b[0m eta: 0:40:47  iter: 5399  total_loss: 1.418  loss_cls: 0.3681  loss_box_reg: 0.5614  loss_mask: 0.3068  loss_rpn_cls: 0.05971  loss_rpn_loc: 0.1113  time: 0.7640  data_time: 0.1298  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:08:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:08:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:09:06 d2.utils.events]: \u001b[0m eta: 0:40:32  iter: 5419  total_loss: 1.167  loss_cls: 0.2956  loss_box_reg: 0.5196  loss_mask: 0.2756  loss_rpn_cls: 0.02749  loss_rpn_loc: 0.06254  time: 0.7643  data_time: 0.1703  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:09:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:09:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:09:22 d2.utils.events]: \u001b[0m eta: 0:40:19  iter: 5439  total_loss: 1.332  loss_cls: 0.3398  loss_box_reg: 0.5421  loss_mask: 0.293  loss_rpn_cls: 0.04285  loss_rpn_loc: 0.06535  time: 0.7643  data_time: 0.1148  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:09:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:09:36 d2.utils.events]: \u001b[0m eta: 0:40:05  iter: 5459  total_loss: 1.323  loss_cls: 0.3454  loss_box_reg: 0.5397  loss_mask: 0.3012  loss_rpn_cls: 0.04882  loss_rpn_loc: 0.06755  time: 0.7641  data_time: 0.1333  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:09:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:09:51 d2.utils.events]: \u001b[0m eta: 0:39:54  iter: 5479  total_loss: 1.313  loss_cls: 0.3338  loss_box_reg: 0.5203  loss_mask: 0.2813  loss_rpn_cls: 0.04326  loss_rpn_loc: 0.06801  time: 0.7641  data_time: 0.1742  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:09:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:10:09 d2.utils.events]: \u001b[0m eta: 0:39:43  iter: 5499  total_loss: 1.273  loss_cls: 0.3488  loss_box_reg: 0.5562  loss_mask: 0.2897  loss_rpn_cls: 0.03946  loss_rpn_loc: 0.05602  time: 0.7645  data_time: 0.2426  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:10:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:10:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:10:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:10:28 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 5519  total_loss: 1.408  loss_cls: 0.3752  loss_box_reg: 0.57  loss_mask: 0.3107  loss_rpn_cls: 0.06653  loss_rpn_loc: 0.102  time: 0.7652  data_time: 0.1718  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:10:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:10:44 d2.utils.events]: \u001b[0m eta: 0:39:21  iter: 5539  total_loss: 1.315  loss_cls: 0.3433  loss_box_reg: 0.544  loss_mask: 0.2951  loss_rpn_cls: 0.04333  loss_rpn_loc: 0.07493  time: 0.7654  data_time: 0.2013  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:10:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:10:59 d2.utils.events]: \u001b[0m eta: 0:39:04  iter: 5559  total_loss: 1.323  loss_cls: 0.333  loss_box_reg: 0.5439  loss_mask: 0.2998  loss_rpn_cls: 0.03934  loss_rpn_loc: 0.059  time: 0.7653  data_time: 0.1423  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:11:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:11:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:11:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:11:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:11:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:11:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:11:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0642 s/iter. Total: 0.1559 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 17:11:10 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0695 s/iter. Total: 0.1590 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 17:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0718 s/iter. Total: 0.1614 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 17:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0890 s/iter. Eval: 0.0762 s/iter. Total: 0.1660 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 17:11:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.095176 (0.164614 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:11:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088813 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:11:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:11:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26862368236432604\n",
      "\u001b[32m[02/05 17:11:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:11:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:11:35 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 5579  total_loss: 1.348  loss_cls: 0.3372  loss_box_reg: 0.5821  loss_mask: 0.3069  loss_rpn_cls: 0.03309  loss_rpn_loc: 0.06625  time: 0.7652  data_time: 0.0933  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:11:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:11:50 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 5599  total_loss: 1.186  loss_cls: 0.3039  loss_box_reg: 0.5273  loss_mask: 0.2881  loss_rpn_cls: 0.03068  loss_rpn_loc: 0.06856  time: 0.7651  data_time: 0.1234  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:11:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:11:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:10 d2.utils.events]: \u001b[0m eta: 0:38:24  iter: 5619  total_loss: 1.325  loss_cls: 0.3264  loss_box_reg: 0.5499  loss_mask: 0.298  loss_rpn_cls: 0.05916  loss_rpn_loc: 0.05729  time: 0.7661  data_time: 0.1526  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:12:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:30 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 5639  total_loss: 1.304  loss_cls: 0.3264  loss_box_reg: 0.5471  loss_mask: 0.2923  loss_rpn_cls: 0.04691  loss_rpn_loc: 0.0968  time: 0.7669  data_time: 0.2489  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:12:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:48 d2.utils.events]: \u001b[0m eta: 0:37:56  iter: 5659  total_loss: 1.389  loss_cls: 0.3652  loss_box_reg: 0.5555  loss_mask: 0.2988  loss_rpn_cls: 0.05753  loss_rpn_loc: 0.1153  time: 0.7673  data_time: 0.1868  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:12:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:12:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:13:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:13:06 d2.utils.events]: \u001b[0m eta: 0:37:46  iter: 5679  total_loss: 1.345  loss_cls: 0.3581  loss_box_reg: 0.5412  loss_mask: 0.3049  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.1097  time: 0.7679  data_time: 0.1957  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:13:19 d2.utils.events]: \u001b[0m eta: 0:37:35  iter: 5699  total_loss: 1.308  loss_cls: 0.3352  loss_box_reg: 0.5301  loss_mask: 0.2862  loss_rpn_cls: 0.03747  loss_rpn_loc: 0.06818  time: 0.7674  data_time: 0.1166  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:13:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:13:34 d2.utils.events]: \u001b[0m eta: 0:37:23  iter: 5719  total_loss: 1.385  loss_cls: 0.3738  loss_box_reg: 0.565  loss_mask: 0.2962  loss_rpn_cls: 0.04503  loss_rpn_loc: 0.1073  time: 0.7673  data_time: 0.1401  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:13:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:13:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:13:50 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 5739  total_loss: 1.336  loss_cls: 0.3435  loss_box_reg: 0.5536  loss_mask: 0.2932  loss_rpn_cls: 0.05447  loss_rpn_loc: 0.06333  time: 0.7675  data_time: 0.1222  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:14:05 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 5759  total_loss: 1.416  loss_cls: 0.3729  loss_box_reg: 0.5548  loss_mask: 0.3003  loss_rpn_cls: 0.06042  loss_rpn_loc: 0.1173  time: 0.7674  data_time: 0.2059  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:14:16 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 5779  total_loss: 1.192  loss_cls: 0.3078  loss_box_reg: 0.5172  loss_mask: 0.2838  loss_rpn_cls: 0.03046  loss_rpn_loc: 0.04273  time: 0.7667  data_time: 0.0922  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:14:30 d2.utils.events]: \u001b[0m eta: 0:36:31  iter: 5799  total_loss: 1.221  loss_cls: 0.3211  loss_box_reg: 0.5367  loss_mask: 0.2723  loss_rpn_cls: 0.02511  loss_rpn_loc: 0.05556  time: 0.7663  data_time: 0.1670  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:14:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:14:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:14:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:14:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:14:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:14:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0938 s/iter. Eval: 0.0615 s/iter. Total: 0.1560 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 17:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0721 s/iter. Total: 0.1634 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 17:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0723 s/iter. Total: 0.1623 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 17:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0892 s/iter. Eval: 0.0762 s/iter. Total: 0.1663 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 17:14:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.107966 (0.164724 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:14:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088960 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:14:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:14:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2702116253551942\n",
      "\u001b[32m[02/05 17:14:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:15:06 d2.utils.events]: \u001b[0m eta: 0:36:14  iter: 5819  total_loss: 1.289  loss_cls: 0.331  loss_box_reg: 0.5467  loss_mask: 0.282  loss_rpn_cls: 0.0311  loss_rpn_loc: 0.05575  time: 0.7664  data_time: 0.1611  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:15:21 d2.utils.events]: \u001b[0m eta: 0:36:03  iter: 5839  total_loss: 1.325  loss_cls: 0.3485  loss_box_reg: 0.5195  loss_mask: 0.2844  loss_rpn_cls: 0.04776  loss_rpn_loc: 0.09843  time: 0.7662  data_time: 0.2215  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:15:32 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 5859  total_loss: 1.277  loss_cls: 0.3333  loss_box_reg: 0.547  loss_mask: 0.3034  loss_rpn_cls: 0.02635  loss_rpn_loc: 0.04874  time: 0.7656  data_time: 0.0956  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:15:45 d2.utils.events]: \u001b[0m eta: 0:35:41  iter: 5879  total_loss: 1.359  loss_cls: 0.3755  loss_box_reg: 0.5777  loss_mask: 0.2945  loss_rpn_cls: 0.04503  loss_rpn_loc: 0.08219  time: 0.7651  data_time: 0.1253  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:15:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:15:58 d2.utils.events]: \u001b[0m eta: 0:35:29  iter: 5899  total_loss: 1.178  loss_cls: 0.3074  loss_box_reg: 0.5273  loss_mask: 0.2795  loss_rpn_cls: 0.03636  loss_rpn_loc: 0.05883  time: 0.7648  data_time: 0.1067  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:16:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:16:13 d2.utils.events]: \u001b[0m eta: 0:35:16  iter: 5919  total_loss: 1.384  loss_cls: 0.3549  loss_box_reg: 0.5413  loss_mask: 0.3089  loss_rpn_cls: 0.05251  loss_rpn_loc: 0.1012  time: 0.7647  data_time: 0.1327  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:16:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:16:28 d2.utils.events]: \u001b[0m eta: 0:35:02  iter: 5939  total_loss: 1.172  loss_cls: 0.3084  loss_box_reg: 0.5225  loss_mask: 0.293  loss_rpn_cls: 0.02919  loss_rpn_loc: 0.05149  time: 0.7647  data_time: 0.1496  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:16:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:16:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:16:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:16:47 d2.utils.events]: \u001b[0m eta: 0:34:53  iter: 5959  total_loss: 1.308  loss_cls: 0.3386  loss_box_reg: 0.5459  loss_mask: 0.3014  loss_rpn_cls: 0.04618  loss_rpn_loc: 0.109  time: 0.7652  data_time: 0.1164  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:16:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:17:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:17:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:17:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:17:10 d2.utils.events]: \u001b[0m eta: 0:34:47  iter: 5979  total_loss: 1.386  loss_cls: 0.3539  loss_box_reg: 0.5553  loss_mask: 0.3051  loss_rpn_cls: 0.03794  loss_rpn_loc: 0.09094  time: 0.7666  data_time: 0.2574  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:17:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:17:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:17:28 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 5999  total_loss: 1.334  loss_cls: 0.3687  loss_box_reg: 0.5514  loss_mask: 0.2897  loss_rpn_cls: 0.05082  loss_rpn_loc: 0.0837  time: 0.7671  data_time: 0.1930  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:17:41 d2.utils.events]: \u001b[0m eta: 0:34:21  iter: 6019  total_loss: 1.366  loss_cls: 0.3522  loss_box_reg: 0.5487  loss_mask: 0.2929  loss_rpn_cls: 0.04617  loss_rpn_loc: 0.09729  time: 0.7666  data_time: 0.1416  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:17:52 d2.utils.events]: \u001b[0m eta: 0:34:00  iter: 6039  total_loss: 1.222  loss_cls: 0.3408  loss_box_reg: 0.5201  loss_mask: 0.2729  loss_rpn_cls: 0.03379  loss_rpn_loc: 0.05866  time: 0.7660  data_time: 0.0886  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:17:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:18:00 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:18:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:18:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:18:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:18:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:18:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:18:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:18:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0954 s/iter. Eval: 0.0741 s/iter. Total: 0.1703 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 17:18:10 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0009 s/iter. Inference: 0.0942 s/iter. Eval: 0.0790 s/iter. Total: 0.1742 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 17:18:15 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0009 s/iter. Inference: 0.0923 s/iter. Eval: 0.0772 s/iter. Total: 0.1704 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 17:18:20 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0917 s/iter. Eval: 0.0806 s/iter. Total: 0.1732 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 17:18:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.911521 (0.171651 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:18:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091539 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:18:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:18:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2727160859006012\n",
      "\u001b[32m[02/05 17:18:30 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 6059  total_loss: 1.303  loss_cls: 0.335  loss_box_reg: 0.5448  loss_mask: 0.2735  loss_rpn_cls: 0.04793  loss_rpn_loc: 0.09292  time: 0.7660  data_time: 0.1231  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:18:42 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 6079  total_loss: 1.309  loss_cls: 0.3296  loss_box_reg: 0.5626  loss_mask: 0.3027  loss_rpn_cls: 0.05001  loss_rpn_loc: 0.09164  time: 0.7655  data_time: 0.1241  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:18:56 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 6099  total_loss: 1.255  loss_cls: 0.3198  loss_box_reg: 0.5072  loss_mask: 0.2773  loss_rpn_cls: 0.03765  loss_rpn_loc: 0.06829  time: 0.7652  data_time: 0.1887  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:18:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:19:09 d2.utils.events]: \u001b[0m eta: 0:33:09  iter: 6119  total_loss: 1.298  loss_cls: 0.348  loss_box_reg: 0.5531  loss_mask: 0.2954  loss_rpn_cls: 0.04775  loss_rpn_loc: 0.08447  time: 0.7649  data_time: 0.0714  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:19:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:19:23 d2.utils.events]: \u001b[0m eta: 0:32:55  iter: 6139  total_loss: 1.34  loss_cls: 0.3241  loss_box_reg: 0.544  loss_mask: 0.287  loss_rpn_cls: 0.0378  loss_rpn_loc: 0.07885  time: 0.7647  data_time: 0.1236  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:19:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:19:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:19:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:19:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:19:44 d2.utils.events]: \u001b[0m eta: 0:32:48  iter: 6159  total_loss: 1.326  loss_cls: 0.3259  loss_box_reg: 0.542  loss_mask: 0.2967  loss_rpn_cls: 0.05005  loss_rpn_loc: 0.08793  time: 0.7656  data_time: 0.1825  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:19:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:20:00 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 6179  total_loss: 1.339  loss_cls: 0.3632  loss_box_reg: 0.546  loss_mask: 0.3062  loss_rpn_cls: 0.04709  loss_rpn_loc: 0.09765  time: 0.7658  data_time: 0.2248  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:20:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:20:14 d2.utils.events]: \u001b[0m eta: 0:32:29  iter: 6199  total_loss: 1.275  loss_cls: 0.3241  loss_box_reg: 0.561  loss_mask: 0.2924  loss_rpn_cls: 0.04934  loss_rpn_loc: 0.05771  time: 0.7655  data_time: 0.1340  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:20:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:20:29 d2.utils.events]: \u001b[0m eta: 0:32:18  iter: 6219  total_loss: 1.299  loss_cls: 0.3397  loss_box_reg: 0.5315  loss_mask: 0.2843  loss_rpn_cls: 0.04471  loss_rpn_loc: 0.06497  time: 0.7655  data_time: 0.1484  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:20:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:20:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:20:46 d2.utils.events]: \u001b[0m eta: 0:32:08  iter: 6239  total_loss: 1.311  loss_cls: 0.3474  loss_box_reg: 0.5492  loss_mask: 0.2894  loss_rpn_cls: 0.04772  loss_rpn_loc: 0.0852  time: 0.7657  data_time: 0.1775  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:20:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:21:01 d2.utils.events]: \u001b[0m eta: 0:32:03  iter: 6259  total_loss: 1.356  loss_cls: 0.3454  loss_box_reg: 0.5562  loss_mask: 0.2888  loss_rpn_cls: 0.04572  loss_rpn_loc: 0.09582  time: 0.7656  data_time: 0.1213  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:21:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:21:17 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 6279  total_loss: 1.296  loss_cls: 0.3391  loss_box_reg: 0.5489  loss_mask: 0.2924  loss_rpn_cls: 0.04162  loss_rpn_loc: 0.08232  time: 0.7658  data_time: 0.2052  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:21:26 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:21:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:21:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:21:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:21:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:21:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:21:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0714 s/iter. Total: 0.1633 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 17:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0892 s/iter. Eval: 0.0739 s/iter. Total: 0.1640 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 17:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0734 s/iter. Total: 0.1629 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 17:21:49 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0890 s/iter. Eval: 0.0774 s/iter. Total: 0.1673 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 17:21:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.390063 (0.167156 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:21:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089117 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:21:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:21:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27259999668084867\n",
      "\u001b[32m[02/05 17:21:57 d2.utils.events]: \u001b[0m eta: 0:31:42  iter: 6299  total_loss: 1.354  loss_cls: 0.352  loss_box_reg: 0.5452  loss_mask: 0.3042  loss_rpn_cls: 0.05207  loss_rpn_loc: 0.08558  time: 0.7664  data_time: 0.2609  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:22:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:22:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:22:13 d2.utils.events]: \u001b[0m eta: 0:31:34  iter: 6319  total_loss: 1.269  loss_cls: 0.3177  loss_box_reg: 0.5623  loss_mask: 0.2997  loss_rpn_cls: 0.0284  loss_rpn_loc: 0.04624  time: 0.7665  data_time: 0.1235  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:22:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:22:27 d2.utils.events]: \u001b[0m eta: 0:31:23  iter: 6339  total_loss: 1.352  loss_cls: 0.3375  loss_box_reg: 0.5503  loss_mask: 0.2996  loss_rpn_cls: 0.0477  loss_rpn_loc: 0.06658  time: 0.7663  data_time: 0.1338  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:22:40 d2.utils.events]: \u001b[0m eta: 0:31:11  iter: 6359  total_loss: 1.32  loss_cls: 0.3514  loss_box_reg: 0.5369  loss_mask: 0.287  loss_rpn_cls: 0.04626  loss_rpn_loc: 0.06582  time: 0.7659  data_time: 0.1364  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:22:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:22:57 d2.utils.events]: \u001b[0m eta: 0:31:02  iter: 6379  total_loss: 1.316  loss_cls: 0.3465  loss_box_reg: 0.5187  loss_mask: 0.295  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.09852  time: 0.7661  data_time: 0.1979  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:23:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:23:12 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 6399  total_loss: 1.352  loss_cls: 0.3634  loss_box_reg: 0.5834  loss_mask: 0.2944  loss_rpn_cls: 0.04713  loss_rpn_loc: 0.0971  time: 0.7661  data_time: 0.1618  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:23:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:23:27 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 6419  total_loss: 1.195  loss_cls: 0.3132  loss_box_reg: 0.53  loss_mask: 0.2769  loss_rpn_cls: 0.03447  loss_rpn_loc: 0.06115  time: 0.7660  data_time: 0.1435  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:23:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:23:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:23:45 d2.utils.events]: \u001b[0m eta: 0:30:32  iter: 6439  total_loss: 1.377  loss_cls: 0.345  loss_box_reg: 0.5407  loss_mask: 0.2921  loss_rpn_cls: 0.05336  loss_rpn_loc: 0.1065  time: 0.7665  data_time: 0.2140  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:23:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:24:01 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 6459  total_loss: 1.312  loss_cls: 0.3492  loss_box_reg: 0.547  loss_mask: 0.2903  loss_rpn_cls: 0.04201  loss_rpn_loc: 0.06104  time: 0.7665  data_time: 0.1703  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:24:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:24:17 d2.utils.events]: \u001b[0m eta: 0:30:15  iter: 6479  total_loss: 1.241  loss_cls: 0.3184  loss_box_reg: 0.5365  loss_mask: 0.2905  loss_rpn_cls: 0.04162  loss_rpn_loc: 0.09383  time: 0.7666  data_time: 0.1658  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:24:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:24:34 d2.utils.events]: \u001b[0m eta: 0:30:06  iter: 6499  total_loss: 1.344  loss_cls: 0.3445  loss_box_reg: 0.5571  loss_mask: 0.3082  loss_rpn_cls: 0.05269  loss_rpn_loc: 0.09818  time: 0.7670  data_time: 0.2243  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:24:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:24:48 d2.utils.events]: \u001b[0m eta: 0:29:51  iter: 6519  total_loss: 1.156  loss_cls: 0.2715  loss_box_reg: 0.5149  loss_mask: 0.2758  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.04236  time: 0.7667  data_time: 0.1257  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:24:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:24:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:24:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:24:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:24:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:25:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0914 s/iter. Eval: 0.0687 s/iter. Total: 0.1610 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 17:25:07 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0746 s/iter. Total: 0.1660 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 17:25:12 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0731 s/iter. Total: 0.1646 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 17:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0919 s/iter. Eval: 0.0805 s/iter. Total: 0.1732 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 17:25:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.018850 (0.172576 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:25:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092824 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:25:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27244682325203\n",
      "\u001b[32m[02/05 17:25:24 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 6539  total_loss: 1.248  loss_cls: 0.3579  loss_box_reg: 0.5249  loss_mask: 0.2763  loss_rpn_cls: 0.03492  loss_rpn_loc: 0.07523  time: 0.7665  data_time: 0.1521  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:25:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:25:38 d2.utils.events]: \u001b[0m eta: 0:29:32  iter: 6559  total_loss: 1.183  loss_cls: 0.3219  loss_box_reg: 0.5218  loss_mask: 0.2774  loss_rpn_cls: 0.02914  loss_rpn_loc: 0.05591  time: 0.7663  data_time: 0.1008  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:25:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:25:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:25:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:25:59 d2.utils.events]: \u001b[0m eta: 0:29:23  iter: 6579  total_loss: 1.493  loss_cls: 0.4079  loss_box_reg: 0.5612  loss_mask: 0.3171  loss_rpn_cls: 0.07668  loss_rpn_loc: 0.1172  time: 0.7672  data_time: 0.2585  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:26:11 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 6599  total_loss: 1.254  loss_cls: 0.3227  loss_box_reg: 0.5416  loss_mask: 0.2873  loss_rpn_cls: 0.02818  loss_rpn_loc: 0.05766  time: 0.7667  data_time: 0.1247  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:26:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:26:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:26:28 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 6619  total_loss: 1.39  loss_cls: 0.3669  loss_box_reg: 0.554  loss_mask: 0.3083  loss_rpn_cls: 0.05185  loss_rpn_loc: 0.09205  time: 0.7670  data_time: 0.1499  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:26:41 d2.utils.events]: \u001b[0m eta: 0:28:51  iter: 6639  total_loss: 1.296  loss_cls: 0.347  loss_box_reg: 0.547  loss_mask: 0.2914  loss_rpn_cls: 0.04771  loss_rpn_loc: 0.08196  time: 0.7665  data_time: 0.1066  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:26:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:26:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:26:59 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 6659  total_loss: 1.286  loss_cls: 0.3344  loss_box_reg: 0.5317  loss_mask: 0.2932  loss_rpn_cls: 0.03943  loss_rpn_loc: 0.09379  time: 0.7670  data_time: 0.2019  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:27:12 d2.utils.events]: \u001b[0m eta: 0:28:31  iter: 6679  total_loss: 1.223  loss_cls: 0.3136  loss_box_reg: 0.5167  loss_mask: 0.284  loss_rpn_cls: 0.03829  loss_rpn_loc: 0.05206  time: 0.7665  data_time: 0.1392  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:27:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:27:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:27:29 d2.utils.events]: \u001b[0m eta: 0:28:20  iter: 6699  total_loss: 1.35  loss_cls: 0.3434  loss_box_reg: 0.5437  loss_mask: 0.2865  loss_rpn_cls: 0.04732  loss_rpn_loc: 0.09524  time: 0.7669  data_time: 0.2427  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:27:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:27:43 d2.utils.events]: \u001b[0m eta: 0:28:10  iter: 6719  total_loss: 1.322  loss_cls: 0.3488  loss_box_reg: 0.5562  loss_mask: 0.2943  loss_rpn_cls: 0.04203  loss_rpn_loc: 0.06947  time: 0.7666  data_time: 0.0794  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:27:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:27:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:28:01 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 6739  total_loss: 1.313  loss_cls: 0.3538  loss_box_reg: 0.5385  loss_mask: 0.2898  loss_rpn_cls: 0.0425  loss_rpn_loc: 0.09182  time: 0.7670  data_time: 0.2211  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:28:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:28:18 d2.utils.events]: \u001b[0m eta: 0:27:48  iter: 6759  total_loss: 1.302  loss_cls: 0.3255  loss_box_reg: 0.5441  loss_mask: 0.2992  loss_rpn_cls: 0.04522  loss_rpn_loc: 0.06776  time: 0.7672  data_time: 0.1902  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:28:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:28:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:28:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:28:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:28:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:28:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:28:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0014 s/iter. Inference: 0.1021 s/iter. Eval: 0.0811 s/iter. Total: 0.1846 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/05 17:28:38 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0014 s/iter. Inference: 0.0959 s/iter. Eval: 0.0830 s/iter. Total: 0.1803 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 17:28:43 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0011 s/iter. Inference: 0.0932 s/iter. Eval: 0.0796 s/iter. Total: 0.1739 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 17:28:48 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0010 s/iter. Inference: 0.0922 s/iter. Eval: 0.0821 s/iter. Total: 0.1754 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 17:28:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.047386 (0.172822 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:28:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091477 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:28:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:28:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2723909133391666\n",
      "\u001b[32m[02/05 17:28:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:28:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:28:59 d2.utils.events]: \u001b[0m eta: 0:27:40  iter: 6779  total_loss: 1.308  loss_cls: 0.3367  loss_box_reg: 0.5443  loss_mask: 0.2831  loss_rpn_cls: 0.03161  loss_rpn_loc: 0.0581  time: 0.7678  data_time: 0.1560  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:29:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:29:15 d2.utils.events]: \u001b[0m eta: 0:27:30  iter: 6799  total_loss: 1.3  loss_cls: 0.3426  loss_box_reg: 0.5565  loss_mask: 0.2997  loss_rpn_cls: 0.03596  loss_rpn_loc: 0.06132  time: 0.7679  data_time: 0.1816  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:29:28 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 6819  total_loss: 1.339  loss_cls: 0.342  loss_box_reg: 0.5494  loss_mask: 0.2985  loss_rpn_cls: 0.04536  loss_rpn_loc: 0.09177  time: 0.7676  data_time: 0.1658  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:29:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:29:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:29:47 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 6839  total_loss: 1.367  loss_cls: 0.3312  loss_box_reg: 0.5749  loss_mask: 0.3179  loss_rpn_cls: 0.04905  loss_rpn_loc: 0.1008  time: 0.7681  data_time: 0.2207  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:29:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:30:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:30:04 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 6859  total_loss: 1.289  loss_cls: 0.3303  loss_box_reg: 0.5371  loss_mask: 0.2911  loss_rpn_cls: 0.03262  loss_rpn_loc: 0.06354  time: 0.7683  data_time: 0.1844  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:30:15 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 6879  total_loss: 1.116  loss_cls: 0.2784  loss_box_reg: 0.5108  loss_mask: 0.2913  loss_rpn_cls: 0.0225  loss_rpn_loc: 0.04313  time: 0.7677  data_time: 0.0784  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:30:27 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 6899  total_loss: 1.214  loss_cls: 0.3104  loss_box_reg: 0.5406  loss_mask: 0.305  loss_rpn_cls: 0.03036  loss_rpn_loc: 0.05442  time: 0.7672  data_time: 0.0927  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:30:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:30:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:30:43 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 6919  total_loss: 1.22  loss_cls: 0.3148  loss_box_reg: 0.5325  loss_mask: 0.2831  loss_rpn_cls: 0.04028  loss_rpn_loc: 0.06541  time: 0.7674  data_time: 0.1254  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:30:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:30:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:31:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:31:04 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 6939  total_loss: 1.277  loss_cls: 0.3129  loss_box_reg: 0.5469  loss_mask: 0.294  loss_rpn_cls: 0.02902  loss_rpn_loc: 0.05614  time: 0.7682  data_time: 0.1743  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:31:17 d2.utils.events]: \u001b[0m eta: 0:26:09  iter: 6959  total_loss: 1.376  loss_cls: 0.3587  loss_box_reg: 0.5508  loss_mask: 0.2972  loss_rpn_cls: 0.0585  loss_rpn_loc: 0.1113  time: 0.7678  data_time: 0.1278  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:31:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:31:33 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 6979  total_loss: 1.301  loss_cls: 0.3363  loss_box_reg: 0.5137  loss_mask: 0.2956  loss_rpn_cls: 0.03906  loss_rpn_loc: 0.0793  time: 0.7678  data_time: 0.2030  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:31:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:31:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:31:51 d2.utils.events]: \u001b[0m eta: 0:25:48  iter: 6999  total_loss: 1.342  loss_cls: 0.3557  loss_box_reg: 0.539  loss_mask: 0.2902  loss_rpn_cls: 0.05261  loss_rpn_loc: 0.105  time: 0.7683  data_time: 0.2210  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:31:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:32:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:32:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:32:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:32:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:32:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:32:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0888 s/iter. Eval: 0.0686 s/iter. Total: 0.1581 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 17:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0765 s/iter. Total: 0.1672 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 17:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0741 s/iter. Total: 0.1639 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 17:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0782 s/iter. Total: 0.1682 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 17:32:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.419434 (0.167409 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:32:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088957 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:32:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:32:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27456685766486216\n",
      "\u001b[32m[02/05 17:32:29 d2.utils.events]: \u001b[0m eta: 0:25:38  iter: 7019  total_loss: 1.33  loss_cls: 0.3566  loss_box_reg: 0.529  loss_mask: 0.2977  loss_rpn_cls: 0.06317  loss_rpn_loc: 0.105  time: 0.7684  data_time: 0.2004  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:32:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:32:45 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 7039  total_loss: 1.255  loss_cls: 0.3259  loss_box_reg: 0.5523  loss_mask: 0.2859  loss_rpn_cls: 0.04201  loss_rpn_loc: 0.068  time: 0.7685  data_time: 0.1848  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:32:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:32:58 d2.utils.events]: \u001b[0m eta: 0:25:18  iter: 7059  total_loss: 1.178  loss_cls: 0.2978  loss_box_reg: 0.5167  loss_mask: 0.2876  loss_rpn_cls: 0.02536  loss_rpn_loc: 0.05323  time: 0.7682  data_time: 0.0946  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:33:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:33:13 d2.utils.events]: \u001b[0m eta: 0:25:07  iter: 7079  total_loss: 1.231  loss_cls: 0.3251  loss_box_reg: 0.5355  loss_mask: 0.2782  loss_rpn_cls: 0.03204  loss_rpn_loc: 0.0668  time: 0.7681  data_time: 0.1485  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:33:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:33:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:33:34 d2.utils.events]: \u001b[0m eta: 0:25:05  iter: 7099  total_loss: 1.441  loss_cls: 0.3748  loss_box_reg: 0.5583  loss_mask: 0.301  loss_rpn_cls: 0.07661  loss_rpn_loc: 0.1111  time: 0.7690  data_time: 0.3437  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:33:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:33:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:33:52 d2.utils.events]: \u001b[0m eta: 0:24:57  iter: 7119  total_loss: 1.239  loss_cls: 0.321  loss_box_reg: 0.5276  loss_mask: 0.2803  loss_rpn_cls: 0.0501  loss_rpn_loc: 0.06778  time: 0.7693  data_time: 0.1850  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:33:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:34:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:34:07 d2.utils.events]: \u001b[0m eta: 0:24:45  iter: 7139  total_loss: 1.203  loss_cls: 0.3134  loss_box_reg: 0.5389  loss_mask: 0.2842  loss_rpn_cls: 0.0336  loss_rpn_loc: 0.04811  time: 0.7693  data_time: 0.1430  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:34:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:34:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:34:25 d2.utils.events]: \u001b[0m eta: 0:24:35  iter: 7159  total_loss: 1.213  loss_cls: 0.303  loss_box_reg: 0.5233  loss_mask: 0.2739  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.04972  time: 0.7696  data_time: 0.1517  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:34:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:34:41 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 7179  total_loss: 1.313  loss_cls: 0.3447  loss_box_reg: 0.556  loss_mask: 0.293  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1056  time: 0.7696  data_time: 0.1449  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:34:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:34:55 d2.utils.events]: \u001b[0m eta: 0:24:22  iter: 7199  total_loss: 1.314  loss_cls: 0.3446  loss_box_reg: 0.5265  loss_mask: 0.3056  loss_rpn_cls: 0.0585  loss_rpn_loc: 0.1003  time: 0.7695  data_time: 0.1390  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:35:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:35:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:35:12 d2.utils.events]: \u001b[0m eta: 0:24:13  iter: 7219  total_loss: 1.367  loss_cls: 0.3645  loss_box_reg: 0.5631  loss_mask: 0.2955  loss_rpn_cls: 0.06019  loss_rpn_loc: 0.107  time: 0.7698  data_time: 0.1457  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:35:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:35:29 d2.utils.events]: \u001b[0m eta: 0:24:04  iter: 7239  total_loss: 1.372  loss_cls: 0.3566  loss_box_reg: 0.5501  loss_mask: 0.292  loss_rpn_cls: 0.05148  loss_rpn_loc: 0.1056  time: 0.7699  data_time: 0.1846  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:35:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:35:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:35:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:35:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:35:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:35:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:35:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0903 s/iter. Eval: 0.0699 s/iter. Total: 0.1610 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 17:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0013 s/iter. Inference: 0.0929 s/iter. Eval: 0.0808 s/iter. Total: 0.1750 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 17:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0011 s/iter. Inference: 0.0924 s/iter. Eval: 0.0777 s/iter. Total: 0.1712 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 17:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0010 s/iter. Inference: 0.0921 s/iter. Eval: 0.0825 s/iter. Total: 0.1757 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 17:36:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.075806 (0.173067 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:36:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091995 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:36:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:36:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27160816030203283\n",
      "\u001b[32m[02/05 17:36:06 d2.utils.events]: \u001b[0m eta: 0:23:52  iter: 7259  total_loss: 1.199  loss_cls: 0.3083  loss_box_reg: 0.5366  loss_mask: 0.3093  loss_rpn_cls: 0.03639  loss_rpn_loc: 0.04145  time: 0.7699  data_time: 0.1563  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:36:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:36:22 d2.utils.events]: \u001b[0m eta: 0:23:40  iter: 7279  total_loss: 1.272  loss_cls: 0.3264  loss_box_reg: 0.549  loss_mask: 0.2921  loss_rpn_cls: 0.03899  loss_rpn_loc: 0.06526  time: 0.7699  data_time: 0.1690  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:36:36 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 7299  total_loss: 1.228  loss_cls: 0.3441  loss_box_reg: 0.5507  loss_mask: 0.2885  loss_rpn_cls: 0.03659  loss_rpn_loc: 0.05218  time: 0.7698  data_time: 0.1831  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:36:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:36:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:36:56 d2.utils.events]: \u001b[0m eta: 0:23:19  iter: 7319  total_loss: 1.356  loss_cls: 0.3379  loss_box_reg: 0.5577  loss_mask: 0.2851  loss_rpn_cls: 0.04547  loss_rpn_loc: 0.0838  time: 0.7704  data_time: 0.2416  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:37:09 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 7339  total_loss: 1.301  loss_cls: 0.3316  loss_box_reg: 0.5477  loss_mask: 0.2858  loss_rpn_cls: 0.03645  loss_rpn_loc: 0.08226  time: 0.7701  data_time: 0.0871  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:37:22 d2.utils.events]: \u001b[0m eta: 0:23:02  iter: 7359  total_loss: 1.223  loss_cls: 0.3204  loss_box_reg: 0.5239  loss_mask: 0.2759  loss_rpn_cls: 0.04009  loss_rpn_loc: 0.03977  time: 0.7697  data_time: 0.1034  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:37:35 d2.utils.events]: \u001b[0m eta: 0:22:52  iter: 7379  total_loss: 1.295  loss_cls: 0.3301  loss_box_reg: 0.5575  loss_mask: 0.2863  loss_rpn_cls: 0.03546  loss_rpn_loc: 0.06786  time: 0.7694  data_time: 0.1196  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:37:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:37:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:37:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:37:54 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 7399  total_loss: 1.28  loss_cls: 0.3383  loss_box_reg: 0.5636  loss_mask: 0.2906  loss_rpn_cls: 0.03587  loss_rpn_loc: 0.06314  time: 0.7699  data_time: 0.1432  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:38:02 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:38:14 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 7419  total_loss: 1.361  loss_cls: 0.3555  loss_box_reg: 0.557  loss_mask: 0.2934  loss_rpn_cls: 0.06969  loss_rpn_loc: 0.1044  time: 0.7706  data_time: 0.3609  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:38:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:38:33 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 7439  total_loss: 1.334  loss_cls: 0.3484  loss_box_reg: 0.5413  loss_mask: 0.2993  loss_rpn_cls: 0.05311  loss_rpn_loc: 0.09825  time: 0.7710  data_time: 0.2229  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:38:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:38:49 d2.utils.events]: \u001b[0m eta: 0:22:14  iter: 7459  total_loss: 1.268  loss_cls: 0.3199  loss_box_reg: 0.5266  loss_mask: 0.2918  loss_rpn_cls: 0.03468  loss_rpn_loc: 0.06794  time: 0.7711  data_time: 0.2386  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:39:02 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 7479  total_loss: 1.339  loss_cls: 0.3391  loss_box_reg: 0.5607  loss_mask: 0.2968  loss_rpn_cls: 0.0562  loss_rpn_loc: 0.0988  time: 0.7708  data_time: 0.1372  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:39:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:39:18 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 7499  total_loss: 1.373  loss_cls: 0.3657  loss_box_reg: 0.563  loss_mask: 0.291  loss_rpn_cls: 0.05473  loss_rpn_loc: 0.09587  time: 0.7708  data_time: 0.1694  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:39:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:39:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:39:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:39:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:39:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:39:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0928 s/iter. Eval: 0.0707 s/iter. Total: 0.1644 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 17:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0009 s/iter. Inference: 0.0910 s/iter. Eval: 0.0809 s/iter. Total: 0.1729 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 17:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0900 s/iter. Eval: 0.0776 s/iter. Total: 0.1685 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 17:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0899 s/iter. Eval: 0.0809 s/iter. Total: 0.1716 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 17:39:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.711422 (0.169926 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:39:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089465 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:39:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:39:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27166255052060356\n",
      "\u001b[32m[02/05 17:39:53 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 7519  total_loss: 1.249  loss_cls: 0.3287  loss_box_reg: 0.5328  loss_mask: 0.2915  loss_rpn_cls: 0.04584  loss_rpn_loc: 0.09739  time: 0.7706  data_time: 0.1539  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:39:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:40:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:40:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:40:16 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 7539  total_loss: 1.391  loss_cls: 0.3613  loss_box_reg: 0.5743  loss_mask: 0.3009  loss_rpn_cls: 0.06138  loss_rpn_loc: 0.1064  time: 0.7717  data_time: 0.3469  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:40:28 d2.utils.events]: \u001b[0m eta: 0:21:25  iter: 7559  total_loss: 1.14  loss_cls: 0.318  loss_box_reg: 0.518  loss_mask: 0.2795  loss_rpn_cls: 0.0249  loss_rpn_loc: 0.03952  time: 0.7711  data_time: 0.0709  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:40:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:40:43 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 7579  total_loss: 1.267  loss_cls: 0.3062  loss_box_reg: 0.56  loss_mask: 0.3035  loss_rpn_cls: 0.02702  loss_rpn_loc: 0.05805  time: 0.7711  data_time: 0.1474  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:40:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:40:57 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 7599  total_loss: 1.329  loss_cls: 0.3344  loss_box_reg: 0.5485  loss_mask: 0.2922  loss_rpn_cls: 0.05068  loss_rpn_loc: 0.08631  time: 0.7709  data_time: 0.1136  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:41:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:41:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:41:16 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 7619  total_loss: 1.372  loss_cls: 0.3563  loss_box_reg: 0.5494  loss_mask: 0.3048  loss_rpn_cls: 0.04885  loss_rpn_loc: 0.1065  time: 0.7713  data_time: 0.2244  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:41:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:41:33 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 7639  total_loss: 1.26  loss_cls: 0.3299  loss_box_reg: 0.5219  loss_mask: 0.2785  loss_rpn_cls: 0.03007  loss_rpn_loc: 0.0698  time: 0.7716  data_time: 0.2398  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:41:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:41:51 d2.utils.events]: \u001b[0m eta: 0:20:33  iter: 7659  total_loss: 1.3  loss_cls: 0.3427  loss_box_reg: 0.5402  loss_mask: 0.2971  loss_rpn_cls: 0.05218  loss_rpn_loc: 0.106  time: 0.7719  data_time: 0.2668  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:42:04 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 7679  total_loss: 1.323  loss_cls: 0.3395  loss_box_reg: 0.5319  loss_mask: 0.2954  loss_rpn_cls: 0.05683  loss_rpn_loc: 0.09101  time: 0.7716  data_time: 0.1179  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:42:15 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 7699  total_loss: 1.25  loss_cls: 0.3258  loss_box_reg: 0.5314  loss_mask: 0.2886  loss_rpn_cls: 0.032  loss_rpn_loc: 0.06075  time: 0.7710  data_time: 0.0545  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:42:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:42:30 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 7719  total_loss: 1.295  loss_cls: 0.3371  loss_box_reg: 0.5277  loss_mask: 0.2848  loss_rpn_cls: 0.03872  loss_rpn_loc: 0.08172  time: 0.7710  data_time: 0.1693  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:42:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:42:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:42:49 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 7739  total_loss: 1.378  loss_cls: 0.3616  loss_box_reg: 0.561  loss_mask: 0.304  loss_rpn_cls: 0.05309  loss_rpn_loc: 0.08781  time: 0.7714  data_time: 0.2201  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:42:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:42:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 17:42:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 17:42:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 17:42:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 17:42:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 17:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.0785 s/iter. Total: 0.1738 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 17:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0009 s/iter. Inference: 0.0944 s/iter. Eval: 0.0842 s/iter. Total: 0.1796 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 17:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0923 s/iter. Eval: 0.0806 s/iter. Total: 0.1738 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 17:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0917 s/iter. Eval: 0.0845 s/iter. Total: 0.1771 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 17:43:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.196024 (0.174104 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:43:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091320 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 17:43:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 17:43:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2735823988690285\n",
      "\u001b[32m[02/05 17:43:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:43:29 d2.utils.events]: \u001b[0m eta: 0:19:44  iter: 7759  total_loss: 1.344  loss_cls: 0.3521  loss_box_reg: 0.5526  loss_mask: 0.303  loss_rpn_cls: 0.05327  loss_rpn_loc: 0.1054  time: 0.7717  data_time: 0.2073  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:43:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:43:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:43:48 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 7779  total_loss: 1.377  loss_cls: 0.36  loss_box_reg: 0.5619  loss_mask: 0.2989  loss_rpn_cls: 0.06109  loss_rpn_loc: 0.1089  time: 0.7722  data_time: 0.2545  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:44:02 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 7799  total_loss: 1.198  loss_cls: 0.3235  loss_box_reg: 0.5359  loss_mask: 0.2822  loss_rpn_cls: 0.03899  loss_rpn_loc: 0.06065  time: 0.7720  data_time: 0.1955  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:44:15 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 7819  total_loss: 1.34  loss_cls: 0.3523  loss_box_reg: 0.5545  loss_mask: 0.2855  loss_rpn_cls: 0.03906  loss_rpn_loc: 0.07799  time: 0.7717  data_time: 0.1699  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:44:26 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 7839  total_loss: 1.201  loss_cls: 0.2946  loss_box_reg: 0.5134  loss_mask: 0.2955  loss_rpn_cls: 0.04407  loss_rpn_loc: 0.04724  time: 0.7711  data_time: 0.0633  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:44:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 17:44:44 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 7859  total_loss: 1.344  loss_cls: 0.3472  loss_box_reg: 0.5371  loss_mask: 0.2914  loss_rpn_cls: 0.04792  loss_rpn_loc: 0.09926  time: 0.7714  data_time: 0.2893  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 17:44:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n"
     ]
    }
   ],
   "source": [
    "# changing the anchor generator sizes and aspect ratios (other values)\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16], [32], [64], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0, 4.0]]\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dc187378-adb2-40fa-8774-5accf03db519",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 18:29:30 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 18:29:31 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 18:29:32 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/05 18:29:33 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 18:29:33 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/05 18:29:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/05 18:29:33 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/05 18:29:33 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:29:33 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 18:29:33 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/05 18:29:47 d2.utils.events]: \u001b[0m eta: 1:16:03  iter: 19  total_loss: 3.282  loss_cls: 1.349  loss_box_reg: 0.5794  loss_mask: 0.6912  loss_rpn_cls: 0.3576  loss_rpn_loc: 0.3019  time: 0.5957  data_time: 0.2176  lr: 9.9905e-06  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:29:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:30:04 d2.utils.events]: \u001b[0m eta: 1:16:44  iter: 39  total_loss: 2.976  loss_cls: 1.252  loss_box_reg: 0.477  loss_mask: 0.6865  loss_rpn_cls: 0.3261  loss_rpn_loc: 0.2597  time: 0.7398  data_time: 0.3207  lr: 1.998e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:30:17 d2.utils.events]: \u001b[0m eta: 1:17:11  iter: 59  total_loss: 2.746  loss_cls: 1.049  loss_box_reg: 0.5973  loss_mask: 0.6702  loss_rpn_cls: 0.2752  loss_rpn_loc: 0.2091  time: 0.7098  data_time: 0.1944  lr: 2.997e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:30:31 d2.utils.events]: \u001b[0m eta: 1:17:02  iter: 79  total_loss: 2.6  loss_cls: 0.7955  loss_box_reg: 0.5175  loss_mask: 0.646  loss_rpn_cls: 0.2794  loss_rpn_loc: 0.2278  time: 0.7015  data_time: 0.2141  lr: 3.9961e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:30:41 d2.utils.events]: \u001b[0m eta: 1:17:37  iter: 99  total_loss: 2.525  loss_cls: 0.7212  loss_box_reg: 0.7879  loss_mask: 0.6119  loss_rpn_cls: 0.1936  loss_rpn_loc: 0.1887  time: 0.6686  data_time: 0.0796  lr: 4.9951e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:30:54 d2.utils.events]: \u001b[0m eta: 1:18:24  iter: 119  total_loss: 2.573  loss_cls: 0.7306  loss_box_reg: 0.8313  loss_mask: 0.5896  loss_rpn_cls: 0.2074  loss_rpn_loc: 0.1991  time: 0.6611  data_time: 0.1458  lr: 5.9941e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:31:06 d2.utils.events]: \u001b[0m eta: 1:18:59  iter: 139  total_loss: 2.514  loss_cls: 0.7169  loss_box_reg: 0.8302  loss_mask: 0.5701  loss_rpn_cls: 0.199  loss_rpn_loc: 0.2051  time: 0.6544  data_time: 0.1354  lr: 6.993e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:31:19 d2.utils.events]: \u001b[0m eta: 1:18:06  iter: 159  total_loss: 2.327  loss_cls: 0.6794  loss_box_reg: 0.8279  loss_mask: 0.5313  loss_rpn_cls: 0.1506  loss_rpn_loc: 0.1703  time: 0.6528  data_time: 0.1837  lr: 7.9921e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:31:33 d2.utils.events]: \u001b[0m eta: 1:18:34  iter: 179  total_loss: 2.276  loss_cls: 0.6356  loss_box_reg: 0.7988  loss_mask: 0.5081  loss_rpn_cls: 0.1522  loss_rpn_loc: 0.1751  time: 0.6569  data_time: 0.2076  lr: 8.991e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:31:45 d2.utils.events]: \u001b[0m eta: 1:18:25  iter: 199  total_loss: 2.171  loss_cls: 0.621  loss_box_reg: 0.7777  loss_mask: 0.4695  loss_rpn_cls: 0.1504  loss_rpn_loc: 0.1527  time: 0.6540  data_time: 0.1642  lr: 9.9901e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:32:00 d2.utils.events]: \u001b[0m eta: 1:18:43  iter: 219  total_loss: 2.12  loss_cls: 0.5672  loss_box_reg: 0.7483  loss_mask: 0.4436  loss_rpn_cls: 0.1425  loss_rpn_loc: 0.183  time: 0.6618  data_time: 0.2640  lr: 0.00010989  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:32:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:32:16 d2.utils.events]: \u001b[0m eta: 1:18:41  iter: 239  total_loss: 2.072  loss_cls: 0.5313  loss_box_reg: 0.7962  loss_mask: 0.4186  loss_rpn_cls: 0.1607  loss_rpn_loc: 0.1836  time: 0.6713  data_time: 0.2217  lr: 0.00011988  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:32:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:32:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:32:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:32:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:32:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:32:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0880 s/iter. Eval: 0.0198 s/iter. Total: 0.1085 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 18:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0008 s/iter. Inference: 0.0852 s/iter. Eval: 0.0190 s/iter. Total: 0.1050 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 18:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0008 s/iter. Inference: 0.0844 s/iter. Eval: 0.0174 s/iter. Total: 0.1027 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 18:32:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.855820 (0.102205 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:32:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.084409 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:32:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:32:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.11731922241242906\n",
      "\u001b[32m[02/05 18:32:44 d2.utils.events]: \u001b[0m eta: 1:18:49  iter: 259  total_loss: 2.046  loss_cls: 0.5897  loss_box_reg: 0.7358  loss_mask: 0.3966  loss_rpn_cls: 0.1664  loss_rpn_loc: 0.1719  time: 0.6763  data_time: 0.2439  lr: 0.00012987  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:32:57 d2.utils.events]: \u001b[0m eta: 1:18:34  iter: 279  total_loss: 1.903  loss_cls: 0.492  loss_box_reg: 0.7648  loss_mask: 0.3622  loss_rpn_cls: 0.1378  loss_rpn_loc: 0.1505  time: 0.6740  data_time: 0.1793  lr: 0.00013986  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:33:10 d2.utils.events]: \u001b[0m eta: 1:18:20  iter: 299  total_loss: 1.774  loss_cls: 0.4681  loss_box_reg: 0.7583  loss_mask: 0.3406  loss_rpn_cls: 0.09312  loss_rpn_loc: 0.1339  time: 0.6731  data_time: 0.2071  lr: 0.00014985  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:33:25 d2.utils.events]: \u001b[0m eta: 1:18:16  iter: 319  total_loss: 1.787  loss_cls: 0.4491  loss_box_reg: 0.7184  loss_mask: 0.3461  loss_rpn_cls: 0.09889  loss_rpn_loc: 0.1655  time: 0.6781  data_time: 0.2752  lr: 0.00015984  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:33:36 d2.utils.events]: \u001b[0m eta: 1:18:11  iter: 339  total_loss: 1.736  loss_cls: 0.4264  loss_box_reg: 0.7023  loss_mask: 0.3209  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1542  time: 0.6711  data_time: 0.0972  lr: 0.00016983  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:33:49 d2.utils.events]: \u001b[0m eta: 1:17:57  iter: 359  total_loss: 1.705  loss_cls: 0.3894  loss_box_reg: 0.6872  loss_mask: 0.35  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.1428  time: 0.6702  data_time: 0.1900  lr: 0.00017982  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:34:03 d2.utils.events]: \u001b[0m eta: 1:18:03  iter: 379  total_loss: 1.726  loss_cls: 0.4508  loss_box_reg: 0.678  loss_mask: 0.3244  loss_rpn_cls: 0.1466  loss_rpn_loc: 0.1793  time: 0.6714  data_time: 0.2163  lr: 0.00018981  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:34:16 d2.utils.events]: \u001b[0m eta: 1:17:59  iter: 399  total_loss: 1.597  loss_cls: 0.4035  loss_box_reg: 0.6697  loss_mask: 0.3111  loss_rpn_cls: 0.08293  loss_rpn_loc: 0.144  time: 0.6694  data_time: 0.1533  lr: 0.0001998  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:34:28 d2.utils.events]: \u001b[0m eta: 1:17:52  iter: 419  total_loss: 1.618  loss_cls: 0.4002  loss_box_reg: 0.6533  loss_mask: 0.3091  loss_rpn_cls: 0.06467  loss_rpn_loc: 0.1116  time: 0.6664  data_time: 0.1214  lr: 0.00020979  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:34:42 d2.utils.events]: \u001b[0m eta: 1:17:58  iter: 439  total_loss: 1.729  loss_cls: 0.4366  loss_box_reg: 0.6641  loss_mask: 0.3319  loss_rpn_cls: 0.1204  loss_rpn_loc: 0.1401  time: 0.6691  data_time: 0.2157  lr: 0.00021978  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:34:55 d2.utils.events]: \u001b[0m eta: 1:17:54  iter: 459  total_loss: 1.593  loss_cls: 0.399  loss_box_reg: 0.6402  loss_mask: 0.3151  loss_rpn_cls: 0.08027  loss_rpn_loc: 0.139  time: 0.6681  data_time: 0.1632  lr: 0.00022977  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:35:07 d2.utils.events]: \u001b[0m eta: 1:17:55  iter: 479  total_loss: 1.653  loss_cls: 0.4013  loss_box_reg: 0.6471  loss_mask: 0.3176  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.141  time: 0.6656  data_time: 0.1089  lr: 0.00023976  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:35:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:35:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:35:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:35:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:35:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:35:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0940 s/iter. Eval: 0.0520 s/iter. Total: 0.1467 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 18:35:17 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0919 s/iter. Eval: 0.0692 s/iter. Total: 0.1619 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 18:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0924 s/iter. Eval: 0.0699 s/iter. Total: 0.1632 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 18:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0919 s/iter. Eval: 0.0744 s/iter. Total: 0.1671 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 18:35:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.214189 (0.165640 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:35:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091708 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:35:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:35:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.213110066978714\n",
      "\u001b[32m[02/05 18:35:39 d2.utils.events]: \u001b[0m eta: 1:17:48  iter: 499  total_loss: 1.742  loss_cls: 0.4055  loss_box_reg: 0.661  loss_mask: 0.322  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1369  time: 0.6612  data_time: 0.0876  lr: 0.00024975  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:35:55 d2.utils.events]: \u001b[0m eta: 1:17:38  iter: 519  total_loss: 1.521  loss_cls: 0.3574  loss_box_reg: 0.6191  loss_mask: 0.316  loss_rpn_cls: 0.101  loss_rpn_loc: 0.1458  time: 0.6656  data_time: 0.3076  lr: 0.00025974  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:36:07 d2.utils.events]: \u001b[0m eta: 1:17:28  iter: 539  total_loss: 1.659  loss_cls: 0.4107  loss_box_reg: 0.6553  loss_mask: 0.328  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.1562  time: 0.6625  data_time: 0.1121  lr: 0.00026973  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:36:19 d2.utils.events]: \u001b[0m eta: 1:17:16  iter: 559  total_loss: 1.559  loss_cls: 0.3893  loss_box_reg: 0.6125  loss_mask: 0.3053  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1466  time: 0.6608  data_time: 0.1373  lr: 0.00027972  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:36:33 d2.utils.events]: \u001b[0m eta: 1:17:12  iter: 579  total_loss: 1.695  loss_cls: 0.3879  loss_box_reg: 0.6441  loss_mask: 0.3266  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.1488  time: 0.6619  data_time: 0.1985  lr: 0.00028971  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:36:45 d2.utils.events]: \u001b[0m eta: 1:16:58  iter: 599  total_loss: 1.62  loss_cls: 0.4122  loss_box_reg: 0.6412  loss_mask: 0.3111  loss_rpn_cls: 0.08846  loss_rpn_loc: 0.1354  time: 0.6599  data_time: 0.1266  lr: 0.0002997  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:37:01 d2.utils.events]: \u001b[0m eta: 1:16:48  iter: 619  total_loss: 1.586  loss_cls: 0.4027  loss_box_reg: 0.6245  loss_mask: 0.3201  loss_rpn_cls: 0.08886  loss_rpn_loc: 0.1367  time: 0.6640  data_time: 0.3038  lr: 0.00030969  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:37:13 d2.utils.events]: \u001b[0m eta: 1:16:33  iter: 639  total_loss: 1.568  loss_cls: 0.3856  loss_box_reg: 0.6314  loss_mask: 0.3042  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.1465  time: 0.6626  data_time: 0.1522  lr: 0.00031968  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:37:27 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 659  total_loss: 1.528  loss_cls: 0.3618  loss_box_reg: 0.5999  loss_mask: 0.3122  loss_rpn_cls: 0.09321  loss_rpn_loc: 0.1315  time: 0.6641  data_time: 0.2198  lr: 0.00032967  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:37:40 d2.utils.events]: \u001b[0m eta: 1:16:26  iter: 679  total_loss: 1.562  loss_cls: 0.3775  loss_box_reg: 0.6223  loss_mask: 0.3092  loss_rpn_cls: 0.06908  loss_rpn_loc: 0.1288  time: 0.6636  data_time: 0.1417  lr: 0.00033966  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:37:54 d2.utils.events]: \u001b[0m eta: 1:16:19  iter: 699  total_loss: 1.517  loss_cls: 0.3751  loss_box_reg: 0.5993  loss_mask: 0.3204  loss_rpn_cls: 0.08555  loss_rpn_loc: 0.1342  time: 0.6648  data_time: 0.2268  lr: 0.00034965  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:38:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:38:12 d2.utils.events]: \u001b[0m eta: 1:16:12  iter: 719  total_loss: 1.592  loss_cls: 0.3919  loss_box_reg: 0.5994  loss_mask: 0.306  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.1487  time: 0.6708  data_time: 0.3352  lr: 0.00035964  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:38:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:38:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:38:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:38:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:38:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:38:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0908 s/iter. Eval: 0.0547 s/iter. Total: 0.1461 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 18:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0706 s/iter. Total: 0.1595 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 18:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0707 s/iter. Total: 0.1595 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 18:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0734 s/iter. Total: 0.1624 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 18:38:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.734639 (0.161506 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:38:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087916 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:38:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:38:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.233196542321106\n",
      "\u001b[32m[02/05 18:38:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:38:51 d2.utils.events]: \u001b[0m eta: 1:16:06  iter: 739  total_loss: 1.516  loss_cls: 0.3762  loss_box_reg: 0.5957  loss_mask: 0.3317  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1343  time: 0.6783  data_time: 0.3619  lr: 0.00036963  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:39:03 d2.utils.events]: \u001b[0m eta: 1:15:54  iter: 759  total_loss: 1.495  loss_cls: 0.3676  loss_box_reg: 0.599  loss_mask: 0.2992  loss_rpn_cls: 0.0825  loss_rpn_loc: 0.1431  time: 0.6766  data_time: 0.1403  lr: 0.00037962  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:39:15 d2.utils.events]: \u001b[0m eta: 1:15:42  iter: 779  total_loss: 1.452  loss_cls: 0.3811  loss_box_reg: 0.579  loss_mask: 0.3099  loss_rpn_cls: 0.07382  loss_rpn_loc: 0.1128  time: 0.6746  data_time: 0.1441  lr: 0.00038961  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:39:30 d2.utils.events]: \u001b[0m eta: 1:15:31  iter: 799  total_loss: 1.545  loss_cls: 0.3646  loss_box_reg: 0.6142  loss_mask: 0.3042  loss_rpn_cls: 0.09678  loss_rpn_loc: 0.151  time: 0.6765  data_time: 0.2870  lr: 0.0003996  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:39:41 d2.utils.events]: \u001b[0m eta: 1:15:16  iter: 819  total_loss: 1.511  loss_cls: 0.381  loss_box_reg: 0.6218  loss_mask: 0.3171  loss_rpn_cls: 0.08335  loss_rpn_loc: 0.1354  time: 0.6725  data_time: 0.0563  lr: 0.00040959  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:39:56 d2.utils.events]: \u001b[0m eta: 1:15:10  iter: 839  total_loss: 1.653  loss_cls: 0.4477  loss_box_reg: 0.6212  loss_mask: 0.3189  loss_rpn_cls: 0.1172  loss_rpn_loc: 0.17  time: 0.6743  data_time: 0.2649  lr: 0.00041958  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:40:11 d2.utils.events]: \u001b[0m eta: 1:15:03  iter: 859  total_loss: 1.466  loss_cls: 0.3597  loss_box_reg: 0.5965  loss_mask: 0.3014  loss_rpn_cls: 0.08404  loss_rpn_loc: 0.1204  time: 0.6765  data_time: 0.2854  lr: 0.00042957  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:40:24 d2.utils.events]: \u001b[0m eta: 1:14:54  iter: 879  total_loss: 1.527  loss_cls: 0.3837  loss_box_reg: 0.5982  loss_mask: 0.3174  loss_rpn_cls: 0.08772  loss_rpn_loc: 0.1516  time: 0.6753  data_time: 0.1361  lr: 0.00043956  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:40:37 d2.utils.events]: \u001b[0m eta: 1:14:43  iter: 899  total_loss: 1.449  loss_cls: 0.3617  loss_box_reg: 0.5805  loss_mask: 0.3022  loss_rpn_cls: 0.07133  loss_rpn_loc: 0.1406  time: 0.6751  data_time: 0.1895  lr: 0.00044955  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:40:51 d2.utils.events]: \u001b[0m eta: 1:14:32  iter: 919  total_loss: 1.524  loss_cls: 0.3905  loss_box_reg: 0.6095  loss_mask: 0.301  loss_rpn_cls: 0.09345  loss_rpn_loc: 0.1459  time: 0.6758  data_time: 0.2445  lr: 0.00045954  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:41:05 d2.utils.events]: \u001b[0m eta: 1:14:34  iter: 939  total_loss: 1.536  loss_cls: 0.3621  loss_box_reg: 0.5756  loss_mask: 0.3015  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.1356  time: 0.6759  data_time: 0.1731  lr: 0.00046953  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:41:18 d2.utils.events]: \u001b[0m eta: 1:14:28  iter: 959  total_loss: 1.51  loss_cls: 0.3724  loss_box_reg: 0.6009  loss_mask: 0.3173  loss_rpn_cls: 0.0766  loss_rpn_loc: 0.1292  time: 0.6755  data_time: 0.1715  lr: 0.00047952  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:41:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:41:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:41:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:41:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:41:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:41:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0974 s/iter. Eval: 0.0655 s/iter. Total: 0.1636 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 18:41:30 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0008 s/iter. Inference: 0.0992 s/iter. Eval: 0.0813 s/iter. Total: 0.1814 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 18:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0008 s/iter. Inference: 0.0992 s/iter. Eval: 0.0814 s/iter. Total: 0.1815 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 18:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.0997 s/iter. Eval: 0.0864 s/iter. Total: 0.1870 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 18:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0993 s/iter. Eval: 0.0841 s/iter. Total: 0.1843 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 18:41:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.446656 (0.184885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:41:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.099384 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:41:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:41:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23375701002393337\n",
      "\u001b[32m[02/05 18:41:54 d2.utils.events]: \u001b[0m eta: 1:14:21  iter: 979  total_loss: 1.622  loss_cls: 0.4  loss_box_reg: 0.6007  loss_mask: 0.3093  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.145  time: 0.6748  data_time: 0.1251  lr: 0.00048951  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:42:08 d2.utils.events]: \u001b[0m eta: 1:14:26  iter: 999  total_loss: 1.481  loss_cls: 0.379  loss_box_reg: 0.5963  loss_mask: 0.3111  loss_rpn_cls: 0.09977  loss_rpn_loc: 0.1358  time: 0.6753  data_time: 0.1617  lr: 0.0004995  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:42:21 d2.utils.events]: \u001b[0m eta: 1:14:21  iter: 1019  total_loss: 1.462  loss_cls: 0.3396  loss_box_reg: 0.5755  loss_mask: 0.3052  loss_rpn_cls: 0.0823  loss_rpn_loc: 0.1321  time: 0.6748  data_time: 0.1600  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:42:32 d2.utils.events]: \u001b[0m eta: 1:14:08  iter: 1039  total_loss: 1.455  loss_cls: 0.3983  loss_box_reg: 0.5896  loss_mask: 0.2941  loss_rpn_cls: 0.05721  loss_rpn_loc: 0.1225  time: 0.6729  data_time: 0.1046  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:42:43 d2.utils.events]: \u001b[0m eta: 1:14:01  iter: 1059  total_loss: 1.507  loss_cls: 0.3512  loss_box_reg: 0.579  loss_mask: 0.3191  loss_rpn_cls: 0.07095  loss_rpn_loc: 0.1138  time: 0.6703  data_time: 0.0731  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:42:54 d2.utils.events]: \u001b[0m eta: 1:13:55  iter: 1079  total_loss: 1.533  loss_cls: 0.4039  loss_box_reg: 0.5939  loss_mask: 0.2922  loss_rpn_cls: 0.08914  loss_rpn_loc: 0.1526  time: 0.6683  data_time: 0.0869  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:43:06 d2.utils.events]: \u001b[0m eta: 1:13:43  iter: 1099  total_loss: 1.588  loss_cls: 0.3867  loss_box_reg: 0.6231  loss_mask: 0.3225  loss_rpn_cls: 0.0811  loss_rpn_loc: 0.1351  time: 0.6672  data_time: 0.1427  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:43:21 d2.utils.events]: \u001b[0m eta: 1:13:31  iter: 1119  total_loss: 1.448  loss_cls: 0.3362  loss_box_reg: 0.5748  loss_mask: 0.3108  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.13  time: 0.6681  data_time: 0.2423  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:43:37 d2.utils.events]: \u001b[0m eta: 1:13:30  iter: 1139  total_loss: 1.535  loss_cls: 0.4008  loss_box_reg: 0.5727  loss_mask: 0.3107  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.1374  time: 0.6704  data_time: 0.3050  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:43:49 d2.utils.events]: \u001b[0m eta: 1:13:26  iter: 1159  total_loss: 1.524  loss_cls: 0.3577  loss_box_reg: 0.5839  loss_mask: 0.3035  loss_rpn_cls: 0.09322  loss_rpn_loc: 0.1332  time: 0.6691  data_time: 0.1155  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:44:06 d2.utils.events]: \u001b[0m eta: 1:13:29  iter: 1179  total_loss: 1.567  loss_cls: 0.4187  loss_box_reg: 0.6062  loss_mask: 0.3124  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.146  time: 0.6721  data_time: 0.3627  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:44:21 d2.utils.events]: \u001b[0m eta: 1:13:23  iter: 1199  total_loss: 1.481  loss_cls: 0.3398  loss_box_reg: 0.6171  loss_mask: 0.323  loss_rpn_cls: 0.0763  loss_rpn_loc: 0.1406  time: 0.6736  data_time: 0.2970  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:44:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:44:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:44:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:44:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:44:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:44:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0960 s/iter. Eval: 0.0589 s/iter. Total: 0.1556 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 18:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0969 s/iter. Eval: 0.0753 s/iter. Total: 0.1731 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 18:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0968 s/iter. Eval: 0.0741 s/iter. Total: 0.1718 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 18:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0976 s/iter. Eval: 0.0812 s/iter. Total: 0.1796 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 18:44:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.589222 (0.177493 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:44:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.097277 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:44:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:44:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24987710899805599\n",
      "\u001b[32m[02/05 18:44:56 d2.utils.events]: \u001b[0m eta: 1:13:22  iter: 1219  total_loss: 1.52  loss_cls: 0.3746  loss_box_reg: 0.6049  loss_mask: 0.307  loss_rpn_cls: 0.08671  loss_rpn_loc: 0.1204  time: 0.6731  data_time: 0.1317  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:45:11 d2.utils.events]: \u001b[0m eta: 1:13:25  iter: 1239  total_loss: 1.517  loss_cls: 0.367  loss_box_reg: 0.5789  loss_mask: 0.2995  loss_rpn_cls: 0.09808  loss_rpn_loc: 0.1437  time: 0.6741  data_time: 0.2019  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:45:23 d2.utils.events]: \u001b[0m eta: 1:13:12  iter: 1259  total_loss: 1.369  loss_cls: 0.364  loss_box_reg: 0.5891  loss_mask: 0.311  loss_rpn_cls: 0.06739  loss_rpn_loc: 0.1216  time: 0.6729  data_time: 0.0971  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:45:35 d2.utils.events]: \u001b[0m eta: 1:13:02  iter: 1279  total_loss: 1.567  loss_cls: 0.3902  loss_box_reg: 0.5871  loss_mask: 0.3035  loss_rpn_cls: 0.09049  loss_rpn_loc: 0.1461  time: 0.6717  data_time: 0.1223  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:45:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:45:51 d2.utils.events]: \u001b[0m eta: 1:12:55  iter: 1299  total_loss: 1.466  loss_cls: 0.3646  loss_box_reg: 0.5755  loss_mask: 0.309  loss_rpn_cls: 0.08271  loss_rpn_loc: 0.1313  time: 0.6741  data_time: 0.2274  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:46:05 d2.utils.events]: \u001b[0m eta: 1:12:53  iter: 1319  total_loss: 1.407  loss_cls: 0.321  loss_box_reg: 0.5877  loss_mask: 0.2976  loss_rpn_cls: 0.05871  loss_rpn_loc: 0.08892  time: 0.6741  data_time: 0.1608  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:46:19 d2.utils.events]: \u001b[0m eta: 1:12:54  iter: 1339  total_loss: 1.344  loss_cls: 0.3096  loss_box_reg: 0.523  loss_mask: 0.2995  loss_rpn_cls: 0.05208  loss_rpn_loc: 0.1273  time: 0.6750  data_time: 0.2121  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:46:33 d2.utils.events]: \u001b[0m eta: 1:12:57  iter: 1359  total_loss: 1.618  loss_cls: 0.4198  loss_box_reg: 0.5892  loss_mask: 0.3083  loss_rpn_cls: 0.08339  loss_rpn_loc: 0.1173  time: 0.6753  data_time: 0.1661  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:46:49 d2.utils.events]: \u001b[0m eta: 1:12:59  iter: 1379  total_loss: 1.486  loss_cls: 0.371  loss_box_reg: 0.5591  loss_mask: 0.305  loss_rpn_cls: 0.109  loss_rpn_loc: 0.1424  time: 0.6766  data_time: 0.2356  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:47:05 d2.utils.events]: \u001b[0m eta: 1:12:56  iter: 1399  total_loss: 1.514  loss_cls: 0.3814  loss_box_reg: 0.5589  loss_mask: 0.3114  loss_rpn_cls: 0.09999  loss_rpn_loc: 0.1417  time: 0.6789  data_time: 0.3090  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:47:18 d2.utils.events]: \u001b[0m eta: 1:12:50  iter: 1419  total_loss: 1.439  loss_cls: 0.3599  loss_box_reg: 0.5926  loss_mask: 0.3082  loss_rpn_cls: 0.08262  loss_rpn_loc: 0.1308  time: 0.6784  data_time: 0.1785  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:47:32 d2.utils.events]: \u001b[0m eta: 1:12:35  iter: 1439  total_loss: 1.523  loss_cls: 0.3654  loss_box_reg: 0.5866  loss_mask: 0.31  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.1481  time: 0.6783  data_time: 0.2065  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:47:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:47:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:47:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:47:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:47:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:47:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0874 s/iter. Eval: 0.0514 s/iter. Total: 0.1395 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 18:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0729 s/iter. Total: 0.1627 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 18:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0712 s/iter. Total: 0.1615 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 18:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0751 s/iter. Total: 0.1654 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 18:47:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.195153 (0.165475 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:47:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089779 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:47:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:47:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25900894653581447\n",
      "\u001b[32m[02/05 18:48:04 d2.utils.events]: \u001b[0m eta: 1:12:21  iter: 1459  total_loss: 1.538  loss_cls: 0.3895  loss_box_reg: 0.6026  loss_mask: 0.3034  loss_rpn_cls: 0.08461  loss_rpn_loc: 0.1338  time: 0.6766  data_time: 0.0807  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:48:17 d2.utils.events]: \u001b[0m eta: 1:12:17  iter: 1479  total_loss: 1.424  loss_cls: 0.3683  loss_box_reg: 0.5561  loss_mask: 0.2973  loss_rpn_cls: 0.09782  loss_rpn_loc: 0.1278  time: 0.6766  data_time: 0.1673  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:48:29 d2.utils.events]: \u001b[0m eta: 1:12:05  iter: 1499  total_loss: 1.468  loss_cls: 0.3621  loss_box_reg: 0.5739  loss_mask: 0.309  loss_rpn_cls: 0.06756  loss_rpn_loc: 0.1439  time: 0.6754  data_time: 0.1159  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:48:43 d2.utils.events]: \u001b[0m eta: 1:11:59  iter: 1519  total_loss: 1.453  loss_cls: 0.3721  loss_box_reg: 0.553  loss_mask: 0.2934  loss_rpn_cls: 0.0618  loss_rpn_loc: 0.102  time: 0.6758  data_time: 0.2091  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:48:59 d2.utils.events]: \u001b[0m eta: 1:11:54  iter: 1539  total_loss: 1.501  loss_cls: 0.3759  loss_box_reg: 0.5929  loss_mask: 0.3059  loss_rpn_cls: 0.08945  loss_rpn_loc: 0.1454  time: 0.6770  data_time: 0.2875  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:49:12 d2.utils.events]: \u001b[0m eta: 1:11:57  iter: 1559  total_loss: 1.387  loss_cls: 0.309  loss_box_reg: 0.5908  loss_mask: 0.2907  loss_rpn_cls: 0.08057  loss_rpn_loc: 0.1328  time: 0.6767  data_time: 0.1314  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:49:27 d2.utils.events]: \u001b[0m eta: 1:12:07  iter: 1579  total_loss: 1.46  loss_cls: 0.3678  loss_box_reg: 0.584  loss_mask: 0.2922  loss_rpn_cls: 0.07107  loss_rpn_loc: 0.1353  time: 0.6776  data_time: 0.2111  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:49:38 d2.utils.events]: \u001b[0m eta: 1:12:02  iter: 1599  total_loss: 1.37  loss_cls: 0.332  loss_box_reg: 0.5613  loss_mask: 0.3075  loss_rpn_cls: 0.04846  loss_rpn_loc: 0.1088  time: 0.6760  data_time: 0.0506  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:49:50 d2.utils.events]: \u001b[0m eta: 1:12:00  iter: 1619  total_loss: 1.323  loss_cls: 0.3379  loss_box_reg: 0.5583  loss_mask: 0.2898  loss_rpn_cls: 0.06734  loss_rpn_loc: 0.1045  time: 0.6755  data_time: 0.1338  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:50:03 d2.utils.events]: \u001b[0m eta: 1:11:52  iter: 1639  total_loss: 1.565  loss_cls: 0.3866  loss_box_reg: 0.6072  loss_mask: 0.3377  loss_rpn_cls: 0.07626  loss_rpn_loc: 0.1338  time: 0.6748  data_time: 0.1348  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:50:20 d2.utils.events]: \u001b[0m eta: 1:11:41  iter: 1659  total_loss: 1.553  loss_cls: 0.3956  loss_box_reg: 0.6  loss_mask: 0.3147  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.1469  time: 0.6771  data_time: 0.3763  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:50:35 d2.utils.events]: \u001b[0m eta: 1:11:21  iter: 1679  total_loss: 1.463  loss_cls: 0.349  loss_box_reg: 0.5932  loss_mask: 0.3095  loss_rpn_cls: 0.08973  loss_rpn_loc: 0.1422  time: 0.6778  data_time: 0.2492  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:50:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:50:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:50:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:50:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:50:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:50:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:50:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:50:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0903 s/iter. Eval: 0.0582 s/iter. Total: 0.1492 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 18:50:58 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0902 s/iter. Eval: 0.0734 s/iter. Total: 0.1645 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 18:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0724 s/iter. Total: 0.1627 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 18:51:08 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0762 s/iter. Total: 0.1666 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 18:51:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.184001 (0.165379 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:51:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089044 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:51:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:51:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2570578479487029\n",
      "\u001b[32m[02/05 18:51:15 d2.utils.events]: \u001b[0m eta: 1:11:10  iter: 1699  total_loss: 1.501  loss_cls: 0.3712  loss_box_reg: 0.5897  loss_mask: 0.3096  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.1191  time: 0.6811  data_time: 0.3159  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:51:30 d2.utils.events]: \u001b[0m eta: 1:10:55  iter: 1719  total_loss: 1.43  loss_cls: 0.3456  loss_box_reg: 0.5687  loss_mask: 0.306  loss_rpn_cls: 0.08635  loss_rpn_loc: 0.1477  time: 0.6819  data_time: 0.2565  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:51:42 d2.utils.events]: \u001b[0m eta: 1:10:39  iter: 1739  total_loss: 1.46  loss_cls: 0.3709  loss_box_reg: 0.5769  loss_mask: 0.3104  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.1177  time: 0.6812  data_time: 0.1437  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:51:55 d2.utils.events]: \u001b[0m eta: 1:10:37  iter: 1759  total_loss: 1.419  loss_cls: 0.3703  loss_box_reg: 0.5689  loss_mask: 0.3018  loss_rpn_cls: 0.07654  loss_rpn_loc: 0.1275  time: 0.6809  data_time: 0.1293  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:52:10 d2.utils.events]: \u001b[0m eta: 1:10:38  iter: 1779  total_loss: 1.427  loss_cls: 0.3312  loss_box_reg: 0.5857  loss_mask: 0.3061  loss_rpn_cls: 0.07064  loss_rpn_loc: 0.1199  time: 0.6814  data_time: 0.2490  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:52:22 d2.utils.events]: \u001b[0m eta: 1:10:29  iter: 1799  total_loss: 1.426  loss_cls: 0.357  loss_box_reg: 0.5603  loss_mask: 0.3022  loss_rpn_cls: 0.08165  loss_rpn_loc: 0.1467  time: 0.6807  data_time: 0.1492  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:52:34 d2.utils.events]: \u001b[0m eta: 1:10:24  iter: 1819  total_loss: 1.36  loss_cls: 0.3274  loss_box_reg: 0.5568  loss_mask: 0.3037  loss_rpn_cls: 0.04941  loss_rpn_loc: 0.1123  time: 0.6796  data_time: 0.0763  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:52:49 d2.utils.events]: \u001b[0m eta: 1:10:14  iter: 1839  total_loss: 1.463  loss_cls: 0.354  loss_box_reg: 0.5818  loss_mask: 0.2992  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.1243  time: 0.6806  data_time: 0.2448  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:53:04 d2.utils.events]: \u001b[0m eta: 1:10:06  iter: 1859  total_loss: 1.468  loss_cls: 0.3753  loss_box_reg: 0.5762  loss_mask: 0.3024  loss_rpn_cls: 0.08204  loss_rpn_loc: 0.1327  time: 0.6811  data_time: 0.2224  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:53:15 d2.utils.events]: \u001b[0m eta: 1:10:03  iter: 1879  total_loss: 1.403  loss_cls: 0.3542  loss_box_reg: 0.5761  loss_mask: 0.3083  loss_rpn_cls: 0.05474  loss_rpn_loc: 0.1146  time: 0.6801  data_time: 0.0849  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:53:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:53:32 d2.utils.events]: \u001b[0m eta: 1:10:04  iter: 1899  total_loss: 1.483  loss_cls: 0.3585  loss_box_reg: 0.5331  loss_mask: 0.3004  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.1268  time: 0.6816  data_time: 0.2166  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:53:48 d2.utils.events]: \u001b[0m eta: 1:10:14  iter: 1919  total_loss: 1.497  loss_cls: 0.3931  loss_box_reg: 0.5866  loss_mask: 0.3113  loss_rpn_cls: 0.09664  loss_rpn_loc: 0.1485  time: 0.6826  data_time: 0.2441  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:53:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:54:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:54:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:54:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:54:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:54:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:54:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:54:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0935 s/iter. Eval: 0.0575 s/iter. Total: 0.1516 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 18:54:08 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.0735 s/iter. Total: 0.1699 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 18:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0950 s/iter. Eval: 0.0727 s/iter. Total: 0.1685 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 18:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0958 s/iter. Eval: 0.0797 s/iter. Total: 0.1763 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 18:54:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.288217 (0.174898 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:54:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.095634 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:54:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:54:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2509947534748495\n",
      "\u001b[32m[02/05 18:54:24 d2.utils.events]: \u001b[0m eta: 1:09:56  iter: 1939  total_loss: 1.453  loss_cls: 0.3716  loss_box_reg: 0.5663  loss_mask: 0.2964  loss_rpn_cls: 0.08654  loss_rpn_loc: 0.1241  time: 0.6832  data_time: 0.1433  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:54:37 d2.utils.events]: \u001b[0m eta: 1:09:45  iter: 1959  total_loss: 1.427  loss_cls: 0.3448  loss_box_reg: 0.5866  loss_mask: 0.2914  loss_rpn_cls: 0.07014  loss_rpn_loc: 0.1144  time: 0.6827  data_time: 0.1554  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:54:50 d2.utils.events]: \u001b[0m eta: 1:09:31  iter: 1979  total_loss: 1.406  loss_cls: 0.3571  loss_box_reg: 0.5517  loss_mask: 0.2928  loss_rpn_cls: 0.07442  loss_rpn_loc: 0.1209  time: 0.6827  data_time: 0.1789  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:55:06 d2.utils.events]: \u001b[0m eta: 1:09:15  iter: 1999  total_loss: 1.516  loss_cls: 0.4003  loss_box_reg: 0.5832  loss_mask: 0.3038  loss_rpn_cls: 0.09171  loss_rpn_loc: 0.1319  time: 0.6834  data_time: 0.2581  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:55:16 d2.utils.events]: \u001b[0m eta: 1:09:02  iter: 2019  total_loss: 1.466  loss_cls: 0.3723  loss_box_reg: 0.592  loss_mask: 0.2911  loss_rpn_cls: 0.0589  loss_rpn_loc: 0.1284  time: 0.6819  data_time: 0.0659  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:55:29 d2.utils.events]: \u001b[0m eta: 1:08:52  iter: 2039  total_loss: 1.437  loss_cls: 0.3318  loss_box_reg: 0.5631  loss_mask: 0.3135  loss_rpn_cls: 0.08673  loss_rpn_loc: 0.1264  time: 0.6814  data_time: 0.1757  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:55:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:55:46 d2.utils.events]: \u001b[0m eta: 1:08:52  iter: 2059  total_loss: 1.522  loss_cls: 0.3915  loss_box_reg: 0.5854  loss_mask: 0.312  loss_rpn_cls: 0.08832  loss_rpn_loc: 0.1374  time: 0.6831  data_time: 0.3027  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:56:01 d2.utils.events]: \u001b[0m eta: 1:08:52  iter: 2079  total_loss: 1.43  loss_cls: 0.3688  loss_box_reg: 0.5659  loss_mask: 0.2942  loss_rpn_cls: 0.09195  loss_rpn_loc: 0.1302  time: 0.6836  data_time: 0.2559  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:56:14 d2.utils.events]: \u001b[0m eta: 1:08:56  iter: 2099  total_loss: 1.368  loss_cls: 0.3192  loss_box_reg: 0.5432  loss_mask: 0.2983  loss_rpn_cls: 0.06112  loss_rpn_loc: 0.1141  time: 0.6836  data_time: 0.1610  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:56:31 d2.utils.events]: \u001b[0m eta: 1:08:54  iter: 2119  total_loss: 1.482  loss_cls: 0.351  loss_box_reg: 0.5633  loss_mask: 0.3063  loss_rpn_cls: 0.0841  loss_rpn_loc: 0.138  time: 0.6850  data_time: 0.3016  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:56:43 d2.utils.events]: \u001b[0m eta: 1:08:37  iter: 2139  total_loss: 1.352  loss_cls: 0.3537  loss_box_reg: 0.5626  loss_mask: 0.3044  loss_rpn_cls: 0.05043  loss_rpn_loc: 0.1178  time: 0.6842  data_time: 0.1207  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:56:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:56:58 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 2159  total_loss: 1.49  loss_cls: 0.394  loss_box_reg: 0.5568  loss_mask: 0.312  loss_rpn_cls: 0.07939  loss_rpn_loc: 0.1286  time: 0.6847  data_time: 0.1944  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:57:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:57:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 18:57:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 18:57:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 18:57:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 18:57:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 18:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0917 s/iter. Eval: 0.0605 s/iter. Total: 0.1528 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 18:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0920 s/iter. Eval: 0.0756 s/iter. Total: 0.1684 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 18:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0915 s/iter. Eval: 0.0744 s/iter. Total: 0.1667 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 18:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0920 s/iter. Eval: 0.0803 s/iter. Total: 0.1731 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 18:57:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.031628 (0.172686 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:57:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091614 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 18:57:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 18:57:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24556794139034502\n",
      "\u001b[32m[02/05 18:57:31 d2.utils.events]: \u001b[0m eta: 1:08:07  iter: 2179  total_loss: 1.43  loss_cls: 0.3458  loss_box_reg: 0.5615  loss_mask: 0.2931  loss_rpn_cls: 0.08739  loss_rpn_loc: 0.125  time: 0.6836  data_time: 0.1019  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:57:44 d2.utils.events]: \u001b[0m eta: 1:07:56  iter: 2199  total_loss: 1.436  loss_cls: 0.3535  loss_box_reg: 0.5628  loss_mask: 0.3203  loss_rpn_cls: 0.08888  loss_rpn_loc: 0.1242  time: 0.6835  data_time: 0.1900  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:58:00 d2.utils.events]: \u001b[0m eta: 1:07:47  iter: 2219  total_loss: 1.361  loss_cls: 0.3572  loss_box_reg: 0.5461  loss_mask: 0.3034  loss_rpn_cls: 0.06389  loss_rpn_loc: 0.1325  time: 0.6843  data_time: 0.2994  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:58:10 d2.utils.events]: \u001b[0m eta: 1:07:19  iter: 2239  total_loss: 1.221  loss_cls: 0.2924  loss_box_reg: 0.5168  loss_mask: 0.2738  loss_rpn_cls: 0.03996  loss_rpn_loc: 0.09595  time: 0.6828  data_time: 0.0364  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:58:24 d2.utils.events]: \u001b[0m eta: 1:07:06  iter: 2259  total_loss: 1.458  loss_cls: 0.365  loss_box_reg: 0.5946  loss_mask: 0.3105  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.132  time: 0.6828  data_time: 0.1801  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:58:39 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 2279  total_loss: 1.474  loss_cls: 0.3691  loss_box_reg: 0.5748  loss_mask: 0.3144  loss_rpn_cls: 0.09475  loss_rpn_loc: 0.1421  time: 0.6836  data_time: 0.2837  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:58:55 d2.utils.events]: \u001b[0m eta: 1:07:13  iter: 2299  total_loss: 1.478  loss_cls: 0.3621  loss_box_reg: 0.568  loss_mask: 0.3127  loss_rpn_cls: 0.07818  loss_rpn_loc: 0.1359  time: 0.6844  data_time: 0.2524  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:59:08 d2.utils.events]: \u001b[0m eta: 1:06:52  iter: 2319  total_loss: 1.333  loss_cls: 0.3345  loss_box_reg: 0.5477  loss_mask: 0.2934  loss_rpn_cls: 0.05776  loss_rpn_loc: 0.1182  time: 0.6843  data_time: 0.1846  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:59:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 18:59:22 d2.utils.events]: \u001b[0m eta: 1:06:27  iter: 2339  total_loss: 1.416  loss_cls: 0.3461  loss_box_reg: 0.5663  loss_mask: 0.2883  loss_rpn_cls: 0.05275  loss_rpn_loc: 0.09601  time: 0.6842  data_time: 0.1366  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:59:37 d2.utils.events]: \u001b[0m eta: 1:06:05  iter: 2359  total_loss: 1.428  loss_cls: 0.3506  loss_box_reg: 0.5671  loss_mask: 0.3116  loss_rpn_cls: 0.07794  loss_rpn_loc: 0.1296  time: 0.6850  data_time: 0.2848  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 18:59:55 d2.utils.events]: \u001b[0m eta: 1:05:54  iter: 2379  total_loss: 1.587  loss_cls: 0.4111  loss_box_reg: 0.5809  loss_mask: 0.2989  loss_rpn_cls: 0.088  loss_rpn_loc: 0.1525  time: 0.6869  data_time: 0.3783  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:00:07 d2.utils.events]: \u001b[0m eta: 1:05:39  iter: 2399  total_loss: 1.475  loss_cls: 0.3929  loss_box_reg: 0.5567  loss_mask: 0.3048  loss_rpn_cls: 0.0735  loss_rpn_loc: 0.1322  time: 0.6861  data_time: 0.1026  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:00:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:00:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:00:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:00:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:00:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:00:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0866 s/iter. Eval: 0.0689 s/iter. Total: 0.1561 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 19:00:28 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0821 s/iter. Total: 0.1713 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 19:00:33 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0821 s/iter. Total: 0.1718 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 19:00:38 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0875 s/iter. Total: 0.1779 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 19:00:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.195202 (0.174097 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:00:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088937 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:00:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:00:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2666029607526717\n",
      "\u001b[32m[02/05 19:00:42 d2.utils.events]: \u001b[0m eta: 1:05:26  iter: 2419  total_loss: 1.316  loss_cls: 0.3277  loss_box_reg: 0.549  loss_mask: 0.2848  loss_rpn_cls: 0.05556  loss_rpn_loc: 0.1161  time: 0.6857  data_time: 0.1612  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:00:59 d2.utils.events]: \u001b[0m eta: 1:05:16  iter: 2439  total_loss: 1.447  loss_cls: 0.3626  loss_box_reg: 0.5571  loss_mask: 0.2986  loss_rpn_cls: 0.06628  loss_rpn_loc: 0.113  time: 0.6870  data_time: 0.3674  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:01:13 d2.utils.events]: \u001b[0m eta: 1:05:05  iter: 2459  total_loss: 1.379  loss_cls: 0.3423  loss_box_reg: 0.5504  loss_mask: 0.2859  loss_rpn_cls: 0.05443  loss_rpn_loc: 0.1283  time: 0.6869  data_time: 0.1946  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:01:25 d2.utils.events]: \u001b[0m eta: 1:04:39  iter: 2479  total_loss: 1.378  loss_cls: 0.3306  loss_box_reg: 0.551  loss_mask: 0.2872  loss_rpn_cls: 0.0498  loss_rpn_loc: 0.1131  time: 0.6863  data_time: 0.1265  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:01:40 d2.utils.events]: \u001b[0m eta: 1:04:45  iter: 2499  total_loss: 1.394  loss_cls: 0.3662  loss_box_reg: 0.565  loss_mask: 0.3042  loss_rpn_cls: 0.06662  loss_rpn_loc: 0.114  time: 0.6868  data_time: 0.2449  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:01:50 d2.utils.events]: \u001b[0m eta: 1:04:23  iter: 2519  total_loss: 1.299  loss_cls: 0.3239  loss_box_reg: 0.5577  loss_mask: 0.2823  loss_rpn_cls: 0.05693  loss_rpn_loc: 0.1175  time: 0.6856  data_time: 0.0552  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:02:03 d2.utils.events]: \u001b[0m eta: 1:04:24  iter: 2539  total_loss: 1.46  loss_cls: 0.3382  loss_box_reg: 0.5803  loss_mask: 0.308  loss_rpn_cls: 0.06606  loss_rpn_loc: 0.1288  time: 0.6851  data_time: 0.1182  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:02:18 d2.utils.events]: \u001b[0m eta: 1:04:02  iter: 2559  total_loss: 1.5  loss_cls: 0.3723  loss_box_reg: 0.591  loss_mask: 0.3068  loss_rpn_cls: 0.08534  loss_rpn_loc: 0.1544  time: 0.6855  data_time: 0.2502  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:02:33 d2.utils.events]: \u001b[0m eta: 1:03:34  iter: 2579  total_loss: 1.362  loss_cls: 0.3435  loss_box_reg: 0.5429  loss_mask: 0.2825  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.1198  time: 0.6860  data_time: 0.2540  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:02:47 d2.utils.events]: \u001b[0m eta: 1:03:24  iter: 2599  total_loss: 1.414  loss_cls: 0.342  loss_box_reg: 0.5532  loss_mask: 0.3105  loss_rpn_cls: 0.06515  loss_rpn_loc: 0.1441  time: 0.6862  data_time: 0.2265  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:03:00 d2.utils.events]: \u001b[0m eta: 1:03:10  iter: 2619  total_loss: 1.297  loss_cls: 0.3306  loss_box_reg: 0.5539  loss_mask: 0.2838  loss_rpn_cls: 0.04281  loss_rpn_loc: 0.1037  time: 0.6859  data_time: 0.1525  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:03:13 d2.utils.events]: \u001b[0m eta: 1:02:58  iter: 2639  total_loss: 1.381  loss_cls: 0.3452  loss_box_reg: 0.5467  loss_mask: 0.2939  loss_rpn_cls: 0.07884  loss_rpn_loc: 0.1128  time: 0.6857  data_time: 0.1741  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:03:27 d2.utils.events]: \u001b[0m eta: 1:02:41  iter: 2659  total_loss: 1.582  loss_cls: 0.3929  loss_box_reg: 0.6082  loss_mask: 0.3121  loss_rpn_cls: 0.09358  loss_rpn_loc: 0.1442  time: 0.6857  data_time: 0.2029  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:03:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:03:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:03:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:03:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:03:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:03:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0923 s/iter. Eval: 0.0829 s/iter. Total: 0.1759 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 19:03:36 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0009 s/iter. Inference: 0.0924 s/iter. Eval: 0.0862 s/iter. Total: 0.1795 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 19:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0919 s/iter. Eval: 0.0819 s/iter. Total: 0.1747 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 19:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0914 s/iter. Eval: 0.0862 s/iter. Total: 0.1785 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 19:03:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.374002 (0.175638 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:03:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090763 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:03:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:03:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25405537942495915\n",
      "\u001b[32m[02/05 19:04:01 d2.utils.events]: \u001b[0m eta: 1:02:31  iter: 2679  total_loss: 1.257  loss_cls: 0.2798  loss_box_reg: 0.5393  loss_mask: 0.2904  loss_rpn_cls: 0.05912  loss_rpn_loc: 0.08757  time: 0.6850  data_time: 0.1271  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:04:17 d2.utils.events]: \u001b[0m eta: 1:02:19  iter: 2699  total_loss: 1.46  loss_cls: 0.3356  loss_box_reg: 0.5653  loss_mask: 0.2972  loss_rpn_cls: 0.06388  loss_rpn_loc: 0.1366  time: 0.6859  data_time: 0.3380  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:04:30 d2.utils.events]: \u001b[0m eta: 1:02:05  iter: 2719  total_loss: 1.345  loss_cls: 0.3203  loss_box_reg: 0.5748  loss_mask: 0.2965  loss_rpn_cls: 0.07002  loss_rpn_loc: 0.1159  time: 0.6856  data_time: 0.1695  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:04:44 d2.utils.events]: \u001b[0m eta: 1:02:03  iter: 2739  total_loss: 1.444  loss_cls: 0.3555  loss_box_reg: 0.5682  loss_mask: 0.296  loss_rpn_cls: 0.05709  loss_rpn_loc: 0.1356  time: 0.6859  data_time: 0.2490  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:05:00 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 2759  total_loss: 1.376  loss_cls: 0.3241  loss_box_reg: 0.5523  loss_mask: 0.2922  loss_rpn_cls: 0.08532  loss_rpn_loc: 0.1163  time: 0.6867  data_time: 0.2883  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:05:14 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 2779  total_loss: 1.555  loss_cls: 0.3601  loss_box_reg: 0.6103  loss_mask: 0.3252  loss_rpn_cls: 0.08025  loss_rpn_loc: 0.1341  time: 0.6865  data_time: 0.1363  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:05:29 d2.utils.events]: \u001b[0m eta: 1:01:58  iter: 2799  total_loss: 1.521  loss_cls: 0.4006  loss_box_reg: 0.5861  loss_mask: 0.3056  loss_rpn_cls: 0.09254  loss_rpn_loc: 0.1348  time: 0.6871  data_time: 0.2649  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:05:44 d2.utils.events]: \u001b[0m eta: 1:02:00  iter: 2819  total_loss: 1.513  loss_cls: 0.3771  loss_box_reg: 0.577  loss_mask: 0.3192  loss_rpn_cls: 0.098  loss_rpn_loc: 0.1474  time: 0.6876  data_time: 0.2487  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:05:57 d2.utils.events]: \u001b[0m eta: 1:01:37  iter: 2839  total_loss: 1.418  loss_cls: 0.3458  loss_box_reg: 0.5483  loss_mask: 0.2876  loss_rpn_cls: 0.07615  loss_rpn_loc: 0.1155  time: 0.6874  data_time: 0.1849  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:06:11 d2.utils.events]: \u001b[0m eta: 1:01:07  iter: 2859  total_loss: 1.429  loss_cls: 0.3493  loss_box_reg: 0.5385  loss_mask: 0.3066  loss_rpn_cls: 0.07382  loss_rpn_loc: 0.1181  time: 0.6875  data_time: 0.2413  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:06:23 d2.utils.events]: \u001b[0m eta: 1:00:48  iter: 2879  total_loss: 1.295  loss_cls: 0.309  loss_box_reg: 0.525  loss_mask: 0.2877  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.1094  time: 0.6867  data_time: 0.0906  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:06:36 d2.utils.events]: \u001b[0m eta: 1:00:38  iter: 2899  total_loss: 1.31  loss_cls: 0.3232  loss_box_reg: 0.5558  loss_mask: 0.2916  loss_rpn_cls: 0.05718  loss_rpn_loc: 0.1105  time: 0.6864  data_time: 0.1182  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:06:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:06:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:06:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:06:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:06:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:06:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:06:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0913 s/iter. Eval: 0.0621 s/iter. Total: 0.1541 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 19:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0746 s/iter. Total: 0.1638 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0745 s/iter. Total: 0.1630 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:07:00 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0785 s/iter. Total: 0.1677 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:07:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.310616 (0.166471 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:07:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088024 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:07:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:07:03 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.265469644806186\n",
      "\u001b[32m[02/05 19:07:14 d2.utils.events]: \u001b[0m eta: 1:00:10  iter: 2919  total_loss: 1.434  loss_cls: 0.3611  loss_box_reg: 0.5776  loss_mask: 0.2949  loss_rpn_cls: 0.06105  loss_rpn_loc: 0.122  time: 0.6875  data_time: 0.2660  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:07:27 d2.utils.events]: \u001b[0m eta: 0:59:50  iter: 2939  total_loss: 1.593  loss_cls: 0.392  loss_box_reg: 0.5998  loss_mask: 0.3242  loss_rpn_cls: 0.08368  loss_rpn_loc: 0.1677  time: 0.6872  data_time: 0.1778  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:07:40 d2.utils.events]: \u001b[0m eta: 0:59:37  iter: 2959  total_loss: 1.309  loss_cls: 0.3269  loss_box_reg: 0.5434  loss_mask: 0.2827  loss_rpn_cls: 0.06052  loss_rpn_loc: 0.1245  time: 0.6870  data_time: 0.1864  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:07:57 d2.utils.events]: \u001b[0m eta: 0:59:29  iter: 2979  total_loss: 1.403  loss_cls: 0.3334  loss_box_reg: 0.5777  loss_mask: 0.3045  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.1268  time: 0.6880  data_time: 0.3550  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:08:10 d2.utils.events]: \u001b[0m eta: 0:59:14  iter: 2999  total_loss: 1.419  loss_cls: 0.3378  loss_box_reg: 0.5581  loss_mask: 0.3032  loss_rpn_cls: 0.07177  loss_rpn_loc: 0.1297  time: 0.6880  data_time: 0.2095  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:08:25 d2.utils.events]: \u001b[0m eta: 0:59:09  iter: 3019  total_loss: 1.377  loss_cls: 0.3329  loss_box_reg: 0.5442  loss_mask: 0.2965  loss_rpn_cls: 0.0556  loss_rpn_loc: 0.1163  time: 0.6884  data_time: 0.2681  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:08:41 d2.utils.events]: \u001b[0m eta: 0:59:04  iter: 3039  total_loss: 1.395  loss_cls: 0.3601  loss_box_reg: 0.5385  loss_mask: 0.3071  loss_rpn_cls: 0.07839  loss_rpn_loc: 0.1194  time: 0.6890  data_time: 0.2851  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:08:55 d2.utils.events]: \u001b[0m eta: 0:58:54  iter: 3059  total_loss: 1.445  loss_cls: 0.3599  loss_box_reg: 0.5479  loss_mask: 0.2867  loss_rpn_cls: 0.0609  loss_rpn_loc: 0.1381  time: 0.6890  data_time: 0.2074  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:09:10 d2.utils.events]: \u001b[0m eta: 0:58:43  iter: 3079  total_loss: 1.391  loss_cls: 0.3406  loss_box_reg: 0.5415  loss_mask: 0.2918  loss_rpn_cls: 0.08953  loss_rpn_loc: 0.1215  time: 0.6894  data_time: 0.2605  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:09:24 d2.utils.events]: \u001b[0m eta: 0:58:28  iter: 3099  total_loss: 1.485  loss_cls: 0.3718  loss_box_reg: 0.579  loss_mask: 0.3042  loss_rpn_cls: 0.08749  loss_rpn_loc: 0.1429  time: 0.6894  data_time: 0.2255  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:09:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:09:40 d2.utils.events]: \u001b[0m eta: 0:58:07  iter: 3119  total_loss: 1.389  loss_cls: 0.3332  loss_box_reg: 0.5656  loss_mask: 0.3267  loss_rpn_cls: 0.06466  loss_rpn_loc: 0.128  time: 0.6902  data_time: 0.2509  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:09:52 d2.utils.events]: \u001b[0m eta: 0:58:00  iter: 3139  total_loss: 1.328  loss_cls: 0.2955  loss_box_reg: 0.5493  loss_mask: 0.2999  loss_rpn_cls: 0.04675  loss_rpn_loc: 0.1016  time: 0.6896  data_time: 0.1349  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:09:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:09:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:09:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:09:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:09:56 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:09:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0880 s/iter. Eval: 0.0564 s/iter. Total: 0.1451 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0724 s/iter. Total: 0.1619 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0740 s/iter. Total: 0.1632 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0783 s/iter. Total: 0.1678 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:10:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.324190 (0.166588 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:10:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088462 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:10:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:10:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2645993370511662\n",
      "\u001b[32m[02/05 19:10:27 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 3159  total_loss: 1.399  loss_cls: 0.3517  loss_box_reg: 0.5582  loss_mask: 0.2836  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.1398  time: 0.6897  data_time: 0.2221  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:10:39 d2.utils.events]: \u001b[0m eta: 0:57:41  iter: 3179  total_loss: 1.37  loss_cls: 0.3444  loss_box_reg: 0.548  loss_mask: 0.3084  loss_rpn_cls: 0.06634  loss_rpn_loc: 0.1399  time: 0.6894  data_time: 0.1617  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:10:50 d2.utils.events]: \u001b[0m eta: 0:57:25  iter: 3199  total_loss: 1.298  loss_cls: 0.3225  loss_box_reg: 0.5445  loss_mask: 0.2822  loss_rpn_cls: 0.0499  loss_rpn_loc: 0.09658  time: 0.6883  data_time: 0.0611  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:10:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:11:05 d2.utils.events]: \u001b[0m eta: 0:57:15  iter: 3219  total_loss: 1.444  loss_cls: 0.3569  loss_box_reg: 0.5705  loss_mask: 0.3156  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.1303  time: 0.6886  data_time: 0.1836  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:11:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:11:21 d2.utils.events]: \u001b[0m eta: 0:57:06  iter: 3239  total_loss: 1.436  loss_cls: 0.3687  loss_box_reg: 0.5394  loss_mask: 0.292  loss_rpn_cls: 0.06312  loss_rpn_loc: 0.1332  time: 0.6894  data_time: 0.2585  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:11:38 d2.utils.events]: \u001b[0m eta: 0:56:56  iter: 3259  total_loss: 1.456  loss_cls: 0.3564  loss_box_reg: 0.5626  loss_mask: 0.3147  loss_rpn_cls: 0.08234  loss_rpn_loc: 0.1348  time: 0.6905  data_time: 0.3748  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:11:51 d2.utils.events]: \u001b[0m eta: 0:56:46  iter: 3279  total_loss: 1.409  loss_cls: 0.3517  loss_box_reg: 0.5379  loss_mask: 0.3016  loss_rpn_cls: 0.07445  loss_rpn_loc: 0.1213  time: 0.6902  data_time: 0.1680  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:12:06 d2.utils.events]: \u001b[0m eta: 0:56:32  iter: 3299  total_loss: 1.349  loss_cls: 0.3431  loss_box_reg: 0.5565  loss_mask: 0.2938  loss_rpn_cls: 0.07122  loss_rpn_loc: 0.1272  time: 0.6904  data_time: 0.2414  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:12:17 d2.utils.events]: \u001b[0m eta: 0:56:17  iter: 3319  total_loss: 1.425  loss_cls: 0.3531  loss_box_reg: 0.5528  loss_mask: 0.2984  loss_rpn_cls: 0.05982  loss_rpn_loc: 0.1271  time: 0.6896  data_time: 0.0948  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:12:32 d2.utils.events]: \u001b[0m eta: 0:56:15  iter: 3339  total_loss: 1.497  loss_cls: 0.3784  loss_box_reg: 0.5939  loss_mask: 0.3134  loss_rpn_cls: 0.08137  loss_rpn_loc: 0.1552  time: 0.6900  data_time: 0.2745  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:12:43 d2.utils.events]: \u001b[0m eta: 0:56:03  iter: 3359  total_loss: 1.141  loss_cls: 0.2875  loss_box_reg: 0.5121  loss_mask: 0.2804  loss_rpn_cls: 0.04522  loss_rpn_loc: 0.0735  time: 0.6893  data_time: 0.1073  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:12:54 d2.utils.events]: \u001b[0m eta: 0:55:45  iter: 3379  total_loss: 1.298  loss_cls: 0.2841  loss_box_reg: 0.5567  loss_mask: 0.312  loss_rpn_cls: 0.04324  loss_rpn_loc: 0.1001  time: 0.6883  data_time: 0.0609  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:13:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:13:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:13:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:13:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:13:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:13:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0939 s/iter. Eval: 0.0644 s/iter. Total: 0.1590 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 19:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0009 s/iter. Inference: 0.0944 s/iter. Eval: 0.0799 s/iter. Total: 0.1752 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 19:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0924 s/iter. Eval: 0.0775 s/iter. Total: 0.1707 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 19:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0818 s/iter. Total: 0.1740 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 19:13:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.816649 (0.170833 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:13:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090537 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:13:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:13:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26978591862986756\n",
      "\u001b[32m[02/05 19:13:30 d2.utils.events]: \u001b[0m eta: 0:55:40  iter: 3399  total_loss: 1.497  loss_cls: 0.3746  loss_box_reg: 0.5798  loss_mask: 0.2991  loss_rpn_cls: 0.08279  loss_rpn_loc: 0.1394  time: 0.6885  data_time: 0.1973  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:13:41 d2.utils.events]: \u001b[0m eta: 0:55:31  iter: 3419  total_loss: 1.26  loss_cls: 0.2935  loss_box_reg: 0.5486  loss_mask: 0.2874  loss_rpn_cls: 0.03869  loss_rpn_loc: 0.1018  time: 0.6877  data_time: 0.0721  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:13:54 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 3439  total_loss: 1.463  loss_cls: 0.3546  loss_box_reg: 0.5803  loss_mask: 0.3188  loss_rpn_cls: 0.08687  loss_rpn_loc: 0.1347  time: 0.6874  data_time: 0.1678  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:14:06 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 3459  total_loss: 1.251  loss_cls: 0.2863  loss_box_reg: 0.5472  loss_mask: 0.2887  loss_rpn_cls: 0.04397  loss_rpn_loc: 0.09453  time: 0.6870  data_time: 0.1589  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:14:20 d2.utils.events]: \u001b[0m eta: 0:54:56  iter: 3479  total_loss: 1.498  loss_cls: 0.3834  loss_box_reg: 0.574  loss_mask: 0.2997  loss_rpn_cls: 0.09602  loss_rpn_loc: 0.1405  time: 0.6870  data_time: 0.1944  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:14:36 d2.utils.events]: \u001b[0m eta: 0:54:42  iter: 3499  total_loss: 1.369  loss_cls: 0.358  loss_box_reg: 0.5555  loss_mask: 0.2897  loss_rpn_cls: 0.09316  loss_rpn_loc: 0.116  time: 0.6877  data_time: 0.3269  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:14:51 d2.utils.events]: \u001b[0m eta: 0:54:41  iter: 3519  total_loss: 1.374  loss_cls: 0.3503  loss_box_reg: 0.5521  loss_mask: 0.3031  loss_rpn_cls: 0.0849  loss_rpn_loc: 0.1193  time: 0.6880  data_time: 0.2504  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:15:06 d2.utils.events]: \u001b[0m eta: 0:54:25  iter: 3539  total_loss: 1.477  loss_cls: 0.3734  loss_box_reg: 0.5782  loss_mask: 0.2963  loss_rpn_cls: 0.07539  loss_rpn_loc: 0.1438  time: 0.6884  data_time: 0.2651  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:15:18 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 3559  total_loss: 1.354  loss_cls: 0.3293  loss_box_reg: 0.5505  loss_mask: 0.3035  loss_rpn_cls: 0.04899  loss_rpn_loc: 0.1011  time: 0.6880  data_time: 0.1001  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:15:32 d2.utils.events]: \u001b[0m eta: 0:54:11  iter: 3579  total_loss: 1.355  loss_cls: 0.3194  loss_box_reg: 0.5552  loss_mask: 0.3114  loss_rpn_cls: 0.04598  loss_rpn_loc: 0.1061  time: 0.6880  data_time: 0.1909  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:15:48 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 3599  total_loss: 1.337  loss_cls: 0.3139  loss_box_reg: 0.5319  loss_mask: 0.2976  loss_rpn_cls: 0.07438  loss_rpn_loc: 0.1152  time: 0.6885  data_time: 0.2676  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:16:03 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 3619  total_loss: 1.373  loss_cls: 0.3518  loss_box_reg: 0.5695  loss_mask: 0.2903  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.113  time: 0.6889  data_time: 0.2446  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:16:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:16:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:16:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:16:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:16:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:16:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0936 s/iter. Eval: 0.0588 s/iter. Total: 0.1531 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 19:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0009 s/iter. Inference: 0.0956 s/iter. Eval: 0.0783 s/iter. Total: 0.1748 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 19:16:23 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0009 s/iter. Inference: 0.0960 s/iter. Eval: 0.0800 s/iter. Total: 0.1769 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 19:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0009 s/iter. Inference: 0.0968 s/iter. Eval: 0.0882 s/iter. Total: 0.1860 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 19:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0009 s/iter. Inference: 0.0966 s/iter. Eval: 0.0852 s/iter. Total: 0.1827 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 19:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.226425 (0.182986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.096619 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:16:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:16:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2697734248320303\n",
      "\u001b[32m[02/05 19:16:40 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 3639  total_loss: 1.359  loss_cls: 0.3307  loss_box_reg: 0.5383  loss_mask: 0.3014  loss_rpn_cls: 0.04903  loss_rpn_loc: 0.1197  time: 0.6889  data_time: 0.1796  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:16:53 d2.utils.events]: \u001b[0m eta: 0:53:41  iter: 3659  total_loss: 1.434  loss_cls: 0.3506  loss_box_reg: 0.5753  loss_mask: 0.3003  loss_rpn_cls: 0.06763  loss_rpn_loc: 0.1365  time: 0.6887  data_time: 0.1464  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:17:08 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 3679  total_loss: 1.527  loss_cls: 0.3681  loss_box_reg: 0.5625  loss_mask: 0.3135  loss_rpn_cls: 0.0794  loss_rpn_loc: 0.1274  time: 0.6890  data_time: 0.2332  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:17:23 d2.utils.events]: \u001b[0m eta: 0:53:35  iter: 3699  total_loss: 1.552  loss_cls: 0.387  loss_box_reg: 0.5839  loss_mask: 0.3153  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.1662  time: 0.6893  data_time: 0.2491  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:17:37 d2.utils.events]: \u001b[0m eta: 0:53:26  iter: 3719  total_loss: 1.341  loss_cls: 0.3282  loss_box_reg: 0.5359  loss_mask: 0.2915  loss_rpn_cls: 0.05387  loss_rpn_loc: 0.08179  time: 0.6895  data_time: 0.2284  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:17:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:17:55 d2.utils.events]: \u001b[0m eta: 0:53:14  iter: 3739  total_loss: 1.52  loss_cls: 0.3668  loss_box_reg: 0.575  loss_mask: 0.3044  loss_rpn_cls: 0.08054  loss_rpn_loc: 0.1381  time: 0.6907  data_time: 0.3584  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:18:09 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 3759  total_loss: 1.322  loss_cls: 0.3353  loss_box_reg: 0.5381  loss_mask: 0.2885  loss_rpn_cls: 0.05482  loss_rpn_loc: 0.1318  time: 0.6906  data_time: 0.1946  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:18:21 d2.utils.events]: \u001b[0m eta: 0:52:45  iter: 3779  total_loss: 1.351  loss_cls: 0.3406  loss_box_reg: 0.538  loss_mask: 0.2942  loss_rpn_cls: 0.05831  loss_rpn_loc: 0.1122  time: 0.6902  data_time: 0.1494  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:18:35 d2.utils.events]: \u001b[0m eta: 0:52:32  iter: 3799  total_loss: 1.45  loss_cls: 0.3362  loss_box_reg: 0.5558  loss_mask: 0.298  loss_rpn_cls: 0.07734  loss_rpn_loc: 0.1296  time: 0.6903  data_time: 0.2215  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:18:46 d2.utils.events]: \u001b[0m eta: 0:52:14  iter: 3819  total_loss: 1.43  loss_cls: 0.3163  loss_box_reg: 0.5841  loss_mask: 0.303  loss_rpn_cls: 0.0594  loss_rpn_loc: 0.09955  time: 0.6896  data_time: 0.0781  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:18:57 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 3839  total_loss: 1.418  loss_cls: 0.3317  loss_box_reg: 0.5646  loss_mask: 0.3052  loss_rpn_cls: 0.05389  loss_rpn_loc: 0.1082  time: 0.6889  data_time: 0.0883  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:19:14 d2.utils.events]: \u001b[0m eta: 0:51:54  iter: 3859  total_loss: 1.419  loss_cls: 0.3526  loss_box_reg: 0.5448  loss_mask: 0.2861  loss_rpn_cls: 0.08723  loss_rpn_loc: 0.1384  time: 0.6895  data_time: 0.3149  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:19:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:19:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:19:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:19:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:19:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:19:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0845 s/iter. Eval: 0.0521 s/iter. Total: 0.1373 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0890 s/iter. Eval: 0.0727 s/iter. Total: 0.1626 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 19:19:35 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0714 s/iter. Total: 0.1603 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:19:40 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0750 s/iter. Total: 0.1641 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:19:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.963686 (0.163480 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:19:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088138 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:19:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:19:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2679013789174664\n",
      "\u001b[32m[02/05 19:19:48 d2.utils.events]: \u001b[0m eta: 0:51:44  iter: 3879  total_loss: 1.356  loss_cls: 0.3396  loss_box_reg: 0.5535  loss_mask: 0.3027  loss_rpn_cls: 0.05155  loss_rpn_loc: 0.1215  time: 0.6895  data_time: 0.2032  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:19:58 d2.utils.events]: \u001b[0m eta: 0:51:29  iter: 3899  total_loss: 1.37  loss_cls: 0.3301  loss_box_reg: 0.5335  loss_mask: 0.292  loss_rpn_cls: 0.06707  loss_rpn_loc: 0.1084  time: 0.6886  data_time: 0.0549  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:20:12 d2.utils.events]: \u001b[0m eta: 0:51:19  iter: 3919  total_loss: 1.344  loss_cls: 0.3437  loss_box_reg: 0.5587  loss_mask: 0.2964  loss_rpn_cls: 0.05556  loss_rpn_loc: 0.1209  time: 0.6886  data_time: 0.2002  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:20:28 d2.utils.events]: \u001b[0m eta: 0:51:09  iter: 3939  total_loss: 1.415  loss_cls: 0.3604  loss_box_reg: 0.5627  loss_mask: 0.3015  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.1156  time: 0.6890  data_time: 0.2843  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:20:40 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 3959  total_loss: 1.342  loss_cls: 0.3173  loss_box_reg: 0.5426  loss_mask: 0.2779  loss_rpn_cls: 0.05846  loss_rpn_loc: 0.1065  time: 0.6886  data_time: 0.1165  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:20:54 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 3979  total_loss: 1.537  loss_cls: 0.3814  loss_box_reg: 0.5785  loss_mask: 0.3076  loss_rpn_cls: 0.08629  loss_rpn_loc: 0.1589  time: 0.6888  data_time: 0.2392  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:21:07 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 3999  total_loss: 1.428  loss_cls: 0.339  loss_box_reg: 0.5753  loss_mask: 0.311  loss_rpn_cls: 0.08084  loss_rpn_loc: 0.1231  time: 0.6884  data_time: 0.1320  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:21:19 d2.utils.events]: \u001b[0m eta: 0:50:28  iter: 4019  total_loss: 1.258  loss_cls: 0.3098  loss_box_reg: 0.5351  loss_mask: 0.2759  loss_rpn_cls: 0.05519  loss_rpn_loc: 0.1102  time: 0.6882  data_time: 0.1470  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:21:33 d2.utils.events]: \u001b[0m eta: 0:50:18  iter: 4039  total_loss: 1.338  loss_cls: 0.3261  loss_box_reg: 0.5366  loss_mask: 0.2917  loss_rpn_cls: 0.0611  loss_rpn_loc: 0.1211  time: 0.6882  data_time: 0.2199  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:21:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:21:50 d2.utils.events]: \u001b[0m eta: 0:50:07  iter: 4059  total_loss: 1.389  loss_cls: 0.35  loss_box_reg: 0.5408  loss_mask: 0.288  loss_rpn_cls: 0.05811  loss_rpn_loc: 0.1126  time: 0.6890  data_time: 0.2956  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:22:02 d2.utils.events]: \u001b[0m eta: 0:49:53  iter: 4079  total_loss: 1.366  loss_cls: 0.3415  loss_box_reg: 0.5407  loss_mask: 0.2897  loss_rpn_cls: 0.04703  loss_rpn_loc: 0.1132  time: 0.6884  data_time: 0.1066  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:22:17 d2.utils.events]: \u001b[0m eta: 0:49:43  iter: 4099  total_loss: 1.389  loss_cls: 0.3178  loss_box_reg: 0.5891  loss_mask: 0.3005  loss_rpn_cls: 0.06177  loss_rpn_loc: 0.1257  time: 0.6888  data_time: 0.2711  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:22:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:22:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:22:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:22:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:22:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:22:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0894 s/iter. Eval: 0.0557 s/iter. Total: 0.1457 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 19:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0887 s/iter. Eval: 0.0707 s/iter. Total: 0.1602 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0709 s/iter. Total: 0.1595 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0898 s/iter. Eval: 0.0763 s/iter. Total: 0.1669 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:22:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.273998 (0.166155 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:22:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089583 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:22:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:22:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2739207513424205\n",
      "\u001b[32m[02/05 19:22:52 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 4119  total_loss: 1.45  loss_cls: 0.3494  loss_box_reg: 0.5624  loss_mask: 0.3013  loss_rpn_cls: 0.07105  loss_rpn_loc: 0.1294  time: 0.6890  data_time: 0.2386  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:23:06 d2.utils.events]: \u001b[0m eta: 0:49:27  iter: 4139  total_loss: 1.334  loss_cls: 0.3179  loss_box_reg: 0.5364  loss_mask: 0.291  loss_rpn_cls: 0.05511  loss_rpn_loc: 0.1295  time: 0.6889  data_time: 0.2011  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:23:20 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 4159  total_loss: 1.383  loss_cls: 0.322  loss_box_reg: 0.5539  loss_mask: 0.2854  loss_rpn_cls: 0.05346  loss_rpn_loc: 0.1145  time: 0.6890  data_time: 0.2342  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:23:30 d2.utils.events]: \u001b[0m eta: 0:49:02  iter: 4179  total_loss: 1.227  loss_cls: 0.2931  loss_box_reg: 0.5007  loss_mask: 0.2594  loss_rpn_cls: 0.04892  loss_rpn_loc: 0.1062  time: 0.6881  data_time: 0.0508  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:23:45 d2.utils.events]: \u001b[0m eta: 0:48:58  iter: 4199  total_loss: 1.37  loss_cls: 0.3471  loss_box_reg: 0.5372  loss_mask: 0.2846  loss_rpn_cls: 0.07905  loss_rpn_loc: 0.1293  time: 0.6884  data_time: 0.2556  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:24:00 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 4219  total_loss: 1.414  loss_cls: 0.3423  loss_box_reg: 0.5535  loss_mask: 0.3037  loss_rpn_cls: 0.08636  loss_rpn_loc: 0.1324  time: 0.6888  data_time: 0.2706  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:24:12 d2.utils.events]: \u001b[0m eta: 0:48:37  iter: 4239  total_loss: 1.305  loss_cls: 0.3292  loss_box_reg: 0.543  loss_mask: 0.2801  loss_rpn_cls: 0.04674  loss_rpn_loc: 0.1194  time: 0.6882  data_time: 0.0933  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:24:29 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 4259  total_loss: 1.507  loss_cls: 0.3711  loss_box_reg: 0.5868  loss_mask: 0.3068  loss_rpn_cls: 0.07619  loss_rpn_loc: 0.1574  time: 0.6889  data_time: 0.3601  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:24:42 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 4279  total_loss: 1.4  loss_cls: 0.342  loss_box_reg: 0.5535  loss_mask: 0.2906  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.1216  time: 0.6889  data_time: 0.2002  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:24:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:25:01 d2.utils.events]: \u001b[0m eta: 0:48:06  iter: 4299  total_loss: 1.421  loss_cls: 0.3549  loss_box_reg: 0.5402  loss_mask: 0.293  loss_rpn_cls: 0.06434  loss_rpn_loc: 0.1271  time: 0.6900  data_time: 0.3570  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:25:12 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 4319  total_loss: 1.471  loss_cls: 0.3236  loss_box_reg: 0.5852  loss_mask: 0.3  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.1385  time: 0.6894  data_time: 0.0885  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:25:24 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 4339  total_loss: 1.411  loss_cls: 0.3465  loss_box_reg: 0.5557  loss_mask: 0.2975  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.1236  time: 0.6891  data_time: 0.1407  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:25:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:25:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:25:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:25:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:25:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:25:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:25:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0896 s/iter. Eval: 0.0572 s/iter. Total: 0.1475 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 19:25:42 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0742 s/iter. Total: 0.1663 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 19:25:47 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0773 s/iter. Total: 0.1691 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 19:25:52 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0822 s/iter. Total: 0.1739 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 19:25:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.805999 (0.170741 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:25:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090336 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:25:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:25:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2653423271628354\n",
      "\u001b[32m[02/05 19:26:00 d2.utils.events]: \u001b[0m eta: 0:47:36  iter: 4359  total_loss: 1.353  loss_cls: 0.3274  loss_box_reg: 0.5825  loss_mask: 0.3022  loss_rpn_cls: 0.06404  loss_rpn_loc: 0.1134  time: 0.6892  data_time: 0.2139  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:26:06 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:26:14 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 4379  total_loss: 1.133  loss_cls: 0.2712  loss_box_reg: 0.5071  loss_mask: 0.2911  loss_rpn_cls: 0.04521  loss_rpn_loc: 0.07598  time: 0.6892  data_time: 0.1477  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:26:24 d2.utils.events]: \u001b[0m eta: 0:47:03  iter: 4399  total_loss: 1.371  loss_cls: 0.3122  loss_box_reg: 0.5768  loss_mask: 0.3095  loss_rpn_cls: 0.0555  loss_rpn_loc: 0.1106  time: 0.6884  data_time: 0.0579  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:26:36 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 4419  total_loss: 1.24  loss_cls: 0.2862  loss_box_reg: 0.5211  loss_mask: 0.2905  loss_rpn_cls: 0.04377  loss_rpn_loc: 0.1047  time: 0.6880  data_time: 0.1136  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:26:52 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 4439  total_loss: 1.423  loss_cls: 0.3565  loss_box_reg: 0.5511  loss_mask: 0.3038  loss_rpn_cls: 0.0729  loss_rpn_loc: 0.1419  time: 0.6884  data_time: 0.2735  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:27:04 d2.utils.events]: \u001b[0m eta: 0:46:44  iter: 4459  total_loss: 1.27  loss_cls: 0.3036  loss_box_reg: 0.5247  loss_mask: 0.2827  loss_rpn_cls: 0.0612  loss_rpn_loc: 0.09008  time: 0.6881  data_time: 0.1267  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:27:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:27:24 d2.utils.events]: \u001b[0m eta: 0:46:34  iter: 4479  total_loss: 1.411  loss_cls: 0.3385  loss_box_reg: 0.5515  loss_mask: 0.3059  loss_rpn_cls: 0.08454  loss_rpn_loc: 0.1411  time: 0.6894  data_time: 0.4171  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:27:36 d2.utils.events]: \u001b[0m eta: 0:46:24  iter: 4499  total_loss: 1.398  loss_cls: 0.3336  loss_box_reg: 0.5403  loss_mask: 0.2936  loss_rpn_cls: 0.0645  loss_rpn_loc: 0.1381  time: 0.6890  data_time: 0.1124  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:27:51 d2.utils.events]: \u001b[0m eta: 0:46:13  iter: 4519  total_loss: 1.327  loss_cls: 0.3322  loss_box_reg: 0.543  loss_mask: 0.2841  loss_rpn_cls: 0.06937  loss_rpn_loc: 0.1182  time: 0.6893  data_time: 0.2493  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:28:06 d2.utils.events]: \u001b[0m eta: 0:46:05  iter: 4539  total_loss: 1.396  loss_cls: 0.3557  loss_box_reg: 0.553  loss_mask: 0.3122  loss_rpn_cls: 0.06698  loss_rpn_loc: 0.1307  time: 0.6896  data_time: 0.2405  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:28:19 d2.utils.events]: \u001b[0m eta: 0:45:53  iter: 4559  total_loss: 1.396  loss_cls: 0.3579  loss_box_reg: 0.5772  loss_mask: 0.313  loss_rpn_cls: 0.08291  loss_rpn_loc: 0.1103  time: 0.6894  data_time: 0.1755  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:28:31 d2.utils.events]: \u001b[0m eta: 0:45:34  iter: 4579  total_loss: 1.376  loss_cls: 0.3525  loss_box_reg: 0.5498  loss_mask: 0.294  loss_rpn_cls: 0.06185  loss_rpn_loc: 0.1191  time: 0.6890  data_time: 0.0962  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:28:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:28:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:28:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:28:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:28:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:28:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0882 s/iter. Eval: 0.0549 s/iter. Total: 0.1437 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0724 s/iter. Total: 0.1611 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0730 s/iter. Total: 0.1619 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0775 s/iter. Total: 0.1669 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:29:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.439020 (0.167578 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:29:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089173 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:29:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2633786075578223\n",
      "\u001b[32m[02/05 19:29:07 d2.utils.events]: \u001b[0m eta: 0:45:27  iter: 4599  total_loss: 1.505  loss_cls: 0.3687  loss_box_reg: 0.5574  loss_mask: 0.308  loss_rpn_cls: 0.08062  loss_rpn_loc: 0.1317  time: 0.6892  data_time: 0.2267  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:29:20 d2.utils.events]: \u001b[0m eta: 0:45:12  iter: 4619  total_loss: 1.3  loss_cls: 0.2971  loss_box_reg: 0.527  loss_mask: 0.2957  loss_rpn_cls: 0.05682  loss_rpn_loc: 0.1076  time: 0.6890  data_time: 0.1674  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:29:36 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 4639  total_loss: 1.432  loss_cls: 0.3451  loss_box_reg: 0.5474  loss_mask: 0.3082  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.1415  time: 0.6894  data_time: 0.2783  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:29:52 d2.utils.events]: \u001b[0m eta: 0:44:52  iter: 4659  total_loss: 1.418  loss_cls: 0.352  loss_box_reg: 0.5631  loss_mask: 0.2941  loss_rpn_cls: 0.08801  loss_rpn_loc: 0.1416  time: 0.6900  data_time: 0.3185  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:30:03 d2.utils.events]: \u001b[0m eta: 0:44:36  iter: 4679  total_loss: 1.379  loss_cls: 0.323  loss_box_reg: 0.5398  loss_mask: 0.2886  loss_rpn_cls: 0.05675  loss_rpn_loc: 0.1092  time: 0.6894  data_time: 0.0869  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:30:17 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 4699  total_loss: 1.323  loss_cls: 0.3037  loss_box_reg: 0.547  loss_mask: 0.2864  loss_rpn_cls: 0.0813  loss_rpn_loc: 0.1255  time: 0.6895  data_time: 0.2363  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:30:30 d2.utils.events]: \u001b[0m eta: 0:44:10  iter: 4719  total_loss: 1.37  loss_cls: 0.3259  loss_box_reg: 0.5655  loss_mask: 0.298  loss_rpn_cls: 0.06312  loss_rpn_loc: 0.1232  time: 0.6893  data_time: 0.1734  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:30:42 d2.utils.events]: \u001b[0m eta: 0:43:58  iter: 4739  total_loss: 1.317  loss_cls: 0.3178  loss_box_reg: 0.5341  loss_mask: 0.2911  loss_rpn_cls: 0.05154  loss_rpn_loc: 0.117  time: 0.6889  data_time: 0.1173  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:30:55 d2.utils.events]: \u001b[0m eta: 0:43:48  iter: 4759  total_loss: 1.409  loss_cls: 0.336  loss_box_reg: 0.5561  loss_mask: 0.3025  loss_rpn_cls: 0.05989  loss_rpn_loc: 0.1324  time: 0.6887  data_time: 0.1732  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:31:10 d2.utils.events]: \u001b[0m eta: 0:43:38  iter: 4779  total_loss: 1.465  loss_cls: 0.365  loss_box_reg: 0.5649  loss_mask: 0.3017  loss_rpn_cls: 0.09183  loss_rpn_loc: 0.1508  time: 0.6890  data_time: 0.2854  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:31:24 d2.utils.events]: \u001b[0m eta: 0:43:28  iter: 4799  total_loss: 1.265  loss_cls: 0.2968  loss_box_reg: 0.5272  loss_mask: 0.2812  loss_rpn_cls: 0.05145  loss_rpn_loc: 0.1206  time: 0.6890  data_time: 0.1998  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:31:37 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 4819  total_loss: 1.307  loss_cls: 0.3198  loss_box_reg: 0.5427  loss_mask: 0.2803  loss_rpn_cls: 0.05468  loss_rpn_loc: 0.1034  time: 0.6888  data_time: 0.1665  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:31:50 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:31:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:31:50 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:31:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:31:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:31:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0853 s/iter. Eval: 0.0568 s/iter. Total: 0.1427 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0729 s/iter. Total: 0.1606 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0885 s/iter. Eval: 0.0738 s/iter. Total: 0.1632 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:32:08 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0777 s/iter. Total: 0.1670 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:32:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.236949 (0.165836 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:32:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088165 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:32:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:32:11 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27083131045233044\n",
      "\u001b[32m[02/05 19:32:11 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 4839  total_loss: 1.394  loss_cls: 0.3609  loss_box_reg: 0.5668  loss_mask: 0.3015  loss_rpn_cls: 0.07045  loss_rpn_loc: 0.1195  time: 0.6887  data_time: 0.1748  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:32:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:32:28 d2.utils.events]: \u001b[0m eta: 0:42:58  iter: 4859  total_loss: 1.324  loss_cls: 0.335  loss_box_reg: 0.5393  loss_mask: 0.2909  loss_rpn_cls: 0.06095  loss_rpn_loc: 0.1048  time: 0.6893  data_time: 0.2975  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:32:40 d2.utils.events]: \u001b[0m eta: 0:42:48  iter: 4879  total_loss: 1.368  loss_cls: 0.3124  loss_box_reg: 0.5514  loss_mask: 0.3141  loss_rpn_cls: 0.06911  loss_rpn_loc: 0.1304  time: 0.6890  data_time: 0.1778  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:32:55 d2.utils.events]: \u001b[0m eta: 0:42:40  iter: 4899  total_loss: 1.383  loss_cls: 0.3501  loss_box_reg: 0.5661  loss_mask: 0.292  loss_rpn_cls: 0.06634  loss_rpn_loc: 0.1331  time: 0.6893  data_time: 0.2569  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:33:07 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 4919  total_loss: 1.369  loss_cls: 0.328  loss_box_reg: 0.5669  loss_mask: 0.3057  loss_rpn_cls: 0.05845  loss_rpn_loc: 0.1153  time: 0.6889  data_time: 0.1235  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:33:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:33:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:33:23 d2.utils.events]: \u001b[0m eta: 0:42:20  iter: 4939  total_loss: 1.353  loss_cls: 0.3308  loss_box_reg: 0.5156  loss_mask: 0.2906  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.1245  time: 0.6893  data_time: 0.1938  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:33:38 d2.utils.events]: \u001b[0m eta: 0:42:08  iter: 4959  total_loss: 1.342  loss_cls: 0.3149  loss_box_reg: 0.5403  loss_mask: 0.287  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.1318  time: 0.6896  data_time: 0.2883  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:33:51 d2.utils.events]: \u001b[0m eta: 0:41:55  iter: 4979  total_loss: 1.305  loss_cls: 0.3241  loss_box_reg: 0.5315  loss_mask: 0.2886  loss_rpn_cls: 0.0482  loss_rpn_loc: 0.113  time: 0.6893  data_time: 0.1461  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:34:03 d2.utils.events]: \u001b[0m eta: 0:41:44  iter: 4999  total_loss: 1.366  loss_cls: 0.3528  loss_box_reg: 0.5582  loss_mask: 0.2941  loss_rpn_cls: 0.04716  loss_rpn_loc: 0.102  time: 0.6889  data_time: 0.1268  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:34:16 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 5019  total_loss: 1.448  loss_cls: 0.3566  loss_box_reg: 0.5642  loss_mask: 0.3034  loss_rpn_cls: 0.08832  loss_rpn_loc: 0.1251  time: 0.6889  data_time: 0.2001  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:34:28 d2.utils.events]: \u001b[0m eta: 0:41:20  iter: 5039  total_loss: 1.172  loss_cls: 0.2949  loss_box_reg: 0.4975  loss_mask: 0.2786  loss_rpn_cls: 0.04661  loss_rpn_loc: 0.09309  time: 0.6885  data_time: 0.1275  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:34:42 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 5059  total_loss: 1.384  loss_cls: 0.3278  loss_box_reg: 0.5539  loss_mask: 0.3103  loss_rpn_cls: 0.06662  loss_rpn_loc: 0.1274  time: 0.6885  data_time: 0.2134  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:34:56 d2.utils.events]: \u001b[0m eta: 0:41:00  iter: 5079  total_loss: 1.394  loss_cls: 0.3395  loss_box_reg: 0.5735  loss_mask: 0.3009  loss_rpn_cls: 0.06076  loss_rpn_loc: 0.1204  time: 0.6886  data_time: 0.2410  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:34:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:34:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:34:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:34:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:34:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:34:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.0929 s/iter. Eval: 0.0667 s/iter. Total: 0.1605 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 19:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0009 s/iter. Inference: 0.0907 s/iter. Eval: 0.0765 s/iter. Total: 0.1680 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 19:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0739 s/iter. Total: 0.1634 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0885 s/iter. Eval: 0.0775 s/iter. Total: 0.1669 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:35:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.275994 (0.166172 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:35:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088290 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:35:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:35:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2722432351944911\n",
      "\u001b[32m[02/05 19:35:30 d2.utils.events]: \u001b[0m eta: 0:40:50  iter: 5099  total_loss: 1.477  loss_cls: 0.3546  loss_box_reg: 0.5703  loss_mask: 0.3025  loss_rpn_cls: 0.07992  loss_rpn_loc: 0.1441  time: 0.6884  data_time: 0.1645  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:35:45 d2.utils.events]: \u001b[0m eta: 0:40:38  iter: 5119  total_loss: 1.243  loss_cls: 0.294  loss_box_reg: 0.5469  loss_mask: 0.2897  loss_rpn_cls: 0.04556  loss_rpn_loc: 0.1003  time: 0.6887  data_time: 0.2728  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:35:56 d2.utils.events]: \u001b[0m eta: 0:40:26  iter: 5139  total_loss: 1.333  loss_cls: 0.329  loss_box_reg: 0.5392  loss_mask: 0.2907  loss_rpn_cls: 0.05094  loss_rpn_loc: 0.1167  time: 0.6882  data_time: 0.0915  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:36:10 d2.utils.events]: \u001b[0m eta: 0:40:17  iter: 5159  total_loss: 1.232  loss_cls: 0.2848  loss_box_reg: 0.5243  loss_mask: 0.2928  loss_rpn_cls: 0.0367  loss_rpn_loc: 0.1087  time: 0.6883  data_time: 0.2320  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:36:23 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 5179  total_loss: 1.348  loss_cls: 0.3164  loss_box_reg: 0.5339  loss_mask: 0.2864  loss_rpn_cls: 0.05741  loss_rpn_loc: 0.1087  time: 0.6881  data_time: 0.1456  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:36:38 d2.utils.events]: \u001b[0m eta: 0:39:55  iter: 5199  total_loss: 1.379  loss_cls: 0.3427  loss_box_reg: 0.5472  loss_mask: 0.2919  loss_rpn_cls: 0.07097  loss_rpn_loc: 0.1216  time: 0.6883  data_time: 0.2528  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:36:53 d2.utils.events]: \u001b[0m eta: 0:39:48  iter: 5219  total_loss: 1.309  loss_cls: 0.3362  loss_box_reg: 0.529  loss_mask: 0.2896  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.1187  time: 0.6885  data_time: 0.2413  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:37:07 d2.utils.events]: \u001b[0m eta: 0:39:39  iter: 5239  total_loss: 1.42  loss_cls: 0.3414  loss_box_reg: 0.5603  loss_mask: 0.3114  loss_rpn_cls: 0.08863  loss_rpn_loc: 0.1394  time: 0.6886  data_time: 0.2185  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:37:22 d2.utils.events]: \u001b[0m eta: 0:39:29  iter: 5259  total_loss: 1.37  loss_cls: 0.3499  loss_box_reg: 0.5633  loss_mask: 0.292  loss_rpn_cls: 0.06789  loss_rpn_loc: 0.09335  time: 0.6888  data_time: 0.2530  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:37:35 d2.utils.events]: \u001b[0m eta: 0:39:20  iter: 5279  total_loss: 1.36  loss_cls: 0.3357  loss_box_reg: 0.5621  loss_mask: 0.2993  loss_rpn_cls: 0.0588  loss_rpn_loc: 0.1189  time: 0.6886  data_time: 0.1703  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:37:48 d2.utils.events]: \u001b[0m eta: 0:39:10  iter: 5299  total_loss: 1.455  loss_cls: 0.3615  loss_box_reg: 0.5834  loss_mask: 0.305  loss_rpn_cls: 0.07971  loss_rpn_loc: 0.1327  time: 0.6885  data_time: 0.1865  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:38:00 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 5319  total_loss: 1.298  loss_cls: 0.3254  loss_box_reg: 0.5302  loss_mask: 0.2801  loss_rpn_cls: 0.057  loss_rpn_loc: 0.114  time: 0.6882  data_time: 0.1415  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:38:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:38:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:38:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:38:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:38:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:38:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:38:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0898 s/iter. Eval: 0.0549 s/iter. Total: 0.1454 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0722 s/iter. Total: 0.1616 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0736 s/iter. Total: 0.1630 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:38:21 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0775 s/iter. Total: 0.1673 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:38:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.257626 (0.166014 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:38:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:38:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:38:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27209443645482334\n",
      "\u001b[32m[02/05 19:38:35 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 5339  total_loss: 1.305  loss_cls: 0.3142  loss_box_reg: 0.533  loss_mask: 0.2798  loss_rpn_cls: 0.06661  loss_rpn_loc: 0.1174  time: 0.6882  data_time: 0.2063  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:38:48 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 5359  total_loss: 1.435  loss_cls: 0.3365  loss_box_reg: 0.5801  loss_mask: 0.2949  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1224  time: 0.6881  data_time: 0.1854  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:39:01 d2.utils.events]: \u001b[0m eta: 0:38:30  iter: 5379  total_loss: 1.369  loss_cls: 0.3389  loss_box_reg: 0.5498  loss_mask: 0.2959  loss_rpn_cls: 0.07267  loss_rpn_loc: 0.1211  time: 0.6880  data_time: 0.1700  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:39:17 d2.utils.events]: \u001b[0m eta: 0:38:22  iter: 5399  total_loss: 1.443  loss_cls: 0.3619  loss_box_reg: 0.5613  loss_mask: 0.3075  loss_rpn_cls: 0.07421  loss_rpn_loc: 0.1311  time: 0.6882  data_time: 0.2742  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:39:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:39:34 d2.utils.events]: \u001b[0m eta: 0:38:15  iter: 5419  total_loss: 1.465  loss_cls: 0.3321  loss_box_reg: 0.5759  loss_mask: 0.3035  loss_rpn_cls: 0.07708  loss_rpn_loc: 0.135  time: 0.6889  data_time: 0.2967  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:39:46 d2.utils.events]: \u001b[0m eta: 0:38:02  iter: 5439  total_loss: 1.484  loss_cls: 0.3334  loss_box_reg: 0.58  loss_mask: 0.3165  loss_rpn_cls: 0.07  loss_rpn_loc: 0.1194  time: 0.6886  data_time: 0.1425  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:39:58 d2.utils.events]: \u001b[0m eta: 0:37:50  iter: 5459  total_loss: 1.265  loss_cls: 0.3017  loss_box_reg: 0.5139  loss_mask: 0.2861  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.0891  time: 0.6883  data_time: 0.1364  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:40:12 d2.utils.events]: \u001b[0m eta: 0:37:39  iter: 5479  total_loss: 1.411  loss_cls: 0.3388  loss_box_reg: 0.5534  loss_mask: 0.2988  loss_rpn_cls: 0.06  loss_rpn_loc: 0.1275  time: 0.6883  data_time: 0.2144  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:40:24 d2.utils.events]: \u001b[0m eta: 0:37:28  iter: 5499  total_loss: 1.382  loss_cls: 0.3421  loss_box_reg: 0.5528  loss_mask: 0.2938  loss_rpn_cls: 0.05616  loss_rpn_loc: 0.1259  time: 0.6880  data_time: 0.1276  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:40:37 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 5519  total_loss: 1.234  loss_cls: 0.2972  loss_box_reg: 0.52  loss_mask: 0.2918  loss_rpn_cls: 0.05017  loss_rpn_loc: 0.09019  time: 0.6878  data_time: 0.1575  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:40:51 d2.utils.events]: \u001b[0m eta: 0:37:01  iter: 5539  total_loss: 1.398  loss_cls: 0.3323  loss_box_reg: 0.535  loss_mask: 0.2971  loss_rpn_cls: 0.06982  loss_rpn_loc: 0.1386  time: 0.6880  data_time: 0.2451  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:41:05 d2.utils.events]: \u001b[0m eta: 0:36:53  iter: 5559  total_loss: 1.331  loss_cls: 0.3096  loss_box_reg: 0.5308  loss_mask: 0.2994  loss_rpn_cls: 0.04658  loss_rpn_loc: 0.123  time: 0.6879  data_time: 0.1657  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:41:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:41:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:41:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:41:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:41:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:41:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0878 s/iter. Eval: 0.0543 s/iter. Total: 0.1427 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0905 s/iter. Eval: 0.0752 s/iter. Total: 0.1665 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 19:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0749 s/iter. Total: 0.1670 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 19:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0803 s/iter. Total: 0.1725 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 19:41:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.706525 (0.169884 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:41:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090606 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:41:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:41:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2736285710035106\n",
      "\u001b[32m[02/05 19:41:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:41:42 d2.utils.events]: \u001b[0m eta: 0:36:45  iter: 5579  total_loss: 1.358  loss_cls: 0.3579  loss_box_reg: 0.54  loss_mask: 0.2985  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.1254  time: 0.6882  data_time: 0.2015  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:41:58 d2.utils.events]: \u001b[0m eta: 0:36:37  iter: 5599  total_loss: 1.382  loss_cls: 0.336  loss_box_reg: 0.5541  loss_mask: 0.2915  loss_rpn_cls: 0.08982  loss_rpn_loc: 0.1311  time: 0.6887  data_time: 0.3067  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:42:11 d2.utils.events]: \u001b[0m eta: 0:36:25  iter: 5619  total_loss: 1.376  loss_cls: 0.3148  loss_box_reg: 0.5634  loss_mask: 0.2946  loss_rpn_cls: 0.06768  loss_rpn_loc: 0.1161  time: 0.6885  data_time: 0.1520  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:42:21 d2.utils.events]: \u001b[0m eta: 0:36:06  iter: 5639  total_loss: 1.278  loss_cls: 0.3054  loss_box_reg: 0.5372  loss_mask: 0.2812  loss_rpn_cls: 0.04442  loss_rpn_loc: 0.08262  time: 0.6879  data_time: 0.0629  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:42:33 d2.utils.events]: \u001b[0m eta: 0:35:48  iter: 5659  total_loss: 1.304  loss_cls: 0.3027  loss_box_reg: 0.5307  loss_mask: 0.2848  loss_rpn_cls: 0.04719  loss_rpn_loc: 0.1002  time: 0.6875  data_time: 0.1081  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:42:45 d2.utils.events]: \u001b[0m eta: 0:35:40  iter: 5679  total_loss: 1.393  loss_cls: 0.3448  loss_box_reg: 0.5642  loss_mask: 0.2888  loss_rpn_cls: 0.05792  loss_rpn_loc: 0.1323  time: 0.6873  data_time: 0.1500  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:43:01 d2.utils.events]: \u001b[0m eta: 0:35:38  iter: 5699  total_loss: 1.517  loss_cls: 0.3749  loss_box_reg: 0.5728  loss_mask: 0.3132  loss_rpn_cls: 0.05939  loss_rpn_loc: 0.1353  time: 0.6876  data_time: 0.2915  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:43:13 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 5719  total_loss: 1.39  loss_cls: 0.3402  loss_box_reg: 0.5637  loss_mask: 0.2896  loss_rpn_cls: 0.0617  loss_rpn_loc: 0.1305  time: 0.6872  data_time: 0.1105  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:43:29 d2.utils.events]: \u001b[0m eta: 0:35:18  iter: 5739  total_loss: 1.453  loss_cls: 0.3517  loss_box_reg: 0.5497  loss_mask: 0.3088  loss_rpn_cls: 0.08097  loss_rpn_loc: 0.1361  time: 0.6877  data_time: 0.3341  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:43:40 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 5759  total_loss: 1.231  loss_cls: 0.2963  loss_box_reg: 0.5214  loss_mask: 0.2697  loss_rpn_cls: 0.05051  loss_rpn_loc: 0.09551  time: 0.6873  data_time: 0.0864  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:43:54 d2.utils.events]: \u001b[0m eta: 0:34:53  iter: 5779  total_loss: 1.344  loss_cls: 0.3363  loss_box_reg: 0.5558  loss_mask: 0.2842  loss_rpn_cls: 0.05773  loss_rpn_loc: 0.1214  time: 0.6873  data_time: 0.2418  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:44:07 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 5799  total_loss: 1.27  loss_cls: 0.2913  loss_box_reg: 0.5222  loss_mask: 0.2973  loss_rpn_cls: 0.04762  loss_rpn_loc: 0.1015  time: 0.6871  data_time: 0.1456  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:44:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:44:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:44:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:44:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:44:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:44:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0837 s/iter. Eval: 0.0513 s/iter. Total: 0.1357 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 19:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0667 s/iter. Total: 0.1533 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 19:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0860 s/iter. Eval: 0.0695 s/iter. Total: 0.1563 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0723 s/iter. Total: 0.1595 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 19:44:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.465824 (0.159188 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:44:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086330 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:44:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:44:32 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2741809000591613\n",
      "\u001b[32m[02/05 19:44:43 d2.utils.events]: \u001b[0m eta: 0:34:34  iter: 5819  total_loss: 1.469  loss_cls: 0.3578  loss_box_reg: 0.5525  loss_mask: 0.3137  loss_rpn_cls: 0.07781  loss_rpn_loc: 0.1455  time: 0.6874  data_time: 0.3070  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:44:53 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 5839  total_loss: 1.274  loss_cls: 0.2973  loss_box_reg: 0.5313  loss_mask: 0.278  loss_rpn_cls: 0.05035  loss_rpn_loc: 0.113  time: 0.6868  data_time: 0.0754  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:45:05 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 5859  total_loss: 1.373  loss_cls: 0.3285  loss_box_reg: 0.5438  loss_mask: 0.2882  loss_rpn_cls: 0.06318  loss_rpn_loc: 0.1235  time: 0.6865  data_time: 0.1316  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:45:16 d2.utils.events]: \u001b[0m eta: 0:33:55  iter: 5879  total_loss: 1.324  loss_cls: 0.3189  loss_box_reg: 0.5474  loss_mask: 0.3101  loss_rpn_cls: 0.05119  loss_rpn_loc: 0.1114  time: 0.6861  data_time: 0.1131  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:45:30 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 5899  total_loss: 1.371  loss_cls: 0.3206  loss_box_reg: 0.5306  loss_mask: 0.2939  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.1113  time: 0.6861  data_time: 0.2003  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:45:45 d2.utils.events]: \u001b[0m eta: 0:33:37  iter: 5919  total_loss: 1.395  loss_cls: 0.3331  loss_box_reg: 0.5395  loss_mask: 0.2944  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.1365  time: 0.6864  data_time: 0.3072  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:45:57 d2.utils.events]: \u001b[0m eta: 0:33:26  iter: 5939  total_loss: 1.355  loss_cls: 0.3299  loss_box_reg: 0.5331  loss_mask: 0.2928  loss_rpn_cls: 0.06968  loss_rpn_loc: 0.1292  time: 0.6861  data_time: 0.1305  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:46:13 d2.utils.events]: \u001b[0m eta: 0:33:19  iter: 5959  total_loss: 1.518  loss_cls: 0.3789  loss_box_reg: 0.5813  loss_mask: 0.3024  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.1452  time: 0.6865  data_time: 0.3292  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:46:27 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 5979  total_loss: 1.32  loss_cls: 0.3188  loss_box_reg: 0.5321  loss_mask: 0.2995  loss_rpn_cls: 0.06125  loss_rpn_loc: 0.1136  time: 0.6865  data_time: 0.2138  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:46:38 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 5999  total_loss: 1.341  loss_cls: 0.3252  loss_box_reg: 0.5445  loss_mask: 0.2841  loss_rpn_cls: 0.0637  loss_rpn_loc: 0.1225  time: 0.6861  data_time: 0.0996  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:46:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:46:57 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 6019  total_loss: 1.362  loss_cls: 0.319  loss_box_reg: 0.5347  loss_mask: 0.2992  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.1065  time: 0.6868  data_time: 0.3511  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:47:09 d2.utils.events]: \u001b[0m eta: 0:32:45  iter: 6039  total_loss: 1.322  loss_cls: 0.3219  loss_box_reg: 0.5358  loss_mask: 0.2802  loss_rpn_cls: 0.07124  loss_rpn_loc: 0.1265  time: 0.6866  data_time: 0.1558  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:47:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:47:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:47:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:47:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:47:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:47:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:47:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0850 s/iter. Eval: 0.0553 s/iter. Total: 0.1409 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0861 s/iter. Eval: 0.0695 s/iter. Total: 0.1565 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0722 s/iter. Total: 0.1593 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0756 s/iter. Total: 0.1632 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 19:47:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.810513 (0.162160 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:47:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086656 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:47:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:47:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27010300714376023\n",
      "\u001b[32m[02/05 19:47:43 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 6059  total_loss: 1.471  loss_cls: 0.3459  loss_box_reg: 0.5712  loss_mask: 0.3371  loss_rpn_cls: 0.08811  loss_rpn_loc: 0.1388  time: 0.6866  data_time: 0.2098  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:47:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:48:00 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 6079  total_loss: 1.537  loss_cls: 0.368  loss_box_reg: 0.58  loss_mask: 0.3009  loss_rpn_cls: 0.08531  loss_rpn_loc: 0.1506  time: 0.6870  data_time: 0.2547  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:48:13 d2.utils.events]: \u001b[0m eta: 0:32:15  iter: 6099  total_loss: 1.39  loss_cls: 0.3307  loss_box_reg: 0.5642  loss_mask: 0.3055  loss_rpn_cls: 0.06084  loss_rpn_loc: 0.1137  time: 0.6869  data_time: 0.2058  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:48:25 d2.utils.events]: \u001b[0m eta: 0:32:01  iter: 6119  total_loss: 1.417  loss_cls: 0.3446  loss_box_reg: 0.5688  loss_mask: 0.3112  loss_rpn_cls: 0.07161  loss_rpn_loc: 0.1296  time: 0.6867  data_time: 0.1416  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:48:37 d2.utils.events]: \u001b[0m eta: 0:31:54  iter: 6139  total_loss: 1.37  loss_cls: 0.3396  loss_box_reg: 0.5438  loss_mask: 0.2945  loss_rpn_cls: 0.06693  loss_rpn_loc: 0.1294  time: 0.6864  data_time: 0.1392  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:48:49 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 6159  total_loss: 1.284  loss_cls: 0.3238  loss_box_reg: 0.5364  loss_mask: 0.2744  loss_rpn_cls: 0.05191  loss_rpn_loc: 0.1264  time: 0.6862  data_time: 0.1497  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:49:02 d2.utils.events]: \u001b[0m eta: 0:31:34  iter: 6179  total_loss: 1.365  loss_cls: 0.3346  loss_box_reg: 0.5456  loss_mask: 0.2849  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.1171  time: 0.6860  data_time: 0.1750  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:49:19 d2.utils.events]: \u001b[0m eta: 0:31:24  iter: 6199  total_loss: 1.333  loss_cls: 0.3225  loss_box_reg: 0.5105  loss_mask: 0.2807  loss_rpn_cls: 0.05292  loss_rpn_loc: 0.1301  time: 0.6865  data_time: 0.3546  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:49:31 d2.utils.events]: \u001b[0m eta: 0:31:07  iter: 6219  total_loss: 1.32  loss_cls: 0.3176  loss_box_reg: 0.5551  loss_mask: 0.2889  loss_rpn_cls: 0.04468  loss_rpn_loc: 0.1105  time: 0.6863  data_time: 0.1625  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:49:46 d2.utils.events]: \u001b[0m eta: 0:30:57  iter: 6239  total_loss: 1.304  loss_cls: 0.3337  loss_box_reg: 0.5166  loss_mask: 0.2923  loss_rpn_cls: 0.06046  loss_rpn_loc: 0.1224  time: 0.6864  data_time: 0.2712  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:49:58 d2.utils.events]: \u001b[0m eta: 0:30:45  iter: 6259  total_loss: 1.388  loss_cls: 0.3281  loss_box_reg: 0.5615  loss_mask: 0.2932  loss_rpn_cls: 0.05053  loss_rpn_loc: 0.1158  time: 0.6862  data_time: 0.1534  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:50:10 d2.utils.events]: \u001b[0m eta: 0:30:35  iter: 6279  total_loss: 1.23  loss_cls: 0.3114  loss_box_reg: 0.5358  loss_mask: 0.2901  loss_rpn_cls: 0.04697  loss_rpn_loc: 0.08138  time: 0.6859  data_time: 0.1310  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:50:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:50:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:50:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:50:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:50:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:50:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:50:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0849 s/iter. Eval: 0.0543 s/iter. Total: 0.1399 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0715 s/iter. Total: 0.1607 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:50:30 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0721 s/iter. Total: 0.1604 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0750 s/iter. Total: 0.1632 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 19:50:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.857829 (0.162567 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:50:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087236 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:50:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:50:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27385047505611515\n",
      "\u001b[32m[02/05 19:50:44 d2.utils.events]: \u001b[0m eta: 0:30:24  iter: 6299  total_loss: 1.302  loss_cls: 0.298  loss_box_reg: 0.5536  loss_mask: 0.3069  loss_rpn_cls: 0.04552  loss_rpn_loc: 0.12  time: 0.6858  data_time: 0.2056  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:50:58 d2.utils.events]: \u001b[0m eta: 0:30:16  iter: 6319  total_loss: 1.365  loss_cls: 0.3129  loss_box_reg: 0.54  loss_mask: 0.2855  loss_rpn_cls: 0.06586  loss_rpn_loc: 0.11  time: 0.6858  data_time: 0.2076  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:51:09 d2.utils.events]: \u001b[0m eta: 0:30:06  iter: 6339  total_loss: 1.198  loss_cls: 0.298  loss_box_reg: 0.5021  loss_mask: 0.2655  loss_rpn_cls: 0.0498  loss_rpn_loc: 0.09664  time: 0.6854  data_time: 0.0963  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:51:24 d2.utils.events]: \u001b[0m eta: 0:29:57  iter: 6359  total_loss: 1.452  loss_cls: 0.3644  loss_box_reg: 0.556  loss_mask: 0.3048  loss_rpn_cls: 0.08388  loss_rpn_loc: 0.1426  time: 0.6856  data_time: 0.2639  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:51:35 d2.utils.events]: \u001b[0m eta: 0:29:47  iter: 6379  total_loss: 1.368  loss_cls: 0.3296  loss_box_reg: 0.5508  loss_mask: 0.2935  loss_rpn_cls: 0.06187  loss_rpn_loc: 0.1126  time: 0.6853  data_time: 0.1120  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:51:48 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 6399  total_loss: 1.213  loss_cls: 0.305  loss_box_reg: 0.5306  loss_mask: 0.2848  loss_rpn_cls: 0.03635  loss_rpn_loc: 0.08536  time: 0.6851  data_time: 0.1421  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:52:00 d2.utils.events]: \u001b[0m eta: 0:29:22  iter: 6419  total_loss: 1.329  loss_cls: 0.3331  loss_box_reg: 0.5558  loss_mask: 0.2824  loss_rpn_cls: 0.05154  loss_rpn_loc: 0.1121  time: 0.6848  data_time: 0.1436  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:52:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:52:14 d2.utils.events]: \u001b[0m eta: 0:29:08  iter: 6439  total_loss: 1.323  loss_cls: 0.3306  loss_box_reg: 0.5517  loss_mask: 0.2793  loss_rpn_cls: 0.0507  loss_rpn_loc: 0.1174  time: 0.6850  data_time: 0.2055  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:52:26 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 6459  total_loss: 1.336  loss_cls: 0.2952  loss_box_reg: 0.5444  loss_mask: 0.302  loss_rpn_cls: 0.0468  loss_rpn_loc: 0.1167  time: 0.6847  data_time: 0.1212  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:52:38 d2.utils.events]: \u001b[0m eta: 0:28:43  iter: 6479  total_loss: 1.211  loss_cls: 0.283  loss_box_reg: 0.517  loss_mask: 0.2894  loss_rpn_cls: 0.03667  loss_rpn_loc: 0.07516  time: 0.6845  data_time: 0.1544  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:52:51 d2.utils.events]: \u001b[0m eta: 0:28:34  iter: 6499  total_loss: 1.341  loss_cls: 0.3296  loss_box_reg: 0.5345  loss_mask: 0.2999  loss_rpn_cls: 0.05911  loss_rpn_loc: 0.1216  time: 0.6843  data_time: 0.1650  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:53:06 d2.utils.events]: \u001b[0m eta: 0:28:28  iter: 6519  total_loss: 1.494  loss_cls: 0.3503  loss_box_reg: 0.5679  loss_mask: 0.3109  loss_rpn_cls: 0.06811  loss_rpn_loc: 0.1483  time: 0.6845  data_time: 0.2635  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:53:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:53:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:53:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:53:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:53:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:53:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0853 s/iter. Eval: 0.0549 s/iter. Total: 0.1408 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0868 s/iter. Eval: 0.0712 s/iter. Total: 0.1587 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0713 s/iter. Total: 0.1587 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0754 s/iter. Total: 0.1632 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 19:53:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.800802 (0.162076 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:53:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086791 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:53:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:53:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2672957403709723\n",
      "\u001b[32m[02/05 19:53:43 d2.utils.events]: \u001b[0m eta: 0:28:17  iter: 6539  total_loss: 1.485  loss_cls: 0.355  loss_box_reg: 0.5599  loss_mask: 0.3128  loss_rpn_cls: 0.07053  loss_rpn_loc: 0.1545  time: 0.6848  data_time: 0.3047  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:53:59 d2.utils.events]: \u001b[0m eta: 0:28:07  iter: 6559  total_loss: 1.383  loss_cls: 0.3355  loss_box_reg: 0.5481  loss_mask: 0.3113  loss_rpn_cls: 0.06964  loss_rpn_loc: 0.1115  time: 0.6853  data_time: 0.3562  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:54:10 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 6579  total_loss: 1.278  loss_cls: 0.2755  loss_box_reg: 0.5585  loss_mask: 0.3041  loss_rpn_cls: 0.04119  loss_rpn_loc: 0.08913  time: 0.6848  data_time: 0.0622  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:54:24 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 6599  total_loss: 1.388  loss_cls: 0.3406  loss_box_reg: 0.5487  loss_mask: 0.2987  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.1239  time: 0.6849  data_time: 0.2375  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:54:37 d2.utils.events]: \u001b[0m eta: 0:27:25  iter: 6619  total_loss: 1.361  loss_cls: 0.3273  loss_box_reg: 0.5641  loss_mask: 0.298  loss_rpn_cls: 0.05908  loss_rpn_loc: 0.1149  time: 0.6848  data_time: 0.2029  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:54:50 d2.utils.events]: \u001b[0m eta: 0:27:18  iter: 6639  total_loss: 1.367  loss_cls: 0.3272  loss_box_reg: 0.5579  loss_mask: 0.2913  loss_rpn_cls: 0.05591  loss_rpn_loc: 0.1236  time: 0.6846  data_time: 0.1464  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:55:01 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 6659  total_loss: 1.358  loss_cls: 0.3162  loss_box_reg: 0.5316  loss_mask: 0.291  loss_rpn_cls: 0.05464  loss_rpn_loc: 0.1088  time: 0.6843  data_time: 0.1133  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:55:15 d2.utils.events]: \u001b[0m eta: 0:26:56  iter: 6679  total_loss: 1.473  loss_cls: 0.3533  loss_box_reg: 0.5693  loss_mask: 0.3055  loss_rpn_cls: 0.0848  loss_rpn_loc: 0.1458  time: 0.6843  data_time: 0.2351  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:55:29 d2.utils.events]: \u001b[0m eta: 0:26:46  iter: 6699  total_loss: 1.353  loss_cls: 0.3353  loss_box_reg: 0.5382  loss_mask: 0.2938  loss_rpn_cls: 0.05668  loss_rpn_loc: 0.1319  time: 0.6843  data_time: 0.1939  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:55:41 d2.utils.events]: \u001b[0m eta: 0:26:41  iter: 6719  total_loss: 1.364  loss_cls: 0.3434  loss_box_reg: 0.5234  loss_mask: 0.2917  loss_rpn_cls: 0.06606  loss_rpn_loc: 0.1152  time: 0.6842  data_time: 0.1613  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:55:54 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 6739  total_loss: 1.274  loss_cls: 0.3077  loss_box_reg: 0.5228  loss_mask: 0.2864  loss_rpn_cls: 0.04165  loss_rpn_loc: 0.1051  time: 0.6840  data_time: 0.1593  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:56:07 d2.utils.events]: \u001b[0m eta: 0:26:23  iter: 6759  total_loss: 1.333  loss_cls: 0.328  loss_box_reg: 0.552  loss_mask: 0.2996  loss_rpn_cls: 0.06228  loss_rpn_loc: 0.1115  time: 0.6839  data_time: 0.1850  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:56:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:56:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:56:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:56:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:56:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:56:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:56:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0850 s/iter. Eval: 0.0540 s/iter. Total: 0.1396 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0681 s/iter. Total: 0.1553 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0710 s/iter. Total: 0.1586 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0737 s/iter. Total: 0.1615 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 19:56:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.673041 (0.160974 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:56:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086927 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:56:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:56:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2731746472057968\n",
      "\u001b[32m[02/05 19:56:40 d2.utils.events]: \u001b[0m eta: 0:26:14  iter: 6779  total_loss: 1.354  loss_cls: 0.3308  loss_box_reg: 0.5542  loss_mask: 0.2966  loss_rpn_cls: 0.04868  loss_rpn_loc: 0.1119  time: 0.6837  data_time: 0.1281  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:56:52 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 6799  total_loss: 1.23  loss_cls: 0.3077  loss_box_reg: 0.5365  loss_mask: 0.2842  loss_rpn_cls: 0.03729  loss_rpn_loc: 0.09818  time: 0.6835  data_time: 0.1624  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:57:06 d2.utils.events]: \u001b[0m eta: 0:25:55  iter: 6819  total_loss: 1.434  loss_cls: 0.3532  loss_box_reg: 0.5396  loss_mask: 0.3076  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.1185  time: 0.6835  data_time: 0.2135  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:57:18 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 6839  total_loss: 1.188  loss_cls: 0.304  loss_box_reg: 0.5096  loss_mask: 0.2823  loss_rpn_cls: 0.04079  loss_rpn_loc: 0.08932  time: 0.6832  data_time: 0.0973  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:57:29 d2.utils.events]: \u001b[0m eta: 0:25:42  iter: 6859  total_loss: 1.342  loss_cls: 0.3356  loss_box_reg: 0.5328  loss_mask: 0.2917  loss_rpn_cls: 0.0528  loss_rpn_loc: 0.1204  time: 0.6829  data_time: 0.0821  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:57:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:57:44 d2.utils.events]: \u001b[0m eta: 0:25:35  iter: 6879  total_loss: 1.314  loss_cls: 0.3076  loss_box_reg: 0.5414  loss_mask: 0.3109  loss_rpn_cls: 0.0486  loss_rpn_loc: 0.1078  time: 0.6831  data_time: 0.2181  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:57:58 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 6899  total_loss: 1.408  loss_cls: 0.3402  loss_box_reg: 0.5721  loss_mask: 0.3169  loss_rpn_cls: 0.07988  loss_rpn_loc: 0.1198  time: 0.6832  data_time: 0.2320  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:58:12 d2.utils.events]: \u001b[0m eta: 0:25:14  iter: 6919  total_loss: 1.407  loss_cls: 0.3467  loss_box_reg: 0.5781  loss_mask: 0.3056  loss_rpn_cls: 0.08063  loss_rpn_loc: 0.1266  time: 0.6832  data_time: 0.2242  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:58:25 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 6939  total_loss: 1.395  loss_cls: 0.3406  loss_box_reg: 0.5375  loss_mask: 0.2832  loss_rpn_cls: 0.08521  loss_rpn_loc: 0.1257  time: 0.6831  data_time: 0.1611  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:58:39 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 6959  total_loss: 1.332  loss_cls: 0.3241  loss_box_reg: 0.5157  loss_mask: 0.2932  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.126  time: 0.6832  data_time: 0.2347  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:58:51 d2.utils.events]: \u001b[0m eta: 0:24:40  iter: 6979  total_loss: 1.309  loss_cls: 0.3116  loss_box_reg: 0.5596  loss_mask: 0.2992  loss_rpn_cls: 0.05831  loss_rpn_loc: 0.1086  time: 0.6829  data_time: 0.1303  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:59:04 d2.utils.events]: \u001b[0m eta: 0:24:33  iter: 6999  total_loss: 1.397  loss_cls: 0.3355  loss_box_reg: 0.5528  loss_mask: 0.3134  loss_rpn_cls: 0.06622  loss_rpn_loc: 0.1298  time: 0.6829  data_time: 0.1725  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:59:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 19:59:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:59:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 19:59:20 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 19:59:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 19:59:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 19:59:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 19:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0887 s/iter. Eval: 0.0546 s/iter. Total: 0.1440 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 19:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0708 s/iter. Total: 0.1596 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 19:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0714 s/iter. Total: 0.1595 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 19:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0752 s/iter. Total: 0.1635 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 19:59:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.819660 (0.162238 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:59:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087150 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 19:59:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 19:59:40 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2734151598997283\n",
      "\u001b[32m[02/05 19:59:41 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 7019  total_loss: 1.447  loss_cls: 0.3661  loss_box_reg: 0.5591  loss_mask: 0.2989  loss_rpn_cls: 0.09609  loss_rpn_loc: 0.1365  time: 0.6832  data_time: 0.2220  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 19:59:55 d2.utils.events]: \u001b[0m eta: 0:24:17  iter: 7039  total_loss: 1.346  loss_cls: 0.3343  loss_box_reg: 0.5277  loss_mask: 0.3005  loss_rpn_cls: 0.05192  loss_rpn_loc: 0.118  time: 0.6833  data_time: 0.2394  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:00:09 d2.utils.events]: \u001b[0m eta: 0:24:07  iter: 7059  total_loss: 1.37  loss_cls: 0.3319  loss_box_reg: 0.5293  loss_mask: 0.2943  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.1206  time: 0.6833  data_time: 0.2204  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:00:19 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 7079  total_loss: 1.264  loss_cls: 0.2946  loss_box_reg: 0.5349  loss_mask: 0.2704  loss_rpn_cls: 0.04189  loss_rpn_loc: 0.08463  time: 0.6829  data_time: 0.0687  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:00:34 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 7099  total_loss: 1.459  loss_cls: 0.3609  loss_box_reg: 0.5571  loss_mask: 0.3098  loss_rpn_cls: 0.08591  loss_rpn_loc: 0.1279  time: 0.6830  data_time: 0.2688  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:00:49 d2.utils.events]: \u001b[0m eta: 0:23:41  iter: 7119  total_loss: 1.294  loss_cls: 0.3063  loss_box_reg: 0.5224  loss_mask: 0.2883  loss_rpn_cls: 0.05395  loss_rpn_loc: 0.1279  time: 0.6831  data_time: 0.2312  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:01:04 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 7139  total_loss: 1.419  loss_cls: 0.3335  loss_box_reg: 0.5536  loss_mask: 0.3039  loss_rpn_cls: 0.0775  loss_rpn_loc: 0.138  time: 0.6833  data_time: 0.2771  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:01:16 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 7159  total_loss: 1.403  loss_cls: 0.3273  loss_box_reg: 0.5534  loss_mask: 0.2882  loss_rpn_cls: 0.05245  loss_rpn_loc: 0.1056  time: 0.6831  data_time: 0.1379  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:01:28 d2.utils.events]: \u001b[0m eta: 0:23:12  iter: 7179  total_loss: 1.455  loss_cls: 0.3561  loss_box_reg: 0.5652  loss_mask: 0.3102  loss_rpn_cls: 0.05529  loss_rpn_loc: 0.153  time: 0.6828  data_time: 0.1069  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:01:40 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 7199  total_loss: 1.351  loss_cls: 0.3169  loss_box_reg: 0.5467  loss_mask: 0.3011  loss_rpn_cls: 0.04809  loss_rpn_loc: 0.1165  time: 0.6826  data_time: 0.1254  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:01:54 d2.utils.events]: \u001b[0m eta: 0:22:52  iter: 7219  total_loss: 1.326  loss_cls: 0.3338  loss_box_reg: 0.5504  loss_mask: 0.2832  loss_rpn_cls: 0.05314  loss_rpn_loc: 0.1147  time: 0.6827  data_time: 0.2382  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:02:12 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 7239  total_loss: 1.469  loss_cls: 0.3627  loss_box_reg: 0.5766  loss_mask: 0.316  loss_rpn_cls: 0.08486  loss_rpn_loc: 0.1366  time: 0.6832  data_time: 0.3871  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:02:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:02:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:02:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:02:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:02:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:02:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:02:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0857 s/iter. Eval: 0.0524 s/iter. Total: 0.1387 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0697 s/iter. Total: 0.1585 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0704 s/iter. Total: 0.1587 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0746 s/iter. Total: 0.1635 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:02:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.872035 (0.162690 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:02:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087916 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:02:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:02:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2738688294160004\n",
      "\u001b[32m[02/05 20:02:44 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 7259  total_loss: 1.238  loss_cls: 0.3142  loss_box_reg: 0.5273  loss_mask: 0.2822  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.1168  time: 0.6830  data_time: 0.1186  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:02:55 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 7279  total_loss: 1.295  loss_cls: 0.2996  loss_box_reg: 0.5243  loss_mask: 0.2873  loss_rpn_cls: 0.04304  loss_rpn_loc: 0.1163  time: 0.6826  data_time: 0.0982  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:03:09 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 7299  total_loss: 1.347  loss_cls: 0.3223  loss_box_reg: 0.5536  loss_mask: 0.3046  loss_rpn_cls: 0.05834  loss_rpn_loc: 0.1169  time: 0.6826  data_time: 0.2019  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:03:22 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 7319  total_loss: 1.421  loss_cls: 0.3367  loss_box_reg: 0.5671  loss_mask: 0.2966  loss_rpn_cls: 0.05746  loss_rpn_loc: 0.1268  time: 0.6826  data_time: 0.2118  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:03:39 d2.utils.events]: \u001b[0m eta: 0:21:57  iter: 7339  total_loss: 1.345  loss_cls: 0.3163  loss_box_reg: 0.5547  loss_mask: 0.2985  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.137  time: 0.6831  data_time: 0.3596  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:03:55 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 7359  total_loss: 1.355  loss_cls: 0.3444  loss_box_reg: 0.5192  loss_mask: 0.2897  loss_rpn_cls: 0.06716  loss_rpn_loc: 0.1368  time: 0.6834  data_time: 0.3011  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:04:08 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 7379  total_loss: 1.483  loss_cls: 0.3645  loss_box_reg: 0.5872  loss_mask: 0.3251  loss_rpn_cls: 0.06932  loss_rpn_loc: 0.142  time: 0.6833  data_time: 0.1786  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:04:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:04:25 d2.utils.events]: \u001b[0m eta: 0:21:29  iter: 7399  total_loss: 1.433  loss_cls: 0.3196  loss_box_reg: 0.5562  loss_mask: 0.3004  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.1388  time: 0.6838  data_time: 0.2944  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:04:37 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 7419  total_loss: 1.291  loss_cls: 0.3115  loss_box_reg: 0.5273  loss_mask: 0.277  loss_rpn_cls: 0.04436  loss_rpn_loc: 0.09653  time: 0.6836  data_time: 0.1480  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:04:51 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 7439  total_loss: 1.324  loss_cls: 0.3462  loss_box_reg: 0.538  loss_mask: 0.2945  loss_rpn_cls: 0.07209  loss_rpn_loc: 0.1168  time: 0.6835  data_time: 0.1810  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:05:03 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 7459  total_loss: 1.275  loss_cls: 0.3023  loss_box_reg: 0.5217  loss_mask: 0.2851  loss_rpn_cls: 0.03893  loss_rpn_loc: 0.09759  time: 0.6833  data_time: 0.1326  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:05:16 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 7479  total_loss: 1.377  loss_cls: 0.3457  loss_box_reg: 0.5379  loss_mask: 0.2963  loss_rpn_cls: 0.07552  loss_rpn_loc: 0.1235  time: 0.6832  data_time: 0.1860  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:05:27 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 7499  total_loss: 1.324  loss_cls: 0.3143  loss_box_reg: 0.5425  loss_mask: 0.2933  loss_rpn_cls: 0.06777  loss_rpn_loc: 0.132  time: 0.6828  data_time: 0.0677  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:05:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:05:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:05:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:05:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:05:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:05:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0854 s/iter. Eval: 0.0548 s/iter. Total: 0.1409 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0710 s/iter. Total: 0.1595 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:05:41 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0720 s/iter. Total: 0.1605 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:05:46 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0755 s/iter. Total: 0.1642 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:05:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.894182 (0.162881 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:05:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087565 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:05:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:05:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.270837663594582\n",
      "\u001b[32m[02/05 20:06:01 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 7519  total_loss: 1.392  loss_cls: 0.3383  loss_box_reg: 0.5289  loss_mask: 0.297  loss_rpn_cls: 0.08019  loss_rpn_loc: 0.1314  time: 0.6828  data_time: 0.2117  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:06:15 d2.utils.events]: \u001b[0m eta: 0:20:22  iter: 7539  total_loss: 1.361  loss_cls: 0.3168  loss_box_reg: 0.51  loss_mask: 0.3067  loss_rpn_cls: 0.07338  loss_rpn_loc: 0.127  time: 0.6829  data_time: 0.2363  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:06:29 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 7559  total_loss: 1.311  loss_cls: 0.3218  loss_box_reg: 0.5323  loss_mask: 0.2984  loss_rpn_cls: 0.05289  loss_rpn_loc: 0.1094  time: 0.6829  data_time: 0.2221  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:06:42 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 7579  total_loss: 1.197  loss_cls: 0.2929  loss_box_reg: 0.5007  loss_mask: 0.2759  loss_rpn_cls: 0.05286  loss_rpn_loc: 0.08344  time: 0.6828  data_time: 0.1709  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:06:58 d2.utils.events]: \u001b[0m eta: 0:19:54  iter: 7599  total_loss: 1.498  loss_cls: 0.3795  loss_box_reg: 0.563  loss_mask: 0.3184  loss_rpn_cls: 0.081  loss_rpn_loc: 0.1495  time: 0.6831  data_time: 0.3079  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:07:10 d2.utils.events]: \u001b[0m eta: 0:19:44  iter: 7619  total_loss: 1.387  loss_cls: 0.337  loss_box_reg: 0.5861  loss_mask: 0.3101  loss_rpn_cls: 0.05265  loss_rpn_loc: 0.1235  time: 0.6829  data_time: 0.1193  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:07:24 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 7639  total_loss: 1.339  loss_cls: 0.3294  loss_box_reg: 0.5285  loss_mask: 0.2872  loss_rpn_cls: 0.06256  loss_rpn_loc: 0.1174  time: 0.6829  data_time: 0.2376  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:07:37 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 7659  total_loss: 1.307  loss_cls: 0.308  loss_box_reg: 0.538  loss_mask: 0.294  loss_rpn_cls: 0.05638  loss_rpn_loc: 0.1216  time: 0.6829  data_time: 0.2214  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:07:50 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 7679  total_loss: 1.239  loss_cls: 0.3186  loss_box_reg: 0.5305  loss_mask: 0.2859  loss_rpn_cls: 0.03727  loss_rpn_loc: 0.09393  time: 0.6827  data_time: 0.1418  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:08:03 d2.utils.events]: \u001b[0m eta: 0:19:06  iter: 7699  total_loss: 1.319  loss_cls: 0.3313  loss_box_reg: 0.5283  loss_mask: 0.2798  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.1209  time: 0.6827  data_time: 0.1764  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:08:15 d2.utils.events]: \u001b[0m eta: 0:18:54  iter: 7719  total_loss: 1.342  loss_cls: 0.3131  loss_box_reg: 0.5443  loss_mask: 0.2893  loss_rpn_cls: 0.05571  loss_rpn_loc: 0.1156  time: 0.6825  data_time: 0.1842  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:08:27 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 7739  total_loss: 1.388  loss_cls: 0.3546  loss_box_reg: 0.5827  loss_mask: 0.2944  loss_rpn_cls: 0.05474  loss_rpn_loc: 0.1453  time: 0.6822  data_time: 0.0912  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:08:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:08:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:08:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:08:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:08:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:08:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0851 s/iter. Eval: 0.0545 s/iter. Total: 0.1403 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0691 s/iter. Total: 0.1562 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0716 s/iter. Total: 0.1586 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0741 s/iter. Total: 0.1621 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:08:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.805254 (0.162114 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:08:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087097 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:08:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:08:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27127500894014944\n",
      "\u001b[32m[02/05 20:09:00 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 7759  total_loss: 1.34  loss_cls: 0.3112  loss_box_reg: 0.5543  loss_mask: 0.3005  loss_rpn_cls: 0.06044  loss_rpn_loc: 0.112  time: 0.6821  data_time: 0.1527  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:09:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:09:15 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 7779  total_loss: 1.361  loss_cls: 0.3388  loss_box_reg: 0.5435  loss_mask: 0.2948  loss_rpn_cls: 0.06831  loss_rpn_loc: 0.1139  time: 0.6823  data_time: 0.2216  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:09:27 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 7799  total_loss: 1.361  loss_cls: 0.3218  loss_box_reg: 0.5448  loss_mask: 0.2894  loss_rpn_cls: 0.05638  loss_rpn_loc: 0.1308  time: 0.6821  data_time: 0.1089  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:09:40 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 7819  total_loss: 1.393  loss_cls: 0.3295  loss_box_reg: 0.5479  loss_mask: 0.3073  loss_rpn_cls: 0.05973  loss_rpn_loc: 0.1218  time: 0.6820  data_time: 0.1864  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:09:52 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 7839  total_loss: 1.391  loss_cls: 0.3409  loss_box_reg: 0.5557  loss_mask: 0.299  loss_rpn_cls: 0.07059  loss_rpn_loc: 0.1398  time: 0.6818  data_time: 0.1486  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:10:07 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 7859  total_loss: 1.354  loss_cls: 0.3045  loss_box_reg: 0.5429  loss_mask: 0.3011  loss_rpn_cls: 0.05521  loss_rpn_loc: 0.1025  time: 0.6820  data_time: 0.2538  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:10:21 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 7879  total_loss: 1.311  loss_cls: 0.3197  loss_box_reg: 0.527  loss_mask: 0.2729  loss_rpn_cls: 0.05995  loss_rpn_loc: 0.124  time: 0.6821  data_time: 0.2369  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:10:35 d2.utils.events]: \u001b[0m eta: 0:17:24  iter: 7899  total_loss: 1.299  loss_cls: 0.3243  loss_box_reg: 0.5178  loss_mask: 0.2797  loss_rpn_cls: 0.05836  loss_rpn_loc: 0.121  time: 0.6820  data_time: 0.1930  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:10:49 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 7919  total_loss: 1.36  loss_cls: 0.3303  loss_box_reg: 0.5707  loss_mask: 0.303  loss_rpn_cls: 0.04828  loss_rpn_loc: 0.1083  time: 0.6820  data_time: 0.2319  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:11:01 d2.utils.events]: \u001b[0m eta: 0:17:03  iter: 7939  total_loss: 1.195  loss_cls: 0.2891  loss_box_reg: 0.5253  loss_mask: 0.2842  loss_rpn_cls: 0.03829  loss_rpn_loc: 0.101  time: 0.6819  data_time: 0.1709  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:11:15 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 7959  total_loss: 1.3  loss_cls: 0.3125  loss_box_reg: 0.5391  loss_mask: 0.2864  loss_rpn_cls: 0.04901  loss_rpn_loc: 0.1154  time: 0.6819  data_time: 0.2113  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:11:28 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 7979  total_loss: 1.356  loss_cls: 0.3454  loss_box_reg: 0.545  loss_mask: 0.3149  loss_rpn_cls: 0.07789  loss_rpn_loc: 0.13  time: 0.6818  data_time: 0.1704  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:11:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:11:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:11:32 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:11:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:11:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:11:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0852 s/iter. Eval: 0.0547 s/iter. Total: 0.1405 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0703 s/iter. Total: 0.1579 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:11:44 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0712 s/iter. Total: 0.1590 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0751 s/iter. Total: 0.1633 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:11:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.864629 (0.162626 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:11:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087428 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:11:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:11:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26996669123437056\n",
      "\u001b[32m[02/05 20:11:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:12:04 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 7999  total_loss: 1.43  loss_cls: 0.3666  loss_box_reg: 0.5565  loss_mask: 0.2953  loss_rpn_cls: 0.06842  loss_rpn_loc: 0.1193  time: 0.6821  data_time: 0.2070  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:12:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:12:20 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 8019  total_loss: 1.48  loss_cls: 0.3678  loss_box_reg: 0.5547  loss_mask: 0.3059  loss_rpn_cls: 0.07527  loss_rpn_loc: 0.1472  time: 0.6823  data_time: 0.2290  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:12:34 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 8039  total_loss: 1.332  loss_cls: 0.3229  loss_box_reg: 0.5448  loss_mask: 0.2914  loss_rpn_cls: 0.06026  loss_rpn_loc: 0.1066  time: 0.6824  data_time: 0.2348  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:12:45 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 8059  total_loss: 1.322  loss_cls: 0.3178  loss_box_reg: 0.5221  loss_mask: 0.2913  loss_rpn_cls: 0.04835  loss_rpn_loc: 0.1061  time: 0.6821  data_time: 0.1106  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:13:00 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 8079  total_loss: 1.355  loss_cls: 0.3423  loss_box_reg: 0.537  loss_mask: 0.2926  loss_rpn_cls: 0.05339  loss_rpn_loc: 0.1235  time: 0.6823  data_time: 0.2475  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:13:14 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 8099  total_loss: 1.36  loss_cls: 0.3292  loss_box_reg: 0.5406  loss_mask: 0.2948  loss_rpn_cls: 0.0583  loss_rpn_loc: 0.1283  time: 0.6823  data_time: 0.2195  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:13:28 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 8119  total_loss: 1.444  loss_cls: 0.3566  loss_box_reg: 0.5627  loss_mask: 0.3037  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.1456  time: 0.6823  data_time: 0.2068  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:13:42 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 8139  total_loss: 1.363  loss_cls: 0.3289  loss_box_reg: 0.5404  loss_mask: 0.3063  loss_rpn_cls: 0.0621  loss_rpn_loc: 0.1211  time: 0.6824  data_time: 0.2693  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:13:53 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 8159  total_loss: 1.203  loss_cls: 0.2628  loss_box_reg: 0.5082  loss_mask: 0.276  loss_rpn_cls: 0.03936  loss_rpn_loc: 0.08582  time: 0.6821  data_time: 0.1086  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:14:06 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 8179  total_loss: 1.357  loss_cls: 0.321  loss_box_reg: 0.5509  loss_mask: 0.3103  loss_rpn_cls: 0.06424  loss_rpn_loc: 0.1117  time: 0.6820  data_time: 0.1703  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:14:24 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 8199  total_loss: 1.448  loss_cls: 0.3377  loss_box_reg: 0.5341  loss_mask: 0.3089  loss_rpn_cls: 0.09401  loss_rpn_loc: 0.1485  time: 0.6825  data_time: 0.4046  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:14:39 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 8219  total_loss: 1.337  loss_cls: 0.3205  loss_box_reg: 0.526  loss_mask: 0.2916  loss_rpn_cls: 0.06514  loss_rpn_loc: 0.1182  time: 0.6827  data_time: 0.2792  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:14:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:14:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:14:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:14:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:14:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:14:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0860 s/iter. Eval: 0.0541 s/iter. Total: 0.1407 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0864 s/iter. Eval: 0.0691 s/iter. Total: 0.1563 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0717 s/iter. Total: 0.1589 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0757 s/iter. Total: 0.1634 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:15:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.883683 (0.162790 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:15:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086959 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:15:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:15:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2746717026311644\n",
      "\u001b[32m[02/05 20:15:13 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 8239  total_loss: 1.425  loss_cls: 0.3501  loss_box_reg: 0.5743  loss_mask: 0.2988  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.1251  time: 0.6826  data_time: 0.1790  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:15:25 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 8259  total_loss: 1.256  loss_cls: 0.2834  loss_box_reg: 0.5429  loss_mask: 0.2876  loss_rpn_cls: 0.04276  loss_rpn_loc: 0.115  time: 0.6824  data_time: 0.1438  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:15:39 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 8279  total_loss: 1.441  loss_cls: 0.3461  loss_box_reg: 0.5744  loss_mask: 0.2939  loss_rpn_cls: 0.06243  loss_rpn_loc: 0.1608  time: 0.6824  data_time: 0.2199  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:15:54 d2.utils.events]: \u001b[0m eta: 0:14:00  iter: 8299  total_loss: 1.391  loss_cls: 0.3449  loss_box_reg: 0.543  loss_mask: 0.3001  loss_rpn_cls: 0.08099  loss_rpn_loc: 0.1272  time: 0.6826  data_time: 0.2669  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:16:06 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 8319  total_loss: 1.261  loss_cls: 0.2832  loss_box_reg: 0.5234  loss_mask: 0.2833  loss_rpn_cls: 0.04432  loss_rpn_loc: 0.09046  time: 0.6824  data_time: 0.1338  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:16:19 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 8339  total_loss: 1.401  loss_cls: 0.3456  loss_box_reg: 0.5499  loss_mask: 0.2985  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.1343  time: 0.6823  data_time: 0.1722  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:16:31 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 8359  total_loss: 1.154  loss_cls: 0.2739  loss_box_reg: 0.4916  loss_mask: 0.2732  loss_rpn_cls: 0.03793  loss_rpn_loc: 0.1037  time: 0.6821  data_time: 0.1300  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:16:43 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 8379  total_loss: 1.336  loss_cls: 0.3332  loss_box_reg: 0.5393  loss_mask: 0.2936  loss_rpn_cls: 0.0669  loss_rpn_loc: 0.1281  time: 0.6820  data_time: 0.1413  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:16:57 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 8399  total_loss: 1.321  loss_cls: 0.3253  loss_box_reg: 0.5462  loss_mask: 0.2829  loss_rpn_cls: 0.04831  loss_rpn_loc: 0.1168  time: 0.6819  data_time: 0.1711  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:17:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:17:15 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 8419  total_loss: 1.367  loss_cls: 0.325  loss_box_reg: 0.5549  loss_mask: 0.2929  loss_rpn_cls: 0.06654  loss_rpn_loc: 0.132  time: 0.6825  data_time: 0.3412  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:17:26 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 8439  total_loss: 1.184  loss_cls: 0.2939  loss_box_reg: 0.5384  loss_mask: 0.2817  loss_rpn_cls: 0.03121  loss_rpn_loc: 0.07746  time: 0.6822  data_time: 0.0981  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:17:39 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 8459  total_loss: 1.345  loss_cls: 0.3414  loss_box_reg: 0.5361  loss_mask: 0.2955  loss_rpn_cls: 0.07344  loss_rpn_loc: 0.1266  time: 0.6821  data_time: 0.1567  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:17:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:17:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:17:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:17:48 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:17:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:17:48 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:17:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0868 s/iter. Eval: 0.0531 s/iter. Total: 0.1405 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0700 s/iter. Total: 0.1584 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0705 s/iter. Total: 0.1585 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:18:05 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0737 s/iter. Total: 0.1618 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:18:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.719814 (0.161378 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:18:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087195 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:18:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:18:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27464817892783555\n",
      "\u001b[32m[02/05 20:18:14 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 8479  total_loss: 1.373  loss_cls: 0.3396  loss_box_reg: 0.5556  loss_mask: 0.2952  loss_rpn_cls: 0.05046  loss_rpn_loc: 0.1174  time: 0.6822  data_time: 0.1739  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:18:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:18:30 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 8499  total_loss: 1.335  loss_cls: 0.321  loss_box_reg: 0.526  loss_mask: 0.2878  loss_rpn_cls: 0.05604  loss_rpn_loc: 0.1237  time: 0.6825  data_time: 0.2685  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:18:43 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 8519  total_loss: 1.394  loss_cls: 0.3458  loss_box_reg: 0.5521  loss_mask: 0.2938  loss_rpn_cls: 0.06218  loss_rpn_loc: 0.1287  time: 0.6824  data_time: 0.1531  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:18:55 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 8539  total_loss: 1.225  loss_cls: 0.3131  loss_box_reg: 0.5191  loss_mask: 0.2893  loss_rpn_cls: 0.04114  loss_rpn_loc: 0.0935  time: 0.6822  data_time: 0.1756  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:19:11 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 8559  total_loss: 1.412  loss_cls: 0.3325  loss_box_reg: 0.5722  loss_mask: 0.3114  loss_rpn_cls: 0.07467  loss_rpn_loc: 0.1397  time: 0.6825  data_time: 0.3024  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:19:22 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 8579  total_loss: 1.427  loss_cls: 0.3491  loss_box_reg: 0.5521  loss_mask: 0.3003  loss_rpn_cls: 0.06208  loss_rpn_loc: 0.1097  time: 0.6822  data_time: 0.0824  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:19:32 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 8599  total_loss: 1.248  loss_cls: 0.305  loss_box_reg: 0.5192  loss_mask: 0.2748  loss_rpn_cls: 0.0484  loss_rpn_loc: 0.1047  time: 0.6817  data_time: 0.0372  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:19:45 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 8619  total_loss: 1.229  loss_cls: 0.2698  loss_box_reg: 0.5088  loss_mask: 0.2837  loss_rpn_cls: 0.05848  loss_rpn_loc: 0.1002  time: 0.6817  data_time: 0.2026  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:20:00 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 8639  total_loss: 1.448  loss_cls: 0.3591  loss_box_reg: 0.5856  loss_mask: 0.3181  loss_rpn_cls: 0.07359  loss_rpn_loc: 0.1332  time: 0.6818  data_time: 0.2410  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:20:14 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 8659  total_loss: 1.333  loss_cls: 0.3236  loss_box_reg: 0.5433  loss_mask: 0.2826  loss_rpn_cls: 0.0635  loss_rpn_loc: 0.1278  time: 0.6819  data_time: 0.2466  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:20:27 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 8679  total_loss: 1.271  loss_cls: 0.3138  loss_box_reg: 0.5181  loss_mask: 0.2806  loss_rpn_cls: 0.05272  loss_rpn_loc: 0.1075  time: 0.6818  data_time: 0.1783  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:20:39 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 8699  total_loss: 1.331  loss_cls: 0.3218  loss_box_reg: 0.5577  loss_mask: 0.2861  loss_rpn_cls: 0.06053  loss_rpn_loc: 0.1246  time: 0.6817  data_time: 0.1323  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:20:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:20:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:20:47 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:20:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:20:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:20:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:20:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0865 s/iter. Eval: 0.0564 s/iter. Total: 0.1435 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0710 s/iter. Total: 0.1592 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0717 s/iter. Total: 0.1598 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0755 s/iter. Total: 0.1638 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:21:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.878169 (0.162743 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:21:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087351 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:21:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:21:07 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2714931738253501\n",
      "\u001b[32m[02/05 20:21:13 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 8719  total_loss: 1.355  loss_cls: 0.3189  loss_box_reg: 0.5425  loss_mask: 0.3031  loss_rpn_cls: 0.06175  loss_rpn_loc: 0.1345  time: 0.6816  data_time: 0.1777  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:21:26 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 8739  total_loss: 1.373  loss_cls: 0.3324  loss_box_reg: 0.5596  loss_mask: 0.3041  loss_rpn_cls: 0.05482  loss_rpn_loc: 0.1254  time: 0.6815  data_time: 0.1813  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:21:41 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 8759  total_loss: 1.374  loss_cls: 0.366  loss_box_reg: 0.5676  loss_mask: 0.2937  loss_rpn_cls: 0.0628  loss_rpn_loc: 0.1369  time: 0.6817  data_time: 0.2814  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:21:53 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 8779  total_loss: 1.307  loss_cls: 0.3411  loss_box_reg: 0.5165  loss_mask: 0.2914  loss_rpn_cls: 0.05892  loss_rpn_loc: 0.09745  time: 0.6815  data_time: 0.1482  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:22:07 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 8799  total_loss: 1.396  loss_cls: 0.3446  loss_box_reg: 0.5609  loss_mask: 0.2992  loss_rpn_cls: 0.07687  loss_rpn_loc: 0.1233  time: 0.6815  data_time: 0.1960  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:22:20 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 8819  total_loss: 1.357  loss_cls: 0.3183  loss_box_reg: 0.5585  loss_mask: 0.2901  loss_rpn_cls: 0.0638  loss_rpn_loc: 0.1212  time: 0.6815  data_time: 0.1866  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:22:34 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 8839  total_loss: 1.355  loss_cls: 0.325  loss_box_reg: 0.5337  loss_mask: 0.2858  loss_rpn_cls: 0.06983  loss_rpn_loc: 0.1208  time: 0.6815  data_time: 0.2197  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:22:45 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 8859  total_loss: 1.273  loss_cls: 0.3113  loss_box_reg: 0.5276  loss_mask: 0.2809  loss_rpn_cls: 0.04715  loss_rpn_loc: 0.1085  time: 0.6812  data_time: 0.0930  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:22:59 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 8879  total_loss: 1.356  loss_cls: 0.3279  loss_box_reg: 0.5546  loss_mask: 0.3034  loss_rpn_cls: 0.06462  loss_rpn_loc: 0.1085  time: 0.6813  data_time: 0.2540  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:23:12 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 8899  total_loss: 1.363  loss_cls: 0.3325  loss_box_reg: 0.5495  loss_mask: 0.2939  loss_rpn_cls: 0.06101  loss_rpn_loc: 0.1215  time: 0.6812  data_time: 0.1589  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:23:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:23:28 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 8919  total_loss: 1.294  loss_cls: 0.2957  loss_box_reg: 0.5104  loss_mask: 0.2868  loss_rpn_cls: 0.0496  loss_rpn_loc: 0.1053  time: 0.6814  data_time: 0.2579  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:23:39 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:23:43 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 8939  total_loss: 1.286  loss_cls: 0.3037  loss_box_reg: 0.5364  loss_mask: 0.2901  loss_rpn_cls: 0.04242  loss_rpn_loc: 0.109  time: 0.6816  data_time: 0.2178  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:23:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:23:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:23:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:23:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:23:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:23:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0873 s/iter. Eval: 0.0608 s/iter. Total: 0.1488 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 20:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0715 s/iter. Total: 0.1599 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0724 s/iter. Total: 0.1601 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0757 s/iter. Total: 0.1639 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:24:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.894815 (0.162886 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:24:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087173 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:24:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:24:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27253770395435484\n",
      "\u001b[32m[02/05 20:24:17 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 8959  total_loss: 1.376  loss_cls: 0.3362  loss_box_reg: 0.5399  loss_mask: 0.2883  loss_rpn_cls: 0.069  loss_rpn_loc: 0.1294  time: 0.6815  data_time: 0.1891  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:24:30 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 8979  total_loss: 1.355  loss_cls: 0.3288  loss_box_reg: 0.5394  loss_mask: 0.2964  loss_rpn_cls: 0.0693  loss_rpn_loc: 0.1376  time: 0.6815  data_time: 0.1695  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:24:44 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 8999  total_loss: 1.308  loss_cls: 0.3015  loss_box_reg: 0.5629  loss_mask: 0.294  loss_rpn_cls: 0.04724  loss_rpn_loc: 0.08577  time: 0.6815  data_time: 0.2111  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:24:56 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 9019  total_loss: 1.291  loss_cls: 0.3067  loss_box_reg: 0.5412  loss_mask: 0.2789  loss_rpn_cls: 0.04018  loss_rpn_loc: 0.1123  time: 0.6813  data_time: 0.1434  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:25:08 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 9039  total_loss: 1.306  loss_cls: 0.3294  loss_box_reg: 0.5381  loss_mask: 0.2851  loss_rpn_cls: 0.05279  loss_rpn_loc: 0.1174  time: 0.6812  data_time: 0.1494  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:25:19 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 9059  total_loss: 1.306  loss_cls: 0.318  loss_box_reg: 0.5176  loss_mask: 0.2915  loss_rpn_cls: 0.04345  loss_rpn_loc: 0.1134  time: 0.6809  data_time: 0.0746  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:25:30 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 9079  total_loss: 1.261  loss_cls: 0.2948  loss_box_reg: 0.5183  loss_mask: 0.2923  loss_rpn_cls: 0.04721  loss_rpn_loc: 0.1005  time: 0.6805  data_time: 0.0788  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:25:43 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 9099  total_loss: 1.402  loss_cls: 0.33  loss_box_reg: 0.5331  loss_mask: 0.2945  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.1426  time: 0.6805  data_time: 0.1779  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:26:00 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 9119  total_loss: 1.29  loss_cls: 0.3149  loss_box_reg: 0.5213  loss_mask: 0.2839  loss_rpn_cls: 0.06315  loss_rpn_loc: 0.1221  time: 0.6809  data_time: 0.3715  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:26:14 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 9139  total_loss: 1.358  loss_cls: 0.3154  loss_box_reg: 0.5182  loss_mask: 0.2998  loss_rpn_cls: 0.06389  loss_rpn_loc: 0.1341  time: 0.6809  data_time: 0.2130  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:26:28 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 9159  total_loss: 1.33  loss_cls: 0.3202  loss_box_reg: 0.5154  loss_mask: 0.2781  loss_rpn_cls: 0.05429  loss_rpn_loc: 0.1213  time: 0.6810  data_time: 0.2542  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:26:43 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 9179  total_loss: 1.4  loss_cls: 0.345  loss_box_reg: 0.5644  loss_mask: 0.3006  loss_rpn_cls: 0.05865  loss_rpn_loc: 0.1196  time: 0.6811  data_time: 0.2552  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:26:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:26:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:26:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:26:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:26:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:26:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0865 s/iter. Eval: 0.0564 s/iter. Total: 0.1436 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0871 s/iter. Eval: 0.0692 s/iter. Total: 0.1571 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0716 s/iter. Total: 0.1596 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0754 s/iter. Total: 0.1638 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:27:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.922871 (0.163128 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:27:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087495 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:27:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:27:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27320640838657484\n",
      "\u001b[32m[02/05 20:27:15 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 9199  total_loss: 1.386  loss_cls: 0.3416  loss_box_reg: 0.543  loss_mask: 0.3067  loss_rpn_cls: 0.07177  loss_rpn_loc: 0.1243  time: 0.6808  data_time: 0.0867  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:27:29 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 9219  total_loss: 1.469  loss_cls: 0.3684  loss_box_reg: 0.5645  loss_mask: 0.3125  loss_rpn_cls: 0.08266  loss_rpn_loc: 0.1386  time: 0.6809  data_time: 0.2168  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:27:42 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 9239  total_loss: 1.179  loss_cls: 0.2893  loss_box_reg: 0.517  loss_mask: 0.2811  loss_rpn_cls: 0.04398  loss_rpn_loc: 0.07971  time: 0.6809  data_time: 0.2177  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:27:59 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 9259  total_loss: 1.318  loss_cls: 0.3087  loss_box_reg: 0.5301  loss_mask: 0.2886  loss_rpn_cls: 0.07177  loss_rpn_loc: 0.1103  time: 0.6812  data_time: 0.3364  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:28:09 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 9279  total_loss: 1.379  loss_cls: 0.3271  loss_box_reg: 0.5595  loss_mask: 0.3023  loss_rpn_cls: 0.05605  loss_rpn_loc: 0.116  time: 0.6808  data_time: 0.0737  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:28:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:28:25 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 9299  total_loss: 1.188  loss_cls: 0.3067  loss_box_reg: 0.5174  loss_mask: 0.2875  loss_rpn_cls: 0.04937  loss_rpn_loc: 0.1063  time: 0.6810  data_time: 0.2138  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:28:37 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 9319  total_loss: 1.353  loss_cls: 0.3286  loss_box_reg: 0.5457  loss_mask: 0.2929  loss_rpn_cls: 0.06284  loss_rpn_loc: 0.1285  time: 0.6809  data_time: 0.1544  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:28:51 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 9339  total_loss: 1.393  loss_cls: 0.3335  loss_box_reg: 0.5603  loss_mask: 0.3079  loss_rpn_cls: 0.06245  loss_rpn_loc: 0.1102  time: 0.6809  data_time: 0.1956  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:29:05 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 9359  total_loss: 1.414  loss_cls: 0.3429  loss_box_reg: 0.5459  loss_mask: 0.3182  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.1299  time: 0.6809  data_time: 0.2156  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:29:19 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 9379  total_loss: 1.361  loss_cls: 0.317  loss_box_reg: 0.556  loss_mask: 0.3056  loss_rpn_cls: 0.05652  loss_rpn_loc: 0.1152  time: 0.6810  data_time: 0.2626  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:29:35 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 9399  total_loss: 1.282  loss_cls: 0.3073  loss_box_reg: 0.5198  loss_mask: 0.2917  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.1097  time: 0.6813  data_time: 0.3085  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:29:48 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 9419  total_loss: 1.333  loss_cls: 0.339  loss_box_reg: 0.5321  loss_mask: 0.2882  loss_rpn_cls: 0.06939  loss_rpn_loc: 0.1246  time: 0.6812  data_time: 0.1876  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:30:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:30:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:30:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:30:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:30:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:30:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0865 s/iter. Eval: 0.0583 s/iter. Total: 0.1454 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 20:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0007 s/iter. Inference: 0.0866 s/iter. Eval: 0.0698 s/iter. Total: 0.1573 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0720 s/iter. Total: 0.1597 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0758 s/iter. Total: 0.1642 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:30:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.916861 (0.163076 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:30:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087387 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:30:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:30:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27394684255281143\n",
      "\u001b[32m[02/05 20:30:21 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 9439  total_loss: 1.332  loss_cls: 0.3332  loss_box_reg: 0.5264  loss_mask: 0.283  loss_rpn_cls: 0.05354  loss_rpn_loc: 0.1221  time: 0.6811  data_time: 0.1442  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:30:33 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 9459  total_loss: 1.363  loss_cls: 0.3403  loss_box_reg: 0.525  loss_mask: 0.2896  loss_rpn_cls: 0.0712  loss_rpn_loc: 0.1105  time: 0.6809  data_time: 0.1359  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:30:43 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 9479  total_loss: 1.251  loss_cls: 0.2824  loss_box_reg: 0.523  loss_mask: 0.2875  loss_rpn_cls: 0.03617  loss_rpn_loc: 0.09248  time: 0.6805  data_time: 0.0268  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:30:56 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 9499  total_loss: 1.385  loss_cls: 0.3317  loss_box_reg: 0.5511  loss_mask: 0.2915  loss_rpn_cls: 0.05988  loss_rpn_loc: 0.138  time: 0.6804  data_time: 0.1806  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:31:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:31:12 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 9519  total_loss: 1.373  loss_cls: 0.327  loss_box_reg: 0.5348  loss_mask: 0.3123  loss_rpn_cls: 0.0833  loss_rpn_loc: 0.1258  time: 0.6806  data_time: 0.2440  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:31:25 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 9539  total_loss: 1.343  loss_cls: 0.3133  loss_box_reg: 0.5648  loss_mask: 0.3152  loss_rpn_cls: 0.06178  loss_rpn_loc: 0.1235  time: 0.6806  data_time: 0.2048  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:31:38 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 9559  total_loss: 1.335  loss_cls: 0.3218  loss_box_reg: 0.5526  loss_mask: 0.292  loss_rpn_cls: 0.05164  loss_rpn_loc: 0.1134  time: 0.6805  data_time: 0.1565  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:31:50 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 9579  total_loss: 1.242  loss_cls: 0.2964  loss_box_reg: 0.5334  loss_mask: 0.2924  loss_rpn_cls: 0.04971  loss_rpn_loc: 0.1146  time: 0.6804  data_time: 0.1306  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:32:01 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 9599  total_loss: 1.3  loss_cls: 0.3083  loss_box_reg: 0.5455  loss_mask: 0.3147  loss_rpn_cls: 0.05685  loss_rpn_loc: 0.1091  time: 0.6801  data_time: 0.0900  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:32:17 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 9619  total_loss: 1.294  loss_cls: 0.3073  loss_box_reg: 0.5332  loss_mask: 0.286  loss_rpn_cls: 0.06719  loss_rpn_loc: 0.1261  time: 0.6803  data_time: 0.3169  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:32:31 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 9639  total_loss: 1.254  loss_cls: 0.3094  loss_box_reg: 0.5132  loss_mask: 0.2872  loss_rpn_cls: 0.0539  loss_rpn_loc: 0.1136  time: 0.6803  data_time: 0.2118  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:32:44 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 9659  total_loss: 1.487  loss_cls: 0.3628  loss_box_reg: 0.5728  loss_mask: 0.3015  loss_rpn_cls: 0.06805  loss_rpn_loc: 0.1553  time: 0.6804  data_time: 0.2102  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:32:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:32:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:32:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:32:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:32:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:32:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:33:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0898 s/iter. Eval: 0.0592 s/iter. Total: 0.1498 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 20:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0702 s/iter. Total: 0.1582 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0723 s/iter. Total: 0.1601 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 105/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0746 s/iter. Total: 0.1626 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:33:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.891253 (0.162856 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:33:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087186 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:33:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:33:18 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27583830778588003\n",
      "\u001b[32m[02/05 20:33:18 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 9679  total_loss: 1.265  loss_cls: 0.2964  loss_box_reg: 0.5433  loss_mask: 0.2788  loss_rpn_cls: 0.04423  loss_rpn_loc: 0.09098  time: 0.6803  data_time: 0.1975  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:33:31 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 9699  total_loss: 1.45  loss_cls: 0.3406  loss_box_reg: 0.5657  loss_mask: 0.3025  loss_rpn_cls: 0.07197  loss_rpn_loc: 0.1363  time: 0.6803  data_time: 0.1859  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:33:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:33:47 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 9719  total_loss: 1.384  loss_cls: 0.307  loss_box_reg: 0.573  loss_mask: 0.2965  loss_rpn_cls: 0.04785  loss_rpn_loc: 0.1065  time: 0.6805  data_time: 0.2400  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:33:59 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 9739  total_loss: 1.316  loss_cls: 0.3076  loss_box_reg: 0.5206  loss_mask: 0.2729  loss_rpn_cls: 0.05512  loss_rpn_loc: 0.1172  time: 0.6804  data_time: 0.1513  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:34:15 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 9759  total_loss: 1.517  loss_cls: 0.3895  loss_box_reg: 0.5775  loss_mask: 0.3206  loss_rpn_cls: 0.08588  loss_rpn_loc: 0.1617  time: 0.6806  data_time: 0.3036  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:34:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:34:32 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 9779  total_loss: 1.409  loss_cls: 0.3366  loss_box_reg: 0.5727  loss_mask: 0.3138  loss_rpn_cls: 0.0705  loss_rpn_loc: 0.1406  time: 0.6809  data_time: 0.2336  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:34:44 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 9799  total_loss: 1.363  loss_cls: 0.3102  loss_box_reg: 0.5397  loss_mask: 0.2973  loss_rpn_cls: 0.06313  loss_rpn_loc: 0.1139  time: 0.6807  data_time: 0.1512  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:34:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:35:01 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 9819  total_loss: 1.295  loss_cls: 0.3069  loss_box_reg: 0.5162  loss_mask: 0.2917  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.1143  time: 0.6811  data_time: 0.3255  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:35:14 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 9839  total_loss: 1.27  loss_cls: 0.3227  loss_box_reg: 0.519  loss_mask: 0.293  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.1102  time: 0.6810  data_time: 0.1769  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:35:26 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 9859  total_loss: 1.379  loss_cls: 0.3201  loss_box_reg: 0.5396  loss_mask: 0.2897  loss_rpn_cls: 0.05855  loss_rpn_loc: 0.1167  time: 0.6809  data_time: 0.1409  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:35:39 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 9879  total_loss: 1.303  loss_cls: 0.3206  loss_box_reg: 0.5152  loss_mask: 0.2831  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.1153  time: 0.6808  data_time: 0.1787  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:35:52 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 9899  total_loss: 1.324  loss_cls: 0.3134  loss_box_reg: 0.5307  loss_mask: 0.2983  loss_rpn_cls: 0.07418  loss_rpn_loc: 0.1148  time: 0.6807  data_time: 0.1626  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:36:03 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9919  total_loss: 1.357  loss_cls: 0.3001  loss_box_reg: 0.5574  loss_mask: 0.2891  loss_rpn_cls: 0.03454  loss_rpn_loc: 0.1039  time: 0.6804  data_time: 0.0886  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:36:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:36:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:36:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:36:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:36:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:36:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0870 s/iter. Eval: 0.0620 s/iter. Total: 0.1496 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 20:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 43/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0703 s/iter. Total: 0.1581 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0720 s/iter. Total: 0.1598 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0755 s/iter. Total: 0.1636 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:36:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.880544 (0.162763 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:36:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087227 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:36:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:36:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27419785675736985\n",
      "\u001b[32m[02/05 20:36:35 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 9939  total_loss: 1.299  loss_cls: 0.3115  loss_box_reg: 0.5305  loss_mask: 0.2764  loss_rpn_cls: 0.03857  loss_rpn_loc: 0.1115  time: 0.6802  data_time: 0.1088  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:36:47 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9959  total_loss: 1.268  loss_cls: 0.3152  loss_box_reg: 0.522  loss_mask: 0.2753  loss_rpn_cls: 0.04183  loss_rpn_loc: 0.1201  time: 0.6801  data_time: 0.1436  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:37:01 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 9979  total_loss: 1.328  loss_cls: 0.3269  loss_box_reg: 0.5259  loss_mask: 0.2872  loss_rpn_cls: 0.07181  loss_rpn_loc: 0.1345  time: 0.6801  data_time: 0.1903  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:37:12 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.329  loss_cls: 0.3234  loss_box_reg: 0.5439  loss_mask: 0.2925  loss_rpn_cls: 0.05152  loss_rpn_loc: 0.1082  time: 0.6798  data_time: 0.0977  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:37:12 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:53:16 (0.6798 s / it)\n",
      "\u001b[32m[02/05 20:37:12 d2.engine.hooks]: \u001b[0mTotal training time: 2:07:36 (0:14:19 on hooks)\n",
      "\u001b[32m[02/05 20:37:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:37:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:37:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:37:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:37:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:37:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:37:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0875 s/iter. Eval: 0.0645 s/iter. Total: 0.1527 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 20:37:20 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0729 s/iter. Total: 0.1611 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 20:37:25 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0871 s/iter. Eval: 0.0726 s/iter. Total: 0.1605 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 20:37:30 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0753 s/iter. Total: 0.1633 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 20:37:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.926595 (0.163160 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:37:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087278 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:37:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:37:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27535279170378846\n"
     ]
    }
   ],
   "source": [
    "# changing the anchor generator sizes and aspect ratios (other values)\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24], [40], [80], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 3.0]]\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "43231dfc-528a-490d-8153-bced72c62670",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 20:54:21 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 20:54:22 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 20:54:23 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/05 20:54:23 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 20:54:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/05 20:54:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/05 20:54:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/05 20:54:24 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:54:24 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 20:54:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/05 20:54:39 d2.utils.events]: \u001b[0m eta: 1:17:52  iter: 19  total_loss: 3.192  loss_cls: 1.335  loss_box_reg: 0.4647  loss_mask: 0.6943  loss_rpn_cls: 0.4021  loss_rpn_loc: 0.2733  time: 0.7555  data_time: 0.3069  lr: 9.9905e-06  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:54:52 d2.utils.events]: \u001b[0m eta: 1:14:56  iter: 39  total_loss: 2.95  loss_cls: 1.228  loss_box_reg: 0.488  loss_mask: 0.687  loss_rpn_cls: 0.3336  loss_rpn_loc: 0.2124  time: 0.6876  data_time: 0.1944  lr: 1.998e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:55:03 d2.utils.events]: \u001b[0m eta: 1:15:02  iter: 59  total_loss: 2.89  loss_cls: 1.058  loss_box_reg: 0.6111  loss_mask: 0.6681  loss_rpn_cls: 0.2997  loss_rpn_loc: 0.2471  time: 0.6410  data_time: 0.1133  lr: 2.997e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:55:17 d2.utils.events]: \u001b[0m eta: 1:15:00  iter: 79  total_loss: 2.57  loss_cls: 0.8471  loss_box_reg: 0.6056  loss_mask: 0.6426  loss_rpn_cls: 0.2658  loss_rpn_loc: 0.2258  time: 0.6556  data_time: 0.2403  lr: 3.9961e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:55:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:55:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:55:32 d2.utils.events]: \u001b[0m eta: 1:14:59  iter: 99  total_loss: 2.42  loss_cls: 0.6988  loss_box_reg: 0.7071  loss_mask: 0.6122  loss_rpn_cls: 0.2404  loss_rpn_loc: 0.2079  time: 0.6756  data_time: 0.1652  lr: 4.9951e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:55:43 d2.utils.events]: \u001b[0m eta: 1:16:41  iter: 119  total_loss: 2.539  loss_cls: 0.7304  loss_box_reg: 0.7956  loss_mask: 0.5986  loss_rpn_cls: 0.2265  loss_rpn_loc: 0.2212  time: 0.6572  data_time: 0.0870  lr: 5.9941e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:55:58 d2.utils.events]: \u001b[0m eta: 1:17:12  iter: 139  total_loss: 2.58  loss_cls: 0.7173  loss_box_reg: 0.8004  loss_mask: 0.5843  loss_rpn_cls: 0.2271  loss_rpn_loc: 0.2312  time: 0.6715  data_time: 0.2830  lr: 6.993e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:56:09 d2.utils.events]: \u001b[0m eta: 1:17:02  iter: 159  total_loss: 2.402  loss_cls: 0.6792  loss_box_reg: 0.7985  loss_mask: 0.5379  loss_rpn_cls: 0.1649  loss_rpn_loc: 0.1687  time: 0.6571  data_time: 0.1076  lr: 7.9921e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:56:22 d2.utils.events]: \u001b[0m eta: 1:17:20  iter: 179  total_loss: 2.299  loss_cls: 0.6315  loss_box_reg: 0.7763  loss_mask: 0.5146  loss_rpn_cls: 0.1932  loss_rpn_loc: 0.1912  time: 0.6566  data_time: 0.1860  lr: 8.991e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:56:36 d2.utils.events]: \u001b[0m eta: 1:17:27  iter: 199  total_loss: 2.145  loss_cls: 0.577  loss_box_reg: 0.7349  loss_mask: 0.4859  loss_rpn_cls: 0.1293  loss_rpn_loc: 0.1573  time: 0.6581  data_time: 0.1987  lr: 9.9901e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:56:49 d2.utils.events]: \u001b[0m eta: 1:17:13  iter: 219  total_loss: 2.112  loss_cls: 0.5408  loss_box_reg: 0.7727  loss_mask: 0.4533  loss_rpn_cls: 0.1576  loss_rpn_loc: 0.1439  time: 0.6580  data_time: 0.1996  lr: 0.00010989  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:57:01 d2.utils.events]: \u001b[0m eta: 1:16:57  iter: 239  total_loss: 2.007  loss_cls: 0.5066  loss_box_reg: 0.7839  loss_mask: 0.3974  loss_rpn_cls: 0.136  loss_rpn_loc: 0.155  time: 0.6513  data_time: 0.1267  lr: 0.00011988  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:57:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:57:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:57:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:57:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:57:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:57:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 20:57:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0855 s/iter. Eval: 0.0189 s/iter. Total: 0.1050 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 20:57:09 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0007 s/iter. Inference: 0.0842 s/iter. Eval: 0.0175 s/iter. Total: 0.1025 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 20:57:14 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0007 s/iter. Inference: 0.0833 s/iter. Eval: 0.0151 s/iter. Total: 0.0992 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 20:57:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.497864 (0.099120 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:57:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.083292 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 20:57:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 20:57:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.1083838557980789\n",
      "\u001b[32m[02/05 20:57:27 d2.utils.events]: \u001b[0m eta: 1:16:47  iter: 259  total_loss: 1.915  loss_cls: 0.4769  loss_box_reg: 0.7382  loss_mask: 0.3888  loss_rpn_cls: 0.1605  loss_rpn_loc: 0.167  time: 0.6543  data_time: 0.2272  lr: 0.00012987  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:57:41 d2.utils.events]: \u001b[0m eta: 1:17:05  iter: 279  total_loss: 1.918  loss_cls: 0.5046  loss_box_reg: 0.7705  loss_mask: 0.3745  loss_rpn_cls: 0.1578  loss_rpn_loc: 0.1647  time: 0.6552  data_time: 0.2138  lr: 0.00013986  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:57:54 d2.utils.events]: \u001b[0m eta: 1:16:55  iter: 299  total_loss: 1.733  loss_cls: 0.3957  loss_box_reg: 0.7325  loss_mask: 0.3349  loss_rpn_cls: 0.1254  loss_rpn_loc: 0.1482  time: 0.6554  data_time: 0.2035  lr: 0.00014985  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:58:08 d2.utils.events]: \u001b[0m eta: 1:16:58  iter: 319  total_loss: 1.684  loss_cls: 0.3691  loss_box_reg: 0.7239  loss_mask: 0.3503  loss_rpn_cls: 0.1302  loss_rpn_loc: 0.1574  time: 0.6599  data_time: 0.2598  lr: 0.00015984  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:58:21 d2.utils.events]: \u001b[0m eta: 1:16:41  iter: 339  total_loss: 1.77  loss_cls: 0.3935  loss_box_reg: 0.719  loss_mask: 0.3346  loss_rpn_cls: 0.131  loss_rpn_loc: 0.1428  time: 0.6581  data_time: 0.1754  lr: 0.00016983  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:58:33 d2.utils.events]: \u001b[0m eta: 1:16:36  iter: 359  total_loss: 1.711  loss_cls: 0.4239  loss_box_reg: 0.6824  loss_mask: 0.3328  loss_rpn_cls: 0.1288  loss_rpn_loc: 0.1715  time: 0.6546  data_time: 0.1301  lr: 0.00017982  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:58:45 d2.utils.events]: \u001b[0m eta: 1:16:33  iter: 379  total_loss: 1.576  loss_cls: 0.3384  loss_box_reg: 0.6689  loss_mask: 0.3117  loss_rpn_cls: 0.0976  loss_rpn_loc: 0.1141  time: 0.6525  data_time: 0.1530  lr: 0.00018981  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:59:04 d2.utils.events]: \u001b[0m eta: 1:16:39  iter: 399  total_loss: 1.616  loss_cls: 0.3546  loss_box_reg: 0.6765  loss_mask: 0.3257  loss_rpn_cls: 0.1676  loss_rpn_loc: 0.1687  time: 0.6680  data_time: 0.4796  lr: 0.0001998  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:59:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 20:59:18 d2.utils.events]: \u001b[0m eta: 1:16:22  iter: 419  total_loss: 1.478  loss_cls: 0.3236  loss_box_reg: 0.6204  loss_mask: 0.3056  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.1433  time: 0.6682  data_time: 0.1415  lr: 0.00020979  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:59:32 d2.utils.events]: \u001b[0m eta: 1:16:21  iter: 439  total_loss: 1.641  loss_cls: 0.3685  loss_box_reg: 0.6723  loss_mask: 0.339  loss_rpn_cls: 0.1397  loss_rpn_loc: 0.1508  time: 0.6689  data_time: 0.2074  lr: 0.00021978  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:59:42 d2.utils.events]: \u001b[0m eta: 1:16:05  iter: 459  total_loss: 1.531  loss_cls: 0.3499  loss_box_reg: 0.6419  loss_mask: 0.3235  loss_rpn_cls: 0.09387  loss_rpn_loc: 0.104  time: 0.6627  data_time: 0.0683  lr: 0.00022977  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:59:53 d2.utils.events]: \u001b[0m eta: 1:15:53  iter: 479  total_loss: 1.561  loss_cls: 0.3408  loss_box_reg: 0.6485  loss_mask: 0.3183  loss_rpn_cls: 0.09227  loss_rpn_loc: 0.1332  time: 0.6585  data_time: 0.0939  lr: 0.00023976  max_mem: 9526M\n",
      "\u001b[32m[02/05 20:59:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:59:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 20:59:58 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 20:59:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 20:59:58 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 20:59:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:00:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0905 s/iter. Eval: 0.0709 s/iter. Total: 0.1620 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 21:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0007 s/iter. Inference: 0.0906 s/iter. Eval: 0.0913 s/iter. Total: 0.1826 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 21:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0007 s/iter. Inference: 0.0905 s/iter. Eval: 0.0937 s/iter. Total: 0.1850 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 21:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0969 s/iter. Total: 0.1882 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 21:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0945 s/iter. Total: 0.1857 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 21:00:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.585910 (0.186085 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:00:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090420 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:00:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:00:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.17410562889557804\n",
      "\u001b[32m[02/05 21:00:31 d2.utils.events]: \u001b[0m eta: 1:15:46  iter: 499  total_loss: 1.59  loss_cls: 0.3827  loss_box_reg: 0.6277  loss_mask: 0.3245  loss_rpn_cls: 0.1166  loss_rpn_loc: 0.163  time: 0.6603  data_time: 0.2409  lr: 0.00024975  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:00:46 d2.utils.events]: \u001b[0m eta: 1:15:41  iter: 519  total_loss: 1.519  loss_cls: 0.3411  loss_box_reg: 0.6041  loss_mask: 0.3276  loss_rpn_cls: 0.1319  loss_rpn_loc: 0.1397  time: 0.6651  data_time: 0.3089  lr: 0.00025974  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:00:59 d2.utils.events]: \u001b[0m eta: 1:15:29  iter: 539  total_loss: 1.404  loss_cls: 0.2847  loss_box_reg: 0.6055  loss_mask: 0.3199  loss_rpn_cls: 0.07045  loss_rpn_loc: 0.1108  time: 0.6633  data_time: 0.1522  lr: 0.00026973  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:01:17 d2.utils.events]: \u001b[0m eta: 1:15:27  iter: 559  total_loss: 1.636  loss_cls: 0.3559  loss_box_reg: 0.6272  loss_mask: 0.3344  loss_rpn_cls: 0.138  loss_rpn_loc: 0.1644  time: 0.6724  data_time: 0.4364  lr: 0.00027972  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:01:30 d2.utils.events]: \u001b[0m eta: 1:15:32  iter: 579  total_loss: 1.729  loss_cls: 0.385  loss_box_reg: 0.6645  loss_mask: 0.3258  loss_rpn_cls: 0.1453  loss_rpn_loc: 0.1609  time: 0.6719  data_time: 0.1721  lr: 0.00028971  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:01:43 d2.utils.events]: \u001b[0m eta: 1:15:21  iter: 599  total_loss: 1.374  loss_cls: 0.3045  loss_box_reg: 0.5706  loss_mask: 0.3154  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.1363  time: 0.6703  data_time: 0.1625  lr: 0.0002997  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:01:56 d2.utils.events]: \u001b[0m eta: 1:15:06  iter: 619  total_loss: 1.509  loss_cls: 0.3279  loss_box_reg: 0.602  loss_mask: 0.3116  loss_rpn_cls: 0.1227  loss_rpn_loc: 0.1395  time: 0.6703  data_time: 0.2112  lr: 0.00030969  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:02:06 d2.utils.events]: \u001b[0m eta: 1:14:44  iter: 639  total_loss: 1.382  loss_cls: 0.3185  loss_box_reg: 0.5781  loss_mask: 0.3028  loss_rpn_cls: 0.08315  loss_rpn_loc: 0.1012  time: 0.6649  data_time: 0.0600  lr: 0.00031968  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:02:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:02:20 d2.utils.events]: \u001b[0m eta: 1:14:34  iter: 659  total_loss: 1.411  loss_cls: 0.3192  loss_box_reg: 0.58  loss_mask: 0.311  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.1162  time: 0.6659  data_time: 0.1578  lr: 0.00032967  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:02:34 d2.utils.events]: \u001b[0m eta: 1:14:25  iter: 679  total_loss: 1.55  loss_cls: 0.3316  loss_box_reg: 0.6121  loss_mask: 0.3105  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.1426  time: 0.6663  data_time: 0.2202  lr: 0.00033966  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:02:45 d2.utils.events]: \u001b[0m eta: 1:14:15  iter: 699  total_loss: 1.369  loss_cls: 0.3088  loss_box_reg: 0.5681  loss_mask: 0.3076  loss_rpn_cls: 0.07688  loss_rpn_loc: 0.1373  time: 0.6632  data_time: 0.1061  lr: 0.00034965  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:02:57 d2.utils.events]: \u001b[0m eta: 1:14:06  iter: 719  total_loss: 1.376  loss_cls: 0.2962  loss_box_reg: 0.5879  loss_mask: 0.3013  loss_rpn_cls: 0.09575  loss_rpn_loc: 0.1152  time: 0.6623  data_time: 0.1705  lr: 0.00035964  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:03:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:03:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:03:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:03:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:03:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:03:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0856 s/iter. Eval: 0.0647 s/iter. Total: 0.1509 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0871 s/iter. Eval: 0.0786 s/iter. Total: 0.1665 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0007 s/iter. Inference: 0.0873 s/iter. Eval: 0.0793 s/iter. Total: 0.1674 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0842 s/iter. Total: 0.1726 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:03:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.815466 (0.170823 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:03:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087380 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:03:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:03:22 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.20857400852366847\n",
      "\u001b[32m[02/05 21:03:30 d2.utils.events]: \u001b[0m eta: 1:13:55  iter: 739  total_loss: 1.465  loss_cls: 0.3117  loss_box_reg: 0.5888  loss_mask: 0.3048  loss_rpn_cls: 0.08178  loss_rpn_loc: 0.1285  time: 0.6596  data_time: 0.1087  lr: 0.00036963  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:03:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:03:46 d2.utils.events]: \u001b[0m eta: 1:13:46  iter: 759  total_loss: 1.427  loss_cls: 0.3248  loss_box_reg: 0.5749  loss_mask: 0.3083  loss_rpn_cls: 0.09666  loss_rpn_loc: 0.1369  time: 0.6630  data_time: 0.2464  lr: 0.00037962  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:04:00 d2.utils.events]: \u001b[0m eta: 1:13:37  iter: 779  total_loss: 1.529  loss_cls: 0.3454  loss_box_reg: 0.6212  loss_mask: 0.3247  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.1341  time: 0.6643  data_time: 0.2432  lr: 0.00038961  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:04:12 d2.utils.events]: \u001b[0m eta: 1:13:24  iter: 799  total_loss: 1.475  loss_cls: 0.3234  loss_box_reg: 0.6103  loss_mask: 0.3039  loss_rpn_cls: 0.08642  loss_rpn_loc: 0.1255  time: 0.6631  data_time: 0.1728  lr: 0.0003996  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:04:27 d2.utils.events]: \u001b[0m eta: 1:13:17  iter: 819  total_loss: 1.41  loss_cls: 0.3221  loss_box_reg: 0.5575  loss_mask: 0.2946  loss_rpn_cls: 0.08054  loss_rpn_loc: 0.1245  time: 0.6643  data_time: 0.2550  lr: 0.00040959  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:04:38 d2.utils.events]: \u001b[0m eta: 1:13:12  iter: 839  total_loss: 1.547  loss_cls: 0.3485  loss_box_reg: 0.5702  loss_mask: 0.3093  loss_rpn_cls: 0.09574  loss_rpn_loc: 0.1331  time: 0.6619  data_time: 0.1011  lr: 0.00041958  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:04:56 d2.utils.events]: \u001b[0m eta: 1:13:09  iter: 859  total_loss: 1.457  loss_cls: 0.3241  loss_box_reg: 0.5483  loss_mask: 0.3076  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.1427  time: 0.6672  data_time: 0.4098  lr: 0.00042957  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:05:07 d2.utils.events]: \u001b[0m eta: 1:12:55  iter: 879  total_loss: 1.482  loss_cls: 0.3334  loss_box_reg: 0.5943  loss_mask: 0.3131  loss_rpn_cls: 0.08229  loss_rpn_loc: 0.1282  time: 0.6647  data_time: 0.1081  lr: 0.00043956  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:05:22 d2.utils.events]: \u001b[0m eta: 1:12:58  iter: 899  total_loss: 1.535  loss_cls: 0.3567  loss_box_reg: 0.5768  loss_mask: 0.3232  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.1477  time: 0.6667  data_time: 0.2773  lr: 0.00044955  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:05:35 d2.utils.events]: \u001b[0m eta: 1:12:47  iter: 919  total_loss: 1.42  loss_cls: 0.2961  loss_box_reg: 0.5683  loss_mask: 0.3154  loss_rpn_cls: 0.09541  loss_rpn_loc: 0.1214  time: 0.6665  data_time: 0.2136  lr: 0.00045954  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:05:48 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 939  total_loss: 1.534  loss_cls: 0.3233  loss_box_reg: 0.6277  loss_mask: 0.3103  loss_rpn_cls: 0.09272  loss_rpn_loc: 0.1561  time: 0.6657  data_time: 0.1692  lr: 0.00046953  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:05:59 d2.utils.events]: \u001b[0m eta: 1:12:17  iter: 959  total_loss: 1.187  loss_cls: 0.2249  loss_box_reg: 0.5298  loss_mask: 0.3057  loss_rpn_cls: 0.07031  loss_rpn_loc: 0.09987  time: 0.6637  data_time: 0.1356  lr: 0.00047952  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:06:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:06:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:06:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:06:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:06:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:06:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0838 s/iter. Eval: 0.0615 s/iter. Total: 0.1459 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0778 s/iter. Total: 0.1642 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0854 s/iter. Eval: 0.0766 s/iter. Total: 0.1628 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 21:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0805 s/iter. Total: 0.1671 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:06:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.364289 (0.166934 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:06:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.085779 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:06:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:06:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23144776621738877\n",
      "\u001b[32m[02/05 21:06:31 d2.utils.events]: \u001b[0m eta: 1:12:04  iter: 979  total_loss: 1.3  loss_cls: 0.2882  loss_box_reg: 0.5532  loss_mask: 0.2885  loss_rpn_cls: 0.07363  loss_rpn_loc: 0.1231  time: 0.6610  data_time: 0.0806  lr: 0.00048951  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:06:44 d2.utils.events]: \u001b[0m eta: 1:12:00  iter: 999  total_loss: 1.504  loss_cls: 0.3346  loss_box_reg: 0.5818  loss_mask: 0.3176  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.1491  time: 0.6612  data_time: 0.2093  lr: 0.0004995  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:06:56 d2.utils.events]: \u001b[0m eta: 1:11:48  iter: 1019  total_loss: 1.451  loss_cls: 0.33  loss_box_reg: 0.5695  loss_mask: 0.3074  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1296  time: 0.6603  data_time: 0.1566  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:07:07 d2.utils.events]: \u001b[0m eta: 1:11:40  iter: 1039  total_loss: 1.412  loss_cls: 0.2961  loss_box_reg: 0.5583  loss_mask: 0.31  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.1207  time: 0.6578  data_time: 0.0835  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:07:16 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:07:24 d2.utils.events]: \u001b[0m eta: 1:11:40  iter: 1059  total_loss: 1.502  loss_cls: 0.3422  loss_box_reg: 0.5926  loss_mask: 0.3139  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.1571  time: 0.6611  data_time: 0.2676  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:07:36 d2.utils.events]: \u001b[0m eta: 1:11:30  iter: 1079  total_loss: 1.298  loss_cls: 0.2718  loss_box_reg: 0.5314  loss_mask: 0.29  loss_rpn_cls: 0.06775  loss_rpn_loc: 0.1159  time: 0.6603  data_time: 0.1603  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:07:52 d2.utils.events]: \u001b[0m eta: 1:11:26  iter: 1099  total_loss: 1.473  loss_cls: 0.3205  loss_box_reg: 0.5797  loss_mask: 0.3223  loss_rpn_cls: 0.1173  loss_rpn_loc: 0.1476  time: 0.6623  data_time: 0.2957  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:08:04 d2.utils.events]: \u001b[0m eta: 1:11:13  iter: 1119  total_loss: 1.381  loss_cls: 0.2907  loss_box_reg: 0.5616  loss_mask: 0.2963  loss_rpn_cls: 0.07896  loss_rpn_loc: 0.1254  time: 0.6619  data_time: 0.1732  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:08:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:08:22 d2.utils.events]: \u001b[0m eta: 1:11:04  iter: 1139  total_loss: 1.463  loss_cls: 0.3407  loss_box_reg: 0.5992  loss_mask: 0.3205  loss_rpn_cls: 0.09932  loss_rpn_loc: 0.1327  time: 0.6655  data_time: 0.2953  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:08:35 d2.utils.events]: \u001b[0m eta: 1:10:58  iter: 1159  total_loss: 1.424  loss_cls: 0.3127  loss_box_reg: 0.5861  loss_mask: 0.3122  loss_rpn_cls: 0.09311  loss_rpn_loc: 0.1202  time: 0.6659  data_time: 0.2194  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:08:51 d2.utils.events]: \u001b[0m eta: 1:10:47  iter: 1179  total_loss: 1.446  loss_cls: 0.31  loss_box_reg: 0.5629  loss_mask: 0.3051  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.1377  time: 0.6677  data_time: 0.3024  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:09:03 d2.utils.events]: \u001b[0m eta: 1:10:32  iter: 1199  total_loss: 1.351  loss_cls: 0.2878  loss_box_reg: 0.5721  loss_mask: 0.3092  loss_rpn_cls: 0.09349  loss_rpn_loc: 0.1302  time: 0.6666  data_time: 0.1494  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:09:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:09:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:09:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:09:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:09:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:09:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0840 s/iter. Eval: 0.0633 s/iter. Total: 0.1481 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0772 s/iter. Total: 0.1638 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0859 s/iter. Eval: 0.0765 s/iter. Total: 0.1632 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 21:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0863 s/iter. Eval: 0.0806 s/iter. Total: 0.1677 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:09:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.362283 (0.166916 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:09:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.086163 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:09:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:09:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23500738145446298\n",
      "\u001b[32m[02/05 21:09:36 d2.utils.events]: \u001b[0m eta: 1:10:20  iter: 1219  total_loss: 1.334  loss_cls: 0.2829  loss_box_reg: 0.5789  loss_mask: 0.3133  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.1122  time: 0.6656  data_time: 0.1574  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:09:49 d2.utils.events]: \u001b[0m eta: 1:10:12  iter: 1239  total_loss: 1.303  loss_cls: 0.2804  loss_box_reg: 0.5294  loss_mask: 0.29  loss_rpn_cls: 0.07332  loss_rpn_loc: 0.1172  time: 0.6650  data_time: 0.1726  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:10:01 d2.utils.events]: \u001b[0m eta: 1:10:01  iter: 1259  total_loss: 1.326  loss_cls: 0.2661  loss_box_reg: 0.5416  loss_mask: 0.2972  loss_rpn_cls: 0.07456  loss_rpn_loc: 0.1144  time: 0.6643  data_time: 0.1735  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:10:12 d2.utils.events]: \u001b[0m eta: 1:09:44  iter: 1279  total_loss: 1.296  loss_cls: 0.2875  loss_box_reg: 0.5371  loss_mask: 0.2942  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.1064  time: 0.6625  data_time: 0.0976  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:10:26 d2.utils.events]: \u001b[0m eta: 1:09:35  iter: 1299  total_loss: 1.47  loss_cls: 0.3281  loss_box_reg: 0.5752  loss_mask: 0.31  loss_rpn_cls: 0.09574  loss_rpn_loc: 0.1431  time: 0.6633  data_time: 0.2447  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:10:39 d2.utils.events]: \u001b[0m eta: 1:09:26  iter: 1319  total_loss: 1.467  loss_cls: 0.3168  loss_box_reg: 0.5742  loss_mask: 0.2955  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.1464  time: 0.6627  data_time: 0.1518  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:10:52 d2.utils.events]: \u001b[0m eta: 1:09:16  iter: 1339  total_loss: 1.416  loss_cls: 0.2938  loss_box_reg: 0.564  loss_mask: 0.3026  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1358  time: 0.6626  data_time: 0.1993  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:11:04 d2.utils.events]: \u001b[0m eta: 1:09:07  iter: 1359  total_loss: 1.406  loss_cls: 0.3093  loss_box_reg: 0.5773  loss_mask: 0.3055  loss_rpn_cls: 0.09825  loss_rpn_loc: 0.1359  time: 0.6614  data_time: 0.1260  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:11:19 d2.utils.events]: \u001b[0m eta: 1:09:04  iter: 1379  total_loss: 1.472  loss_cls: 0.3197  loss_box_reg: 0.5473  loss_mask: 0.3053  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.1442  time: 0.6628  data_time: 0.2868  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:11:30 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 1399  total_loss: 1.447  loss_cls: 0.2844  loss_box_reg: 0.5792  loss_mask: 0.3182  loss_rpn_cls: 0.09378  loss_rpn_loc: 0.1326  time: 0.6612  data_time: 0.0972  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:11:42 d2.utils.events]: \u001b[0m eta: 1:08:36  iter: 1419  total_loss: 1.348  loss_cls: 0.2912  loss_box_reg: 0.565  loss_mask: 0.2965  loss_rpn_cls: 0.0795  loss_rpn_loc: 0.1255  time: 0.6605  data_time: 0.1583  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:11:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:11:59 d2.utils.events]: \u001b[0m eta: 1:08:24  iter: 1439  total_loss: 1.377  loss_cls: 0.3068  loss_box_reg: 0.5799  loss_mask: 0.3051  loss_rpn_cls: 0.08628  loss_rpn_loc: 0.1277  time: 0.6633  data_time: 0.3273  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:12:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:12:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:12:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:12:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:12:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:12:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0863 s/iter. Eval: 0.0680 s/iter. Total: 0.1550 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 21:12:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0873 s/iter. Eval: 0.0818 s/iter. Total: 0.1700 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:12:21 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0816 s/iter. Total: 0.1699 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:12:26 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0862 s/iter. Total: 0.1747 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:12:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.075053 (0.173061 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:12:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087538 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:12:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:12:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2244548959534604\n",
      "\u001b[32m[02/05 21:12:35 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 1459  total_loss: 1.352  loss_cls: 0.2899  loss_box_reg: 0.515  loss_mask: 0.2925  loss_rpn_cls: 0.08709  loss_rpn_loc: 0.1215  time: 0.6636  data_time: 0.2184  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:12:42 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:12:50 d2.utils.events]: \u001b[0m eta: 1:08:10  iter: 1479  total_loss: 1.461  loss_cls: 0.3053  loss_box_reg: 0.553  loss_mask: 0.3174  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.1418  time: 0.6649  data_time: 0.2374  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:13:03 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 1499  total_loss: 1.512  loss_cls: 0.3485  loss_box_reg: 0.5776  loss_mask: 0.3102  loss_rpn_cls: 0.1208  loss_rpn_loc: 0.1577  time: 0.6647  data_time: 0.1793  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:13:16 d2.utils.events]: \u001b[0m eta: 1:07:52  iter: 1519  total_loss: 1.326  loss_cls: 0.2668  loss_box_reg: 0.5449  loss_mask: 0.3039  loss_rpn_cls: 0.1101  loss_rpn_loc: 0.1389  time: 0.6647  data_time: 0.2063  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:13:29 d2.utils.events]: \u001b[0m eta: 1:07:41  iter: 1539  total_loss: 1.341  loss_cls: 0.2771  loss_box_reg: 0.5579  loss_mask: 0.3099  loss_rpn_cls: 0.08441  loss_rpn_loc: 0.127  time: 0.6643  data_time: 0.1746  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:13:41 d2.utils.events]: \u001b[0m eta: 1:07:26  iter: 1559  total_loss: 1.158  loss_cls: 0.2239  loss_box_reg: 0.5204  loss_mask: 0.2966  loss_rpn_cls: 0.06343  loss_rpn_loc: 0.1093  time: 0.6636  data_time: 0.1564  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:13:54 d2.utils.events]: \u001b[0m eta: 1:07:16  iter: 1579  total_loss: 1.379  loss_cls: 0.2962  loss_box_reg: 0.5478  loss_mask: 0.2855  loss_rpn_cls: 0.09822  loss_rpn_loc: 0.1311  time: 0.6634  data_time: 0.1764  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:14:10 d2.utils.events]: \u001b[0m eta: 1:07:09  iter: 1599  total_loss: 1.407  loss_cls: 0.2971  loss_box_reg: 0.5858  loss_mask: 0.3086  loss_rpn_cls: 0.09543  loss_rpn_loc: 0.132  time: 0.6652  data_time: 0.3468  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:14:22 d2.utils.events]: \u001b[0m eta: 1:06:56  iter: 1619  total_loss: 1.329  loss_cls: 0.2813  loss_box_reg: 0.5477  loss_mask: 0.3016  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.09206  time: 0.6641  data_time: 0.1322  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:14:35 d2.utils.events]: \u001b[0m eta: 1:06:49  iter: 1639  total_loss: 1.421  loss_cls: 0.2995  loss_box_reg: 0.556  loss_mask: 0.3025  loss_rpn_cls: 0.09138  loss_rpn_loc: 0.1376  time: 0.6642  data_time: 0.2064  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:14:50 d2.utils.events]: \u001b[0m eta: 1:06:39  iter: 1659  total_loss: 1.444  loss_cls: 0.3171  loss_box_reg: 0.5444  loss_mask: 0.31  loss_rpn_cls: 0.08795  loss_rpn_loc: 0.1347  time: 0.6648  data_time: 0.2472  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:15:02 d2.utils.events]: \u001b[0m eta: 1:06:29  iter: 1679  total_loss: 1.269  loss_cls: 0.2835  loss_box_reg: 0.5393  loss_mask: 0.3092  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.106  time: 0.6641  data_time: 0.1574  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:15:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:15:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:15:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:15:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:15:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:15:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:15:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0858 s/iter. Eval: 0.0683 s/iter. Total: 0.1548 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 21:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0007 s/iter. Inference: 0.0872 s/iter. Eval: 0.0822 s/iter. Total: 0.1702 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0007 s/iter. Inference: 0.0874 s/iter. Eval: 0.0818 s/iter. Total: 0.1700 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0865 s/iter. Total: 0.1752 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:15:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.187911 (0.174034 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:15:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087684 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:15:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:15:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22532623495483503\n",
      "\u001b[32m[02/05 21:15:38 d2.utils.events]: \u001b[0m eta: 1:06:22  iter: 1699  total_loss: 1.431  loss_cls: 0.3062  loss_box_reg: 0.5547  loss_mask: 0.3031  loss_rpn_cls: 0.09743  loss_rpn_loc: 0.1316  time: 0.6646  data_time: 0.2395  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:15:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:15:51 d2.utils.events]: \u001b[0m eta: 1:06:06  iter: 1719  total_loss: 1.184  loss_cls: 0.2252  loss_box_reg: 0.5202  loss_mask: 0.3006  loss_rpn_cls: 0.0589  loss_rpn_loc: 0.09366  time: 0.6649  data_time: 0.1768  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:16:06 d2.utils.events]: \u001b[0m eta: 1:06:01  iter: 1739  total_loss: 1.465  loss_cls: 0.3254  loss_box_reg: 0.5666  loss_mask: 0.3156  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.1463  time: 0.6656  data_time: 0.2461  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:16:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:16:23 d2.utils.events]: \u001b[0m eta: 1:05:54  iter: 1759  total_loss: 1.474  loss_cls: 0.337  loss_box_reg: 0.5971  loss_mask: 0.3136  loss_rpn_cls: 0.0924  loss_rpn_loc: 0.1469  time: 0.6678  data_time: 0.2958  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:16:36 d2.utils.events]: \u001b[0m eta: 1:05:44  iter: 1779  total_loss: 1.385  loss_cls: 0.289  loss_box_reg: 0.5459  loss_mask: 0.3004  loss_rpn_cls: 0.08997  loss_rpn_loc: 0.1122  time: 0.6673  data_time: 0.1655  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:16:46 d2.utils.events]: \u001b[0m eta: 1:05:35  iter: 1799  total_loss: 1.364  loss_cls: 0.295  loss_box_reg: 0.5825  loss_mask: 0.3151  loss_rpn_cls: 0.0709  loss_rpn_loc: 0.1125  time: 0.6659  data_time: 0.0867  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:16:58 d2.utils.events]: \u001b[0m eta: 1:05:20  iter: 1819  total_loss: 1.262  loss_cls: 0.2496  loss_box_reg: 0.5311  loss_mask: 0.2957  loss_rpn_cls: 0.06318  loss_rpn_loc: 0.1006  time: 0.6652  data_time: 0.1497  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:17:12 d2.utils.events]: \u001b[0m eta: 1:05:10  iter: 1839  total_loss: 1.314  loss_cls: 0.2639  loss_box_reg: 0.5441  loss_mask: 0.3023  loss_rpn_cls: 0.08659  loss_rpn_loc: 0.1269  time: 0.6655  data_time: 0.2155  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:17:23 d2.utils.events]: \u001b[0m eta: 1:04:58  iter: 1859  total_loss: 1.409  loss_cls: 0.3004  loss_box_reg: 0.5751  loss_mask: 0.3043  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.135  time: 0.6643  data_time: 0.1083  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:17:36 d2.utils.events]: \u001b[0m eta: 1:04:50  iter: 1879  total_loss: 1.416  loss_cls: 0.3089  loss_box_reg: 0.5554  loss_mask: 0.3046  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.1435  time: 0.6641  data_time: 0.1655  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:17:51 d2.utils.events]: \u001b[0m eta: 1:04:39  iter: 1899  total_loss: 1.459  loss_cls: 0.3243  loss_box_reg: 0.5617  loss_mask: 0.3004  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1499  time: 0.6650  data_time: 0.2924  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:18:02 d2.utils.events]: \u001b[0m eta: 1:04:28  iter: 1919  total_loss: 1.273  loss_cls: 0.2602  loss_box_reg: 0.5362  loss_mask: 0.2833  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.1006  time: 0.6636  data_time: 0.0770  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:18:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:18:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:18:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:18:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:18:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:18:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0849 s/iter. Eval: 0.0665 s/iter. Total: 0.1521 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0867 s/iter. Eval: 0.0803 s/iter. Total: 0.1677 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0804 s/iter. Total: 0.1679 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0871 s/iter. Eval: 0.0854 s/iter. Total: 0.1733 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:18:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.936193 (0.171864 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:18:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086990 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:18:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:18:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2407057049838622\n",
      "\u001b[32m[02/05 21:18:35 d2.utils.events]: \u001b[0m eta: 1:04:18  iter: 1939  total_loss: 1.278  loss_cls: 0.2846  loss_box_reg: 0.5479  loss_mask: 0.275  loss_rpn_cls: 0.0692  loss_rpn_loc: 0.1164  time: 0.6629  data_time: 0.1428  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:18:47 d2.utils.events]: \u001b[0m eta: 1:04:11  iter: 1959  total_loss: 1.309  loss_cls: 0.2788  loss_box_reg: 0.5252  loss_mask: 0.2808  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.1195  time: 0.6623  data_time: 0.1460  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:19:00 d2.utils.events]: \u001b[0m eta: 1:04:02  iter: 1979  total_loss: 1.264  loss_cls: 0.2884  loss_box_reg: 0.5219  loss_mask: 0.2934  loss_rpn_cls: 0.07865  loss_rpn_loc: 0.1141  time: 0.6621  data_time: 0.1740  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:19:10 d2.utils.events]: \u001b[0m eta: 1:03:44  iter: 1999  total_loss: 1.247  loss_cls: 0.2602  loss_box_reg: 0.5193  loss_mask: 0.2937  loss_rpn_cls: 0.05385  loss_rpn_loc: 0.1091  time: 0.6605  data_time: 0.0654  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:19:23 d2.utils.events]: \u001b[0m eta: 1:03:37  iter: 2019  total_loss: 1.387  loss_cls: 0.278  loss_box_reg: 0.5378  loss_mask: 0.3153  loss_rpn_cls: 0.08851  loss_rpn_loc: 0.1244  time: 0.6605  data_time: 0.1951  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:19:37 d2.utils.events]: \u001b[0m eta: 1:03:30  iter: 2039  total_loss: 1.42  loss_cls: 0.2944  loss_box_reg: 0.5668  loss_mask: 0.3105  loss_rpn_cls: 0.08266  loss_rpn_loc: 0.1324  time: 0.6604  data_time: 0.1947  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:19:48 d2.utils.events]: \u001b[0m eta: 1:03:19  iter: 2059  total_loss: 1.372  loss_cls: 0.2989  loss_box_reg: 0.5487  loss_mask: 0.3006  loss_rpn_cls: 0.08388  loss_rpn_loc: 0.1227  time: 0.6596  data_time: 0.1208  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:20:01 d2.utils.events]: \u001b[0m eta: 1:03:14  iter: 2079  total_loss: 1.424  loss_cls: 0.323  loss_box_reg: 0.5478  loss_mask: 0.3109  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.1453  time: 0.6594  data_time: 0.1758  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:20:17 d2.utils.events]: \u001b[0m eta: 1:03:01  iter: 2099  total_loss: 1.471  loss_cls: 0.3255  loss_box_reg: 0.5612  loss_mask: 0.3257  loss_rpn_cls: 0.1212  loss_rpn_loc: 0.1593  time: 0.6609  data_time: 0.3565  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:20:30 d2.utils.events]: \u001b[0m eta: 1:02:49  iter: 2119  total_loss: 1.256  loss_cls: 0.2731  loss_box_reg: 0.5226  loss_mask: 0.2973  loss_rpn_cls: 0.07133  loss_rpn_loc: 0.09375  time: 0.6608  data_time: 0.1871  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:20:44 d2.utils.events]: \u001b[0m eta: 1:02:40  iter: 2139  total_loss: 1.518  loss_cls: 0.3111  loss_box_reg: 0.5726  loss_mask: 0.3199  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.1376  time: 0.6611  data_time: 0.2280  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:20:55 d2.utils.events]: \u001b[0m eta: 1:02:25  iter: 2159  total_loss: 1.349  loss_cls: 0.3115  loss_box_reg: 0.5506  loss_mask: 0.3093  loss_rpn_cls: 0.09468  loss_rpn_loc: 0.1209  time: 0.6602  data_time: 0.1012  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:21:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:21:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:21:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:21:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:21:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:21:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0849 s/iter. Eval: 0.0664 s/iter. Total: 0.1519 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0866 s/iter. Eval: 0.0809 s/iter. Total: 0.1684 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0809 s/iter. Total: 0.1684 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0871 s/iter. Eval: 0.0864 s/iter. Total: 0.1743 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:21:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.011987 (0.172517 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:21:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086881 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:21:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23868758625975445\n",
      "\u001b[32m[02/05 21:21:30 d2.utils.events]: \u001b[0m eta: 1:02:13  iter: 2179  total_loss: 1.333  loss_cls: 0.3034  loss_box_reg: 0.5306  loss_mask: 0.3102  loss_rpn_cls: 0.08268  loss_rpn_loc: 0.1355  time: 0.6600  data_time: 0.1713  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:21:45 d2.utils.events]: \u001b[0m eta: 1:02:07  iter: 2199  total_loss: 1.511  loss_cls: 0.3383  loss_box_reg: 0.5773  loss_mask: 0.3087  loss_rpn_cls: 0.09277  loss_rpn_loc: 0.1606  time: 0.6608  data_time: 0.2750  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:21:57 d2.utils.events]: \u001b[0m eta: 1:01:59  iter: 2219  total_loss: 1.299  loss_cls: 0.2932  loss_box_reg: 0.5174  loss_mask: 0.304  loss_rpn_cls: 0.09406  loss_rpn_loc: 0.1225  time: 0.6605  data_time: 0.1819  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:22:08 d2.utils.events]: \u001b[0m eta: 1:01:46  iter: 2239  total_loss: 1.262  loss_cls: 0.2443  loss_box_reg: 0.5372  loss_mask: 0.3236  loss_rpn_cls: 0.0642  loss_rpn_loc: 0.09721  time: 0.6593  data_time: 0.0792  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:22:20 d2.utils.events]: \u001b[0m eta: 1:01:39  iter: 2259  total_loss: 1.368  loss_cls: 0.2889  loss_box_reg: 0.5227  loss_mask: 0.29  loss_rpn_cls: 0.08918  loss_rpn_loc: 0.1396  time: 0.6588  data_time: 0.1478  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:22:32 d2.utils.events]: \u001b[0m eta: 1:01:28  iter: 2279  total_loss: 1.251  loss_cls: 0.2783  loss_box_reg: 0.523  loss_mask: 0.2922  loss_rpn_cls: 0.07913  loss_rpn_loc: 0.1118  time: 0.6582  data_time: 0.1401  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:22:44 d2.utils.events]: \u001b[0m eta: 1:01:22  iter: 2299  total_loss: 1.404  loss_cls: 0.3171  loss_box_reg: 0.5529  loss_mask: 0.302  loss_rpn_cls: 0.08776  loss_rpn_loc: 0.1302  time: 0.6578  data_time: 0.1476  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:22:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:22:59 d2.utils.events]: \u001b[0m eta: 1:01:06  iter: 2319  total_loss: 1.277  loss_cls: 0.241  loss_box_reg: 0.5397  loss_mask: 0.3001  loss_rpn_cls: 0.06245  loss_rpn_loc: 0.1019  time: 0.6587  data_time: 0.2136  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:23:10 d2.utils.events]: \u001b[0m eta: 1:01:00  iter: 2339  total_loss: 1.368  loss_cls: 0.2826  loss_box_reg: 0.5434  loss_mask: 0.2936  loss_rpn_cls: 0.07982  loss_rpn_loc: 0.1302  time: 0.6577  data_time: 0.1007  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:23:22 d2.utils.events]: \u001b[0m eta: 1:00:45  iter: 2359  total_loss: 1.248  loss_cls: 0.2738  loss_box_reg: 0.5324  loss_mask: 0.2723  loss_rpn_cls: 0.05002  loss_rpn_loc: 0.09728  time: 0.6571  data_time: 0.1304  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:23:33 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 2379  total_loss: 1.336  loss_cls: 0.263  loss_box_reg: 0.5102  loss_mask: 0.295  loss_rpn_cls: 0.06984  loss_rpn_loc: 0.1169  time: 0.6561  data_time: 0.1130  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:23:50 d2.utils.events]: \u001b[0m eta: 1:00:24  iter: 2399  total_loss: 1.49  loss_cls: 0.3039  loss_box_reg: 0.5652  loss_mask: 0.3104  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.1656  time: 0.6579  data_time: 0.3627  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:24:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:24:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:24:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:24:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:24:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:24:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0858 s/iter. Eval: 0.0693 s/iter. Total: 0.1558 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 21:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0823 s/iter. Total: 0.1701 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0814 s/iter. Total: 0.1692 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0863 s/iter. Total: 0.1744 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:24:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.027134 (0.172648 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:24:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087129 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:24:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:24:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23589731937317426\n",
      "\u001b[32m[02/05 21:24:28 d2.utils.events]: \u001b[0m eta: 1:00:25  iter: 2419  total_loss: 1.356  loss_cls: 0.2859  loss_box_reg: 0.5425  loss_mask: 0.2924  loss_rpn_cls: 0.09008  loss_rpn_loc: 0.135  time: 0.6592  data_time: 0.3548  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:24:42 d2.utils.events]: \u001b[0m eta: 1:00:18  iter: 2439  total_loss: 1.364  loss_cls: 0.3035  loss_box_reg: 0.5646  loss_mask: 0.3043  loss_rpn_cls: 0.08899  loss_rpn_loc: 0.1449  time: 0.6595  data_time: 0.2106  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:24:55 d2.utils.events]: \u001b[0m eta: 1:00:08  iter: 2459  total_loss: 1.388  loss_cls: 0.292  loss_box_reg: 0.567  loss_mask: 0.3071  loss_rpn_cls: 0.0802  loss_rpn_loc: 0.1414  time: 0.6593  data_time: 0.1727  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:25:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:25:10 d2.utils.events]: \u001b[0m eta: 0:59:56  iter: 2479  total_loss: 1.369  loss_cls: 0.2774  loss_box_reg: 0.5291  loss_mask: 0.2887  loss_rpn_cls: 0.08922  loss_rpn_loc: 0.1413  time: 0.6601  data_time: 0.2200  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:25:23 d2.utils.events]: \u001b[0m eta: 0:59:36  iter: 2499  total_loss: 1.319  loss_cls: 0.2876  loss_box_reg: 0.5235  loss_mask: 0.2957  loss_rpn_cls: 0.07967  loss_rpn_loc: 0.1237  time: 0.6600  data_time: 0.1756  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:25:36 d2.utils.events]: \u001b[0m eta: 0:59:30  iter: 2519  total_loss: 1.398  loss_cls: 0.3091  loss_box_reg: 0.5308  loss_mask: 0.3097  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.1381  time: 0.6601  data_time: 0.2104  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:25:49 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 2539  total_loss: 1.284  loss_cls: 0.2692  loss_box_reg: 0.5553  loss_mask: 0.3019  loss_rpn_cls: 0.05833  loss_rpn_loc: 0.1204  time: 0.6599  data_time: 0.1919  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:26:06 d2.utils.events]: \u001b[0m eta: 0:59:18  iter: 2559  total_loss: 1.516  loss_cls: 0.3212  loss_box_reg: 0.5655  loss_mask: 0.3171  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.1595  time: 0.6613  data_time: 0.3546  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:26:17 d2.utils.events]: \u001b[0m eta: 0:58:59  iter: 2579  total_loss: 1.344  loss_cls: 0.288  loss_box_reg: 0.5515  loss_mask: 0.2973  loss_rpn_cls: 0.08442  loss_rpn_loc: 0.1318  time: 0.6605  data_time: 0.1140  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:26:30 d2.utils.events]: \u001b[0m eta: 0:58:45  iter: 2599  total_loss: 1.352  loss_cls: 0.2596  loss_box_reg: 0.5357  loss_mask: 0.3001  loss_rpn_cls: 0.07989  loss_rpn_loc: 0.1159  time: 0.6603  data_time: 0.1717  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:26:41 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 2619  total_loss: 1.292  loss_cls: 0.2676  loss_box_reg: 0.5405  loss_mask: 0.3165  loss_rpn_cls: 0.05519  loss_rpn_loc: 0.1018  time: 0.6597  data_time: 0.1477  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:26:53 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 2639  total_loss: 1.328  loss_cls: 0.2782  loss_box_reg: 0.5407  loss_mask: 0.2985  loss_rpn_cls: 0.07768  loss_rpn_loc: 0.1221  time: 0.6592  data_time: 0.1339  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:27:06 d2.utils.events]: \u001b[0m eta: 0:58:17  iter: 2659  total_loss: 1.227  loss_cls: 0.2633  loss_box_reg: 0.5271  loss_mask: 0.3026  loss_rpn_cls: 0.06221  loss_rpn_loc: 0.1004  time: 0.6592  data_time: 0.2042  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:27:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:27:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:27:09 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:27:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:27:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:27:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0852 s/iter. Eval: 0.0662 s/iter. Total: 0.1520 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0867 s/iter. Eval: 0.0808 s/iter. Total: 0.1682 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0007 s/iter. Inference: 0.0867 s/iter. Eval: 0.0808 s/iter. Total: 0.1682 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0870 s/iter. Eval: 0.0857 s/iter. Total: 0.1735 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:27:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.922710 (0.171747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:27:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086839 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:27:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:27:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24050416022490062\n",
      "\u001b[32m[02/05 21:27:42 d2.utils.events]: \u001b[0m eta: 0:58:10  iter: 2679  total_loss: 1.425  loss_cls: 0.3183  loss_box_reg: 0.5619  loss_mask: 0.3189  loss_rpn_cls: 0.08946  loss_rpn_loc: 0.1344  time: 0.6595  data_time: 0.2404  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:27:56 d2.utils.events]: \u001b[0m eta: 0:58:01  iter: 2699  total_loss: 1.412  loss_cls: 0.2985  loss_box_reg: 0.559  loss_mask: 0.3059  loss_rpn_cls: 0.09711  loss_rpn_loc: 0.1369  time: 0.6598  data_time: 0.2351  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:28:11 d2.utils.events]: \u001b[0m eta: 0:58:02  iter: 2719  total_loss: 1.413  loss_cls: 0.3193  loss_box_reg: 0.5571  loss_mask: 0.3092  loss_rpn_cls: 0.08842  loss_rpn_loc: 0.1351  time: 0.6605  data_time: 0.2804  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:28:25 d2.utils.events]: \u001b[0m eta: 0:57:47  iter: 2739  total_loss: 1.443  loss_cls: 0.3217  loss_box_reg: 0.5676  loss_mask: 0.3147  loss_rpn_cls: 0.09371  loss_rpn_loc: 0.1428  time: 0.6608  data_time: 0.2338  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:28:37 d2.utils.events]: \u001b[0m eta: 0:57:30  iter: 2759  total_loss: 1.297  loss_cls: 0.2481  loss_box_reg: 0.5279  loss_mask: 0.291  loss_rpn_cls: 0.06203  loss_rpn_loc: 0.1143  time: 0.6603  data_time: 0.1400  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:28:47 d2.utils.events]: \u001b[0m eta: 0:57:17  iter: 2779  total_loss: 1.121  loss_cls: 0.2137  loss_box_reg: 0.508  loss_mask: 0.287  loss_rpn_cls: 0.04199  loss_rpn_loc: 0.08562  time: 0.6592  data_time: 0.0707  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:29:03 d2.utils.events]: \u001b[0m eta: 0:57:09  iter: 2799  total_loss: 1.337  loss_cls: 0.2986  loss_box_reg: 0.5261  loss_mask: 0.2855  loss_rpn_cls: 0.0976  loss_rpn_loc: 0.1217  time: 0.6601  data_time: 0.3054  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:29:14 d2.utils.events]: \u001b[0m eta: 0:56:59  iter: 2819  total_loss: 1.447  loss_cls: 0.3075  loss_box_reg: 0.5869  loss_mask: 0.3147  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1277  time: 0.6593  data_time: 0.0951  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:29:28 d2.utils.events]: \u001b[0m eta: 0:56:49  iter: 2839  total_loss: 1.288  loss_cls: 0.2711  loss_box_reg: 0.5308  loss_mask: 0.2989  loss_rpn_cls: 0.07224  loss_rpn_loc: 0.1245  time: 0.6597  data_time: 0.2522  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:29:40 d2.utils.events]: \u001b[0m eta: 0:56:40  iter: 2859  total_loss: 1.33  loss_cls: 0.2923  loss_box_reg: 0.5473  loss_mask: 0.302  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.1334  time: 0.6592  data_time: 0.1349  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:29:52 d2.utils.events]: \u001b[0m eta: 0:56:29  iter: 2879  total_loss: 1.261  loss_cls: 0.2679  loss_box_reg: 0.5073  loss_mask: 0.2905  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.1132  time: 0.6588  data_time: 0.1514  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:30:06 d2.utils.events]: \u001b[0m eta: 0:56:19  iter: 2899  total_loss: 1.321  loss_cls: 0.2782  loss_box_reg: 0.523  loss_mask: 0.2916  loss_rpn_cls: 0.09916  loss_rpn_loc: 0.1236  time: 0.6590  data_time: 0.2294  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:30:09 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:30:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:30:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:30:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:30:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:30:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0849 s/iter. Eval: 0.0658 s/iter. Total: 0.1514 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0802 s/iter. Total: 0.1675 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0805 s/iter. Total: 0.1678 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0868 s/iter. Eval: 0.0847 s/iter. Total: 0.1723 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:30:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.850087 (0.171121 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:30:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086726 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:30:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:30:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2455499804925927\n",
      "\u001b[32m[02/05 21:30:43 d2.utils.events]: \u001b[0m eta: 0:56:11  iter: 2919  total_loss: 1.332  loss_cls: 0.274  loss_box_reg: 0.5305  loss_mask: 0.303  loss_rpn_cls: 0.09846  loss_rpn_loc: 0.1236  time: 0.6600  data_time: 0.3299  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:30:56 d2.utils.events]: \u001b[0m eta: 0:56:02  iter: 2939  total_loss: 1.323  loss_cls: 0.2708  loss_box_reg: 0.5404  loss_mask: 0.2965  loss_rpn_cls: 0.08327  loss_rpn_loc: 0.1168  time: 0.6597  data_time: 0.1655  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:31:09 d2.utils.events]: \u001b[0m eta: 0:55:53  iter: 2959  total_loss: 1.361  loss_cls: 0.2997  loss_box_reg: 0.5378  loss_mask: 0.3033  loss_rpn_cls: 0.09768  loss_rpn_loc: 0.1234  time: 0.6598  data_time: 0.2106  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:31:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:31:26 d2.utils.events]: \u001b[0m eta: 0:55:43  iter: 2979  total_loss: 1.202  loss_cls: 0.246  loss_box_reg: 0.4828  loss_mask: 0.2732  loss_rpn_cls: 0.06021  loss_rpn_loc: 0.1067  time: 0.6609  data_time: 0.2887  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:31:36 d2.utils.events]: \u001b[0m eta: 0:55:33  iter: 2999  total_loss: 1.129  loss_cls: 0.2166  loss_box_reg: 0.494  loss_mask: 0.2859  loss_rpn_cls: 0.05101  loss_rpn_loc: 0.1068  time: 0.6600  data_time: 0.0868  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:31:49 d2.utils.events]: \u001b[0m eta: 0:55:24  iter: 3019  total_loss: 1.367  loss_cls: 0.2932  loss_box_reg: 0.5461  loss_mask: 0.311  loss_rpn_cls: 0.08377  loss_rpn_loc: 0.1387  time: 0.6600  data_time: 0.1855  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:32:04 d2.utils.events]: \u001b[0m eta: 0:55:16  iter: 3039  total_loss: 1.388  loss_cls: 0.2874  loss_box_reg: 0.5412  loss_mask: 0.3036  loss_rpn_cls: 0.09693  loss_rpn_loc: 0.1241  time: 0.6604  data_time: 0.2540  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:32:16 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 3059  total_loss: 1.242  loss_cls: 0.2661  loss_box_reg: 0.511  loss_mask: 0.288  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.117  time: 0.6600  data_time: 0.1489  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:32:31 d2.utils.events]: \u001b[0m eta: 0:54:57  iter: 3079  total_loss: 1.471  loss_cls: 0.3475  loss_box_reg: 0.5591  loss_mask: 0.3029  loss_rpn_cls: 0.1132  loss_rpn_loc: 0.1413  time: 0.6607  data_time: 0.2784  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:32:45 d2.utils.events]: \u001b[0m eta: 0:54:49  iter: 3099  total_loss: 1.295  loss_cls: 0.2737  loss_box_reg: 0.5195  loss_mask: 0.2957  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.137  time: 0.6608  data_time: 0.2182  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:32:56 d2.utils.events]: \u001b[0m eta: 0:54:41  iter: 3119  total_loss: 1.301  loss_cls: 0.2796  loss_box_reg: 0.5188  loss_mask: 0.313  loss_rpn_cls: 0.07933  loss_rpn_loc: 0.1249  time: 0.6602  data_time: 0.1259  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:33:10 d2.utils.events]: \u001b[0m eta: 0:54:31  iter: 3139  total_loss: 1.388  loss_cls: 0.2731  loss_box_reg: 0.5753  loss_mask: 0.3241  loss_rpn_cls: 0.0952  loss_rpn_loc: 0.126  time: 0.6604  data_time: 0.2370  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:33:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:33:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:33:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:33:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:33:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:33:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0867 s/iter. Eval: 0.0706 s/iter. Total: 0.1580 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 21:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0832 s/iter. Total: 0.1714 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:33:26 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0834 s/iter. Total: 0.1720 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0880 s/iter. Total: 0.1769 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:33:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.399636 (0.175859 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:33:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087882 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:33:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:33:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23790858972210094\n",
      "\u001b[32m[02/05 21:33:45 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 3159  total_loss: 1.372  loss_cls: 0.284  loss_box_reg: 0.5403  loss_mask: 0.3058  loss_rpn_cls: 0.09103  loss_rpn_loc: 0.1353  time: 0.6602  data_time: 0.1580  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:34:00 d2.utils.events]: \u001b[0m eta: 0:54:21  iter: 3179  total_loss: 1.592  loss_cls: 0.3889  loss_box_reg: 0.5676  loss_mask: 0.3182  loss_rpn_cls: 0.09627  loss_rpn_loc: 0.17  time: 0.6610  data_time: 0.3060  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:34:11 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:34:16 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 3199  total_loss: 1.465  loss_cls: 0.3236  loss_box_reg: 0.5648  loss_mask: 0.3077  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.1455  time: 0.6618  data_time: 0.2548  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:34:31 d2.utils.events]: \u001b[0m eta: 0:54:12  iter: 3219  total_loss: 1.321  loss_cls: 0.2761  loss_box_reg: 0.5398  loss_mask: 0.2968  loss_rpn_cls: 0.08585  loss_rpn_loc: 0.1401  time: 0.6622  data_time: 0.2564  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:34:42 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 3239  total_loss: 1.268  loss_cls: 0.257  loss_box_reg: 0.5134  loss_mask: 0.2894  loss_rpn_cls: 0.08013  loss_rpn_loc: 0.1272  time: 0.6616  data_time: 0.1191  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:34:54 d2.utils.events]: \u001b[0m eta: 0:53:45  iter: 3259  total_loss: 1.222  loss_cls: 0.2294  loss_box_reg: 0.4953  loss_mask: 0.3018  loss_rpn_cls: 0.05611  loss_rpn_loc: 0.1107  time: 0.6612  data_time: 0.1530  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:35:09 d2.utils.events]: \u001b[0m eta: 0:53:35  iter: 3279  total_loss: 1.286  loss_cls: 0.2752  loss_box_reg: 0.5287  loss_mask: 0.2925  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.1294  time: 0.6618  data_time: 0.3045  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:35:23 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 3299  total_loss: 1.301  loss_cls: 0.2695  loss_box_reg: 0.5165  loss_mask: 0.2991  loss_rpn_cls: 0.07425  loss_rpn_loc: 0.1275  time: 0.6619  data_time: 0.2306  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:35:37 d2.utils.events]: \u001b[0m eta: 0:53:17  iter: 3319  total_loss: 1.446  loss_cls: 0.318  loss_box_reg: 0.5562  loss_mask: 0.3253  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.1392  time: 0.6623  data_time: 0.2455  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:35:49 d2.utils.events]: \u001b[0m eta: 0:53:14  iter: 3339  total_loss: 1.314  loss_cls: 0.2808  loss_box_reg: 0.5343  loss_mask: 0.2887  loss_rpn_cls: 0.08102  loss_rpn_loc: 0.129  time: 0.6618  data_time: 0.1424  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:35:59 d2.utils.events]: \u001b[0m eta: 0:52:57  iter: 3359  total_loss: 1.206  loss_cls: 0.2578  loss_box_reg: 0.4846  loss_mask: 0.2784  loss_rpn_cls: 0.06048  loss_rpn_loc: 0.08893  time: 0.6610  data_time: 0.0867  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:36:12 d2.utils.events]: \u001b[0m eta: 0:52:55  iter: 3379  total_loss: 1.184  loss_cls: 0.2413  loss_box_reg: 0.5178  loss_mask: 0.2838  loss_rpn_cls: 0.04661  loss_rpn_loc: 0.09415  time: 0.6608  data_time: 0.1593  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:36:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:36:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:36:17 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:36:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:36:17 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:36:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0850 s/iter. Eval: 0.0666 s/iter. Total: 0.1523 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0866 s/iter. Eval: 0.0810 s/iter. Total: 0.1684 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0808 s/iter. Total: 0.1681 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0848 s/iter. Total: 0.1725 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:36:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.910882 (0.171646 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:36:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086768 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:36:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:36:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24212717053242308\n",
      "\u001b[32m[02/05 21:36:46 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 3399  total_loss: 1.408  loss_cls: 0.3069  loss_box_reg: 0.5542  loss_mask: 0.3077  loss_rpn_cls: 0.09238  loss_rpn_loc: 0.1374  time: 0.6605  data_time: 0.1615  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:36:58 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 3419  total_loss: 1.289  loss_cls: 0.2601  loss_box_reg: 0.5101  loss_mask: 0.2981  loss_rpn_cls: 0.06639  loss_rpn_loc: 0.1262  time: 0.6604  data_time: 0.1828  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:37:13 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 3439  total_loss: 1.38  loss_cls: 0.3107  loss_box_reg: 0.5218  loss_mask: 0.3018  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.137  time: 0.6607  data_time: 0.2558  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:37:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:37:29 d2.utils.events]: \u001b[0m eta: 0:51:59  iter: 3459  total_loss: 1.324  loss_cls: 0.3046  loss_box_reg: 0.5521  loss_mask: 0.3135  loss_rpn_cls: 0.08586  loss_rpn_loc: 0.1341  time: 0.6617  data_time: 0.2732  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:37:42 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 3479  total_loss: 1.326  loss_cls: 0.2913  loss_box_reg: 0.5465  loss_mask: 0.3094  loss_rpn_cls: 0.09168  loss_rpn_loc: 0.1273  time: 0.6615  data_time: 0.1652  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:37:56 d2.utils.events]: \u001b[0m eta: 0:51:46  iter: 3499  total_loss: 1.301  loss_cls: 0.2735  loss_box_reg: 0.512  loss_mask: 0.2974  loss_rpn_cls: 0.06131  loss_rpn_loc: 0.13  time: 0.6616  data_time: 0.2230  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:38:09 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 3519  total_loss: 1.31  loss_cls: 0.2569  loss_box_reg: 0.5394  loss_mask: 0.2997  loss_rpn_cls: 0.05259  loss_rpn_loc: 0.1087  time: 0.6616  data_time: 0.2001  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:38:22 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 3539  total_loss: 1.256  loss_cls: 0.2529  loss_box_reg: 0.5334  loss_mask: 0.285  loss_rpn_cls: 0.07461  loss_rpn_loc: 0.1118  time: 0.6615  data_time: 0.1858  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:38:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:38:37 d2.utils.events]: \u001b[0m eta: 0:51:12  iter: 3559  total_loss: 1.246  loss_cls: 0.2536  loss_box_reg: 0.5076  loss_mask: 0.2917  loss_rpn_cls: 0.05198  loss_rpn_loc: 0.1092  time: 0.6621  data_time: 0.2331  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:38:50 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 3579  total_loss: 1.404  loss_cls: 0.3223  loss_box_reg: 0.5269  loss_mask: 0.3096  loss_rpn_cls: 0.09256  loss_rpn_loc: 0.1224  time: 0.6621  data_time: 0.1968  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:39:04 d2.utils.events]: \u001b[0m eta: 0:51:06  iter: 3599  total_loss: 1.398  loss_cls: 0.2735  loss_box_reg: 0.5781  loss_mask: 0.3083  loss_rpn_cls: 0.09708  loss_rpn_loc: 0.1251  time: 0.6622  data_time: 0.2206  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:39:16 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 3619  total_loss: 1.236  loss_cls: 0.2555  loss_box_reg: 0.5217  loss_mask: 0.284  loss_rpn_cls: 0.06649  loss_rpn_loc: 0.105  time: 0.6620  data_time: 0.1620  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:39:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:39:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:39:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:39:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:39:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:39:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:39:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0847 s/iter. Eval: 0.0666 s/iter. Total: 0.1520 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:39:30 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0809 s/iter. Total: 0.1682 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:39:35 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0862 s/iter. Eval: 0.0804 s/iter. Total: 0.1675 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0867 s/iter. Eval: 0.0855 s/iter. Total: 0.1730 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:39:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.889016 (0.171457 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:39:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.086456 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:39:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:39:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24581984183107858\n",
      "\u001b[32m[02/05 21:39:53 d2.utils.events]: \u001b[0m eta: 0:50:51  iter: 3639  total_loss: 1.245  loss_cls: 0.2627  loss_box_reg: 0.5411  loss_mask: 0.3035  loss_rpn_cls: 0.06997  loss_rpn_loc: 0.1167  time: 0.6625  data_time: 0.2799  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:40:05 d2.utils.events]: \u001b[0m eta: 0:50:42  iter: 3659  total_loss: 1.334  loss_cls: 0.2811  loss_box_reg: 0.5401  loss_mask: 0.2948  loss_rpn_cls: 0.0692  loss_rpn_loc: 0.1237  time: 0.6622  data_time: 0.1635  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:40:18 d2.utils.events]: \u001b[0m eta: 0:50:32  iter: 3679  total_loss: 1.425  loss_cls: 0.3079  loss_box_reg: 0.5648  loss_mask: 0.2998  loss_rpn_cls: 0.09045  loss_rpn_loc: 0.1407  time: 0.6622  data_time: 0.1945  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:40:33 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 3699  total_loss: 1.387  loss_cls: 0.2805  loss_box_reg: 0.5414  loss_mask: 0.3061  loss_rpn_cls: 0.09021  loss_rpn_loc: 0.1294  time: 0.6626  data_time: 0.2765  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:40:48 d2.utils.events]: \u001b[0m eta: 0:50:13  iter: 3719  total_loss: 1.347  loss_cls: 0.2937  loss_box_reg: 0.4996  loss_mask: 0.3062  loss_rpn_cls: 0.09272  loss_rpn_loc: 0.1291  time: 0.6629  data_time: 0.2468  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:41:00 d2.utils.events]: \u001b[0m eta: 0:49:55  iter: 3739  total_loss: 1.152  loss_cls: 0.2063  loss_box_reg: 0.5012  loss_mask: 0.2868  loss_rpn_cls: 0.04945  loss_rpn_loc: 0.0956  time: 0.6627  data_time: 0.1918  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:41:14 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 3759  total_loss: 1.217  loss_cls: 0.2681  loss_box_reg: 0.5301  loss_mask: 0.2905  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.1102  time: 0.6628  data_time: 0.2475  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:41:24 d2.utils.events]: \u001b[0m eta: 0:49:41  iter: 3779  total_loss: 1.189  loss_cls: 0.2148  loss_box_reg: 0.5085  loss_mask: 0.3037  loss_rpn_cls: 0.04596  loss_rpn_loc: 0.1071  time: 0.6619  data_time: 0.0562  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:41:38 d2.utils.events]: \u001b[0m eta: 0:49:27  iter: 3799  total_loss: 1.319  loss_cls: 0.2935  loss_box_reg: 0.5124  loss_mask: 0.2972  loss_rpn_cls: 0.09938  loss_rpn_loc: 0.1326  time: 0.6621  data_time: 0.2313  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:41:50 d2.utils.events]: \u001b[0m eta: 0:49:24  iter: 3819  total_loss: 1.315  loss_cls: 0.2761  loss_box_reg: 0.5319  loss_mask: 0.2889  loss_rpn_cls: 0.0874  loss_rpn_loc: 0.1224  time: 0.6619  data_time: 0.1728  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:42:02 d2.utils.events]: \u001b[0m eta: 0:49:11  iter: 3839  total_loss: 1.332  loss_cls: 0.2785  loss_box_reg: 0.5656  loss_mask: 0.2986  loss_rpn_cls: 0.08694  loss_rpn_loc: 0.1283  time: 0.6617  data_time: 0.1597  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:42:19 d2.utils.events]: \u001b[0m eta: 0:49:06  iter: 3859  total_loss: 1.34  loss_cls: 0.3033  loss_box_reg: 0.5402  loss_mask: 0.3061  loss_rpn_cls: 0.08856  loss_rpn_loc: 0.1161  time: 0.6627  data_time: 0.3837  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:42:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:42:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:42:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:42:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:42:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:42:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0866 s/iter. Eval: 0.0700 s/iter. Total: 0.1572 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 21:42:35 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0007 s/iter. Inference: 0.0873 s/iter. Eval: 0.0832 s/iter. Total: 0.1713 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0828 s/iter. Total: 0.1711 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0872 s/iter. Total: 0.1759 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:42:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.297713 (0.174980 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:42:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087701 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:42:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:42:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2340868440331296\n",
      "\u001b[32m[02/05 21:42:54 d2.utils.events]: \u001b[0m eta: 0:48:52  iter: 3879  total_loss: 1.356  loss_cls: 0.285  loss_box_reg: 0.5253  loss_mask: 0.301  loss_rpn_cls: 0.08227  loss_rpn_loc: 0.1276  time: 0.6624  data_time: 0.1597  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:43:06 d2.utils.events]: \u001b[0m eta: 0:48:37  iter: 3899  total_loss: 1.236  loss_cls: 0.245  loss_box_reg: 0.5169  loss_mask: 0.2916  loss_rpn_cls: 0.05683  loss_rpn_loc: 0.09668  time: 0.6623  data_time: 0.1890  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:43:22 d2.utils.events]: \u001b[0m eta: 0:48:28  iter: 3919  total_loss: 1.524  loss_cls: 0.3386  loss_box_reg: 0.5893  loss_mask: 0.3378  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.1509  time: 0.6630  data_time: 0.3279  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:43:36 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 3939  total_loss: 1.309  loss_cls: 0.2626  loss_box_reg: 0.5261  loss_mask: 0.3027  loss_rpn_cls: 0.0694  loss_rpn_loc: 0.1143  time: 0.6629  data_time: 0.1961  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:43:48 d2.utils.events]: \u001b[0m eta: 0:48:06  iter: 3959  total_loss: 1.322  loss_cls: 0.2753  loss_box_reg: 0.5368  loss_mask: 0.305  loss_rpn_cls: 0.08031  loss_rpn_loc: 0.1188  time: 0.6627  data_time: 0.1596  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:44:00 d2.utils.events]: \u001b[0m eta: 0:47:56  iter: 3979  total_loss: 1.285  loss_cls: 0.2679  loss_box_reg: 0.5341  loss_mask: 0.3066  loss_rpn_cls: 0.07395  loss_rpn_loc: 0.1187  time: 0.6625  data_time: 0.1700  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:44:14 d2.utils.events]: \u001b[0m eta: 0:47:54  iter: 3999  total_loss: 1.419  loss_cls: 0.3076  loss_box_reg: 0.5521  loss_mask: 0.2961  loss_rpn_cls: 0.105  loss_rpn_loc: 0.1371  time: 0.6625  data_time: 0.1910  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:44:27 d2.utils.events]: \u001b[0m eta: 0:47:45  iter: 4019  total_loss: 1.281  loss_cls: 0.2861  loss_box_reg: 0.5135  loss_mask: 0.2803  loss_rpn_cls: 0.0769  loss_rpn_loc: 0.1191  time: 0.6626  data_time: 0.2291  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:44:40 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 4039  total_loss: 1.321  loss_cls: 0.2902  loss_box_reg: 0.5251  loss_mask: 0.2996  loss_rpn_cls: 0.09819  loss_rpn_loc: 0.128  time: 0.6625  data_time: 0.1807  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:44:54 d2.utils.events]: \u001b[0m eta: 0:47:28  iter: 4059  total_loss: 1.393  loss_cls: 0.2923  loss_box_reg: 0.5216  loss_mask: 0.3044  loss_rpn_cls: 0.09823  loss_rpn_loc: 0.1323  time: 0.6627  data_time: 0.2410  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:45:04 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 4079  total_loss: 1.218  loss_cls: 0.2748  loss_box_reg: 0.5046  loss_mask: 0.2788  loss_rpn_cls: 0.05619  loss_rpn_loc: 0.1136  time: 0.6618  data_time: 0.0317  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:45:19 d2.utils.events]: \u001b[0m eta: 0:47:00  iter: 4099  total_loss: 1.359  loss_cls: 0.2974  loss_box_reg: 0.5093  loss_mask: 0.2936  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1479  time: 0.6624  data_time: 0.3037  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:45:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:45:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:45:29 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:45:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:45:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:45:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0843 s/iter. Eval: 0.0645 s/iter. Total: 0.1494 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0858 s/iter. Eval: 0.0798 s/iter. Total: 0.1664 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0856 s/iter. Eval: 0.0781 s/iter. Total: 0.1645 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0861 s/iter. Eval: 0.0827 s/iter. Total: 0.1697 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 21:45:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.602696 (0.168989 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:45:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.086025 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:45:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:45:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26252156815516975\n",
      "\u001b[32m[02/05 21:45:54 d2.utils.events]: \u001b[0m eta: 0:46:50  iter: 4119  total_loss: 1.226  loss_cls: 0.2599  loss_box_reg: 0.5062  loss_mask: 0.2889  loss_rpn_cls: 0.07015  loss_rpn_loc: 0.1194  time: 0.6624  data_time: 0.2038  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:46:07 d2.utils.events]: \u001b[0m eta: 0:46:43  iter: 4139  total_loss: 1.318  loss_cls: 0.3018  loss_box_reg: 0.5482  loss_mask: 0.2942  loss_rpn_cls: 0.08671  loss_rpn_loc: 0.1204  time: 0.6624  data_time: 0.1916  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:46:19 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 4159  total_loss: 1.161  loss_cls: 0.2411  loss_box_reg: 0.4904  loss_mask: 0.2797  loss_rpn_cls: 0.04778  loss_rpn_loc: 0.114  time: 0.6620  data_time: 0.1251  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:46:33 d2.utils.events]: \u001b[0m eta: 0:46:17  iter: 4179  total_loss: 1.32  loss_cls: 0.2971  loss_box_reg: 0.5416  loss_mask: 0.2973  loss_rpn_cls: 0.0929  loss_rpn_loc: 0.1186  time: 0.6623  data_time: 0.2477  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:46:46 d2.utils.events]: \u001b[0m eta: 0:46:03  iter: 4199  total_loss: 1.25  loss_cls: 0.2604  loss_box_reg: 0.519  loss_mask: 0.2873  loss_rpn_cls: 0.05762  loss_rpn_loc: 0.07781  time: 0.6622  data_time: 0.1828  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:46:58 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 4219  total_loss: 1.389  loss_cls: 0.2988  loss_box_reg: 0.5461  loss_mask: 0.3166  loss_rpn_cls: 0.08688  loss_rpn_loc: 0.1367  time: 0.6618  data_time: 0.1098  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:47:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:47:13 d2.utils.events]: \u001b[0m eta: 0:45:46  iter: 4239  total_loss: 1.266  loss_cls: 0.2501  loss_box_reg: 0.5254  loss_mask: 0.2967  loss_rpn_cls: 0.05584  loss_rpn_loc: 0.1027  time: 0.6623  data_time: 0.2484  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:47:25 d2.utils.events]: \u001b[0m eta: 0:45:39  iter: 4259  total_loss: 1.241  loss_cls: 0.2544  loss_box_reg: 0.5163  loss_mask: 0.3147  loss_rpn_cls: 0.06374  loss_rpn_loc: 0.1191  time: 0.6620  data_time: 0.1388  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:47:37 d2.utils.events]: \u001b[0m eta: 0:45:29  iter: 4279  total_loss: 1.289  loss_cls: 0.2587  loss_box_reg: 0.5086  loss_mask: 0.3029  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.1251  time: 0.6616  data_time: 0.1244  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:47:50 d2.utils.events]: \u001b[0m eta: 0:45:25  iter: 4299  total_loss: 1.367  loss_cls: 0.2635  loss_box_reg: 0.5103  loss_mask: 0.3037  loss_rpn_cls: 0.09763  loss_rpn_loc: 0.1366  time: 0.6617  data_time: 0.2230  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:48:04 d2.utils.events]: \u001b[0m eta: 0:45:18  iter: 4319  total_loss: 1.367  loss_cls: 0.2981  loss_box_reg: 0.5505  loss_mask: 0.3003  loss_rpn_cls: 0.0934  loss_rpn_loc: 0.1322  time: 0.6618  data_time: 0.2245  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:48:18 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 4339  total_loss: 1.219  loss_cls: 0.2615  loss_box_reg: 0.5138  loss_mask: 0.2811  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.1195  time: 0.6619  data_time: 0.2211  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:48:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:48:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:48:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:48:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:48:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:48:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0865 s/iter. Eval: 0.0681 s/iter. Total: 0.1552 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 21:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0873 s/iter. Eval: 0.0824 s/iter. Total: 0.1705 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0818 s/iter. Total: 0.1700 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0877 s/iter. Eval: 0.0866 s/iter. Total: 0.1751 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:48:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.203767 (0.174170 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:48:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087553 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:48:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:48:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23918166179623485\n",
      "\u001b[32m[02/05 21:48:51 d2.utils.events]: \u001b[0m eta: 0:44:55  iter: 4359  total_loss: 1.337  loss_cls: 0.2928  loss_box_reg: 0.5284  loss_mask: 0.2966  loss_rpn_cls: 0.09666  loss_rpn_loc: 0.1306  time: 0.6614  data_time: 0.0947  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:49:04 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 4379  total_loss: 1.257  loss_cls: 0.2635  loss_box_reg: 0.5126  loss_mask: 0.2697  loss_rpn_cls: 0.07717  loss_rpn_loc: 0.1184  time: 0.6616  data_time: 0.2404  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:49:17 d2.utils.events]: \u001b[0m eta: 0:44:40  iter: 4399  total_loss: 1.384  loss_cls: 0.2938  loss_box_reg: 0.5482  loss_mask: 0.3025  loss_rpn_cls: 0.07098  loss_rpn_loc: 0.124  time: 0.6615  data_time: 0.1692  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:49:29 d2.utils.events]: \u001b[0m eta: 0:44:30  iter: 4419  total_loss: 1.311  loss_cls: 0.2814  loss_box_reg: 0.5416  loss_mask: 0.3045  loss_rpn_cls: 0.06875  loss_rpn_loc: 0.1186  time: 0.6611  data_time: 0.1305  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:49:42 d2.utils.events]: \u001b[0m eta: 0:44:19  iter: 4439  total_loss: 1.27  loss_cls: 0.2588  loss_box_reg: 0.5351  loss_mask: 0.297  loss_rpn_cls: 0.08232  loss_rpn_loc: 0.1261  time: 0.6610  data_time: 0.1680  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:49:55 d2.utils.events]: \u001b[0m eta: 0:44:05  iter: 4459  total_loss: 1.349  loss_cls: 0.2904  loss_box_reg: 0.554  loss_mask: 0.326  loss_rpn_cls: 0.09013  loss_rpn_loc: 0.1387  time: 0.6610  data_time: 0.2090  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:50:08 d2.utils.events]: \u001b[0m eta: 0:43:55  iter: 4479  total_loss: 1.193  loss_cls: 0.2499  loss_box_reg: 0.4957  loss_mask: 0.2818  loss_rpn_cls: 0.04609  loss_rpn_loc: 0.1101  time: 0.6609  data_time: 0.1783  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:50:20 d2.utils.events]: \u001b[0m eta: 0:43:43  iter: 4499  total_loss: 1.233  loss_cls: 0.2551  loss_box_reg: 0.5147  loss_mask: 0.2856  loss_rpn_cls: 0.06644  loss_rpn_loc: 0.1157  time: 0.6606  data_time: 0.1439  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:50:33 d2.utils.events]: \u001b[0m eta: 0:43:34  iter: 4519  total_loss: 1.331  loss_cls: 0.2605  loss_box_reg: 0.5246  loss_mask: 0.2954  loss_rpn_cls: 0.08288  loss_rpn_loc: 0.118  time: 0.6607  data_time: 0.2251  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:50:47 d2.utils.events]: \u001b[0m eta: 0:43:25  iter: 4539  total_loss: 1.353  loss_cls: 0.2764  loss_box_reg: 0.5466  loss_mask: 0.2968  loss_rpn_cls: 0.08408  loss_rpn_loc: 0.125  time: 0.6609  data_time: 0.2201  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:51:01 d2.utils.events]: \u001b[0m eta: 0:43:14  iter: 4559  total_loss: 1.334  loss_cls: 0.3074  loss_box_reg: 0.5268  loss_mask: 0.3053  loss_rpn_cls: 0.0946  loss_rpn_loc: 0.1411  time: 0.6610  data_time: 0.2475  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:51:16 d2.utils.events]: \u001b[0m eta: 0:43:05  iter: 4579  total_loss: 1.309  loss_cls: 0.296  loss_box_reg: 0.5539  loss_mask: 0.307  loss_rpn_cls: 0.06265  loss_rpn_loc: 0.1154  time: 0.6613  data_time: 0.2470  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:51:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:51:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:51:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:51:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:51:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:51:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0854 s/iter. Eval: 0.0666 s/iter. Total: 0.1526 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 21:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0007 s/iter. Inference: 0.0869 s/iter. Eval: 0.0817 s/iter. Total: 0.1694 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0007 s/iter. Inference: 0.0869 s/iter. Eval: 0.0822 s/iter. Total: 0.1699 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0872 s/iter. Eval: 0.0866 s/iter. Total: 0.1746 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:51:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.061520 (0.172944 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:51:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087018 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:51:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:51:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24696545880658757\n",
      "\u001b[32m[02/05 21:51:48 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 4599  total_loss: 1.241  loss_cls: 0.2437  loss_box_reg: 0.4983  loss_mask: 0.2829  loss_rpn_cls: 0.06451  loss_rpn_loc: 0.1242  time: 0.6608  data_time: 0.0950  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:52:02 d2.utils.events]: \u001b[0m eta: 0:42:42  iter: 4619  total_loss: 1.403  loss_cls: 0.3142  loss_box_reg: 0.5482  loss_mask: 0.31  loss_rpn_cls: 0.09718  loss_rpn_loc: 0.1258  time: 0.6609  data_time: 0.2343  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:52:17 d2.utils.events]: \u001b[0m eta: 0:42:32  iter: 4639  total_loss: 1.242  loss_cls: 0.2561  loss_box_reg: 0.4941  loss_mask: 0.2884  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.1234  time: 0.6614  data_time: 0.3005  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:52:31 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 4659  total_loss: 1.357  loss_cls: 0.3009  loss_box_reg: 0.5583  loss_mask: 0.3031  loss_rpn_cls: 0.08672  loss_rpn_loc: 0.1361  time: 0.6615  data_time: 0.2092  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:52:44 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 4679  total_loss: 1.365  loss_cls: 0.2665  loss_box_reg: 0.5445  loss_mask: 0.3103  loss_rpn_cls: 0.0762  loss_rpn_loc: 0.1295  time: 0.6614  data_time: 0.2008  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:52:57 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 4699  total_loss: 1.278  loss_cls: 0.2649  loss_box_reg: 0.5508  loss_mask: 0.3  loss_rpn_cls: 0.08181  loss_rpn_loc: 0.1138  time: 0.6614  data_time: 0.1986  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:53:08 d2.utils.events]: \u001b[0m eta: 0:41:51  iter: 4719  total_loss: 1.237  loss_cls: 0.2451  loss_box_reg: 0.5271  loss_mask: 0.2864  loss_rpn_cls: 0.0504  loss_rpn_loc: 0.1066  time: 0.6609  data_time: 0.1077  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:53:22 d2.utils.events]: \u001b[0m eta: 0:41:47  iter: 4739  total_loss: 1.37  loss_cls: 0.3004  loss_box_reg: 0.5636  loss_mask: 0.3013  loss_rpn_cls: 0.08757  loss_rpn_loc: 0.1213  time: 0.6610  data_time: 0.2167  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:53:33 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 4759  total_loss: 1.204  loss_cls: 0.2263  loss_box_reg: 0.4897  loss_mask: 0.2906  loss_rpn_cls: 0.05294  loss_rpn_loc: 0.1147  time: 0.6605  data_time: 0.0980  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:53:46 d2.utils.events]: \u001b[0m eta: 0:41:33  iter: 4779  total_loss: 1.4  loss_cls: 0.2973  loss_box_reg: 0.5327  loss_mask: 0.2983  loss_rpn_cls: 0.1137  loss_rpn_loc: 0.139  time: 0.6605  data_time: 0.1866  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:54:00 d2.utils.events]: \u001b[0m eta: 0:41:24  iter: 4799  total_loss: 1.254  loss_cls: 0.2772  loss_box_reg: 0.498  loss_mask: 0.2922  loss_rpn_cls: 0.08962  loss_rpn_loc: 0.1195  time: 0.6606  data_time: 0.2225  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:54:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:54:18 d2.utils.events]: \u001b[0m eta: 0:41:14  iter: 4819  total_loss: 1.433  loss_cls: 0.2926  loss_box_reg: 0.5504  loss_mask: 0.2973  loss_rpn_cls: 0.09591  loss_rpn_loc: 0.1363  time: 0.6616  data_time: 0.3731  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:54:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:54:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:54:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:54:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:54:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:54:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0864 s/iter. Eval: 0.0692 s/iter. Total: 0.1562 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 21:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0007 s/iter. Inference: 0.0874 s/iter. Eval: 0.0833 s/iter. Total: 0.1715 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 21:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0876 s/iter. Eval: 0.0834 s/iter. Total: 0.1717 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0882 s/iter. Total: 0.1769 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:54:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.395124 (0.175820 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:54:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087733 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:54:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:54:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23359149333342727\n",
      "\u001b[32m[02/05 21:54:50 d2.utils.events]: \u001b[0m eta: 0:41:00  iter: 4839  total_loss: 1.179  loss_cls: 0.2271  loss_box_reg: 0.5029  loss_mask: 0.2908  loss_rpn_cls: 0.06966  loss_rpn_loc: 0.1007  time: 0.6610  data_time: 0.0654  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:55:01 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 4859  total_loss: 1.26  loss_cls: 0.2464  loss_box_reg: 0.5158  loss_mask: 0.2948  loss_rpn_cls: 0.05228  loss_rpn_loc: 0.1065  time: 0.6606  data_time: 0.1075  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:55:17 d2.utils.events]: \u001b[0m eta: 0:40:42  iter: 4879  total_loss: 1.238  loss_cls: 0.2539  loss_box_reg: 0.5078  loss_mask: 0.2887  loss_rpn_cls: 0.07548  loss_rpn_loc: 0.1162  time: 0.6611  data_time: 0.3184  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:55:31 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 4899  total_loss: 1.265  loss_cls: 0.2673  loss_box_reg: 0.525  loss_mask: 0.31  loss_rpn_cls: 0.08035  loss_rpn_loc: 0.1078  time: 0.6613  data_time: 0.2621  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:55:48 d2.utils.events]: \u001b[0m eta: 0:40:32  iter: 4919  total_loss: 1.493  loss_cls: 0.3307  loss_box_reg: 0.572  loss_mask: 0.3269  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.1447  time: 0.6620  data_time: 0.3469  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:55:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:56:05 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 4939  total_loss: 1.326  loss_cls: 0.2553  loss_box_reg: 0.5299  loss_mask: 0.3031  loss_rpn_cls: 0.08524  loss_rpn_loc: 0.1244  time: 0.6628  data_time: 0.2807  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:56:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 21:56:20 d2.utils.events]: \u001b[0m eta: 0:40:18  iter: 4959  total_loss: 1.359  loss_cls: 0.2793  loss_box_reg: 0.5315  loss_mask: 0.3084  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.1281  time: 0.6632  data_time: 0.1844  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:56:32 d2.utils.events]: \u001b[0m eta: 0:40:12  iter: 4979  total_loss: 1.156  loss_cls: 0.2455  loss_box_reg: 0.5011  loss_mask: 0.2833  loss_rpn_cls: 0.06159  loss_rpn_loc: 0.09669  time: 0.6630  data_time: 0.1306  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:56:44 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 4999  total_loss: 1.22  loss_cls: 0.2533  loss_box_reg: 0.4963  loss_mask: 0.2964  loss_rpn_cls: 0.06665  loss_rpn_loc: 0.1106  time: 0.6626  data_time: 0.1234  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:56:55 d2.utils.events]: \u001b[0m eta: 0:39:49  iter: 5019  total_loss: 1.28  loss_cls: 0.283  loss_box_reg: 0.5328  loss_mask: 0.3041  loss_rpn_cls: 0.09471  loss_rpn_loc: 0.1261  time: 0.6623  data_time: 0.1150  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:57:09 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 5039  total_loss: 1.302  loss_cls: 0.2855  loss_box_reg: 0.5464  loss_mask: 0.2997  loss_rpn_cls: 0.07041  loss_rpn_loc: 0.1304  time: 0.6624  data_time: 0.1804  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:57:21 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 5059  total_loss: 1.244  loss_cls: 0.2576  loss_box_reg: 0.5129  loss_mask: 0.2994  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.1065  time: 0.6621  data_time: 0.1394  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:57:32 d2.utils.events]: \u001b[0m eta: 0:39:25  iter: 5079  total_loss: 1.101  loss_cls: 0.227  loss_box_reg: 0.4855  loss_mask: 0.2908  loss_rpn_cls: 0.05073  loss_rpn_loc: 0.08672  time: 0.6617  data_time: 0.0941  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:57:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:57:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 21:57:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 21:57:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 21:57:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 21:57:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 21:57:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0926 s/iter. Eval: 0.0715 s/iter. Total: 0.1648 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 21:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0821 s/iter. Total: 0.1736 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 21:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0812 s/iter. Total: 0.1712 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 21:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0906 s/iter. Eval: 0.0884 s/iter. Total: 0.1799 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 21:57:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.577057 (0.177388 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:57:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089856 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 21:57:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 21:57:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.251299406232017\n",
      "\u001b[32m[02/05 21:58:07 d2.utils.events]: \u001b[0m eta: 0:39:17  iter: 5099  total_loss: 1.337  loss_cls: 0.285  loss_box_reg: 0.5361  loss_mask: 0.3042  loss_rpn_cls: 0.08511  loss_rpn_loc: 0.1216  time: 0.6615  data_time: 0.1402  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:58:18 d2.utils.events]: \u001b[0m eta: 0:39:10  iter: 5119  total_loss: 1.339  loss_cls: 0.2864  loss_box_reg: 0.5278  loss_mask: 0.298  loss_rpn_cls: 0.07355  loss_rpn_loc: 0.1229  time: 0.6611  data_time: 0.0854  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:58:30 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 5139  total_loss: 1.109  loss_cls: 0.2166  loss_box_reg: 0.4796  loss_mask: 0.2858  loss_rpn_cls: 0.04937  loss_rpn_loc: 0.09999  time: 0.6609  data_time: 0.1631  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:58:41 d2.utils.events]: \u001b[0m eta: 0:38:49  iter: 5159  total_loss: 1.152  loss_cls: 0.2348  loss_box_reg: 0.5154  loss_mask: 0.2859  loss_rpn_cls: 0.05412  loss_rpn_loc: 0.08543  time: 0.6605  data_time: 0.0983  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:58:54 d2.utils.events]: \u001b[0m eta: 0:38:38  iter: 5179  total_loss: 1.316  loss_cls: 0.2747  loss_box_reg: 0.5109  loss_mask: 0.291  loss_rpn_cls: 0.06195  loss_rpn_loc: 0.1158  time: 0.6604  data_time: 0.1701  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:59:11 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 5199  total_loss: 1.4  loss_cls: 0.2883  loss_box_reg: 0.5408  loss_mask: 0.2953  loss_rpn_cls: 0.09054  loss_rpn_loc: 0.149  time: 0.6611  data_time: 0.3385  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:59:23 d2.utils.events]: \u001b[0m eta: 0:38:20  iter: 5219  total_loss: 1.208  loss_cls: 0.266  loss_box_reg: 0.5172  loss_mask: 0.2985  loss_rpn_cls: 0.0544  loss_rpn_loc: 0.09901  time: 0.6609  data_time: 0.1490  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:59:39 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 5239  total_loss: 1.344  loss_cls: 0.2743  loss_box_reg: 0.5527  loss_mask: 0.3047  loss_rpn_cls: 0.106  loss_rpn_loc: 0.115  time: 0.6614  data_time: 0.3056  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 21:59:52 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 5259  total_loss: 1.259  loss_cls: 0.2317  loss_box_reg: 0.501  loss_mask: 0.2864  loss_rpn_cls: 0.0796  loss_rpn_loc: 0.1198  time: 0.6613  data_time: 0.1494  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:00:04 d2.utils.events]: \u001b[0m eta: 0:38:00  iter: 5279  total_loss: 1.332  loss_cls: 0.2607  loss_box_reg: 0.5462  loss_mask: 0.2971  loss_rpn_cls: 0.06955  loss_rpn_loc: 0.1231  time: 0.6611  data_time: 0.1246  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:00:17 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 5299  total_loss: 1.328  loss_cls: 0.2835  loss_box_reg: 0.5237  loss_mask: 0.3053  loss_rpn_cls: 0.07955  loss_rpn_loc: 0.1302  time: 0.6610  data_time: 0.1853  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:00:31 d2.utils.events]: \u001b[0m eta: 0:37:35  iter: 5319  total_loss: 1.38  loss_cls: 0.2922  loss_box_reg: 0.5427  loss_mask: 0.3189  loss_rpn_cls: 0.09088  loss_rpn_loc: 0.1262  time: 0.6611  data_time: 0.2189  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:00:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:00:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:00:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:00:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:00:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:00:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0877 s/iter. Eval: 0.0680 s/iter. Total: 0.1564 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0007 s/iter. Inference: 0.0888 s/iter. Eval: 0.0824 s/iter. Total: 0.1720 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 22:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0814 s/iter. Total: 0.1706 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0860 s/iter. Total: 0.1751 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:00:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.163915 (0.173827 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:00:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087990 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:00:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:00:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24745692763329155\n",
      "\u001b[32m[02/05 22:01:06 d2.utils.events]: \u001b[0m eta: 0:37:26  iter: 5339  total_loss: 1.318  loss_cls: 0.2601  loss_box_reg: 0.5199  loss_mask: 0.2962  loss_rpn_cls: 0.07097  loss_rpn_loc: 0.1286  time: 0.6612  data_time: 0.2082  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:01:20 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 5359  total_loss: 1.404  loss_cls: 0.3084  loss_box_reg: 0.5515  loss_mask: 0.3071  loss_rpn_cls: 0.09224  loss_rpn_loc: 0.1525  time: 0.6612  data_time: 0.2118  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:01:32 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 5379  total_loss: 1.309  loss_cls: 0.2697  loss_box_reg: 0.5588  loss_mask: 0.3054  loss_rpn_cls: 0.07828  loss_rpn_loc: 0.122  time: 0.6610  data_time: 0.1445  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:01:43 d2.utils.events]: \u001b[0m eta: 0:37:01  iter: 5399  total_loss: 1.285  loss_cls: 0.2719  loss_box_reg: 0.5376  loss_mask: 0.2931  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.1097  time: 0.6606  data_time: 0.0973  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:01:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:01:58 d2.utils.events]: \u001b[0m eta: 0:36:56  iter: 5419  total_loss: 1.287  loss_cls: 0.2763  loss_box_reg: 0.5088  loss_mask: 0.2952  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.1122  time: 0.6611  data_time: 0.2382  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:02:12 d2.utils.events]: \u001b[0m eta: 0:36:48  iter: 5439  total_loss: 1.309  loss_cls: 0.2548  loss_box_reg: 0.5437  loss_mask: 0.3108  loss_rpn_cls: 0.06901  loss_rpn_loc: 0.1259  time: 0.6611  data_time: 0.1867  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:02:22 d2.utils.events]: \u001b[0m eta: 0:36:39  iter: 5459  total_loss: 1.265  loss_cls: 0.2644  loss_box_reg: 0.4958  loss_mask: 0.2908  loss_rpn_cls: 0.06932  loss_rpn_loc: 0.1157  time: 0.6606  data_time: 0.0622  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:02:39 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 5479  total_loss: 1.381  loss_cls: 0.299  loss_box_reg: 0.5332  loss_mask: 0.3021  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.1331  time: 0.6613  data_time: 0.3839  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:02:53 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 5499  total_loss: 1.274  loss_cls: 0.2525  loss_box_reg: 0.5028  loss_mask: 0.2876  loss_rpn_cls: 0.0674  loss_rpn_loc: 0.12  time: 0.6613  data_time: 0.1856  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:03:07 d2.utils.events]: \u001b[0m eta: 0:36:19  iter: 5519  total_loss: 1.349  loss_cls: 0.2941  loss_box_reg: 0.52  loss_mask: 0.2953  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.1438  time: 0.6614  data_time: 0.2163  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:03:19 d2.utils.events]: \u001b[0m eta: 0:36:06  iter: 5539  total_loss: 1.238  loss_cls: 0.2595  loss_box_reg: 0.508  loss_mask: 0.2926  loss_rpn_cls: 0.06576  loss_rpn_loc: 0.1138  time: 0.6613  data_time: 0.1518  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:03:30 d2.utils.events]: \u001b[0m eta: 0:35:56  iter: 5559  total_loss: 1.12  loss_cls: 0.2121  loss_box_reg: 0.4729  loss_mask: 0.2727  loss_rpn_cls: 0.05285  loss_rpn_loc: 0.1033  time: 0.6609  data_time: 0.1148  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:03:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:03:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:03:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:03:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:03:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:03:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0850 s/iter. Eval: 0.0651 s/iter. Total: 0.1507 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 22:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0869 s/iter. Eval: 0.0792 s/iter. Total: 0.1670 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 22:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0864 s/iter. Eval: 0.0779 s/iter. Total: 0.1652 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0885 s/iter. Eval: 0.0872 s/iter. Total: 0.1766 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:03:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.335046 (0.175302 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:03:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088565 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:03:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:03:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2600166762209258\n",
      "\u001b[32m[02/05 22:04:07 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 5579  total_loss: 1.356  loss_cls: 0.2776  loss_box_reg: 0.5251  loss_mask: 0.3046  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.1409  time: 0.6612  data_time: 0.2732  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:04:20 d2.utils.events]: \u001b[0m eta: 0:35:39  iter: 5599  total_loss: 1.182  loss_cls: 0.2259  loss_box_reg: 0.4919  loss_mask: 0.2864  loss_rpn_cls: 0.06147  loss_rpn_loc: 0.1101  time: 0.6612  data_time: 0.1746  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:04:35 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 5619  total_loss: 1.299  loss_cls: 0.2558  loss_box_reg: 0.5082  loss_mask: 0.317  loss_rpn_cls: 0.06667  loss_rpn_loc: 0.1172  time: 0.6614  data_time: 0.2647  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:04:49 d2.utils.events]: \u001b[0m eta: 0:35:22  iter: 5639  total_loss: 1.46  loss_cls: 0.3432  loss_box_reg: 0.5628  loss_mask: 0.3021  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.1454  time: 0.6615  data_time: 0.2048  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:04:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:05:04 d2.utils.events]: \u001b[0m eta: 0:35:12  iter: 5659  total_loss: 1.287  loss_cls: 0.2571  loss_box_reg: 0.5165  loss_mask: 0.2985  loss_rpn_cls: 0.069  loss_rpn_loc: 0.1167  time: 0.6620  data_time: 0.2231  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:05:19 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 5679  total_loss: 1.258  loss_cls: 0.2841  loss_box_reg: 0.5297  loss_mask: 0.2833  loss_rpn_cls: 0.07826  loss_rpn_loc: 0.1079  time: 0.6622  data_time: 0.1962  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:05:31 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 5699  total_loss: 1.21  loss_cls: 0.2622  loss_box_reg: 0.494  loss_mask: 0.2851  loss_rpn_cls: 0.06744  loss_rpn_loc: 0.1095  time: 0.6620  data_time: 0.1436  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:05:43 d2.utils.events]: \u001b[0m eta: 0:34:47  iter: 5719  total_loss: 1.204  loss_cls: 0.2374  loss_box_reg: 0.5332  loss_mask: 0.315  loss_rpn_cls: 0.05444  loss_rpn_loc: 0.1102  time: 0.6618  data_time: 0.1366  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:05:56 d2.utils.events]: \u001b[0m eta: 0:34:38  iter: 5739  total_loss: 1.333  loss_cls: 0.2653  loss_box_reg: 0.5404  loss_mask: 0.3116  loss_rpn_cls: 0.08004  loss_rpn_loc: 0.1324  time: 0.6617  data_time: 0.1666  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:06:09 d2.utils.events]: \u001b[0m eta: 0:34:32  iter: 5759  total_loss: 1.336  loss_cls: 0.2942  loss_box_reg: 0.5364  loss_mask: 0.2875  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.1266  time: 0.6618  data_time: 0.2009  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:06:22 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 5779  total_loss: 1.274  loss_cls: 0.261  loss_box_reg: 0.5222  loss_mask: 0.2998  loss_rpn_cls: 0.05408  loss_rpn_loc: 0.1163  time: 0.6617  data_time: 0.1419  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:06:33 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 5799  total_loss: 1.314  loss_cls: 0.2848  loss_box_reg: 0.5278  loss_mask: 0.2997  loss_rpn_cls: 0.08611  loss_rpn_loc: 0.129  time: 0.6614  data_time: 0.1137  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:06:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:06:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:06:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:06:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:06:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:06:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0871 s/iter. Eval: 0.0718 s/iter. Total: 0.1597 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0847 s/iter. Total: 0.1735 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:06:53 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0839 s/iter. Total: 0.1726 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0883 s/iter. Total: 0.1772 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:07:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.574753 (0.177369 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:07:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088409 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:07:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:07:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.23991948527336723\n",
      "\u001b[32m[02/05 22:07:09 d2.utils.events]: \u001b[0m eta: 0:34:05  iter: 5819  total_loss: 1.274  loss_cls: 0.2631  loss_box_reg: 0.5642  loss_mask: 0.2977  loss_rpn_cls: 0.08857  loss_rpn_loc: 0.1225  time: 0.6614  data_time: 0.2029  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:07:22 d2.utils.events]: \u001b[0m eta: 0:33:59  iter: 5839  total_loss: 1.216  loss_cls: 0.2636  loss_box_reg: 0.5084  loss_mask: 0.2924  loss_rpn_cls: 0.05338  loss_rpn_loc: 0.1121  time: 0.6613  data_time: 0.1449  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:07:38 d2.utils.events]: \u001b[0m eta: 0:33:56  iter: 5859  total_loss: 1.346  loss_cls: 0.2789  loss_box_reg: 0.5347  loss_mask: 0.2972  loss_rpn_cls: 0.08597  loss_rpn_loc: 0.136  time: 0.6618  data_time: 0.2940  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:07:50 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 5879  total_loss: 1.262  loss_cls: 0.2843  loss_box_reg: 0.5248  loss_mask: 0.2716  loss_rpn_cls: 0.06029  loss_rpn_loc: 0.1151  time: 0.6616  data_time: 0.1362  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:08:04 d2.utils.events]: \u001b[0m eta: 0:33:36  iter: 5899  total_loss: 1.373  loss_cls: 0.3127  loss_box_reg: 0.5288  loss_mask: 0.2886  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.1319  time: 0.6618  data_time: 0.2271  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:08:16 d2.utils.events]: \u001b[0m eta: 0:33:26  iter: 5919  total_loss: 1.208  loss_cls: 0.2441  loss_box_reg: 0.4923  loss_mask: 0.2889  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.107  time: 0.6615  data_time: 0.0941  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:08:30 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 5939  total_loss: 1.233  loss_cls: 0.2576  loss_box_reg: 0.5108  loss_mask: 0.2869  loss_rpn_cls: 0.07432  loss_rpn_loc: 0.1193  time: 0.6617  data_time: 0.1987  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:08:46 d2.utils.events]: \u001b[0m eta: 0:33:09  iter: 5959  total_loss: 1.422  loss_cls: 0.3115  loss_box_reg: 0.5427  loss_mask: 0.3087  loss_rpn_cls: 0.0931  loss_rpn_loc: 0.1388  time: 0.6621  data_time: 0.2615  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:09:01 d2.utils.events]: \u001b[0m eta: 0:33:01  iter: 5979  total_loss: 1.253  loss_cls: 0.2383  loss_box_reg: 0.498  loss_mask: 0.2836  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.1029  time: 0.6625  data_time: 0.2427  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:09:15 d2.utils.events]: \u001b[0m eta: 0:32:59  iter: 5999  total_loss: 1.299  loss_cls: 0.2672  loss_box_reg: 0.5222  loss_mask: 0.3077  loss_rpn_cls: 0.05792  loss_rpn_loc: 0.1208  time: 0.6625  data_time: 0.1658  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:09:30 d2.utils.events]: \u001b[0m eta: 0:32:55  iter: 6019  total_loss: 1.359  loss_cls: 0.2934  loss_box_reg: 0.5244  loss_mask: 0.3078  loss_rpn_cls: 0.097  loss_rpn_loc: 0.133  time: 0.6629  data_time: 0.2403  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:09:44 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 6039  total_loss: 1.214  loss_cls: 0.2252  loss_box_reg: 0.5492  loss_mask: 0.2899  loss_rpn_cls: 0.04794  loss_rpn_loc: 0.09614  time: 0.6629  data_time: 0.1580  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:09:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:09:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:09:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:09:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:09:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:09:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:09:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0967 s/iter. Eval: 0.0782 s/iter. Total: 0.1757 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 22:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0008 s/iter. Inference: 0.0981 s/iter. Eval: 0.0930 s/iter. Total: 0.1920 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 22:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0008 s/iter. Inference: 0.0981 s/iter. Eval: 0.0943 s/iter. Total: 0.1933 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 22:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 87/121. Dataloading: 0.0008 s/iter. Inference: 0.0997 s/iter. Eval: 0.1001 s/iter. Total: 0.2007 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/05 22:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0009 s/iter. Inference: 0.1009 s/iter. Eval: 0.0998 s/iter. Total: 0.2016 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 22:10:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.589651 (0.203359 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:10:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.101530 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:10:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:10:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24078221966143476\n",
      "\u001b[32m[02/05 22:10:23 d2.utils.events]: \u001b[0m eta: 0:32:45  iter: 6059  total_loss: 1.283  loss_cls: 0.2776  loss_box_reg: 0.5203  loss_mask: 0.3022  loss_rpn_cls: 0.08894  loss_rpn_loc: 0.1228  time: 0.6629  data_time: 0.1443  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:10:41 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 6079  total_loss: 1.322  loss_cls: 0.2733  loss_box_reg: 0.4868  loss_mask: 0.304  loss_rpn_cls: 0.09128  loss_rpn_loc: 0.1354  time: 0.6637  data_time: 0.3152  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:10:56 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 6099  total_loss: 1.291  loss_cls: 0.2859  loss_box_reg: 0.5041  loss_mask: 0.2886  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.103  time: 0.6640  data_time: 0.2077  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:11:08 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 6119  total_loss: 1.298  loss_cls: 0.2476  loss_box_reg: 0.5224  loss_mask: 0.2987  loss_rpn_cls: 0.06428  loss_rpn_loc: 0.1097  time: 0.6638  data_time: 0.1414  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:11:21 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 6139  total_loss: 1.321  loss_cls: 0.2971  loss_box_reg: 0.5363  loss_mask: 0.2977  loss_rpn_cls: 0.09911  loss_rpn_loc: 0.1345  time: 0.6638  data_time: 0.1768  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:11:35 d2.utils.events]: \u001b[0m eta: 0:32:21  iter: 6159  total_loss: 1.207  loss_cls: 0.2397  loss_box_reg: 0.4851  loss_mask: 0.2914  loss_rpn_cls: 0.07283  loss_rpn_loc: 0.1043  time: 0.6639  data_time: 0.2298  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:11:50 d2.utils.events]: \u001b[0m eta: 0:32:12  iter: 6179  total_loss: 1.385  loss_cls: 0.2777  loss_box_reg: 0.5605  loss_mask: 0.296  loss_rpn_cls: 0.0893  loss_rpn_loc: 0.1268  time: 0.6641  data_time: 0.2393  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:12:02 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 6199  total_loss: 1.235  loss_cls: 0.2527  loss_box_reg: 0.5225  loss_mask: 0.2798  loss_rpn_cls: 0.05662  loss_rpn_loc: 0.1133  time: 0.6640  data_time: 0.1410  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:12:16 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 6219  total_loss: 1.281  loss_cls: 0.2538  loss_box_reg: 0.5081  loss_mask: 0.2917  loss_rpn_cls: 0.0785  loss_rpn_loc: 0.1162  time: 0.6641  data_time: 0.2139  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:12:30 d2.utils.events]: \u001b[0m eta: 0:31:41  iter: 6239  total_loss: 1.252  loss_cls: 0.2854  loss_box_reg: 0.5274  loss_mask: 0.2831  loss_rpn_cls: 0.08924  loss_rpn_loc: 0.1191  time: 0.6641  data_time: 0.1892  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:12:42 d2.utils.events]: \u001b[0m eta: 0:31:30  iter: 6259  total_loss: 1.249  loss_cls: 0.2682  loss_box_reg: 0.5268  loss_mask: 0.2938  loss_rpn_cls: 0.05624  loss_rpn_loc: 0.1056  time: 0.6639  data_time: 0.1184  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:12:54 d2.utils.events]: \u001b[0m eta: 0:31:19  iter: 6279  total_loss: 1.278  loss_cls: 0.2638  loss_box_reg: 0.5122  loss_mask: 0.2978  loss_rpn_cls: 0.09485  loss_rpn_loc: 0.1155  time: 0.6638  data_time: 0.1536  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:13:01 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:13:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:13:01 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:13:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:13:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:13:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0914 s/iter. Eval: 0.0721 s/iter. Total: 0.1642 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 22:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0910 s/iter. Eval: 0.0839 s/iter. Total: 0.1758 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:13:14 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0829 s/iter. Total: 0.1733 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0873 s/iter. Total: 0.1775 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:13:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.548477 (0.177142 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:13:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089434 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:13:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:13:23 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25066026276016096\n",
      "\u001b[32m[02/05 22:13:29 d2.utils.events]: \u001b[0m eta: 0:31:10  iter: 6299  total_loss: 1.238  loss_cls: 0.2377  loss_box_reg: 0.508  loss_mask: 0.2879  loss_rpn_cls: 0.05516  loss_rpn_loc: 0.1053  time: 0.6637  data_time: 0.1624  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:13:41 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 6319  total_loss: 1.3  loss_cls: 0.277  loss_box_reg: 0.5278  loss_mask: 0.2918  loss_rpn_cls: 0.07087  loss_rpn_loc: 0.127  time: 0.6635  data_time: 0.1356  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:13:54 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 6339  total_loss: 1.261  loss_cls: 0.2724  loss_box_reg: 0.515  loss_mask: 0.3061  loss_rpn_cls: 0.06581  loss_rpn_loc: 0.1291  time: 0.6634  data_time: 0.1522  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:14:08 d2.utils.events]: \u001b[0m eta: 0:30:40  iter: 6359  total_loss: 1.269  loss_cls: 0.2691  loss_box_reg: 0.503  loss_mask: 0.2888  loss_rpn_cls: 0.08167  loss_rpn_loc: 0.1171  time: 0.6635  data_time: 0.2230  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:14:22 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 6379  total_loss: 1.418  loss_cls: 0.2969  loss_box_reg: 0.5668  loss_mask: 0.3052  loss_rpn_cls: 0.09994  loss_rpn_loc: 0.1551  time: 0.6636  data_time: 0.2181  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:14:35 d2.utils.events]: \u001b[0m eta: 0:30:30  iter: 6399  total_loss: 1.409  loss_cls: 0.2873  loss_box_reg: 0.5485  loss_mask: 0.3017  loss_rpn_cls: 0.08921  loss_rpn_loc: 0.1391  time: 0.6636  data_time: 0.1718  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:14:45 d2.utils.events]: \u001b[0m eta: 0:30:17  iter: 6419  total_loss: 1.109  loss_cls: 0.2154  loss_box_reg: 0.4813  loss_mask: 0.2816  loss_rpn_cls: 0.05259  loss_rpn_loc: 0.09282  time: 0.6631  data_time: 0.0434  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:14:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:15:01 d2.utils.events]: \u001b[0m eta: 0:30:16  iter: 6439  total_loss: 1.352  loss_cls: 0.287  loss_box_reg: 0.558  loss_mask: 0.2989  loss_rpn_cls: 0.06091  loss_rpn_loc: 0.1228  time: 0.6635  data_time: 0.1925  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:15:13 d2.utils.events]: \u001b[0m eta: 0:30:05  iter: 6459  total_loss: 1.164  loss_cls: 0.2204  loss_box_reg: 0.5062  loss_mask: 0.2732  loss_rpn_cls: 0.05072  loss_rpn_loc: 0.091  time: 0.6633  data_time: 0.1083  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:15:27 d2.utils.events]: \u001b[0m eta: 0:29:49  iter: 6479  total_loss: 1.272  loss_cls: 0.2684  loss_box_reg: 0.5245  loss_mask: 0.2979  loss_rpn_cls: 0.09146  loss_rpn_loc: 0.122  time: 0.6634  data_time: 0.2185  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:15:40 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 6499  total_loss: 1.348  loss_cls: 0.2835  loss_box_reg: 0.5442  loss_mask: 0.2994  loss_rpn_cls: 0.07436  loss_rpn_loc: 0.1156  time: 0.6634  data_time: 0.1965  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:15:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:15:54 d2.utils.events]: \u001b[0m eta: 0:29:26  iter: 6519  total_loss: 1.32  loss_cls: 0.279  loss_box_reg: 0.5137  loss_mask: 0.2911  loss_rpn_cls: 0.07401  loss_rpn_loc: 0.1232  time: 0.6635  data_time: 0.1590  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:16:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:16:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:16:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:16:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:16:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:16:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0885 s/iter. Eval: 0.0680 s/iter. Total: 0.1571 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0905 s/iter. Eval: 0.0833 s/iter. Total: 0.1746 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0827 s/iter. Total: 0.1739 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 22:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0900 s/iter. Eval: 0.0878 s/iter. Total: 0.1787 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:16:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.442278 (0.176227 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:16:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089262 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:16:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:16:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2504236405326116\n",
      "\u001b[32m[02/05 22:16:30 d2.utils.events]: \u001b[0m eta: 0:29:19  iter: 6539  total_loss: 1.269  loss_cls: 0.2715  loss_box_reg: 0.5165  loss_mask: 0.2951  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.1304  time: 0.6636  data_time: 0.2025  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:16:44 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 6559  total_loss: 1.229  loss_cls: 0.2837  loss_box_reg: 0.521  loss_mask: 0.2756  loss_rpn_cls: 0.07131  loss_rpn_loc: 0.1273  time: 0.6637  data_time: 0.2199  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:16:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:17:00 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 6579  total_loss: 1.34  loss_cls: 0.2672  loss_box_reg: 0.5223  loss_mask: 0.2961  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.1213  time: 0.6641  data_time: 0.2510  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:17:13 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 6599  total_loss: 1.303  loss_cls: 0.2671  loss_box_reg: 0.4929  loss_mask: 0.2903  loss_rpn_cls: 0.07136  loss_rpn_loc: 0.1302  time: 0.6641  data_time: 0.1913  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:17:25 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 6619  total_loss: 1.248  loss_cls: 0.2397  loss_box_reg: 0.5274  loss_mask: 0.2901  loss_rpn_cls: 0.06729  loss_rpn_loc: 0.1161  time: 0.6638  data_time: 0.0876  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:17:37 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 6639  total_loss: 1.325  loss_cls: 0.2813  loss_box_reg: 0.5289  loss_mask: 0.2875  loss_rpn_cls: 0.08579  loss_rpn_loc: 0.143  time: 0.6637  data_time: 0.1633  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:17:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:17:54 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 6659  total_loss: 1.324  loss_cls: 0.2702  loss_box_reg: 0.5208  loss_mask: 0.2915  loss_rpn_cls: 0.07251  loss_rpn_loc: 0.1303  time: 0.6642  data_time: 0.2776  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:18:05 d2.utils.events]: \u001b[0m eta: 0:28:05  iter: 6679  total_loss: 1.156  loss_cls: 0.2287  loss_box_reg: 0.499  loss_mask: 0.286  loss_rpn_cls: 0.05939  loss_rpn_loc: 0.08345  time: 0.6639  data_time: 0.1075  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:18:19 d2.utils.events]: \u001b[0m eta: 0:27:56  iter: 6699  total_loss: 1.355  loss_cls: 0.2845  loss_box_reg: 0.5244  loss_mask: 0.302  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.1274  time: 0.6641  data_time: 0.2248  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:18:32 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 6719  total_loss: 1.311  loss_cls: 0.2727  loss_box_reg: 0.544  loss_mask: 0.3086  loss_rpn_cls: 0.07366  loss_rpn_loc: 0.1261  time: 0.6640  data_time: 0.1712  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:18:49 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 6739  total_loss: 1.376  loss_cls: 0.3203  loss_box_reg: 0.533  loss_mask: 0.3112  loss_rpn_cls: 0.09586  loss_rpn_loc: 0.1309  time: 0.6644  data_time: 0.3286  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:19:02 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 6759  total_loss: 1.237  loss_cls: 0.2449  loss_box_reg: 0.5129  loss_mask: 0.3001  loss_rpn_cls: 0.05084  loss_rpn_loc: 0.1026  time: 0.6644  data_time: 0.1979  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:19:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:19:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:19:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:19:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:19:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:19:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0887 s/iter. Eval: 0.0680 s/iter. Total: 0.1573 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0820 s/iter. Total: 0.1722 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 22:19:24 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0817 s/iter. Total: 0.1716 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0864 s/iter. Total: 0.1765 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:19:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.430449 (0.176125 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:19:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089484 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:19:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:19:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2521311950054462\n",
      "\u001b[32m[02/05 22:19:36 d2.utils.events]: \u001b[0m eta: 0:27:17  iter: 6779  total_loss: 1.299  loss_cls: 0.273  loss_box_reg: 0.5228  loss_mask: 0.2939  loss_rpn_cls: 0.08045  loss_rpn_loc: 0.08232  time: 0.6643  data_time: 0.1394  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:19:49 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 6799  total_loss: 1.296  loss_cls: 0.2686  loss_box_reg: 0.5232  loss_mask: 0.2827  loss_rpn_cls: 0.07836  loss_rpn_loc: 0.1236  time: 0.6642  data_time: 0.1463  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:20:00 d2.utils.events]: \u001b[0m eta: 0:26:52  iter: 6819  total_loss: 1.179  loss_cls: 0.2509  loss_box_reg: 0.4971  loss_mask: 0.2824  loss_rpn_cls: 0.05835  loss_rpn_loc: 0.1087  time: 0.6639  data_time: 0.1193  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:20:13 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 6839  total_loss: 1.313  loss_cls: 0.274  loss_box_reg: 0.5186  loss_mask: 0.3017  loss_rpn_cls: 0.068  loss_rpn_loc: 0.11  time: 0.6638  data_time: 0.1487  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:20:26 d2.utils.events]: \u001b[0m eta: 0:26:27  iter: 6859  total_loss: 1.265  loss_cls: 0.2549  loss_box_reg: 0.5251  loss_mask: 0.2858  loss_rpn_cls: 0.0645  loss_rpn_loc: 0.1075  time: 0.6638  data_time: 0.1899  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:20:39 d2.utils.events]: \u001b[0m eta: 0:26:17  iter: 6879  total_loss: 1.426  loss_cls: 0.2909  loss_box_reg: 0.5649  loss_mask: 0.308  loss_rpn_cls: 0.08837  loss_rpn_loc: 0.1188  time: 0.6637  data_time: 0.1752  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:20:53 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 6899  total_loss: 1.245  loss_cls: 0.2665  loss_box_reg: 0.5217  loss_mask: 0.3045  loss_rpn_cls: 0.06951  loss_rpn_loc: 0.1086  time: 0.6638  data_time: 0.2160  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:21:05 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 6919  total_loss: 1.34  loss_cls: 0.2948  loss_box_reg: 0.5304  loss_mask: 0.297  loss_rpn_cls: 0.08012  loss_rpn_loc: 0.1221  time: 0.6637  data_time: 0.1487  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:21:19 d2.utils.events]: \u001b[0m eta: 0:25:47  iter: 6939  total_loss: 1.273  loss_cls: 0.2558  loss_box_reg: 0.5194  loss_mask: 0.2855  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.1105  time: 0.6637  data_time: 0.1776  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:21:33 d2.utils.events]: \u001b[0m eta: 0:25:35  iter: 6959  total_loss: 1.264  loss_cls: 0.2714  loss_box_reg: 0.5114  loss_mask: 0.2956  loss_rpn_cls: 0.06229  loss_rpn_loc: 0.1139  time: 0.6639  data_time: 0.2538  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:21:48 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 6979  total_loss: 1.387  loss_cls: 0.2904  loss_box_reg: 0.5184  loss_mask: 0.2968  loss_rpn_cls: 0.0965  loss_rpn_loc: 0.1359  time: 0.6641  data_time: 0.2588  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:22:00 d2.utils.events]: \u001b[0m eta: 0:25:09  iter: 6999  total_loss: 1.207  loss_cls: 0.2409  loss_box_reg: 0.5038  loss_mask: 0.2856  loss_rpn_cls: 0.05073  loss_rpn_loc: 0.1047  time: 0.6639  data_time: 0.1466  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:22:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:22:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:22:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:22:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:22:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:22:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0012 s/iter. Inference: 0.0935 s/iter. Eval: 0.0787 s/iter. Total: 0.1733 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 22:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0009 s/iter. Inference: 0.0926 s/iter. Eval: 0.0873 s/iter. Total: 0.1809 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.0918 s/iter. Eval: 0.0860 s/iter. Total: 0.1787 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 22:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0008 s/iter. Inference: 0.0922 s/iter. Eval: 0.0917 s/iter. Total: 0.1847 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 22:22:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.192274 (0.182692 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:22:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091996 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:22:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:22:34 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24778539754562437\n",
      "\u001b[32m[02/05 22:22:36 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 7019  total_loss: 1.132  loss_cls: 0.2445  loss_box_reg: 0.4965  loss_mask: 0.2792  loss_rpn_cls: 0.06218  loss_rpn_loc: 0.0864  time: 0.6638  data_time: 0.1103  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:22:56 d2.utils.events]: \u001b[0m eta: 0:24:37  iter: 7039  total_loss: 1.338  loss_cls: 0.2846  loss_box_reg: 0.536  loss_mask: 0.3061  loss_rpn_cls: 0.09718  loss_rpn_loc: 0.119  time: 0.6648  data_time: 0.5177  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:23:12 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 7059  total_loss: 1.266  loss_cls: 0.2786  loss_box_reg: 0.5193  loss_mask: 0.2849  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.1276  time: 0.6651  data_time: 0.2956  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:23:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:23:24 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 7079  total_loss: 1.204  loss_cls: 0.2334  loss_box_reg: 0.4955  loss_mask: 0.2808  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.09802  time: 0.6650  data_time: 0.0997  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:23:38 d2.utils.events]: \u001b[0m eta: 0:23:54  iter: 7099  total_loss: 1.321  loss_cls: 0.2875  loss_box_reg: 0.499  loss_mask: 0.3009  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.1187  time: 0.6651  data_time: 0.2280  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:23:54 d2.utils.events]: \u001b[0m eta: 0:23:47  iter: 7119  total_loss: 1.289  loss_cls: 0.279  loss_box_reg: 0.5049  loss_mask: 0.2981  loss_rpn_cls: 0.087  loss_rpn_loc: 0.123  time: 0.6654  data_time: 0.3070  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:24:08 d2.utils.events]: \u001b[0m eta: 0:23:37  iter: 7139  total_loss: 1.399  loss_cls: 0.2986  loss_box_reg: 0.538  loss_mask: 0.3038  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.1317  time: 0.6656  data_time: 0.2330  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:24:22 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 7159  total_loss: 1.323  loss_cls: 0.2698  loss_box_reg: 0.5203  loss_mask: 0.2985  loss_rpn_cls: 0.07601  loss_rpn_loc: 0.1135  time: 0.6656  data_time: 0.2153  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:24:35 d2.utils.events]: \u001b[0m eta: 0:23:16  iter: 7179  total_loss: 1.219  loss_cls: 0.2623  loss_box_reg: 0.5103  loss_mask: 0.2739  loss_rpn_cls: 0.06823  loss_rpn_loc: 0.1192  time: 0.6656  data_time: 0.1832  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:24:45 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 7199  total_loss: 1.175  loss_cls: 0.2392  loss_box_reg: 0.4995  loss_mask: 0.2832  loss_rpn_cls: 0.06011  loss_rpn_loc: 0.09696  time: 0.6652  data_time: 0.0720  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:24:56 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 7219  total_loss: 1.142  loss_cls: 0.218  loss_box_reg: 0.4978  loss_mask: 0.279  loss_rpn_cls: 0.05554  loss_rpn_loc: 0.09428  time: 0.6649  data_time: 0.0813  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:25:13 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 7239  total_loss: 1.414  loss_cls: 0.3117  loss_box_reg: 0.5535  loss_mask: 0.3072  loss_rpn_cls: 0.09042  loss_rpn_loc: 0.1295  time: 0.6653  data_time: 0.3207  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:25:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:25:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:25:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:25:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:25:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:25:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0879 s/iter. Eval: 0.0661 s/iter. Total: 0.1547 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0008 s/iter. Inference: 0.0917 s/iter. Eval: 0.0829 s/iter. Total: 0.1754 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.0914 s/iter. Eval: 0.0832 s/iter. Total: 0.1754 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 22:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0008 s/iter. Inference: 0.0922 s/iter. Eval: 0.0888 s/iter. Total: 0.1818 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:25:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.856370 (0.179796 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:25:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092321 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:25:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:25:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2515978505321947\n",
      "\u001b[32m[02/05 22:25:50 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 7259  total_loss: 1.296  loss_cls: 0.2608  loss_box_reg: 0.4984  loss_mask: 0.2936  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.1265  time: 0.6655  data_time: 0.2438  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:26:05 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 7279  total_loss: 1.333  loss_cls: 0.2769  loss_box_reg: 0.5203  loss_mask: 0.2923  loss_rpn_cls: 0.08405  loss_rpn_loc: 0.1298  time: 0.6657  data_time: 0.2463  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:26:18 d2.utils.events]: \u001b[0m eta: 0:22:17  iter: 7299  total_loss: 1.234  loss_cls: 0.2484  loss_box_reg: 0.5078  loss_mask: 0.2994  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.119  time: 0.6656  data_time: 0.1441  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:26:32 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:26:34 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 7319  total_loss: 1.365  loss_cls: 0.2745  loss_box_reg: 0.5424  loss_mask: 0.3017  loss_rpn_cls: 0.07794  loss_rpn_loc: 0.1363  time: 0.6660  data_time: 0.2361  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:26:50 d2.utils.events]: \u001b[0m eta: 0:22:00  iter: 7339  total_loss: 1.276  loss_cls: 0.2889  loss_box_reg: 0.5312  loss_mask: 0.2994  loss_rpn_cls: 0.08798  loss_rpn_loc: 0.1238  time: 0.6664  data_time: 0.2947  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:27:05 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 7359  total_loss: 1.3  loss_cls: 0.2721  loss_box_reg: 0.512  loss_mask: 0.2919  loss_rpn_cls: 0.09159  loss_rpn_loc: 0.1275  time: 0.6666  data_time: 0.2449  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:27:18 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 7379  total_loss: 1.177  loss_cls: 0.2245  loss_box_reg: 0.4776  loss_mask: 0.2887  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.09798  time: 0.6666  data_time: 0.2041  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:27:31 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 7399  total_loss: 1.248  loss_cls: 0.25  loss_box_reg: 0.5364  loss_mask: 0.301  loss_rpn_cls: 0.05904  loss_rpn_loc: 0.1098  time: 0.6665  data_time: 0.1697  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:27:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:27:48 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 7419  total_loss: 1.325  loss_cls: 0.2638  loss_box_reg: 0.513  loss_mask: 0.2944  loss_rpn_cls: 0.07332  loss_rpn_loc: 0.1274  time: 0.6671  data_time: 0.2733  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:28:03 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 7439  total_loss: 1.332  loss_cls: 0.2822  loss_box_reg: 0.5303  loss_mask: 0.2974  loss_rpn_cls: 0.07714  loss_rpn_loc: 0.1243  time: 0.6673  data_time: 0.2718  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:28:14 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 7459  total_loss: 1.171  loss_cls: 0.2399  loss_box_reg: 0.4948  loss_mask: 0.2868  loss_rpn_cls: 0.047  loss_rpn_loc: 0.09939  time: 0.6669  data_time: 0.0873  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:28:29 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 7479  total_loss: 1.372  loss_cls: 0.2836  loss_box_reg: 0.5468  loss_mask: 0.2977  loss_rpn_cls: 0.09181  loss_rpn_loc: 0.1338  time: 0.6672  data_time: 0.2435  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:28:42 d2.utils.events]: \u001b[0m eta: 0:20:40  iter: 7499  total_loss: 1.204  loss_cls: 0.2417  loss_box_reg: 0.5163  loss_mask: 0.2729  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.09734  time: 0.6671  data_time: 0.1557  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:28:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:28:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:28:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:28:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:28:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:28:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0917 s/iter. Eval: 0.0684 s/iter. Total: 0.1608 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0914 s/iter. Eval: 0.0822 s/iter. Total: 0.1744 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0809 s/iter. Total: 0.1722 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0875 s/iter. Total: 0.1795 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:29:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.553419 (0.177185 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:29:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090543 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:29:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:29:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25638366403346896\n",
      "\u001b[32m[02/05 22:29:20 d2.utils.events]: \u001b[0m eta: 0:20:33  iter: 7519  total_loss: 1.354  loss_cls: 0.2854  loss_box_reg: 0.5272  loss_mask: 0.3096  loss_rpn_cls: 0.08404  loss_rpn_loc: 0.1221  time: 0.6674  data_time: 0.2661  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:29:32 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 7539  total_loss: 1.112  loss_cls: 0.2068  loss_box_reg: 0.4755  loss_mask: 0.2842  loss_rpn_cls: 0.06405  loss_rpn_loc: 0.1061  time: 0.6672  data_time: 0.1226  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:29:44 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 7559  total_loss: 1.304  loss_cls: 0.2784  loss_box_reg: 0.5408  loss_mask: 0.3023  loss_rpn_cls: 0.04882  loss_rpn_loc: 0.1282  time: 0.6670  data_time: 0.1123  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:29:56 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 7579  total_loss: 1.262  loss_cls: 0.2628  loss_box_reg: 0.5337  loss_mask: 0.2815  loss_rpn_cls: 0.07865  loss_rpn_loc: 0.1133  time: 0.6668  data_time: 0.1081  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:30:11 d2.utils.events]: \u001b[0m eta: 0:19:54  iter: 7599  total_loss: 1.329  loss_cls: 0.278  loss_box_reg: 0.528  loss_mask: 0.3103  loss_rpn_cls: 0.09401  loss_rpn_loc: 0.1314  time: 0.6671  data_time: 0.2469  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:30:23 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 7619  total_loss: 1.202  loss_cls: 0.2497  loss_box_reg: 0.506  loss_mask: 0.276  loss_rpn_cls: 0.05232  loss_rpn_loc: 0.1063  time: 0.6669  data_time: 0.0936  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:30:37 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 7639  total_loss: 1.301  loss_cls: 0.2713  loss_box_reg: 0.5203  loss_mask: 0.2964  loss_rpn_cls: 0.07072  loss_rpn_loc: 0.1178  time: 0.6669  data_time: 0.1619  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:30:49 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 7659  total_loss: 1.23  loss_cls: 0.2638  loss_box_reg: 0.5037  loss_mask: 0.2784  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.1221  time: 0.6668  data_time: 0.1323  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:31:03 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 7679  total_loss: 1.327  loss_cls: 0.2909  loss_box_reg: 0.5358  loss_mask: 0.3176  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.1357  time: 0.6669  data_time: 0.2322  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:31:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:31:22 d2.utils.events]: \u001b[0m eta: 0:19:09  iter: 7699  total_loss: 1.418  loss_cls: 0.3085  loss_box_reg: 0.5526  loss_mask: 0.3038  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.1505  time: 0.6677  data_time: 0.3619  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:31:34 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 7719  total_loss: 1.313  loss_cls: 0.275  loss_box_reg: 0.5133  loss_mask: 0.2917  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.123  time: 0.6674  data_time: 0.0769  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:31:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:31:51 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 7739  total_loss: 1.246  loss_cls: 0.2549  loss_box_reg: 0.5095  loss_mask: 0.2974  loss_rpn_cls: 0.07507  loss_rpn_loc: 0.1037  time: 0.6679  data_time: 0.2780  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:31:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:31:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:31:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:31:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:31:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:31:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0853 s/iter. Eval: 0.0661 s/iter. Total: 0.1521 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 22:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0824 s/iter. Total: 0.1729 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0820 s/iter. Total: 0.1724 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0868 s/iter. Total: 0.1771 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:32:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.460380 (0.176383 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:32:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089448 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:32:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25334410033275856\n",
      "\u001b[32m[02/05 22:32:26 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 7759  total_loss: 1.329  loss_cls: 0.2805  loss_box_reg: 0.538  loss_mask: 0.3035  loss_rpn_cls: 0.06303  loss_rpn_loc: 0.1074  time: 0.6678  data_time: 0.1493  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:32:39 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 7779  total_loss: 1.345  loss_cls: 0.2758  loss_box_reg: 0.4962  loss_mask: 0.2965  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.1401  time: 0.6678  data_time: 0.1868  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:32:53 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 7799  total_loss: 1.42  loss_cls: 0.319  loss_box_reg: 0.5405  loss_mask: 0.3018  loss_rpn_cls: 0.09284  loss_rpn_loc: 0.1543  time: 0.6678  data_time: 0.1688  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:33:07 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 7819  total_loss: 1.311  loss_cls: 0.2793  loss_box_reg: 0.5377  loss_mask: 0.3061  loss_rpn_cls: 0.06267  loss_rpn_loc: 0.1089  time: 0.6680  data_time: 0.2325  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:33:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:33:24 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 7839  total_loss: 1.322  loss_cls: 0.2762  loss_box_reg: 0.5179  loss_mask: 0.2972  loss_rpn_cls: 0.0752  loss_rpn_loc: 0.1225  time: 0.6684  data_time: 0.2612  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:33:38 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 7859  total_loss: 1.272  loss_cls: 0.2662  loss_box_reg: 0.5005  loss_mask: 0.2812  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.1328  time: 0.6685  data_time: 0.1906  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:33:51 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 7879  total_loss: 1.21  loss_cls: 0.216  loss_box_reg: 0.5164  loss_mask: 0.3057  loss_rpn_cls: 0.05981  loss_rpn_loc: 0.09335  time: 0.6684  data_time: 0.1822  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:34:06 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 7899  total_loss: 1.299  loss_cls: 0.2496  loss_box_reg: 0.531  loss_mask: 0.3049  loss_rpn_cls: 0.06522  loss_rpn_loc: 0.1175  time: 0.6687  data_time: 0.2954  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:34:20 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 7919  total_loss: 1.283  loss_cls: 0.2738  loss_box_reg: 0.5031  loss_mask: 0.2821  loss_rpn_cls: 0.08698  loss_rpn_loc: 0.1088  time: 0.6687  data_time: 0.2118  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:34:34 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 7939  total_loss: 1.208  loss_cls: 0.2474  loss_box_reg: 0.4858  loss_mask: 0.2908  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.103  time: 0.6688  data_time: 0.2238  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:34:46 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 7959  total_loss: 1.162  loss_cls: 0.2366  loss_box_reg: 0.4989  loss_mask: 0.2971  loss_rpn_cls: 0.04396  loss_rpn_loc: 0.09935  time: 0.6687  data_time: 0.1675  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:34:59 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 7979  total_loss: 1.186  loss_cls: 0.2583  loss_box_reg: 0.48  loss_mask: 0.2832  loss_rpn_cls: 0.07237  loss_rpn_loc: 0.1111  time: 0.6686  data_time: 0.1431  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:35:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:35:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:35:03 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:35:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:35:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:35:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0886 s/iter. Eval: 0.0659 s/iter. Total: 0.1551 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:35:11 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0900 s/iter. Eval: 0.0822 s/iter. Total: 0.1731 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0897 s/iter. Eval: 0.0807 s/iter. Total: 0.1712 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0857 s/iter. Total: 0.1758 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:35:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.219788 (0.174309 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:35:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088811 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:35:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:35:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2543446143001656\n",
      "\u001b[32m[02/05 22:35:32 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 7999  total_loss: 1.325  loss_cls: 0.2819  loss_box_reg: 0.5531  loss_mask: 0.2979  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.1158  time: 0.6683  data_time: 0.0816  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:35:43 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 8019  total_loss: 1.317  loss_cls: 0.2879  loss_box_reg: 0.5232  loss_mask: 0.2901  loss_rpn_cls: 0.06834  loss_rpn_loc: 0.1291  time: 0.6680  data_time: 0.0904  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:35:58 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 8039  total_loss: 1.351  loss_cls: 0.2743  loss_box_reg: 0.5481  loss_mask: 0.298  loss_rpn_cls: 0.09092  loss_rpn_loc: 0.1284  time: 0.6682  data_time: 0.2590  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:36:10 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 8059  total_loss: 1.147  loss_cls: 0.2317  loss_box_reg: 0.5061  loss_mask: 0.2866  loss_rpn_cls: 0.05614  loss_rpn_loc: 0.1074  time: 0.6680  data_time: 0.0788  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:36:23 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 8079  total_loss: 1.292  loss_cls: 0.2631  loss_box_reg: 0.5169  loss_mask: 0.3027  loss_rpn_cls: 0.07734  loss_rpn_loc: 0.1224  time: 0.6679  data_time: 0.1585  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:36:37 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 8099  total_loss: 1.324  loss_cls: 0.2654  loss_box_reg: 0.535  loss_mask: 0.2882  loss_rpn_cls: 0.07154  loss_rpn_loc: 0.133  time: 0.6680  data_time: 0.2266  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:36:51 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 8119  total_loss: 1.307  loss_cls: 0.2815  loss_box_reg: 0.5147  loss_mask: 0.2811  loss_rpn_cls: 0.07699  loss_rpn_loc: 0.1402  time: 0.6681  data_time: 0.2166  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:37:08 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 8139  total_loss: 1.312  loss_cls: 0.2831  loss_box_reg: 0.5192  loss_mask: 0.2959  loss_rpn_cls: 0.08  loss_rpn_loc: 0.1257  time: 0.6686  data_time: 0.3751  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:37:20 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 8159  total_loss: 1.163  loss_cls: 0.2407  loss_box_reg: 0.481  loss_mask: 0.2872  loss_rpn_cls: 0.07078  loss_rpn_loc: 0.1093  time: 0.6684  data_time: 0.1474  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:37:35 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 8179  total_loss: 1.249  loss_cls: 0.2634  loss_box_reg: 0.4934  loss_mask: 0.2857  loss_rpn_cls: 0.08595  loss_rpn_loc: 0.1151  time: 0.6686  data_time: 0.2486  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:37:46 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 8199  total_loss: 1.117  loss_cls: 0.2424  loss_box_reg: 0.4878  loss_mask: 0.2793  loss_rpn_cls: 0.04678  loss_rpn_loc: 0.09786  time: 0.6683  data_time: 0.1039  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:37:59 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 8219  total_loss: 1.266  loss_cls: 0.2646  loss_box_reg: 0.5309  loss_mask: 0.315  loss_rpn_cls: 0.07561  loss_rpn_loc: 0.1062  time: 0.6683  data_time: 0.1706  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:38:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:38:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:38:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:38:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:38:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:38:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0932 s/iter. Eval: 0.0709 s/iter. Total: 0.1648 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 22:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0850 s/iter. Total: 0.1790 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.0928 s/iter. Eval: 0.0858 s/iter. Total: 0.1794 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 22:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0908 s/iter. Total: 0.1848 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:38:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.145963 (0.182293 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:38:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092392 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:38:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24314529762233217\n",
      "\u001b[32m[02/05 22:38:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:38:37 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 8239  total_loss: 1.309  loss_cls: 0.278  loss_box_reg: 0.5483  loss_mask: 0.3062  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.1197  time: 0.6685  data_time: 0.1996  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:38:50 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 8259  total_loss: 1.213  loss_cls: 0.2541  loss_box_reg: 0.513  loss_mask: 0.2865  loss_rpn_cls: 0.06568  loss_rpn_loc: 0.1053  time: 0.6685  data_time: 0.1855  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:39:02 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 8279  total_loss: 1.092  loss_cls: 0.2158  loss_box_reg: 0.5013  loss_mask: 0.2702  loss_rpn_cls: 0.05223  loss_rpn_loc: 0.08871  time: 0.6683  data_time: 0.1209  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:39:14 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 8299  total_loss: 1.214  loss_cls: 0.2737  loss_box_reg: 0.4802  loss_mask: 0.2888  loss_rpn_cls: 0.06796  loss_rpn_loc: 0.108  time: 0.6681  data_time: 0.1377  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:39:29 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 8319  total_loss: 1.4  loss_cls: 0.302  loss_box_reg: 0.5319  loss_mask: 0.3219  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1471  time: 0.6683  data_time: 0.2640  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:39:43 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 8339  total_loss: 1.32  loss_cls: 0.2909  loss_box_reg: 0.52  loss_mask: 0.2966  loss_rpn_cls: 0.07841  loss_rpn_loc: 0.1142  time: 0.6683  data_time: 0.1629  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:39:55 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 8359  total_loss: 1.305  loss_cls: 0.2677  loss_box_reg: 0.5127  loss_mask: 0.2944  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.1204  time: 0.6682  data_time: 0.1296  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:40:07 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 8379  total_loss: 1.135  loss_cls: 0.2202  loss_box_reg: 0.4864  loss_mask: 0.2784  loss_rpn_cls: 0.05097  loss_rpn_loc: 0.1082  time: 0.6680  data_time: 0.0826  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:40:19 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 8399  total_loss: 1.318  loss_cls: 0.2811  loss_box_reg: 0.5161  loss_mask: 0.2866  loss_rpn_cls: 0.0645  loss_rpn_loc: 0.1184  time: 0.6679  data_time: 0.1439  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:40:36 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 8419  total_loss: 1.386  loss_cls: 0.3155  loss_box_reg: 0.525  loss_mask: 0.3024  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.1378  time: 0.6683  data_time: 0.3448  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:40:48 d2.utils.events]: \u001b[0m eta: 0:13:11  iter: 8439  total_loss: 1.201  loss_cls: 0.2552  loss_box_reg: 0.5111  loss_mask: 0.2996  loss_rpn_cls: 0.06983  loss_rpn_loc: 0.1155  time: 0.6682  data_time: 0.1466  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:41:01 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 8459  total_loss: 1.327  loss_cls: 0.2802  loss_box_reg: 0.5179  loss_mask: 0.2961  loss_rpn_cls: 0.08235  loss_rpn_loc: 0.1131  time: 0.6681  data_time: 0.1380  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:41:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:41:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:41:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:41:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:41:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:41:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.0758 s/iter. Total: 0.1713 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 22:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 39/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0848 s/iter. Total: 0.1788 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.0932 s/iter. Eval: 0.0846 s/iter. Total: 0.1786 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 22:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 93/121. Dataloading: 0.0008 s/iter. Inference: 0.0942 s/iter. Eval: 0.0897 s/iter. Total: 0.1847 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 22:41:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.231303 (0.183028 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:41:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093982 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:41:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:41:30 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24831524402603175\n",
      "\u001b[32m[02/05 22:41:37 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 8479  total_loss: 1.286  loss_cls: 0.2682  loss_box_reg: 0.5403  loss_mask: 0.2837  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.1213  time: 0.6681  data_time: 0.1850  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:41:51 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 8499  total_loss: 1.165  loss_cls: 0.2478  loss_box_reg: 0.5001  loss_mask: 0.2842  loss_rpn_cls: 0.07684  loss_rpn_loc: 0.1062  time: 0.6681  data_time: 0.1860  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:42:05 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 8519  total_loss: 1.331  loss_cls: 0.2765  loss_box_reg: 0.4875  loss_mask: 0.2969  loss_rpn_cls: 0.0802  loss_rpn_loc: 0.1237  time: 0.6681  data_time: 0.2237  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:42:19 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 8539  total_loss: 1.181  loss_cls: 0.2499  loss_box_reg: 0.4836  loss_mask: 0.2753  loss_rpn_cls: 0.05781  loss_rpn_loc: 0.1169  time: 0.6682  data_time: 0.2139  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:42:32 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 8559  total_loss: 1.353  loss_cls: 0.2826  loss_box_reg: 0.5144  loss_mask: 0.3131  loss_rpn_cls: 0.08658  loss_rpn_loc: 0.139  time: 0.6683  data_time: 0.2116  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:42:48 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 8579  total_loss: 1.255  loss_cls: 0.263  loss_box_reg: 0.5059  loss_mask: 0.2918  loss_rpn_cls: 0.06377  loss_rpn_loc: 0.1115  time: 0.6685  data_time: 0.2882  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:43:01 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 8599  total_loss: 1.303  loss_cls: 0.2701  loss_box_reg: 0.5177  loss_mask: 0.2882  loss_rpn_cls: 0.09037  loss_rpn_loc: 0.1301  time: 0.6685  data_time: 0.1830  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:43:15 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 8619  total_loss: 1.251  loss_cls: 0.2549  loss_box_reg: 0.518  loss_mask: 0.316  loss_rpn_cls: 0.07799  loss_rpn_loc: 0.119  time: 0.6686  data_time: 0.2163  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:43:30 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 8639  total_loss: 1.371  loss_cls: 0.2962  loss_box_reg: 0.544  loss_mask: 0.294  loss_rpn_cls: 0.075  loss_rpn_loc: 0.1351  time: 0.6687  data_time: 0.2329  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:43:45 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 8659  total_loss: 1.212  loss_cls: 0.2724  loss_box_reg: 0.5045  loss_mask: 0.2925  loss_rpn_cls: 0.07095  loss_rpn_loc: 0.1087  time: 0.6689  data_time: 0.2583  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:43:55 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 8679  total_loss: 1.158  loss_cls: 0.2469  loss_box_reg: 0.4976  loss_mask: 0.275  loss_rpn_cls: 0.06217  loss_rpn_loc: 0.0972  time: 0.6685  data_time: 0.0562  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:44:08 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 8699  total_loss: 1.335  loss_cls: 0.2746  loss_box_reg: 0.5304  loss_mask: 0.2957  loss_rpn_cls: 0.08434  loss_rpn_loc: 0.1334  time: 0.6685  data_time: 0.1598  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:44:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:44:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:44:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:44:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:44:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:44:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0874 s/iter. Eval: 0.0695 s/iter. Total: 0.1577 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0811 s/iter. Total: 0.1708 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 22:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0808 s/iter. Total: 0.1698 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0862 s/iter. Total: 0.1766 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:44:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.212055 (0.174242 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:44:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088803 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:44:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:44:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.252912141743104\n",
      "\u001b[32m[02/05 22:44:43 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 8719  total_loss: 1.288  loss_cls: 0.2574  loss_box_reg: 0.5078  loss_mask: 0.2885  loss_rpn_cls: 0.0753  loss_rpn_loc: 0.1148  time: 0.6684  data_time: 0.1983  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:44:57 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 8739  total_loss: 1.171  loss_cls: 0.2282  loss_box_reg: 0.5138  loss_mask: 0.2929  loss_rpn_cls: 0.05489  loss_rpn_loc: 0.09782  time: 0.6685  data_time: 0.1969  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:45:08 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 8759  total_loss: 1.282  loss_cls: 0.2627  loss_box_reg: 0.5299  loss_mask: 0.3018  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.09874  time: 0.6682  data_time: 0.0977  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:45:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:45:23 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 8779  total_loss: 1.148  loss_cls: 0.2088  loss_box_reg: 0.4858  loss_mask: 0.2825  loss_rpn_cls: 0.05598  loss_rpn_loc: 0.09323  time: 0.6685  data_time: 0.2317  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:45:36 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 8799  total_loss: 1.258  loss_cls: 0.2754  loss_box_reg: 0.5248  loss_mask: 0.2919  loss_rpn_cls: 0.07782  loss_rpn_loc: 0.1201  time: 0.6683  data_time: 0.1407  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:45:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:45:54 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 8819  total_loss: 1.236  loss_cls: 0.252  loss_box_reg: 0.4982  loss_mask: 0.301  loss_rpn_cls: 0.08582  loss_rpn_loc: 0.1114  time: 0.6689  data_time: 0.3338  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:46:08 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 8839  total_loss: 1.357  loss_cls: 0.2875  loss_box_reg: 0.5503  loss_mask: 0.296  loss_rpn_cls: 0.08424  loss_rpn_loc: 0.13  time: 0.6690  data_time: 0.2292  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:46:22 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 8859  total_loss: 1.355  loss_cls: 0.3046  loss_box_reg: 0.5205  loss_mask: 0.3  loss_rpn_cls: 0.08785  loss_rpn_loc: 0.1359  time: 0.6690  data_time: 0.2026  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:46:36 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 8879  total_loss: 1.363  loss_cls: 0.2897  loss_box_reg: 0.5218  loss_mask: 0.3086  loss_rpn_cls: 0.06375  loss_rpn_loc: 0.1086  time: 0.6691  data_time: 0.2481  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:46:51 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 8899  total_loss: 1.319  loss_cls: 0.2735  loss_box_reg: 0.5359  loss_mask: 0.304  loss_rpn_cls: 0.09195  loss_rpn_loc: 0.1331  time: 0.6693  data_time: 0.2548  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:47:04 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 8919  total_loss: 1.163  loss_cls: 0.2409  loss_box_reg: 0.4972  loss_mask: 0.2907  loss_rpn_cls: 0.05561  loss_rpn_loc: 0.08777  time: 0.6693  data_time: 0.2083  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:47:17 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 8939  total_loss: 1.294  loss_cls: 0.268  loss_box_reg: 0.5423  loss_mask: 0.3006  loss_rpn_cls: 0.08282  loss_rpn_loc: 0.1343  time: 0.6692  data_time: 0.1760  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:47:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:47:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:47:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:47:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:47:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:47:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0875 s/iter. Eval: 0.0724 s/iter. Total: 0.1607 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0848 s/iter. Total: 0.1747 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 22:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0892 s/iter. Eval: 0.0833 s/iter. Total: 0.1733 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0890 s/iter. Eval: 0.0883 s/iter. Total: 0.1782 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:47:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.506768 (0.176782 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:47:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088801 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:47:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:47:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2507494924438211\n",
      "\u001b[32m[02/05 22:47:51 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 8959  total_loss: 1.21  loss_cls: 0.261  loss_box_reg: 0.5249  loss_mask: 0.2892  loss_rpn_cls: 0.0612  loss_rpn_loc: 0.1046  time: 0.6691  data_time: 0.1176  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:48:03 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 8979  total_loss: 1.188  loss_cls: 0.2434  loss_box_reg: 0.5195  loss_mask: 0.2916  loss_rpn_cls: 0.0533  loss_rpn_loc: 0.08147  time: 0.6688  data_time: 0.1040  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:48:15 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 8999  total_loss: 1.214  loss_cls: 0.243  loss_box_reg: 0.5254  loss_mask: 0.2881  loss_rpn_cls: 0.05892  loss_rpn_loc: 0.1112  time: 0.6687  data_time: 0.1491  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:48:31 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 9019  total_loss: 1.353  loss_cls: 0.2946  loss_box_reg: 0.5418  loss_mask: 0.2891  loss_rpn_cls: 0.09137  loss_rpn_loc: 0.1312  time: 0.6690  data_time: 0.3329  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:48:42 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 9039  total_loss: 1.199  loss_cls: 0.2377  loss_box_reg: 0.4885  loss_mask: 0.2844  loss_rpn_cls: 0.05358  loss_rpn_loc: 0.1202  time: 0.6688  data_time: 0.1080  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:48:45 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:49:01 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 9059  total_loss: 1.43  loss_cls: 0.2962  loss_box_reg: 0.5612  loss_mask: 0.3155  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.1418  time: 0.6693  data_time: 0.3297  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:49:17 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 9079  total_loss: 1.239  loss_cls: 0.2669  loss_box_reg: 0.5252  loss_mask: 0.2857  loss_rpn_cls: 0.07562  loss_rpn_loc: 0.1096  time: 0.6696  data_time: 0.3288  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:49:31 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 9099  total_loss: 1.348  loss_cls: 0.2862  loss_box_reg: 0.5314  loss_mask: 0.2984  loss_rpn_cls: 0.07609  loss_rpn_loc: 0.1219  time: 0.6697  data_time: 0.2258  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:49:43 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 9119  total_loss: 1.228  loss_cls: 0.2733  loss_box_reg: 0.5017  loss_mask: 0.2839  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.1126  time: 0.6695  data_time: 0.1299  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:49:54 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 9139  total_loss: 1.17  loss_cls: 0.2232  loss_box_reg: 0.5121  loss_mask: 0.2754  loss_rpn_cls: 0.04618  loss_rpn_loc: 0.1081  time: 0.6693  data_time: 0.1104  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:50:06 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 9159  total_loss: 1.268  loss_cls: 0.2553  loss_box_reg: 0.5159  loss_mask: 0.2845  loss_rpn_cls: 0.05364  loss_rpn_loc: 0.1102  time: 0.6691  data_time: 0.1306  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:50:19 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 9179  total_loss: 1.311  loss_cls: 0.2811  loss_box_reg: 0.5251  loss_mask: 0.2919  loss_rpn_cls: 0.09499  loss_rpn_loc: 0.1311  time: 0.6691  data_time: 0.1877  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:50:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:50:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:50:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:50:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:50:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:50:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0878 s/iter. Eval: 0.0744 s/iter. Total: 0.1630 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/05 22:50:40 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0875 s/iter. Eval: 0.0834 s/iter. Total: 0.1717 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 22:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0822 s/iter. Total: 0.1708 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:50:50 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0879 s/iter. Eval: 0.0870 s/iter. Total: 0.1758 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:50:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.309396 (0.175081 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:50:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088065 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:50:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:50:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24750795650309912\n",
      "\u001b[32m[02/05 22:50:57 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 9199  total_loss: 1.431  loss_cls: 0.3088  loss_box_reg: 0.544  loss_mask: 0.2996  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.1476  time: 0.6694  data_time: 0.3189  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:51:09 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 9219  total_loss: 1.232  loss_cls: 0.2564  loss_box_reg: 0.4999  loss_mask: 0.2731  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.1257  time: 0.6692  data_time: 0.1427  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:51:23 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 9239  total_loss: 1.309  loss_cls: 0.2746  loss_box_reg: 0.5182  loss_mask: 0.307  loss_rpn_cls: 0.07081  loss_rpn_loc: 0.1242  time: 0.6693  data_time: 0.1940  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:51:34 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 9259  total_loss: 1.188  loss_cls: 0.2336  loss_box_reg: 0.5133  loss_mask: 0.2852  loss_rpn_cls: 0.04241  loss_rpn_loc: 0.09696  time: 0.6690  data_time: 0.1085  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:51:47 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 9279  total_loss: 1.334  loss_cls: 0.2796  loss_box_reg: 0.5543  loss_mask: 0.2917  loss_rpn_cls: 0.0951  loss_rpn_loc: 0.1335  time: 0.6690  data_time: 0.1662  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:52:00 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 9299  total_loss: 1.243  loss_cls: 0.2293  loss_box_reg: 0.5292  loss_mask: 0.3094  loss_rpn_cls: 0.04504  loss_rpn_loc: 0.1107  time: 0.6689  data_time: 0.1674  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:52:16 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 9319  total_loss: 1.263  loss_cls: 0.2534  loss_box_reg: 0.5225  loss_mask: 0.2897  loss_rpn_cls: 0.08  loss_rpn_loc: 0.1187  time: 0.6692  data_time: 0.3176  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:52:30 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 9339  total_loss: 1.095  loss_cls: 0.2083  loss_box_reg: 0.4859  loss_mask: 0.2979  loss_rpn_cls: 0.04155  loss_rpn_loc: 0.07972  time: 0.6693  data_time: 0.2702  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:52:45 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 9359  total_loss: 1.305  loss_cls: 0.279  loss_box_reg: 0.5308  loss_mask: 0.2914  loss_rpn_cls: 0.07372  loss_rpn_loc: 0.1354  time: 0.6694  data_time: 0.2512  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:52:57 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 9379  total_loss: 1.186  loss_cls: 0.2486  loss_box_reg: 0.5045  loss_mask: 0.2841  loss_rpn_cls: 0.05563  loss_rpn_loc: 0.08975  time: 0.6693  data_time: 0.1589  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:53:11 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 9399  total_loss: 1.295  loss_cls: 0.2697  loss_box_reg: 0.5331  loss_mask: 0.3036  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.1123  time: 0.6694  data_time: 0.2244  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:53:24 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 9419  total_loss: 1.247  loss_cls: 0.243  loss_box_reg: 0.49  loss_mask: 0.2739  loss_rpn_cls: 0.06076  loss_rpn_loc: 0.1178  time: 0.6693  data_time: 0.2001  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:53:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:53:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:53:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:53:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:53:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:53:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0868 s/iter. Eval: 0.0793 s/iter. Total: 0.1668 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/05 22:53:44 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0880 s/iter. Eval: 0.0835 s/iter. Total: 0.1724 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 22:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0818 s/iter. Total: 0.1709 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 22:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0882 s/iter. Eval: 0.0871 s/iter. Total: 0.1761 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 22:53:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.252446 (0.174590 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:53:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.087852 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:53:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:53:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2521077872605662\n",
      "\u001b[32m[02/05 22:54:00 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 9439  total_loss: 1.313  loss_cls: 0.2664  loss_box_reg: 0.504  loss_mask: 0.2984  loss_rpn_cls: 0.09587  loss_rpn_loc: 0.1294  time: 0.6694  data_time: 0.2066  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:54:14 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 9459  total_loss: 1.278  loss_cls: 0.2702  loss_box_reg: 0.5225  loss_mask: 0.2923  loss_rpn_cls: 0.08334  loss_rpn_loc: 0.1269  time: 0.6694  data_time: 0.2346  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:54:29 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9479  total_loss: 1.247  loss_cls: 0.2502  loss_box_reg: 0.5095  loss_mask: 0.2964  loss_rpn_cls: 0.07326  loss_rpn_loc: 0.1252  time: 0.6696  data_time: 0.2664  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:54:42 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 9499  total_loss: 1.225  loss_cls: 0.2595  loss_box_reg: 0.492  loss_mask: 0.288  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.1185  time: 0.6696  data_time: 0.2104  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:54:56 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 9519  total_loss: 1.365  loss_cls: 0.3197  loss_box_reg: 0.5415  loss_mask: 0.3075  loss_rpn_cls: 0.08497  loss_rpn_loc: 0.1269  time: 0.6697  data_time: 0.2252  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:55:11 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 9539  total_loss: 1.241  loss_cls: 0.2492  loss_box_reg: 0.4819  loss_mask: 0.291  loss_rpn_cls: 0.08526  loss_rpn_loc: 0.1089  time: 0.6698  data_time: 0.2477  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:55:26 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 9559  total_loss: 1.309  loss_cls: 0.2789  loss_box_reg: 0.5362  loss_mask: 0.3087  loss_rpn_cls: 0.08839  loss_rpn_loc: 0.1388  time: 0.6700  data_time: 0.2962  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:55:36 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 9579  total_loss: 1.075  loss_cls: 0.1918  loss_box_reg: 0.4571  loss_mask: 0.2746  loss_rpn_cls: 0.04706  loss_rpn_loc: 0.09784  time: 0.6696  data_time: 0.0458  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:55:51 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 9599  total_loss: 1.36  loss_cls: 0.2964  loss_box_reg: 0.5512  loss_mask: 0.3027  loss_rpn_cls: 0.09708  loss_rpn_loc: 0.1439  time: 0.6698  data_time: 0.2483  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:56:05 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 9619  total_loss: 1.211  loss_cls: 0.2623  loss_box_reg: 0.5072  loss_mask: 0.2782  loss_rpn_cls: 0.05398  loss_rpn_loc: 0.1062  time: 0.6699  data_time: 0.2548  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:56:18 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 9639  total_loss: 1.281  loss_cls: 0.2545  loss_box_reg: 0.499  loss_mask: 0.3002  loss_rpn_cls: 0.06131  loss_rpn_loc: 0.1184  time: 0.6698  data_time: 0.1392  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:56:33 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 9659  total_loss: 1.315  loss_cls: 0.2713  loss_box_reg: 0.4961  loss_mask: 0.3034  loss_rpn_cls: 0.08784  loss_rpn_loc: 0.1307  time: 0.6700  data_time: 0.2511  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:56:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:56:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:56:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:56:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:56:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:56:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:56:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0950 s/iter. Eval: 0.0964 s/iter. Total: 0.1922 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/05 22:56:53 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0009 s/iter. Inference: 0.0965 s/iter. Eval: 0.0949 s/iter. Total: 0.1923 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 22:56:58 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.0952 s/iter. Eval: 0.0904 s/iter. Total: 0.1864 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/05 22:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.0938 s/iter. Eval: 0.0936 s/iter. Total: 0.1884 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 22:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.0933 s/iter. Eval: 0.0908 s/iter. Total: 0.1850 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 22:57:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.562110 (0.185880 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:57:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093380 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 22:57:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 22:57:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2540195161237502\n",
      "\u001b[32m[02/05 22:57:08 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 9679  total_loss: 1.312  loss_cls: 0.2728  loss_box_reg: 0.5336  loss_mask: 0.305  loss_rpn_cls: 0.05285  loss_rpn_loc: 0.1153  time: 0.6698  data_time: 0.1323  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:57:20 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 9699  total_loss: 1.181  loss_cls: 0.2556  loss_box_reg: 0.4728  loss_mask: 0.2683  loss_rpn_cls: 0.05124  loss_rpn_loc: 0.1145  time: 0.6697  data_time: 0.1187  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:57:37 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 9719  total_loss: 1.257  loss_cls: 0.263  loss_box_reg: 0.5175  loss_mask: 0.2996  loss_rpn_cls: 0.06417  loss_rpn_loc: 0.1118  time: 0.6700  data_time: 0.3101  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:57:48 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 9739  total_loss: 1.296  loss_cls: 0.2747  loss_box_reg: 0.5316  loss_mask: 0.2905  loss_rpn_cls: 0.06826  loss_rpn_loc: 0.109  time: 0.6698  data_time: 0.1024  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:58:04 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 9759  total_loss: 1.299  loss_cls: 0.2705  loss_box_reg: 0.5077  loss_mask: 0.2969  loss_rpn_cls: 0.08901  loss_rpn_loc: 0.1275  time: 0.6700  data_time: 0.3012  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:58:15 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 9779  total_loss: 1.295  loss_cls: 0.2689  loss_box_reg: 0.5089  loss_mask: 0.291  loss_rpn_cls: 0.06249  loss_rpn_loc: 0.1116  time: 0.6698  data_time: 0.1202  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:58:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 22:58:31 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 9799  total_loss: 1.248  loss_cls: 0.225  loss_box_reg: 0.5356  loss_mask: 0.3271  loss_rpn_cls: 0.05981  loss_rpn_loc: 0.1155  time: 0.6701  data_time: 0.2017  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:58:43 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 9819  total_loss: 1.213  loss_cls: 0.2476  loss_box_reg: 0.5143  loss_mask: 0.3035  loss_rpn_cls: 0.0682  loss_rpn_loc: 0.1131  time: 0.6699  data_time: 0.1096  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:58:55 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 9839  total_loss: 1.306  loss_cls: 0.2557  loss_box_reg: 0.5352  loss_mask: 0.2926  loss_rpn_cls: 0.06716  loss_rpn_loc: 0.1096  time: 0.6698  data_time: 0.1547  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:59:13 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 9859  total_loss: 1.481  loss_cls: 0.3276  loss_box_reg: 0.5379  loss_mask: 0.3058  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.1496  time: 0.6702  data_time: 0.4021  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:59:24 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 9879  total_loss: 1.392  loss_cls: 0.2968  loss_box_reg: 0.52  loss_mask: 0.2957  loss_rpn_cls: 0.08591  loss_rpn_loc: 0.1212  time: 0.6700  data_time: 0.0986  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:59:37 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 9899  total_loss: 1.102  loss_cls: 0.2214  loss_box_reg: 0.4847  loss_mask: 0.2788  loss_rpn_cls: 0.04527  loss_rpn_loc: 0.09141  time: 0.6699  data_time: 0.1481  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:59:50 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9919  total_loss: 1.299  loss_cls: 0.2728  loss_box_reg: 0.5206  loss_mask: 0.2987  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.1249  time: 0.6699  data_time: 0.1914  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 22:59:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:59:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 22:59:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 22:59:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 22:59:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 22:59:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 22:59:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0993 s/iter. Eval: 0.1028 s/iter. Total: 0.2029 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/05 22:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0009 s/iter. Inference: 0.0949 s/iter. Eval: 0.0946 s/iter. Total: 0.1904 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 23:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0009 s/iter. Inference: 0.0932 s/iter. Eval: 0.0884 s/iter. Total: 0.1826 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 23:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.0937 s/iter. Eval: 0.0944 s/iter. Total: 0.1890 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/05 23:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0008 s/iter. Inference: 0.0935 s/iter. Eval: 0.0907 s/iter. Total: 0.1851 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/05 23:00:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.516108 (0.185484 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:00:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093518 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:00:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:00:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2513317629817987\n",
      "\u001b[32m[02/05 23:00:27 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 9939  total_loss: 1.268  loss_cls: 0.2741  loss_box_reg: 0.514  loss_mask: 0.2656  loss_rpn_cls: 0.07492  loss_rpn_loc: 0.1198  time: 0.6699  data_time: 0.1498  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:00:38 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 9959  total_loss: 1.295  loss_cls: 0.2817  loss_box_reg: 0.5107  loss_mask: 0.305  loss_rpn_cls: 0.07606  loss_rpn_loc: 0.1198  time: 0.6697  data_time: 0.1146  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:00:51 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 9979  total_loss: 1.34  loss_cls: 0.2769  loss_box_reg: 0.5055  loss_mask: 0.3115  loss_rpn_cls: 0.08347  loss_rpn_loc: 0.1405  time: 0.6696  data_time: 0.1579  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:01:04 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.17  loss_cls: 0.2322  loss_box_reg: 0.4944  loss_mask: 0.2952  loss_rpn_cls: 0.05826  loss_rpn_loc: 0.1112  time: 0.6696  data_time: 0.1934  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:01:04 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:51:34 (0.6696 s / it)\n",
      "\u001b[32m[02/05 23:01:04 d2.engine.hooks]: \u001b[0mTotal training time: 2:06:38 (0:15:04 on hooks)\n",
      "\u001b[32m[02/05 23:01:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:01:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:01:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:01:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:01:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:01:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:01:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0923 s/iter. Eval: 0.0812 s/iter. Total: 0.1743 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/05 23:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0855 s/iter. Total: 0.1753 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 23:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.0899 s/iter. Eval: 0.0853 s/iter. Total: 0.1760 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/05 23:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0008 s/iter. Inference: 0.0903 s/iter. Eval: 0.0897 s/iter. Total: 0.1808 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 23:01:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.910047 (0.180259 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:01:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090700 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:01:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:01:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2527238408359408\n"
     ]
    }
   ],
   "source": [
    "# changing the RPN IOU thresholds and the NMS threshold\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 4000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24], [40], [80], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 3.0]]\n",
    "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.4, 0.7]\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.6\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "378a43b2-5f7b-45fc-ab1c-b4a404319527",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 23:23:16 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 23:23:17 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 23:23:18 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/05 23:23:19 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/05 23:23:19 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/05 23:23:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/05 23:23:19 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/05 23:23:19 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:23:19 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 23:23:19 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/05 23:23:34 d2.utils.events]: \u001b[0m eta: 1:13:40  iter: 19  total_loss: 2.99  loss_cls: 1.337  loss_box_reg: 0.4009  loss_mask: 0.6913  loss_rpn_cls: 0.3282  loss_rpn_loc: 0.2408  time: 0.7408  data_time: 0.2973  lr: 9.9905e-06  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:23:46 d2.utils.events]: \u001b[0m eta: 1:18:46  iter: 39  total_loss: 3.177  loss_cls: 1.268  loss_box_reg: 0.5786  loss_mask: 0.6846  loss_rpn_cls: 0.3271  loss_rpn_loc: 0.2844  time: 0.6605  data_time: 0.1172  lr: 1.998e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:24:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 23:24:05 d2.utils.events]: \u001b[0m eta: 1:24:57  iter: 59  total_loss: 2.886  loss_cls: 1.091  loss_box_reg: 0.6299  loss_mask: 0.6733  loss_rpn_cls: 0.2977  loss_rpn_loc: 0.272  time: 0.7638  data_time: 0.3763  lr: 2.997e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:24:17 d2.utils.events]: \u001b[0m eta: 1:26:45  iter: 79  total_loss: 2.718  loss_cls: 0.8777  loss_box_reg: 0.7453  loss_mask: 0.6461  loss_rpn_cls: 0.2393  loss_rpn_loc: 0.2279  time: 0.7235  data_time: 0.0973  lr: 3.9961e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:24:32 d2.utils.events]: \u001b[0m eta: 1:24:45  iter: 99  total_loss: 2.675  loss_cls: 0.7626  loss_box_reg: 0.8028  loss_mask: 0.6046  loss_rpn_cls: 0.2275  loss_rpn_loc: 0.2262  time: 0.7239  data_time: 0.2360  lr: 4.9951e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:24:44 d2.utils.events]: \u001b[0m eta: 1:24:28  iter: 119  total_loss: 2.551  loss_cls: 0.7301  loss_box_reg: 0.8754  loss_mask: 0.577  loss_rpn_cls: 0.1685  loss_rpn_loc: 0.1972  time: 0.7082  data_time: 0.1425  lr: 5.9941e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:24:59 d2.utils.events]: \u001b[0m eta: 1:25:51  iter: 139  total_loss: 2.506  loss_cls: 0.7286  loss_box_reg: 0.8783  loss_mask: 0.5694  loss_rpn_cls: 0.1394  loss_rpn_loc: 0.1937  time: 0.7108  data_time: 0.2248  lr: 6.993e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:25:12 d2.utils.events]: \u001b[0m eta: 1:25:12  iter: 159  total_loss: 2.464  loss_cls: 0.7085  loss_box_reg: 0.8337  loss_mask: 0.5512  loss_rpn_cls: 0.1609  loss_rpn_loc: 0.2184  time: 0.7028  data_time: 0.1556  lr: 7.9921e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:25:25 d2.utils.events]: \u001b[0m eta: 1:24:22  iter: 179  total_loss: 2.316  loss_cls: 0.6568  loss_box_reg: 0.8585  loss_mask: 0.5113  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.1568  time: 0.6965  data_time: 0.1525  lr: 8.991e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:25:39 d2.utils.events]: \u001b[0m eta: 1:24:11  iter: 199  total_loss: 2.327  loss_cls: 0.6514  loss_box_reg: 0.825  loss_mask: 0.4806  loss_rpn_cls: 0.15  loss_rpn_loc: 0.1755  time: 0.6986  data_time: 0.2262  lr: 9.9901e-05  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:25:50 d2.utils.events]: \u001b[0m eta: 1:23:36  iter: 219  total_loss: 2.205  loss_cls: 0.603  loss_box_reg: 0.8434  loss_mask: 0.452  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.1465  time: 0.6850  data_time: 0.0895  lr: 0.00010989  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:26:06 d2.utils.events]: \u001b[0m eta: 1:23:34  iter: 239  total_loss: 2.063  loss_cls: 0.548  loss_box_reg: 0.821  loss_mask: 0.41  loss_rpn_cls: 0.117  loss_rpn_loc: 0.152  time: 0.6931  data_time: 0.2612  lr: 0.00011988  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:26:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:26:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:26:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:26:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:26:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:26:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:26:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0876 s/iter. Eval: 0.0202 s/iter. Total: 0.1083 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 23:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 56/121. Dataloading: 0.0007 s/iter. Inference: 0.0895 s/iter. Eval: 0.0227 s/iter. Total: 0.1130 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0007 s/iter. Inference: 0.0880 s/iter. Eval: 0.0202 s/iter. Total: 0.1090 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/05 23:26:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.602887 (0.108646 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:26:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088041 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:26:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:26:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.11853540350128877\n",
      "\u001b[32m[02/05 23:26:32 d2.utils.events]: \u001b[0m eta: 1:23:17  iter: 259  total_loss: 2.031  loss_cls: 0.5438  loss_box_reg: 0.8135  loss_mask: 0.3859  loss_rpn_cls: 0.1182  loss_rpn_loc: 0.1765  time: 0.6871  data_time: 0.1215  lr: 0.00012987  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:26:45 d2.utils.events]: \u001b[0m eta: 1:23:04  iter: 279  total_loss: 1.92  loss_cls: 0.5068  loss_box_reg: 0.8029  loss_mask: 0.3519  loss_rpn_cls: 0.08802  loss_rpn_loc: 0.1451  time: 0.6839  data_time: 0.1513  lr: 0.00013986  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:26:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 23:27:01 d2.utils.events]: \u001b[0m eta: 1:22:56  iter: 299  total_loss: 1.883  loss_cls: 0.4703  loss_box_reg: 0.8104  loss_mask: 0.3451  loss_rpn_cls: 0.06839  loss_rpn_loc: 0.1495  time: 0.6925  data_time: 0.2350  lr: 0.00014985  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:27:15 d2.utils.events]: \u001b[0m eta: 1:22:54  iter: 319  total_loss: 1.849  loss_cls: 0.4589  loss_box_reg: 0.7691  loss_mask: 0.33  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.1507  time: 0.6916  data_time: 0.1629  lr: 0.00015984  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:27:24 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 23:27:33 d2.utils.events]: \u001b[0m eta: 1:23:07  iter: 339  total_loss: 1.785  loss_cls: 0.4332  loss_box_reg: 0.7299  loss_mask: 0.3402  loss_rpn_cls: 0.114  loss_rpn_loc: 0.1711  time: 0.7045  data_time: 0.3336  lr: 0.00016983  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:27:47 d2.utils.events]: \u001b[0m eta: 1:22:56  iter: 359  total_loss: 1.697  loss_cls: 0.4128  loss_box_reg: 0.7208  loss_mask: 0.3264  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.1508  time: 0.7058  data_time: 0.2271  lr: 0.00017982  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:28:03 d2.utils.events]: \u001b[0m eta: 1:22:49  iter: 379  total_loss: 1.749  loss_cls: 0.4363  loss_box_reg: 0.7074  loss_mask: 0.3269  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.157  time: 0.7097  data_time: 0.2752  lr: 0.00018981  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:28:19 d2.utils.events]: \u001b[0m eta: 1:22:36  iter: 399  total_loss: 1.719  loss_cls: 0.4167  loss_box_reg: 0.695  loss_mask: 0.3224  loss_rpn_cls: 0.09276  loss_rpn_loc: 0.1451  time: 0.7141  data_time: 0.3004  lr: 0.0001998  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:28:31 d2.utils.events]: \u001b[0m eta: 1:22:34  iter: 419  total_loss: 1.617  loss_cls: 0.4246  loss_box_reg: 0.6781  loss_mask: 0.3079  loss_rpn_cls: 0.08298  loss_rpn_loc: 0.1499  time: 0.7077  data_time: 0.0840  lr: 0.00020979  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:28:46 d2.utils.events]: \u001b[0m eta: 1:22:41  iter: 439  total_loss: 1.649  loss_cls: 0.3954  loss_box_reg: 0.6723  loss_mask: 0.3089  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.1585  time: 0.7100  data_time: 0.2453  lr: 0.00021978  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:28:58 d2.utils.events]: \u001b[0m eta: 1:22:13  iter: 459  total_loss: 1.511  loss_cls: 0.3761  loss_box_reg: 0.6694  loss_mask: 0.3138  loss_rpn_cls: 0.06522  loss_rpn_loc: 0.1177  time: 0.7048  data_time: 0.1008  lr: 0.00022977  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:29:08 d2.utils.events]: \u001b[0m eta: 1:21:54  iter: 479  total_loss: 1.586  loss_cls: 0.3794  loss_box_reg: 0.6754  loss_mask: 0.318  loss_rpn_cls: 0.06105  loss_rpn_loc: 0.1289  time: 0.6971  data_time: 0.0322  lr: 0.00023976  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:29:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:29:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:29:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:29:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:29:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:29:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0917 s/iter. Eval: 0.0524 s/iter. Total: 0.1448 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 23:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0923 s/iter. Eval: 0.0678 s/iter. Total: 0.1610 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 23:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0683 s/iter. Total: 0.1598 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0703 s/iter. Total: 0.1624 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 23:29:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.785069 (0.161940 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:29:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091451 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:29:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:29:31 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.22504392421608757\n",
      "\u001b[32m[02/05 23:29:41 d2.utils.events]: \u001b[0m eta: 1:21:34  iter: 499  total_loss: 1.479  loss_cls: 0.3684  loss_box_reg: 0.6619  loss_mask: 0.3157  loss_rpn_cls: 0.05278  loss_rpn_loc: 0.1147  time: 0.6940  data_time: 0.1142  lr: 0.00024975  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:29:55 d2.utils.events]: \u001b[0m eta: 1:21:56  iter: 519  total_loss: 1.642  loss_cls: 0.4174  loss_box_reg: 0.7001  loss_mask: 0.32  loss_rpn_cls: 0.09696  loss_rpn_loc: 0.1333  time: 0.6949  data_time: 0.2075  lr: 0.00025974  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:30:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 23:30:13 d2.utils.events]: \u001b[0m eta: 1:21:49  iter: 539  total_loss: 1.577  loss_cls: 0.384  loss_box_reg: 0.6369  loss_mask: 0.3176  loss_rpn_cls: 0.07965  loss_rpn_loc: 0.1386  time: 0.7020  data_time: 0.3279  lr: 0.00026973  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:30:25 d2.utils.events]: \u001b[0m eta: 1:21:40  iter: 559  total_loss: 1.638  loss_cls: 0.4217  loss_box_reg: 0.6405  loss_mask: 0.3112  loss_rpn_cls: 0.08381  loss_rpn_loc: 0.1606  time: 0.6990  data_time: 0.1222  lr: 0.00027972  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:30:39 d2.utils.events]: \u001b[0m eta: 1:21:29  iter: 579  total_loss: 1.613  loss_cls: 0.3848  loss_box_reg: 0.6568  loss_mask: 0.3105  loss_rpn_cls: 0.0915  loss_rpn_loc: 0.1547  time: 0.6979  data_time: 0.1673  lr: 0.00028971  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:30:54 d2.utils.events]: \u001b[0m eta: 1:21:23  iter: 599  total_loss: 1.629  loss_cls: 0.4022  loss_box_reg: 0.6249  loss_mask: 0.3381  loss_rpn_cls: 0.09247  loss_rpn_loc: 0.1533  time: 0.6997  data_time: 0.2483  lr: 0.0002997  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:31:06 d2.utils.events]: \u001b[0m eta: 1:21:17  iter: 619  total_loss: 1.526  loss_cls: 0.3759  loss_box_reg: 0.6011  loss_mask: 0.3027  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.1395  time: 0.6972  data_time: 0.1139  lr: 0.00030969  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:31:21 d2.utils.events]: \u001b[0m eta: 1:21:14  iter: 639  total_loss: 1.568  loss_cls: 0.4016  loss_box_reg: 0.6536  loss_mask: 0.309  loss_rpn_cls: 0.08009  loss_rpn_loc: 0.1475  time: 0.6989  data_time: 0.2281  lr: 0.00031968  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:31:32 d2.utils.events]: \u001b[0m eta: 1:21:00  iter: 659  total_loss: 1.43  loss_cls: 0.3818  loss_box_reg: 0.6219  loss_mask: 0.3051  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.08994  time: 0.6948  data_time: 0.0777  lr: 0.00032967  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:31:48 d2.utils.events]: \u001b[0m eta: 1:20:53  iter: 679  total_loss: 1.467  loss_cls: 0.39  loss_box_reg: 0.573  loss_mask: 0.2868  loss_rpn_cls: 0.07293  loss_rpn_loc: 0.1412  time: 0.6967  data_time: 0.2599  lr: 0.00033966  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:32:02 d2.utils.events]: \u001b[0m eta: 1:20:39  iter: 699  total_loss: 1.57  loss_cls: 0.3865  loss_box_reg: 0.5973  loss_mask: 0.306  loss_rpn_cls: 0.07855  loss_rpn_loc: 0.1374  time: 0.6970  data_time: 0.2119  lr: 0.00034965  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:32:15 d2.utils.events]: \u001b[0m eta: 1:20:32  iter: 719  total_loss: 1.487  loss_cls: 0.3663  loss_box_reg: 0.6179  loss_mask: 0.3129  loss_rpn_cls: 0.08131  loss_rpn_loc: 0.131  time: 0.6960  data_time: 0.1558  lr: 0.00035964  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:32:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:32:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:32:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:32:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:32:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:32:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0889 s/iter. Eval: 0.0504 s/iter. Total: 0.1399 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 23:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0900 s/iter. Eval: 0.0693 s/iter. Total: 0.1601 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 23:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0891 s/iter. Eval: 0.0695 s/iter. Total: 0.1594 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 104/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0722 s/iter. Total: 0.1623 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/05 23:32:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.845010 (0.162457 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:32:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089545 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:32:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:32:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24528112920557477\n",
      "\u001b[32m[02/05 23:32:49 d2.utils.events]: \u001b[0m eta: 1:20:18  iter: 739  total_loss: 1.566  loss_cls: 0.4134  loss_box_reg: 0.6517  loss_mask: 0.3361  loss_rpn_cls: 0.08868  loss_rpn_loc: 0.1415  time: 0.6955  data_time: 0.1861  lr: 0.00036963  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:33:02 d2.utils.events]: \u001b[0m eta: 1:20:01  iter: 759  total_loss: 1.453  loss_cls: 0.3627  loss_box_reg: 0.5868  loss_mask: 0.308  loss_rpn_cls: 0.06634  loss_rpn_loc: 0.1364  time: 0.6937  data_time: 0.1386  lr: 0.00037962  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:33:14 d2.utils.events]: \u001b[0m eta: 1:19:46  iter: 779  total_loss: 1.483  loss_cls: 0.3691  loss_box_reg: 0.6249  loss_mask: 0.3031  loss_rpn_cls: 0.07084  loss_rpn_loc: 0.1316  time: 0.6920  data_time: 0.1510  lr: 0.00038961  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:33:25 d2.utils.events]: \u001b[0m eta: 1:19:33  iter: 799  total_loss: 1.386  loss_cls: 0.364  loss_box_reg: 0.5821  loss_mask: 0.2876  loss_rpn_cls: 0.04585  loss_rpn_loc: 0.1149  time: 0.6888  data_time: 0.0598  lr: 0.0003996  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:33:38 d2.utils.events]: \u001b[0m eta: 1:19:21  iter: 819  total_loss: 1.486  loss_cls: 0.391  loss_box_reg: 0.6069  loss_mask: 0.2987  loss_rpn_cls: 0.06433  loss_rpn_loc: 0.1409  time: 0.6877  data_time: 0.1476  lr: 0.00040959  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:33:50 d2.utils.events]: \u001b[0m eta: 1:18:57  iter: 839  total_loss: 1.546  loss_cls: 0.3843  loss_box_reg: 0.6304  loss_mask: 0.311  loss_rpn_cls: 0.07378  loss_rpn_loc: 0.1271  time: 0.6849  data_time: 0.0898  lr: 0.00041958  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:34:03 d2.utils.events]: \u001b[0m eta: 1:18:59  iter: 859  total_loss: 1.419  loss_cls: 0.3683  loss_box_reg: 0.5751  loss_mask: 0.2972  loss_rpn_cls: 0.08051  loss_rpn_loc: 0.1277  time: 0.6840  data_time: 0.1271  lr: 0.00042957  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:34:18 d2.utils.events]: \u001b[0m eta: 1:18:48  iter: 879  total_loss: 1.557  loss_cls: 0.3795  loss_box_reg: 0.6235  loss_mask: 0.307  loss_rpn_cls: 0.0819  loss_rpn_loc: 0.1329  time: 0.6861  data_time: 0.2723  lr: 0.00043956  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:34:32 d2.utils.events]: \u001b[0m eta: 1:18:38  iter: 899  total_loss: 1.534  loss_cls: 0.3695  loss_box_reg: 0.6082  loss_mask: 0.3114  loss_rpn_cls: 0.07818  loss_rpn_loc: 0.1417  time: 0.6866  data_time: 0.2094  lr: 0.00044955  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:34:46 d2.utils.events]: \u001b[0m eta: 1:18:29  iter: 919  total_loss: 1.453  loss_cls: 0.3529  loss_box_reg: 0.6028  loss_mask: 0.3105  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.1298  time: 0.6863  data_time: 0.1864  lr: 0.00045954  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:35:01 d2.utils.events]: \u001b[0m eta: 1:18:19  iter: 939  total_loss: 1.49  loss_cls: 0.3821  loss_box_reg: 0.5852  loss_mask: 0.3105  loss_rpn_cls: 0.07937  loss_rpn_loc: 0.1363  time: 0.6880  data_time: 0.2733  lr: 0.00046953  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:35:15 d2.utils.events]: \u001b[0m eta: 1:18:08  iter: 959  total_loss: 1.485  loss_cls: 0.3983  loss_box_reg: 0.5815  loss_mask: 0.3028  loss_rpn_cls: 0.07325  loss_rpn_loc: 0.1344  time: 0.6875  data_time: 0.1681  lr: 0.00047952  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:35:20 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:35:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:35:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:35:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:35:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:35:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:35:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0888 s/iter. Eval: 0.0605 s/iter. Total: 0.1500 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 23:35:28 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0899 s/iter. Eval: 0.0732 s/iter. Total: 0.1639 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 23:35:33 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0900 s/iter. Eval: 0.0724 s/iter. Total: 0.1632 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:35:38 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0898 s/iter. Eval: 0.0763 s/iter. Total: 0.1670 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 23:35:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.291480 (0.166306 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:35:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089561 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:35:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:35:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24730813288981396\n",
      "\u001b[32m[02/05 23:35:50 d2.utils.events]: \u001b[0m eta: 1:17:54  iter: 979  total_loss: 1.414  loss_cls: 0.3581  loss_box_reg: 0.5895  loss_mask: 0.2878  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.1306  time: 0.6883  data_time: 0.2462  lr: 0.00048951  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:36:04 d2.utils.events]: \u001b[0m eta: 1:17:43  iter: 999  total_loss: 1.574  loss_cls: 0.3884  loss_box_reg: 0.6182  loss_mask: 0.311  loss_rpn_cls: 0.07271  loss_rpn_loc: 0.1367  time: 0.6888  data_time: 0.2188  lr: 0.0004995  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:36:17 d2.utils.events]: \u001b[0m eta: 1:17:32  iter: 1019  total_loss: 1.455  loss_cls: 0.3666  loss_box_reg: 0.5729  loss_mask: 0.2861  loss_rpn_cls: 0.07339  loss_rpn_loc: 0.1212  time: 0.6874  data_time: 0.1333  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:36:29 d2.utils.events]: \u001b[0m eta: 1:17:18  iter: 1039  total_loss: 1.384  loss_cls: 0.3514  loss_box_reg: 0.5819  loss_mask: 0.2996  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.1149  time: 0.6864  data_time: 0.1693  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:36:44 d2.utils.events]: \u001b[0m eta: 1:16:58  iter: 1059  total_loss: 1.376  loss_cls: 0.3737  loss_box_reg: 0.5501  loss_mask: 0.2834  loss_rpn_cls: 0.08006  loss_rpn_loc: 0.1285  time: 0.6873  data_time: 0.2487  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:36:55 d2.utils.events]: \u001b[0m eta: 1:16:32  iter: 1079  total_loss: 1.61  loss_cls: 0.4165  loss_box_reg: 0.6269  loss_mask: 0.3179  loss_rpn_cls: 0.09431  loss_rpn_loc: 0.1455  time: 0.6852  data_time: 0.1002  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:37:09 d2.utils.events]: \u001b[0m eta: 1:16:36  iter: 1099  total_loss: 1.455  loss_cls: 0.3939  loss_box_reg: 0.5732  loss_mask: 0.2942  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.1399  time: 0.6854  data_time: 0.1934  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:37:22 d2.utils.events]: \u001b[0m eta: 1:16:13  iter: 1119  total_loss: 1.438  loss_cls: 0.3648  loss_box_reg: 0.6308  loss_mask: 0.3301  loss_rpn_cls: 0.05973  loss_rpn_loc: 0.0936  time: 0.6842  data_time: 0.1481  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:37:39 d2.utils.events]: \u001b[0m eta: 1:16:16  iter: 1139  total_loss: 1.536  loss_cls: 0.3824  loss_box_reg: 0.603  loss_mask: 0.3081  loss_rpn_cls: 0.08433  loss_rpn_loc: 0.1383  time: 0.6874  data_time: 0.3110  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:37:55 d2.utils.events]: \u001b[0m eta: 1:16:05  iter: 1159  total_loss: 1.526  loss_cls: 0.399  loss_box_reg: 0.6299  loss_mask: 0.3156  loss_rpn_cls: 0.06227  loss_rpn_loc: 0.1362  time: 0.6889  data_time: 0.2774  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:38:05 d2.utils.events]: \u001b[0m eta: 1:15:37  iter: 1179  total_loss: 1.456  loss_cls: 0.3621  loss_box_reg: 0.5972  loss_mask: 0.2952  loss_rpn_cls: 0.05563  loss_rpn_loc: 0.1257  time: 0.6864  data_time: 0.0813  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:38:19 d2.utils.events]: \u001b[0m eta: 1:15:26  iter: 1199  total_loss: 1.537  loss_cls: 0.4068  loss_box_reg: 0.6137  loss_mask: 0.3099  loss_rpn_cls: 0.06622  loss_rpn_loc: 0.1483  time: 0.6860  data_time: 0.1913  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:38:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:38:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:38:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:38:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:38:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:38:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0856 s/iter. Eval: 0.0448 s/iter. Total: 0.1310 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/05 23:38:33 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0008 s/iter. Inference: 0.0865 s/iter. Eval: 0.0646 s/iter. Total: 0.1519 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/05 23:38:38 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0008 s/iter. Inference: 0.0878 s/iter. Eval: 0.0677 s/iter. Total: 0.1563 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0919 s/iter. Eval: 0.0727 s/iter. Total: 0.1654 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 23:38:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.375382 (0.167029 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:38:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093576 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:38:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:38:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2544925689791361\n",
      "\u001b[32m[02/05 23:38:54 d2.utils.events]: \u001b[0m eta: 1:15:29  iter: 1219  total_loss: 1.481  loss_cls: 0.3796  loss_box_reg: 0.5914  loss_mask: 0.3088  loss_rpn_cls: 0.05735  loss_rpn_loc: 0.146  time: 0.6864  data_time: 0.2044  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:39:09 d2.utils.events]: \u001b[0m eta: 1:15:25  iter: 1239  total_loss: 1.337  loss_cls: 0.3537  loss_box_reg: 0.5851  loss_mask: 0.3059  loss_rpn_cls: 0.05792  loss_rpn_loc: 0.1138  time: 0.6878  data_time: 0.2437  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:39:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 23:39:26 d2.utils.events]: \u001b[0m eta: 1:15:21  iter: 1259  total_loss: 1.468  loss_cls: 0.3614  loss_box_reg: 0.5687  loss_mask: 0.3063  loss_rpn_cls: 0.06864  loss_rpn_loc: 0.112  time: 0.6902  data_time: 0.2348  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:39:38 d2.utils.events]: \u001b[0m eta: 1:15:12  iter: 1279  total_loss: 1.434  loss_cls: 0.3511  loss_box_reg: 0.574  loss_mask: 0.309  loss_rpn_cls: 0.06125  loss_rpn_loc: 0.1285  time: 0.6888  data_time: 0.1094  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:39:53 d2.utils.events]: \u001b[0m eta: 1:15:01  iter: 1299  total_loss: 1.433  loss_cls: 0.3597  loss_box_reg: 0.5779  loss_mask: 0.2933  loss_rpn_cls: 0.05301  loss_rpn_loc: 0.1225  time: 0.6898  data_time: 0.2495  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:40:05 d2.utils.events]: \u001b[0m eta: 1:14:40  iter: 1319  total_loss: 1.517  loss_cls: 0.3803  loss_box_reg: 0.5801  loss_mask: 0.306  loss_rpn_cls: 0.06626  loss_rpn_loc: 0.1473  time: 0.6884  data_time: 0.1271  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:40:18 d2.utils.events]: \u001b[0m eta: 1:14:14  iter: 1339  total_loss: 1.439  loss_cls: 0.3679  loss_box_reg: 0.5799  loss_mask: 0.3012  loss_rpn_cls: 0.07232  loss_rpn_loc: 0.1316  time: 0.6874  data_time: 0.1436  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:40:31 d2.utils.events]: \u001b[0m eta: 1:14:03  iter: 1359  total_loss: 1.511  loss_cls: 0.3881  loss_box_reg: 0.5785  loss_mask: 0.2939  loss_rpn_cls: 0.06836  loss_rpn_loc: 0.131  time: 0.6870  data_time: 0.1866  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:40:45 d2.utils.events]: \u001b[0m eta: 1:13:53  iter: 1379  total_loss: 1.528  loss_cls: 0.3913  loss_box_reg: 0.6146  loss_mask: 0.3032  loss_rpn_cls: 0.07757  loss_rpn_loc: 0.1386  time: 0.6875  data_time: 0.2279  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:40:59 d2.utils.events]: \u001b[0m eta: 1:13:48  iter: 1399  total_loss: 1.476  loss_cls: 0.4042  loss_box_reg: 0.5689  loss_mask: 0.2952  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.1498  time: 0.6873  data_time: 0.1440  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:41:14 d2.utils.events]: \u001b[0m eta: 1:13:36  iter: 1419  total_loss: 1.545  loss_cls: 0.3833  loss_box_reg: 0.6245  loss_mask: 0.3204  loss_rpn_cls: 0.05625  loss_rpn_loc: 0.1392  time: 0.6884  data_time: 0.2796  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:41:24 d2.utils.events]: \u001b[0m eta: 1:13:19  iter: 1439  total_loss: 1.26  loss_cls: 0.3168  loss_box_reg: 0.5551  loss_mask: 0.2865  loss_rpn_cls: 0.03568  loss_rpn_loc: 0.08826  time: 0.6860  data_time: 0.0744  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:41:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:41:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:41:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:41:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:41:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:41:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:41:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0943 s/iter. Eval: 0.0584 s/iter. Total: 0.1535 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 23:41:41 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0766 s/iter. Total: 0.1683 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 23:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0899 s/iter. Eval: 0.0745 s/iter. Total: 0.1653 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:41:51 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0910 s/iter. Eval: 0.0783 s/iter. Total: 0.1701 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 23:41:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.598483 (0.168952 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:41:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091246 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:41:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:41:54 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25879601418090664\n",
      "\u001b[32m[02/05 23:42:00 d2.utils.events]: \u001b[0m eta: 1:13:13  iter: 1459  total_loss: 1.596  loss_cls: 0.4188  loss_box_reg: 0.6252  loss_mask: 0.3153  loss_rpn_cls: 0.0809  loss_rpn_loc: 0.1484  time: 0.6864  data_time: 0.1669  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:42:12 d2.utils.events]: \u001b[0m eta: 1:13:00  iter: 1479  total_loss: 1.486  loss_cls: 0.3946  loss_box_reg: 0.6065  loss_mask: 0.2918  loss_rpn_cls: 0.07054  loss_rpn_loc: 0.1102  time: 0.6855  data_time: 0.1556  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:42:24 d2.utils.events]: \u001b[0m eta: 1:12:49  iter: 1499  total_loss: 1.363  loss_cls: 0.3248  loss_box_reg: 0.5638  loss_mask: 0.2976  loss_rpn_cls: 0.05192  loss_rpn_loc: 0.1375  time: 0.6838  data_time: 0.0783  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:42:35 d2.utils.events]: \u001b[0m eta: 1:12:23  iter: 1519  total_loss: 1.304  loss_cls: 0.3156  loss_box_reg: 0.5661  loss_mask: 0.2804  loss_rpn_cls: 0.03256  loss_rpn_loc: 0.1015  time: 0.6822  data_time: 0.0712  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:42:48 d2.utils.events]: \u001b[0m eta: 1:12:23  iter: 1539  total_loss: 1.505  loss_cls: 0.3879  loss_box_reg: 0.6001  loss_mask: 0.2935  loss_rpn_cls: 0.07551  loss_rpn_loc: 0.1426  time: 0.6818  data_time: 0.1241  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:42:59 d2.utils.events]: \u001b[0m eta: 1:12:10  iter: 1559  total_loss: 1.368  loss_cls: 0.3372  loss_box_reg: 0.5586  loss_mask: 0.2843  loss_rpn_cls: 0.05178  loss_rpn_loc: 0.1175  time: 0.6805  data_time: 0.0737  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:43:12 d2.utils.events]: \u001b[0m eta: 1:12:00  iter: 1579  total_loss: 1.452  loss_cls: 0.3587  loss_box_reg: 0.6046  loss_mask: 0.3095  loss_rpn_cls: 0.04524  loss_rpn_loc: 0.1322  time: 0.6796  data_time: 0.1187  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:43:23 d2.utils.events]: \u001b[0m eta: 1:11:40  iter: 1599  total_loss: 1.347  loss_cls: 0.3171  loss_box_reg: 0.5845  loss_mask: 0.2864  loss_rpn_cls: 0.03646  loss_rpn_loc: 0.1018  time: 0.6779  data_time: 0.0811  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:43:38 d2.utils.events]: \u001b[0m eta: 1:11:31  iter: 1619  total_loss: 1.603  loss_cls: 0.4241  loss_box_reg: 0.6159  loss_mask: 0.3278  loss_rpn_cls: 0.08027  loss_rpn_loc: 0.1358  time: 0.6788  data_time: 0.2426  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:43:53 d2.utils.events]: \u001b[0m eta: 1:11:17  iter: 1639  total_loss: 1.434  loss_cls: 0.3862  loss_box_reg: 0.5774  loss_mask: 0.3075  loss_rpn_cls: 0.07325  loss_rpn_loc: 0.143  time: 0.6800  data_time: 0.2762  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:44:07 d2.utils.events]: \u001b[0m eta: 1:11:10  iter: 1659  total_loss: 1.566  loss_cls: 0.4233  loss_box_reg: 0.5949  loss_mask: 0.312  loss_rpn_cls: 0.0703  loss_rpn_loc: 0.1447  time: 0.6803  data_time: 0.1922  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:44:21 d2.utils.events]: \u001b[0m eta: 1:10:58  iter: 1679  total_loss: 1.451  loss_cls: 0.3529  loss_box_reg: 0.5987  loss_mask: 0.2991  loss_rpn_cls: 0.06569  loss_rpn_loc: 0.1262  time: 0.6801  data_time: 0.1604  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:44:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:44:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:44:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:44:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:44:32 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:44:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0890 s/iter. Eval: 0.0558 s/iter. Total: 0.1454 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 23:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0919 s/iter. Eval: 0.0730 s/iter. Total: 0.1657 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 23:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0719 s/iter. Total: 0.1638 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 23:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0758 s/iter. Total: 0.1673 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 23:44:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.262627 (0.166057 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:44:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090280 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:44:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:44:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2589206528361107\n",
      "\u001b[32m[02/05 23:44:56 d2.utils.events]: \u001b[0m eta: 1:10:50  iter: 1699  total_loss: 1.438  loss_cls: 0.3883  loss_box_reg: 0.5666  loss_mask: 0.299  loss_rpn_cls: 0.06477  loss_rpn_loc: 0.1428  time: 0.6808  data_time: 0.2178  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:45:07 d2.utils.events]: \u001b[0m eta: 1:10:36  iter: 1719  total_loss: 1.437  loss_cls: 0.3591  loss_box_reg: 0.5826  loss_mask: 0.3043  loss_rpn_cls: 0.06246  loss_rpn_loc: 0.1184  time: 0.6794  data_time: 0.0733  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:45:22 d2.utils.events]: \u001b[0m eta: 1:10:30  iter: 1739  total_loss: 1.43  loss_cls: 0.3731  loss_box_reg: 0.5652  loss_mask: 0.297  loss_rpn_cls: 0.05573  loss_rpn_loc: 0.1121  time: 0.6797  data_time: 0.2037  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:45:35 d2.utils.events]: \u001b[0m eta: 1:10:24  iter: 1759  total_loss: 1.538  loss_cls: 0.3639  loss_box_reg: 0.6104  loss_mask: 0.3024  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.1313  time: 0.6798  data_time: 0.1911  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:45:48 d2.utils.events]: \u001b[0m eta: 1:10:11  iter: 1779  total_loss: 1.438  loss_cls: 0.3641  loss_box_reg: 0.5566  loss_mask: 0.2902  loss_rpn_cls: 0.06288  loss_rpn_loc: 0.1224  time: 0.6791  data_time: 0.1312  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:46:01 d2.utils.events]: \u001b[0m eta: 1:09:57  iter: 1799  total_loss: 1.478  loss_cls: 0.382  loss_box_reg: 0.5947  loss_mask: 0.3165  loss_rpn_cls: 0.05088  loss_rpn_loc: 0.1252  time: 0.6791  data_time: 0.1951  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:46:15 d2.utils.events]: \u001b[0m eta: 1:09:58  iter: 1819  total_loss: 1.451  loss_cls: 0.3673  loss_box_reg: 0.5555  loss_mask: 0.2959  loss_rpn_cls: 0.07317  loss_rpn_loc: 0.1403  time: 0.6789  data_time: 0.1390  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:46:27 d2.utils.events]: \u001b[0m eta: 1:09:53  iter: 1839  total_loss: 1.441  loss_cls: 0.3587  loss_box_reg: 0.5619  loss_mask: 0.2919  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.1271  time: 0.6781  data_time: 0.1310  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:46:40 d2.utils.events]: \u001b[0m eta: 1:09:23  iter: 1859  total_loss: 1.361  loss_cls: 0.3484  loss_box_reg: 0.5492  loss_mask: 0.2798  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.1096  time: 0.6779  data_time: 0.1759  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:46:55 d2.utils.events]: \u001b[0m eta: 1:09:18  iter: 1879  total_loss: 1.504  loss_cls: 0.3964  loss_box_reg: 0.6077  loss_mask: 0.2964  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.1505  time: 0.6787  data_time: 0.2379  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:47:09 d2.utils.events]: \u001b[0m eta: 1:09:06  iter: 1899  total_loss: 1.432  loss_cls: 0.3617  loss_box_reg: 0.6005  loss_mask: 0.3104  loss_rpn_cls: 0.05881  loss_rpn_loc: 0.1313  time: 0.6789  data_time: 0.2050  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:47:24 d2.utils.events]: \u001b[0m eta: 1:08:55  iter: 1919  total_loss: 1.437  loss_cls: 0.3614  loss_box_reg: 0.5727  loss_mask: 0.2905  loss_rpn_cls: 0.05818  loss_rpn_loc: 0.1312  time: 0.6799  data_time: 0.2764  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:47:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:47:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:47:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:47:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:47:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:47:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0886 s/iter. Eval: 0.0532 s/iter. Total: 0.1424 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 23:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0918 s/iter. Eval: 0.0711 s/iter. Total: 0.1637 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 23:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0701 s/iter. Total: 0.1618 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0744 s/iter. Total: 0.1664 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 23:47:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.258544 (0.166022 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:47:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091449 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:47:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:47:57 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2597967105444078\n",
      "\u001b[32m[02/05 23:47:59 d2.utils.events]: \u001b[0m eta: 1:08:45  iter: 1939  total_loss: 1.494  loss_cls: 0.3698  loss_box_reg: 0.6145  loss_mask: 0.305  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.1441  time: 0.6801  data_time: 0.1963  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:48:12 d2.utils.events]: \u001b[0m eta: 1:08:38  iter: 1959  total_loss: 1.5  loss_cls: 0.3845  loss_box_reg: 0.6014  loss_mask: 0.3207  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1464  time: 0.6795  data_time: 0.1421  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:48:26 d2.utils.events]: \u001b[0m eta: 1:08:36  iter: 1979  total_loss: 1.425  loss_cls: 0.3676  loss_box_reg: 0.5907  loss_mask: 0.2926  loss_rpn_cls: 0.04766  loss_rpn_loc: 0.1371  time: 0.6801  data_time: 0.2343  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:48:42 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 1999  total_loss: 1.367  loss_cls: 0.3874  loss_box_reg: 0.5514  loss_mask: 0.2825  loss_rpn_cls: 0.05089  loss_rpn_loc: 0.1343  time: 0.6809  data_time: 0.2385  lr: 0.0005  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:48:55 d2.utils.events]: \u001b[0m eta: 1:08:25  iter: 2019  total_loss: 1.419  loss_cls: 0.3536  loss_box_reg: 0.5876  loss_mask: 0.2987  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.1293  time: 0.6809  data_time: 0.1903  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:49:08 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 2039  total_loss: 1.445  loss_cls: 0.3557  loss_box_reg: 0.5741  loss_mask: 0.3033  loss_rpn_cls: 0.05226  loss_rpn_loc: 0.1403  time: 0.6803  data_time: 0.1307  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:49:19 d2.utils.events]: \u001b[0m eta: 1:08:06  iter: 2059  total_loss: 1.345  loss_cls: 0.3367  loss_box_reg: 0.5586  loss_mask: 0.3054  loss_rpn_cls: 0.0504  loss_rpn_loc: 0.09572  time: 0.6794  data_time: 0.1045  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:49:34 d2.utils.events]: \u001b[0m eta: 1:07:57  iter: 2079  total_loss: 1.388  loss_cls: 0.3622  loss_box_reg: 0.5718  loss_mask: 0.3062  loss_rpn_cls: 0.05134  loss_rpn_loc: 0.124  time: 0.6798  data_time: 0.2319  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:49:48 d2.utils.events]: \u001b[0m eta: 1:07:44  iter: 2099  total_loss: 1.373  loss_cls: 0.3326  loss_box_reg: 0.5917  loss_mask: 0.3277  loss_rpn_cls: 0.05408  loss_rpn_loc: 0.09443  time: 0.6800  data_time: 0.1870  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:50:03 d2.utils.events]: \u001b[0m eta: 1:07:40  iter: 2119  total_loss: 1.445  loss_cls: 0.3725  loss_box_reg: 0.598  loss_mask: 0.3102  loss_rpn_cls: 0.07868  loss_rpn_loc: 0.1398  time: 0.6806  data_time: 0.2330  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:50:15 d2.utils.events]: \u001b[0m eta: 1:07:17  iter: 2139  total_loss: 1.423  loss_cls: 0.3473  loss_box_reg: 0.5933  loss_mask: 0.2936  loss_rpn_cls: 0.04977  loss_rpn_loc: 0.124  time: 0.6799  data_time: 0.1126  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:50:29 d2.utils.events]: \u001b[0m eta: 1:07:09  iter: 2159  total_loss: 1.374  loss_cls: 0.3594  loss_box_reg: 0.5724  loss_mask: 0.2923  loss_rpn_cls: 0.05222  loss_rpn_loc: 0.1162  time: 0.6804  data_time: 0.2213  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:50:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:50:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:50:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:50:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:50:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:50:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0903 s/iter. Eval: 0.0558 s/iter. Total: 0.1467 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 23:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0926 s/iter. Eval: 0.0729 s/iter. Total: 0.1663 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 23:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0923 s/iter. Eval: 0.0717 s/iter. Total: 0.1649 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/05 23:50:59 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0929 s/iter. Eval: 0.0775 s/iter. Total: 0.1712 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 23:51:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.726186 (0.170053 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:51:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093016 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:51:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:51:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2602271009943735\n",
      "\u001b[32m[02/05 23:51:04 d2.utils.events]: \u001b[0m eta: 1:07:06  iter: 2179  total_loss: 1.414  loss_cls: 0.3657  loss_box_reg: 0.5828  loss_mask: 0.3136  loss_rpn_cls: 0.05871  loss_rpn_loc: 0.121  time: 0.6799  data_time: 0.1536  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:51:17 d2.utils.events]: \u001b[0m eta: 1:06:59  iter: 2199  total_loss: 1.346  loss_cls: 0.3433  loss_box_reg: 0.5623  loss_mask: 0.2758  loss_rpn_cls: 0.04195  loss_rpn_loc: 0.1257  time: 0.6800  data_time: 0.1647  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:51:30 d2.utils.events]: \u001b[0m eta: 1:06:48  iter: 2219  total_loss: 1.34  loss_cls: 0.3292  loss_box_reg: 0.5613  loss_mask: 0.2916  loss_rpn_cls: 0.04923  loss_rpn_loc: 0.1101  time: 0.6797  data_time: 0.1470  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:51:46 d2.utils.events]: \u001b[0m eta: 1:06:35  iter: 2239  total_loss: 1.415  loss_cls: 0.3423  loss_box_reg: 0.575  loss_mask: 0.3004  loss_rpn_cls: 0.0507  loss_rpn_loc: 0.1272  time: 0.6804  data_time: 0.2529  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:51:59 d2.utils.events]: \u001b[0m eta: 1:06:22  iter: 2259  total_loss: 1.434  loss_cls: 0.3721  loss_box_reg: 0.6031  loss_mask: 0.2943  loss_rpn_cls: 0.05163  loss_rpn_loc: 0.1161  time: 0.6803  data_time: 0.1730  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:52:10 d2.utils.events]: \u001b[0m eta: 1:06:15  iter: 2279  total_loss: 1.327  loss_cls: 0.3243  loss_box_reg: 0.5782  loss_mask: 0.2976  loss_rpn_cls: 0.05056  loss_rpn_loc: 0.1149  time: 0.6794  data_time: 0.0835  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:52:27 d2.utils.events]: \u001b[0m eta: 1:06:07  iter: 2299  total_loss: 1.488  loss_cls: 0.3841  loss_box_reg: 0.6165  loss_mask: 0.3082  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.1347  time: 0.6807  data_time: 0.3007  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:52:40 d2.utils.events]: \u001b[0m eta: 1:05:58  iter: 2319  total_loss: 1.398  loss_cls: 0.3564  loss_box_reg: 0.5759  loss_mask: 0.299  loss_rpn_cls: 0.04882  loss_rpn_loc: 0.119  time: 0.6803  data_time: 0.1446  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:52:54 d2.utils.events]: \u001b[0m eta: 1:05:57  iter: 2339  total_loss: 1.298  loss_cls: 0.347  loss_box_reg: 0.5366  loss_mask: 0.2866  loss_rpn_cls: 0.04827  loss_rpn_loc: 0.1239  time: 0.6805  data_time: 0.2037  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:53:05 d2.utils.events]: \u001b[0m eta: 1:05:44  iter: 2359  total_loss: 1.428  loss_cls: 0.3523  loss_box_reg: 0.5768  loss_mask: 0.2968  loss_rpn_cls: 0.05191  loss_rpn_loc: 0.1362  time: 0.6797  data_time: 0.0969  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:53:22 d2.utils.events]: \u001b[0m eta: 1:05:34  iter: 2379  total_loss: 1.425  loss_cls: 0.3535  loss_box_reg: 0.5769  loss_mask: 0.3058  loss_rpn_cls: 0.06434  loss_rpn_loc: 0.1334  time: 0.6808  data_time: 0.3125  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:53:39 d2.utils.events]: \u001b[0m eta: 1:05:24  iter: 2399  total_loss: 1.53  loss_cls: 0.4004  loss_box_reg: 0.6127  loss_mask: 0.3242  loss_rpn_cls: 0.07826  loss_rpn_loc: 0.1426  time: 0.6821  data_time: 0.3165  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:53:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:53:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:53:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:53:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:53:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:53:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0864 s/iter. Eval: 0.0550 s/iter. Total: 0.1420 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/05 23:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0905 s/iter. Eval: 0.0704 s/iter. Total: 0.1618 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/05 23:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0916 s/iter. Eval: 0.0722 s/iter. Total: 0.1646 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0932 s/iter. Eval: 0.0825 s/iter. Total: 0.1766 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/05 23:54:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.099311 (0.173270 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:54:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092045 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:54:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:54:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2686667924495307\n",
      "\u001b[32m[02/05 23:54:14 d2.utils.events]: \u001b[0m eta: 1:05:16  iter: 2419  total_loss: 1.315  loss_cls: 0.3178  loss_box_reg: 0.5307  loss_mask: 0.2809  loss_rpn_cls: 0.03961  loss_rpn_loc: 0.1042  time: 0.6821  data_time: 0.1596  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:54:25 d2.utils.events]: \u001b[0m eta: 1:05:09  iter: 2439  total_loss: 1.296  loss_cls: 0.3256  loss_box_reg: 0.5413  loss_mask: 0.2883  loss_rpn_cls: 0.03222  loss_rpn_loc: 0.1064  time: 0.6810  data_time: 0.0928  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:54:37 d2.utils.events]: \u001b[0m eta: 1:04:50  iter: 2459  total_loss: 1.349  loss_cls: 0.3611  loss_box_reg: 0.5479  loss_mask: 0.3029  loss_rpn_cls: 0.04045  loss_rpn_loc: 0.115  time: 0.6805  data_time: 0.1316  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:54:52 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 23:54:55 d2.utils.events]: \u001b[0m eta: 1:04:50  iter: 2479  total_loss: 1.462  loss_cls: 0.3793  loss_box_reg: 0.5766  loss_mask: 0.3043  loss_rpn_cls: 0.06483  loss_rpn_loc: 0.1373  time: 0.6821  data_time: 0.3277  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:55:10 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 2499  total_loss: 1.417  loss_cls: 0.3523  loss_box_reg: 0.5812  loss_mask: 0.2957  loss_rpn_cls: 0.06224  loss_rpn_loc: 0.1315  time: 0.6829  data_time: 0.2822  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:55:24 d2.utils.events]: \u001b[0m eta: 1:04:50  iter: 2519  total_loss: 1.328  loss_cls: 0.3629  loss_box_reg: 0.5536  loss_mask: 0.2828  loss_rpn_cls: 0.06565  loss_rpn_loc: 0.1177  time: 0.6829  data_time: 0.1859  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:55:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 23:55:39 d2.utils.events]: \u001b[0m eta: 1:04:33  iter: 2539  total_loss: 1.476  loss_cls: 0.3676  loss_box_reg: 0.5672  loss_mask: 0.2904  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.1287  time: 0.6834  data_time: 0.1837  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:55:53 d2.utils.events]: \u001b[0m eta: 1:04:27  iter: 2559  total_loss: 1.419  loss_cls: 0.343  loss_box_reg: 0.5828  loss_mask: 0.2916  loss_rpn_cls: 0.06101  loss_rpn_loc: 0.1357  time: 0.6834  data_time: 0.1721  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:55:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/05 23:56:07 d2.utils.events]: \u001b[0m eta: 1:04:13  iter: 2579  total_loss: 1.38  loss_cls: 0.3748  loss_box_reg: 0.5617  loss_mask: 0.3002  loss_rpn_cls: 0.04893  loss_rpn_loc: 0.1275  time: 0.6838  data_time: 0.1848  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:56:23 d2.utils.events]: \u001b[0m eta: 1:04:14  iter: 2599  total_loss: 1.49  loss_cls: 0.375  loss_box_reg: 0.5863  loss_mask: 0.2988  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.1503  time: 0.6845  data_time: 0.2651  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:56:34 d2.utils.events]: \u001b[0m eta: 1:04:00  iter: 2619  total_loss: 1.294  loss_cls: 0.3142  loss_box_reg: 0.56  loss_mask: 0.3071  loss_rpn_cls: 0.03602  loss_rpn_loc: 0.09538  time: 0.6836  data_time: 0.0651  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:56:50 d2.utils.events]: \u001b[0m eta: 1:03:53  iter: 2639  total_loss: 1.563  loss_cls: 0.3985  loss_box_reg: 0.5983  loss_mask: 0.3222  loss_rpn_cls: 0.07619  loss_rpn_loc: 0.1555  time: 0.6843  data_time: 0.2640  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:57:02 d2.utils.events]: \u001b[0m eta: 1:03:36  iter: 2659  total_loss: 1.276  loss_cls: 0.3263  loss_box_reg: 0.5327  loss_mask: 0.2792  loss_rpn_cls: 0.03221  loss_rpn_loc: 0.1046  time: 0.6838  data_time: 0.1370  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:57:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:57:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/05 23:57:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/05 23:57:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/05 23:57:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/05 23:57:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/05 23:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0926 s/iter. Eval: 0.0560 s/iter. Total: 0.1494 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/05 23:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0921 s/iter. Eval: 0.0721 s/iter. Total: 0.1650 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/05 23:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0898 s/iter. Eval: 0.0705 s/iter. Total: 0.1611 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/05 23:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0903 s/iter. Eval: 0.0754 s/iter. Total: 0.1666 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/05 23:57:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.247793 (0.165929 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:57:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090198 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/05 23:57:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/05 23:57:24 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26958252973543007\n",
      "\u001b[32m[02/05 23:57:36 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 2679  total_loss: 1.386  loss_cls: 0.3677  loss_box_reg: 0.5549  loss_mask: 0.2737  loss_rpn_cls: 0.05652  loss_rpn_loc: 0.1305  time: 0.6835  data_time: 0.1441  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:57:53 d2.utils.events]: \u001b[0m eta: 1:03:18  iter: 2699  total_loss: 1.528  loss_cls: 0.3846  loss_box_reg: 0.5902  loss_mask: 0.3027  loss_rpn_cls: 0.06408  loss_rpn_loc: 0.1549  time: 0.6847  data_time: 0.3046  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:58:06 d2.utils.events]: \u001b[0m eta: 1:03:05  iter: 2719  total_loss: 1.446  loss_cls: 0.3654  loss_box_reg: 0.5692  loss_mask: 0.2942  loss_rpn_cls: 0.05911  loss_rpn_loc: 0.1303  time: 0.6844  data_time: 0.1663  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:58:20 d2.utils.events]: \u001b[0m eta: 1:02:53  iter: 2739  total_loss: 1.397  loss_cls: 0.3326  loss_box_reg: 0.5478  loss_mask: 0.3079  loss_rpn_cls: 0.06022  loss_rpn_loc: 0.1138  time: 0.6846  data_time: 0.2162  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:58:34 d2.utils.events]: \u001b[0m eta: 1:02:44  iter: 2759  total_loss: 1.401  loss_cls: 0.3697  loss_box_reg: 0.5632  loss_mask: 0.2989  loss_rpn_cls: 0.05543  loss_rpn_loc: 0.1399  time: 0.6847  data_time: 0.1974  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:58:47 d2.utils.events]: \u001b[0m eta: 1:02:40  iter: 2779  total_loss: 1.367  loss_cls: 0.3457  loss_box_reg: 0.5633  loss_mask: 0.2981  loss_rpn_cls: 0.04468  loss_rpn_loc: 0.1314  time: 0.6844  data_time: 0.1329  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:59:01 d2.utils.events]: \u001b[0m eta: 1:02:30  iter: 2799  total_loss: 1.244  loss_cls: 0.3204  loss_box_reg: 0.5254  loss_mask: 0.2771  loss_rpn_cls: 0.04573  loss_rpn_loc: 0.108  time: 0.6847  data_time: 0.2411  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:59:13 d2.utils.events]: \u001b[0m eta: 1:02:12  iter: 2819  total_loss: 1.415  loss_cls: 0.3496  loss_box_reg: 0.5809  loss_mask: 0.3008  loss_rpn_cls: 0.06096  loss_rpn_loc: 0.1106  time: 0.6841  data_time: 0.1162  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:59:25 d2.utils.events]: \u001b[0m eta: 1:01:57  iter: 2839  total_loss: 1.412  loss_cls: 0.3542  loss_box_reg: 0.5621  loss_mask: 0.2856  loss_rpn_cls: 0.04749  loss_rpn_loc: 0.1282  time: 0.6833  data_time: 0.0914  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:59:37 d2.utils.events]: \u001b[0m eta: 1:01:52  iter: 2859  total_loss: 1.434  loss_cls: 0.3674  loss_box_reg: 0.5634  loss_mask: 0.3007  loss_rpn_cls: 0.05115  loss_rpn_loc: 0.131  time: 0.6829  data_time: 0.1353  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/05 23:59:49 d2.utils.events]: \u001b[0m eta: 1:01:33  iter: 2879  total_loss: 1.329  loss_cls: 0.334  loss_box_reg: 0.5717  loss_mask: 0.2917  loss_rpn_cls: 0.05029  loss_rpn_loc: 0.09351  time: 0.6821  data_time: 0.0732  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:00:03 d2.utils.events]: \u001b[0m eta: 1:01:23  iter: 2899  total_loss: 1.388  loss_cls: 0.3575  loss_box_reg: 0.5682  loss_mask: 0.2912  loss_rpn_cls: 0.06587  loss_rpn_loc: 0.1292  time: 0.6823  data_time: 0.2180  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:00:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:00:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:00:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:00:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:00:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:00:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0887 s/iter. Eval: 0.0531 s/iter. Total: 0.1425 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:00:13 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0693 s/iter. Total: 0.1605 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 00:00:18 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0919 s/iter. Eval: 0.0698 s/iter. Total: 0.1625 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:00:23 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0921 s/iter. Eval: 0.0747 s/iter. Total: 0.1676 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:00:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.329971 (0.166638 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:00:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091806 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:00:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:00:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2710081815198503\n",
      "\u001b[32m[02/06 00:00:36 d2.utils.events]: \u001b[0m eta: 1:01:07  iter: 2919  total_loss: 1.376  loss_cls: 0.3125  loss_box_reg: 0.5714  loss_mask: 0.3016  loss_rpn_cls: 0.04359  loss_rpn_loc: 0.1014  time: 0.6817  data_time: 0.1091  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:00:51 d2.utils.events]: \u001b[0m eta: 1:00:57  iter: 2939  total_loss: 1.419  loss_cls: 0.3625  loss_box_reg: 0.5542  loss_mask: 0.3006  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.1363  time: 0.6821  data_time: 0.2442  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:01:03 d2.utils.events]: \u001b[0m eta: 1:00:44  iter: 2959  total_loss: 1.348  loss_cls: 0.331  loss_box_reg: 0.5669  loss_mask: 0.2887  loss_rpn_cls: 0.04546  loss_rpn_loc: 0.1193  time: 0.6818  data_time: 0.1658  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:01:17 d2.utils.events]: \u001b[0m eta: 1:00:32  iter: 2979  total_loss: 1.459  loss_cls: 0.3462  loss_box_reg: 0.5905  loss_mask: 0.3019  loss_rpn_cls: 0.05147  loss_rpn_loc: 0.152  time: 0.6818  data_time: 0.1919  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:01:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:01:33 d2.utils.events]: \u001b[0m eta: 1:00:16  iter: 2999  total_loss: 1.426  loss_cls: 0.3597  loss_box_reg: 0.5966  loss_mask: 0.3045  loss_rpn_cls: 0.04737  loss_rpn_loc: 0.1214  time: 0.6825  data_time: 0.2094  lr: 0.0004  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:01:46 d2.utils.events]: \u001b[0m eta: 1:00:01  iter: 3019  total_loss: 1.392  loss_cls: 0.3671  loss_box_reg: 0.5593  loss_mask: 0.3022  loss_rpn_cls: 0.05442  loss_rpn_loc: 0.1217  time: 0.6825  data_time: 0.2130  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:01:58 d2.utils.events]: \u001b[0m eta: 0:59:50  iter: 3039  total_loss: 1.284  loss_cls: 0.343  loss_box_reg: 0.5188  loss_mask: 0.2728  loss_rpn_cls: 0.04335  loss_rpn_loc: 0.1104  time: 0.6817  data_time: 0.0930  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:02:11 d2.utils.events]: \u001b[0m eta: 0:59:40  iter: 3059  total_loss: 1.453  loss_cls: 0.376  loss_box_reg: 0.5711  loss_mask: 0.2998  loss_rpn_cls: 0.05747  loss_rpn_loc: 0.1389  time: 0.6817  data_time: 0.1924  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:02:23 d2.utils.events]: \u001b[0m eta: 0:59:30  iter: 3079  total_loss: 1.422  loss_cls: 0.3459  loss_box_reg: 0.5571  loss_mask: 0.2981  loss_rpn_cls: 0.06355  loss_rpn_loc: 0.1304  time: 0.6812  data_time: 0.1244  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:02:38 d2.utils.events]: \u001b[0m eta: 0:59:19  iter: 3099  total_loss: 1.397  loss_cls: 0.3522  loss_box_reg: 0.5563  loss_mask: 0.2885  loss_rpn_cls: 0.04479  loss_rpn_loc: 0.1342  time: 0.6815  data_time: 0.2162  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:02:54 d2.utils.events]: \u001b[0m eta: 0:59:17  iter: 3119  total_loss: 1.554  loss_cls: 0.3999  loss_box_reg: 0.5682  loss_mask: 0.3023  loss_rpn_cls: 0.08116  loss_rpn_loc: 0.1409  time: 0.6823  data_time: 0.3035  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:03:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:03:10 d2.utils.events]: \u001b[0m eta: 0:58:59  iter: 3139  total_loss: 1.371  loss_cls: 0.3293  loss_box_reg: 0.5374  loss_mask: 0.2934  loss_rpn_cls: 0.06297  loss_rpn_loc: 0.1223  time: 0.6829  data_time: 0.2137  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:03:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:03:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:03:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:03:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:03:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:03:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0866 s/iter. Eval: 0.0549 s/iter. Total: 0.1421 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0893 s/iter. Eval: 0.0695 s/iter. Total: 0.1596 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 00:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0884 s/iter. Eval: 0.0705 s/iter. Total: 0.1598 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0887 s/iter. Eval: 0.0745 s/iter. Total: 0.1640 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/06 00:03:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.878113 (0.162742 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:03:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088342 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:03:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.268228747663459\n",
      "\u001b[32m[02/06 00:03:42 d2.utils.events]: \u001b[0m eta: 0:58:48  iter: 3159  total_loss: 1.409  loss_cls: 0.342  loss_box_reg: 0.5681  loss_mask: 0.303  loss_rpn_cls: 0.0574  loss_rpn_loc: 0.1407  time: 0.6823  data_time: 0.0934  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:03:54 d2.utils.events]: \u001b[0m eta: 0:58:45  iter: 3179  total_loss: 1.431  loss_cls: 0.3473  loss_box_reg: 0.5785  loss_mask: 0.2954  loss_rpn_cls: 0.05063  loss_rpn_loc: 0.1293  time: 0.6820  data_time: 0.1288  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:04:05 d2.utils.events]: \u001b[0m eta: 0:58:28  iter: 3199  total_loss: 1.247  loss_cls: 0.2896  loss_box_reg: 0.5332  loss_mask: 0.2919  loss_rpn_cls: 0.02825  loss_rpn_loc: 0.1052  time: 0.6811  data_time: 0.0510  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:04:20 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 3219  total_loss: 1.353  loss_cls: 0.3481  loss_box_reg: 0.5273  loss_mask: 0.2926  loss_rpn_cls: 0.05909  loss_rpn_loc: 0.1158  time: 0.6813  data_time: 0.2086  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:04:35 d2.utils.events]: \u001b[0m eta: 0:58:14  iter: 3239  total_loss: 1.372  loss_cls: 0.3452  loss_box_reg: 0.549  loss_mask: 0.286  loss_rpn_cls: 0.06035  loss_rpn_loc: 0.1388  time: 0.6817  data_time: 0.2117  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:04:50 d2.utils.events]: \u001b[0m eta: 0:58:06  iter: 3259  total_loss: 1.401  loss_cls: 0.334  loss_box_reg: 0.5753  loss_mask: 0.3149  loss_rpn_cls: 0.04374  loss_rpn_loc: 0.1185  time: 0.6821  data_time: 0.2499  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:05:06 d2.utils.events]: \u001b[0m eta: 0:57:58  iter: 3279  total_loss: 1.431  loss_cls: 0.398  loss_box_reg: 0.5675  loss_mask: 0.2902  loss_rpn_cls: 0.05419  loss_rpn_loc: 0.1245  time: 0.6828  data_time: 0.2991  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:05:19 d2.utils.events]: \u001b[0m eta: 0:57:45  iter: 3299  total_loss: 1.412  loss_cls: 0.3721  loss_box_reg: 0.5565  loss_mask: 0.2989  loss_rpn_cls: 0.06173  loss_rpn_loc: 0.1223  time: 0.6829  data_time: 0.1921  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:05:32 d2.utils.events]: \u001b[0m eta: 0:57:32  iter: 3319  total_loss: 1.373  loss_cls: 0.3393  loss_box_reg: 0.5721  loss_mask: 0.2938  loss_rpn_cls: 0.04281  loss_rpn_loc: 0.09728  time: 0.6827  data_time: 0.1753  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:05:44 d2.utils.events]: \u001b[0m eta: 0:57:16  iter: 3339  total_loss: 1.443  loss_cls: 0.3449  loss_box_reg: 0.5726  loss_mask: 0.3034  loss_rpn_cls: 0.04389  loss_rpn_loc: 0.1268  time: 0.6820  data_time: 0.0836  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:05:58 d2.utils.events]: \u001b[0m eta: 0:57:08  iter: 3359  total_loss: 1.395  loss_cls: 0.3535  loss_box_reg: 0.5879  loss_mask: 0.2858  loss_rpn_cls: 0.05264  loss_rpn_loc: 0.1169  time: 0.6823  data_time: 0.2345  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:06:10 d2.utils.events]: \u001b[0m eta: 0:56:54  iter: 3379  total_loss: 1.325  loss_cls: 0.3327  loss_box_reg: 0.545  loss_mask: 0.2949  loss_rpn_cls: 0.03934  loss_rpn_loc: 0.1011  time: 0.6816  data_time: 0.0919  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:06:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:06:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:06:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:06:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:06:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:06:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0905 s/iter. Eval: 0.0574 s/iter. Total: 0.1486 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 00:06:23 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0729 s/iter. Total: 0.1651 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0717 s/iter. Total: 0.1633 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0758 s/iter. Total: 0.1679 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:06:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.391919 (0.167172 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:06:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091077 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:06:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:06:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2693748470823016\n",
      "\u001b[32m[02/06 00:06:45 d2.utils.events]: \u001b[0m eta: 0:56:40  iter: 3399  total_loss: 1.343  loss_cls: 0.3352  loss_box_reg: 0.5409  loss_mask: 0.2771  loss_rpn_cls: 0.05355  loss_rpn_loc: 0.1199  time: 0.6817  data_time: 0.1906  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:06:56 d2.utils.events]: \u001b[0m eta: 0:56:23  iter: 3419  total_loss: 1.243  loss_cls: 0.283  loss_box_reg: 0.5522  loss_mask: 0.2792  loss_rpn_cls: 0.04212  loss_rpn_loc: 0.08877  time: 0.6809  data_time: 0.0723  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:07:11 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 3439  total_loss: 1.385  loss_cls: 0.3556  loss_box_reg: 0.5717  loss_mask: 0.3008  loss_rpn_cls: 0.05685  loss_rpn_loc: 0.1361  time: 0.6812  data_time: 0.2472  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:07:27 d2.utils.events]: \u001b[0m eta: 0:56:12  iter: 3459  total_loss: 1.41  loss_cls: 0.3425  loss_box_reg: 0.5582  loss_mask: 0.3004  loss_rpn_cls: 0.05861  loss_rpn_loc: 0.1313  time: 0.6820  data_time: 0.3444  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:07:40 d2.utils.events]: \u001b[0m eta: 0:55:59  iter: 3479  total_loss: 1.427  loss_cls: 0.3659  loss_box_reg: 0.5988  loss_mask: 0.3136  loss_rpn_cls: 0.0471  loss_rpn_loc: 0.125  time: 0.6819  data_time: 0.1572  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:07:55 d2.utils.events]: \u001b[0m eta: 0:55:48  iter: 3499  total_loss: 1.419  loss_cls: 0.3565  loss_box_reg: 0.5657  loss_mask: 0.2964  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.144  time: 0.6823  data_time: 0.2670  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:08:08 d2.utils.events]: \u001b[0m eta: 0:55:38  iter: 3519  total_loss: 1.207  loss_cls: 0.2951  loss_box_reg: 0.5386  loss_mask: 0.2777  loss_rpn_cls: 0.0427  loss_rpn_loc: 0.08862  time: 0.6821  data_time: 0.1377  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:08:21 d2.utils.events]: \u001b[0m eta: 0:55:27  iter: 3539  total_loss: 1.439  loss_cls: 0.3575  loss_box_reg: 0.5773  loss_mask: 0.3061  loss_rpn_cls: 0.04678  loss_rpn_loc: 0.1155  time: 0.6819  data_time: 0.1396  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:08:38 d2.utils.events]: \u001b[0m eta: 0:55:15  iter: 3559  total_loss: 1.454  loss_cls: 0.3535  loss_box_reg: 0.5599  loss_mask: 0.2982  loss_rpn_cls: 0.064  loss_rpn_loc: 0.1385  time: 0.6827  data_time: 0.3172  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:08:50 d2.utils.events]: \u001b[0m eta: 0:55:08  iter: 3579  total_loss: 1.377  loss_cls: 0.3303  loss_box_reg: 0.5873  loss_mask: 0.2857  loss_rpn_cls: 0.04964  loss_rpn_loc: 0.125  time: 0.6824  data_time: 0.1224  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:09:04 d2.utils.events]: \u001b[0m eta: 0:54:54  iter: 3599  total_loss: 1.438  loss_cls: 0.3471  loss_box_reg: 0.5747  loss_mask: 0.3095  loss_rpn_cls: 0.0505  loss_rpn_loc: 0.1351  time: 0.6825  data_time: 0.2061  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:09:16 d2.utils.events]: \u001b[0m eta: 0:54:41  iter: 3619  total_loss: 1.311  loss_cls: 0.3329  loss_box_reg: 0.5416  loss_mask: 0.3058  loss_rpn_cls: 0.04581  loss_rpn_loc: 0.1187  time: 0.6820  data_time: 0.1033  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:09:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:09:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:09:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:09:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:09:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:09:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0897 s/iter. Eval: 0.0545 s/iter. Total: 0.1448 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0916 s/iter. Eval: 0.0732 s/iter. Total: 0.1657 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:09:36 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0910 s/iter. Eval: 0.0718 s/iter. Total: 0.1637 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:09:41 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0915 s/iter. Eval: 0.0769 s/iter. Total: 0.1693 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:09:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.534766 (0.168403 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:09:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091457 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:09:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:09:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2694586920561793\n",
      "\u001b[32m[02/06 00:09:51 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 3639  total_loss: 1.362  loss_cls: 0.318  loss_box_reg: 0.6016  loss_mask: 0.3032  loss_rpn_cls: 0.04426  loss_rpn_loc: 0.1138  time: 0.6819  data_time: 0.1674  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:10:04 d2.utils.events]: \u001b[0m eta: 0:54:17  iter: 3659  total_loss: 1.407  loss_cls: 0.3388  loss_box_reg: 0.5766  loss_mask: 0.2951  loss_rpn_cls: 0.06065  loss_rpn_loc: 0.1248  time: 0.6818  data_time: 0.1789  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:10:21 d2.utils.events]: \u001b[0m eta: 0:54:06  iter: 3679  total_loss: 1.45  loss_cls: 0.3684  loss_box_reg: 0.5605  loss_mask: 0.3018  loss_rpn_cls: 0.06568  loss_rpn_loc: 0.1504  time: 0.6827  data_time: 0.3339  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:10:39 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 3699  total_loss: 1.547  loss_cls: 0.3603  loss_box_reg: 0.5995  loss_mask: 0.3204  loss_rpn_cls: 0.05992  loss_rpn_loc: 0.149  time: 0.6839  data_time: 0.3854  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:10:54 d2.utils.events]: \u001b[0m eta: 0:53:48  iter: 3719  total_loss: 1.53  loss_cls: 0.3782  loss_box_reg: 0.5925  loss_mask: 0.3109  loss_rpn_cls: 0.05269  loss_rpn_loc: 0.1468  time: 0.6842  data_time: 0.2351  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:11:08 d2.utils.events]: \u001b[0m eta: 0:53:34  iter: 3739  total_loss: 1.355  loss_cls: 0.3564  loss_box_reg: 0.5533  loss_mask: 0.2812  loss_rpn_cls: 0.05271  loss_rpn_loc: 0.1057  time: 0.6845  data_time: 0.2381  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:11:19 d2.utils.events]: \u001b[0m eta: 0:53:19  iter: 3759  total_loss: 1.293  loss_cls: 0.3281  loss_box_reg: 0.5402  loss_mask: 0.2923  loss_rpn_cls: 0.04164  loss_rpn_loc: 0.09965  time: 0.6837  data_time: 0.0635  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:11:32 d2.utils.events]: \u001b[0m eta: 0:53:03  iter: 3779  total_loss: 1.412  loss_cls: 0.3436  loss_box_reg: 0.5702  loss_mask: 0.2924  loss_rpn_cls: 0.05237  loss_rpn_loc: 0.1381  time: 0.6835  data_time: 0.1646  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:11:43 d2.utils.events]: \u001b[0m eta: 0:52:49  iter: 3799  total_loss: 1.328  loss_cls: 0.3144  loss_box_reg: 0.5736  loss_mask: 0.2942  loss_rpn_cls: 0.0315  loss_rpn_loc: 0.1009  time: 0.6828  data_time: 0.0786  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:11:56 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 3819  total_loss: 1.308  loss_cls: 0.3053  loss_box_reg: 0.5475  loss_mask: 0.2908  loss_rpn_cls: 0.03704  loss_rpn_loc: 0.1204  time: 0.6826  data_time: 0.1295  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:12:07 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 3839  total_loss: 1.44  loss_cls: 0.351  loss_box_reg: 0.5471  loss_mask: 0.303  loss_rpn_cls: 0.04865  loss_rpn_loc: 0.1151  time: 0.6819  data_time: 0.0665  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:12:20 d2.utils.events]: \u001b[0m eta: 0:52:22  iter: 3859  total_loss: 1.336  loss_cls: 0.338  loss_box_reg: 0.5419  loss_mask: 0.2747  loss_rpn_cls: 0.05346  loss_rpn_loc: 0.1288  time: 0.6817  data_time: 0.1643  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:12:28 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:12:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:12:28 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:12:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:12:29 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:12:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:12:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0895 s/iter. Eval: 0.0583 s/iter. Total: 0.1484 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 00:12:36 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0917 s/iter. Eval: 0.0750 s/iter. Total: 0.1676 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:12:41 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0735 s/iter. Total: 0.1656 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:12:46 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0918 s/iter. Eval: 0.0788 s/iter. Total: 0.1714 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:12:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.704822 (0.169869 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:12:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:12:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:12:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2523872502452251\n",
      "\u001b[32m[02/06 00:12:54 d2.utils.events]: \u001b[0m eta: 0:52:12  iter: 3879  total_loss: 1.437  loss_cls: 0.3572  loss_box_reg: 0.5803  loss_mask: 0.2989  loss_rpn_cls: 0.05822  loss_rpn_loc: 0.1235  time: 0.6815  data_time: 0.1533  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:13:08 d2.utils.events]: \u001b[0m eta: 0:52:01  iter: 3899  total_loss: 1.436  loss_cls: 0.3723  loss_box_reg: 0.5892  loss_mask: 0.2978  loss_rpn_cls: 0.05862  loss_rpn_loc: 0.1345  time: 0.6816  data_time: 0.2041  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:13:21 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 3919  total_loss: 1.409  loss_cls: 0.3419  loss_box_reg: 0.5631  loss_mask: 0.2951  loss_rpn_cls: 0.05048  loss_rpn_loc: 0.1202  time: 0.6813  data_time: 0.1417  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:13:32 d2.utils.events]: \u001b[0m eta: 0:51:37  iter: 3939  total_loss: 1.342  loss_cls: 0.3244  loss_box_reg: 0.5401  loss_mask: 0.2839  loss_rpn_cls: 0.03884  loss_rpn_loc: 0.0986  time: 0.6806  data_time: 0.0808  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:13:48 d2.utils.events]: \u001b[0m eta: 0:51:27  iter: 3959  total_loss: 1.41  loss_cls: 0.349  loss_box_reg: 0.5804  loss_mask: 0.3006  loss_rpn_cls: 0.0463  loss_rpn_loc: 0.1243  time: 0.6813  data_time: 0.3022  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:14:02 d2.utils.events]: \u001b[0m eta: 0:51:19  iter: 3979  total_loss: 1.439  loss_cls: 0.3567  loss_box_reg: 0.59  loss_mask: 0.2987  loss_rpn_cls: 0.0455  loss_rpn_loc: 0.1337  time: 0.6815  data_time: 0.2201  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:14:15 d2.utils.events]: \u001b[0m eta: 0:51:15  iter: 3999  total_loss: 1.376  loss_cls: 0.3492  loss_box_reg: 0.553  loss_mask: 0.2954  loss_rpn_cls: 0.05331  loss_rpn_loc: 0.1303  time: 0.6814  data_time: 0.1521  lr: 0.00032  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:14:30 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 4019  total_loss: 1.306  loss_cls: 0.3336  loss_box_reg: 0.5589  loss_mask: 0.2811  loss_rpn_cls: 0.05202  loss_rpn_loc: 0.1163  time: 0.6817  data_time: 0.2405  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:14:43 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 4039  total_loss: 1.372  loss_cls: 0.3332  loss_box_reg: 0.5558  loss_mask: 0.305  loss_rpn_cls: 0.05307  loss_rpn_loc: 0.09704  time: 0.6815  data_time: 0.1558  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:14:57 d2.utils.events]: \u001b[0m eta: 0:50:51  iter: 4059  total_loss: 1.391  loss_cls: 0.3546  loss_box_reg: 0.5717  loss_mask: 0.2815  loss_rpn_cls: 0.03483  loss_rpn_loc: 0.1227  time: 0.6816  data_time: 0.2025  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:15:10 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 4079  total_loss: 1.414  loss_cls: 0.3543  loss_box_reg: 0.5749  loss_mask: 0.2951  loss_rpn_cls: 0.05082  loss_rpn_loc: 0.1361  time: 0.6814  data_time: 0.1506  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:15:23 d2.utils.events]: \u001b[0m eta: 0:50:33  iter: 4099  total_loss: 1.403  loss_cls: 0.3466  loss_box_reg: 0.5563  loss_mask: 0.3013  loss_rpn_cls: 0.04661  loss_rpn_loc: 0.1252  time: 0.6813  data_time: 0.1597  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:15:34 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:15:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:15:34 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:15:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:15:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:15:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0905 s/iter. Eval: 0.0534 s/iter. Total: 0.1445 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0691 s/iter. Total: 0.1607 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 00:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0705 s/iter. Total: 0.1616 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0746 s/iter. Total: 0.1662 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/06 00:15:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.157798 (0.165153 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:15:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090688 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:15:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:15:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2718255755260575\n",
      "\u001b[32m[02/06 00:15:59 d2.utils.events]: \u001b[0m eta: 0:50:18  iter: 4119  total_loss: 1.373  loss_cls: 0.3552  loss_box_reg: 0.5441  loss_mask: 0.2948  loss_rpn_cls: 0.05182  loss_rpn_loc: 0.1367  time: 0.6816  data_time: 0.2511  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:16:11 d2.utils.events]: \u001b[0m eta: 0:50:11  iter: 4139  total_loss: 1.38  loss_cls: 0.3399  loss_box_reg: 0.5461  loss_mask: 0.2866  loss_rpn_cls: 0.06243  loss_rpn_loc: 0.1274  time: 0.6811  data_time: 0.0979  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:16:25 d2.utils.events]: \u001b[0m eta: 0:50:04  iter: 4159  total_loss: 1.443  loss_cls: 0.3653  loss_box_reg: 0.5879  loss_mask: 0.3098  loss_rpn_cls: 0.06215  loss_rpn_loc: 0.1294  time: 0.6814  data_time: 0.2230  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:16:39 d2.utils.events]: \u001b[0m eta: 0:49:54  iter: 4179  total_loss: 1.488  loss_cls: 0.339  loss_box_reg: 0.5727  loss_mask: 0.3227  loss_rpn_cls: 0.04638  loss_rpn_loc: 0.1119  time: 0.6813  data_time: 0.1700  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:16:53 d2.utils.events]: \u001b[0m eta: 0:49:45  iter: 4199  total_loss: 1.496  loss_cls: 0.3942  loss_box_reg: 0.5854  loss_mask: 0.303  loss_rpn_cls: 0.05818  loss_rpn_loc: 0.1473  time: 0.6814  data_time: 0.1898  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:17:07 d2.utils.events]: \u001b[0m eta: 0:49:34  iter: 4219  total_loss: 1.254  loss_cls: 0.3161  loss_box_reg: 0.5389  loss_mask: 0.2842  loss_rpn_cls: 0.03527  loss_rpn_loc: 0.1071  time: 0.6816  data_time: 0.2499  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:17:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:17:24 d2.utils.events]: \u001b[0m eta: 0:49:21  iter: 4239  total_loss: 1.397  loss_cls: 0.3559  loss_box_reg: 0.5625  loss_mask: 0.2937  loss_rpn_cls: 0.04354  loss_rpn_loc: 0.1232  time: 0.6824  data_time: 0.2602  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:17:36 d2.utils.events]: \u001b[0m eta: 0:49:08  iter: 4259  total_loss: 1.303  loss_cls: 0.3263  loss_box_reg: 0.5526  loss_mask: 0.2778  loss_rpn_cls: 0.04842  loss_rpn_loc: 0.1204  time: 0.6821  data_time: 0.1287  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:17:49 d2.utils.events]: \u001b[0m eta: 0:48:54  iter: 4279  total_loss: 1.333  loss_cls: 0.3421  loss_box_reg: 0.5756  loss_mask: 0.2972  loss_rpn_cls: 0.05566  loss_rpn_loc: 0.1127  time: 0.6819  data_time: 0.1786  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:18:03 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 4299  total_loss: 1.382  loss_cls: 0.3441  loss_box_reg: 0.5748  loss_mask: 0.2935  loss_rpn_cls: 0.05031  loss_rpn_loc: 0.1164  time: 0.6819  data_time: 0.1966  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:18:17 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 4319  total_loss: 1.511  loss_cls: 0.3751  loss_box_reg: 0.5848  loss_mask: 0.3061  loss_rpn_cls: 0.07197  loss_rpn_loc: 0.1437  time: 0.6820  data_time: 0.2012  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:18:30 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 4339  total_loss: 1.339  loss_cls: 0.3284  loss_box_reg: 0.5318  loss_mask: 0.2957  loss_rpn_cls: 0.03976  loss_rpn_loc: 0.09093  time: 0.6819  data_time: 0.1779  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:18:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:18:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:18:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:18:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:18:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:18:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:18:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0892 s/iter. Eval: 0.0551 s/iter. Total: 0.1449 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:18:48 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0924 s/iter. Eval: 0.0734 s/iter. Total: 0.1667 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:18:53 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0935 s/iter. Eval: 0.0733 s/iter. Total: 0.1677 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:18:58 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0779 s/iter. Total: 0.1718 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:19:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.686486 (0.169711 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:19:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092687 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:19:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:19:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2688631743275465\n",
      "\u001b[32m[02/06 00:19:04 d2.utils.events]: \u001b[0m eta: 0:48:13  iter: 4359  total_loss: 1.427  loss_cls: 0.3565  loss_box_reg: 0.5728  loss_mask: 0.3033  loss_rpn_cls: 0.05245  loss_rpn_loc: 0.136  time: 0.6816  data_time: 0.1305  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:19:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:19:21 d2.utils.events]: \u001b[0m eta: 0:48:05  iter: 4379  total_loss: 1.507  loss_cls: 0.3855  loss_box_reg: 0.5687  loss_mask: 0.3049  loss_rpn_cls: 0.05682  loss_rpn_loc: 0.1286  time: 0.6825  data_time: 0.2836  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:19:37 d2.utils.events]: \u001b[0m eta: 0:47:55  iter: 4399  total_loss: 1.367  loss_cls: 0.3265  loss_box_reg: 0.5683  loss_mask: 0.2937  loss_rpn_cls: 0.0502  loss_rpn_loc: 0.1401  time: 0.6829  data_time: 0.2679  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:19:49 d2.utils.events]: \u001b[0m eta: 0:47:49  iter: 4419  total_loss: 1.37  loss_cls: 0.324  loss_box_reg: 0.5475  loss_mask: 0.2914  loss_rpn_cls: 0.04357  loss_rpn_loc: 0.1083  time: 0.6825  data_time: 0.1140  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:20:02 d2.utils.events]: \u001b[0m eta: 0:47:37  iter: 4439  total_loss: 1.322  loss_cls: 0.335  loss_box_reg: 0.5469  loss_mask: 0.2843  loss_rpn_cls: 0.04662  loss_rpn_loc: 0.1039  time: 0.6823  data_time: 0.1577  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:20:17 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 4459  total_loss: 1.4  loss_cls: 0.347  loss_box_reg: 0.5498  loss_mask: 0.3063  loss_rpn_cls: 0.05111  loss_rpn_loc: 0.1234  time: 0.6827  data_time: 0.2740  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:20:30 d2.utils.events]: \u001b[0m eta: 0:47:13  iter: 4479  total_loss: 1.376  loss_cls: 0.3238  loss_box_reg: 0.5379  loss_mask: 0.2822  loss_rpn_cls: 0.03886  loss_rpn_loc: 0.1083  time: 0.6825  data_time: 0.1619  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:20:43 d2.utils.events]: \u001b[0m eta: 0:47:01  iter: 4499  total_loss: 1.327  loss_cls: 0.3581  loss_box_reg: 0.5568  loss_mask: 0.2702  loss_rpn_cls: 0.04484  loss_rpn_loc: 0.102  time: 0.6824  data_time: 0.1480  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:20:58 d2.utils.events]: \u001b[0m eta: 0:46:51  iter: 4519  total_loss: 1.376  loss_cls: 0.3464  loss_box_reg: 0.5668  loss_mask: 0.3108  loss_rpn_cls: 0.04888  loss_rpn_loc: 0.1044  time: 0.6827  data_time: 0.2509  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:21:10 d2.utils.events]: \u001b[0m eta: 0:46:40  iter: 4539  total_loss: 1.293  loss_cls: 0.3177  loss_box_reg: 0.5458  loss_mask: 0.2776  loss_rpn_cls: 0.04716  loss_rpn_loc: 0.1099  time: 0.6824  data_time: 0.1011  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:21:25 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 4559  total_loss: 1.362  loss_cls: 0.3449  loss_box_reg: 0.5642  loss_mask: 0.2943  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.1191  time: 0.6826  data_time: 0.2095  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:21:40 d2.utils.events]: \u001b[0m eta: 0:46:20  iter: 4579  total_loss: 1.416  loss_cls: 0.3547  loss_box_reg: 0.582  loss_mask: 0.297  loss_rpn_cls: 0.04355  loss_rpn_loc: 0.1343  time: 0.6830  data_time: 0.2813  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:21:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:21:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:21:53 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:21:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:21:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:21:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0869 s/iter. Eval: 0.0548 s/iter. Total: 0.1424 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0716 s/iter. Total: 0.1613 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 00:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0008 s/iter. Inference: 0.0886 s/iter. Eval: 0.0722 s/iter. Total: 0.1616 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 103/121. Dataloading: 0.0008 s/iter. Inference: 0.0889 s/iter. Eval: 0.0758 s/iter. Total: 0.1656 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/06 00:22:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.294547 (0.166332 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:22:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089687 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:22:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:22:14 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2719017653647684\n",
      "\u001b[32m[02/06 00:22:15 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 4599  total_loss: 1.423  loss_cls: 0.3513  loss_box_reg: 0.5524  loss_mask: 0.2934  loss_rpn_cls: 0.05828  loss_rpn_loc: 0.1302  time: 0.6830  data_time: 0.2075  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:22:28 d2.utils.events]: \u001b[0m eta: 0:45:59  iter: 4619  total_loss: 1.35  loss_cls: 0.3194  loss_box_reg: 0.5463  loss_mask: 0.2847  loss_rpn_cls: 0.04811  loss_rpn_loc: 0.1131  time: 0.6828  data_time: 0.1303  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:22:41 d2.utils.events]: \u001b[0m eta: 0:45:49  iter: 4639  total_loss: 1.327  loss_cls: 0.3253  loss_box_reg: 0.5517  loss_mask: 0.3054  loss_rpn_cls: 0.04686  loss_rpn_loc: 0.1147  time: 0.6827  data_time: 0.1730  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:22:54 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:23:00 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 4659  total_loss: 1.474  loss_cls: 0.378  loss_box_reg: 0.5899  loss_mask: 0.3186  loss_rpn_cls: 0.06179  loss_rpn_loc: 0.1381  time: 0.6839  data_time: 0.3712  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:23:13 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 4679  total_loss: 1.269  loss_cls: 0.3261  loss_box_reg: 0.5481  loss_mask: 0.282  loss_rpn_cls: 0.03623  loss_rpn_loc: 0.1208  time: 0.6837  data_time: 0.1323  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:23:28 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 4699  total_loss: 1.424  loss_cls: 0.3635  loss_box_reg: 0.5827  loss_mask: 0.2971  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1339  time: 0.6840  data_time: 0.2224  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:23:43 d2.utils.events]: \u001b[0m eta: 0:45:13  iter: 4719  total_loss: 1.344  loss_cls: 0.3371  loss_box_reg: 0.5685  loss_mask: 0.2926  loss_rpn_cls: 0.04564  loss_rpn_loc: 0.1191  time: 0.6843  data_time: 0.2376  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:23:56 d2.utils.events]: \u001b[0m eta: 0:45:06  iter: 4739  total_loss: 1.406  loss_cls: 0.359  loss_box_reg: 0.5618  loss_mask: 0.2953  loss_rpn_cls: 0.04753  loss_rpn_loc: 0.1245  time: 0.6841  data_time: 0.1215  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:24:09 d2.utils.events]: \u001b[0m eta: 0:45:05  iter: 4759  total_loss: 1.294  loss_cls: 0.3053  loss_box_reg: 0.5326  loss_mask: 0.2796  loss_rpn_cls: 0.05074  loss_rpn_loc: 0.1136  time: 0.6840  data_time: 0.1489  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:24:23 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 4779  total_loss: 1.423  loss_cls: 0.3454  loss_box_reg: 0.5648  loss_mask: 0.2846  loss_rpn_cls: 0.05837  loss_rpn_loc: 0.1312  time: 0.6840  data_time: 0.1854  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:24:38 d2.utils.events]: \u001b[0m eta: 0:44:54  iter: 4799  total_loss: 1.39  loss_cls: 0.3469  loss_box_reg: 0.5575  loss_mask: 0.2969  loss_rpn_cls: 0.05266  loss_rpn_loc: 0.1174  time: 0.6843  data_time: 0.2413  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:24:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:24:57 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 4819  total_loss: 1.399  loss_cls: 0.3349  loss_box_reg: 0.563  loss_mask: 0.3097  loss_rpn_cls: 0.04914  loss_rpn_loc: 0.1205  time: 0.6853  data_time: 0.3227  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:25:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:25:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:25:08 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:25:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:25:08 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:25:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:25:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0881 s/iter. Eval: 0.0525 s/iter. Total: 0.1412 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0736 s/iter. Total: 0.1676 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:25:20 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0932 s/iter. Eval: 0.0737 s/iter. Total: 0.1678 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.0940 s/iter. Eval: 0.0799 s/iter. Total: 0.1748 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/06 00:25:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.095835 (0.173240 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:25:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093894 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:25:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:25:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2731872491503903\n",
      "\u001b[32m[02/06 00:25:29 d2.utils.events]: \u001b[0m eta: 0:44:36  iter: 4839  total_loss: 1.333  loss_cls: 0.3339  loss_box_reg: 0.5227  loss_mask: 0.2817  loss_rpn_cls: 0.04484  loss_rpn_loc: 0.1065  time: 0.6847  data_time: 0.0453  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:25:41 d2.utils.events]: \u001b[0m eta: 0:44:33  iter: 4859  total_loss: 1.443  loss_cls: 0.3705  loss_box_reg: 0.561  loss_mask: 0.2746  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1102  time: 0.6843  data_time: 0.0625  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:25:53 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 4879  total_loss: 1.289  loss_cls: 0.3339  loss_box_reg: 0.5643  loss_mask: 0.2866  loss_rpn_cls: 0.04397  loss_rpn_loc: 0.1056  time: 0.6840  data_time: 0.1327  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:26:08 d2.utils.events]: \u001b[0m eta: 0:44:11  iter: 4899  total_loss: 1.444  loss_cls: 0.369  loss_box_reg: 0.5617  loss_mask: 0.299  loss_rpn_cls: 0.05594  loss_rpn_loc: 0.1373  time: 0.6842  data_time: 0.2384  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:26:25 d2.utils.events]: \u001b[0m eta: 0:44:04  iter: 4919  total_loss: 1.354  loss_cls: 0.33  loss_box_reg: 0.533  loss_mask: 0.2834  loss_rpn_cls: 0.05308  loss_rpn_loc: 0.1266  time: 0.6848  data_time: 0.3276  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:26:39 d2.utils.events]: \u001b[0m eta: 0:43:56  iter: 4939  total_loss: 1.38  loss_cls: 0.3667  loss_box_reg: 0.576  loss_mask: 0.2949  loss_rpn_cls: 0.04998  loss_rpn_loc: 0.1254  time: 0.6850  data_time: 0.2148  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:26:54 d2.utils.events]: \u001b[0m eta: 0:43:45  iter: 4959  total_loss: 1.331  loss_cls: 0.3611  loss_box_reg: 0.5463  loss_mask: 0.2883  loss_rpn_cls: 0.04968  loss_rpn_loc: 0.1224  time: 0.6852  data_time: 0.2508  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:27:05 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 4979  total_loss: 1.407  loss_cls: 0.3584  loss_box_reg: 0.5835  loss_mask: 0.2969  loss_rpn_cls: 0.05299  loss_rpn_loc: 0.1009  time: 0.6846  data_time: 0.0642  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:27:18 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 4999  total_loss: 1.306  loss_cls: 0.3251  loss_box_reg: 0.551  loss_mask: 0.2843  loss_rpn_cls: 0.0426  loss_rpn_loc: 0.1075  time: 0.6846  data_time: 0.1833  lr: 0.000256  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:27:31 d2.utils.events]: \u001b[0m eta: 0:43:07  iter: 5019  total_loss: 1.424  loss_cls: 0.3514  loss_box_reg: 0.5493  loss_mask: 0.2967  loss_rpn_cls: 0.05768  loss_rpn_loc: 0.1365  time: 0.6843  data_time: 0.1219  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:27:44 d2.utils.events]: \u001b[0m eta: 0:43:02  iter: 5039  total_loss: 1.381  loss_cls: 0.336  loss_box_reg: 0.5629  loss_mask: 0.3012  loss_rpn_cls: 0.0475  loss_rpn_loc: 0.1249  time: 0.6843  data_time: 0.1554  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:27:57 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 5059  total_loss: 1.459  loss_cls: 0.3703  loss_box_reg: 0.5587  loss_mask: 0.2929  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.1496  time: 0.6841  data_time: 0.1411  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:28:12 d2.utils.events]: \u001b[0m eta: 0:42:38  iter: 5079  total_loss: 1.502  loss_cls: 0.3821  loss_box_reg: 0.6057  loss_mask: 0.3007  loss_rpn_cls: 0.05458  loss_rpn_loc: 0.1362  time: 0.6845  data_time: 0.2869  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:28:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:28:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:28:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:28:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:28:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:28:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0888 s/iter. Eval: 0.0541 s/iter. Total: 0.1435 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0713 s/iter. Total: 0.1630 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0905 s/iter. Eval: 0.0707 s/iter. Total: 0.1620 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0922 s/iter. Eval: 0.0765 s/iter. Total: 0.1696 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:28:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.701153 (0.169838 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:28:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092755 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:28:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:28:36 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27392626557342864\n",
      "\u001b[32m[02/06 00:28:47 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 5099  total_loss: 1.29  loss_cls: 0.328  loss_box_reg: 0.5261  loss_mask: 0.2889  loss_rpn_cls: 0.04136  loss_rpn_loc: 0.1078  time: 0.6844  data_time: 0.1647  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:29:02 d2.utils.events]: \u001b[0m eta: 0:42:20  iter: 5119  total_loss: 1.423  loss_cls: 0.3638  loss_box_reg: 0.5651  loss_mask: 0.2782  loss_rpn_cls: 0.05448  loss_rpn_loc: 0.1251  time: 0.6847  data_time: 0.2805  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:29:17 d2.utils.events]: \u001b[0m eta: 0:42:12  iter: 5139  total_loss: 1.502  loss_cls: 0.3736  loss_box_reg: 0.5822  loss_mask: 0.3058  loss_rpn_cls: 0.06219  loss_rpn_loc: 0.1384  time: 0.6850  data_time: 0.2407  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:29:34 d2.utils.events]: \u001b[0m eta: 0:42:01  iter: 5159  total_loss: 1.481  loss_cls: 0.3807  loss_box_reg: 0.5676  loss_mask: 0.2969  loss_rpn_cls: 0.06803  loss_rpn_loc: 0.1261  time: 0.6855  data_time: 0.3008  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:29:46 d2.utils.events]: \u001b[0m eta: 0:41:51  iter: 5179  total_loss: 1.487  loss_cls: 0.3538  loss_box_reg: 0.5939  loss_mask: 0.2903  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.1379  time: 0.6852  data_time: 0.1139  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:29:58 d2.utils.events]: \u001b[0m eta: 0:41:40  iter: 5199  total_loss: 1.364  loss_cls: 0.3373  loss_box_reg: 0.5733  loss_mask: 0.2921  loss_rpn_cls: 0.04061  loss_rpn_loc: 0.1169  time: 0.6849  data_time: 0.0972  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:30:13 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 5219  total_loss: 1.404  loss_cls: 0.3552  loss_box_reg: 0.5506  loss_mask: 0.3045  loss_rpn_cls: 0.05499  loss_rpn_loc: 0.123  time: 0.6852  data_time: 0.3038  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:30:30 d2.utils.events]: \u001b[0m eta: 0:41:20  iter: 5239  total_loss: 1.432  loss_cls: 0.3584  loss_box_reg: 0.5597  loss_mask: 0.2979  loss_rpn_cls: 0.0432  loss_rpn_loc: 0.139  time: 0.6857  data_time: 0.3073  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:30:41 d2.utils.events]: \u001b[0m eta: 0:41:09  iter: 5259  total_loss: 1.327  loss_cls: 0.3098  loss_box_reg: 0.5869  loss_mask: 0.2946  loss_rpn_cls: 0.03237  loss_rpn_loc: 0.0925  time: 0.6852  data_time: 0.0862  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:30:54 d2.utils.events]: \u001b[0m eta: 0:40:59  iter: 5279  total_loss: 1.482  loss_cls: 0.3732  loss_box_reg: 0.596  loss_mask: 0.2967  loss_rpn_cls: 0.05409  loss_rpn_loc: 0.1359  time: 0.6851  data_time: 0.1558  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:31:06 d2.utils.events]: \u001b[0m eta: 0:40:52  iter: 5299  total_loss: 1.391  loss_cls: 0.3543  loss_box_reg: 0.5792  loss_mask: 0.2883  loss_rpn_cls: 0.04567  loss_rpn_loc: 0.1112  time: 0.6849  data_time: 0.1339  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:31:16 d2.utils.events]: \u001b[0m eta: 0:40:35  iter: 5319  total_loss: 1.181  loss_cls: 0.2825  loss_box_reg: 0.5014  loss_mask: 0.2725  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.07132  time: 0.6842  data_time: 0.0392  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:31:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:31:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:31:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:31:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:31:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:31:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:31:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0857 s/iter. Eval: 0.0571 s/iter. Total: 0.1435 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:31:26 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0881 s/iter. Eval: 0.0723 s/iter. Total: 0.1613 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 00:31:31 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0883 s/iter. Eval: 0.0725 s/iter. Total: 0.1616 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.0888 s/iter. Eval: 0.0765 s/iter. Total: 0.1661 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:31:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.279582 (0.166203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:31:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.088979 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:31:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:31:39 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2713674898803675\n",
      "\u001b[32m[02/06 00:31:50 d2.utils.events]: \u001b[0m eta: 0:40:26  iter: 5339  total_loss: 1.395  loss_cls: 0.3422  loss_box_reg: 0.5646  loss_mask: 0.2885  loss_rpn_cls: 0.05337  loss_rpn_loc: 0.1326  time: 0.6840  data_time: 0.1467  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:32:04 d2.utils.events]: \u001b[0m eta: 0:40:13  iter: 5359  total_loss: 1.418  loss_cls: 0.352  loss_box_reg: 0.5666  loss_mask: 0.3005  loss_rpn_cls: 0.05031  loss_rpn_loc: 0.1305  time: 0.6840  data_time: 0.2196  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:32:20 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 5379  total_loss: 1.424  loss_cls: 0.369  loss_box_reg: 0.5666  loss_mask: 0.3087  loss_rpn_cls: 0.04105  loss_rpn_loc: 0.1372  time: 0.6844  data_time: 0.2962  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:32:30 d2.utils.events]: \u001b[0m eta: 0:39:48  iter: 5399  total_loss: 1.214  loss_cls: 0.2973  loss_box_reg: 0.5051  loss_mask: 0.2843  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.09594  time: 0.6839  data_time: 0.0869  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:32:44 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 5419  total_loss: 1.372  loss_cls: 0.3674  loss_box_reg: 0.5746  loss_mask: 0.2951  loss_rpn_cls: 0.05504  loss_rpn_loc: 0.1112  time: 0.6838  data_time: 0.1882  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:32:58 d2.utils.events]: \u001b[0m eta: 0:39:28  iter: 5439  total_loss: 1.293  loss_cls: 0.3293  loss_box_reg: 0.5216  loss_mask: 0.2793  loss_rpn_cls: 0.05242  loss_rpn_loc: 0.1137  time: 0.6839  data_time: 0.2319  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:33:10 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 5459  total_loss: 1.272  loss_cls: 0.3118  loss_box_reg: 0.525  loss_mask: 0.2812  loss_rpn_cls: 0.03493  loss_rpn_loc: 0.09285  time: 0.6835  data_time: 0.1273  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:33:25 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 5479  total_loss: 1.408  loss_cls: 0.3446  loss_box_reg: 0.5742  loss_mask: 0.2917  loss_rpn_cls: 0.04386  loss_rpn_loc: 0.1232  time: 0.6838  data_time: 0.2520  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:33:39 d2.utils.events]: \u001b[0m eta: 0:38:56  iter: 5499  total_loss: 1.398  loss_cls: 0.3471  loss_box_reg: 0.551  loss_mask: 0.2902  loss_rpn_cls: 0.04364  loss_rpn_loc: 0.1175  time: 0.6840  data_time: 0.2537  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:33:53 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 5519  total_loss: 1.405  loss_cls: 0.3459  loss_box_reg: 0.5848  loss_mask: 0.2959  loss_rpn_cls: 0.06042  loss_rpn_loc: 0.1225  time: 0.6840  data_time: 0.2087  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:34:07 d2.utils.events]: \u001b[0m eta: 0:38:36  iter: 5539  total_loss: 1.415  loss_cls: 0.3688  loss_box_reg: 0.553  loss_mask: 0.3001  loss_rpn_cls: 0.05081  loss_rpn_loc: 0.1347  time: 0.6841  data_time: 0.2110  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:34:18 d2.utils.events]: \u001b[0m eta: 0:38:17  iter: 5559  total_loss: 1.326  loss_cls: 0.309  loss_box_reg: 0.5642  loss_mask: 0.2711  loss_rpn_cls: 0.03931  loss_rpn_loc: 0.1107  time: 0.6835  data_time: 0.0456  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:34:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:34:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:34:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:34:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:34:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:34:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0910 s/iter. Eval: 0.0585 s/iter. Total: 0.1501 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 00:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0901 s/iter. Eval: 0.0745 s/iter. Total: 0.1654 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0730 s/iter. Total: 0.1633 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0898 s/iter. Eval: 0.0772 s/iter. Total: 0.1678 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:34:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.332550 (0.166660 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:34:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089336 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:34:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:34:42 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27316859631393153\n",
      "\u001b[32m[02/06 00:34:53 d2.utils.events]: \u001b[0m eta: 0:38:04  iter: 5579  total_loss: 1.362  loss_cls: 0.3506  loss_box_reg: 0.5574  loss_mask: 0.2914  loss_rpn_cls: 0.05686  loss_rpn_loc: 0.129  time: 0.6835  data_time: 0.2350  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:35:08 d2.utils.events]: \u001b[0m eta: 0:37:54  iter: 5599  total_loss: 1.45  loss_cls: 0.3656  loss_box_reg: 0.5791  loss_mask: 0.3065  loss_rpn_cls: 0.05598  loss_rpn_loc: 0.1462  time: 0.6838  data_time: 0.2671  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:35:23 d2.utils.events]: \u001b[0m eta: 0:37:44  iter: 5619  total_loss: 1.44  loss_cls: 0.3579  loss_box_reg: 0.5639  loss_mask: 0.2919  loss_rpn_cls: 0.05342  loss_rpn_loc: 0.1277  time: 0.6840  data_time: 0.2431  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:35:39 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 5639  total_loss: 1.415  loss_cls: 0.3284  loss_box_reg: 0.5564  loss_mask: 0.2872  loss_rpn_cls: 0.08032  loss_rpn_loc: 0.1411  time: 0.6844  data_time: 0.3026  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:35:51 d2.utils.events]: \u001b[0m eta: 0:37:17  iter: 5659  total_loss: 1.254  loss_cls: 0.3004  loss_box_reg: 0.5245  loss_mask: 0.2655  loss_rpn_cls: 0.03719  loss_rpn_loc: 0.1064  time: 0.6842  data_time: 0.1565  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:36:07 d2.utils.events]: \u001b[0m eta: 0:37:07  iter: 5679  total_loss: 1.382  loss_cls: 0.3446  loss_box_reg: 0.552  loss_mask: 0.2874  loss_rpn_cls: 0.04702  loss_rpn_loc: 0.1272  time: 0.6846  data_time: 0.3008  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:36:23 d2.utils.events]: \u001b[0m eta: 0:36:56  iter: 5699  total_loss: 1.355  loss_cls: 0.3129  loss_box_reg: 0.5696  loss_mask: 0.2976  loss_rpn_cls: 0.03729  loss_rpn_loc: 0.1186  time: 0.6849  data_time: 0.2461  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:36:35 d2.utils.events]: \u001b[0m eta: 0:36:44  iter: 5719  total_loss: 1.233  loss_cls: 0.3074  loss_box_reg: 0.4999  loss_mask: 0.2775  loss_rpn_cls: 0.04095  loss_rpn_loc: 0.1129  time: 0.6847  data_time: 0.1152  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:36:48 d2.utils.events]: \u001b[0m eta: 0:36:25  iter: 5739  total_loss: 1.389  loss_cls: 0.3261  loss_box_reg: 0.5701  loss_mask: 0.2878  loss_rpn_cls: 0.04198  loss_rpn_loc: 0.1233  time: 0.6846  data_time: 0.1955  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:37:01 d2.utils.events]: \u001b[0m eta: 0:36:13  iter: 5759  total_loss: 1.368  loss_cls: 0.3365  loss_box_reg: 0.5568  loss_mask: 0.2916  loss_rpn_cls: 0.04079  loss_rpn_loc: 0.1159  time: 0.6844  data_time: 0.1109  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:37:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:37:16 d2.utils.events]: \u001b[0m eta: 0:36:02  iter: 5779  total_loss: 1.243  loss_cls: 0.3143  loss_box_reg: 0.5431  loss_mask: 0.2885  loss_rpn_cls: 0.04163  loss_rpn_loc: 0.1088  time: 0.6846  data_time: 0.2038  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:37:30 d2.utils.events]: \u001b[0m eta: 0:35:49  iter: 5799  total_loss: 1.349  loss_cls: 0.3533  loss_box_reg: 0.5612  loss_mask: 0.29  loss_rpn_cls: 0.0408  loss_rpn_loc: 0.113  time: 0.6846  data_time: 0.1682  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:37:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:37:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:37:35 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:37:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:37:35 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:37:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0891 s/iter. Eval: 0.0569 s/iter. Total: 0.1467 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 00:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0915 s/iter. Eval: 0.0743 s/iter. Total: 0.1667 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0918 s/iter. Eval: 0.0729 s/iter. Total: 0.1656 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0925 s/iter. Eval: 0.0784 s/iter. Total: 0.1718 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:37:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.737435 (0.170150 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:37:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092595 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:37:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:37:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2739994968867645\n",
      "\u001b[32m[02/06 00:38:03 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 5819  total_loss: 1.338  loss_cls: 0.3338  loss_box_reg: 0.5579  loss_mask: 0.2923  loss_rpn_cls: 0.04614  loss_rpn_loc: 0.1118  time: 0.6843  data_time: 0.0916  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:38:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:38:22 d2.utils.events]: \u001b[0m eta: 0:35:32  iter: 5839  total_loss: 1.397  loss_cls: 0.3468  loss_box_reg: 0.5664  loss_mask: 0.3022  loss_rpn_cls: 0.04281  loss_rpn_loc: 0.1195  time: 0.6853  data_time: 0.3525  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:38:35 d2.utils.events]: \u001b[0m eta: 0:35:17  iter: 5859  total_loss: 1.319  loss_cls: 0.3419  loss_box_reg: 0.556  loss_mask: 0.2853  loss_rpn_cls: 0.04076  loss_rpn_loc: 0.119  time: 0.6852  data_time: 0.1444  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:38:49 d2.utils.events]: \u001b[0m eta: 0:35:07  iter: 5879  total_loss: 1.291  loss_cls: 0.3162  loss_box_reg: 0.5511  loss_mask: 0.2943  loss_rpn_cls: 0.03353  loss_rpn_loc: 0.09977  time: 0.6851  data_time: 0.1673  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:39:02 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 5899  total_loss: 1.29  loss_cls: 0.3389  loss_box_reg: 0.5343  loss_mask: 0.2704  loss_rpn_cls: 0.04547  loss_rpn_loc: 0.1109  time: 0.6850  data_time: 0.1652  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:39:17 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 5919  total_loss: 1.336  loss_cls: 0.3432  loss_box_reg: 0.523  loss_mask: 0.2968  loss_rpn_cls: 0.0469  loss_rpn_loc: 0.1207  time: 0.6853  data_time: 0.2470  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:39:33 d2.utils.events]: \u001b[0m eta: 0:34:36  iter: 5939  total_loss: 1.195  loss_cls: 0.2799  loss_box_reg: 0.5092  loss_mask: 0.2704  loss_rpn_cls: 0.0439  loss_rpn_loc: 0.09863  time: 0.6856  data_time: 0.3065  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:39:46 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 5959  total_loss: 1.361  loss_cls: 0.3527  loss_box_reg: 0.5577  loss_mask: 0.2819  loss_rpn_cls: 0.05745  loss_rpn_loc: 0.1306  time: 0.6854  data_time: 0.1340  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:39:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:40:05 d2.utils.events]: \u001b[0m eta: 0:34:18  iter: 5979  total_loss: 1.366  loss_cls: 0.3365  loss_box_reg: 0.5619  loss_mask: 0.2958  loss_rpn_cls: 0.05844  loss_rpn_loc: 0.1076  time: 0.6864  data_time: 0.3962  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:40:20 d2.utils.events]: \u001b[0m eta: 0:34:09  iter: 5999  total_loss: 1.369  loss_cls: 0.3395  loss_box_reg: 0.5532  loss_mask: 0.2931  loss_rpn_cls: 0.04208  loss_rpn_loc: 0.119  time: 0.6867  data_time: 0.2561  lr: 0.0002048  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:40:33 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 6019  total_loss: 1.405  loss_cls: 0.3271  loss_box_reg: 0.5829  loss_mask: 0.3043  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.128  time: 0.6865  data_time: 0.1498  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:40:46 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 6039  total_loss: 1.347  loss_cls: 0.3216  loss_box_reg: 0.5443  loss_mask: 0.2782  loss_rpn_cls: 0.04188  loss_rpn_loc: 0.1007  time: 0.6864  data_time: 0.1418  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:40:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:40:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:40:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:40:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:40:53 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:40:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0895 s/iter. Eval: 0.0562 s/iter. Total: 0.1463 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 00:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0918 s/iter. Eval: 0.0728 s/iter. Total: 0.1655 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0920 s/iter. Eval: 0.0731 s/iter. Total: 0.1660 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0924 s/iter. Eval: 0.0787 s/iter. Total: 0.1720 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:41:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.758678 (0.170333 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:41:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092401 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:41:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:41:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2751965410027297\n",
      "\u001b[32m[02/06 00:41:20 d2.utils.events]: \u001b[0m eta: 0:33:35  iter: 6059  total_loss: 1.378  loss_cls: 0.3406  loss_box_reg: 0.5833  loss_mask: 0.3128  loss_rpn_cls: 0.03216  loss_rpn_loc: 0.1208  time: 0.6861  data_time: 0.1282  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:41:35 d2.utils.events]: \u001b[0m eta: 0:33:31  iter: 6079  total_loss: 1.359  loss_cls: 0.3487  loss_box_reg: 0.5444  loss_mask: 0.2813  loss_rpn_cls: 0.04938  loss_rpn_loc: 0.1299  time: 0.6864  data_time: 0.2431  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:41:50 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 6099  total_loss: 1.381  loss_cls: 0.353  loss_box_reg: 0.5603  loss_mask: 0.3089  loss_rpn_cls: 0.05127  loss_rpn_loc: 0.1201  time: 0.6866  data_time: 0.2483  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:42:03 d2.utils.events]: \u001b[0m eta: 0:33:06  iter: 6119  total_loss: 1.269  loss_cls: 0.2942  loss_box_reg: 0.5481  loss_mask: 0.296  loss_rpn_cls: 0.03377  loss_rpn_loc: 0.1048  time: 0.6865  data_time: 0.1541  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:42:16 d2.utils.events]: \u001b[0m eta: 0:32:53  iter: 6139  total_loss: 1.356  loss_cls: 0.3358  loss_box_reg: 0.5492  loss_mask: 0.2832  loss_rpn_cls: 0.03987  loss_rpn_loc: 0.1161  time: 0.6864  data_time: 0.1551  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:42:28 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:42:33 d2.utils.events]: \u001b[0m eta: 0:32:46  iter: 6159  total_loss: 1.286  loss_cls: 0.3248  loss_box_reg: 0.5098  loss_mask: 0.2867  loss_rpn_cls: 0.05108  loss_rpn_loc: 0.1253  time: 0.6869  data_time: 0.2686  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:42:50 d2.utils.events]: \u001b[0m eta: 0:32:37  iter: 6179  total_loss: 1.347  loss_cls: 0.3262  loss_box_reg: 0.5529  loss_mask: 0.2935  loss_rpn_cls: 0.05589  loss_rpn_loc: 0.1157  time: 0.6874  data_time: 0.3303  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:43:06 d2.utils.events]: \u001b[0m eta: 0:32:30  iter: 6199  total_loss: 1.389  loss_cls: 0.3384  loss_box_reg: 0.551  loss_mask: 0.2719  loss_rpn_cls: 0.06421  loss_rpn_loc: 0.1336  time: 0.6878  data_time: 0.2921  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:43:17 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 6219  total_loss: 1.212  loss_cls: 0.3014  loss_box_reg: 0.5207  loss_mask: 0.2764  loss_rpn_cls: 0.03518  loss_rpn_loc: 0.1006  time: 0.6874  data_time: 0.0779  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:43:30 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 6239  total_loss: 1.336  loss_cls: 0.3312  loss_box_reg: 0.5571  loss_mask: 0.2881  loss_rpn_cls: 0.04229  loss_rpn_loc: 0.1265  time: 0.6872  data_time: 0.1487  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:43:43 d2.utils.events]: \u001b[0m eta: 0:31:59  iter: 6259  total_loss: 1.277  loss_cls: 0.3298  loss_box_reg: 0.5512  loss_mask: 0.3015  loss_rpn_cls: 0.03453  loss_rpn_loc: 0.102  time: 0.6871  data_time: 0.1595  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:43:58 d2.utils.events]: \u001b[0m eta: 0:31:50  iter: 6279  total_loss: 1.451  loss_cls: 0.3626  loss_box_reg: 0.5892  loss_mask: 0.3079  loss_rpn_cls: 0.05644  loss_rpn_loc: 0.1311  time: 0.6873  data_time: 0.2360  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:44:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:44:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:44:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:44:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:44:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:44:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0977 s/iter. Eval: 0.0677 s/iter. Total: 0.1663 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 00:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 38/121. Dataloading: 0.0009 s/iter. Inference: 0.0986 s/iter. Eval: 0.0834 s/iter. Total: 0.1829 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:44:19 d2.evaluation.evaluator]: \u001b[0mInference done 66/121. Dataloading: 0.0009 s/iter. Inference: 0.0979 s/iter. Eval: 0.0828 s/iter. Total: 0.1817 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/06 00:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 90/121. Dataloading: 0.0009 s/iter. Inference: 0.0989 s/iter. Eval: 0.0894 s/iter. Total: 0.1892 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/06 00:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0009 s/iter. Inference: 0.0982 s/iter. Eval: 0.0865 s/iter. Total: 0.1856 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 00:44:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.673158 (0.186838 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:44:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.098313 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:44:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:44:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2734787385248795\n",
      "\u001b[32m[02/06 00:44:37 d2.utils.events]: \u001b[0m eta: 0:31:43  iter: 6299  total_loss: 1.37  loss_cls: 0.3545  loss_box_reg: 0.5552  loss_mask: 0.3118  loss_rpn_cls: 0.0605  loss_rpn_loc: 0.1091  time: 0.6875  data_time: 0.2410  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:44:50 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 6319  total_loss: 1.413  loss_cls: 0.3356  loss_box_reg: 0.5717  loss_mask: 0.2899  loss_rpn_cls: 0.05642  loss_rpn_loc: 0.1302  time: 0.6874  data_time: 0.1379  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:45:04 d2.utils.events]: \u001b[0m eta: 0:31:32  iter: 6339  total_loss: 1.334  loss_cls: 0.3385  loss_box_reg: 0.5427  loss_mask: 0.279  loss_rpn_cls: 0.04232  loss_rpn_loc: 0.1255  time: 0.6875  data_time: 0.2114  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:45:18 d2.utils.events]: \u001b[0m eta: 0:31:25  iter: 6359  total_loss: 1.38  loss_cls: 0.3344  loss_box_reg: 0.5625  loss_mask: 0.3001  loss_rpn_cls: 0.05036  loss_rpn_loc: 0.1064  time: 0.6875  data_time: 0.1736  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:45:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:45:35 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 6379  total_loss: 1.32  loss_cls: 0.3344  loss_box_reg: 0.5564  loss_mask: 0.2907  loss_rpn_cls: 0.04097  loss_rpn_loc: 0.114  time: 0.6881  data_time: 0.2690  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:45:49 d2.utils.events]: \u001b[0m eta: 0:31:13  iter: 6399  total_loss: 1.297  loss_cls: 0.3254  loss_box_reg: 0.5228  loss_mask: 0.3012  loss_rpn_cls: 0.03608  loss_rpn_loc: 0.1168  time: 0.6880  data_time: 0.1577  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:46:03 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 6419  total_loss: 1.453  loss_cls: 0.365  loss_box_reg: 0.5725  loss_mask: 0.3048  loss_rpn_cls: 0.06263  loss_rpn_loc: 0.1516  time: 0.6881  data_time: 0.2156  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:46:15 d2.utils.events]: \u001b[0m eta: 0:30:53  iter: 6439  total_loss: 1.3  loss_cls: 0.3329  loss_box_reg: 0.5383  loss_mask: 0.2755  loss_rpn_cls: 0.04248  loss_rpn_loc: 0.1198  time: 0.6879  data_time: 0.1132  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:46:30 d2.utils.events]: \u001b[0m eta: 0:30:47  iter: 6459  total_loss: 1.353  loss_cls: 0.3333  loss_box_reg: 0.5593  loss_mask: 0.2954  loss_rpn_cls: 0.05308  loss_rpn_loc: 0.1237  time: 0.6880  data_time: 0.2233  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:46:45 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 6479  total_loss: 1.248  loss_cls: 0.3185  loss_box_reg: 0.5199  loss_mask: 0.276  loss_rpn_cls: 0.05137  loss_rpn_loc: 0.1168  time: 0.6882  data_time: 0.2455  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:46:56 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 6499  total_loss: 1.231  loss_cls: 0.2944  loss_box_reg: 0.5163  loss_mask: 0.2743  loss_rpn_cls: 0.02685  loss_rpn_loc: 0.09801  time: 0.6878  data_time: 0.0988  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:47:11 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 6519  total_loss: 1.383  loss_cls: 0.3349  loss_box_reg: 0.571  loss_mask: 0.3078  loss_rpn_cls: 0.03983  loss_rpn_loc: 0.1239  time: 0.6880  data_time: 0.2480  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:47:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:47:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:47:22 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:47:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:47:22 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:47:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0895 s/iter. Eval: 0.0522 s/iter. Total: 0.1423 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0923 s/iter. Eval: 0.0744 s/iter. Total: 0.1675 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0926 s/iter. Eval: 0.0748 s/iter. Total: 0.1682 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0930 s/iter. Eval: 0.0805 s/iter. Total: 0.1744 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/06 00:47:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.894418 (0.171504 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:47:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092334 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:47:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:47:43 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27322114824628074\n",
      "\u001b[32m[02/06 00:47:47 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 6539  total_loss: 1.299  loss_cls: 0.3198  loss_box_reg: 0.5262  loss_mask: 0.2862  loss_rpn_cls: 0.04436  loss_rpn_loc: 0.1089  time: 0.6881  data_time: 0.2061  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:48:02 d2.utils.events]: \u001b[0m eta: 0:29:55  iter: 6559  total_loss: 1.449  loss_cls: 0.3672  loss_box_reg: 0.5557  loss_mask: 0.2891  loss_rpn_cls: 0.04907  loss_rpn_loc: 0.1495  time: 0.6882  data_time: 0.2109  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:48:14 d2.utils.events]: \u001b[0m eta: 0:29:46  iter: 6579  total_loss: 1.393  loss_cls: 0.3481  loss_box_reg: 0.544  loss_mask: 0.2984  loss_rpn_cls: 0.05789  loss_rpn_loc: 0.1355  time: 0.6880  data_time: 0.1516  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:48:30 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 6599  total_loss: 1.308  loss_cls: 0.3311  loss_box_reg: 0.537  loss_mask: 0.2853  loss_rpn_cls: 0.04352  loss_rpn_loc: 0.1181  time: 0.6882  data_time: 0.2589  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:48:41 d2.utils.events]: \u001b[0m eta: 0:29:24  iter: 6619  total_loss: 1.157  loss_cls: 0.2821  loss_box_reg: 0.5126  loss_mask: 0.2854  loss_rpn_cls: 0.03723  loss_rpn_loc: 0.08061  time: 0.6878  data_time: 0.0689  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:48:55 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 6639  total_loss: 1.405  loss_cls: 0.3665  loss_box_reg: 0.5734  loss_mask: 0.3047  loss_rpn_cls: 0.05185  loss_rpn_loc: 0.1327  time: 0.6879  data_time: 0.2024  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:49:08 d2.utils.events]: \u001b[0m eta: 0:29:09  iter: 6659  total_loss: 1.342  loss_cls: 0.327  loss_box_reg: 0.5316  loss_mask: 0.2987  loss_rpn_cls: 0.03532  loss_rpn_loc: 0.1153  time: 0.6879  data_time: 0.1676  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:49:21 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 6679  total_loss: 1.462  loss_cls: 0.3724  loss_box_reg: 0.6043  loss_mask: 0.3155  loss_rpn_cls: 0.03863  loss_rpn_loc: 0.1344  time: 0.6877  data_time: 0.1587  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:49:34 d2.utils.events]: \u001b[0m eta: 0:28:47  iter: 6699  total_loss: 1.311  loss_cls: 0.3444  loss_box_reg: 0.5632  loss_mask: 0.2795  loss_rpn_cls: 0.05158  loss_rpn_loc: 0.1177  time: 0.6876  data_time: 0.1342  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:49:49 d2.utils.events]: \u001b[0m eta: 0:28:37  iter: 6719  total_loss: 1.361  loss_cls: 0.3489  loss_box_reg: 0.5401  loss_mask: 0.2938  loss_rpn_cls: 0.05745  loss_rpn_loc: 0.1248  time: 0.6878  data_time: 0.2547  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:50:02 d2.utils.events]: \u001b[0m eta: 0:28:26  iter: 6739  total_loss: 1.29  loss_cls: 0.3296  loss_box_reg: 0.5361  loss_mask: 0.271  loss_rpn_cls: 0.05972  loss_rpn_loc: 0.1073  time: 0.6877  data_time: 0.1576  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:50:15 d2.utils.events]: \u001b[0m eta: 0:28:15  iter: 6759  total_loss: 1.25  loss_cls: 0.312  loss_box_reg: 0.5404  loss_mask: 0.2846  loss_rpn_cls: 0.0353  loss_rpn_loc: 0.09275  time: 0.6876  data_time: 0.1495  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:50:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:50:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:50:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:50:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:50:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:50:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:50:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0941 s/iter. Eval: 0.0570 s/iter. Total: 0.1519 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 00:50:33 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0934 s/iter. Eval: 0.0750 s/iter. Total: 0.1692 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:50:38 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0936 s/iter. Eval: 0.0758 s/iter. Total: 0.1703 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:50:43 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0940 s/iter. Eval: 0.0814 s/iter. Total: 0.1763 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/06 00:50:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.200701 (0.174144 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:50:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.093772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:50:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:50:47 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27634252341062754\n",
      "\u001b[32m[02/06 00:50:49 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 6779  total_loss: 1.32  loss_cls: 0.3276  loss_box_reg: 0.5566  loss_mask: 0.3007  loss_rpn_cls: 0.03436  loss_rpn_loc: 0.1008  time: 0.6873  data_time: 0.1040  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:51:07 d2.utils.events]: \u001b[0m eta: 0:27:56  iter: 6799  total_loss: 1.432  loss_cls: 0.3684  loss_box_reg: 0.5779  loss_mask: 0.3079  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.1363  time: 0.6878  data_time: 0.3408  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:51:19 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 6819  total_loss: 1.292  loss_cls: 0.3056  loss_box_reg: 0.538  loss_mask: 0.2923  loss_rpn_cls: 0.04479  loss_rpn_loc: 0.1065  time: 0.6877  data_time: 0.1395  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:51:36 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 6839  total_loss: 1.439  loss_cls: 0.3677  loss_box_reg: 0.5721  loss_mask: 0.2994  loss_rpn_cls: 0.05924  loss_rpn_loc: 0.1304  time: 0.6881  data_time: 0.3145  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:51:49 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 6859  total_loss: 1.212  loss_cls: 0.3045  loss_box_reg: 0.5377  loss_mask: 0.2717  loss_rpn_cls: 0.04027  loss_rpn_loc: 0.101  time: 0.6880  data_time: 0.1704  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:52:06 d2.utils.events]: \u001b[0m eta: 0:27:16  iter: 6879  total_loss: 1.339  loss_cls: 0.3456  loss_box_reg: 0.5651  loss_mask: 0.3028  loss_rpn_cls: 0.05481  loss_rpn_loc: 0.1472  time: 0.6885  data_time: 0.3125  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:52:21 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 6899  total_loss: 1.251  loss_cls: 0.2989  loss_box_reg: 0.5319  loss_mask: 0.2941  loss_rpn_cls: 0.04406  loss_rpn_loc: 0.0737  time: 0.6886  data_time: 0.2401  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:52:37 d2.utils.events]: \u001b[0m eta: 0:26:53  iter: 6919  total_loss: 1.357  loss_cls: 0.3421  loss_box_reg: 0.5392  loss_mask: 0.2913  loss_rpn_cls: 0.05763  loss_rpn_loc: 0.1091  time: 0.6890  data_time: 0.2968  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:52:51 d2.utils.events]: \u001b[0m eta: 0:26:44  iter: 6939  total_loss: 1.45  loss_cls: 0.3704  loss_box_reg: 0.5768  loss_mask: 0.3037  loss_rpn_cls: 0.0607  loss_rpn_loc: 0.1369  time: 0.6890  data_time: 0.1945  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:53:03 d2.utils.events]: \u001b[0m eta: 0:26:34  iter: 6959  total_loss: 1.396  loss_cls: 0.3428  loss_box_reg: 0.573  loss_mask: 0.2953  loss_rpn_cls: 0.05216  loss_rpn_loc: 0.1338  time: 0.6888  data_time: 0.1305  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:53:14 d2.utils.events]: \u001b[0m eta: 0:26:22  iter: 6979  total_loss: 1.324  loss_cls: 0.3175  loss_box_reg: 0.5566  loss_mask: 0.2928  loss_rpn_cls: 0.0346  loss_rpn_loc: 0.1119  time: 0.6883  data_time: 0.0693  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:53:25 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 6999  total_loss: 1.346  loss_cls: 0.3359  loss_box_reg: 0.5586  loss_mask: 0.3002  loss_rpn_cls: 0.03219  loss_rpn_loc: 0.1007  time: 0.6880  data_time: 0.0878  lr: 0.00016384  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:53:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:53:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:53:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:53:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:53:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:53:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:53:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0897 s/iter. Eval: 0.0584 s/iter. Total: 0.1488 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 00:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0923 s/iter. Eval: 0.0777 s/iter. Total: 0.1709 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0739 s/iter. Total: 0.1652 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 00:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0904 s/iter. Eval: 0.0783 s/iter. Total: 0.1696 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:54:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.495835 (0.168068 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:54:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090053 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:54:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:54:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27428635737321094\n",
      "\u001b[32m[02/06 00:54:01 d2.utils.events]: \u001b[0m eta: 0:25:59  iter: 7019  total_loss: 1.288  loss_cls: 0.3266  loss_box_reg: 0.531  loss_mask: 0.2855  loss_rpn_cls: 0.039  loss_rpn_loc: 0.1212  time: 0.6881  data_time: 0.2512  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:54:13 d2.utils.events]: \u001b[0m eta: 0:25:48  iter: 7039  total_loss: 1.319  loss_cls: 0.3182  loss_box_reg: 0.5675  loss_mask: 0.2823  loss_rpn_cls: 0.03275  loss_rpn_loc: 0.1096  time: 0.6879  data_time: 0.1593  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:54:26 d2.utils.events]: \u001b[0m eta: 0:25:36  iter: 7059  total_loss: 1.25  loss_cls: 0.3138  loss_box_reg: 0.536  loss_mask: 0.2904  loss_rpn_cls: 0.03483  loss_rpn_loc: 0.1202  time: 0.6878  data_time: 0.1749  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:54:40 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 7079  total_loss: 1.331  loss_cls: 0.3225  loss_box_reg: 0.5425  loss_mask: 0.2846  loss_rpn_cls: 0.04955  loss_rpn_loc: 0.1294  time: 0.6878  data_time: 0.2278  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:54:52 d2.utils.events]: \u001b[0m eta: 0:25:08  iter: 7099  total_loss: 1.377  loss_cls: 0.3282  loss_box_reg: 0.5471  loss_mask: 0.2787  loss_rpn_cls: 0.0422  loss_rpn_loc: 0.1224  time: 0.6874  data_time: 0.0903  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:55:05 d2.utils.events]: \u001b[0m eta: 0:24:58  iter: 7119  total_loss: 1.287  loss_cls: 0.3136  loss_box_reg: 0.5326  loss_mask: 0.2962  loss_rpn_cls: 0.03322  loss_rpn_loc: 0.1032  time: 0.6874  data_time: 0.2105  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:55:18 d2.utils.events]: \u001b[0m eta: 0:24:47  iter: 7139  total_loss: 1.408  loss_cls: 0.3562  loss_box_reg: 0.5497  loss_mask: 0.2939  loss_rpn_cls: 0.05372  loss_rpn_loc: 0.1409  time: 0.6873  data_time: 0.1633  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:55:33 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 7159  total_loss: 1.539  loss_cls: 0.4068  loss_box_reg: 0.5817  loss_mask: 0.3059  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.1613  time: 0.6875  data_time: 0.2503  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:55:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:55:52 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 7179  total_loss: 1.476  loss_cls: 0.3767  loss_box_reg: 0.5684  loss_mask: 0.3125  loss_rpn_cls: 0.07353  loss_rpn_loc: 0.1371  time: 0.6881  data_time: 0.3188  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:56:06 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 7199  total_loss: 1.279  loss_cls: 0.3378  loss_box_reg: 0.545  loss_mask: 0.2902  loss_rpn_cls: 0.03973  loss_rpn_loc: 0.115  time: 0.6882  data_time: 0.2117  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:56:17 d2.utils.events]: \u001b[0m eta: 0:24:01  iter: 7219  total_loss: 1.265  loss_cls: 0.2997  loss_box_reg: 0.5406  loss_mask: 0.2845  loss_rpn_cls: 0.02795  loss_rpn_loc: 0.1113  time: 0.6878  data_time: 0.0815  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:56:31 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 7239  total_loss: 1.384  loss_cls: 0.3322  loss_box_reg: 0.5406  loss_mask: 0.2847  loss_rpn_cls: 0.05008  loss_rpn_loc: 0.1118  time: 0.6878  data_time: 0.2202  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:56:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:56:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:56:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:56:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:56:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:56:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0888 s/iter. Eval: 0.0560 s/iter. Total: 0.1454 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 00:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0905 s/iter. Eval: 0.0736 s/iter. Total: 0.1650 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 00:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0892 s/iter. Eval: 0.0725 s/iter. Total: 0.1626 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 00:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0896 s/iter. Eval: 0.0770 s/iter. Total: 0.1675 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 00:57:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.373322 (0.167011 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:57:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.089569 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 00:57:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 00:57:06 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2763634513342404\n",
      "\u001b[32m[02/06 00:57:06 d2.utils.events]: \u001b[0m eta: 0:23:38  iter: 7259  total_loss: 1.345  loss_cls: 0.3392  loss_box_reg: 0.5448  loss_mask: 0.2929  loss_rpn_cls: 0.05213  loss_rpn_loc: 0.1217  time: 0.6878  data_time: 0.2110  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:57:19 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 7279  total_loss: 1.316  loss_cls: 0.3198  loss_box_reg: 0.5584  loss_mask: 0.2803  loss_rpn_cls: 0.04403  loss_rpn_loc: 0.1078  time: 0.6878  data_time: 0.1591  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:57:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 00:57:36 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 7299  total_loss: 1.404  loss_cls: 0.3623  loss_box_reg: 0.564  loss_mask: 0.2813  loss_rpn_cls: 0.06238  loss_rpn_loc: 0.1409  time: 0.6883  data_time: 0.2973  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:57:47 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 7319  total_loss: 1.236  loss_cls: 0.3111  loss_box_reg: 0.5137  loss_mask: 0.282  loss_rpn_cls: 0.03169  loss_rpn_loc: 0.1158  time: 0.6878  data_time: 0.0577  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:58:02 d2.utils.events]: \u001b[0m eta: 0:22:50  iter: 7339  total_loss: 1.434  loss_cls: 0.368  loss_box_reg: 0.5759  loss_mask: 0.3083  loss_rpn_cls: 0.05762  loss_rpn_loc: 0.1332  time: 0.6880  data_time: 0.2602  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:58:14 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 7359  total_loss: 1.312  loss_cls: 0.329  loss_box_reg: 0.5395  loss_mask: 0.2883  loss_rpn_cls: 0.03798  loss_rpn_loc: 0.1177  time: 0.6878  data_time: 0.0960  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:58:29 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 7379  total_loss: 1.438  loss_cls: 0.3533  loss_box_reg: 0.5664  loss_mask: 0.3051  loss_rpn_cls: 0.0462  loss_rpn_loc: 0.1213  time: 0.6879  data_time: 0.1979  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:58:41 d2.utils.events]: \u001b[0m eta: 0:22:18  iter: 7399  total_loss: 1.313  loss_cls: 0.3291  loss_box_reg: 0.5402  loss_mask: 0.2827  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.1102  time: 0.6877  data_time: 0.1547  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:58:57 d2.utils.events]: \u001b[0m eta: 0:22:05  iter: 7419  total_loss: 1.359  loss_cls: 0.3413  loss_box_reg: 0.5671  loss_mask: 0.2879  loss_rpn_cls: 0.04677  loss_rpn_loc: 0.09952  time: 0.6879  data_time: 0.2410  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:59:07 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 7439  total_loss: 1.266  loss_cls: 0.3221  loss_box_reg: 0.5333  loss_mask: 0.2774  loss_rpn_cls: 0.04429  loss_rpn_loc: 0.1201  time: 0.6875  data_time: 0.0457  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:59:18 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 7459  total_loss: 1.305  loss_cls: 0.3233  loss_box_reg: 0.5471  loss_mask: 0.2755  loss_rpn_cls: 0.03835  loss_rpn_loc: 0.1007  time: 0.6872  data_time: 0.0600  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:59:32 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 7479  total_loss: 1.348  loss_cls: 0.318  loss_box_reg: 0.5553  loss_mask: 0.2929  loss_rpn_cls: 0.03975  loss_rpn_loc: 0.1198  time: 0.6872  data_time: 0.2144  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:59:49 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 7499  total_loss: 1.33  loss_cls: 0.3449  loss_box_reg: 0.5429  loss_mask: 0.2963  loss_rpn_cls: 0.04878  loss_rpn_loc: 0.1312  time: 0.6876  data_time: 0.3441  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 00:59:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:59:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 00:59:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 00:59:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 00:59:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 00:59:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 00:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0898 s/iter. Eval: 0.0569 s/iter. Total: 0.1473 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 00:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0915 s/iter. Eval: 0.0741 s/iter. Total: 0.1665 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0726 s/iter. Total: 0.1648 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 01:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0918 s/iter. Eval: 0.0784 s/iter. Total: 0.1710 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:00:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.801975 (0.170707 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:00:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092277 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:00:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:00:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27254221222764025\n",
      "\u001b[32m[02/06 01:00:26 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 7519  total_loss: 1.346  loss_cls: 0.3372  loss_box_reg: 0.5579  loss_mask: 0.2922  loss_rpn_cls: 0.04401  loss_rpn_loc: 0.116  time: 0.6877  data_time: 0.2194  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:00:39 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 7539  total_loss: 1.254  loss_cls: 0.328  loss_box_reg: 0.5291  loss_mask: 0.2896  loss_rpn_cls: 0.0329  loss_rpn_loc: 0.1117  time: 0.6877  data_time: 0.2023  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:00:53 d2.utils.events]: \u001b[0m eta: 0:20:54  iter: 7559  total_loss: 1.483  loss_cls: 0.3781  loss_box_reg: 0.6054  loss_mask: 0.3072  loss_rpn_cls: 0.04301  loss_rpn_loc: 0.129  time: 0.6877  data_time: 0.1587  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:01:05 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 7579  total_loss: 1.342  loss_cls: 0.3309  loss_box_reg: 0.5567  loss_mask: 0.2984  loss_rpn_cls: 0.03211  loss_rpn_loc: 0.1092  time: 0.6875  data_time: 0.1451  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:01:22 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 7599  total_loss: 1.361  loss_cls: 0.3337  loss_box_reg: 0.545  loss_mask: 0.2775  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.1216  time: 0.6879  data_time: 0.3012  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:01:38 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 7619  total_loss: 1.353  loss_cls: 0.3375  loss_box_reg: 0.5309  loss_mask: 0.292  loss_rpn_cls: 0.05377  loss_rpn_loc: 0.145  time: 0.6882  data_time: 0.2952  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:01:50 d2.utils.events]: \u001b[0m eta: 0:20:14  iter: 7639  total_loss: 1.265  loss_cls: 0.322  loss_box_reg: 0.5206  loss_mask: 0.2855  loss_rpn_cls: 0.02852  loss_rpn_loc: 0.1038  time: 0.6879  data_time: 0.1138  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:02:04 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 7659  total_loss: 1.376  loss_cls: 0.3442  loss_box_reg: 0.5508  loss_mask: 0.2936  loss_rpn_cls: 0.05463  loss_rpn_loc: 0.1418  time: 0.6880  data_time: 0.2028  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:02:15 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 7679  total_loss: 1.273  loss_cls: 0.3139  loss_box_reg: 0.5247  loss_mask: 0.2784  loss_rpn_cls: 0.05296  loss_rpn_loc: 0.1202  time: 0.6877  data_time: 0.1135  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:02:27 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 7699  total_loss: 1.389  loss_cls: 0.3312  loss_box_reg: 0.5556  loss_mask: 0.3046  loss_rpn_cls: 0.04431  loss_rpn_loc: 0.122  time: 0.6875  data_time: 0.0850  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:02:43 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 7719  total_loss: 1.394  loss_cls: 0.3487  loss_box_reg: 0.5638  loss_mask: 0.3061  loss_rpn_cls: 0.06197  loss_rpn_loc: 0.1179  time: 0.6877  data_time: 0.2381  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:02:55 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 7739  total_loss: 1.321  loss_cls: 0.322  loss_box_reg: 0.5445  loss_mask: 0.2875  loss_rpn_cls: 0.04754  loss_rpn_loc: 0.1132  time: 0.6875  data_time: 0.1450  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:03:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:03:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:03:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:03:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:03:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:03:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0895 s/iter. Eval: 0.0546 s/iter. Total: 0.1448 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 01:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0730 s/iter. Total: 0.1650 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:03:12 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0718 s/iter. Total: 0.1635 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 01:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0915 s/iter. Eval: 0.0774 s/iter. Total: 0.1698 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:03:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.538635 (0.168437 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:03:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091481 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:03:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:03:21 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27330389359366675\n",
      "\u001b[32m[02/06 01:03:30 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 7759  total_loss: 1.351  loss_cls: 0.3403  loss_box_reg: 0.5526  loss_mask: 0.2886  loss_rpn_cls: 0.03906  loss_rpn_loc: 0.12  time: 0.6875  data_time: 0.1576  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:03:44 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 7779  total_loss: 1.397  loss_cls: 0.3386  loss_box_reg: 0.5508  loss_mask: 0.2876  loss_rpn_cls: 0.06007  loss_rpn_loc: 0.1303  time: 0.6875  data_time: 0.2033  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:03:58 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 7799  total_loss: 1.337  loss_cls: 0.3574  loss_box_reg: 0.5446  loss_mask: 0.2976  loss_rpn_cls: 0.04613  loss_rpn_loc: 0.1207  time: 0.6875  data_time: 0.1888  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:04:10 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 7819  total_loss: 1.275  loss_cls: 0.3156  loss_box_reg: 0.5304  loss_mask: 0.2902  loss_rpn_cls: 0.03894  loss_rpn_loc: 0.09541  time: 0.6873  data_time: 0.1057  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:04:22 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 7839  total_loss: 1.275  loss_cls: 0.3289  loss_box_reg: 0.5352  loss_mask: 0.2819  loss_rpn_cls: 0.03923  loss_rpn_loc: 0.1154  time: 0.6871  data_time: 0.1275  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:04:35 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 7859  total_loss: 1.266  loss_cls: 0.3069  loss_box_reg: 0.5191  loss_mask: 0.2866  loss_rpn_cls: 0.02997  loss_rpn_loc: 0.1105  time: 0.6870  data_time: 0.1790  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:04:52 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 7879  total_loss: 1.387  loss_cls: 0.3319  loss_box_reg: 0.5449  loss_mask: 0.3039  loss_rpn_cls: 0.0671  loss_rpn_loc: 0.1327  time: 0.6874  data_time: 0.3222  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:05:06 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 7899  total_loss: 1.432  loss_cls: 0.3475  loss_box_reg: 0.5802  loss_mask: 0.2994  loss_rpn_cls: 0.04916  loss_rpn_loc: 0.1275  time: 0.6875  data_time: 0.2278  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:05:21 d2.utils.events]: \u001b[0m eta: 0:17:42  iter: 7919  total_loss: 1.234  loss_cls: 0.3366  loss_box_reg: 0.5502  loss_mask: 0.2904  loss_rpn_cls: 0.03166  loss_rpn_loc: 0.1043  time: 0.6876  data_time: 0.2351  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:05:35 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 7939  total_loss: 1.414  loss_cls: 0.3468  loss_box_reg: 0.5649  loss_mask: 0.2889  loss_rpn_cls: 0.05938  loss_rpn_loc: 0.1293  time: 0.6876  data_time: 0.2218  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:05:47 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 7959  total_loss: 1.331  loss_cls: 0.3087  loss_box_reg: 0.5224  loss_mask: 0.2793  loss_rpn_cls: 0.05613  loss_rpn_loc: 0.1232  time: 0.6875  data_time: 0.1341  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:06:00 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 7979  total_loss: 1.286  loss_cls: 0.3115  loss_box_reg: 0.5407  loss_mask: 0.2844  loss_rpn_cls: 0.03615  loss_rpn_loc: 0.1105  time: 0.6874  data_time: 0.1669  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:06:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:06:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:06:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:06:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:06:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:06:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.0888 s/iter. Eval: 0.0527 s/iter. Total: 0.1421 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 01:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0007 s/iter. Inference: 0.0908 s/iter. Eval: 0.0699 s/iter. Total: 0.1615 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 01:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0700 s/iter. Total: 0.1616 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 01:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0749 s/iter. Total: 0.1669 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:06:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.311347 (0.166477 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:06:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091097 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:06:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:06:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27500993243409405\n",
      "\u001b[32m[02/06 01:06:36 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 7999  total_loss: 1.5  loss_cls: 0.3856  loss_box_reg: 0.5873  loss_mask: 0.3254  loss_rpn_cls: 0.05153  loss_rpn_loc: 0.1413  time: 0.6875  data_time: 0.2548  lr: 0.00013107  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:06:51 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 8019  total_loss: 1.331  loss_cls: 0.3432  loss_box_reg: 0.5387  loss_mask: 0.2918  loss_rpn_cls: 0.03285  loss_rpn_loc: 0.1214  time: 0.6877  data_time: 0.2474  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:07:07 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 8039  total_loss: 1.359  loss_cls: 0.3447  loss_box_reg: 0.5591  loss_mask: 0.2941  loss_rpn_cls: 0.04936  loss_rpn_loc: 0.1268  time: 0.6879  data_time: 0.2612  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:07:22 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 8059  total_loss: 1.317  loss_cls: 0.3022  loss_box_reg: 0.5433  loss_mask: 0.2849  loss_rpn_cls: 0.04433  loss_rpn_loc: 0.1415  time: 0.6880  data_time: 0.2574  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:07:34 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 8079  total_loss: 1.26  loss_cls: 0.3136  loss_box_reg: 0.5422  loss_mask: 0.2965  loss_rpn_cls: 0.03613  loss_rpn_loc: 0.08822  time: 0.6879  data_time: 0.1434  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:07:50 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 8099  total_loss: 1.401  loss_cls: 0.3472  loss_box_reg: 0.5791  loss_mask: 0.309  loss_rpn_cls: 0.05119  loss_rpn_loc: 0.1187  time: 0.6881  data_time: 0.2635  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:08:05 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 8119  total_loss: 1.294  loss_cls: 0.3363  loss_box_reg: 0.5474  loss_mask: 0.2879  loss_rpn_cls: 0.05649  loss_rpn_loc: 0.1116  time: 0.6882  data_time: 0.2253  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:08:16 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 8139  total_loss: 1.236  loss_cls: 0.325  loss_box_reg: 0.5161  loss_mask: 0.276  loss_rpn_cls: 0.04239  loss_rpn_loc: 0.09824  time: 0.6880  data_time: 0.1303  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:08:29 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 8159  total_loss: 1.344  loss_cls: 0.3236  loss_box_reg: 0.5504  loss_mask: 0.2842  loss_rpn_cls: 0.04814  loss_rpn_loc: 0.123  time: 0.6878  data_time: 0.1500  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:08:43 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 8179  total_loss: 1.476  loss_cls: 0.3851  loss_box_reg: 0.5704  loss_mask: 0.3049  loss_rpn_cls: 0.06193  loss_rpn_loc: 0.1546  time: 0.6878  data_time: 0.2077  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:08:55 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 8199  total_loss: 1.441  loss_cls: 0.3667  loss_box_reg: 0.5726  loss_mask: 0.292  loss_rpn_cls: 0.06206  loss_rpn_loc: 0.131  time: 0.6877  data_time: 0.1137  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:09:09 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 8219  total_loss: 1.327  loss_cls: 0.3222  loss_box_reg: 0.5605  loss_mask: 0.2814  loss_rpn_cls: 0.04803  loss_rpn_loc: 0.1216  time: 0.6876  data_time: 0.1766  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:09:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:09:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:09:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:09:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:09:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:09:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:09:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0935 s/iter. Eval: 0.0565 s/iter. Total: 0.1507 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 01:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0925 s/iter. Eval: 0.0762 s/iter. Total: 0.1695 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:09:29 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0752 s/iter. Total: 0.1692 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 01:09:34 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0804 s/iter. Total: 0.1743 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/06 01:09:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.894688 (0.171506 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:09:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092721 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:09:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:09:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27392613507975994\n",
      "\u001b[32m[02/06 01:09:44 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 8239  total_loss: 1.372  loss_cls: 0.3447  loss_box_reg: 0.5645  loss_mask: 0.3088  loss_rpn_cls: 0.0429  loss_rpn_loc: 0.1293  time: 0.6876  data_time: 0.1731  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:09:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 01:10:01 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 8259  total_loss: 1.54  loss_cls: 0.3898  loss_box_reg: 0.5785  loss_mask: 0.3171  loss_rpn_cls: 0.05781  loss_rpn_loc: 0.1533  time: 0.6880  data_time: 0.2629  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:10:15 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 8279  total_loss: 1.364  loss_cls: 0.3531  loss_box_reg: 0.5505  loss_mask: 0.284  loss_rpn_cls: 0.04902  loss_rpn_loc: 0.1129  time: 0.6881  data_time: 0.2467  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:10:28 d2.utils.events]: \u001b[0m eta: 0:14:34  iter: 8299  total_loss: 1.237  loss_cls: 0.2779  loss_box_reg: 0.5275  loss_mask: 0.2824  loss_rpn_cls: 0.03663  loss_rpn_loc: 0.1007  time: 0.6879  data_time: 0.1555  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:10:44 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 8319  total_loss: 1.29  loss_cls: 0.3284  loss_box_reg: 0.5336  loss_mask: 0.2807  loss_rpn_cls: 0.04342  loss_rpn_loc: 0.1326  time: 0.6882  data_time: 0.2865  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:11:00 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 8339  total_loss: 1.364  loss_cls: 0.3419  loss_box_reg: 0.5357  loss_mask: 0.2946  loss_rpn_cls: 0.04649  loss_rpn_loc: 0.1211  time: 0.6885  data_time: 0.3233  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:11:15 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 8359  total_loss: 1.419  loss_cls: 0.3575  loss_box_reg: 0.5805  loss_mask: 0.3018  loss_rpn_cls: 0.05507  loss_rpn_loc: 0.132  time: 0.6886  data_time: 0.2507  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:11:27 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 8379  total_loss: 1.402  loss_cls: 0.3398  loss_box_reg: 0.5564  loss_mask: 0.2938  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.1249  time: 0.6884  data_time: 0.1008  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:11:42 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 8399  total_loss: 1.357  loss_cls: 0.3462  loss_box_reg: 0.5307  loss_mask: 0.2857  loss_rpn_cls: 0.04994  loss_rpn_loc: 0.1218  time: 0.6886  data_time: 0.2672  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:11:54 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 8419  total_loss: 1.349  loss_cls: 0.3323  loss_box_reg: 0.5505  loss_mask: 0.2847  loss_rpn_cls: 0.0409  loss_rpn_loc: 0.1162  time: 0.6884  data_time: 0.1242  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:12:07 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 8439  total_loss: 1.37  loss_cls: 0.3226  loss_box_reg: 0.5718  loss_mask: 0.2995  loss_rpn_cls: 0.04647  loss_rpn_loc: 0.1287  time: 0.6883  data_time: 0.1817  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:12:17 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 8459  total_loss: 1.253  loss_cls: 0.2906  loss_box_reg: 0.5356  loss_mask: 0.2879  loss_rpn_cls: 0.03086  loss_rpn_loc: 0.09603  time: 0.6878  data_time: 0.0464  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:12:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:12:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:12:25 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:12:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:12:25 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:12:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0894 s/iter. Eval: 0.0606 s/iter. Total: 0.1507 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 01:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0895 s/iter. Eval: 0.0751 s/iter. Total: 0.1654 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:12:37 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0894 s/iter. Eval: 0.0739 s/iter. Total: 0.1641 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 01:12:42 d2.evaluation.evaluator]: \u001b[0mInference done 100/121. Dataloading: 0.0008 s/iter. Inference: 0.0907 s/iter. Eval: 0.0792 s/iter. Total: 0.1707 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:12:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.683386 (0.169684 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:12:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090577 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:12:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:12:46 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2705488248200559\n",
      "\u001b[32m[02/06 01:12:53 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 8479  total_loss: 1.376  loss_cls: 0.3382  loss_box_reg: 0.5621  loss_mask: 0.3002  loss_rpn_cls: 0.05348  loss_rpn_loc: 0.1148  time: 0.6878  data_time: 0.2129  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:13:04 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 8499  total_loss: 1.467  loss_cls: 0.3616  loss_box_reg: 0.5695  loss_mask: 0.3049  loss_rpn_cls: 0.04054  loss_rpn_loc: 0.127  time: 0.6876  data_time: 0.1021  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:13:17 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 8519  total_loss: 1.273  loss_cls: 0.2956  loss_box_reg: 0.5189  loss_mask: 0.289  loss_rpn_cls: 0.04968  loss_rpn_loc: 0.1111  time: 0.6874  data_time: 0.1715  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:13:33 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 8539  total_loss: 1.297  loss_cls: 0.3347  loss_box_reg: 0.547  loss_mask: 0.2813  loss_rpn_cls: 0.03786  loss_rpn_loc: 0.1104  time: 0.6877  data_time: 0.3298  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:13:46 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 8559  total_loss: 1.156  loss_cls: 0.2764  loss_box_reg: 0.5053  loss_mask: 0.2733  loss_rpn_cls: 0.043  loss_rpn_loc: 0.09423  time: 0.6876  data_time: 0.1718  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:13:56 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 8579  total_loss: 1.398  loss_cls: 0.3639  loss_box_reg: 0.5569  loss_mask: 0.2862  loss_rpn_cls: 0.04161  loss_rpn_loc: 0.1197  time: 0.6872  data_time: 0.0495  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:14:12 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 8599  total_loss: 1.418  loss_cls: 0.3488  loss_box_reg: 0.5644  loss_mask: 0.2917  loss_rpn_cls: 0.05964  loss_rpn_loc: 0.1412  time: 0.6875  data_time: 0.3223  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:14:26 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 8619  total_loss: 1.371  loss_cls: 0.323  loss_box_reg: 0.5558  loss_mask: 0.2927  loss_rpn_cls: 0.03946  loss_rpn_loc: 0.1042  time: 0.6875  data_time: 0.2256  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:14:40 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 8639  total_loss: 1.317  loss_cls: 0.3196  loss_box_reg: 0.558  loss_mask: 0.3009  loss_rpn_cls: 0.04279  loss_rpn_loc: 0.1168  time: 0.6875  data_time: 0.1960  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:14:50 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 8659  total_loss: 1.308  loss_cls: 0.3342  loss_box_reg: 0.5392  loss_mask: 0.2881  loss_rpn_cls: 0.04292  loss_rpn_loc: 0.1087  time: 0.6871  data_time: 0.0363  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:15:08 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 8679  total_loss: 1.434  loss_cls: 0.3434  loss_box_reg: 0.5441  loss_mask: 0.2819  loss_rpn_cls: 0.05567  loss_rpn_loc: 0.1313  time: 0.6876  data_time: 0.3915  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:15:21 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 8699  total_loss: 1.285  loss_cls: 0.3143  loss_box_reg: 0.5198  loss_mask: 0.2875  loss_rpn_cls: 0.04726  loss_rpn_loc: 0.1066  time: 0.6875  data_time: 0.1533  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:15:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:15:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:15:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:15:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:15:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:15:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:15:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0900 s/iter. Eval: 0.0540 s/iter. Total: 0.1447 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 01:15:38 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0712 s/iter. Total: 0.1632 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:15:43 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0905 s/iter. Eval: 0.0706 s/iter. Total: 0.1620 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 01:15:48 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0908 s/iter. Eval: 0.0753 s/iter. Total: 0.1670 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:15:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.519585 (0.168272 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:15:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091406 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:15:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:15:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2721017045884285\n",
      "\u001b[32m[02/06 01:15:57 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 8719  total_loss: 1.337  loss_cls: 0.3478  loss_box_reg: 0.5391  loss_mask: 0.2882  loss_rpn_cls: 0.05176  loss_rpn_loc: 0.1216  time: 0.6876  data_time: 0.2387  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:16:09 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 8739  total_loss: 1.321  loss_cls: 0.3307  loss_box_reg: 0.5547  loss_mask: 0.2901  loss_rpn_cls: 0.0326  loss_rpn_loc: 0.1153  time: 0.6873  data_time: 0.0727  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:16:24 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 8759  total_loss: 1.435  loss_cls: 0.3728  loss_box_reg: 0.5875  loss_mask: 0.3154  loss_rpn_cls: 0.0592  loss_rpn_loc: 0.1349  time: 0.6876  data_time: 0.2824  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:16:37 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 8779  total_loss: 1.232  loss_cls: 0.3078  loss_box_reg: 0.5388  loss_mask: 0.2848  loss_rpn_cls: 0.03944  loss_rpn_loc: 0.09952  time: 0.6875  data_time: 0.1439  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:16:49 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 8799  total_loss: 1.332  loss_cls: 0.3166  loss_box_reg: 0.5155  loss_mask: 0.2782  loss_rpn_cls: 0.04257  loss_rpn_loc: 0.1156  time: 0.6873  data_time: 0.1179  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:17:01 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 8819  total_loss: 1.369  loss_cls: 0.341  loss_box_reg: 0.556  loss_mask: 0.2942  loss_rpn_cls: 0.04666  loss_rpn_loc: 0.1209  time: 0.6871  data_time: 0.1135  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:17:18 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 8839  total_loss: 1.388  loss_cls: 0.3664  loss_box_reg: 0.5376  loss_mask: 0.2984  loss_rpn_cls: 0.06367  loss_rpn_loc: 0.1208  time: 0.6874  data_time: 0.3070  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:17:33 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 8859  total_loss: 1.331  loss_cls: 0.3349  loss_box_reg: 0.5303  loss_mask: 0.3007  loss_rpn_cls: 0.04927  loss_rpn_loc: 0.128  time: 0.6876  data_time: 0.2727  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:17:47 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 8879  total_loss: 1.386  loss_cls: 0.355  loss_box_reg: 0.5828  loss_mask: 0.2943  loss_rpn_cls: 0.0453  loss_rpn_loc: 0.1083  time: 0.6876  data_time: 0.1914  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:17:59 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 8899  total_loss: 1.339  loss_cls: 0.3112  loss_box_reg: 0.5447  loss_mask: 0.3024  loss_rpn_cls: 0.03655  loss_rpn_loc: 0.1225  time: 0.6873  data_time: 0.1166  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:18:14 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 8919  total_loss: 1.345  loss_cls: 0.3418  loss_box_reg: 0.5436  loss_mask: 0.2807  loss_rpn_cls: 0.04754  loss_rpn_loc: 0.1267  time: 0.6875  data_time: 0.2569  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:18:29 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 8939  total_loss: 1.368  loss_cls: 0.3628  loss_box_reg: 0.56  loss_mask: 0.3072  loss_rpn_cls: 0.06762  loss_rpn_loc: 0.1225  time: 0.6877  data_time: 0.2700  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:18:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:18:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:18:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:18:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:18:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:18:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0907 s/iter. Eval: 0.0577 s/iter. Total: 0.1492 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 01:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0916 s/iter. Eval: 0.0732 s/iter. Total: 0.1657 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0912 s/iter. Eval: 0.0716 s/iter. Total: 0.1637 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 01:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0008 s/iter. Inference: 0.0917 s/iter. Eval: 0.0780 s/iter. Total: 0.1705 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:18:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.682872 (0.169680 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:18:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091686 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:18:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:18:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2737172970588742\n",
      "\u001b[32m[02/06 01:19:03 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 8959  total_loss: 1.244  loss_cls: 0.3081  loss_box_reg: 0.529  loss_mask: 0.2747  loss_rpn_cls: 0.04  loss_rpn_loc: 0.1089  time: 0.6875  data_time: 0.1220  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:19:17 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 8979  total_loss: 1.382  loss_cls: 0.3388  loss_box_reg: 0.5283  loss_mask: 0.2944  loss_rpn_cls: 0.05287  loss_rpn_loc: 0.1281  time: 0.6876  data_time: 0.2147  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:19:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 01:19:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 01:19:36 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 8999  total_loss: 1.377  loss_cls: 0.3213  loss_box_reg: 0.5504  loss_mask: 0.2896  loss_rpn_cls: 0.03817  loss_rpn_loc: 0.1259  time: 0.6881  data_time: 0.2689  lr: 0.00010486  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:19:50 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 9019  total_loss: 1.333  loss_cls: 0.3267  loss_box_reg: 0.5572  loss_mask: 0.3089  loss_rpn_cls: 0.05237  loss_rpn_loc: 0.1245  time: 0.6882  data_time: 0.2299  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:20:05 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 9039  total_loss: 1.346  loss_cls: 0.3394  loss_box_reg: 0.5595  loss_mask: 0.2863  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.1167  time: 0.6883  data_time: 0.2165  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:20:18 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 9059  total_loss: 1.387  loss_cls: 0.3509  loss_box_reg: 0.5562  loss_mask: 0.2949  loss_rpn_cls: 0.04354  loss_rpn_loc: 0.1201  time: 0.6882  data_time: 0.1481  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:20:31 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 9079  total_loss: 1.315  loss_cls: 0.3206  loss_box_reg: 0.5483  loss_mask: 0.2875  loss_rpn_cls: 0.03831  loss_rpn_loc: 0.1229  time: 0.6882  data_time: 0.1696  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:20:47 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 9099  total_loss: 1.428  loss_cls: 0.3802  loss_box_reg: 0.5464  loss_mask: 0.3003  loss_rpn_cls: 0.05527  loss_rpn_loc: 0.1526  time: 0.6884  data_time: 0.2904  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:20:55 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 01:21:04 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 9119  total_loss: 1.437  loss_cls: 0.3493  loss_box_reg: 0.5588  loss_mask: 0.2928  loss_rpn_cls: 0.05195  loss_rpn_loc: 0.138  time: 0.6887  data_time: 0.2529  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:21:19 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 9139  total_loss: 1.281  loss_cls: 0.3337  loss_box_reg: 0.5225  loss_mask: 0.2738  loss_rpn_cls: 0.04937  loss_rpn_loc: 0.1279  time: 0.6889  data_time: 0.2409  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:21:32 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 9159  total_loss: 1.369  loss_cls: 0.3526  loss_box_reg: 0.5616  loss_mask: 0.2945  loss_rpn_cls: 0.05251  loss_rpn_loc: 0.1136  time: 0.6888  data_time: 0.1796  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:21:43 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 9179  total_loss: 1.223  loss_cls: 0.2895  loss_box_reg: 0.5216  loss_mask: 0.281  loss_rpn_cls: 0.02373  loss_rpn_loc: 0.08559  time: 0.6885  data_time: 0.0408  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:21:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:21:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:21:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:21:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:21:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:21:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0936 s/iter. Eval: 0.0628 s/iter. Total: 0.1572 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/06 01:22:02 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0929 s/iter. Eval: 0.0774 s/iter. Total: 0.1713 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0753 s/iter. Total: 0.1672 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 01:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0910 s/iter. Eval: 0.0808 s/iter. Total: 0.1727 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:22:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.694762 (0.169782 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:22:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090383 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:22:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:22:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27384846148819075\n",
      "\u001b[32m[02/06 01:22:18 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 9199  total_loss: 1.227  loss_cls: 0.313  loss_box_reg: 0.5247  loss_mask: 0.2827  loss_rpn_cls: 0.03531  loss_rpn_loc: 0.1071  time: 0.6884  data_time: 0.1577  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:22:28 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 9219  total_loss: 1.3  loss_cls: 0.3157  loss_box_reg: 0.5428  loss_mask: 0.2799  loss_rpn_cls: 0.03809  loss_rpn_loc: 0.108  time: 0.6881  data_time: 0.0716  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:22:43 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 9239  total_loss: 1.374  loss_cls: 0.3369  loss_box_reg: 0.5371  loss_mask: 0.3015  loss_rpn_cls: 0.04915  loss_rpn_loc: 0.1197  time: 0.6881  data_time: 0.2258  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:22:56 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 9259  total_loss: 1.313  loss_cls: 0.3307  loss_box_reg: 0.5465  loss_mask: 0.2963  loss_rpn_cls: 0.04179  loss_rpn_loc: 0.1074  time: 0.6880  data_time: 0.1823  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:23:08 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 9279  total_loss: 1.241  loss_cls: 0.292  loss_box_reg: 0.5172  loss_mask: 0.2779  loss_rpn_cls: 0.03124  loss_rpn_loc: 0.08171  time: 0.6880  data_time: 0.1783  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:23:22 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 9299  total_loss: 1.442  loss_cls: 0.3636  loss_box_reg: 0.562  loss_mask: 0.3045  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.1201  time: 0.6879  data_time: 0.1931  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:23:35 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 9319  total_loss: 1.324  loss_cls: 0.3253  loss_box_reg: 0.5222  loss_mask: 0.2893  loss_rpn_cls: 0.04111  loss_rpn_loc: 0.1267  time: 0.6879  data_time: 0.1840  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:23:48 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 9339  total_loss: 1.312  loss_cls: 0.3401  loss_box_reg: 0.5429  loss_mask: 0.2824  loss_rpn_cls: 0.05023  loss_rpn_loc: 0.1348  time: 0.6878  data_time: 0.1124  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:24:02 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 9359  total_loss: 1.256  loss_cls: 0.3125  loss_box_reg: 0.5379  loss_mask: 0.2776  loss_rpn_cls: 0.02973  loss_rpn_loc: 0.1025  time: 0.6878  data_time: 0.2237  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:24:16 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 9379  total_loss: 1.328  loss_cls: 0.3321  loss_box_reg: 0.5314  loss_mask: 0.282  loss_rpn_cls: 0.04766  loss_rpn_loc: 0.1206  time: 0.6878  data_time: 0.1755  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:24:29 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 9399  total_loss: 1.336  loss_cls: 0.3273  loss_box_reg: 0.5572  loss_mask: 0.2984  loss_rpn_cls: 0.04743  loss_rpn_loc: 0.1197  time: 0.6877  data_time: 0.1619  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:24:44 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 9419  total_loss: 1.395  loss_cls: 0.3649  loss_box_reg: 0.5663  loss_mask: 0.3014  loss_rpn_cls: 0.03342  loss_rpn_loc: 0.1216  time: 0.6878  data_time: 0.2209  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:24:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 01:24:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:24:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:24:57 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:24:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:24:57 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:24:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.0925 s/iter. Eval: 0.0613 s/iter. Total: 0.1545 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 01:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0927 s/iter. Eval: 0.0763 s/iter. Total: 0.1698 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:25:10 d2.evaluation.evaluator]: \u001b[0mInference done 72/121. Dataloading: 0.0008 s/iter. Inference: 0.0923 s/iter. Eval: 0.0743 s/iter. Total: 0.1674 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 01:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.0931 s/iter. Eval: 0.0812 s/iter. Total: 0.1752 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/06 01:25:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.967729 (0.172136 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:25:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.092508 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:25:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:25:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2748281358383743\n",
      "\u001b[32m[02/06 01:25:20 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 9439  total_loss: 1.274  loss_cls: 0.3024  loss_box_reg: 0.5329  loss_mask: 0.2853  loss_rpn_cls: 0.05503  loss_rpn_loc: 0.1128  time: 0.6879  data_time: 0.1319  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:25:34 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 9459  total_loss: 1.431  loss_cls: 0.3676  loss_box_reg: 0.5824  loss_mask: 0.3018  loss_rpn_cls: 0.05812  loss_rpn_loc: 0.1358  time: 0.6879  data_time: 0.2276  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:25:51 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 9479  total_loss: 1.43  loss_cls: 0.3667  loss_box_reg: 0.5421  loss_mask: 0.3059  loss_rpn_cls: 0.06395  loss_rpn_loc: 0.1459  time: 0.6883  data_time: 0.3501  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:26:06 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 9499  total_loss: 1.296  loss_cls: 0.3225  loss_box_reg: 0.5176  loss_mask: 0.2717  loss_rpn_cls: 0.04044  loss_rpn_loc: 0.1271  time: 0.6884  data_time: 0.2350  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:26:23 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 9519  total_loss: 1.363  loss_cls: 0.3482  loss_box_reg: 0.5709  loss_mask: 0.2991  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.128  time: 0.6888  data_time: 0.3432  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:26:42 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 9539  total_loss: 1.352  loss_cls: 0.3427  loss_box_reg: 0.5471  loss_mask: 0.2939  loss_rpn_cls: 0.04717  loss_rpn_loc: 0.1254  time: 0.6893  data_time: 0.3931  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:26:56 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 9559  total_loss: 1.306  loss_cls: 0.3125  loss_box_reg: 0.5539  loss_mask: 0.2945  loss_rpn_cls: 0.03288  loss_rpn_loc: 0.09751  time: 0.6893  data_time: 0.2017  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:27:08 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 9579  total_loss: 1.335  loss_cls: 0.3246  loss_box_reg: 0.5521  loss_mask: 0.296  loss_rpn_cls: 0.03921  loss_rpn_loc: 0.1067  time: 0.6891  data_time: 0.0910  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:27:21 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 9599  total_loss: 1.316  loss_cls: 0.3182  loss_box_reg: 0.5373  loss_mask: 0.2872  loss_rpn_cls: 0.04505  loss_rpn_loc: 0.1164  time: 0.6891  data_time: 0.1346  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:27:35 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 9619  total_loss: 1.404  loss_cls: 0.3445  loss_box_reg: 0.5673  loss_mask: 0.2855  loss_rpn_cls: 0.05931  loss_rpn_loc: 0.1197  time: 0.6891  data_time: 0.1744  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:27:47 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9639  total_loss: 1.305  loss_cls: 0.3287  loss_box_reg: 0.5271  loss_mask: 0.2972  loss_rpn_cls: 0.04119  loss_rpn_loc: 0.1305  time: 0.6889  data_time: 0.1076  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:28:04 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 9659  total_loss: 1.388  loss_cls: 0.3352  loss_box_reg: 0.5452  loss_mask: 0.297  loss_rpn_cls: 0.04165  loss_rpn_loc: 0.1201  time: 0.6892  data_time: 0.3170  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:28:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:28:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:28:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:28:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:28:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:28:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.0680 s/iter. Total: 0.1644 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 01:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 40/121. Dataloading: 0.0008 s/iter. Inference: 0.0946 s/iter. Eval: 0.0780 s/iter. Total: 0.1734 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/06 01:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.0941 s/iter. Eval: 0.0752 s/iter. Total: 0.1702 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 01:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.0951 s/iter. Eval: 0.0829 s/iter. Total: 0.1789 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/06 01:28:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:20.508426 (0.176797 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:28:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.094953 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:28:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:28:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27704069690040545\n",
      "\u001b[32m[02/06 01:28:37 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 9679  total_loss: 1.265  loss_cls: 0.2956  loss_box_reg: 0.5104  loss_mask: 0.2723  loss_rpn_cls: 0.03911  loss_rpn_loc: 0.1005  time: 0.6889  data_time: 0.0525  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:28:48 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 9699  total_loss: 1.285  loss_cls: 0.3113  loss_box_reg: 0.5456  loss_mask: 0.2844  loss_rpn_cls: 0.03675  loss_rpn_loc: 0.1118  time: 0.6886  data_time: 0.0737  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:29:02 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9719  total_loss: 1.268  loss_cls: 0.3063  loss_box_reg: 0.5158  loss_mask: 0.2844  loss_rpn_cls: 0.04322  loss_rpn_loc: 0.1145  time: 0.6886  data_time: 0.1697  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:29:15 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 9739  total_loss: 1.356  loss_cls: 0.3272  loss_box_reg: 0.5584  loss_mask: 0.2824  loss_rpn_cls: 0.03524  loss_rpn_loc: 0.1348  time: 0.6886  data_time: 0.1883  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:29:28 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 9759  total_loss: 1.46  loss_cls: 0.3654  loss_box_reg: 0.5734  loss_mask: 0.2899  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.1512  time: 0.6885  data_time: 0.1572  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:29:42 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 9779  total_loss: 1.375  loss_cls: 0.3254  loss_box_reg: 0.5676  loss_mask: 0.3056  loss_rpn_cls: 0.04602  loss_rpn_loc: 0.1225  time: 0.6885  data_time: 0.1783  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:29:55 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 9799  total_loss: 1.305  loss_cls: 0.3133  loss_box_reg: 0.5324  loss_mask: 0.2889  loss_rpn_cls: 0.0367  loss_rpn_loc: 0.1069  time: 0.6885  data_time: 0.2126  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:30:10 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9819  total_loss: 1.378  loss_cls: 0.3554  loss_box_reg: 0.5592  loss_mask: 0.2967  loss_rpn_cls: 0.03949  loss_rpn_loc: 0.1376  time: 0.6886  data_time: 0.2388  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:30:24 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 9839  total_loss: 1.244  loss_cls: 0.3081  loss_box_reg: 0.526  loss_mask: 0.293  loss_rpn_cls: 0.03494  loss_rpn_loc: 0.09453  time: 0.6885  data_time: 0.1785  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:30:38 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 9859  total_loss: 1.304  loss_cls: 0.3239  loss_box_reg: 0.5473  loss_mask: 0.2805  loss_rpn_cls: 0.03814  loss_rpn_loc: 0.1178  time: 0.6886  data_time: 0.2472  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:30:49 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9879  total_loss: 1.329  loss_cls: 0.3098  loss_box_reg: 0.5443  loss_mask: 0.2854  loss_rpn_cls: 0.03572  loss_rpn_loc: 0.116  time: 0.6883  data_time: 0.0559  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:30:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f9b0687f1f0> to CPU due to CUDA OOM\n",
      "\u001b[32m[02/06 01:31:07 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 9899  total_loss: 1.311  loss_cls: 0.3507  loss_box_reg: 0.549  loss_mask: 0.2758  loss_rpn_cls: 0.05029  loss_rpn_loc: 0.1389  time: 0.6887  data_time: 0.3390  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:31:19 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 9919  total_loss: 1.373  loss_cls: 0.3509  loss_box_reg: 0.569  loss_mask: 0.281  loss_rpn_cls: 0.05432  loss_rpn_loc: 0.1137  time: 0.6886  data_time: 0.1235  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:31:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:31:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:31:23 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:31:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:31:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:31:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0673 s/iter. Total: 0.1594 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/06 01:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0727 s/iter. Total: 0.1644 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 01:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0731 s/iter. Total: 0.1648 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 01:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0911 s/iter. Eval: 0.0771 s/iter. Total: 0.1691 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:31:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.528489 (0.168349 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:31:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.090958 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:31:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:31:44 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2758380095213904\n",
      "\u001b[32m[02/06 01:31:56 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9939  total_loss: 1.354  loss_cls: 0.3561  loss_box_reg: 0.5501  loss_mask: 0.2959  loss_rpn_cls: 0.05742  loss_rpn_loc: 0.1138  time: 0.6888  data_time: 0.2685  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:32:09 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 9959  total_loss: 1.288  loss_cls: 0.316  loss_box_reg: 0.5265  loss_mask: 0.2869  loss_rpn_cls: 0.04137  loss_rpn_loc: 0.1046  time: 0.6886  data_time: 0.1345  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:32:23 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 9979  total_loss: 1.431  loss_cls: 0.3719  loss_box_reg: 0.5692  loss_mask: 0.302  loss_rpn_cls: 0.06234  loss_rpn_loc: 0.1585  time: 0.6887  data_time: 0.2173  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:32:38 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.277  loss_cls: 0.3069  loss_box_reg: 0.538  loss_mask: 0.2779  loss_rpn_cls: 0.04985  loss_rpn_loc: 0.1174  time: 0.6888  data_time: 0.2349  lr: 8.3886e-05  max_mem: 9526M\n",
      "\u001b[32m[02/06 01:32:38 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:54:46 (0.6888 s / it)\n",
      "\u001b[32m[02/06 01:32:38 d2.engine.hooks]: \u001b[0mTotal training time: 2:09:16 (0:14:30 on hooks)\n",
      "\u001b[32m[02/06 01:32:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:32:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 01:32:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 01:32:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 01:32:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 01:32:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 01:32:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.0930 s/iter. Eval: 0.0683 s/iter. Total: 0.1622 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/06 01:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 41/121. Dataloading: 0.0008 s/iter. Inference: 0.0918 s/iter. Eval: 0.0754 s/iter. Total: 0.1680 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 01:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0729 s/iter. Total: 0.1647 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 01:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0008 s/iter. Inference: 0.0913 s/iter. Eval: 0.0773 s/iter. Total: 0.1694 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 01:32:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.545236 (0.168493 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:32:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:10 (0.091060 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 01:32:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 01:32:59 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2742426883472815\n"
     ]
    }
   ],
   "source": [
    "# changing the RPN IOU thresholds and the NMS threshold\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 4000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24], [40], [80], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 3.0]]\n",
    "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.7]\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.75\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f85c2e-44bf-45e4-8f34-076a771fa599",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/06 18:27:20 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/06 18:27:21 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/06 18:27:23 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/06 18:27:24 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../sartorius-annotations-coco-format/annotations_train.json\n",
      "\u001b[32m[02/06 18:27:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[02/06 18:27:24 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/06 18:27:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/06 18:27:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/06 18:27:24 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:27:24 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/06 18:27:25 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/hamdi/miniconda3/envs/env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/06 18:27:39 d2.utils.events]: \u001b[0m eta: 1:21:41  iter: 19  total_loss: 3.311  loss_cls: 1.469  loss_box_reg: 0.5768  loss_mask: 0.6958  loss_rpn_cls: 0.3359  loss_rpn_loc: 0.2579  time: 0.6966  data_time: 0.2034  lr: 9.9905e-06  max_mem: 5557M\n",
      "\u001b[32m[02/06 18:27:50 d2.utils.events]: \u001b[0m eta: 1:17:58  iter: 39  total_loss: 3.098  loss_cls: 1.343  loss_box_reg: 0.5051  loss_mask: 0.6889  loss_rpn_cls: 0.3425  loss_rpn_loc: 0.2068  time: 0.6358  data_time: 0.1388  lr: 1.998e-05  max_mem: 5557M\n",
      "\u001b[32m[02/06 18:28:05 d2.utils.events]: \u001b[0m eta: 1:22:20  iter: 59  total_loss: 2.91  loss_cls: 1.107  loss_box_reg: 0.5708  loss_mask: 0.6718  loss_rpn_cls: 0.3166  loss_rpn_loc: 0.2534  time: 0.6757  data_time: 0.2392  lr: 2.997e-05  max_mem: 5557M\n",
      "\u001b[32m[02/06 18:28:18 d2.utils.events]: \u001b[0m eta: 1:23:18  iter: 79  total_loss: 2.836  loss_cls: 0.8743  loss_box_reg: 0.817  loss_mask: 0.6459  loss_rpn_cls: 0.2498  loss_rpn_loc: 0.2402  time: 0.6603  data_time: 0.1177  lr: 3.9961e-05  max_mem: 5557M\n",
      "\u001b[32m[02/06 18:28:33 d2.utils.events]: \u001b[0m eta: 1:25:05  iter: 99  total_loss: 2.784  loss_cls: 0.8256  loss_box_reg: 0.8363  loss_mask: 0.6214  loss_rpn_cls: 0.2281  loss_rpn_loc: 0.2691  time: 0.6807  data_time: 0.2407  lr: 4.9951e-05  max_mem: 5557M\n",
      "\u001b[32m[02/06 18:28:45 d2.utils.events]: \u001b[0m eta: 1:25:33  iter: 119  total_loss: 2.59  loss_cls: 0.7488  loss_box_reg: 0.8665  loss_mask: 0.6054  loss_rpn_cls: 0.176  loss_rpn_loc: 0.2037  time: 0.6677  data_time: 0.0944  lr: 5.9941e-05  max_mem: 5557M\n",
      "\u001b[32m[02/06 18:29:00 d2.utils.events]: \u001b[0m eta: 1:25:49  iter: 139  total_loss: 2.475  loss_cls: 0.7056  loss_box_reg: 0.85  loss_mask: 0.5672  loss_rpn_cls: 0.1576  loss_rpn_loc: 0.1711  time: 0.6825  data_time: 0.2550  lr: 6.993e-05  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:29:16 d2.utils.events]: \u001b[0m eta: 1:25:50  iter: 159  total_loss: 2.412  loss_cls: 0.6947  loss_box_reg: 0.8403  loss_mask: 0.5551  loss_rpn_cls: 0.1461  loss_rpn_loc: 0.1586  time: 0.6962  data_time: 0.2635  lr: 7.9921e-05  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:29:34 d2.utils.events]: \u001b[0m eta: 1:26:44  iter: 179  total_loss: 2.316  loss_cls: 0.6516  loss_box_reg: 0.819  loss_mask: 0.5215  loss_rpn_cls: 0.1534  loss_rpn_loc: 0.1913  time: 0.7148  data_time: 0.3326  lr: 8.991e-05  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:29:46 d2.utils.events]: \u001b[0m eta: 1:26:21  iter: 199  total_loss: 2.185  loss_cls: 0.5999  loss_box_reg: 0.8354  loss_mask: 0.4839  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.12  time: 0.7079  data_time: 0.1503  lr: 9.9901e-05  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:30:00 d2.utils.events]: \u001b[0m eta: 1:26:03  iter: 219  total_loss: 2.142  loss_cls: 0.5577  loss_box_reg: 0.8308  loss_mask: 0.4572  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.1789  time: 0.7032  data_time: 0.1514  lr: 0.00010989  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:30:12 d2.utils.events]: \u001b[0m eta: 1:25:53  iter: 239  total_loss: 2.097  loss_cls: 0.5322  loss_box_reg: 0.8315  loss_mask: 0.4189  loss_rpn_cls: 0.1388  loss_rpn_loc: 0.1636  time: 0.6971  data_time: 0.1339  lr: 0.00011988  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:30:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:30:14 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/06 18:30:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:30:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:30:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:30:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:30:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1988 s/iter. Eval: 0.0201 s/iter. Total: 0.2196 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 18:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.2086 s/iter. Eval: 0.0696 s/iter. Total: 0.2791 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/06 18:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0009 s/iter. Inference: 0.2048 s/iter. Eval: 0.0874 s/iter. Total: 0.2931 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/06 18:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0009 s/iter. Inference: 0.2040 s/iter. Eval: 0.0811 s/iter. Total: 0.2861 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 18:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0009 s/iter. Inference: 0.2037 s/iter. Eval: 0.0947 s/iter. Total: 0.2993 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 18:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0009 s/iter. Inference: 0.2034 s/iter. Eval: 0.0968 s/iter. Total: 0.3012 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 18:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0009 s/iter. Inference: 0.2015 s/iter. Eval: 0.0938 s/iter. Total: 0.2962 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 18:30:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.187063 (0.294716 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:30:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:23 (0.201668 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:30:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:30:50 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.13428417509441906\n",
      "\u001b[32m[02/06 18:31:00 d2.utils.events]: \u001b[0m eta: 1:25:06  iter: 259  total_loss: 1.974  loss_cls: 0.4817  loss_box_reg: 0.8073  loss_mask: 0.3928  loss_rpn_cls: 0.09692  loss_rpn_loc: 0.1395  time: 0.6865  data_time: 0.0734  lr: 0.00012987  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:31:14 d2.utils.events]: \u001b[0m eta: 1:25:06  iter: 279  total_loss: 1.952  loss_cls: 0.4803  loss_box_reg: 0.7758  loss_mask: 0.3813  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.179  time: 0.6884  data_time: 0.2120  lr: 0.00013986  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:31:27 d2.utils.events]: \u001b[0m eta: 1:24:36  iter: 299  total_loss: 1.868  loss_cls: 0.4782  loss_box_reg: 0.7945  loss_mask: 0.3553  loss_rpn_cls: 0.08228  loss_rpn_loc: 0.1408  time: 0.6846  data_time: 0.1375  lr: 0.00014985  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:31:41 d2.utils.events]: \u001b[0m eta: 1:24:09  iter: 319  total_loss: 1.741  loss_cls: 0.4153  loss_box_reg: 0.752  loss_mask: 0.3352  loss_rpn_cls: 0.09546  loss_rpn_loc: 0.1385  time: 0.6879  data_time: 0.2454  lr: 0.00015984  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:31:57 d2.utils.events]: \u001b[0m eta: 1:24:10  iter: 339  total_loss: 1.844  loss_cls: 0.4988  loss_box_reg: 0.7152  loss_mask: 0.3363  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.1639  time: 0.6933  data_time: 0.2767  lr: 0.00016983  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:32:11 d2.utils.events]: \u001b[0m eta: 1:24:00  iter: 359  total_loss: 1.747  loss_cls: 0.4493  loss_box_reg: 0.7319  loss_mask: 0.3325  loss_rpn_cls: 0.09357  loss_rpn_loc: 0.1465  time: 0.6924  data_time: 0.1842  lr: 0.00017982  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:32:23 d2.utils.events]: \u001b[0m eta: 1:23:40  iter: 379  total_loss: 1.721  loss_cls: 0.4095  loss_box_reg: 0.6977  loss_mask: 0.3329  loss_rpn_cls: 0.08465  loss_rpn_loc: 0.1382  time: 0.6887  data_time: 0.1255  lr: 0.00018981  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:32:34 d2.utils.events]: \u001b[0m eta: 1:23:24  iter: 399  total_loss: 1.721  loss_cls: 0.4241  loss_box_reg: 0.6986  loss_mask: 0.3342  loss_rpn_cls: 0.08319  loss_rpn_loc: 0.1547  time: 0.6824  data_time: 0.0807  lr: 0.0001998  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:32:45 d2.utils.events]: \u001b[0m eta: 1:23:04  iter: 419  total_loss: 1.606  loss_cls: 0.4122  loss_box_reg: 0.6709  loss_mask: 0.3108  loss_rpn_cls: 0.08591  loss_rpn_loc: 0.14  time: 0.6759  data_time: 0.0797  lr: 0.00020979  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:32:58 d2.utils.events]: \u001b[0m eta: 1:22:53  iter: 439  total_loss: 1.606  loss_cls: 0.4062  loss_box_reg: 0.6756  loss_mask: 0.3097  loss_rpn_cls: 0.08352  loss_rpn_loc: 0.1447  time: 0.6741  data_time: 0.1545  lr: 0.00021978  max_mem: 6731M\n",
      "\u001b[32m[02/06 18:33:13 d2.utils.events]: \u001b[0m eta: 1:22:43  iter: 459  total_loss: 1.604  loss_cls: 0.4125  loss_box_reg: 0.6911  loss_mask: 0.3203  loss_rpn_cls: 0.08072  loss_rpn_loc: 0.1419  time: 0.6767  data_time: 0.2170  lr: 0.00022977  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:33:26 d2.utils.events]: \u001b[0m eta: 1:22:32  iter: 479  total_loss: 1.654  loss_cls: 0.433  loss_box_reg: 0.6793  loss_mask: 0.2977  loss_rpn_cls: 0.08897  loss_rpn_loc: 0.1714  time: 0.6767  data_time: 0.1885  lr: 0.00023976  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:33:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:33:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:33:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:33:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:33:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:33:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:33:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1314 s/iter. Eval: 0.0400 s/iter. Total: 0.1721 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 18:33:38 d2.evaluation.evaluator]: \u001b[0mInference done 28/121. Dataloading: 0.0008 s/iter. Inference: 0.1433 s/iter. Eval: 0.1199 s/iter. Total: 0.2640 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 18:33:43 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1468 s/iter. Eval: 0.1471 s/iter. Total: 0.2947 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/06 18:33:48 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0008 s/iter. Inference: 0.1426 s/iter. Eval: 0.1377 s/iter. Total: 0.2812 s/iter. ETA=0:00:15\n",
      "\u001b[32m[02/06 18:33:53 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1457 s/iter. Eval: 0.1542 s/iter. Total: 0.3007 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 18:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.1498 s/iter. Eval: 0.1673 s/iter. Total: 0.3180 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/06 18:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 106/121. Dataloading: 0.0008 s/iter. Inference: 0.1487 s/iter. Eval: 0.1711 s/iter. Total: 0.3208 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/06 18:34:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.379169 (0.313614 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:34:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.148890 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:34:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:34:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.24599550357522393\n",
      "\u001b[32m[02/06 18:34:18 d2.utils.events]: \u001b[0m eta: 1:22:16  iter: 499  total_loss: 1.64  loss_cls: 0.3979  loss_box_reg: 0.6813  loss_mask: 0.3144  loss_rpn_cls: 0.08037  loss_rpn_loc: 0.1604  time: 0.6753  data_time: 0.1414  lr: 0.00024975  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:34:31 d2.utils.events]: \u001b[0m eta: 1:22:11  iter: 519  total_loss: 1.662  loss_cls: 0.4291  loss_box_reg: 0.6924  loss_mask: 0.3211  loss_rpn_cls: 0.09314  loss_rpn_loc: 0.1598  time: 0.6755  data_time: 0.1728  lr: 0.00025974  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:34:44 d2.utils.events]: \u001b[0m eta: 1:21:37  iter: 539  total_loss: 1.496  loss_cls: 0.3519  loss_box_reg: 0.6606  loss_mask: 0.2975  loss_rpn_cls: 0.05364  loss_rpn_loc: 0.1136  time: 0.6738  data_time: 0.1570  lr: 0.00026973  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:34:57 d2.utils.events]: \u001b[0m eta: 1:21:13  iter: 559  total_loss: 1.487  loss_cls: 0.3592  loss_box_reg: 0.6226  loss_mask: 0.3038  loss_rpn_cls: 0.06109  loss_rpn_loc: 0.1257  time: 0.6737  data_time: 0.1895  lr: 0.00027972  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:35:15 d2.utils.events]: \u001b[0m eta: 1:21:15  iter: 579  total_loss: 1.611  loss_cls: 0.4036  loss_box_reg: 0.661  loss_mask: 0.3191  loss_rpn_cls: 0.08998  loss_rpn_loc: 0.1391  time: 0.6807  data_time: 0.3707  lr: 0.00028971  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:35:28 d2.utils.events]: \u001b[0m eta: 1:20:56  iter: 599  total_loss: 1.594  loss_cls: 0.4215  loss_box_reg: 0.6398  loss_mask: 0.3214  loss_rpn_cls: 0.08067  loss_rpn_loc: 0.149  time: 0.6801  data_time: 0.1775  lr: 0.0002997  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:35:39 d2.utils.events]: \u001b[0m eta: 1:20:39  iter: 619  total_loss: 1.718  loss_cls: 0.4574  loss_box_reg: 0.6547  loss_mask: 0.3113  loss_rpn_cls: 0.08892  loss_rpn_loc: 0.1548  time: 0.6754  data_time: 0.0534  lr: 0.00030969  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:35:53 d2.utils.events]: \u001b[0m eta: 1:20:27  iter: 639  total_loss: 1.587  loss_cls: 0.3932  loss_box_reg: 0.6459  loss_mask: 0.321  loss_rpn_cls: 0.07455  loss_rpn_loc: 0.1401  time: 0.6773  data_time: 0.2460  lr: 0.00031968  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:36:08 d2.utils.events]: \u001b[0m eta: 1:20:16  iter: 659  total_loss: 1.634  loss_cls: 0.424  loss_box_reg: 0.6203  loss_mask: 0.332  loss_rpn_cls: 0.09588  loss_rpn_loc: 0.1432  time: 0.6793  data_time: 0.2548  lr: 0.00032967  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:36:20 d2.utils.events]: \u001b[0m eta: 1:20:01  iter: 679  total_loss: 1.554  loss_cls: 0.4191  loss_box_reg: 0.6186  loss_mask: 0.3106  loss_rpn_cls: 0.07504  loss_rpn_loc: 0.1375  time: 0.6770  data_time: 0.1549  lr: 0.00033966  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:36:33 d2.utils.events]: \u001b[0m eta: 1:19:50  iter: 699  total_loss: 1.582  loss_cls: 0.3913  loss_box_reg: 0.6207  loss_mask: 0.31  loss_rpn_cls: 0.09396  loss_rpn_loc: 0.1381  time: 0.6754  data_time: 0.1410  lr: 0.00034965  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:36:47 d2.utils.events]: \u001b[0m eta: 1:19:37  iter: 719  total_loss: 1.533  loss_cls: 0.3787  loss_box_reg: 0.6264  loss_mask: 0.2981  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.1224  time: 0.6765  data_time: 0.2351  lr: 0.00035964  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:36:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:36:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:36:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:36:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:36:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:36:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:36:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1205 s/iter. Eval: 0.0475 s/iter. Total: 0.1686 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 18:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1270 s/iter. Eval: 0.1355 s/iter. Total: 0.2634 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 18:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.1283 s/iter. Eval: 0.1390 s/iter. Total: 0.2681 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 18:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0007 s/iter. Inference: 0.1251 s/iter. Eval: 0.1304 s/iter. Total: 0.2563 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 18:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1298 s/iter. Eval: 0.1588 s/iter. Total: 0.2894 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 18:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1312 s/iter. Eval: 0.1650 s/iter. Total: 0.2970 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 18:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.1298 s/iter. Eval: 0.1559 s/iter. Total: 0.2866 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 18:37:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.616794 (0.289800 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:37:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.130787 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:37:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:37:27 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.25865379168200464\n",
      "\u001b[32m[02/06 18:37:35 d2.utils.events]: \u001b[0m eta: 1:19:19  iter: 739  total_loss: 1.543  loss_cls: 0.4008  loss_box_reg: 0.6461  loss_mask: 0.3093  loss_rpn_cls: 0.05353  loss_rpn_loc: 0.1354  time: 0.6745  data_time: 0.1354  lr: 0.00036963  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:37:52 d2.utils.events]: \u001b[0m eta: 1:19:14  iter: 759  total_loss: 1.657  loss_cls: 0.4112  loss_box_reg: 0.6265  loss_mask: 0.322  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.177  time: 0.6791  data_time: 0.3572  lr: 0.00037962  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:38:04 d2.utils.events]: \u001b[0m eta: 1:19:00  iter: 779  total_loss: 1.64  loss_cls: 0.3687  loss_box_reg: 0.6316  loss_mask: 0.3201  loss_rpn_cls: 0.0782  loss_rpn_loc: 0.1504  time: 0.6779  data_time: 0.1657  lr: 0.00038961  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:38:18 d2.utils.events]: \u001b[0m eta: 1:18:44  iter: 799  total_loss: 1.488  loss_cls: 0.3768  loss_box_reg: 0.6204  loss_mask: 0.3047  loss_rpn_cls: 0.05419  loss_rpn_loc: 0.1224  time: 0.6774  data_time: 0.1860  lr: 0.0003996  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:38:31 d2.utils.events]: \u001b[0m eta: 1:18:31  iter: 819  total_loss: 1.531  loss_cls: 0.3919  loss_box_reg: 0.5926  loss_mask: 0.3077  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.1348  time: 0.6770  data_time: 0.1863  lr: 0.00040959  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:38:43 d2.utils.events]: \u001b[0m eta: 1:18:19  iter: 839  total_loss: 1.498  loss_cls: 0.353  loss_box_reg: 0.6005  loss_mask: 0.2974  loss_rpn_cls: 0.08086  loss_rpn_loc: 0.1316  time: 0.6755  data_time: 0.1470  lr: 0.00041958  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:38:54 d2.utils.events]: \u001b[0m eta: 1:18:04  iter: 859  total_loss: 1.482  loss_cls: 0.3685  loss_box_reg: 0.6221  loss_mask: 0.3125  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.1254  time: 0.6722  data_time: 0.0668  lr: 0.00042957  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:39:07 d2.utils.events]: \u001b[0m eta: 1:17:52  iter: 879  total_loss: 1.468  loss_cls: 0.3765  loss_box_reg: 0.5926  loss_mask: 0.2911  loss_rpn_cls: 0.06212  loss_rpn_loc: 0.1167  time: 0.6719  data_time: 0.1963  lr: 0.00043956  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:39:21 d2.utils.events]: \u001b[0m eta: 1:17:35  iter: 899  total_loss: 1.46  loss_cls: 0.3621  loss_box_reg: 0.6019  loss_mask: 0.3226  loss_rpn_cls: 0.06568  loss_rpn_loc: 0.1148  time: 0.6725  data_time: 0.2371  lr: 0.00044955  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:39:32 d2.utils.events]: \u001b[0m eta: 1:17:17  iter: 919  total_loss: 1.528  loss_cls: 0.4055  loss_box_reg: 0.6008  loss_mask: 0.2991  loss_rpn_cls: 0.06921  loss_rpn_loc: 0.1516  time: 0.6704  data_time: 0.1096  lr: 0.00045954  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:39:46 d2.utils.events]: \u001b[0m eta: 1:16:59  iter: 939  total_loss: 1.531  loss_cls: 0.4058  loss_box_reg: 0.5888  loss_mask: 0.3096  loss_rpn_cls: 0.07898  loss_rpn_loc: 0.149  time: 0.6707  data_time: 0.2126  lr: 0.00046953  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:40:00 d2.utils.events]: \u001b[0m eta: 1:16:49  iter: 959  total_loss: 1.558  loss_cls: 0.4046  loss_box_reg: 0.6092  loss_mask: 0.3155  loss_rpn_cls: 0.07676  loss_rpn_loc: 0.1517  time: 0.6713  data_time: 0.2219  lr: 0.00047952  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:40:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:40:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:40:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:40:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:40:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:40:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1173 s/iter. Eval: 0.0582 s/iter. Total: 0.1762 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 18:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1304 s/iter. Eval: 0.1424 s/iter. Total: 0.2736 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/06 18:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.1325 s/iter. Eval: 0.1507 s/iter. Total: 0.2841 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/06 18:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.1291 s/iter. Eval: 0.1354 s/iter. Total: 0.2652 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/06 18:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1335 s/iter. Eval: 0.1618 s/iter. Total: 0.2961 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 18:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1372 s/iter. Eval: 0.1736 s/iter. Total: 0.3116 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/06 18:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0008 s/iter. Inference: 0.1349 s/iter. Eval: 0.1676 s/iter. Total: 0.3033 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 18:40:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.832424 (0.300280 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:40:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.135428 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:40:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:40:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.26532591293059576\n",
      "\u001b[32m[02/06 18:40:47 d2.utils.events]: \u001b[0m eta: 1:16:27  iter: 979  total_loss: 1.396  loss_cls: 0.3433  loss_box_reg: 0.5674  loss_mask: 0.293  loss_rpn_cls: 0.056  loss_rpn_loc: 0.1139  time: 0.6673  data_time: 0.0194  lr: 0.00048951  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:41:00 d2.utils.events]: \u001b[0m eta: 1:16:15  iter: 999  total_loss: 1.489  loss_cls: 0.3729  loss_box_reg: 0.6055  loss_mask: 0.3051  loss_rpn_cls: 0.07355  loss_rpn_loc: 0.1455  time: 0.6671  data_time: 0.1882  lr: 0.0004995  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:41:11 d2.utils.events]: \u001b[0m eta: 1:15:56  iter: 1019  total_loss: 1.362  loss_cls: 0.3528  loss_box_reg: 0.6044  loss_mask: 0.2913  loss_rpn_cls: 0.04488  loss_rpn_loc: 0.09817  time: 0.6648  data_time: 0.0943  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:41:25 d2.utils.events]: \u001b[0m eta: 1:15:55  iter: 1039  total_loss: 1.564  loss_cls: 0.3974  loss_box_reg: 0.626  loss_mask: 0.3155  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.1455  time: 0.6661  data_time: 0.2493  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:41:39 d2.utils.events]: \u001b[0m eta: 1:15:36  iter: 1059  total_loss: 1.477  loss_cls: 0.3642  loss_box_reg: 0.5783  loss_mask: 0.2942  loss_rpn_cls: 0.04505  loss_rpn_loc: 0.1241  time: 0.6662  data_time: 0.2073  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:41:51 d2.utils.events]: \u001b[0m eta: 1:15:08  iter: 1079  total_loss: 1.617  loss_cls: 0.4187  loss_box_reg: 0.6229  loss_mask: 0.3095  loss_rpn_cls: 0.06787  loss_rpn_loc: 0.1285  time: 0.6651  data_time: 0.1429  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:42:01 d2.utils.events]: \u001b[0m eta: 1:14:41  iter: 1099  total_loss: 1.409  loss_cls: 0.3449  loss_box_reg: 0.5999  loss_mask: 0.3026  loss_rpn_cls: 0.04683  loss_rpn_loc: 0.09813  time: 0.6623  data_time: 0.0668  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:42:17 d2.utils.events]: \u001b[0m eta: 1:14:25  iter: 1119  total_loss: 1.487  loss_cls: 0.3733  loss_box_reg: 0.6  loss_mask: 0.3014  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1404  time: 0.6646  data_time: 0.3105  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:42:31 d2.utils.events]: \u001b[0m eta: 1:14:10  iter: 1139  total_loss: 1.469  loss_cls: 0.3768  loss_box_reg: 0.5832  loss_mask: 0.2995  loss_rpn_cls: 0.09476  loss_rpn_loc: 0.1369  time: 0.6653  data_time: 0.2367  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:42:47 d2.utils.events]: \u001b[0m eta: 1:13:59  iter: 1159  total_loss: 1.537  loss_cls: 0.3976  loss_box_reg: 0.5908  loss_mask: 0.3278  loss_rpn_cls: 0.08053  loss_rpn_loc: 0.1509  time: 0.6677  data_time: 0.3207  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:42:59 d2.utils.events]: \u001b[0m eta: 1:13:38  iter: 1179  total_loss: 1.525  loss_cls: 0.385  loss_box_reg: 0.6118  loss_mask: 0.3039  loss_rpn_cls: 0.06952  loss_rpn_loc: 0.1388  time: 0.6665  data_time: 0.1436  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:43:12 d2.utils.events]: \u001b[0m eta: 1:13:28  iter: 1199  total_loss: 1.501  loss_cls: 0.3943  loss_box_reg: 0.6043  loss_mask: 0.2913  loss_rpn_cls: 0.08194  loss_rpn_loc: 0.1493  time: 0.6661  data_time: 0.1667  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:43:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:43:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:43:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:43:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:43:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:43:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1074 s/iter. Eval: 0.0573 s/iter. Total: 0.1653 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 18:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1216 s/iter. Eval: 0.1306 s/iter. Total: 0.2529 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 18:43:32 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.1226 s/iter. Eval: 0.1358 s/iter. Total: 0.2592 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 18:43:37 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0007 s/iter. Inference: 0.1198 s/iter. Eval: 0.1281 s/iter. Total: 0.2488 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 18:43:42 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0007 s/iter. Inference: 0.1260 s/iter. Eval: 0.1528 s/iter. Total: 0.2796 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/06 18:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0007 s/iter. Inference: 0.1270 s/iter. Eval: 0.1594 s/iter. Total: 0.2872 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 18:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0007 s/iter. Inference: 0.1260 s/iter. Eval: 0.1491 s/iter. Total: 0.2759 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 18:43:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.057030 (0.276354 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:43:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.125980 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:43:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:43:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2763024034961247\n",
      "\u001b[32m[02/06 18:43:59 d2.utils.events]: \u001b[0m eta: 1:13:15  iter: 1219  total_loss: 1.413  loss_cls: 0.3755  loss_box_reg: 0.5664  loss_mask: 0.3061  loss_rpn_cls: 0.05505  loss_rpn_loc: 0.119  time: 0.6654  data_time: 0.1519  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:44:13 d2.utils.events]: \u001b[0m eta: 1:12:58  iter: 1239  total_loss: 1.5  loss_cls: 0.3855  loss_box_reg: 0.6274  loss_mask: 0.3338  loss_rpn_cls: 0.06642  loss_rpn_loc: 0.1251  time: 0.6665  data_time: 0.2579  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:44:25 d2.utils.events]: \u001b[0m eta: 1:12:38  iter: 1259  total_loss: 1.459  loss_cls: 0.3827  loss_box_reg: 0.6007  loss_mask: 0.2923  loss_rpn_cls: 0.05522  loss_rpn_loc: 0.1276  time: 0.6653  data_time: 0.1259  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:44:38 d2.utils.events]: \u001b[0m eta: 1:12:19  iter: 1279  total_loss: 1.45  loss_cls: 0.3496  loss_box_reg: 0.5863  loss_mask: 0.306  loss_rpn_cls: 0.06318  loss_rpn_loc: 0.1238  time: 0.6646  data_time: 0.1558  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:44:52 d2.utils.events]: \u001b[0m eta: 1:12:07  iter: 1299  total_loss: 1.491  loss_cls: 0.3631  loss_box_reg: 0.6156  loss_mask: 0.2988  loss_rpn_cls: 0.06669  loss_rpn_loc: 0.1403  time: 0.6653  data_time: 0.2317  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:45:05 d2.utils.events]: \u001b[0m eta: 1:11:50  iter: 1319  total_loss: 1.541  loss_cls: 0.3951  loss_box_reg: 0.6185  loss_mask: 0.295  loss_rpn_cls: 0.07058  loss_rpn_loc: 0.1361  time: 0.6651  data_time: 0.1808  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:45:19 d2.utils.events]: \u001b[0m eta: 1:11:27  iter: 1339  total_loss: 1.396  loss_cls: 0.3477  loss_box_reg: 0.5786  loss_mask: 0.2917  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.1287  time: 0.6659  data_time: 0.2610  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:45:32 d2.utils.events]: \u001b[0m eta: 1:11:13  iter: 1359  total_loss: 1.508  loss_cls: 0.3777  loss_box_reg: 0.5785  loss_mask: 0.2974  loss_rpn_cls: 0.06983  loss_rpn_loc: 0.1338  time: 0.6656  data_time: 0.1749  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:45:45 d2.utils.events]: \u001b[0m eta: 1:11:00  iter: 1379  total_loss: 1.48  loss_cls: 0.3505  loss_box_reg: 0.5998  loss_mask: 0.3072  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.1389  time: 0.6651  data_time: 0.1641  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:45:58 d2.utils.events]: \u001b[0m eta: 1:10:47  iter: 1399  total_loss: 1.476  loss_cls: 0.3704  loss_box_reg: 0.5992  loss_mask: 0.3031  loss_rpn_cls: 0.05963  loss_rpn_loc: 0.1277  time: 0.6648  data_time: 0.1766  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:46:08 d2.utils.events]: \u001b[0m eta: 1:10:36  iter: 1419  total_loss: 1.338  loss_cls: 0.3421  loss_box_reg: 0.5606  loss_mask: 0.2899  loss_rpn_cls: 0.054  loss_rpn_loc: 0.1084  time: 0.6629  data_time: 0.0809  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:46:23 d2.utils.events]: \u001b[0m eta: 1:10:22  iter: 1439  total_loss: 1.48  loss_cls: 0.3696  loss_box_reg: 0.5688  loss_mask: 0.3022  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.1373  time: 0.6642  data_time: 0.2730  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:46:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:46:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:46:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:46:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:46:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:46:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1100 s/iter. Eval: 0.0551 s/iter. Total: 0.1658 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 18:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1193 s/iter. Eval: 0.1344 s/iter. Total: 0.2546 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 18:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1213 s/iter. Eval: 0.1409 s/iter. Total: 0.2631 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 18:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1195 s/iter. Eval: 0.1341 s/iter. Total: 0.2544 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 18:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1245 s/iter. Eval: 0.1602 s/iter. Total: 0.2855 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 18:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1253 s/iter. Eval: 0.1673 s/iter. Total: 0.2935 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 18:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1245 s/iter. Eval: 0.1574 s/iter. Total: 0.2827 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 18:47:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.896028 (0.283586 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:47:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.124745 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:47:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:47:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2805384624519842\n",
      "\u001b[32m[02/06 18:47:10 d2.utils.events]: \u001b[0m eta: 1:10:08  iter: 1459  total_loss: 1.492  loss_cls: 0.38  loss_box_reg: 0.5914  loss_mask: 0.301  loss_rpn_cls: 0.08411  loss_rpn_loc: 0.123  time: 0.6635  data_time: 0.1466  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:47:25 d2.utils.events]: \u001b[0m eta: 1:09:54  iter: 1479  total_loss: 1.498  loss_cls: 0.3754  loss_box_reg: 0.5892  loss_mask: 0.2951  loss_rpn_cls: 0.0751  loss_rpn_loc: 0.1254  time: 0.6641  data_time: 0.2445  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:47:38 d2.utils.events]: \u001b[0m eta: 1:09:40  iter: 1499  total_loss: 1.46  loss_cls: 0.3542  loss_box_reg: 0.5843  loss_mask: 0.2969  loss_rpn_cls: 0.07391  loss_rpn_loc: 0.1333  time: 0.6641  data_time: 0.2006  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:47:51 d2.utils.events]: \u001b[0m eta: 1:09:21  iter: 1519  total_loss: 1.482  loss_cls: 0.3643  loss_box_reg: 0.5778  loss_mask: 0.301  loss_rpn_cls: 0.06132  loss_rpn_loc: 0.1376  time: 0.6640  data_time: 0.1903  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:48:02 d2.utils.events]: \u001b[0m eta: 1:09:05  iter: 1539  total_loss: 1.397  loss_cls: 0.3533  loss_box_reg: 0.5949  loss_mask: 0.2995  loss_rpn_cls: 0.07055  loss_rpn_loc: 0.1219  time: 0.6623  data_time: 0.0802  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:48:15 d2.utils.events]: \u001b[0m eta: 1:08:50  iter: 1559  total_loss: 1.429  loss_cls: 0.3681  loss_box_reg: 0.5528  loss_mask: 0.2915  loss_rpn_cls: 0.06741  loss_rpn_loc: 0.1217  time: 0.6621  data_time: 0.1769  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:48:26 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 1579  total_loss: 1.341  loss_cls: 0.3464  loss_box_reg: 0.5785  loss_mask: 0.2909  loss_rpn_cls: 0.04611  loss_rpn_loc: 0.09918  time: 0.6606  data_time: 0.0840  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:48:40 d2.utils.events]: \u001b[0m eta: 1:08:21  iter: 1599  total_loss: 1.443  loss_cls: 0.3751  loss_box_reg: 0.5745  loss_mask: 0.3022  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.1372  time: 0.6613  data_time: 0.2384  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:48:54 d2.utils.events]: \u001b[0m eta: 1:08:07  iter: 1619  total_loss: 1.566  loss_cls: 0.4058  loss_box_reg: 0.6375  loss_mask: 0.3183  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.1524  time: 0.6617  data_time: 0.2280  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:49:07 d2.utils.events]: \u001b[0m eta: 1:07:56  iter: 1639  total_loss: 1.37  loss_cls: 0.3341  loss_box_reg: 0.5702  loss_mask: 0.312  loss_rpn_cls: 0.05207  loss_rpn_loc: 0.1009  time: 0.6618  data_time: 0.2148  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:49:22 d2.utils.events]: \u001b[0m eta: 1:07:42  iter: 1659  total_loss: 1.432  loss_cls: 0.3759  loss_box_reg: 0.5867  loss_mask: 0.3081  loss_rpn_cls: 0.06632  loss_rpn_loc: 0.1423  time: 0.6630  data_time: 0.2935  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:49:35 d2.utils.events]: \u001b[0m eta: 1:07:32  iter: 1679  total_loss: 1.465  loss_cls: 0.3587  loss_box_reg: 0.5868  loss_mask: 0.3096  loss_rpn_cls: 0.06824  loss_rpn_loc: 0.128  time: 0.6624  data_time: 0.1474  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:49:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:49:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:49:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:49:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:49:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:49:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1127 s/iter. Eval: 0.0541 s/iter. Total: 0.1674 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 18:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1196 s/iter. Eval: 0.1316 s/iter. Total: 0.2520 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 18:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1215 s/iter. Eval: 0.1380 s/iter. Total: 0.2604 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 18:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1189 s/iter. Eval: 0.1340 s/iter. Total: 0.2537 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 18:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1236 s/iter. Eval: 0.1610 s/iter. Total: 0.2854 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 18:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1247 s/iter. Eval: 0.1681 s/iter. Total: 0.2935 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 18:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1237 s/iter. Eval: 0.1585 s/iter. Total: 0.2830 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 18:50:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.909019 (0.283698 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:50:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.124023 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:50:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:50:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2831203663324378\n",
      "\u001b[32m[02/06 18:50:23 d2.utils.events]: \u001b[0m eta: 1:07:20  iter: 1699  total_loss: 1.494  loss_cls: 0.385  loss_box_reg: 0.5931  loss_mask: 0.2987  loss_rpn_cls: 0.07283  loss_rpn_loc: 0.1461  time: 0.6626  data_time: 0.2010  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:50:37 d2.utils.events]: \u001b[0m eta: 1:07:09  iter: 1719  total_loss: 1.37  loss_cls: 0.3435  loss_box_reg: 0.564  loss_mask: 0.288  loss_rpn_cls: 0.04703  loss_rpn_loc: 0.1145  time: 0.6627  data_time: 0.2064  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:50:50 d2.utils.events]: \u001b[0m eta: 1:06:58  iter: 1739  total_loss: 1.474  loss_cls: 0.3777  loss_box_reg: 0.6223  loss_mask: 0.3259  loss_rpn_cls: 0.067  loss_rpn_loc: 0.1138  time: 0.6625  data_time: 0.1823  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:51:06 d2.utils.events]: \u001b[0m eta: 1:06:46  iter: 1759  total_loss: 1.542  loss_cls: 0.3827  loss_box_reg: 0.5996  loss_mask: 0.3051  loss_rpn_cls: 0.06634  loss_rpn_loc: 0.1501  time: 0.6645  data_time: 0.3563  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:51:19 d2.utils.events]: \u001b[0m eta: 1:06:35  iter: 1779  total_loss: 1.539  loss_cls: 0.4083  loss_box_reg: 0.6149  loss_mask: 0.3193  loss_rpn_cls: 0.07341  loss_rpn_loc: 0.1322  time: 0.6641  data_time: 0.1583  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:51:30 d2.utils.events]: \u001b[0m eta: 1:06:26  iter: 1799  total_loss: 1.436  loss_cls: 0.3836  loss_box_reg: 0.5946  loss_mask: 0.3028  loss_rpn_cls: 0.05934  loss_rpn_loc: 0.1132  time: 0.6630  data_time: 0.1120  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:51:44 d2.utils.events]: \u001b[0m eta: 1:06:16  iter: 1819  total_loss: 1.536  loss_cls: 0.387  loss_box_reg: 0.6217  loss_mask: 0.3202  loss_rpn_cls: 0.08313  loss_rpn_loc: 0.1314  time: 0.6632  data_time: 0.2169  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:51:59 d2.utils.events]: \u001b[0m eta: 1:06:12  iter: 1839  total_loss: 1.452  loss_cls: 0.3722  loss_box_reg: 0.5743  loss_mask: 0.3121  loss_rpn_cls: 0.04299  loss_rpn_loc: 0.1448  time: 0.6645  data_time: 0.2932  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:52:13 d2.utils.events]: \u001b[0m eta: 1:06:00  iter: 1859  total_loss: 1.46  loss_cls: 0.3809  loss_box_reg: 0.596  loss_mask: 0.3046  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.1313  time: 0.6643  data_time: 0.1927  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:52:23 d2.utils.events]: \u001b[0m eta: 1:05:47  iter: 1879  total_loss: 1.29  loss_cls: 0.3222  loss_box_reg: 0.563  loss_mask: 0.2932  loss_rpn_cls: 0.04477  loss_rpn_loc: 0.1287  time: 0.6631  data_time: 0.0914  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:52:37 d2.utils.events]: \u001b[0m eta: 1:05:38  iter: 1899  total_loss: 1.374  loss_cls: 0.3492  loss_box_reg: 0.5531  loss_mask: 0.2949  loss_rpn_cls: 0.06526  loss_rpn_loc: 0.1112  time: 0.6632  data_time: 0.2081  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:52:50 d2.utils.events]: \u001b[0m eta: 1:05:31  iter: 1919  total_loss: 1.409  loss_cls: 0.3433  loss_box_reg: 0.5574  loss_mask: 0.2914  loss_rpn_cls: 0.06429  loss_rpn_loc: 0.1289  time: 0.6632  data_time: 0.1900  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:52:59 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:52:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:52:59 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:52:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:53:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:53:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:53:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1071 s/iter. Eval: 0.0568 s/iter. Total: 0.1645 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 18:53:07 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1185 s/iter. Eval: 0.1393 s/iter. Total: 0.2587 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 18:53:12 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1202 s/iter. Eval: 0.1453 s/iter. Total: 0.2663 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 18:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.1177 s/iter. Eval: 0.1346 s/iter. Total: 0.2531 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 18:53:23 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1230 s/iter. Eval: 0.1640 s/iter. Total: 0.2879 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 18:53:28 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1246 s/iter. Eval: 0.1724 s/iter. Total: 0.2978 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 18:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.1234 s/iter. Eval: 0.1639 s/iter. Total: 0.2882 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 18:53:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.666661 (0.290230 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:53:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.123896 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:53:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:53:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.27926371032116054\n",
      "\u001b[32m[02/06 18:53:36 d2.utils.events]: \u001b[0m eta: 1:05:20  iter: 1939  total_loss: 1.349  loss_cls: 0.3263  loss_box_reg: 0.562  loss_mask: 0.2748  loss_rpn_cls: 0.03822  loss_rpn_loc: 0.1189  time: 0.6618  data_time: 0.0741  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:53:49 d2.utils.events]: \u001b[0m eta: 1:05:08  iter: 1959  total_loss: 1.408  loss_cls: 0.3318  loss_box_reg: 0.5612  loss_mask: 0.3001  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.1199  time: 0.6614  data_time: 0.1660  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:54:03 d2.utils.events]: \u001b[0m eta: 1:05:06  iter: 1979  total_loss: 1.524  loss_cls: 0.3938  loss_box_reg: 0.6141  loss_mask: 0.3218  loss_rpn_cls: 0.05812  loss_rpn_loc: 0.126  time: 0.6617  data_time: 0.2158  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:54:16 d2.utils.events]: \u001b[0m eta: 1:04:57  iter: 1999  total_loss: 1.433  loss_cls: 0.373  loss_box_reg: 0.572  loss_mask: 0.2933  loss_rpn_cls: 0.04965  loss_rpn_loc: 0.1186  time: 0.6617  data_time: 0.1946  lr: 0.0005  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:54:30 d2.utils.events]: \u001b[0m eta: 1:04:49  iter: 2019  total_loss: 1.435  loss_cls: 0.3734  loss_box_reg: 0.5883  loss_mask: 0.2904  loss_rpn_cls: 0.05864  loss_rpn_loc: 0.1245  time: 0.6620  data_time: 0.2167  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:54:44 d2.utils.events]: \u001b[0m eta: 1:04:38  iter: 2039  total_loss: 1.472  loss_cls: 0.3737  loss_box_reg: 0.563  loss_mask: 0.2892  loss_rpn_cls: 0.06372  loss_rpn_loc: 0.142  time: 0.6623  data_time: 0.2227  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:54:54 d2.utils.events]: \u001b[0m eta: 1:04:23  iter: 2059  total_loss: 1.355  loss_cls: 0.3494  loss_box_reg: 0.5854  loss_mask: 0.2833  loss_rpn_cls: 0.0377  loss_rpn_loc: 0.1157  time: 0.6608  data_time: 0.0532  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:55:07 d2.utils.events]: \u001b[0m eta: 1:04:19  iter: 2079  total_loss: 1.426  loss_cls: 0.3683  loss_box_reg: 0.5765  loss_mask: 0.2982  loss_rpn_cls: 0.06107  loss_rpn_loc: 0.1334  time: 0.6610  data_time: 0.2054  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:55:24 d2.utils.events]: \u001b[0m eta: 1:04:16  iter: 2099  total_loss: 1.519  loss_cls: 0.383  loss_box_reg: 0.5738  loss_mask: 0.3004  loss_rpn_cls: 0.0727  loss_rpn_loc: 0.1389  time: 0.6628  data_time: 0.3741  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:55:38 d2.utils.events]: \u001b[0m eta: 1:04:03  iter: 2119  total_loss: 1.405  loss_cls: 0.3713  loss_box_reg: 0.5559  loss_mask: 0.295  loss_rpn_cls: 0.047  loss_rpn_loc: 0.1118  time: 0.6627  data_time: 0.1927  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:55:49 d2.utils.events]: \u001b[0m eta: 1:03:51  iter: 2139  total_loss: 1.364  loss_cls: 0.3626  loss_box_reg: 0.5848  loss_mask: 0.3027  loss_rpn_cls: 0.07034  loss_rpn_loc: 0.1033  time: 0.6621  data_time: 0.1308  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:56:02 d2.utils.events]: \u001b[0m eta: 1:03:39  iter: 2159  total_loss: 1.462  loss_cls: 0.3534  loss_box_reg: 0.5707  loss_mask: 0.2919  loss_rpn_cls: 0.05497  loss_rpn_loc: 0.1298  time: 0.6617  data_time: 0.1379  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:56:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:56:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:56:15 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:56:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:56:15 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:56:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1237 s/iter. Eval: 0.0576 s/iter. Total: 0.1819 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 18:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1273 s/iter. Eval: 0.1291 s/iter. Total: 0.2572 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 18:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1279 s/iter. Eval: 0.1354 s/iter. Total: 0.2642 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 18:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.1255 s/iter. Eval: 0.1279 s/iter. Total: 0.2542 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 18:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1306 s/iter. Eval: 0.1584 s/iter. Total: 0.2898 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 18:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1317 s/iter. Eval: 0.1651 s/iter. Total: 0.2976 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 18:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.1306 s/iter. Eval: 0.1580 s/iter. Total: 0.2894 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 18:56:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.784947 (0.291250 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:56:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.131023 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 18:56:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 18:56:51 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2866226833388803\n",
      "\u001b[32m[02/06 18:56:52 d2.utils.events]: \u001b[0m eta: 1:03:35  iter: 2179  total_loss: 1.342  loss_cls: 0.3203  loss_box_reg: 0.5676  loss_mask: 0.2934  loss_rpn_cls: 0.04583  loss_rpn_loc: 0.1024  time: 0.6620  data_time: 0.1997  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:57:07 d2.utils.events]: \u001b[0m eta: 1:03:28  iter: 2199  total_loss: 1.364  loss_cls: 0.3365  loss_box_reg: 0.5536  loss_mask: 0.2952  loss_rpn_cls: 0.05916  loss_rpn_loc: 0.1017  time: 0.6627  data_time: 0.2438  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:57:21 d2.utils.events]: \u001b[0m eta: 1:03:24  iter: 2219  total_loss: 1.385  loss_cls: 0.3308  loss_box_reg: 0.5869  loss_mask: 0.2884  loss_rpn_cls: 0.0466  loss_rpn_loc: 0.1371  time: 0.6634  data_time: 0.2336  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:57:37 d2.utils.events]: \u001b[0m eta: 1:03:22  iter: 2239  total_loss: 1.344  loss_cls: 0.3415  loss_box_reg: 0.5574  loss_mask: 0.2871  loss_rpn_cls: 0.05189  loss_rpn_loc: 0.1218  time: 0.6644  data_time: 0.2553  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:57:51 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 2259  total_loss: 1.461  loss_cls: 0.369  loss_box_reg: 0.5758  loss_mask: 0.3114  loss_rpn_cls: 0.06857  loss_rpn_loc: 0.1333  time: 0.6650  data_time: 0.2379  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:58:07 d2.utils.events]: \u001b[0m eta: 1:03:12  iter: 2279  total_loss: 1.4  loss_cls: 0.3465  loss_box_reg: 0.5565  loss_mask: 0.2903  loss_rpn_cls: 0.04676  loss_rpn_loc: 0.1187  time: 0.6661  data_time: 0.2894  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:58:20 d2.utils.events]: \u001b[0m eta: 1:03:03  iter: 2299  total_loss: 1.398  loss_cls: 0.3361  loss_box_reg: 0.5687  loss_mask: 0.2892  loss_rpn_cls: 0.05535  loss_rpn_loc: 0.119  time: 0.6660  data_time: 0.1597  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:58:34 d2.utils.events]: \u001b[0m eta: 1:02:56  iter: 2319  total_loss: 1.415  loss_cls: 0.3593  loss_box_reg: 0.5742  loss_mask: 0.2992  loss_rpn_cls: 0.05631  loss_rpn_loc: 0.1229  time: 0.6661  data_time: 0.1832  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:58:50 d2.utils.events]: \u001b[0m eta: 1:02:51  iter: 2339  total_loss: 1.381  loss_cls: 0.3498  loss_box_reg: 0.5547  loss_mask: 0.294  loss_rpn_cls: 0.05031  loss_rpn_loc: 0.1217  time: 0.6672  data_time: 0.2974  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:59:04 d2.utils.events]: \u001b[0m eta: 1:02:46  iter: 2359  total_loss: 1.382  loss_cls: 0.3515  loss_box_reg: 0.5685  loss_mask: 0.3  loss_rpn_cls: 0.05562  loss_rpn_loc: 0.1258  time: 0.6674  data_time: 0.1895  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:59:15 d2.utils.events]: \u001b[0m eta: 1:02:47  iter: 2379  total_loss: 1.295  loss_cls: 0.3105  loss_box_reg: 0.5453  loss_mask: 0.2814  loss_rpn_cls: 0.04877  loss_rpn_loc: 0.1093  time: 0.6667  data_time: 0.0768  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:59:28 d2.utils.events]: \u001b[0m eta: 1:02:43  iter: 2399  total_loss: 1.486  loss_cls: 0.3867  loss_box_reg: 0.5934  loss_mask: 0.3082  loss_rpn_cls: 0.05267  loss_rpn_loc: 0.1434  time: 0.6663  data_time: 0.1253  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 18:59:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:59:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 18:59:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 18:59:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 18:59:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 18:59:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 18:59:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1123 s/iter. Eval: 0.0587 s/iter. Total: 0.1717 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 18:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1272 s/iter. Eval: 0.1326 s/iter. Total: 0.2606 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 18:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0007 s/iter. Inference: 0.1275 s/iter. Eval: 0.1383 s/iter. Total: 0.2666 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 18:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1252 s/iter. Eval: 0.1316 s/iter. Total: 0.2577 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1326 s/iter. Eval: 0.1527 s/iter. Total: 0.2861 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1345 s/iter. Eval: 0.1632 s/iter. Total: 0.2985 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 19:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1340 s/iter. Eval: 0.1523 s/iter. Total: 0.2872 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 19:00:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.391241 (0.287856 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:00:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.134191 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:00:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:00:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2774613924837673\n",
      "\u001b[32m[02/06 19:00:15 d2.utils.events]: \u001b[0m eta: 1:02:41  iter: 2419  total_loss: 1.38  loss_cls: 0.3606  loss_box_reg: 0.5768  loss_mask: 0.2918  loss_rpn_cls: 0.05475  loss_rpn_loc: 0.1231  time: 0.6658  data_time: 0.1051  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:00:28 d2.utils.events]: \u001b[0m eta: 1:02:40  iter: 2439  total_loss: 1.442  loss_cls: 0.3506  loss_box_reg: 0.5905  loss_mask: 0.3114  loss_rpn_cls: 0.05799  loss_rpn_loc: 0.1178  time: 0.6654  data_time: 0.0941  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:00:42 d2.utils.events]: \u001b[0m eta: 1:02:37  iter: 2459  total_loss: 1.443  loss_cls: 0.3814  loss_box_reg: 0.5761  loss_mask: 0.2831  loss_rpn_cls: 0.05585  loss_rpn_loc: 0.1217  time: 0.6658  data_time: 0.2056  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:00:54 d2.utils.events]: \u001b[0m eta: 1:02:30  iter: 2479  total_loss: 1.332  loss_cls: 0.3275  loss_box_reg: 0.5652  loss_mask: 0.3036  loss_rpn_cls: 0.05186  loss_rpn_loc: 0.09178  time: 0.6655  data_time: 0.1161  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:01:12 d2.utils.events]: \u001b[0m eta: 1:02:21  iter: 2499  total_loss: 1.451  loss_cls: 0.3619  loss_box_reg: 0.5668  loss_mask: 0.2898  loss_rpn_cls: 0.05282  loss_rpn_loc: 0.1212  time: 0.6672  data_time: 0.3685  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:01:26 d2.utils.events]: \u001b[0m eta: 1:02:20  iter: 2519  total_loss: 1.406  loss_cls: 0.3479  loss_box_reg: 0.5372  loss_mask: 0.3017  loss_rpn_cls: 0.04538  loss_rpn_loc: 0.1386  time: 0.6672  data_time: 0.1688  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:01:39 d2.utils.events]: \u001b[0m eta: 1:02:22  iter: 2539  total_loss: 1.519  loss_cls: 0.3944  loss_box_reg: 0.5939  loss_mask: 0.3048  loss_rpn_cls: 0.06507  loss_rpn_loc: 0.1335  time: 0.6673  data_time: 0.1780  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:01:52 d2.utils.events]: \u001b[0m eta: 1:02:13  iter: 2559  total_loss: 1.303  loss_cls: 0.3037  loss_box_reg: 0.5445  loss_mask: 0.2991  loss_rpn_cls: 0.04707  loss_rpn_loc: 0.07083  time: 0.6671  data_time: 0.1784  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:02:06 d2.utils.events]: \u001b[0m eta: 1:02:16  iter: 2579  total_loss: 1.411  loss_cls: 0.3662  loss_box_reg: 0.5489  loss_mask: 0.2947  loss_rpn_cls: 0.06028  loss_rpn_loc: 0.1209  time: 0.6674  data_time: 0.1896  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:02:20 d2.utils.events]: \u001b[0m eta: 1:02:09  iter: 2599  total_loss: 1.453  loss_cls: 0.3546  loss_box_reg: 0.5913  loss_mask: 0.3128  loss_rpn_cls: 0.05069  loss_rpn_loc: 0.1311  time: 0.6678  data_time: 0.2177  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:02:35 d2.utils.events]: \u001b[0m eta: 1:02:00  iter: 2619  total_loss: 1.471  loss_cls: 0.3755  loss_box_reg: 0.5946  loss_mask: 0.3149  loss_rpn_cls: 0.05465  loss_rpn_loc: 0.1306  time: 0.6684  data_time: 0.2289  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:02:51 d2.utils.events]: \u001b[0m eta: 1:02:04  iter: 2639  total_loss: 1.542  loss_cls: 0.3921  loss_box_reg: 0.5957  loss_mask: 0.3104  loss_rpn_cls: 0.07693  loss_rpn_loc: 0.1399  time: 0.6692  data_time: 0.2469  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:03:04 d2.utils.events]: \u001b[0m eta: 1:02:00  iter: 2659  total_loss: 1.398  loss_cls: 0.3686  loss_box_reg: 0.581  loss_mask: 0.2883  loss_rpn_cls: 0.05771  loss_rpn_loc: 0.1218  time: 0.6693  data_time: 0.1805  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:03:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:03:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:03:06 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:03:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:03:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:03:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1134 s/iter. Eval: 0.0569 s/iter. Total: 0.1709 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:03:14 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1252 s/iter. Eval: 0.1331 s/iter. Total: 0.2590 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:03:19 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1265 s/iter. Eval: 0.1390 s/iter. Total: 0.2663 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1236 s/iter. Eval: 0.1334 s/iter. Total: 0.2579 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1291 s/iter. Eval: 0.1600 s/iter. Total: 0.2899 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1302 s/iter. Eval: 0.1677 s/iter. Total: 0.2987 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 19:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1294 s/iter. Eval: 0.1585 s/iter. Total: 0.2887 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 19:03:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.589921 (0.289568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:03:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.129751 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:03:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:03:41 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.28935212483221656\n",
      "\u001b[32m[02/06 19:03:53 d2.utils.events]: \u001b[0m eta: 1:02:02  iter: 2679  total_loss: 1.471  loss_cls: 0.3641  loss_box_reg: 0.604  loss_mask: 0.3153  loss_rpn_cls: 0.05512  loss_rpn_loc: 0.1322  time: 0.6691  data_time: 0.1389  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:04:03 d2.utils.events]: \u001b[0m eta: 1:01:51  iter: 2699  total_loss: 1.325  loss_cls: 0.3163  loss_box_reg: 0.5431  loss_mask: 0.3027  loss_rpn_cls: 0.03706  loss_rpn_loc: 0.0933  time: 0.6677  data_time: 0.0113  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:04:17 d2.utils.events]: \u001b[0m eta: 1:01:46  iter: 2719  total_loss: 1.409  loss_cls: 0.356  loss_box_reg: 0.5699  loss_mask: 0.3076  loss_rpn_cls: 0.04897  loss_rpn_loc: 0.1191  time: 0.6679  data_time: 0.1837  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:04:30 d2.utils.events]: \u001b[0m eta: 1:01:53  iter: 2739  total_loss: 1.402  loss_cls: 0.3625  loss_box_reg: 0.5534  loss_mask: 0.3004  loss_rpn_cls: 0.06024  loss_rpn_loc: 0.1288  time: 0.6680  data_time: 0.1843  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:04:44 d2.utils.events]: \u001b[0m eta: 1:01:43  iter: 2759  total_loss: 1.324  loss_cls: 0.3299  loss_box_reg: 0.5474  loss_mask: 0.2735  loss_rpn_cls: 0.04768  loss_rpn_loc: 0.1153  time: 0.6680  data_time: 0.1800  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:04:56 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 2779  total_loss: 1.342  loss_cls: 0.3328  loss_box_reg: 0.5843  loss_mask: 0.2804  loss_rpn_cls: 0.04807  loss_rpn_loc: 0.1216  time: 0.6677  data_time: 0.1179  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:05:12 d2.utils.events]: \u001b[0m eta: 1:01:45  iter: 2799  total_loss: 1.51  loss_cls: 0.3965  loss_box_reg: 0.5925  loss_mask: 0.3094  loss_rpn_cls: 0.08253  loss_rpn_loc: 0.1493  time: 0.6688  data_time: 0.2793  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:05:27 d2.utils.events]: \u001b[0m eta: 1:01:41  iter: 2819  total_loss: 1.372  loss_cls: 0.3603  loss_box_reg: 0.5434  loss_mask: 0.2792  loss_rpn_cls: 0.05928  loss_rpn_loc: 0.1304  time: 0.6694  data_time: 0.2383  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:05:43 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 2839  total_loss: 1.399  loss_cls: 0.3404  loss_box_reg: 0.5769  loss_mask: 0.3051  loss_rpn_cls: 0.05807  loss_rpn_loc: 0.1186  time: 0.6700  data_time: 0.2341  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:05:56 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 2859  total_loss: 1.461  loss_cls: 0.3608  loss_box_reg: 0.5876  loss_mask: 0.2959  loss_rpn_cls: 0.04054  loss_rpn_loc: 0.1296  time: 0.6701  data_time: 0.1720  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:06:09 d2.utils.events]: \u001b[0m eta: 1:01:27  iter: 2879  total_loss: 1.455  loss_cls: 0.3557  loss_box_reg: 0.5771  loss_mask: 0.3033  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.1022  time: 0.6699  data_time: 0.1539  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:06:22 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 2899  total_loss: 1.482  loss_cls: 0.3633  loss_box_reg: 0.5972  loss_mask: 0.3064  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.1231  time: 0.6698  data_time: 0.1703  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:06:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:06:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:06:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:06:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:06:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:06:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1224 s/iter. Eval: 0.0531 s/iter. Total: 0.1761 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1287 s/iter. Eval: 0.1369 s/iter. Total: 0.2664 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 19:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1326 s/iter. Eval: 0.1580 s/iter. Total: 0.2915 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/06 19:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0008 s/iter. Inference: 0.1306 s/iter. Eval: 0.1519 s/iter. Total: 0.2833 s/iter. ETA=0:00:16\n",
      "\u001b[32m[02/06 19:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0008 s/iter. Inference: 0.1320 s/iter. Eval: 0.1667 s/iter. Total: 0.2996 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0008 s/iter. Inference: 0.1355 s/iter. Eval: 0.1811 s/iter. Total: 0.3174 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/06 19:07:02 d2.evaluation.evaluator]: \u001b[0mInference done 108/121. Dataloading: 0.0008 s/iter. Inference: 0.1349 s/iter. Eval: 0.1838 s/iter. Total: 0.3196 s/iter. ETA=0:00:04\n",
      "\u001b[32m[02/06 19:07:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.139108 (0.311544 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:07:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.134477 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:07:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:07:05 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2851717314064056\n",
      "\u001b[32m[02/06 19:07:14 d2.utils.events]: \u001b[0m eta: 1:01:10  iter: 2919  total_loss: 1.341  loss_cls: 0.3574  loss_box_reg: 0.5577  loss_mask: 0.2909  loss_rpn_cls: 0.0385  loss_rpn_loc: 0.1181  time: 0.6699  data_time: 0.1529  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:07:26 d2.utils.events]: \u001b[0m eta: 1:01:05  iter: 2939  total_loss: 1.434  loss_cls: 0.3524  loss_box_reg: 0.5773  loss_mask: 0.2991  loss_rpn_cls: 0.04986  loss_rpn_loc: 0.1307  time: 0.6693  data_time: 0.1003  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:07:39 d2.utils.events]: \u001b[0m eta: 1:00:58  iter: 2959  total_loss: 1.394  loss_cls: 0.3623  loss_box_reg: 0.5765  loss_mask: 0.3058  loss_rpn_cls: 0.05463  loss_rpn_loc: 0.1144  time: 0.6693  data_time: 0.1576  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:07:52 d2.utils.events]: \u001b[0m eta: 1:00:52  iter: 2979  total_loss: 1.313  loss_cls: 0.3249  loss_box_reg: 0.5423  loss_mask: 0.3027  loss_rpn_cls: 0.04466  loss_rpn_loc: 0.1137  time: 0.6692  data_time: 0.1374  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:08:05 d2.utils.events]: \u001b[0m eta: 1:00:44  iter: 2999  total_loss: 1.294  loss_cls: 0.323  loss_box_reg: 0.5595  loss_mask: 0.3037  loss_rpn_cls: 0.03353  loss_rpn_loc: 0.09654  time: 0.6689  data_time: 0.1168  lr: 0.0004  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:08:17 d2.utils.events]: \u001b[0m eta: 1:00:33  iter: 3019  total_loss: 1.423  loss_cls: 0.3558  loss_box_reg: 0.5862  loss_mask: 0.2943  loss_rpn_cls: 0.04582  loss_rpn_loc: 0.1205  time: 0.6686  data_time: 0.1263  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:08:33 d2.utils.events]: \u001b[0m eta: 1:00:31  iter: 3039  total_loss: 1.488  loss_cls: 0.367  loss_box_reg: 0.5694  loss_mask: 0.3063  loss_rpn_cls: 0.06849  loss_rpn_loc: 0.1504  time: 0.6693  data_time: 0.2475  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:08:47 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 3059  total_loss: 1.321  loss_cls: 0.3492  loss_box_reg: 0.554  loss_mask: 0.3028  loss_rpn_cls: 0.04484  loss_rpn_loc: 0.1152  time: 0.6696  data_time: 0.1969  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:09:01 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 3079  total_loss: 1.387  loss_cls: 0.3401  loss_box_reg: 0.5686  loss_mask: 0.2787  loss_rpn_cls: 0.05552  loss_rpn_loc: 0.1334  time: 0.6697  data_time: 0.1792  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:09:18 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 3099  total_loss: 1.454  loss_cls: 0.369  loss_box_reg: 0.5453  loss_mask: 0.2851  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.1412  time: 0.6709  data_time: 0.3256  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:09:36 d2.utils.events]: \u001b[0m eta: 1:00:11  iter: 3119  total_loss: 1.487  loss_cls: 0.3666  loss_box_reg: 0.5763  loss_mask: 0.2967  loss_rpn_cls: 0.05677  loss_rpn_loc: 0.1532  time: 0.6722  data_time: 0.3387  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:09:48 d2.utils.events]: \u001b[0m eta: 1:00:04  iter: 3139  total_loss: 1.431  loss_cls: 0.3472  loss_box_reg: 0.5998  loss_mask: 0.2974  loss_rpn_cls: 0.04777  loss_rpn_loc: 0.1258  time: 0.6720  data_time: 0.1318  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:09:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:09:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:09:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:09:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:09:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:09:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:09:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1158 s/iter. Eval: 0.0568 s/iter. Total: 0.1733 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:10:00 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1268 s/iter. Eval: 0.1395 s/iter. Total: 0.2671 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 19:10:05 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.1296 s/iter. Eval: 0.1497 s/iter. Total: 0.2802 s/iter. ETA=0:00:21\n",
      "\u001b[32m[02/06 19:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.1280 s/iter. Eval: 0.1373 s/iter. Total: 0.2662 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/06 19:10:15 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1320 s/iter. Eval: 0.1619 s/iter. Total: 0.2948 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1353 s/iter. Eval: 0.1735 s/iter. Total: 0.3096 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 19:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0008 s/iter. Inference: 0.1336 s/iter. Eval: 0.1699 s/iter. Total: 0.3044 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 19:10:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.874435 (0.300642 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:10:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.133801 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:10:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:10:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2935668684691771\n",
      "\u001b[32m[02/06 19:10:38 d2.utils.events]: \u001b[0m eta: 0:59:59  iter: 3159  total_loss: 1.331  loss_cls: 0.3549  loss_box_reg: 0.5488  loss_mask: 0.2958  loss_rpn_cls: 0.0593  loss_rpn_loc: 0.1248  time: 0.6718  data_time: 0.1310  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:10:51 d2.utils.events]: \u001b[0m eta: 0:59:48  iter: 3179  total_loss: 1.285  loss_cls: 0.3304  loss_box_reg: 0.5502  loss_mask: 0.2915  loss_rpn_cls: 0.04996  loss_rpn_loc: 0.105  time: 0.6716  data_time: 0.1500  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:11:06 d2.utils.events]: \u001b[0m eta: 0:59:44  iter: 3199  total_loss: 1.419  loss_cls: 0.3631  loss_box_reg: 0.5739  loss_mask: 0.2926  loss_rpn_cls: 0.05418  loss_rpn_loc: 0.1211  time: 0.6721  data_time: 0.2083  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:11:17 d2.utils.events]: \u001b[0m eta: 0:59:24  iter: 3219  total_loss: 1.352  loss_cls: 0.3475  loss_box_reg: 0.5388  loss_mask: 0.294  loss_rpn_cls: 0.04717  loss_rpn_loc: 0.1191  time: 0.6714  data_time: 0.0772  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:11:28 d2.utils.events]: \u001b[0m eta: 0:59:09  iter: 3239  total_loss: 1.325  loss_cls: 0.326  loss_box_reg: 0.5788  loss_mask: 0.307  loss_rpn_cls: 0.0408  loss_rpn_loc: 0.1165  time: 0.6707  data_time: 0.0893  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:11:44 d2.utils.events]: \u001b[0m eta: 0:59:03  iter: 3259  total_loss: 1.413  loss_cls: 0.3643  loss_box_reg: 0.5829  loss_mask: 0.2895  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.1352  time: 0.6715  data_time: 0.2435  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:11:58 d2.utils.events]: \u001b[0m eta: 0:58:55  iter: 3279  total_loss: 1.341  loss_cls: 0.3354  loss_box_reg: 0.5574  loss_mask: 0.2891  loss_rpn_cls: 0.04291  loss_rpn_loc: 0.1221  time: 0.6715  data_time: 0.1636  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:12:13 d2.utils.events]: \u001b[0m eta: 0:58:51  iter: 3299  total_loss: 1.388  loss_cls: 0.3482  loss_box_reg: 0.5636  loss_mask: 0.2882  loss_rpn_cls: 0.05265  loss_rpn_loc: 0.1148  time: 0.6719  data_time: 0.2252  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:12:30 d2.utils.events]: \u001b[0m eta: 0:58:53  iter: 3319  total_loss: 1.437  loss_cls: 0.3864  loss_box_reg: 0.5717  loss_mask: 0.302  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.1486  time: 0.6731  data_time: 0.3217  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:12:44 d2.utils.events]: \u001b[0m eta: 0:58:43  iter: 3339  total_loss: 1.433  loss_cls: 0.3586  loss_box_reg: 0.5484  loss_mask: 0.2845  loss_rpn_cls: 0.05231  loss_rpn_loc: 0.1452  time: 0.6733  data_time: 0.1796  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:12:59 d2.utils.events]: \u001b[0m eta: 0:58:35  iter: 3359  total_loss: 1.42  loss_cls: 0.3511  loss_box_reg: 0.5713  loss_mask: 0.2965  loss_rpn_cls: 0.05635  loss_rpn_loc: 0.1376  time: 0.6738  data_time: 0.2264  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:13:11 d2.utils.events]: \u001b[0m eta: 0:58:24  iter: 3379  total_loss: 1.415  loss_cls: 0.3563  loss_box_reg: 0.5589  loss_mask: 0.2915  loss_rpn_cls: 0.05748  loss_rpn_loc: 0.1022  time: 0.6732  data_time: 0.0726  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:13:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:13:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:13:16 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:13:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:13:16 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:13:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1228 s/iter. Eval: 0.0637 s/iter. Total: 0.1871 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 19:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1297 s/iter. Eval: 0.1478 s/iter. Total: 0.2784 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/06 19:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0008 s/iter. Inference: 0.1327 s/iter. Eval: 0.1609 s/iter. Total: 0.2945 s/iter. ETA=0:00:22\n",
      "\u001b[32m[02/06 19:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0008 s/iter. Inference: 0.1277 s/iter. Eval: 0.1442 s/iter. Total: 0.2727 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/06 19:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1308 s/iter. Eval: 0.1703 s/iter. Total: 0.3020 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 92/121. Dataloading: 0.0008 s/iter. Inference: 0.1336 s/iter. Eval: 0.1834 s/iter. Total: 0.3179 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/06 19:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 110/121. Dataloading: 0.0008 s/iter. Inference: 0.1325 s/iter. Eval: 0.1783 s/iter. Total: 0.3117 s/iter. ETA=0:00:03\n",
      "\u001b[32m[02/06 19:13:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.690636 (0.307678 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:13:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.132569 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:13:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:13:53 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2886201382499291\n",
      "\u001b[32m[02/06 19:14:02 d2.utils.events]: \u001b[0m eta: 0:58:13  iter: 3399  total_loss: 1.248  loss_cls: 0.307  loss_box_reg: 0.5326  loss_mask: 0.283  loss_rpn_cls: 0.02998  loss_rpn_loc: 0.07109  time: 0.6732  data_time: 0.1560  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:14:15 d2.utils.events]: \u001b[0m eta: 0:58:05  iter: 3419  total_loss: 1.335  loss_cls: 0.3106  loss_box_reg: 0.5873  loss_mask: 0.3061  loss_rpn_cls: 0.02596  loss_rpn_loc: 0.1062  time: 0.6730  data_time: 0.1305  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:14:28 d2.utils.events]: \u001b[0m eta: 0:57:54  iter: 3439  total_loss: 1.385  loss_cls: 0.342  loss_box_reg: 0.5623  loss_mask: 0.2864  loss_rpn_cls: 0.05415  loss_rpn_loc: 0.1213  time: 0.6730  data_time: 0.1422  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:14:44 d2.utils.events]: \u001b[0m eta: 0:57:45  iter: 3459  total_loss: 1.395  loss_cls: 0.3281  loss_box_reg: 0.5525  loss_mask: 0.3021  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.1332  time: 0.6735  data_time: 0.2629  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:14:57 d2.utils.events]: \u001b[0m eta: 0:57:37  iter: 3479  total_loss: 1.429  loss_cls: 0.3544  loss_box_reg: 0.5572  loss_mask: 0.3021  loss_rpn_cls: 0.03668  loss_rpn_loc: 0.1086  time: 0.6735  data_time: 0.1588  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:15:11 d2.utils.events]: \u001b[0m eta: 0:57:32  iter: 3499  total_loss: 1.445  loss_cls: 0.3549  loss_box_reg: 0.554  loss_mask: 0.3038  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.1393  time: 0.6736  data_time: 0.1626  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:15:25 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 3519  total_loss: 1.436  loss_cls: 0.3559  loss_box_reg: 0.563  loss_mask: 0.3006  loss_rpn_cls: 0.05389  loss_rpn_loc: 0.1369  time: 0.6737  data_time: 0.1770  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:15:38 d2.utils.events]: \u001b[0m eta: 0:57:19  iter: 3539  total_loss: 1.326  loss_cls: 0.345  loss_box_reg: 0.5394  loss_mask: 0.2898  loss_rpn_cls: 0.04931  loss_rpn_loc: 0.1123  time: 0.6736  data_time: 0.1374  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:15:51 d2.utils.events]: \u001b[0m eta: 0:57:08  iter: 3559  total_loss: 1.283  loss_cls: 0.3204  loss_box_reg: 0.5385  loss_mask: 0.2798  loss_rpn_cls: 0.03725  loss_rpn_loc: 0.1069  time: 0.6735  data_time: 0.1636  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:16:04 d2.utils.events]: \u001b[0m eta: 0:56:53  iter: 3579  total_loss: 1.372  loss_cls: 0.3362  loss_box_reg: 0.549  loss_mask: 0.3012  loss_rpn_cls: 0.05751  loss_rpn_loc: 0.09577  time: 0.6735  data_time: 0.1648  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:16:18 d2.utils.events]: \u001b[0m eta: 0:56:47  iter: 3599  total_loss: 1.333  loss_cls: 0.325  loss_box_reg: 0.5379  loss_mask: 0.2754  loss_rpn_cls: 0.04227  loss_rpn_loc: 0.1153  time: 0.6736  data_time: 0.1602  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:16:31 d2.utils.events]: \u001b[0m eta: 0:56:35  iter: 3619  total_loss: 1.41  loss_cls: 0.3738  loss_box_reg: 0.5717  loss_mask: 0.2994  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.123  time: 0.6735  data_time: 0.1510  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:16:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:16:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:16:38 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:16:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:16:38 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:16:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:16:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1149 s/iter. Eval: 0.0514 s/iter. Total: 0.1670 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:16:46 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1271 s/iter. Eval: 0.1292 s/iter. Total: 0.2571 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:16:51 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1270 s/iter. Eval: 0.1324 s/iter. Total: 0.2603 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1247 s/iter. Eval: 0.1284 s/iter. Total: 0.2539 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:17:01 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.1287 s/iter. Eval: 0.1500 s/iter. Total: 0.2796 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/06 19:17:06 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1299 s/iter. Eval: 0.1577 s/iter. Total: 0.2884 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 19:17:11 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1282 s/iter. Eval: 0.1485 s/iter. Total: 0.2775 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 19:17:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.244617 (0.277971 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:17:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.128327 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:17:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:17:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29295495992228965\n",
      "\u001b[32m[02/06 19:17:20 d2.utils.events]: \u001b[0m eta: 0:56:19  iter: 3639  total_loss: 1.502  loss_cls: 0.3775  loss_box_reg: 0.5848  loss_mask: 0.3043  loss_rpn_cls: 0.06058  loss_rpn_loc: 0.1382  time: 0.6737  data_time: 0.1727  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:17:34 d2.utils.events]: \u001b[0m eta: 0:56:14  iter: 3659  total_loss: 1.338  loss_cls: 0.3274  loss_box_reg: 0.5458  loss_mask: 0.2935  loss_rpn_cls: 0.06032  loss_rpn_loc: 0.1262  time: 0.6740  data_time: 0.1954  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:17:47 d2.utils.events]: \u001b[0m eta: 0:56:03  iter: 3679  total_loss: 1.314  loss_cls: 0.3241  loss_box_reg: 0.5452  loss_mask: 0.2792  loss_rpn_cls: 0.05183  loss_rpn_loc: 0.1181  time: 0.6738  data_time: 0.1401  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:18:00 d2.utils.events]: \u001b[0m eta: 0:56:00  iter: 3699  total_loss: 1.381  loss_cls: 0.3839  loss_box_reg: 0.5682  loss_mask: 0.288  loss_rpn_cls: 0.05659  loss_rpn_loc: 0.1305  time: 0.6736  data_time: 0.1248  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:18:13 d2.utils.events]: \u001b[0m eta: 0:55:50  iter: 3719  total_loss: 1.401  loss_cls: 0.3342  loss_box_reg: 0.5731  loss_mask: 0.3021  loss_rpn_cls: 0.03809  loss_rpn_loc: 0.1202  time: 0.6736  data_time: 0.1563  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:18:27 d2.utils.events]: \u001b[0m eta: 0:55:40  iter: 3739  total_loss: 1.372  loss_cls: 0.3423  loss_box_reg: 0.5584  loss_mask: 0.3012  loss_rpn_cls: 0.04777  loss_rpn_loc: 0.1241  time: 0.6737  data_time: 0.1817  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:18:43 d2.utils.events]: \u001b[0m eta: 0:55:32  iter: 3759  total_loss: 1.446  loss_cls: 0.3716  loss_box_reg: 0.5728  loss_mask: 0.2995  loss_rpn_cls: 0.05408  loss_rpn_loc: 0.1452  time: 0.6744  data_time: 0.2571  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:18:55 d2.utils.events]: \u001b[0m eta: 0:55:19  iter: 3779  total_loss: 1.426  loss_cls: 0.3494  loss_box_reg: 0.5573  loss_mask: 0.3061  loss_rpn_cls: 0.04976  loss_rpn_loc: 0.1398  time: 0.6740  data_time: 0.0979  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:19:12 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 3799  total_loss: 1.362  loss_cls: 0.3455  loss_box_reg: 0.5574  loss_mask: 0.2889  loss_rpn_cls: 0.0444  loss_rpn_loc: 0.1211  time: 0.6748  data_time: 0.3209  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:19:27 d2.utils.events]: \u001b[0m eta: 0:54:57  iter: 3819  total_loss: 1.291  loss_cls: 0.3216  loss_box_reg: 0.5337  loss_mask: 0.2775  loss_rpn_cls: 0.05402  loss_rpn_loc: 0.1226  time: 0.6751  data_time: 0.2138  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:19:40 d2.utils.events]: \u001b[0m eta: 0:54:47  iter: 3839  total_loss: 1.336  loss_cls: 0.3388  loss_box_reg: 0.568  loss_mask: 0.2967  loss_rpn_cls: 0.04931  loss_rpn_loc: 0.1226  time: 0.6752  data_time: 0.1619  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:19:53 d2.utils.events]: \u001b[0m eta: 0:54:33  iter: 3859  total_loss: 1.393  loss_cls: 0.3497  loss_box_reg: 0.5521  loss_mask: 0.3046  loss_rpn_cls: 0.05436  loss_rpn_loc: 0.1172  time: 0.6750  data_time: 0.1440  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:20:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:20:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:20:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:20:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:20:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:20:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1151 s/iter. Eval: 0.0584 s/iter. Total: 0.1742 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:20:08 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1245 s/iter. Eval: 0.1380 s/iter. Total: 0.2633 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 19:20:13 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.1270 s/iter. Eval: 0.1483 s/iter. Total: 0.2762 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 19:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.1249 s/iter. Eval: 0.1368 s/iter. Total: 0.2627 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 19:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0008 s/iter. Inference: 0.1287 s/iter. Eval: 0.1603 s/iter. Total: 0.2899 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1297 s/iter. Eval: 0.1686 s/iter. Total: 0.2993 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 19:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.1278 s/iter. Eval: 0.1594 s/iter. Total: 0.2880 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 19:20:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.839754 (0.291722 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:20:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.128568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:20:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:20:35 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29076478453574933\n",
      "\u001b[32m[02/06 19:20:42 d2.utils.events]: \u001b[0m eta: 0:54:22  iter: 3879  total_loss: 1.419  loss_cls: 0.3346  loss_box_reg: 0.5684  loss_mask: 0.2947  loss_rpn_cls: 0.04833  loss_rpn_loc: 0.1186  time: 0.6748  data_time: 0.1399  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:20:56 d2.utils.events]: \u001b[0m eta: 0:54:13  iter: 3899  total_loss: 1.335  loss_cls: 0.3436  loss_box_reg: 0.5397  loss_mask: 0.2913  loss_rpn_cls: 0.04769  loss_rpn_loc: 0.1217  time: 0.6749  data_time: 0.1880  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:21:09 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 3919  total_loss: 1.25  loss_cls: 0.3313  loss_box_reg: 0.5477  loss_mask: 0.2871  loss_rpn_cls: 0.04084  loss_rpn_loc: 0.09459  time: 0.6748  data_time: 0.1539  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:21:22 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 3939  total_loss: 1.338  loss_cls: 0.3417  loss_box_reg: 0.5657  loss_mask: 0.2781  loss_rpn_cls: 0.04231  loss_rpn_loc: 0.09986  time: 0.6748  data_time: 0.1548  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:21:36 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 3959  total_loss: 1.328  loss_cls: 0.346  loss_box_reg: 0.5455  loss_mask: 0.295  loss_rpn_cls: 0.04756  loss_rpn_loc: 0.1192  time: 0.6750  data_time: 0.2207  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:21:48 d2.utils.events]: \u001b[0m eta: 0:53:29  iter: 3979  total_loss: 1.393  loss_cls: 0.3119  loss_box_reg: 0.5586  loss_mask: 0.2829  loss_rpn_cls: 0.04544  loss_rpn_loc: 0.1061  time: 0.6744  data_time: 0.0803  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:22:00 d2.utils.events]: \u001b[0m eta: 0:53:18  iter: 3999  total_loss: 1.404  loss_cls: 0.3569  loss_box_reg: 0.5667  loss_mask: 0.3003  loss_rpn_cls: 0.04202  loss_rpn_loc: 0.1182  time: 0.6740  data_time: 0.1152  lr: 0.00032  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:22:16 d2.utils.events]: \u001b[0m eta: 0:53:13  iter: 4019  total_loss: 1.422  loss_cls: 0.3536  loss_box_reg: 0.5547  loss_mask: 0.2947  loss_rpn_cls: 0.0592  loss_rpn_loc: 0.1404  time: 0.6746  data_time: 0.2723  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:22:30 d2.utils.events]: \u001b[0m eta: 0:52:59  iter: 4039  total_loss: 1.319  loss_cls: 0.3196  loss_box_reg: 0.5592  loss_mask: 0.2811  loss_rpn_cls: 0.04455  loss_rpn_loc: 0.12  time: 0.6749  data_time: 0.2003  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:22:45 d2.utils.events]: \u001b[0m eta: 0:52:48  iter: 4059  total_loss: 1.475  loss_cls: 0.3636  loss_box_reg: 0.586  loss_mask: 0.3028  loss_rpn_cls: 0.06588  loss_rpn_loc: 0.1339  time: 0.6752  data_time: 0.2010  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:23:03 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 4079  total_loss: 1.521  loss_cls: 0.388  loss_box_reg: 0.5907  loss_mask: 0.3028  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.137  time: 0.6763  data_time: 0.3697  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:23:17 d2.utils.events]: \u001b[0m eta: 0:52:30  iter: 4099  total_loss: 1.492  loss_cls: 0.3834  loss_box_reg: 0.5861  loss_mask: 0.2969  loss_rpn_cls: 0.05984  loss_rpn_loc: 0.1313  time: 0.6764  data_time: 0.1750  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:23:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:23:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:23:26 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:23:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:23:26 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:23:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1095 s/iter. Eval: 0.0564 s/iter. Total: 0.1666 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:23:34 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1201 s/iter. Eval: 0.1319 s/iter. Total: 0.2529 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1227 s/iter. Eval: 0.1384 s/iter. Total: 0.2619 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:23:44 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.1210 s/iter. Eval: 0.1293 s/iter. Total: 0.2512 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1272 s/iter. Eval: 0.1576 s/iter. Total: 0.2856 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:23:54 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1290 s/iter. Eval: 0.1641 s/iter. Total: 0.2940 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 19:23:59 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.1276 s/iter. Eval: 0.1552 s/iter. Total: 0.2836 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 19:24:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.306028 (0.287121 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:24:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.128493 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:24:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:24:01 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2915327876266374\n",
      "\u001b[32m[02/06 19:24:06 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 4119  total_loss: 1.353  loss_cls: 0.3511  loss_box_reg: 0.5651  loss_mask: 0.2988  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.1355  time: 0.6765  data_time: 0.1934  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:24:19 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 4139  total_loss: 1.408  loss_cls: 0.3551  loss_box_reg: 0.5738  loss_mask: 0.2903  loss_rpn_cls: 0.05554  loss_rpn_loc: 0.1292  time: 0.6763  data_time: 0.1480  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:24:33 d2.utils.events]: \u001b[0m eta: 0:51:55  iter: 4159  total_loss: 1.259  loss_cls: 0.3264  loss_box_reg: 0.5027  loss_mask: 0.2714  loss_rpn_cls: 0.03681  loss_rpn_loc: 0.1048  time: 0.6766  data_time: 0.2189  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:24:46 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 4179  total_loss: 1.345  loss_cls: 0.3378  loss_box_reg: 0.581  loss_mask: 0.3007  loss_rpn_cls: 0.04633  loss_rpn_loc: 0.1197  time: 0.6764  data_time: 0.1354  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:25:00 d2.utils.events]: \u001b[0m eta: 0:51:36  iter: 4199  total_loss: 1.41  loss_cls: 0.3534  loss_box_reg: 0.5885  loss_mask: 0.3087  loss_rpn_cls: 0.0468  loss_rpn_loc: 0.1181  time: 0.6765  data_time: 0.1598  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:25:12 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 4219  total_loss: 1.257  loss_cls: 0.3181  loss_box_reg: 0.54  loss_mask: 0.2838  loss_rpn_cls: 0.04035  loss_rpn_loc: 0.1009  time: 0.6760  data_time: 0.0740  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:25:26 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 4239  total_loss: 1.41  loss_cls: 0.3698  loss_box_reg: 0.5744  loss_mask: 0.2854  loss_rpn_cls: 0.05173  loss_rpn_loc: 0.1439  time: 0.6763  data_time: 0.2312  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:25:42 d2.utils.events]: \u001b[0m eta: 0:51:16  iter: 4259  total_loss: 1.391  loss_cls: 0.3655  loss_box_reg: 0.5591  loss_mask: 0.3  loss_rpn_cls: 0.06802  loss_rpn_loc: 0.124  time: 0.6768  data_time: 0.2667  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:25:58 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 4279  total_loss: 1.379  loss_cls: 0.3393  loss_box_reg: 0.5469  loss_mask: 0.2983  loss_rpn_cls: 0.05148  loss_rpn_loc: 0.1243  time: 0.6773  data_time: 0.2544  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:26:14 d2.utils.events]: \u001b[0m eta: 0:50:57  iter: 4299  total_loss: 1.314  loss_cls: 0.3229  loss_box_reg: 0.5451  loss_mask: 0.2951  loss_rpn_cls: 0.04485  loss_rpn_loc: 0.1094  time: 0.6778  data_time: 0.2703  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:26:26 d2.utils.events]: \u001b[0m eta: 0:50:41  iter: 4319  total_loss: 1.345  loss_cls: 0.3216  loss_box_reg: 0.5459  loss_mask: 0.2889  loss_rpn_cls: 0.05351  loss_rpn_loc: 0.1132  time: 0.6777  data_time: 0.1233  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:26:40 d2.utils.events]: \u001b[0m eta: 0:50:23  iter: 4339  total_loss: 1.404  loss_cls: 0.3607  loss_box_reg: 0.5588  loss_mask: 0.3146  loss_rpn_cls: 0.04738  loss_rpn_loc: 0.1236  time: 0.6775  data_time: 0.1475  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:26:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:26:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:26:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:26:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:26:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:26:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:26:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1086 s/iter. Eval: 0.0547 s/iter. Total: 0.1639 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:27:02 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1207 s/iter. Eval: 0.1304 s/iter. Total: 0.2520 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:27:07 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1236 s/iter. Eval: 0.1387 s/iter. Total: 0.2631 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.1208 s/iter. Eval: 0.1275 s/iter. Total: 0.2492 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1253 s/iter. Eval: 0.1531 s/iter. Total: 0.2793 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1266 s/iter. Eval: 0.1624 s/iter. Total: 0.2899 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 19:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1256 s/iter. Eval: 0.1530 s/iter. Total: 0.2794 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 19:27:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.483287 (0.280028 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:27:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.125747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:27:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:27:28 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29884816714003076\n",
      "\u001b[32m[02/06 19:27:30 d2.utils.events]: \u001b[0m eta: 0:50:16  iter: 4359  total_loss: 1.37  loss_cls: 0.3563  loss_box_reg: 0.5526  loss_mask: 0.2951  loss_rpn_cls: 0.04241  loss_rpn_loc: 0.1238  time: 0.6782  data_time: 0.2786  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:27:44 d2.utils.events]: \u001b[0m eta: 0:50:07  iter: 4379  total_loss: 1.335  loss_cls: 0.3409  loss_box_reg: 0.5698  loss_mask: 0.2873  loss_rpn_cls: 0.04543  loss_rpn_loc: 0.1205  time: 0.6782  data_time: 0.1771  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:27:59 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 4399  total_loss: 1.362  loss_cls: 0.3033  loss_box_reg: 0.5586  loss_mask: 0.2962  loss_rpn_cls: 0.04527  loss_rpn_loc: 0.104  time: 0.6785  data_time: 0.2520  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:28:13 d2.utils.events]: \u001b[0m eta: 0:49:48  iter: 4419  total_loss: 1.281  loss_cls: 0.3334  loss_box_reg: 0.5381  loss_mask: 0.2691  loss_rpn_cls: 0.05283  loss_rpn_loc: 0.1047  time: 0.6785  data_time: 0.1792  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:28:26 d2.utils.events]: \u001b[0m eta: 0:49:31  iter: 4439  total_loss: 1.424  loss_cls: 0.3525  loss_box_reg: 0.5852  loss_mask: 0.2926  loss_rpn_cls: 0.04928  loss_rpn_loc: 0.1223  time: 0.6784  data_time: 0.1477  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:28:39 d2.utils.events]: \u001b[0m eta: 0:49:18  iter: 4459  total_loss: 1.388  loss_cls: 0.3397  loss_box_reg: 0.573  loss_mask: 0.2943  loss_rpn_cls: 0.04127  loss_rpn_loc: 0.1199  time: 0.6783  data_time: 0.1714  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:28:52 d2.utils.events]: \u001b[0m eta: 0:49:07  iter: 4479  total_loss: 1.472  loss_cls: 0.3771  loss_box_reg: 0.5983  loss_mask: 0.3133  loss_rpn_cls: 0.06238  loss_rpn_loc: 0.121  time: 0.6782  data_time: 0.1722  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:29:07 d2.utils.events]: \u001b[0m eta: 0:48:56  iter: 4499  total_loss: 1.519  loss_cls: 0.3713  loss_box_reg: 0.5853  loss_mask: 0.3006  loss_rpn_cls: 0.0647  loss_rpn_loc: 0.1579  time: 0.6784  data_time: 0.1962  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:29:21 d2.utils.events]: \u001b[0m eta: 0:48:46  iter: 4519  total_loss: 1.375  loss_cls: 0.3444  loss_box_reg: 0.5605  loss_mask: 0.3041  loss_rpn_cls: 0.03993  loss_rpn_loc: 0.1236  time: 0.6787  data_time: 0.2110  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:29:35 d2.utils.events]: \u001b[0m eta: 0:48:29  iter: 4539  total_loss: 1.264  loss_cls: 0.3181  loss_box_reg: 0.5494  loss_mask: 0.2793  loss_rpn_cls: 0.04602  loss_rpn_loc: 0.09995  time: 0.6787  data_time: 0.1852  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:29:47 d2.utils.events]: \u001b[0m eta: 0:48:18  iter: 4559  total_loss: 1.392  loss_cls: 0.3241  loss_box_reg: 0.5467  loss_mask: 0.2892  loss_rpn_cls: 0.03495  loss_rpn_loc: 0.1246  time: 0.6784  data_time: 0.1094  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:30:02 d2.utils.events]: \u001b[0m eta: 0:48:09  iter: 4579  total_loss: 1.439  loss_cls: 0.3477  loss_box_reg: 0.5814  loss_mask: 0.301  loss_rpn_cls: 0.05266  loss_rpn_loc: 0.1154  time: 0.6786  data_time: 0.1971  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:30:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:30:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:30:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:30:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:30:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:30:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1158 s/iter. Eval: 0.0556 s/iter. Total: 0.1720 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1264 s/iter. Eval: 0.1290 s/iter. Total: 0.2563 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1268 s/iter. Eval: 0.1350 s/iter. Total: 0.2627 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1236 s/iter. Eval: 0.1297 s/iter. Total: 0.2541 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1281 s/iter. Eval: 0.1550 s/iter. Total: 0.2840 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1290 s/iter. Eval: 0.1617 s/iter. Total: 0.2915 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 19:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1278 s/iter. Eval: 0.1521 s/iter. Total: 0.2807 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 19:30:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.627942 (0.281275 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:30:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127941 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:30:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:30:49 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2970501335466972\n",
      "\u001b[32m[02/06 19:30:50 d2.utils.events]: \u001b[0m eta: 0:47:57  iter: 4599  total_loss: 1.324  loss_cls: 0.3213  loss_box_reg: 0.5529  loss_mask: 0.2874  loss_rpn_cls: 0.0399  loss_rpn_loc: 0.111  time: 0.6785  data_time: 0.1460  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:31:02 d2.utils.events]: \u001b[0m eta: 0:47:46  iter: 4619  total_loss: 1.314  loss_cls: 0.3241  loss_box_reg: 0.5412  loss_mask: 0.284  loss_rpn_cls: 0.0403  loss_rpn_loc: 0.118  time: 0.6783  data_time: 0.1041  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:31:20 d2.utils.events]: \u001b[0m eta: 0:47:35  iter: 4639  total_loss: 1.361  loss_cls: 0.3503  loss_box_reg: 0.5417  loss_mask: 0.2804  loss_rpn_cls: 0.06596  loss_rpn_loc: 0.1321  time: 0.6792  data_time: 0.3698  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:31:35 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 4659  total_loss: 1.421  loss_cls: 0.3534  loss_box_reg: 0.5727  loss_mask: 0.3085  loss_rpn_cls: 0.05218  loss_rpn_loc: 0.1263  time: 0.6795  data_time: 0.2306  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:31:48 d2.utils.events]: \u001b[0m eta: 0:47:14  iter: 4679  total_loss: 1.473  loss_cls: 0.3482  loss_box_reg: 0.6071  loss_mask: 0.3146  loss_rpn_cls: 0.05904  loss_rpn_loc: 0.1406  time: 0.6794  data_time: 0.1381  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:32:00 d2.utils.events]: \u001b[0m eta: 0:47:03  iter: 4699  total_loss: 1.353  loss_cls: 0.3365  loss_box_reg: 0.5456  loss_mask: 0.2882  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.1141  time: 0.6791  data_time: 0.0966  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:32:14 d2.utils.events]: \u001b[0m eta: 0:46:53  iter: 4719  total_loss: 1.426  loss_cls: 0.3718  loss_box_reg: 0.5765  loss_mask: 0.3088  loss_rpn_cls: 0.05695  loss_rpn_loc: 0.1205  time: 0.6791  data_time: 0.1713  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:32:27 d2.utils.events]: \u001b[0m eta: 0:46:42  iter: 4739  total_loss: 1.371  loss_cls: 0.3604  loss_box_reg: 0.5517  loss_mask: 0.2832  loss_rpn_cls: 0.05147  loss_rpn_loc: 0.1245  time: 0.6791  data_time: 0.1509  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:32:41 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 4759  total_loss: 1.379  loss_cls: 0.3432  loss_box_reg: 0.5555  loss_mask: 0.2913  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.117  time: 0.6790  data_time: 0.1387  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:32:56 d2.utils.events]: \u001b[0m eta: 0:46:25  iter: 4779  total_loss: 1.3  loss_cls: 0.3332  loss_box_reg: 0.5157  loss_mask: 0.2654  loss_rpn_cls: 0.04202  loss_rpn_loc: 0.1145  time: 0.6795  data_time: 0.2555  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:33:09 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 4799  total_loss: 1.199  loss_cls: 0.2783  loss_box_reg: 0.5334  loss_mask: 0.291  loss_rpn_cls: 0.03186  loss_rpn_loc: 0.07453  time: 0.6792  data_time: 0.1225  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:33:22 d2.utils.events]: \u001b[0m eta: 0:45:59  iter: 4819  total_loss: 1.408  loss_cls: 0.3548  loss_box_reg: 0.5698  loss_mask: 0.2929  loss_rpn_cls: 0.06565  loss_rpn_loc: 0.119  time: 0.6792  data_time: 0.1736  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:33:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:33:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:33:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:33:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:33:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:33:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:33:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1187 s/iter. Eval: 0.0568 s/iter. Total: 0.1761 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1261 s/iter. Eval: 0.1379 s/iter. Total: 0.2649 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 19:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1262 s/iter. Eval: 0.1441 s/iter. Total: 0.2711 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 19:33:57 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1239 s/iter. Eval: 0.1334 s/iter. Total: 0.2582 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 19:34:02 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0008 s/iter. Inference: 0.1285 s/iter. Eval: 0.1596 s/iter. Total: 0.2889 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1299 s/iter. Eval: 0.1680 s/iter. Total: 0.2987 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 19:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.1291 s/iter. Eval: 0.1600 s/iter. Total: 0.2900 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 19:34:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.909148 (0.292320 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:34:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.129770 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:34:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:34:15 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29397958395523366\n",
      "\u001b[32m[02/06 19:34:15 d2.utils.events]: \u001b[0m eta: 0:45:49  iter: 4839  total_loss: 1.46  loss_cls: 0.3906  loss_box_reg: 0.5866  loss_mask: 0.2878  loss_rpn_cls: 0.05298  loss_rpn_loc: 0.1366  time: 0.6798  data_time: 0.2868  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:34:30 d2.utils.events]: \u001b[0m eta: 0:45:46  iter: 4859  total_loss: 1.343  loss_cls: 0.3287  loss_box_reg: 0.5552  loss_mask: 0.3018  loss_rpn_cls: 0.05356  loss_rpn_loc: 0.1233  time: 0.6802  data_time: 0.2644  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:34:44 d2.utils.events]: \u001b[0m eta: 0:45:39  iter: 4879  total_loss: 1.381  loss_cls: 0.3483  loss_box_reg: 0.5491  loss_mask: 0.2903  loss_rpn_cls: 0.05376  loss_rpn_loc: 0.1376  time: 0.6801  data_time: 0.1529  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:34:57 d2.utils.events]: \u001b[0m eta: 0:45:29  iter: 4899  total_loss: 1.403  loss_cls: 0.3506  loss_box_reg: 0.5952  loss_mask: 0.3104  loss_rpn_cls: 0.04945  loss_rpn_loc: 0.1215  time: 0.6801  data_time: 0.1551  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:35:13 d2.utils.events]: \u001b[0m eta: 0:45:20  iter: 4919  total_loss: 1.271  loss_cls: 0.3237  loss_box_reg: 0.5205  loss_mask: 0.2896  loss_rpn_cls: 0.06769  loss_rpn_loc: 0.1276  time: 0.6806  data_time: 0.2962  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:35:24 d2.utils.events]: \u001b[0m eta: 0:45:06  iter: 4939  total_loss: 1.172  loss_cls: 0.2749  loss_box_reg: 0.5222  loss_mask: 0.2788  loss_rpn_cls: 0.02165  loss_rpn_loc: 0.09997  time: 0.6800  data_time: 0.0441  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:35:38 d2.utils.events]: \u001b[0m eta: 0:44:56  iter: 4959  total_loss: 1.426  loss_cls: 0.3631  loss_box_reg: 0.5725  loss_mask: 0.3043  loss_rpn_cls: 0.05174  loss_rpn_loc: 0.1181  time: 0.6801  data_time: 0.1735  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:35:51 d2.utils.events]: \u001b[0m eta: 0:44:50  iter: 4979  total_loss: 1.334  loss_cls: 0.3396  loss_box_reg: 0.5612  loss_mask: 0.2873  loss_rpn_cls: 0.0471  loss_rpn_loc: 0.1066  time: 0.6799  data_time: 0.1306  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:36:06 d2.utils.events]: \u001b[0m eta: 0:44:40  iter: 4999  total_loss: 1.325  loss_cls: 0.3362  loss_box_reg: 0.5556  loss_mask: 0.2993  loss_rpn_cls: 0.05024  loss_rpn_loc: 0.1141  time: 0.6802  data_time: 0.2472  lr: 0.000256  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:36:20 d2.utils.events]: \u001b[0m eta: 0:44:24  iter: 5019  total_loss: 1.275  loss_cls: 0.3245  loss_box_reg: 0.5475  loss_mask: 0.293  loss_rpn_cls: 0.03668  loss_rpn_loc: 0.1146  time: 0.6804  data_time: 0.2221  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:36:32 d2.utils.events]: \u001b[0m eta: 0:44:08  iter: 5039  total_loss: 1.397  loss_cls: 0.3502  loss_box_reg: 0.5689  loss_mask: 0.3008  loss_rpn_cls: 0.05707  loss_rpn_loc: 0.1308  time: 0.6801  data_time: 0.1279  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:36:46 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 5059  total_loss: 1.409  loss_cls: 0.3432  loss_box_reg: 0.5775  loss_mask: 0.2922  loss_rpn_cls: 0.04144  loss_rpn_loc: 0.1245  time: 0.6801  data_time: 0.1835  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:37:02 d2.utils.events]: \u001b[0m eta: 0:43:41  iter: 5079  total_loss: 1.429  loss_cls: 0.3846  loss_box_reg: 0.5589  loss_mask: 0.3069  loss_rpn_cls: 0.06603  loss_rpn_loc: 0.1248  time: 0.6805  data_time: 0.2616  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:37:03 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:37:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:37:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:37:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:37:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:37:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1119 s/iter. Eval: 0.0512 s/iter. Total: 0.1637 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 30/121. Dataloading: 0.0008 s/iter. Inference: 0.1227 s/iter. Eval: 0.1353 s/iter. Total: 0.2588 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 52/121. Dataloading: 0.0008 s/iter. Inference: 0.1198 s/iter. Eval: 0.1258 s/iter. Total: 0.2465 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/06 19:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0008 s/iter. Inference: 0.1192 s/iter. Eval: 0.1259 s/iter. Total: 0.2459 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0008 s/iter. Inference: 0.1237 s/iter. Eval: 0.1513 s/iter. Total: 0.2758 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/06 19:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 102/121. Dataloading: 0.0008 s/iter. Inference: 0.1252 s/iter. Eval: 0.1548 s/iter. Total: 0.2809 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/06 19:37:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.156626 (0.277212 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:37:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.125781 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:37:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:37:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29734402550085137\n",
      "\u001b[32m[02/06 19:37:49 d2.utils.events]: \u001b[0m eta: 0:43:30  iter: 5099  total_loss: 1.399  loss_cls: 0.3614  loss_box_reg: 0.5609  loss_mask: 0.2914  loss_rpn_cls: 0.05757  loss_rpn_loc: 0.1272  time: 0.6804  data_time: 0.1436  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:38:02 d2.utils.events]: \u001b[0m eta: 0:43:19  iter: 5119  total_loss: 1.192  loss_cls: 0.2817  loss_box_reg: 0.511  loss_mask: 0.272  loss_rpn_cls: 0.03146  loss_rpn_loc: 0.09014  time: 0.6804  data_time: 0.1664  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:38:16 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 5139  total_loss: 1.346  loss_cls: 0.3209  loss_box_reg: 0.5528  loss_mask: 0.2944  loss_rpn_cls: 0.04153  loss_rpn_loc: 0.09977  time: 0.6803  data_time: 0.1422  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:38:30 d2.utils.events]: \u001b[0m eta: 0:42:58  iter: 5159  total_loss: 1.45  loss_cls: 0.3556  loss_box_reg: 0.5828  loss_mask: 0.2999  loss_rpn_cls: 0.03972  loss_rpn_loc: 0.1218  time: 0.6804  data_time: 0.1772  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:38:48 d2.utils.events]: \u001b[0m eta: 0:42:54  iter: 5179  total_loss: 1.509  loss_cls: 0.3814  loss_box_reg: 0.5707  loss_mask: 0.3087  loss_rpn_cls: 0.06933  loss_rpn_loc: 0.1546  time: 0.6812  data_time: 0.3581  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:39:00 d2.utils.events]: \u001b[0m eta: 0:42:37  iter: 5199  total_loss: 1.277  loss_cls: 0.3256  loss_box_reg: 0.5347  loss_mask: 0.2788  loss_rpn_cls: 0.03396  loss_rpn_loc: 0.1071  time: 0.6811  data_time: 0.1262  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:39:14 d2.utils.events]: \u001b[0m eta: 0:42:26  iter: 5219  total_loss: 1.386  loss_cls: 0.3446  loss_box_reg: 0.5608  loss_mask: 0.2925  loss_rpn_cls: 0.07297  loss_rpn_loc: 0.1124  time: 0.6810  data_time: 0.1619  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:39:30 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 5239  total_loss: 1.352  loss_cls: 0.3378  loss_box_reg: 0.5716  loss_mask: 0.2935  loss_rpn_cls: 0.05419  loss_rpn_loc: 0.1188  time: 0.6814  data_time: 0.2924  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:39:43 d2.utils.events]: \u001b[0m eta: 0:42:00  iter: 5259  total_loss: 1.364  loss_cls: 0.34  loss_box_reg: 0.5762  loss_mask: 0.2855  loss_rpn_cls: 0.05504  loss_rpn_loc: 0.127  time: 0.6813  data_time: 0.1510  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:39:55 d2.utils.events]: \u001b[0m eta: 0:41:46  iter: 5279  total_loss: 1.484  loss_cls: 0.3645  loss_box_reg: 0.5817  loss_mask: 0.3122  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.1421  time: 0.6811  data_time: 0.1178  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:40:08 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 5299  total_loss: 1.423  loss_cls: 0.358  loss_box_reg: 0.5578  loss_mask: 0.2887  loss_rpn_cls: 0.05799  loss_rpn_loc: 0.1394  time: 0.6810  data_time: 0.1486  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:40:23 d2.utils.events]: \u001b[0m eta: 0:41:23  iter: 5319  total_loss: 1.306  loss_cls: 0.3421  loss_box_reg: 0.5369  loss_mask: 0.2969  loss_rpn_cls: 0.04147  loss_rpn_loc: 0.1251  time: 0.6813  data_time: 0.2265  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:40:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:40:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:40:27 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:40:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:40:27 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:40:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1136 s/iter. Eval: 0.0565 s/iter. Total: 0.1707 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1233 s/iter. Eval: 0.1356 s/iter. Total: 0.2598 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1247 s/iter. Eval: 0.1437 s/iter. Total: 0.2693 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1230 s/iter. Eval: 0.1329 s/iter. Total: 0.2567 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 19:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1274 s/iter. Eval: 0.1603 s/iter. Total: 0.2886 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1292 s/iter. Eval: 0.1671 s/iter. Total: 0.2972 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 19:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.1284 s/iter. Eval: 0.1597 s/iter. Total: 0.2890 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 19:41:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.775290 (0.291166 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:41:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.129024 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:41:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:41:02 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2963205392861376\n",
      "\u001b[32m[02/06 19:41:13 d2.utils.events]: \u001b[0m eta: 0:41:13  iter: 5339  total_loss: 1.342  loss_cls: 0.3329  loss_box_reg: 0.5366  loss_mask: 0.2908  loss_rpn_cls: 0.04763  loss_rpn_loc: 0.1086  time: 0.6813  data_time: 0.1645  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:41:29 d2.utils.events]: \u001b[0m eta: 0:40:59  iter: 5359  total_loss: 1.388  loss_cls: 0.3573  loss_box_reg: 0.5658  loss_mask: 0.3005  loss_rpn_cls: 0.06321  loss_rpn_loc: 0.1265  time: 0.6818  data_time: 0.2937  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:41:42 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 5379  total_loss: 1.381  loss_cls: 0.3425  loss_box_reg: 0.5595  loss_mask: 0.2917  loss_rpn_cls: 0.04755  loss_rpn_loc: 0.1197  time: 0.6816  data_time: 0.0995  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:41:54 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 5399  total_loss: 1.321  loss_cls: 0.3142  loss_box_reg: 0.5536  loss_mask: 0.3047  loss_rpn_cls: 0.03554  loss_rpn_loc: 0.08093  time: 0.6813  data_time: 0.1046  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:42:08 d2.utils.events]: \u001b[0m eta: 0:40:27  iter: 5419  total_loss: 1.475  loss_cls: 0.3516  loss_box_reg: 0.5684  loss_mask: 0.2864  loss_rpn_cls: 0.05601  loss_rpn_loc: 0.1383  time: 0.6815  data_time: 0.2062  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:42:21 d2.utils.events]: \u001b[0m eta: 0:40:17  iter: 5439  total_loss: 1.32  loss_cls: 0.3129  loss_box_reg: 0.5404  loss_mask: 0.304  loss_rpn_cls: 0.04416  loss_rpn_loc: 0.116  time: 0.6812  data_time: 0.1217  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:42:34 d2.utils.events]: \u001b[0m eta: 0:40:05  iter: 5459  total_loss: 1.351  loss_cls: 0.3489  loss_box_reg: 0.5685  loss_mask: 0.3014  loss_rpn_cls: 0.0303  loss_rpn_loc: 0.1084  time: 0.6811  data_time: 0.1402  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:42:48 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 5479  total_loss: 1.362  loss_cls: 0.3375  loss_box_reg: 0.5578  loss_mask: 0.2975  loss_rpn_cls: 0.04568  loss_rpn_loc: 0.1231  time: 0.6812  data_time: 0.1973  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:43:03 d2.utils.events]: \u001b[0m eta: 0:39:46  iter: 5499  total_loss: 1.413  loss_cls: 0.368  loss_box_reg: 0.5576  loss_mask: 0.2898  loss_rpn_cls: 0.06278  loss_rpn_loc: 0.1256  time: 0.6814  data_time: 0.2119  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:43:19 d2.utils.events]: \u001b[0m eta: 0:39:35  iter: 5519  total_loss: 1.481  loss_cls: 0.3759  loss_box_reg: 0.5878  loss_mask: 0.2969  loss_rpn_cls: 0.04582  loss_rpn_loc: 0.1476  time: 0.6820  data_time: 0.2942  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:43:35 d2.utils.events]: \u001b[0m eta: 0:39:29  iter: 5539  total_loss: 1.339  loss_cls: 0.3275  loss_box_reg: 0.5445  loss_mask: 0.2771  loss_rpn_cls: 0.0552  loss_rpn_loc: 0.1285  time: 0.6823  data_time: 0.2380  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:43:46 d2.utils.events]: \u001b[0m eta: 0:39:22  iter: 5559  total_loss: 1.261  loss_cls: 0.3043  loss_box_reg: 0.5182  loss_mask: 0.268  loss_rpn_cls: 0.03808  loss_rpn_loc: 0.1053  time: 0.6819  data_time: 0.0622  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:43:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:43:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:43:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:43:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:43:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:43:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1120 s/iter. Eval: 0.0552 s/iter. Total: 0.1678 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:43:58 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1233 s/iter. Eval: 0.1292 s/iter. Total: 0.2534 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:44:03 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1259 s/iter. Eval: 0.1389 s/iter. Total: 0.2656 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1237 s/iter. Eval: 0.1287 s/iter. Total: 0.2532 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 19:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1283 s/iter. Eval: 0.1556 s/iter. Total: 0.2848 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:44:19 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1299 s/iter. Eval: 0.1622 s/iter. Total: 0.2930 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 19:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 117/121. Dataloading: 0.0008 s/iter. Inference: 0.1288 s/iter. Eval: 0.1535 s/iter. Total: 0.2832 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 19:44:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.225904 (0.286430 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:44:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.129545 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:44:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:44:26 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29189456156544247\n",
      "\u001b[32m[02/06 19:44:36 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 5579  total_loss: 1.387  loss_cls: 0.3425  loss_box_reg: 0.5571  loss_mask: 0.2976  loss_rpn_cls: 0.05652  loss_rpn_loc: 0.1271  time: 0.6820  data_time: 0.1741  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:44:49 d2.utils.events]: \u001b[0m eta: 0:39:02  iter: 5599  total_loss: 1.379  loss_cls: 0.3419  loss_box_reg: 0.5571  loss_mask: 0.2938  loss_rpn_cls: 0.04216  loss_rpn_loc: 0.1172  time: 0.6819  data_time: 0.1554  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:45:02 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 5619  total_loss: 1.277  loss_cls: 0.309  loss_box_reg: 0.5408  loss_mask: 0.2832  loss_rpn_cls: 0.04937  loss_rpn_loc: 0.1084  time: 0.6818  data_time: 0.1514  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:45:18 d2.utils.events]: \u001b[0m eta: 0:38:41  iter: 5639  total_loss: 1.384  loss_cls: 0.361  loss_box_reg: 0.5512  loss_mask: 0.2973  loss_rpn_cls: 0.05255  loss_rpn_loc: 0.1341  time: 0.6823  data_time: 0.3081  lr: 0.0002048  max_mem: 6836M\n",
      "\u001b[32m[02/06 19:45:34 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 5659  total_loss: 1.4  loss_cls: 0.3399  loss_box_reg: 0.5588  loss_mask: 0.2948  loss_rpn_cls: 0.06273  loss_rpn_loc: 0.1264  time: 0.6826  data_time: 0.2558  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:45:47 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 5679  total_loss: 1.389  loss_cls: 0.3361  loss_box_reg: 0.5643  loss_mask: 0.2988  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.1418  time: 0.6825  data_time: 0.1268  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:46:04 d2.utils.events]: \u001b[0m eta: 0:38:10  iter: 5699  total_loss: 1.457  loss_cls: 0.3787  loss_box_reg: 0.5626  loss_mask: 0.2998  loss_rpn_cls: 0.07043  loss_rpn_loc: 0.141  time: 0.6832  data_time: 0.3480  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:46:16 d2.utils.events]: \u001b[0m eta: 0:37:58  iter: 5719  total_loss: 1.384  loss_cls: 0.34  loss_box_reg: 0.5453  loss_mask: 0.2897  loss_rpn_cls: 0.04588  loss_rpn_loc: 0.1343  time: 0.6828  data_time: 0.0904  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:46:32 d2.utils.events]: \u001b[0m eta: 0:37:48  iter: 5739  total_loss: 1.423  loss_cls: 0.3721  loss_box_reg: 0.5901  loss_mask: 0.308  loss_rpn_cls: 0.06131  loss_rpn_loc: 0.1501  time: 0.6832  data_time: 0.2539  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:46:47 d2.utils.events]: \u001b[0m eta: 0:37:37  iter: 5759  total_loss: 1.333  loss_cls: 0.3356  loss_box_reg: 0.5673  loss_mask: 0.3094  loss_rpn_cls: 0.05604  loss_rpn_loc: 0.1003  time: 0.6835  data_time: 0.2543  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:47:00 d2.utils.events]: \u001b[0m eta: 0:37:26  iter: 5779  total_loss: 1.318  loss_cls: 0.321  loss_box_reg: 0.5508  loss_mask: 0.288  loss_rpn_cls: 0.05399  loss_rpn_loc: 0.1211  time: 0.6833  data_time: 0.1060  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:47:11 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 5799  total_loss: 1.219  loss_cls: 0.3034  loss_box_reg: 0.5246  loss_mask: 0.278  loss_rpn_cls: 0.03221  loss_rpn_loc: 0.08515  time: 0.6829  data_time: 0.0851  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:47:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:47:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:47:18 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:47:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:47:18 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:47:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:47:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1081 s/iter. Eval: 0.0534 s/iter. Total: 0.1621 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/06 19:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1203 s/iter. Eval: 0.1298 s/iter. Total: 0.2510 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1222 s/iter. Eval: 0.1360 s/iter. Total: 0.2590 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1204 s/iter. Eval: 0.1304 s/iter. Total: 0.2516 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1256 s/iter. Eval: 0.1548 s/iter. Total: 0.2813 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/06 19:47:47 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1265 s/iter. Eval: 0.1624 s/iter. Total: 0.2897 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 19:47:52 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1255 s/iter. Eval: 0.1526 s/iter. Total: 0.2789 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 19:47:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.438329 (0.279641 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:47:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.125615 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:47:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:47:52 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2963375614569468\n",
      "\u001b[32m[02/06 19:47:59 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 5819  total_loss: 1.334  loss_cls: 0.3211  loss_box_reg: 0.5322  loss_mask: 0.2901  loss_rpn_cls: 0.04723  loss_rpn_loc: 0.128  time: 0.6828  data_time: 0.1591  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:48:14 d2.utils.events]: \u001b[0m eta: 0:36:51  iter: 5839  total_loss: 1.429  loss_cls: 0.3696  loss_box_reg: 0.5744  loss_mask: 0.3033  loss_rpn_cls: 0.0666  loss_rpn_loc: 0.1354  time: 0.6832  data_time: 0.2581  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:48:29 d2.utils.events]: \u001b[0m eta: 0:36:38  iter: 5859  total_loss: 1.348  loss_cls: 0.3318  loss_box_reg: 0.5571  loss_mask: 0.2856  loss_rpn_cls: 0.04334  loss_rpn_loc: 0.1284  time: 0.6832  data_time: 0.2118  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:48:43 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 5879  total_loss: 1.434  loss_cls: 0.3515  loss_box_reg: 0.565  loss_mask: 0.312  loss_rpn_cls: 0.06443  loss_rpn_loc: 0.1341  time: 0.6834  data_time: 0.2248  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:48:58 d2.utils.events]: \u001b[0m eta: 0:36:18  iter: 5899  total_loss: 1.335  loss_cls: 0.3478  loss_box_reg: 0.5392  loss_mask: 0.2862  loss_rpn_cls: 0.05069  loss_rpn_loc: 0.1211  time: 0.6836  data_time: 0.2323  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:49:12 d2.utils.events]: \u001b[0m eta: 0:36:08  iter: 5919  total_loss: 1.268  loss_cls: 0.3053  loss_box_reg: 0.5368  loss_mask: 0.288  loss_rpn_cls: 0.04013  loss_rpn_loc: 0.09807  time: 0.6836  data_time: 0.1676  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:49:25 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 5939  total_loss: 1.362  loss_cls: 0.344  loss_box_reg: 0.5331  loss_mask: 0.2891  loss_rpn_cls: 0.07012  loss_rpn_loc: 0.1303  time: 0.6836  data_time: 0.1797  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:49:41 d2.utils.events]: \u001b[0m eta: 0:35:50  iter: 5959  total_loss: 1.368  loss_cls: 0.3385  loss_box_reg: 0.5423  loss_mask: 0.2845  loss_rpn_cls: 0.05779  loss_rpn_loc: 0.126  time: 0.6840  data_time: 0.2786  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:49:53 d2.utils.events]: \u001b[0m eta: 0:35:38  iter: 5979  total_loss: 1.381  loss_cls: 0.3488  loss_box_reg: 0.5638  loss_mask: 0.2968  loss_rpn_cls: 0.03683  loss_rpn_loc: 0.1122  time: 0.6836  data_time: 0.0978  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:50:08 d2.utils.events]: \u001b[0m eta: 0:35:28  iter: 5999  total_loss: 1.351  loss_cls: 0.3292  loss_box_reg: 0.5472  loss_mask: 0.2849  loss_rpn_cls: 0.04702  loss_rpn_loc: 0.1081  time: 0.6839  data_time: 0.2314  lr: 0.0002048  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:50:22 d2.utils.events]: \u001b[0m eta: 0:35:18  iter: 6019  total_loss: 1.282  loss_cls: 0.3318  loss_box_reg: 0.5366  loss_mask: 0.2775  loss_rpn_cls: 0.04704  loss_rpn_loc: 0.1162  time: 0.6838  data_time: 0.1470  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:50:35 d2.utils.events]: \u001b[0m eta: 0:35:08  iter: 6039  total_loss: 1.297  loss_cls: 0.3337  loss_box_reg: 0.5501  loss_mask: 0.2865  loss_rpn_cls: 0.03844  loss_rpn_loc: 0.1143  time: 0.6838  data_time: 0.1646  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:50:41 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:50:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:50:41 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:50:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:50:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:50:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1113 s/iter. Eval: 0.0536 s/iter. Total: 0.1656 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1233 s/iter. Eval: 0.1342 s/iter. Total: 0.2584 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1242 s/iter. Eval: 0.1384 s/iter. Total: 0.2635 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1213 s/iter. Eval: 0.1331 s/iter. Total: 0.2553 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1265 s/iter. Eval: 0.1585 s/iter. Total: 0.2859 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1280 s/iter. Eval: 0.1656 s/iter. Total: 0.2945 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 19:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1269 s/iter. Eval: 0.1558 s/iter. Total: 0.2835 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 19:51:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.959412 (0.284133 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:51:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127022 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:51:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:51:16 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29759999878986787\n",
      "\u001b[32m[02/06 19:51:21 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 6059  total_loss: 1.372  loss_cls: 0.3432  loss_box_reg: 0.5556  loss_mask: 0.2947  loss_rpn_cls: 0.0504  loss_rpn_loc: 0.1302  time: 0.6834  data_time: 0.0752  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:51:36 d2.utils.events]: \u001b[0m eta: 0:34:46  iter: 6079  total_loss: 1.411  loss_cls: 0.355  loss_box_reg: 0.5689  loss_mask: 0.2962  loss_rpn_cls: 0.05788  loss_rpn_loc: 0.1183  time: 0.6836  data_time: 0.2566  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:51:49 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 6099  total_loss: 1.254  loss_cls: 0.2974  loss_box_reg: 0.5376  loss_mask: 0.2949  loss_rpn_cls: 0.04037  loss_rpn_loc: 0.101  time: 0.6835  data_time: 0.1563  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:52:04 d2.utils.events]: \u001b[0m eta: 0:34:24  iter: 6119  total_loss: 1.369  loss_cls: 0.3203  loss_box_reg: 0.5598  loss_mask: 0.2734  loss_rpn_cls: 0.04757  loss_rpn_loc: 0.1212  time: 0.6837  data_time: 0.2397  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:52:17 d2.utils.events]: \u001b[0m eta: 0:34:12  iter: 6139  total_loss: 1.461  loss_cls: 0.3699  loss_box_reg: 0.5834  loss_mask: 0.2994  loss_rpn_cls: 0.04911  loss_rpn_loc: 0.1121  time: 0.6836  data_time: 0.1551  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:52:31 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 6159  total_loss: 1.261  loss_cls: 0.31  loss_box_reg: 0.5378  loss_mask: 0.2809  loss_rpn_cls: 0.03471  loss_rpn_loc: 0.1281  time: 0.6836  data_time: 0.1825  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:52:46 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 6179  total_loss: 1.443  loss_cls: 0.3517  loss_box_reg: 0.5753  loss_mask: 0.2921  loss_rpn_cls: 0.06345  loss_rpn_loc: 0.1392  time: 0.6838  data_time: 0.1977  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:53:01 d2.utils.events]: \u001b[0m eta: 0:33:42  iter: 6199  total_loss: 1.328  loss_cls: 0.338  loss_box_reg: 0.5382  loss_mask: 0.3029  loss_rpn_cls: 0.03394  loss_rpn_loc: 0.1149  time: 0.6840  data_time: 0.2016  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:53:16 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 6219  total_loss: 1.443  loss_cls: 0.3659  loss_box_reg: 0.5642  loss_mask: 0.3112  loss_rpn_cls: 0.0642  loss_rpn_loc: 0.1229  time: 0.6842  data_time: 0.2385  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:53:29 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 6239  total_loss: 1.305  loss_cls: 0.322  loss_box_reg: 0.5433  loss_mask: 0.2805  loss_rpn_cls: 0.04396  loss_rpn_loc: 0.1132  time: 0.6841  data_time: 0.1381  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:53:41 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 6259  total_loss: 1.418  loss_cls: 0.3508  loss_box_reg: 0.5827  loss_mask: 0.3093  loss_rpn_cls: 0.03662  loss_rpn_loc: 0.1267  time: 0.6838  data_time: 0.0874  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:53:54 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 6279  total_loss: 1.309  loss_cls: 0.3201  loss_box_reg: 0.5482  loss_mask: 0.2887  loss_rpn_cls: 0.03808  loss_rpn_loc: 0.0975  time: 0.6837  data_time: 0.1558  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:54:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:54:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:54:04 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:54:04 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:54:04 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:54:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1115 s/iter. Eval: 0.0570 s/iter. Total: 0.1692 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 19:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1259 s/iter. Eval: 0.1329 s/iter. Total: 0.2596 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 19:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1246 s/iter. Eval: 0.1385 s/iter. Total: 0.2640 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1224 s/iter. Eval: 0.1329 s/iter. Total: 0.2561 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 19:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1270 s/iter. Eval: 0.1574 s/iter. Total: 0.2853 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:54:33 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1280 s/iter. Eval: 0.1644 s/iter. Total: 0.2933 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 19:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1274 s/iter. Eval: 0.1547 s/iter. Total: 0.2830 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 19:54:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.922157 (0.283812 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:54:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127689 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:54:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:54:38 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29753266037696874\n",
      "\u001b[32m[02/06 19:54:43 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 6299  total_loss: 1.262  loss_cls: 0.3412  loss_box_reg: 0.5109  loss_mask: 0.2774  loss_rpn_cls: 0.03936  loss_rpn_loc: 0.09522  time: 0.6839  data_time: 0.1957  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:54:58 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 6319  total_loss: 1.447  loss_cls: 0.3473  loss_box_reg: 0.5564  loss_mask: 0.3131  loss_rpn_cls: 0.05565  loss_rpn_loc: 0.1303  time: 0.6840  data_time: 0.1958  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:55:09 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 6339  total_loss: 1.386  loss_cls: 0.3425  loss_box_reg: 0.5531  loss_mask: 0.2927  loss_rpn_cls: 0.04757  loss_rpn_loc: 0.1038  time: 0.6836  data_time: 0.0539  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:55:22 d2.utils.events]: \u001b[0m eta: 0:32:17  iter: 6359  total_loss: 1.274  loss_cls: 0.3171  loss_box_reg: 0.5188  loss_mask: 0.2957  loss_rpn_cls: 0.03973  loss_rpn_loc: 0.1162  time: 0.6835  data_time: 0.1691  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:55:39 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 6379  total_loss: 1.402  loss_cls: 0.3646  loss_box_reg: 0.5578  loss_mask: 0.2801  loss_rpn_cls: 0.05502  loss_rpn_loc: 0.1307  time: 0.6840  data_time: 0.2981  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:55:52 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 6399  total_loss: 1.345  loss_cls: 0.3378  loss_box_reg: 0.5356  loss_mask: 0.2844  loss_rpn_cls: 0.04332  loss_rpn_loc: 0.09977  time: 0.6839  data_time: 0.1689  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:56:07 d2.utils.events]: \u001b[0m eta: 0:31:46  iter: 6419  total_loss: 1.32  loss_cls: 0.3321  loss_box_reg: 0.5451  loss_mask: 0.2925  loss_rpn_cls: 0.04142  loss_rpn_loc: 0.1397  time: 0.6842  data_time: 0.2212  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:56:21 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 6439  total_loss: 1.466  loss_cls: 0.3558  loss_box_reg: 0.5903  loss_mask: 0.3192  loss_rpn_cls: 0.05838  loss_rpn_loc: 0.1274  time: 0.6841  data_time: 0.1821  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:56:34 d2.utils.events]: \u001b[0m eta: 0:31:29  iter: 6459  total_loss: 1.354  loss_cls: 0.3297  loss_box_reg: 0.5493  loss_mask: 0.2889  loss_rpn_cls: 0.03891  loss_rpn_loc: 0.121  time: 0.6841  data_time: 0.1550  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:56:47 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 6479  total_loss: 1.329  loss_cls: 0.3213  loss_box_reg: 0.5405  loss_mask: 0.2792  loss_rpn_cls: 0.04219  loss_rpn_loc: 0.1133  time: 0.6839  data_time: 0.1279  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:57:00 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 6499  total_loss: 1.345  loss_cls: 0.342  loss_box_reg: 0.5367  loss_mask: 0.2894  loss_rpn_cls: 0.04682  loss_rpn_loc: 0.1335  time: 0.6838  data_time: 0.1137  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:57:12 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 6519  total_loss: 1.376  loss_cls: 0.3481  loss_box_reg: 0.5526  loss_mask: 0.2859  loss_rpn_cls: 0.04614  loss_rpn_loc: 0.114  time: 0.6836  data_time: 0.1192  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:57:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:57:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 19:57:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 19:57:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 19:57:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 19:57:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 19:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1166 s/iter. Eval: 0.0572 s/iter. Total: 0.1745 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 19:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1274 s/iter. Eval: 0.1371 s/iter. Total: 0.2654 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 19:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.1293 s/iter. Eval: 0.1487 s/iter. Total: 0.2788 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 19:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.1266 s/iter. Eval: 0.1358 s/iter. Total: 0.2633 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 19:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0008 s/iter. Inference: 0.1309 s/iter. Eval: 0.1593 s/iter. Total: 0.2911 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 19:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0008 s/iter. Inference: 0.1324 s/iter. Eval: 0.1658 s/iter. Total: 0.2991 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 19:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0008 s/iter. Inference: 0.1317 s/iter. Eval: 0.1634 s/iter. Total: 0.2961 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/06 19:58:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.161640 (0.294497 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:58:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.131403 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 19:58:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 19:58:00 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2965567507346403\n",
      "\u001b[32m[02/06 19:58:04 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 6539  total_loss: 1.444  loss_cls: 0.3581  loss_box_reg: 0.5921  loss_mask: 0.2965  loss_rpn_cls: 0.06225  loss_rpn_loc: 0.1359  time: 0.6838  data_time: 0.2138  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:58:19 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 6559  total_loss: 1.411  loss_cls: 0.3462  loss_box_reg: 0.5675  loss_mask: 0.3015  loss_rpn_cls: 0.05376  loss_rpn_loc: 0.1091  time: 0.6840  data_time: 0.2474  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:58:31 d2.utils.events]: \u001b[0m eta: 0:30:21  iter: 6579  total_loss: 1.34  loss_cls: 0.3254  loss_box_reg: 0.5479  loss_mask: 0.2955  loss_rpn_cls: 0.03687  loss_rpn_loc: 0.1078  time: 0.6838  data_time: 0.0921  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:58:43 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 6599  total_loss: 1.454  loss_cls: 0.3535  loss_box_reg: 0.6062  loss_mask: 0.3075  loss_rpn_cls: 0.04774  loss_rpn_loc: 0.1195  time: 0.6835  data_time: 0.0799  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:58:55 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 6619  total_loss: 1.399  loss_cls: 0.3547  loss_box_reg: 0.5751  loss_mask: 0.2926  loss_rpn_cls: 0.04502  loss_rpn_loc: 0.1145  time: 0.6834  data_time: 0.1108  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:59:12 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 6639  total_loss: 1.283  loss_cls: 0.3191  loss_box_reg: 0.5367  loss_mask: 0.2803  loss_rpn_cls: 0.05565  loss_rpn_loc: 0.1226  time: 0.6838  data_time: 0.2958  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:59:26 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 6659  total_loss: 1.471  loss_cls: 0.3662  loss_box_reg: 0.5812  loss_mask: 0.2914  loss_rpn_cls: 0.06373  loss_rpn_loc: 0.1377  time: 0.6839  data_time: 0.2100  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:59:40 d2.utils.events]: \u001b[0m eta: 0:29:28  iter: 6679  total_loss: 1.316  loss_cls: 0.3203  loss_box_reg: 0.5344  loss_mask: 0.2757  loss_rpn_cls: 0.02881  loss_rpn_loc: 0.1084  time: 0.6840  data_time: 0.1994  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 19:59:56 d2.utils.events]: \u001b[0m eta: 0:29:17  iter: 6699  total_loss: 1.373  loss_cls: 0.3625  loss_box_reg: 0.5365  loss_mask: 0.2826  loss_rpn_cls: 0.05715  loss_rpn_loc: 0.1261  time: 0.6842  data_time: 0.2478  lr: 0.00016384  max_mem: 6922M\n",
      "\u001b[32m[02/06 20:00:11 d2.utils.events]: \u001b[0m eta: 0:29:07  iter: 6719  total_loss: 1.36  loss_cls: 0.3148  loss_box_reg: 0.5593  loss_mask: 0.3225  loss_rpn_cls: 0.04224  loss_rpn_loc: 0.09723  time: 0.6845  data_time: 0.2707  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:00:25 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 6739  total_loss: 1.285  loss_cls: 0.324  loss_box_reg: 0.5202  loss_mask: 0.2845  loss_rpn_cls: 0.04475  loss_rpn_loc: 0.1118  time: 0.6845  data_time: 0.1844  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:00:38 d2.utils.events]: \u001b[0m eta: 0:28:44  iter: 6759  total_loss: 1.285  loss_cls: 0.3111  loss_box_reg: 0.5211  loss_mask: 0.2825  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.1146  time: 0.6844  data_time: 0.1289  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:00:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:00:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:00:51 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:00:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:00:51 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:00:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:00:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1161 s/iter. Eval: 0.0571 s/iter. Total: 0.1738 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:00:59 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1241 s/iter. Eval: 0.1293 s/iter. Total: 0.2542 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:01:04 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1254 s/iter. Eval: 0.1383 s/iter. Total: 0.2645 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:01:09 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1236 s/iter. Eval: 0.1277 s/iter. Total: 0.2521 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 20:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1288 s/iter. Eval: 0.1538 s/iter. Total: 0.2834 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1295 s/iter. Eval: 0.1620 s/iter. Total: 0.2923 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:01:25 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1280 s/iter. Eval: 0.1522 s/iter. Total: 0.2810 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:01:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.666646 (0.281609 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:01:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.128059 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:01:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:01:25 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29836631072303643\n",
      "\u001b[32m[02/06 20:01:27 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 6779  total_loss: 1.463  loss_cls: 0.3765  loss_box_reg: 0.5674  loss_mask: 0.2932  loss_rpn_cls: 0.04947  loss_rpn_loc: 0.1479  time: 0.6845  data_time: 0.2032  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:01:44 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 6799  total_loss: 1.367  loss_cls: 0.3484  loss_box_reg: 0.5549  loss_mask: 0.3029  loss_rpn_cls: 0.04222  loss_rpn_loc: 0.1283  time: 0.6849  data_time: 0.2974  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:01:57 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 6819  total_loss: 1.362  loss_cls: 0.3427  loss_box_reg: 0.554  loss_mask: 0.2901  loss_rpn_cls: 0.04803  loss_rpn_loc: 0.1272  time: 0.6848  data_time: 0.1474  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:02:11 d2.utils.events]: \u001b[0m eta: 0:28:03  iter: 6839  total_loss: 1.302  loss_cls: 0.3117  loss_box_reg: 0.5491  loss_mask: 0.2817  loss_rpn_cls: 0.05512  loss_rpn_loc: 0.09622  time: 0.6849  data_time: 0.2015  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:02:26 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 6859  total_loss: 1.39  loss_cls: 0.3077  loss_box_reg: 0.5754  loss_mask: 0.3035  loss_rpn_cls: 0.05505  loss_rpn_loc: 0.1132  time: 0.6851  data_time: 0.2591  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:02:41 d2.utils.events]: \u001b[0m eta: 0:27:45  iter: 6879  total_loss: 1.355  loss_cls: 0.3403  loss_box_reg: 0.5558  loss_mask: 0.2962  loss_rpn_cls: 0.06169  loss_rpn_loc: 0.1143  time: 0.6853  data_time: 0.2378  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:02:53 d2.utils.events]: \u001b[0m eta: 0:27:31  iter: 6899  total_loss: 1.173  loss_cls: 0.2854  loss_box_reg: 0.5095  loss_mask: 0.2737  loss_rpn_cls: 0.02275  loss_rpn_loc: 0.07424  time: 0.6850  data_time: 0.0742  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:03:07 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 6919  total_loss: 1.325  loss_cls: 0.3415  loss_box_reg: 0.5442  loss_mask: 0.2997  loss_rpn_cls: 0.04331  loss_rpn_loc: 0.1159  time: 0.6851  data_time: 0.2113  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:03:25 d2.utils.events]: \u001b[0m eta: 0:27:09  iter: 6939  total_loss: 1.325  loss_cls: 0.3474  loss_box_reg: 0.5417  loss_mask: 0.2915  loss_rpn_cls: 0.04998  loss_rpn_loc: 0.1247  time: 0.6856  data_time: 0.3372  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:03:38 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 6959  total_loss: 1.337  loss_cls: 0.3469  loss_box_reg: 0.5782  loss_mask: 0.2811  loss_rpn_cls: 0.0563  loss_rpn_loc: 0.1219  time: 0.6856  data_time: 0.1664  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:03:51 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 6979  total_loss: 1.306  loss_cls: 0.3236  loss_box_reg: 0.5345  loss_mask: 0.2923  loss_rpn_cls: 0.03426  loss_rpn_loc: 0.1144  time: 0.6854  data_time: 0.1112  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:04:05 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 6999  total_loss: 1.326  loss_cls: 0.3334  loss_box_reg: 0.5141  loss_mask: 0.2877  loss_rpn_cls: 0.0391  loss_rpn_loc: 0.1136  time: 0.6855  data_time: 0.1978  lr: 0.00016384  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:04:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:04:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:04:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:04:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:04:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:04:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1167 s/iter. Eval: 0.0552 s/iter. Total: 0.1725 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1259 s/iter. Eval: 0.1294 s/iter. Total: 0.2561 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1271 s/iter. Eval: 0.1369 s/iter. Total: 0.2648 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:04:40 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1241 s/iter. Eval: 0.1314 s/iter. Total: 0.2564 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:04:45 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1283 s/iter. Eval: 0.1562 s/iter. Total: 0.2853 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:04:50 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1292 s/iter. Eval: 0.1624 s/iter. Total: 0.2924 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:04:55 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1271 s/iter. Eval: 0.1525 s/iter. Total: 0.2805 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:04:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.617216 (0.281183 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:04:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127235 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:04:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:04:56 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.298396986667848\n",
      "\u001b[32m[02/06 20:04:57 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 7019  total_loss: 1.463  loss_cls: 0.3469  loss_box_reg: 0.5634  loss_mask: 0.3054  loss_rpn_cls: 0.05526  loss_rpn_loc: 0.1273  time: 0.6860  data_time: 0.3131  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:05:10 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 7039  total_loss: 1.356  loss_cls: 0.3392  loss_box_reg: 0.5503  loss_mask: 0.291  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.1397  time: 0.6859  data_time: 0.1649  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:05:26 d2.utils.events]: \u001b[0m eta: 0:26:12  iter: 7059  total_loss: 1.438  loss_cls: 0.36  loss_box_reg: 0.5705  loss_mask: 0.3047  loss_rpn_cls: 0.05711  loss_rpn_loc: 0.1389  time: 0.6863  data_time: 0.3037  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:05:42 d2.utils.events]: \u001b[0m eta: 0:26:03  iter: 7079  total_loss: 1.349  loss_cls: 0.3473  loss_box_reg: 0.5308  loss_mask: 0.2939  loss_rpn_cls: 0.04909  loss_rpn_loc: 0.1138  time: 0.6866  data_time: 0.2617  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:05:55 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 7099  total_loss: 1.23  loss_cls: 0.3163  loss_box_reg: 0.5413  loss_mask: 0.2967  loss_rpn_cls: 0.03106  loss_rpn_loc: 0.1038  time: 0.6864  data_time: 0.1326  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:06:08 d2.utils.events]: \u001b[0m eta: 0:25:39  iter: 7119  total_loss: 1.302  loss_cls: 0.315  loss_box_reg: 0.543  loss_mask: 0.2905  loss_rpn_cls: 0.03977  loss_rpn_loc: 0.106  time: 0.6863  data_time: 0.1639  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:06:21 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 7139  total_loss: 1.345  loss_cls: 0.34  loss_box_reg: 0.5457  loss_mask: 0.2862  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.1211  time: 0.6862  data_time: 0.1378  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:06:33 d2.utils.events]: \u001b[0m eta: 0:25:17  iter: 7159  total_loss: 1.329  loss_cls: 0.3495  loss_box_reg: 0.5518  loss_mask: 0.2854  loss_rpn_cls: 0.03709  loss_rpn_loc: 0.1213  time: 0.6860  data_time: 0.1160  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:06:47 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 7179  total_loss: 1.406  loss_cls: 0.3618  loss_box_reg: 0.5647  loss_mask: 0.3013  loss_rpn_cls: 0.04617  loss_rpn_loc: 0.1305  time: 0.6861  data_time: 0.2205  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:07:03 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 7199  total_loss: 1.413  loss_cls: 0.3514  loss_box_reg: 0.559  loss_mask: 0.3023  loss_rpn_cls: 0.07021  loss_rpn_loc: 0.1374  time: 0.6864  data_time: 0.2632  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:07:18 d2.utils.events]: \u001b[0m eta: 0:24:45  iter: 7219  total_loss: 1.367  loss_cls: 0.3442  loss_box_reg: 0.5518  loss_mask: 0.2986  loss_rpn_cls: 0.05707  loss_rpn_loc: 0.1321  time: 0.6865  data_time: 0.2126  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:07:30 d2.utils.events]: \u001b[0m eta: 0:24:31  iter: 7239  total_loss: 1.261  loss_cls: 0.3142  loss_box_reg: 0.5235  loss_mask: 0.2786  loss_rpn_cls: 0.04181  loss_rpn_loc: 0.1175  time: 0.6863  data_time: 0.1252  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:07:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:07:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:07:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:07:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:07:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:07:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1189 s/iter. Eval: 0.0591 s/iter. Total: 0.1786 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1271 s/iter. Eval: 0.1381 s/iter. Total: 0.2660 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 20:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0009 s/iter. Inference: 0.1262 s/iter. Eval: 0.1450 s/iter. Total: 0.2721 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 20:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1229 s/iter. Eval: 0.1336 s/iter. Total: 0.2573 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 20:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0008 s/iter. Inference: 0.1272 s/iter. Eval: 0.1590 s/iter. Total: 0.2871 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0008 s/iter. Inference: 0.1293 s/iter. Eval: 0.1659 s/iter. Total: 0.2961 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 20:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0008 s/iter. Inference: 0.1289 s/iter. Eval: 0.1640 s/iter. Total: 0.2938 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/06 20:08:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.923370 (0.292443 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:08:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.128760 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:08:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:08:20 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2990969744648899\n",
      "\u001b[32m[02/06 20:08:20 d2.utils.events]: \u001b[0m eta: 0:24:20  iter: 7259  total_loss: 1.36  loss_cls: 0.3297  loss_box_reg: 0.5657  loss_mask: 0.2915  loss_rpn_cls: 0.05422  loss_rpn_loc: 0.1162  time: 0.6863  data_time: 0.1827  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:08:32 d2.utils.events]: \u001b[0m eta: 0:24:13  iter: 7279  total_loss: 1.378  loss_cls: 0.3411  loss_box_reg: 0.5465  loss_mask: 0.2898  loss_rpn_cls: 0.04777  loss_rpn_loc: 0.1314  time: 0.6861  data_time: 0.1005  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:08:50 d2.utils.events]: \u001b[0m eta: 0:24:03  iter: 7299  total_loss: 1.345  loss_cls: 0.3416  loss_box_reg: 0.5438  loss_mask: 0.2931  loss_rpn_cls: 0.05285  loss_rpn_loc: 0.1194  time: 0.6866  data_time: 0.3359  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:09:06 d2.utils.events]: \u001b[0m eta: 0:23:54  iter: 7319  total_loss: 1.401  loss_cls: 0.3664  loss_box_reg: 0.5522  loss_mask: 0.2798  loss_rpn_cls: 0.04933  loss_rpn_loc: 0.1363  time: 0.6870  data_time: 0.2739  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:09:21 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 7339  total_loss: 1.268  loss_cls: 0.3269  loss_box_reg: 0.5197  loss_mask: 0.2927  loss_rpn_cls: 0.0363  loss_rpn_loc: 0.08773  time: 0.6872  data_time: 0.2463  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:09:37 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 7359  total_loss: 1.323  loss_cls: 0.3471  loss_box_reg: 0.5669  loss_mask: 0.3051  loss_rpn_cls: 0.05387  loss_rpn_loc: 0.1242  time: 0.6875  data_time: 0.2696  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:09:51 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 7379  total_loss: 1.282  loss_cls: 0.3132  loss_box_reg: 0.5236  loss_mask: 0.2878  loss_rpn_cls: 0.0456  loss_rpn_loc: 0.1082  time: 0.6875  data_time: 0.1958  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:10:06 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 7399  total_loss: 1.313  loss_cls: 0.3294  loss_box_reg: 0.5307  loss_mask: 0.2788  loss_rpn_cls: 0.05123  loss_rpn_loc: 0.1331  time: 0.6876  data_time: 0.1952  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:10:20 d2.utils.events]: \u001b[0m eta: 0:23:00  iter: 7419  total_loss: 1.354  loss_cls: 0.3427  loss_box_reg: 0.539  loss_mask: 0.2767  loss_rpn_cls: 0.05126  loss_rpn_loc: 0.1171  time: 0.6877  data_time: 0.2124  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:10:33 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 7439  total_loss: 1.252  loss_cls: 0.3047  loss_box_reg: 0.5266  loss_mask: 0.2927  loss_rpn_cls: 0.03335  loss_rpn_loc: 0.1018  time: 0.6876  data_time: 0.1370  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:10:45 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 7459  total_loss: 1.363  loss_cls: 0.3189  loss_box_reg: 0.5478  loss_mask: 0.3057  loss_rpn_cls: 0.04872  loss_rpn_loc: 0.1142  time: 0.6873  data_time: 0.0839  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:10:59 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 7479  total_loss: 1.364  loss_cls: 0.3452  loss_box_reg: 0.5528  loss_mask: 0.2996  loss_rpn_cls: 0.04913  loss_rpn_loc: 0.1123  time: 0.6874  data_time: 0.1816  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:11:12 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 7499  total_loss: 1.306  loss_cls: 0.3221  loss_box_reg: 0.5357  loss_mask: 0.289  loss_rpn_cls: 0.04064  loss_rpn_loc: 0.1135  time: 0.6873  data_time: 0.1365  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:11:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:11:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:11:14 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:11:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:11:14 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:11:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:11:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1140 s/iter. Eval: 0.0561 s/iter. Total: 0.1708 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:11:21 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1236 s/iter. Eval: 0.1284 s/iter. Total: 0.2529 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:11:26 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1239 s/iter. Eval: 0.1347 s/iter. Total: 0.2595 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:11:32 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1215 s/iter. Eval: 0.1289 s/iter. Total: 0.2512 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:11:37 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.1261 s/iter. Eval: 0.1514 s/iter. Total: 0.2784 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/06 20:11:42 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1276 s/iter. Eval: 0.1596 s/iter. Total: 0.2881 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:11:47 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1266 s/iter. Eval: 0.1503 s/iter. Total: 0.2777 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:11:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.308902 (0.278525 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:11:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.126770 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:11:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:11:48 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29945344315679573\n",
      "\u001b[32m[02/06 20:11:59 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 7519  total_loss: 1.433  loss_cls: 0.3536  loss_box_reg: 0.5548  loss_mask: 0.2962  loss_rpn_cls: 0.04536  loss_rpn_loc: 0.1235  time: 0.6871  data_time: 0.0996  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:12:11 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 7539  total_loss: 1.266  loss_cls: 0.3115  loss_box_reg: 0.5134  loss_mask: 0.2843  loss_rpn_cls: 0.04332  loss_rpn_loc: 0.1044  time: 0.6869  data_time: 0.1035  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:12:23 d2.utils.events]: \u001b[0m eta: 0:21:41  iter: 7559  total_loss: 1.284  loss_cls: 0.3321  loss_box_reg: 0.5396  loss_mask: 0.2837  loss_rpn_cls: 0.03603  loss_rpn_loc: 0.1211  time: 0.6867  data_time: 0.0839  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:12:41 d2.utils.events]: \u001b[0m eta: 0:21:32  iter: 7579  total_loss: 1.385  loss_cls: 0.3468  loss_box_reg: 0.5353  loss_mask: 0.2925  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.1368  time: 0.6873  data_time: 0.3819  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:12:53 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 7599  total_loss: 1.311  loss_cls: 0.3363  loss_box_reg: 0.5622  loss_mask: 0.2951  loss_rpn_cls: 0.04185  loss_rpn_loc: 0.1173  time: 0.6871  data_time: 0.1009  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:13:05 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 7619  total_loss: 1.112  loss_cls: 0.2569  loss_box_reg: 0.488  loss_mask: 0.2631  loss_rpn_cls: 0.02174  loss_rpn_loc: 0.07806  time: 0.6867  data_time: 0.0680  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:13:20 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 7639  total_loss: 1.324  loss_cls: 0.3162  loss_box_reg: 0.5834  loss_mask: 0.3119  loss_rpn_cls: 0.03573  loss_rpn_loc: 0.08859  time: 0.6869  data_time: 0.2440  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:13:37 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 7659  total_loss: 1.405  loss_cls: 0.3691  loss_box_reg: 0.5582  loss_mask: 0.2996  loss_rpn_cls: 0.05544  loss_rpn_loc: 0.1269  time: 0.6874  data_time: 0.3382  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:13:51 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 7679  total_loss: 1.372  loss_cls: 0.329  loss_box_reg: 0.5679  loss_mask: 0.2942  loss_rpn_cls: 0.03772  loss_rpn_loc: 0.1216  time: 0.6874  data_time: 0.1704  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:14:04 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 7699  total_loss: 1.33  loss_cls: 0.3395  loss_box_reg: 0.5568  loss_mask: 0.2804  loss_rpn_cls: 0.04651  loss_rpn_loc: 0.1333  time: 0.6873  data_time: 0.1486  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:14:18 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 7719  total_loss: 1.365  loss_cls: 0.348  loss_box_reg: 0.5565  loss_mask: 0.3033  loss_rpn_cls: 0.04548  loss_rpn_loc: 0.1245  time: 0.6874  data_time: 0.1880  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:14:32 d2.utils.events]: \u001b[0m eta: 0:20:06  iter: 7739  total_loss: 1.363  loss_cls: 0.3459  loss_box_reg: 0.5619  loss_mask: 0.2812  loss_rpn_cls: 0.06092  loss_rpn_loc: 0.1355  time: 0.6873  data_time: 0.1478  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:14:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:14:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:14:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:14:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:14:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:14:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:14:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1123 s/iter. Eval: 0.0560 s/iter. Total: 0.1689 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:14:45 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0007 s/iter. Inference: 0.1255 s/iter. Eval: 0.1357 s/iter. Total: 0.2620 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 20:14:50 d2.evaluation.evaluator]: \u001b[0mInference done 46/121. Dataloading: 0.0008 s/iter. Inference: 0.1285 s/iter. Eval: 0.1479 s/iter. Total: 0.2772 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 20:14:55 d2.evaluation.evaluator]: \u001b[0mInference done 68/121. Dataloading: 0.0008 s/iter. Inference: 0.1255 s/iter. Eval: 0.1352 s/iter. Total: 0.2615 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 20:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 80/121. Dataloading: 0.0008 s/iter. Inference: 0.1290 s/iter. Eval: 0.1588 s/iter. Total: 0.2886 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0008 s/iter. Inference: 0.1313 s/iter. Eval: 0.1673 s/iter. Total: 0.2995 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/06 20:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0008 s/iter. Inference: 0.1299 s/iter. Eval: 0.1626 s/iter. Total: 0.2933 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/06 20:15:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.859172 (0.291889 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:15:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.129581 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:15:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:15:12 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29705051262115223\n",
      "\u001b[32m[02/06 20:15:22 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 7759  total_loss: 1.285  loss_cls: 0.3303  loss_box_reg: 0.5425  loss_mask: 0.2953  loss_rpn_cls: 0.05363  loss_rpn_loc: 0.1299  time: 0.6873  data_time: 0.1834  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:15:34 d2.utils.events]: \u001b[0m eta: 0:19:44  iter: 7779  total_loss: 1.388  loss_cls: 0.3486  loss_box_reg: 0.5495  loss_mask: 0.3001  loss_rpn_cls: 0.04674  loss_rpn_loc: 0.09579  time: 0.6872  data_time: 0.1229  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:15:48 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 7799  total_loss: 1.401  loss_cls: 0.3473  loss_box_reg: 0.5435  loss_mask: 0.2837  loss_rpn_cls: 0.05232  loss_rpn_loc: 0.1225  time: 0.6872  data_time: 0.1695  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:16:01 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 7819  total_loss: 1.323  loss_cls: 0.3364  loss_box_reg: 0.5278  loss_mask: 0.2904  loss_rpn_cls: 0.0439  loss_rpn_loc: 0.1115  time: 0.6871  data_time: 0.1575  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:16:16 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 7839  total_loss: 1.489  loss_cls: 0.3874  loss_box_reg: 0.5847  loss_mask: 0.3179  loss_rpn_cls: 0.0623  loss_rpn_loc: 0.1397  time: 0.6872  data_time: 0.2013  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:16:30 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 7859  total_loss: 1.319  loss_cls: 0.3176  loss_box_reg: 0.554  loss_mask: 0.2914  loss_rpn_cls: 0.02747  loss_rpn_loc: 0.1193  time: 0.6873  data_time: 0.2025  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:16:44 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 7879  total_loss: 1.372  loss_cls: 0.3288  loss_box_reg: 0.5617  loss_mask: 0.2988  loss_rpn_cls: 0.03933  loss_rpn_loc: 0.1232  time: 0.6873  data_time: 0.1862  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:16:55 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 7899  total_loss: 1.276  loss_cls: 0.3128  loss_box_reg: 0.5328  loss_mask: 0.2829  loss_rpn_cls: 0.03418  loss_rpn_loc: 0.09529  time: 0.6869  data_time: 0.0680  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:17:11 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 7919  total_loss: 1.448  loss_cls: 0.3476  loss_box_reg: 0.5757  loss_mask: 0.3075  loss_rpn_cls: 0.06608  loss_rpn_loc: 0.1313  time: 0.6872  data_time: 0.2761  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:17:23 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 7939  total_loss: 1.337  loss_cls: 0.339  loss_box_reg: 0.55  loss_mask: 0.2791  loss_rpn_cls: 0.05513  loss_rpn_loc: 0.121  time: 0.6871  data_time: 0.1213  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:17:38 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 7959  total_loss: 1.319  loss_cls: 0.3359  loss_box_reg: 0.5368  loss_mask: 0.2864  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.1164  time: 0.6872  data_time: 0.2237  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:17:50 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 7979  total_loss: 1.154  loss_cls: 0.2859  loss_box_reg: 0.49  loss_mask: 0.2673  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.07706  time: 0.6869  data_time: 0.0920  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:17:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:17:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:17:55 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:17:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:17:55 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:17:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:17:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1097 s/iter. Eval: 0.0550 s/iter. Total: 0.1653 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:18:03 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1203 s/iter. Eval: 0.1300 s/iter. Total: 0.2511 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1223 s/iter. Eval: 0.1377 s/iter. Total: 0.2609 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:18:13 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.1207 s/iter. Eval: 0.1281 s/iter. Total: 0.2496 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1256 s/iter. Eval: 0.1550 s/iter. Total: 0.2815 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.1271 s/iter. Eval: 0.1599 s/iter. Total: 0.2878 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.1261 s/iter. Eval: 0.1536 s/iter. Total: 0.2805 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:18:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.730864 (0.282163 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:18:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.126517 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:18:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:18:29 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29858415207402306\n",
      "\u001b[32m[02/06 20:18:38 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 7999  total_loss: 1.398  loss_cls: 0.3593  loss_box_reg: 0.5611  loss_mask: 0.3002  loss_rpn_cls: 0.05538  loss_rpn_loc: 0.1336  time: 0.6869  data_time: 0.1920  lr: 0.00013107  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:18:55 d2.utils.events]: \u001b[0m eta: 0:17:32  iter: 8019  total_loss: 1.411  loss_cls: 0.3479  loss_box_reg: 0.5617  loss_mask: 0.2886  loss_rpn_cls: 0.05402  loss_rpn_loc: 0.1252  time: 0.6873  data_time: 0.2851  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:19:06 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 8039  total_loss: 1.39  loss_cls: 0.3563  loss_box_reg: 0.5542  loss_mask: 0.287  loss_rpn_cls: 0.04357  loss_rpn_loc: 0.1348  time: 0.6870  data_time: 0.0664  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:19:21 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 8059  total_loss: 1.414  loss_cls: 0.3516  loss_box_reg: 0.5844  loss_mask: 0.3064  loss_rpn_cls: 0.06182  loss_rpn_loc: 0.1276  time: 0.6870  data_time: 0.2136  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:19:35 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 8079  total_loss: 1.369  loss_cls: 0.3388  loss_box_reg: 0.5461  loss_mask: 0.2877  loss_rpn_cls: 0.04446  loss_rpn_loc: 0.1164  time: 0.6871  data_time: 0.1850  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:19:50 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 8099  total_loss: 1.38  loss_cls: 0.3516  loss_box_reg: 0.5588  loss_mask: 0.2896  loss_rpn_cls: 0.05583  loss_rpn_loc: 0.135  time: 0.6873  data_time: 0.2697  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:20:03 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 8119  total_loss: 1.293  loss_cls: 0.3306  loss_box_reg: 0.5326  loss_mask: 0.2816  loss_rpn_cls: 0.03388  loss_rpn_loc: 0.118  time: 0.6871  data_time: 0.0970  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:20:13 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 8139  total_loss: 1.141  loss_cls: 0.2786  loss_box_reg: 0.501  loss_mask: 0.2675  loss_rpn_cls: 0.02458  loss_rpn_loc: 0.07925  time: 0.6868  data_time: 0.0470  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:20:29 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 8159  total_loss: 1.406  loss_cls: 0.3518  loss_box_reg: 0.5503  loss_mask: 0.2853  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.1455  time: 0.6870  data_time: 0.2622  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:20:44 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 8179  total_loss: 1.331  loss_cls: 0.3434  loss_box_reg: 0.554  loss_mask: 0.2783  loss_rpn_cls: 0.04501  loss_rpn_loc: 0.1312  time: 0.6871  data_time: 0.2179  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:20:54 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 8199  total_loss: 1.225  loss_cls: 0.297  loss_box_reg: 0.5327  loss_mask: 0.2815  loss_rpn_cls: 0.02911  loss_rpn_loc: 0.09546  time: 0.6867  data_time: 0.0471  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:21:11 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 8219  total_loss: 1.349  loss_cls: 0.3492  loss_box_reg: 0.5483  loss_mask: 0.2785  loss_rpn_cls: 0.05466  loss_rpn_loc: 0.1241  time: 0.6871  data_time: 0.2830  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:21:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:21:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:21:19 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:21:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:21:19 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:21:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1116 s/iter. Eval: 0.0538 s/iter. Total: 0.1661 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1201 s/iter. Eval: 0.1291 s/iter. Total: 0.2500 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1236 s/iter. Eval: 0.1384 s/iter. Total: 0.2628 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:21:37 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1215 s/iter. Eval: 0.1289 s/iter. Total: 0.2513 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 20:21:42 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1262 s/iter. Eval: 0.1560 s/iter. Total: 0.2831 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 97/121. Dataloading: 0.0008 s/iter. Inference: 0.1274 s/iter. Eval: 0.1608 s/iter. Total: 0.2891 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.1264 s/iter. Eval: 0.1549 s/iter. Total: 0.2822 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:21:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.989197 (0.284390 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:21:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127114 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:21:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:21:53 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2987570304177652\n",
      "\u001b[32m[02/06 20:22:01 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 8239  total_loss: 1.4  loss_cls: 0.3578  loss_box_reg: 0.5606  loss_mask: 0.2899  loss_rpn_cls: 0.05187  loss_rpn_loc: 0.1306  time: 0.6873  data_time: 0.2249  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:22:15 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 8259  total_loss: 1.459  loss_cls: 0.3637  loss_box_reg: 0.5639  loss_mask: 0.2953  loss_rpn_cls: 0.04873  loss_rpn_loc: 0.1103  time: 0.6872  data_time: 0.1757  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:22:29 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 8279  total_loss: 1.322  loss_cls: 0.3363  loss_box_reg: 0.5259  loss_mask: 0.2833  loss_rpn_cls: 0.05172  loss_rpn_loc: 0.1105  time: 0.6872  data_time: 0.1557  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:22:42 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 8299  total_loss: 1.292  loss_cls: 0.3347  loss_box_reg: 0.5515  loss_mask: 0.2778  loss_rpn_cls: 0.02909  loss_rpn_loc: 0.1017  time: 0.6872  data_time: 0.1769  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:22:56 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 8319  total_loss: 1.38  loss_cls: 0.3136  loss_box_reg: 0.5642  loss_mask: 0.2962  loss_rpn_cls: 0.05025  loss_rpn_loc: 0.1168  time: 0.6872  data_time: 0.1846  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:23:11 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 8339  total_loss: 1.386  loss_cls: 0.3425  loss_box_reg: 0.5722  loss_mask: 0.2901  loss_rpn_cls: 0.04494  loss_rpn_loc: 0.1298  time: 0.6873  data_time: 0.1894  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:23:23 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 8359  total_loss: 1.253  loss_cls: 0.3055  loss_box_reg: 0.5189  loss_mask: 0.2737  loss_rpn_cls: 0.02616  loss_rpn_loc: 0.11  time: 0.6871  data_time: 0.1074  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:23:35 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 8379  total_loss: 1.322  loss_cls: 0.3185  loss_box_reg: 0.5542  loss_mask: 0.2838  loss_rpn_cls: 0.05329  loss_rpn_loc: 0.1273  time: 0.6870  data_time: 0.1173  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:23:50 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 8399  total_loss: 1.344  loss_cls: 0.3409  loss_box_reg: 0.5806  loss_mask: 0.2948  loss_rpn_cls: 0.04309  loss_rpn_loc: 0.1029  time: 0.6871  data_time: 0.2267  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:24:02 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 8419  total_loss: 1.335  loss_cls: 0.3195  loss_box_reg: 0.5558  loss_mask: 0.2906  loss_rpn_cls: 0.03863  loss_rpn_loc: 0.111  time: 0.6869  data_time: 0.1028  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:24:18 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 8439  total_loss: 1.285  loss_cls: 0.3276  loss_box_reg: 0.5293  loss_mask: 0.2767  loss_rpn_cls: 0.04759  loss_rpn_loc: 0.1306  time: 0.6872  data_time: 0.2755  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:24:33 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 8459  total_loss: 1.376  loss_cls: 0.3415  loss_box_reg: 0.5726  loss_mask: 0.3033  loss_rpn_cls: 0.03631  loss_rpn_loc: 0.1166  time: 0.6873  data_time: 0.2019  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:24:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:24:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:24:42 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:24:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:24:42 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:24:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0006 s/iter. Inference: 0.1170 s/iter. Eval: 0.0587 s/iter. Total: 0.1763 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:24:50 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1246 s/iter. Eval: 0.1338 s/iter. Total: 0.2593 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1255 s/iter. Eval: 0.1399 s/iter. Total: 0.2663 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 70/121. Dataloading: 0.0008 s/iter. Inference: 0.1229 s/iter. Eval: 0.1298 s/iter. Total: 0.2536 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1277 s/iter. Eval: 0.1569 s/iter. Total: 0.2855 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1293 s/iter. Eval: 0.1640 s/iter. Total: 0.2942 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 20:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0008 s/iter. Inference: 0.1285 s/iter. Eval: 0.1573 s/iter. Total: 0.2866 s/iter. ETA=0:00:01\n",
      "\u001b[32m[02/06 20:25:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.485841 (0.288671 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:25:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.129069 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:25:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:25:17 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2970760987247646\n",
      "\u001b[32m[02/06 20:25:27 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 8479  total_loss: 1.403  loss_cls: 0.3691  loss_box_reg: 0.548  loss_mask: 0.2891  loss_rpn_cls: 0.04831  loss_rpn_loc: 0.1296  time: 0.6878  data_time: 0.3402  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:25:43 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 8499  total_loss: 1.391  loss_cls: 0.3539  loss_box_reg: 0.5492  loss_mask: 0.2935  loss_rpn_cls: 0.04388  loss_rpn_loc: 0.1387  time: 0.6880  data_time: 0.2552  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:25:55 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 8519  total_loss: 1.361  loss_cls: 0.33  loss_box_reg: 0.5406  loss_mask: 0.2805  loss_rpn_cls: 0.04363  loss_rpn_loc: 0.1272  time: 0.6879  data_time: 0.1300  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:26:10 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 8539  total_loss: 1.364  loss_cls: 0.3405  loss_box_reg: 0.5541  loss_mask: 0.2918  loss_rpn_cls: 0.04877  loss_rpn_loc: 0.1372  time: 0.6880  data_time: 0.2261  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:26:24 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 8559  total_loss: 1.422  loss_cls: 0.3715  loss_box_reg: 0.5674  loss_mask: 0.2955  loss_rpn_cls: 0.04922  loss_rpn_loc: 0.1291  time: 0.6881  data_time: 0.1749  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:26:39 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 8579  total_loss: 1.259  loss_cls: 0.3074  loss_box_reg: 0.5378  loss_mask: 0.2881  loss_rpn_cls: 0.04228  loss_rpn_loc: 0.1226  time: 0.6882  data_time: 0.1985  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:26:52 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 8599  total_loss: 1.357  loss_cls: 0.3313  loss_box_reg: 0.5581  loss_mask: 0.2949  loss_rpn_cls: 0.04491  loss_rpn_loc: 0.1211  time: 0.6881  data_time: 0.1556  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:27:06 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 8619  total_loss: 1.41  loss_cls: 0.3452  loss_box_reg: 0.5639  loss_mask: 0.2908  loss_rpn_cls: 0.0439  loss_rpn_loc: 0.122  time: 0.6881  data_time: 0.1668  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:27:23 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 8639  total_loss: 1.395  loss_cls: 0.3608  loss_box_reg: 0.5472  loss_mask: 0.298  loss_rpn_cls: 0.04862  loss_rpn_loc: 0.1258  time: 0.6885  data_time: 0.3173  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:27:34 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 8659  total_loss: 1.267  loss_cls: 0.3049  loss_box_reg: 0.5366  loss_mask: 0.2943  loss_rpn_cls: 0.02501  loss_rpn_loc: 0.111  time: 0.6882  data_time: 0.0713  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:27:48 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 8679  total_loss: 1.34  loss_cls: 0.3356  loss_box_reg: 0.5645  loss_mask: 0.2863  loss_rpn_cls: 0.04565  loss_rpn_loc: 0.122  time: 0.6882  data_time: 0.1636  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:28:01 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 8699  total_loss: 1.295  loss_cls: 0.3254  loss_box_reg: 0.5388  loss_mask: 0.2885  loss_rpn_cls: 0.04723  loss_rpn_loc: 0.104  time: 0.6881  data_time: 0.1537  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:28:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:28:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:28:10 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:28:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:28:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:28:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1113 s/iter. Eval: 0.0612 s/iter. Total: 0.1732 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 30/121. Dataloading: 0.0008 s/iter. Inference: 0.1208 s/iter. Eval: 0.1404 s/iter. Total: 0.2621 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.1222 s/iter. Eval: 0.1361 s/iter. Total: 0.2592 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1208 s/iter. Eval: 0.1334 s/iter. Total: 0.2550 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1260 s/iter. Eval: 0.1577 s/iter. Total: 0.2846 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1281 s/iter. Eval: 0.1642 s/iter. Total: 0.2932 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1273 s/iter. Eval: 0.1544 s/iter. Total: 0.2825 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:28:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.904400 (0.283659 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:28:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127474 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:28:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:28:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29877439915631004\n",
      "\u001b[32m[02/06 20:28:49 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 8719  total_loss: 1.291  loss_cls: 0.3108  loss_box_reg: 0.5251  loss_mask: 0.2861  loss_rpn_cls: 0.03635  loss_rpn_loc: 0.1119  time: 0.6881  data_time: 0.1602  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:29:01 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 8739  total_loss: 1.143  loss_cls: 0.2626  loss_box_reg: 0.5197  loss_mask: 0.2849  loss_rpn_cls: 0.02348  loss_rpn_loc: 0.06259  time: 0.6878  data_time: 0.0609  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:29:17 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 8759  total_loss: 1.358  loss_cls: 0.3398  loss_box_reg: 0.5231  loss_mask: 0.2864  loss_rpn_cls: 0.04297  loss_rpn_loc: 0.1185  time: 0.6881  data_time: 0.2722  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:29:29 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 8779  total_loss: 1.4  loss_cls: 0.3373  loss_box_reg: 0.5591  loss_mask: 0.2892  loss_rpn_cls: 0.04951  loss_rpn_loc: 0.1275  time: 0.6879  data_time: 0.0957  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:29:49 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 8799  total_loss: 1.487  loss_cls: 0.3637  loss_box_reg: 0.5774  loss_mask: 0.311  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.1475  time: 0.6886  data_time: 0.4355  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:30:06 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 8819  total_loss: 1.398  loss_cls: 0.3647  loss_box_reg: 0.5697  loss_mask: 0.2882  loss_rpn_cls: 0.04996  loss_rpn_loc: 0.1384  time: 0.6890  data_time: 0.3245  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:30:19 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 8839  total_loss: 1.313  loss_cls: 0.3211  loss_box_reg: 0.5353  loss_mask: 0.2979  loss_rpn_cls: 0.05437  loss_rpn_loc: 0.1246  time: 0.6889  data_time: 0.1252  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:30:31 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 8859  total_loss: 1.329  loss_cls: 0.3261  loss_box_reg: 0.5432  loss_mask: 0.2924  loss_rpn_cls: 0.03762  loss_rpn_loc: 0.1241  time: 0.6887  data_time: 0.1113  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:30:46 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 8879  total_loss: 1.28  loss_cls: 0.3145  loss_box_reg: 0.531  loss_mask: 0.2897  loss_rpn_cls: 0.04643  loss_rpn_loc: 0.1188  time: 0.6888  data_time: 0.2079  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:30:58 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 8899  total_loss: 1.254  loss_cls: 0.3107  loss_box_reg: 0.5373  loss_mask: 0.2724  loss_rpn_cls: 0.03536  loss_rpn_loc: 0.1184  time: 0.6886  data_time: 0.1145  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:31:12 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 8919  total_loss: 1.451  loss_cls: 0.3643  loss_box_reg: 0.5652  loss_mask: 0.2914  loss_rpn_cls: 0.05471  loss_rpn_loc: 0.1476  time: 0.6887  data_time: 0.1852  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:31:25 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 8939  total_loss: 1.269  loss_cls: 0.291  loss_box_reg: 0.5515  loss_mask: 0.2823  loss_rpn_cls: 0.03309  loss_rpn_loc: 0.09427  time: 0.6886  data_time: 0.1471  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:31:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:31:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:31:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:31:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:31:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:31:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1117 s/iter. Eval: 0.0578 s/iter. Total: 0.1702 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1239 s/iter. Eval: 0.1332 s/iter. Total: 0.2579 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1259 s/iter. Eval: 0.1402 s/iter. Total: 0.2670 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1238 s/iter. Eval: 0.1307 s/iter. Total: 0.2553 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 20:31:57 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1286 s/iter. Eval: 0.1570 s/iter. Total: 0.2865 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:32:02 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0008 s/iter. Inference: 0.1297 s/iter. Eval: 0.1646 s/iter. Total: 0.2952 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 20:32:07 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0008 s/iter. Inference: 0.1278 s/iter. Eval: 0.1562 s/iter. Total: 0.2849 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:32:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.235449 (0.286512 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:32:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.128179 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:32:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:32:08 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2985026095104949\n",
      "\u001b[32m[02/06 20:32:11 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 8959  total_loss: 1.419  loss_cls: 0.3502  loss_box_reg: 0.5558  loss_mask: 0.294  loss_rpn_cls: 0.04773  loss_rpn_loc: 0.1304  time: 0.6882  data_time: 0.0296  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:32:28 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 8979  total_loss: 1.428  loss_cls: 0.3531  loss_box_reg: 0.5585  loss_mask: 0.2951  loss_rpn_cls: 0.05633  loss_rpn_loc: 0.1356  time: 0.6886  data_time: 0.3000  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:32:46 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 8999  total_loss: 1.404  loss_cls: 0.3562  loss_box_reg: 0.5478  loss_mask: 0.2992  loss_rpn_cls: 0.06457  loss_rpn_loc: 0.1301  time: 0.6890  data_time: 0.3427  lr: 0.00010486  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:32:57 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 9019  total_loss: 1.304  loss_cls: 0.3143  loss_box_reg: 0.5582  loss_mask: 0.2984  loss_rpn_cls: 0.03118  loss_rpn_loc: 0.1236  time: 0.6887  data_time: 0.0737  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:33:14 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 9039  total_loss: 1.195  loss_cls: 0.2985  loss_box_reg: 0.4962  loss_mask: 0.2656  loss_rpn_cls: 0.03755  loss_rpn_loc: 0.09937  time: 0.6890  data_time: 0.3204  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:33:26 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 9059  total_loss: 1.377  loss_cls: 0.351  loss_box_reg: 0.5486  loss_mask: 0.3031  loss_rpn_cls: 0.04394  loss_rpn_loc: 0.1218  time: 0.6889  data_time: 0.1065  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:33:41 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 9079  total_loss: 1.403  loss_cls: 0.3355  loss_box_reg: 0.5433  loss_mask: 0.3034  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.1389  time: 0.6890  data_time: 0.2461  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:33:55 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 9099  total_loss: 1.288  loss_cls: 0.3116  loss_box_reg: 0.5563  loss_mask: 0.2805  loss_rpn_cls: 0.03258  loss_rpn_loc: 0.09816  time: 0.6890  data_time: 0.1557  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:34:08 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 9119  total_loss: 1.348  loss_cls: 0.3248  loss_box_reg: 0.5567  loss_mask: 0.2799  loss_rpn_cls: 0.04672  loss_rpn_loc: 0.1262  time: 0.6889  data_time: 0.1479  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:34:22 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 9139  total_loss: 1.413  loss_cls: 0.3484  loss_box_reg: 0.5735  loss_mask: 0.2969  loss_rpn_cls: 0.05243  loss_rpn_loc: 0.123  time: 0.6889  data_time: 0.1724  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:34:34 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 9159  total_loss: 1.346  loss_cls: 0.3279  loss_box_reg: 0.5614  loss_mask: 0.2939  loss_rpn_cls: 0.03328  loss_rpn_loc: 0.1188  time: 0.6888  data_time: 0.1017  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:34:48 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 9179  total_loss: 1.407  loss_cls: 0.3516  loss_box_reg: 0.5768  loss_mask: 0.287  loss_rpn_cls: 0.0659  loss_rpn_loc: 0.127  time: 0.6888  data_time: 0.1823  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:35:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:35:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:35:02 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:35:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:35:02 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:35:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1198 s/iter. Eval: 0.0655 s/iter. Total: 0.1861 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 20:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0009 s/iter. Inference: 0.1251 s/iter. Eval: 0.1349 s/iter. Total: 0.2609 s/iter. ETA=0:00:24\n",
      "\u001b[32m[02/06 20:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1254 s/iter. Eval: 0.1424 s/iter. Total: 0.2687 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1230 s/iter. Eval: 0.1316 s/iter. Total: 0.2556 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 20:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 81/121. Dataloading: 0.0008 s/iter. Inference: 0.1269 s/iter. Eval: 0.1568 s/iter. Total: 0.2846 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:35:31 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1279 s/iter. Eval: 0.1655 s/iter. Total: 0.2943 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0009 s/iter. Inference: 0.1258 s/iter. Eval: 0.1553 s/iter. Total: 0.2821 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:35:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.826665 (0.282988 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:35:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.126030 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:35:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:35:37 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.2966427246407789\n",
      "\u001b[32m[02/06 20:35:39 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 9199  total_loss: 1.468  loss_cls: 0.3634  loss_box_reg: 0.5862  loss_mask: 0.3152  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.1318  time: 0.6890  data_time: 0.2704  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:35:51 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 9219  total_loss: 1.234  loss_cls: 0.2942  loss_box_reg: 0.5123  loss_mask: 0.2765  loss_rpn_cls: 0.0398  loss_rpn_loc: 0.09634  time: 0.6888  data_time: 0.0852  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:36:03 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 9239  total_loss: 1.154  loss_cls: 0.2819  loss_box_reg: 0.4972  loss_mask: 0.2724  loss_rpn_cls: 0.02224  loss_rpn_loc: 0.08866  time: 0.6886  data_time: 0.0907  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:36:17 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 9259  total_loss: 1.364  loss_cls: 0.3438  loss_box_reg: 0.5413  loss_mask: 0.2889  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.1249  time: 0.6886  data_time: 0.1938  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:36:30 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 9279  total_loss: 1.341  loss_cls: 0.3421  loss_box_reg: 0.5494  loss_mask: 0.283  loss_rpn_cls: 0.02723  loss_rpn_loc: 0.1029  time: 0.6886  data_time: 0.1765  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:36:42 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 9299  total_loss: 1.293  loss_cls: 0.3033  loss_box_reg: 0.5454  loss_mask: 0.2917  loss_rpn_cls: 0.03908  loss_rpn_loc: 0.1194  time: 0.6884  data_time: 0.1079  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:36:56 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 9319  total_loss: 1.408  loss_cls: 0.3658  loss_box_reg: 0.551  loss_mask: 0.3171  loss_rpn_cls: 0.0565  loss_rpn_loc: 0.1371  time: 0.6884  data_time: 0.1538  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:37:10 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 9339  total_loss: 1.289  loss_cls: 0.3205  loss_box_reg: 0.5389  loss_mask: 0.2836  loss_rpn_cls: 0.04562  loss_rpn_loc: 0.1133  time: 0.6884  data_time: 0.1697  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:37:25 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 9359  total_loss: 1.283  loss_cls: 0.3199  loss_box_reg: 0.5483  loss_mask: 0.2867  loss_rpn_cls: 0.04356  loss_rpn_loc: 0.1245  time: 0.6886  data_time: 0.2257  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:37:41 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 9379  total_loss: 1.363  loss_cls: 0.345  loss_box_reg: 0.5503  loss_mask: 0.2842  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.122  time: 0.6889  data_time: 0.3187  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:37:53 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 9399  total_loss: 1.344  loss_cls: 0.3347  loss_box_reg: 0.571  loss_mask: 0.2925  loss_rpn_cls: 0.04708  loss_rpn_loc: 0.1115  time: 0.6886  data_time: 0.0573  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:38:09 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9419  total_loss: 1.364  loss_cls: 0.3489  loss_box_reg: 0.5418  loss_mask: 0.2917  loss_rpn_cls: 0.04627  loss_rpn_loc: 0.1244  time: 0.6889  data_time: 0.2908  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:38:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:38:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:38:21 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:38:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:38:21 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:38:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0610 s/iter. Total: 0.1731 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 30/121. Dataloading: 0.0008 s/iter. Inference: 0.1222 s/iter. Eval: 0.1383 s/iter. Total: 0.2614 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 51/121. Dataloading: 0.0008 s/iter. Inference: 0.1217 s/iter. Eval: 0.1319 s/iter. Total: 0.2545 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/06 20:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1211 s/iter. Eval: 0.1314 s/iter. Total: 0.2534 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1265 s/iter. Eval: 0.1563 s/iter. Total: 0.2837 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1282 s/iter. Eval: 0.1636 s/iter. Total: 0.2927 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1269 s/iter. Eval: 0.1541 s/iter. Total: 0.2819 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:38:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.806450 (0.282814 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:38:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127051 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:38:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:38:55 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29818884520752686\n",
      "\u001b[32m[02/06 20:38:56 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 9439  total_loss: 1.338  loss_cls: 0.3112  loss_box_reg: 0.5357  loss_mask: 0.3009  loss_rpn_cls: 0.04372  loss_rpn_loc: 0.0988  time: 0.6887  data_time: 0.1113  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:39:10 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 9459  total_loss: 1.348  loss_cls: 0.3262  loss_box_reg: 0.5492  loss_mask: 0.2888  loss_rpn_cls: 0.04806  loss_rpn_loc: 0.1286  time: 0.6887  data_time: 0.1838  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:39:23 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 9479  total_loss: 1.328  loss_cls: 0.3414  loss_box_reg: 0.5481  loss_mask: 0.2915  loss_rpn_cls: 0.04597  loss_rpn_loc: 0.1161  time: 0.6886  data_time: 0.1354  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:39:40 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 9499  total_loss: 1.347  loss_cls: 0.3599  loss_box_reg: 0.5232  loss_mask: 0.2854  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.1248  time: 0.6890  data_time: 0.3503  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:39:52 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9519  total_loss: 1.221  loss_cls: 0.2876  loss_box_reg: 0.515  loss_mask: 0.2833  loss_rpn_cls: 0.03999  loss_rpn_loc: 0.09886  time: 0.6888  data_time: 0.1132  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:40:07 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 9539  total_loss: 1.399  loss_cls: 0.3534  loss_box_reg: 0.5619  loss_mask: 0.2878  loss_rpn_cls: 0.04968  loss_rpn_loc: 0.131  time: 0.6889  data_time: 0.2172  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:40:20 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 9559  total_loss: 1.261  loss_cls: 0.3089  loss_box_reg: 0.5238  loss_mask: 0.2719  loss_rpn_cls: 0.04351  loss_rpn_loc: 0.1005  time: 0.6888  data_time: 0.1414  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:40:36 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 9579  total_loss: 1.31  loss_cls: 0.3425  loss_box_reg: 0.534  loss_mask: 0.2748  loss_rpn_cls: 0.05467  loss_rpn_loc: 0.1112  time: 0.6890  data_time: 0.2854  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:40:50 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 9599  total_loss: 1.367  loss_cls: 0.3408  loss_box_reg: 0.5399  loss_mask: 0.2901  loss_rpn_cls: 0.05011  loss_rpn_loc: 0.1321  time: 0.6891  data_time: 0.2224  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:41:03 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9619  total_loss: 1.304  loss_cls: 0.3213  loss_box_reg: 0.5573  loss_mask: 0.293  loss_rpn_cls: 0.0403  loss_rpn_loc: 0.1201  time: 0.6889  data_time: 0.1213  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:41:17 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 9639  total_loss: 1.342  loss_cls: 0.3359  loss_box_reg: 0.5454  loss_mask: 0.2968  loss_rpn_cls: 0.05239  loss_rpn_loc: 0.1401  time: 0.6890  data_time: 0.2231  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:41:31 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 9659  total_loss: 1.323  loss_cls: 0.3234  loss_box_reg: 0.5371  loss_mask: 0.2778  loss_rpn_cls: 0.04443  loss_rpn_loc: 0.1097  time: 0.6890  data_time: 0.1812  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:41:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:41:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:41:44 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:41:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:41:44 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:41:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1110 s/iter. Eval: 0.0615 s/iter. Total: 0.1732 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 30/121. Dataloading: 0.0008 s/iter. Inference: 0.1210 s/iter. Eval: 0.1406 s/iter. Total: 0.2626 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0008 s/iter. Inference: 0.1220 s/iter. Eval: 0.1362 s/iter. Total: 0.2590 s/iter. ETA=0:00:18\n",
      "\u001b[32m[02/06 20:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1200 s/iter. Eval: 0.1341 s/iter. Total: 0.2550 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 82/121. Dataloading: 0.0008 s/iter. Inference: 0.1261 s/iter. Eval: 0.1616 s/iter. Total: 0.2886 s/iter. ETA=0:00:11\n",
      "\u001b[32m[02/06 20:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1278 s/iter. Eval: 0.1692 s/iter. Total: 0.2979 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1265 s/iter. Eval: 0.1592 s/iter. Total: 0.2866 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:42:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.340520 (0.287418 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:42:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.126647 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:42:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:42:19 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.30043358795753217\n",
      "\u001b[32m[02/06 20:42:19 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 9679  total_loss: 1.302  loss_cls: 0.3188  loss_box_reg: 0.5478  loss_mask: 0.3076  loss_rpn_cls: 0.04142  loss_rpn_loc: 0.1155  time: 0.6889  data_time: 0.1370  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:42:35 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 9699  total_loss: 1.403  loss_cls: 0.345  loss_box_reg: 0.555  loss_mask: 0.294  loss_rpn_cls: 0.04734  loss_rpn_loc: 0.1185  time: 0.6891  data_time: 0.2883  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:42:50 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 9719  total_loss: 1.339  loss_cls: 0.3432  loss_box_reg: 0.534  loss_mask: 0.2789  loss_rpn_cls: 0.05998  loss_rpn_loc: 0.1124  time: 0.6893  data_time: 0.2382  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:43:06 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 9739  total_loss: 1.435  loss_cls: 0.3557  loss_box_reg: 0.5653  loss_mask: 0.2991  loss_rpn_cls: 0.05664  loss_rpn_loc: 0.1307  time: 0.6895  data_time: 0.2434  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:43:19 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 9759  total_loss: 1.171  loss_cls: 0.2915  loss_box_reg: 0.5065  loss_mask: 0.2804  loss_rpn_cls: 0.03486  loss_rpn_loc: 0.091  time: 0.6894  data_time: 0.1193  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:43:31 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 9779  total_loss: 1.413  loss_cls: 0.3483  loss_box_reg: 0.5787  loss_mask: 0.2938  loss_rpn_cls: 0.05074  loss_rpn_loc: 0.1305  time: 0.6892  data_time: 0.1260  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:43:47 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 9799  total_loss: 1.332  loss_cls: 0.308  loss_box_reg: 0.5379  loss_mask: 0.2963  loss_rpn_cls: 0.04396  loss_rpn_loc: 0.1263  time: 0.6894  data_time: 0.2582  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:43:58 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 9819  total_loss: 1.259  loss_cls: 0.3063  loss_box_reg: 0.5354  loss_mask: 0.279  loss_rpn_cls: 0.0505  loss_rpn_loc: 0.1134  time: 0.6891  data_time: 0.0499  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:44:10 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 9839  total_loss: 1.365  loss_cls: 0.3257  loss_box_reg: 0.5482  loss_mask: 0.2951  loss_rpn_cls: 0.04027  loss_rpn_loc: 0.1259  time: 0.6890  data_time: 0.1297  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:44:24 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 9859  total_loss: 1.329  loss_cls: 0.3273  loss_box_reg: 0.5417  loss_mask: 0.2965  loss_rpn_cls: 0.05337  loss_rpn_loc: 0.1132  time: 0.6890  data_time: 0.1747  lr: 8.3886e-05  max_mem: 6977M\n",
      "\u001b[32m[02/06 20:44:39 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 9879  total_loss: 1.297  loss_cls: 0.3062  loss_box_reg: 0.5196  loss_mask: 0.2849  loss_rpn_cls: 0.03282  loss_rpn_loc: 0.1173  time: 0.6891  data_time: 0.2404  lr: 8.3886e-05  max_mem: 7079M\n",
      "\u001b[32m[02/06 20:44:53 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 9899  total_loss: 1.339  loss_cls: 0.3317  loss_box_reg: 0.5484  loss_mask: 0.289  loss_rpn_cls: 0.04317  loss_rpn_loc: 0.1174  time: 0.6891  data_time: 0.1537  lr: 8.3886e-05  max_mem: 7079M\n",
      "\u001b[32m[02/06 20:45:09 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 9919  total_loss: 1.335  loss_cls: 0.322  loss_box_reg: 0.5234  loss_mask: 0.2849  loss_rpn_cls: 0.05653  loss_rpn_loc: 0.1263  time: 0.6894  data_time: 0.2922  lr: 8.3886e-05  max_mem: 7079M\n",
      "\u001b[32m[02/06 20:45:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:45:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:45:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:45:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:45:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:45:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0008 s/iter. Inference: 0.1162 s/iter. Eval: 0.0624 s/iter. Total: 0.1793 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1244 s/iter. Eval: 0.1299 s/iter. Total: 0.2552 s/iter. ETA=0:00:23\n",
      "\u001b[32m[02/06 20:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0008 s/iter. Inference: 0.1249 s/iter. Eval: 0.1371 s/iter. Total: 0.2629 s/iter. ETA=0:00:19\n",
      "\u001b[32m[02/06 20:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 71/121. Dataloading: 0.0008 s/iter. Inference: 0.1231 s/iter. Eval: 0.1311 s/iter. Total: 0.2551 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 83/121. Dataloading: 0.0008 s/iter. Inference: 0.1273 s/iter. Eval: 0.1536 s/iter. Total: 0.2818 s/iter. ETA=0:00:10\n",
      "\u001b[32m[02/06 20:45:40 d2.evaluation.evaluator]: \u001b[0mInference done 98/121. Dataloading: 0.0008 s/iter. Inference: 0.1288 s/iter. Eval: 0.1619 s/iter. Total: 0.2915 s/iter. ETA=0:00:06\n",
      "\u001b[32m[02/06 20:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 120/121. Dataloading: 0.0008 s/iter. Inference: 0.1272 s/iter. Eval: 0.1525 s/iter. Total: 0.2806 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/06 20:45:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.674736 (0.281679 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:45:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127437 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:45:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:45:45 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29740830551138575\n",
      "\u001b[32m[02/06 20:45:57 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9939  total_loss: 1.364  loss_cls: 0.3631  loss_box_reg: 0.562  loss_mask: 0.2966  loss_rpn_cls: 0.03993  loss_rpn_loc: 0.1378  time: 0.6892  data_time: 0.1137  lr: 8.3886e-05  max_mem: 7079M\n",
      "\u001b[32m[02/06 20:46:09 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 9959  total_loss: 1.419  loss_cls: 0.3628  loss_box_reg: 0.5771  loss_mask: 0.3048  loss_rpn_cls: 0.05445  loss_rpn_loc: 0.1385  time: 0.6891  data_time: 0.1140  lr: 8.3886e-05  max_mem: 7079M\n",
      "\u001b[32m[02/06 20:46:24 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 9979  total_loss: 1.35  loss_cls: 0.337  loss_box_reg: 0.5448  loss_mask: 0.2851  loss_rpn_cls: 0.05001  loss_rpn_loc: 0.1196  time: 0.6892  data_time: 0.2378  lr: 8.3886e-05  max_mem: 7079M\n",
      "\u001b[32m[02/06 20:46:37 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.279  loss_cls: 0.3042  loss_box_reg: 0.5451  loss_mask: 0.2888  loss_rpn_cls: 0.03586  loss_rpn_loc: 0.1033  time: 0.6891  data_time: 0.1310  lr: 8.3886e-05  max_mem: 7079M\n",
      "\u001b[32m[02/06 20:46:37 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:54:49 (0.6891 s / it)\n",
      "\u001b[32m[02/06 20:46:37 d2.engine.hooks]: \u001b[0mTotal training time: 2:19:10 (0:24:20 on hooks)\n",
      "\u001b[32m[02/06 20:46:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:46:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/06 20:46:37 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/06 20:46:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[02/06 20:46:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../sartorius-annotations-coco-format/annotations_val.json\n",
      "\u001b[32m[02/06 20:46:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[02/06 20:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0007 s/iter. Inference: 0.1170 s/iter. Eval: 0.0654 s/iter. Total: 0.1830 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 20:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0008 s/iter. Inference: 0.1274 s/iter. Eval: 0.1494 s/iter. Total: 0.2776 s/iter. ETA=0:00:25\n",
      "\u001b[32m[02/06 20:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0008 s/iter. Inference: 0.1268 s/iter. Eval: 0.1503 s/iter. Total: 0.2780 s/iter. ETA=0:00:20\n",
      "\u001b[32m[02/06 20:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 69/121. Dataloading: 0.0008 s/iter. Inference: 0.1228 s/iter. Eval: 0.1383 s/iter. Total: 0.2619 s/iter. ETA=0:00:13\n",
      "\u001b[32m[02/06 20:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0008 s/iter. Inference: 0.1268 s/iter. Eval: 0.1676 s/iter. Total: 0.2952 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/06 20:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0008 s/iter. Inference: 0.1279 s/iter. Eval: 0.1704 s/iter. Total: 0.2992 s/iter. ETA=0:00:07\n",
      "\u001b[32m[02/06 20:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0008 s/iter. Inference: 0.1268 s/iter. Eval: 0.1653 s/iter. Total: 0.2929 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/06 20:47:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.028303 (0.293347 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:47:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.127371 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/06 20:47:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[02/06 20:47:13 d2.evaluation.testing]: \u001b[0mcopypaste: mAP IoU=0.29875276168077\n"
     ]
    }
   ],
   "source": [
    "# Increasing the maximum number of detections per image\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = 'output_1.1/best_model.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.GAMMA = 0.8\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.SOLVER.STEPS = list(range(2000,10000,1000))\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 10000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 4000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000\n",
    "cfg.MODEL.PIXEL_MEAN = [127.965, 127.965, 127.965]\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .3\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[24], [40], [80], [128], [256]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 3.0]]\n",
    "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.7]\n",
    "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.75\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.03\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 700\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "os.rename(\"output\", \"output_9.14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f3222f6-d3c0-4f83-9cc5-660a7f109ba2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a2d96b0ca4c347d4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a2d96b0ca4c347d4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output_9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdfa85f6-0923-4cbe-b977-d516ee76e2d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-32e2c9da2afe6885\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-32e2c9da2afe6885\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output_9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df076b3-1b5f-4c27-a702-19fc221fc57c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-edc1292a74d789b9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-edc1292a74d789b9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03c3945-e2ae-4a1c-8923-f66cd7871ee7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bfd32c93c80b4182\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bfd32c93c80b4182\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25daef59-8399-41c8-b619-2f90044d9c25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-efc6fe0fa95ec39e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-efc6fe0fa95ec39e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f572e5a6-f153-4190-8c0e-38bf406169cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1a0785667543b108\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1a0785667543b108\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir output_9.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ebced4b-b1fa-4a5f-86ac-09b57ad3f3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  1\n",
      "mAP : 0.26894040640600936\n",
      "False negatives : 0.113113852888519\n",
      "False positives : 0.16123373938854985\n",
      "Experiment  2\n",
      "mAP : 0.2701370579642064\n",
      "False negatives : 0.11342911120800112\n",
      "False positives : 0.16442133602449874\n",
      "Experiment  3\n",
      "mAP : 0.26494994681832634\n",
      "False negatives : 0.10975767042699404\n",
      "False positives : 0.16906982250560273\n",
      "Experiment  4\n",
      "mAP : 0.27252464439209206\n",
      "False negatives : 0.11170060394335944\n",
      "False positives : 0.16533865012292878\n",
      "Experiment  5\n",
      "mAP : 0.27114199741654127\n",
      "False negatives : 0.11149395340595372\n",
      "False positives : 0.1638460054617235\n",
      "Experiment  6\n",
      "mAP : 0.2721525248472835\n",
      "False negatives : 0.11033692143454119\n",
      "False positives : 0.1658628270748274\n",
      "Experiment  7\n",
      "mAP : 0.27581772601010607\n",
      "False negatives : 0.11140320612418314\n",
      "False positives : 0.1543423591246918\n",
      "Experiment  8\n",
      "mAP : 0.2705608873056785\n",
      "False negatives : 0.10605228047482015\n",
      "False positives : 0.17166389912850488\n",
      "Experiment  9\n",
      "mAP : 0.2718862787511309\n",
      "False negatives : 0.11195976208029558\n",
      "False positives : 0.15530339841094057\n",
      "Experiment  10\n",
      "mAP : 0.27336518149774036\n",
      "False negatives : 0.11141540179796859\n",
      "False positives : 0.1552701639263907\n",
      "Experiment  11\n",
      "mAP : 0.27358596577595\n",
      "False negatives : 0.10970420002382275\n",
      "False positives : 0.16275886912138024\n",
      "Experiment  12\n",
      "mAP : 0.25071576538406093\n",
      "False negatives : 0.11011128070710414\n",
      "False positives : 0.161010489459787\n",
      "Experiment  13\n",
      "mAP : 0.2741101886076855\n",
      "False negatives : 0.10850098212711817\n",
      "False positives : 0.16018195376344724\n",
      "Experiment  14\n",
      "mAP : 0.29831205148813517\n",
      "False negatives : 0.10730141434467859\n",
      "False positives : 0.1600605839208217\n",
      "Experiment  15\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def print_metrics(output):\n",
    "    with open(f\"output_{output}/metrics.json\",'r') as f:\n",
    "        metrics = [json.loads(line) for line in f]\n",
    "    print(\"mAP :\", np.mean([metrics[i][\"mAP IoU\"] for i in range(len(metrics)) if 'mAP IoU' in metrics[i]][-10:]))\n",
    "    print(\"False negatives :\", np.mean([metrics[i][\"mask_rcnn/false_negative\"] for i in range(len(metrics)) if 'mask_rcnn/false_negative' in metrics[i]][-100:]))\n",
    "    print(\"False positives :\", np.mean([metrics[i][\"mask_rcnn/false_positive\"] for i in range(len(metrics)) if 'mask_rcnn/false_positive' in metrics[i]][-100:]))\n",
    "i=1\n",
    "while True:\n",
    "    try:\n",
    "        print(\"Experiment \",i)\n",
    "        print_metrics(\"9.\"+str(i))\n",
    "        i+=1\n",
    "    except:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
